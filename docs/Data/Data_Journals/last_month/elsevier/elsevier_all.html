<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>elsevier_all</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h1 id="elsevier">ELSEVIER</h1>
<h2 id="aij---3">AIJ - 3</h2>
<ul>
<li><details>
<summary>
(2025). ICCMA 2023: 5th international competition on computational
models of argumentation. <em>AIJ</em>, <em>342</em>, 104311. (<a
href="https://doi.org/10.1016/j.artint.2025.104311">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study of computational models of argumentation and the development of practical automated approaches to reasoning over the models has developed into a vibrant area of artificial intelligence research in recent years. The series of International Competitions on Computational Models of Argumentation (ICCMA) aims at nurturing research and development of practical reasoning algorithms for models of argumentation. Organized biennially, the ICCMA competitions provide a snapshot of the current state of the art in algorithm implementations for central fundamental reasoning tasks over models of argumentation. The year 2023 marked the 5th instantiation of International Competitions on Computational Models of Argumentation, ICCMA 2023. We provide a comprehensive overview of ICCMA 2023, including details on the various new developments introduced in 2023, overview of the participating solvers, extensive details on the competition benchmarks and results, as well as lessons learned.},
  archive      = {J_AIJ},
  author       = {Matti Järvisalo and Tuomo Lehtonen and Andreas Niskanen},
  doi          = {10.1016/j.artint.2025.104311},
  journal      = {Artificial Intelligence},
  month        = {5},
  pages        = {104311},
  shortjournal = {Artif. Intell.},
  title        = {ICCMA 2023: 5th international competition on computational models of argumentation},
  volume       = {342},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lifted inference beyond first-order logic. <em>AIJ</em>,
<em>342</em>, 104310. (<a
href="https://doi.org/10.1016/j.artint.2025.104310">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weighted First Order Model Counting (WFOMC) is fundamental to probabilistic inference in statistical relational learning models. As WFOMC is known to be intractable in general (#P-complete), logical fragments that admit polynomial time WFOMC are of significant interest. Such fragments are called domain liftable . Recent works have shown that the two-variable fragment of first order logic extended with counting quantifiers (C 2 ) is domain-liftable. However, many properties of real-world data, like acyclicity in citation networks and connectivity in social networks, cannot be modeled in C 2 , or first order logic in general. In this work, we expand the domain liftability of C 2 with multiple such properties. We show that any C 2 sentence remains domain liftable when one of its relations is restricted to represent a directed acyclic graph, a connected graph, a tree (resp. a directed tree) or a forest (resp. a directed forest). All our results rely on a novel and general methodology of counting by splitting . Besides their application to probabilistic inference, our results provide a general framework for counting combinatorial structures. We expand a vast array of previous results in discrete mathematics literature on directed acyclic graphs, phylogenetic networks, etc.},
  archive      = {J_AIJ},
  author       = {Sagar Malhotra and Davide Bizzaro and Luciano Serafini},
  doi          = {10.1016/j.artint.2025.104310},
  journal      = {Artificial Intelligence},
  month        = {5},
  pages        = {104310},
  shortjournal = {Artif. Intell.},
  title        = {Lifted inference beyond first-order logic},
  volume       = {342},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). (Re)conceptualizing trustworthy AI: A foundation for change.
<em>AIJ</em>, <em>342</em>, 104309. (<a
href="https://doi.org/10.1016/j.artint.2025.104309">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developers and academics have grown increasingly interested in developing “trustworthy” artificial intelligence (AI). However, this aim is difficult to achieve in practice, especially given trust and trustworthiness are complex, multifaceted concepts that cannot be completely guaranteed nor built entirely into an AI system. We have drawn on the breadth of trust-related literature across multiple disciplines and fields to synthesize knowledge pertaining to interpersonal trust, trust in automation, and risk and trust. Based on this review we have (re)conceptualized trustworthiness in practice as being both (a) perceptual, meaning that a user assesses whether, when, and to what extent AI model output is trustworthy, even if it has been developed in adherence to AI trustworthiness standards, and (b) context-dependent, meaning that a user&#39;s perceived trustworthiness and use of an AI model can vary based on the specifics of their situation (e.g., time-pressures for decision-making, high-stakes decisions). We provide our reconceptualization to nuance how trustworthiness is thought about, studied, and evaluated by the AI community in ways that are more aligned with past theoretical research.},
  archive      = {J_AIJ},
  author       = {Christopher D. Wirz and Julie L. Demuth and Ann Bostrom and Mariana G. Cains and Imme Ebert-Uphoff and David John Gagne II and Andrea Schumacher and Amy McGovern and Deianna Madlambayan},
  doi          = {10.1016/j.artint.2025.104309},
  journal      = {Artificial Intelligence},
  month        = {5},
  pages        = {104309},
  shortjournal = {Artif. Intell.},
  title        = {(Re)Conceptualizing trustworthy AI: A foundation for change},
  volume       = {342},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="amc---28">AMC - 28</h2>
<ul>
<li><details>
<summary>
(2025). Game strategy analysis on e-commerce platform supply chain
with shared logistics service: A chaos perspective. <em>AMC</em>,
<em>499</em>, 129414. (<a
href="https://doi.org/10.1016/j.amc.2025.129414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores a distinctive scenario within the e-commerce platform supply chain. To assess the performance of these entities, we develop models for both centralized and decentralized decision-making frameworks. Furthermore, we investigate the stability and dynamic behavior of the system during prolonged decentralized model interactions. We found that centralized decision-making has a significant advantage in terms of retail prices and profits within this supply chain. Additionally, the dynamic complexity analysis underscores the challenges of managing an e-commerce supply chain under the decentralized model framework, where finding equilibrium points for decision variables proves complex and the stable ranges for these parameters are notably limited. Higher commission rates incentivize entities to adopt more aggressive strategies, with the most pronounced impact on logistics services and wholesale prices. This adjustment can lead to a substantial decrease in platform profit when the commission rate is raised.},
  archive      = {J_AMC},
  author       = {Yuanyuan Zhang and Shaochuan Fu and Shucheng Fan and Fangfang Ma},
  doi          = {10.1016/j.amc.2025.129414},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129414},
  shortjournal = {Appl. Math. Comput.},
  title        = {Game strategy analysis on E-commerce platform supply chain with shared logistics service: A chaos perspective},
  volume       = {499},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anti-windup design for networked time-delay systems subject
to saturating actuators under round-robin protocol. <em>AMC</em>,
<em>499</em>, 129413. (<a
href="https://doi.org/10.1016/j.amc.2025.129413">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the anti-windup design for networked time-delay systems subject to saturating actuators under the round-robin protocol. Firstly, the actual measurement output is represented by the model that is dependent on a periodic function. Then, using the generalized delay-dependent sector condition, the augmented periodic Lyapunov-Krasovskii functional together with certain inequalities, an anti-windup design criterion is derived based on linear matrix inequalities under which the closed-loop systems have the desirable properties such as boundedness, H ∞ performance, and asymptotic stability. The corresponding results are also presented for the case of constant delay and the case of no time delay. Moreover, the relevant optimizations in the main results are discussed. In the end, two numerical examples illustrate the availability and advantages of the proposed results.},
  archive      = {J_AMC},
  author       = {Yonggang Chen and Yaxue Zhao and Zhou Gu and Xinfen Yang},
  doi          = {10.1016/j.amc.2025.129413},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129413},
  shortjournal = {Appl. Math. Comput.},
  title        = {Anti-windup design for networked time-delay systems subject to saturating actuators under round-robin protocol},
  volume       = {499},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variable-coefficient BDF methods with fully-geometric grid
for linear nonhomogeneous neutral pantograph equations. <em>AMC</em>,
<em>499</em>, 129412. (<a
href="https://doi.org/10.1016/j.amc.2025.129412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with numerical computation and analysis for the initial value problems (IVPs) of linear nonhomogeneous neutral pantograph equations. For solving this kind of IVPs, a class of extended k -step variable-coefficient backward differentiation formula (BDF) methods with fully-geometric grid are constructed. It is proved under the suitable conditions that an extended k -step variable-coefficient BDF method can arrive at k -order accuracy and is asymptotically stable. With a series of numerical experiments, the computational effectiveness and theoretical results of the presented methods are further confirmed.},
  archive      = {J_AMC},
  author       = {Zhixiang Jin and Chengjian Zhang},
  doi          = {10.1016/j.amc.2025.129412},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129412},
  shortjournal = {Appl. Math. Comput.},
  title        = {Variable-coefficient BDF methods with fully-geometric grid for linear nonhomogeneous neutral pantograph equations},
  volume       = {499},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A nonlinear immersed boundary method for weighted compact
nonlinear schemes. <em>AMC</em>, <em>499</em>, 129410. (<a
href="https://doi.org/10.1016/j.amc.2025.129410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weighted compact nonlinear schemes are a class of high-order finite difference schemes that are widely used in applications. The schemes are flexible in the choice of numerical fluxes. When applied to complex configurations, curvilinear grids are often applied, where the symmetric conservative metric method can be used to ensure geometric conservation laws. However, for complex configurations it may be difficult to generate high quality curvilinear grids. Thus, we confine the study in this paper to Cartesian grids and develop a nonlinear immersed boundary method to deal with the boundary. The developed method is applicable to different kinds of boundary conditions. In addition, compared with the traditional immersed boundary method, this new method can handle problems with shocks near boundary. Both one- and two-dimensional cases are studied into details, with corresponding numerical results showing the validity of the proposed method.},
  archive      = {J_AMC},
  author       = {Tianchu Hao and Yaming Chen and Lingyan Tang and Songhe Song},
  doi          = {10.1016/j.amc.2025.129410},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129410},
  shortjournal = {Appl. Math. Comput.},
  title        = {A nonlinear immersed boundary method for weighted compact nonlinear schemes},
  volume       = {499},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exponential stabilization for spatial multiple-fractional
advection-diffusion-reaction system. <em>AMC</em>, <em>499</em>, 129409.
(<a href="https://doi.org/10.1016/j.amc.2025.129409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential stabilization for spatial multiple-fractional advection-diffusion-reaction system (SMFADRS) is considered, and for the disturbed SMFADRS, the finite-time H ∞ stabilization is investigated. To ensure the considered system to achieve the desired performance, a distributed controller is designed to be located in the sub-intervals of the whole spatial domain. Then, by deriving an improved fractional Poincare&#39;s inequality and resorting to the Lyapunov functional method, the sufficient criteria of exponential stability and finite-time H ∞ performance are obtained. Besides, we also explore the effect of the space domain and its division, the control gain, the distribution of controller and the fractional order on the stability. Moreover, we apply the obtained theoretical results to address the control problem of the groundwater pollution, and the corresponding numerical simulations are performed to show the effectiveness of our results.},
  archive      = {J_AMC},
  author       = {Xing-Yu Li and Kai-Ning Wu and Zhan-Wen Yang},
  doi          = {10.1016/j.amc.2025.129409},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129409},
  shortjournal = {Appl. Math. Comput.},
  title        = {Exponential stabilization for spatial multiple-fractional advection-diffusion-reaction system},
  volume       = {499},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spectral properties of flipped toeplitz matrices and
computational applications. <em>AMC</em>, <em>499</em>, 129408. (<a
href="https://doi.org/10.1016/j.amc.2025.129408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the spectral properties of flipped Toeplitz matrices of the form H n ( f ) = Y n T n ( f ) , where T n ( f ) is the n × n Toeplitz matrix generated by the function f and Y n is the n × n exchange (or flip) matrix having 1 on the main anti-diagonal and 0 elsewhere. In particular, under suitable assumptions on f , we establish an alternating sign relationship between the eigenvalues of H n ( f ) , the eigenvalues of T n ( f ) , and the quasi-uniform samples of f . Moreover, after fine-tuning a few known theorems on Toeplitz matrices, we use them to provide localization results for the eigenvalues of H n ( f ) . Our study is motivated by the convergence analysis of the minimal residual (MINRES) method for the solution of real non-symmetric Toeplitz linear systems of the form T n ( f ) x = b after pre-multiplication of both sides by Y n , as suggested by Pestana and Wathen [26] . A selection of numerical experiments is provided to illustrate the theoretical results and to show how to use the spectral localizations for predicting the MINRES performance on linear systems with coefficient matrix H n ( f ) .},
  archive      = {J_AMC},
  author       = {Giovanni Barbarino and Sven-Erik Ekström and Carlo Garoni and David Meadon and Stefano Serra-Capizzano and Paris Vassalos},
  doi          = {10.1016/j.amc.2025.129408},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129408},
  shortjournal = {Appl. Math. Comput.},
  title        = {Spectral properties of flipped toeplitz matrices and computational applications},
  volume       = {499},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Observer-based finite-time h∞ fault-tolerant control for
uncertain markov jump systems against generally bounded transition
probabilities via two-step dynamic event-triggered approach.
<em>AMC</em>, <em>499</em>, 129407. (<a
href="https://doi.org/10.1016/j.amc.2025.129407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of finite-time H ∞ fault-tolerant control for uncertain Markov jump systems with generally bounded transition probabilities using a two-step dynamic event-triggered approach. A novel framework is proposed to optimize data transmission and improve fault tolerance via this approach. First, a dynamic event-triggered mechanism and an observer are introduced where a virtual observer is designed to enhance accuracy and mitigate fault impact. The actual H ∞ observer is then constructed by processing unmeasurable information. Second, based on the obtained estimates, a co-design method for the dynamic event-triggered mechanism and the H ∞ fault-tolerant controller is developed. Finally, comparative experiments and two simulation examples validate the effectiveness and superiority of the proposed method.},
  archive      = {J_AMC},
  author       = {Guochen Pang and Xiang Pan and Xiangyong Chen and Jinde Cao and Yang Liu and Jianlong Qiu},
  doi          = {10.1016/j.amc.2025.129407},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129407},
  shortjournal = {Appl. Math. Comput.},
  title        = {Observer-based finite-time h∞ fault-tolerant control for uncertain markov jump systems against generally bounded transition probabilities via two-step dynamic event-triggered approach},
  volume       = {499},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A co-evolutionary model of information, behavior, and
epidemics in multiplex networks: Incorporating subjective and objective
factors. <em>AMC</em>, <em>499</em>, 129406. (<a
href="https://doi.org/10.1016/j.amc.2025.129406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dissemination of information and the adoption of immunization behaviors are vital for preventing infection during epidemics. Positive and negative information have different influences on the decision to accept immunization behaviors, and individuals make decisions about whether to accept immunization based on both subjective cognizance and objective environmental factors. A three-layer propagation model is proposed to explore the co-evolutionary dynamics of competitive information, immunization behavior, and epidemics in multiplex networks. We consider the competitive transmission of positive and negative information under the effect of individual cognitive preference and the effect of the subjective cognizance and objective environmental factors. For the objective environmental factors, the Prospect Theory is introduced to describe the risk-related costs. Furthermore, we investigate the local group immunity phenomenon. Utilizing the MMCA (microscopic Markov chain approach) for theoretical analysis, our findings indicate that the dynamics of epidemic transmission can indeed undergo multi-stage phase transitions when there exists a competing propagation of positive and negative information. Improving individual cognitive preference for positive information is essential for making the right judgments when engaging in the immunization game process and reducing the epidemic transmission scale. In addition, individuals are encouraged to reduce the free-rider strategy and adopt immunization behavior timely during epidemic transmission, as this contributes to overall emergency management.},
  archive      = {J_AMC},
  author       = {Yue Yu and Liang&#39;an Huo},
  doi          = {10.1016/j.amc.2025.129406},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129406},
  shortjournal = {Appl. Math. Comput.},
  title        = {A co-evolutionary model of information, behavior, and epidemics in multiplex networks: Incorporating subjective and objective factors},
  volume       = {499},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Proper conflict-free 6-coloring of planar graphs without
short cycles. <em>AMC</em>, <em>499</em>, 129405. (<a
href="https://doi.org/10.1016/j.amc.2025.129405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A proper conflict-free l -coloring of a graph G is a proper l -coloring satisfying that for any non-isolated vertex v ∈ V ( G ) , there exists a color appearing exactly once in N G ( v ) . The proper conflict-free chromatic number, denoted by χ p c f ( G ) , is the minimal integer l so that G admits a proper conflict-free l -coloring. This notion was proposed by Fabrici et al. in 2022. They focus mainly on proper conflict-free coloring of outerplanar graphs and planar graphs. They constructed a planar graph that has no proper conflict-free 5-coloring and conjectured every planar graph G has χ p c f ( G ) ≤ 6 . In this paper, we confirm this conjecture for planar graphs without cycles of lengths 3, 5 or 6.},
  archive      = {J_AMC},
  author       = {Yunlong Wang and Weifan Wang and Runrun Liu},
  doi          = {10.1016/j.amc.2025.129405},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129405},
  shortjournal = {Appl. Math. Comput.},
  title        = {Proper conflict-free 6-coloring of planar graphs without short cycles},
  volume       = {499},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A macroscopic pedestrian model with variable maximal
density. <em>AMC</em>, <em>499</em>, 129404. (<a
href="https://doi.org/10.1016/j.amc.2025.129404">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose a novel macroscopic (fluid dynamics) model for describing pedestrian flow in low and high density regimes. The model is characterized by the fact that the maximal density reachable by the crowd – usually a fixed model parameter – is instead a state variable. To do that, the model couples a conservation law, devised as usual for tracking the evolution of the crowd density, with a Burgers-like PDE with a nonlocal term describing the evolution of the maximal density. The variable maximal density is used here to describe the effects of the psychological/physical pushing forces which are observed in crowds during competitive or emergency situations. Specific attention is also dedicated to the fundamental diagram, i.e., the function which expresses the relationship between crowd density and flux. Although the model needs a well defined fundamental diagram as known input parameter, it is not evident a priori which relationship between density and flux will be actually observed, due to the time-varying maximal density. An a posteriori analysis shows that the observed fundamental diagram has an elongated “tail” in the congested region, thus resulting similar to the concave/concave fundamental diagram with a “double hump” observed in real crowds. The main features of the model are investigated through 1D and 2D numerical simulations. The numerical code for the 1D simulation is freely available on this Gitlab repository .},
  archive      = {J_AMC},
  author       = {Laura Bartoli and Simone Cacace and Emiliano Cristiani and Roberto Ferretti},
  doi          = {10.1016/j.amc.2025.129404},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129404},
  shortjournal = {Appl. Math. Comput.},
  title        = {A macroscopic pedestrian model with variable maximal density},
  volume       = {499},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Isospectral reductions of non-negative matrices.
<em>AMC</em>, <em>499</em>, 129402. (<a
href="https://doi.org/10.1016/j.amc.2025.129402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Isospectral reduction is an important tool for network/matrix analysis as it reduces the dimension of a matrix/network while preserving its eigenvalues and eigenvectors. The main contribution of this manuscript is a proposed algorithmic scheme to approximate the stationary measure of a stochastic matrix based on isospectral reductions. We run numerical experiments that indicate this scheme is advantageous when there is more than one eigenvalue near 1, precisely the case where iterative methods perform poorly. We give a partial explanation why this scheme should work well, showing that in some situations isospectral reduction improves the spectral gap.},
  archive      = {J_AMC},
  author       = {Alexandre Baraviera and Pedro Duarte and Longmei Shu and Maria Joana Torres},
  doi          = {10.1016/j.amc.2025.129402},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129402},
  shortjournal = {Appl. Math. Comput.},
  title        = {Isospectral reductions of non-negative matrices},
  volume       = {499},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Regularized directional do-nothing boundary conditions for
the navier-stokes equations: Analytical and numerical study.
<em>AMC</em>, <em>499</em>, 129398. (<a
href="https://doi.org/10.1016/j.amc.2025.129398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the steady 2D and 3D Navier-Stokes equations with homogeneous mixed boundary conditions and the action of an external force. The classical do-nothing (CDN) boundary condition is replaced by a regularized directional do-nothing (RDDN) condition which depends on a parameter 0 &lt; δ ≪ 1 . After establishing the well-posedness of the Navier-Stokes equations with RDDN condition, we prove the convergence, as δ → 0 , to the solution of the Navier-Stokes equations with directional do-nothing (DDN) condition. The use of the RDDN condition in comparison with the CDN and DDN conditions is illustrated with 2D numerical simulations. The theoretical convergence result as δ → 0 is also confirmed by our numerical results.},
  archive      = {J_AMC},
  author       = {Pedro Nogueira and Ana L. Silvestre},
  doi          = {10.1016/j.amc.2025.129398},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129398},
  shortjournal = {Appl. Math. Comput.},
  title        = {Regularized directional do-nothing boundary conditions for the navier-stokes equations: Analytical and numerical study},
  volume       = {499},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effect of time-varying validity of individual interaction on
co-evolution of awareness and epidemics in a multiplex high-order
network. <em>AMC</em>, <em>499</em>, 129396. (<a
href="https://doi.org/10.1016/j.amc.2025.129396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Individual interactions play a crucial role in the co-evolution process of awareness and epidemics; these interactions involve pairwise and higher-order types. Previous research usually assumed that individual interactions are all valid and static, overlooking the fact that some interactions may be invalid and time-varying. Notably, diffusion phenomena cannot occur if interactions lose their validity. To address this gap, a novel coupled model is proposed to study the effect of time-varying interaction validity on the co-evolution of awareness and epidemics in a multiplex high-order network. Individual activity and life-cycle theory are employed to model the time-varying validity of interactions, which is further characterized using threshold functions. Simulation experiments reveal that increasing individual activity will increase the validity of interactions, which then leads to the prevalence of epidemics. In addition, maximizing epidemic control can be achieved by increasing activity in the virtual layer while reducing activity in the physical layer. Moreover, the results in more densely interacted communities suggest that more stringent control measures are required to bring the epidemic to extinction.},
  archive      = {J_AMC},
  author       = {Ming Li and Liang&#39;an Huo},
  doi          = {10.1016/j.amc.2025.129396},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129396},
  shortjournal = {Appl. Math. Comput.},
  title        = {Effect of time-varying validity of individual interaction on co-evolution of awareness and epidemics in a multiplex high-order network},
  volume       = {499},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). First optimal vectorial eighth-order iterative scheme for
solving non-linear systems. <em>AMC</em>, <em>498</em>, 129401. (<a
href="https://doi.org/10.1016/j.amc.2025.129401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a novel iterative method achieving eighth-order convergence, establishing its optimality for solving non-linear systems. A rigorous analysis of convergence order is presented, complemented by investigations into both efficiency indices and the complex dynamics of the proposed method. To assess its performance, extensive numerical experiments are conducted, facilitating comparative analysis with established methods from the literature.},
  archive      = {J_AMC},
  author       = {Alicia Cordero and Juan R. Torregrosa and Paula Triguero-Navarro},
  doi          = {10.1016/j.amc.2025.129401},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129401},
  shortjournal = {Appl. Math. Comput.},
  title        = {First optimal vectorial eighth-order iterative scheme for solving non-linear systems},
  volume       = {498},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cubic s-arc-transitive bi-cayley graphs. <em>AMC</em>,
<em>498</em>, 129400. (<a
href="https://doi.org/10.1016/j.amc.2025.129400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A bipartite graph Γ is a bi-Cayley graph over a group H if H ⩽ Aut Γ acts regularly on each part of Γ. A bi-Cayley graph Γ over a group H is said to be core-free if H is core-free in the bipartition-preserving subgroup of X for X ⩽ Aut Γ . In this paper, a classification is given for cubic core-free s -arc-transitive bi-Cayley graphs.},
  archive      = {J_AMC},
  author       = {Ran Ju and Jing Jian Li and Yang Gao},
  doi          = {10.1016/j.amc.2025.129400},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129400},
  shortjournal = {Appl. Math. Comput.},
  title        = {Cubic s-arc-transitive bi-cayley graphs},
  volume       = {498},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exemplary cooperation strategy with positive influence
enhances cooperation quality in social dilemma. <em>AMC</em>,
<em>498</em>, 129397. (<a
href="https://doi.org/10.1016/j.amc.2025.129397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An exemplary cooperation strategy with completely altruistic behavior is studied in this paper. This strategy not only exhibits altruism comparable to that of ordinary cooperators, but also exerts a power of good example through its unconditional cost, and influences the defector to give unforced-feedback. The findings indicate that even in the face of high temptation, exemplary cooperation strategies can also effectively prevent the total expansion of defection strategies and coexist with them. When the three strategies coexist, higher temptation does not promote defection but rather enhances the quality of cooperation to some extent. Moreover, the increase in unforced-feedback from defectors leads to a rise in the proportion of ordinary cooperation. Notably, the exemplary cooperation strategy can maintain a certain level in the population even in an unfavorable environment for cooperation, thus preventing the population from a state of full defectors. In general, the introduction of exemplary cooperation strategies fosters the development of cooperation to a certain extent. It offers a fresh perspective for understanding the emergence and sustenance of cooperative behavior.},
  archive      = {J_AMC},
  author       = {Xue Fan and Lidong Wang and Xuesong Liu and Anhao Zheng},
  doi          = {10.1016/j.amc.2025.129397},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129397},
  shortjournal = {Appl. Math. Comput.},
  title        = {Exemplary cooperation strategy with positive influence enhances cooperation quality in social dilemma},
  volume       = {498},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergence and stability in mean square of the stochastic
θ-methods for systems of NSDDEs under a coupled monotonicity condition.
<em>AMC</em>, <em>498</em>, 129395. (<a
href="https://doi.org/10.1016/j.amc.2025.129395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our research is devoted to investigating the convergence and stability in mean square of the stochastic θ -methods applied to neutral stochastic differential delay equations (NSDDEs) with super-linearly growing coefficients. Under a coupled monotonicity condition, we show that the numerical approximations of the stochastic θ -methods with θ ∈ [ 1 2 , 1 ] converge to the exact solution of NSDDEs strongly with order 1 2 . Moreover, it is shown that the stochastic θ -methods are capable of preserving the stability of the exact solution of original equations for any given stepsize h &gt; 0 . Finally, several numerical examples are presented to illustrate the theoretical findings.},
  archive      = {J_AMC},
  author       = {Mengyao Niu and Yuanling Niu and Jiaxin Wei},
  doi          = {10.1016/j.amc.2025.129395},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129395},
  shortjournal = {Appl. Math. Comput.},
  title        = {Convergence and stability in mean square of the stochastic θ-methods for systems of NSDDEs under a coupled monotonicity condition},
  volume       = {498},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Observer-based security control for nonlinear networked
systems: The SCP model of semi-markov kernel approach. <em>AMC</em>,
<em>498</em>, 129394. (<a
href="https://doi.org/10.1016/j.amc.2025.129394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, the problem of observer-based security control for interval type-2 nonlinear networked systems with stochastic communication protocol (SCP) and denial-of-service (DoS) attacks is investigated. To begin with, considering the limited network bandwidth, a novel SCP is proposed to avoid data conflicts in information transmission. In particular, compared with the existing SCP, the SCP constructed in this article is scheduled by semi-Markov kernel, and the probability density function of its sojourn-time is assured by both the current mode and the next mode. Then, considering the influence of SCP and DoS attacks, the cooperative design conditions of observer-based security controller based on mode-dependent and fuzzy-dependent are given. Furthermore, a mode-dependent and sojourn-time-dependent Lyapunov function is adopted, and a sufficient condition for the mean square exponential stability of the closed-loop system is ensured. Finally, the feasibility of the method is verified by a mechanical motion model.},
  archive      = {J_AMC},
  author       = {Pei-Zhen Xia and Xiao-Heng Chang},
  doi          = {10.1016/j.amc.2025.129394},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129394},
  shortjournal = {Appl. Math. Comput.},
  title        = {Observer-based security control for nonlinear networked systems: The SCP model of semi-markov kernel approach},
  volume       = {498},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybridizable discontinuous galerkin method for nonlinear
hyperbolic integro-differential equations. <em>AMC</em>, <em>498</em>,
129393. (<a href="https://doi.org/10.1016/j.amc.2025.129393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present the hybridizable discontinuous Galerkin (HDG) method for a nonlinear hyperbolic integro-differential equation. We discuss the semi-discrete and fully-discrete error analysis of the method. For the semi-discrete error analysis, an extended type mixed Ritz-Volterra projection is introduced for the model problem. It helps to achieve the optimal order of convergence for the unknown scalar variable and its gradient. Further, a local post-processing is performed, which helps to achieve super-convergence. Subsequently, by employing the central difference scheme in the temporal direction and applying the mid-point rule for discretizing the integral term, a fully discrete scheme is formulated, accompanied by its corresponding error estimates. Ultimately, through the examination of numerical examples within two-dimensional domains, computational findings are acquired, thus validating the results of our study.},
  archive      = {J_AMC},
  author       = {Riya Jain and Sangita Yadav},
  doi          = {10.1016/j.amc.2025.129393},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129393},
  shortjournal = {Appl. Math. Comput.},
  title        = {Hybridizable discontinuous galerkin method for nonlinear hyperbolic integro-differential equations},
  volume       = {498},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unconditionally stable sixth-order structure-preserving
scheme for the nonlinear schrödinger equation with wave operator.
<em>AMC</em>, <em>498</em>, 129392. (<a
href="https://doi.org/10.1016/j.amc.2025.129392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A structure-preserving two-level numerical method with sixth-order in both time and space is proposed for solving the nonlinear Schrödinger equation with wave operator. By introducing auxiliary variables to transform the original equation into a system, structure-preserving high-order difference scheme is obtained by applying the Crank-Nicolson method and the sixth-order difference operators for discretizing time and space derivatives. Subsequently, the conservation laws of energy and mass for the discretized solution produced by the established scheme are rigorously proven. And a theoretical analysis shows that the scheme is unconditionally convergent and stable in the L 2 -norm. Additionally, a corresponding fast solving algorithm is designed for the established scheme. And the Richardson extrapolation technique is used to enhance the temporal accuracy to sixth order. Finally, the effectiveness of the numerical scheme and the theoretical results of this study are validated through numerical experiments. The results also fully demonstrate the efficiency of the novel scheme in numerical computations.},
  archive      = {J_AMC},
  author       = {Shuaikang Wang and Yongbin Ge and Sheng-en Liu},
  doi          = {10.1016/j.amc.2025.129392},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129392},
  shortjournal = {Appl. Math. Comput.},
  title        = {Unconditionally stable sixth-order structure-preserving scheme for the nonlinear schrödinger equation with wave operator},
  volume       = {498},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Observer-based dynamic event-triggered second-level MPC for
nonlinear time-delay CPSs under joint hybrid attacks. <em>AMC</em>,
<em>498</em>, 129391. (<a
href="https://doi.org/10.1016/j.amc.2025.129391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates observer-based dynamic event-triggered (DET) second-level model predictive control (MPC) for a specific class of nonlinear time-delay cyber-physical systems (CPSs) under hybrid attacks on the sensor-controller (S-C) channel and controller-actuator (C-A) channel. A dynamic event-triggered mechanism with adaptive bias components is developed to reduce trigger frequency, uphold system performance, and conserve communication resources. Additionally, the observer gain is determined using the nominal observation model and linear matrix inequalities. A novel model predictive control approach is devised based on the identified model to enhance system performance. Theoretical analysis demonstrates that the proposed method effectively guarantees that the closed-loop system satisfies the input-to-state practical stability criterion. Finally, a numerical simulation case study is presented to validate the effectiveness of the proposed algorithm.},
  archive      = {J_AMC},
  author       = {Hongchao Song and Zhenlei Wang and Xin Wang},
  doi          = {10.1016/j.amc.2025.129391},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129391},
  shortjournal = {Appl. Math. Comput.},
  title        = {Observer-based dynamic event-triggered second-level MPC for nonlinear time-delay CPSs under joint hybrid attacks},
  volume       = {498},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explicit solutions and finite-time stability for fractional
delay systems. <em>AMC</em>, <em>498</em>, 129388. (<a
href="https://doi.org/10.1016/j.amc.2025.129388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finite-time stability and explicit solutions are considered for nonhomogeneous fractional systems with pure delay. First, explicit solutions are obtained by using new delayed Mittag-Leffler-type matrix functions. Second, the finite-time stability results are obtained by utilizing these explicit solutions and the norm estimate of these delayed Mittag-Leffler-type matrix functions. The results improve, extend, and complement the previous works. Finally, an example is provided to illustrate the importance of the results.},
  archive      = {J_AMC},
  author       = {Ahmed M. Elshenhab and Xing Tao Wang and Mohamed Hosny},
  doi          = {10.1016/j.amc.2025.129388},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129388},
  shortjournal = {Appl. Math. Comput.},
  title        = {Explicit solutions and finite-time stability for fractional delay systems},
  volume       = {498},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). How predator harvesting affects prey-predator dynamics in
deterministic and stochastic environments? <em>AMC</em>, <em>498</em>,
129380. (<a href="https://doi.org/10.1016/j.amc.2025.129380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the dynamics of predator-prey interactions in both deterministic and stochastic environments, with a focus on the ecological implications of predator harvesting. Theoretical and numerical analyses explore local stability, bifurcations, and bionomic equilibria to identify sustainable harvesting strategies. Our findings reveal that increasing predator harvesting rates can induce up to four interior equilibrium points via saddle-node bifurcations, including catastrophic transitions that destabilize the system. At high harvesting rates, the predator-free equilibrium becomes globally stable, while low and intermediate rates result in bistability or tristability, allowing coexistence of prey and predator populations. For the stochastic model, we derive conditions for species persistence and extinction, using the confidence ellipse method to quantify threshold noise intensities that trigger critical transitions between stable states. At low noise levels, predator and prey populations fluctuate around stable equilibria, but higher noise intensities can drive shifts to alternate states or predator extinction. The key factors influencing system dynamics include the predator&#39;s intrinsic growth rate, alternative food sources, and harvesting intensity. Our analysis underscores the vulnerability of ecological systems to stochastic disturbances and emphasizes the importance of carefully managed harvesting practices. These findings contribute to the development of strategies that balance ecological stability with economic objectives, ensuring the long-term sustainability of predator-prey populations.},
  archive      = {J_AMC},
  author       = {Bapin Mondal and Sayan Mandal and Pankaj Kumar Tiwari and Ranjit Kumar Upadhyay},
  doi          = {10.1016/j.amc.2025.129380},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129380},
  shortjournal = {Appl. Math. Comput.},
  title        = {How predator harvesting affects prey-predator dynamics in deterministic and stochastic environments?},
  volume       = {498},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Construction of solutions of the riemann problem for a
two-dimensional keyfitz-kranzer type model governing a thin film flow.
<em>AMC</em>, <em>498</em>, 129378. (<a
href="https://doi.org/10.1016/j.amc.2025.129378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article is concerned with constructing solutions involving nonlinear waves to a three-constant two-dimensional Riemann problem for a reduced hyperbolic model describing a thin film flow of a perfectly soluble anti-surfactant solution. Here, we solve the Riemann problem without the limitation that each jump of the initial data emanates exactly one planar elementary wave. We obtain ten topologically distinct solutions using the generalized characteristic analysis. Our analysis explores the intricate interaction between classical and non-classical waves. Furthermore, in order to validate our solutions we thoroughly compare the obtained analytical solutions with numerical results through the second-order Local Lax Friedrichs scheme which is implemented in numerical simulation.},
  archive      = {J_AMC},
  author       = {Anamika Pandey and Rahul Barthwal and T. Raja Sekhar},
  doi          = {10.1016/j.amc.2025.129378},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129378},
  shortjournal = {Appl. Math. Comput.},
  title        = {Construction of solutions of the riemann problem for a two-dimensional keyfitz-kranzer type model governing a thin film flow},
  volume       = {498},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite element hybridization of port-hamiltonian systems.
<em>AMC</em>, <em>498</em>, 129377. (<a
href="https://doi.org/10.1016/j.amc.2025.129377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this contribution, we extend the hybridization framework for the Hodge Laplacian [Awanou et al. (2023) [16] ] to port-Hamiltonian systems describing linear wave propagation phenomena. To this aim, a dual field mixed Galerkin discretization is introduced, in which one variable is approximated via conforming finite element spaces, whereas the second is completely local. The mixed formulation is then hybridized to obtain an equivalent formulation that can be more efficiently solved using a static condensation procedure in discrete time. The size reduction achieved thanks to the hybridization is greater than the one obtained for the Hodge Laplacian as the final system only contains the globally coupled traces of one variable. Numerical experiments on the 3D wave and Maxwell equations illustrate the convergence of the method and the size reduction achieved by the hybridization.},
  archive      = {J_AMC},
  author       = {Andrea Brugnoli and Ramy Rashad and Yi Zhang and Stefano Stramigioli},
  doi          = {10.1016/j.amc.2025.129377},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129377},
  shortjournal = {Appl. Math. Comput.},
  title        = {Finite element hybridization of port-hamiltonian systems},
  volume       = {498},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Symmetry and the buchanan-lillo conjecture: A resolution of
the mixed feedback case. <em>AMC</em>, <em>498</em>, 129376. (<a
href="https://doi.org/10.1016/j.amc.2025.129376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Buchanan and Lillo both conjectured that oscillatory solutions of the first-order delay differential equation with positive feedback x ′ ( t ) = p ( t ) x ( τ ( t ) ) , t ≥ 0 , where 0 ≤ p ( t ) ≤ 1 , 0 ≤ t − τ ( t ) ≤ 2.75 + ln ⁡ 2 , t ∈ R , are asymptotic to a shifted multiple of a unique periodic solution. This special solution can also be described from the more general perspective of the mixed feedback case (sign-changing p ), thanks to its symmetry (antiperiodicity). The analogue of this conjecture for negative feedback, p ( t ) ≤ 0 , was resolved by Lillo, and the mixed feedback analog was recently set as an open problem. In this paper, we resolve the case of mixed feedback, obtaining results in support of the conjecture of Buchanan and Lillo, underlining its link to the symmetry of the periodic solution. In particular, we obtain and describe the optimal estimates on the necessary delay for existence of periodic (more generally, nonvanishing) solutions, with respect to the period (oscillation speed). These apply to almost any first-order delay system, as we consider the general nonautonomous case, under minimal assumptions of measurability of the parameters. We furthermore discuss and elucidate the relations between the periodic and the nonautonomous case.},
  archive      = {J_AMC},
  author       = {Elena Braverman and John Ioannis Stavroulakis},
  doi          = {10.1016/j.amc.2025.129376},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129376},
  shortjournal = {Appl. Math. Comput.},
  title        = {Symmetry and the buchanan-lillo conjecture: A resolution of the mixed feedback case},
  volume       = {498},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bounded consensus in second-order uncertain nonlinear
multiagent systems: A distributed neural network control approach.
<em>AMC</em>, <em>498</em>, 129369. (<a
href="https://doi.org/10.1016/j.amc.2025.129369">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the consensus issue in second-order generalized nonlinear multiagent systems (MAS) that involve uncertain nonlinear dynamics and external disturbances from the system. Suppose that the uncertain nonlinear terms can be approximated by neural networks with nonlinear residues. Through the incorporation of localized adaptive observer and disturbance observer for each agent, we propose a distributed adaptive protocol to promote bounded consensus (BC) in the network. Due to the use of saturated functions and adaptive gains in the protocol, the chattering phenomenon is weakened. Finally, two simulation examples verify the results of the fully distributed adaptive bounded consensus protocol.},
  archive      = {J_AMC},
  author       = {Chaoyang Li and Shidong Zhai and Yuanshi Zheng},
  doi          = {10.1016/j.amc.2025.129369},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129369},
  shortjournal = {Appl. Math. Comput.},
  title        = {Bounded consensus in second-order uncertain nonlinear multiagent systems: A distributed neural network control approach},
  volume       = {498},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fixed-time stability criteria and adaptive state constrained
control for uncertain switched nonlinear systems. <em>AMC</em>,
<em>498</em>, 129345. (<a
href="https://doi.org/10.1016/j.amc.2025.129345">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates adaptive fixed-time state constrained tracking control problem for uncertain switched nonlinear systems, even if the fixed-time tracking control problem for each subsystem is not solvable. Based on the given fixed-time stability conditions, fixed-time stability criterion is established for switched nonlinear systems by developing a new multiple Lyapunov functions method. Then, by combining the fixed-time stability criterion with multiple integral barrier Lyapunov functions, the fuzzy adaptive controllers and a switching law dependent on states are designed constructively to solve the constrained fixed-time tracking control problem: 1) the boundedness of all the signals of the resulting closed-loop system is verified; 2) the system output can follow a given reference signal into an arbitrarily small compact set; 3) all the system states satisfy with their constraint condition. Finally, two examples are presented to verify the effectiveness of the obtained results.},
  archive      = {J_AMC},
  author       = {Shuo Liu and Huaguang Zhang and Hongbo Pang},
  doi          = {10.1016/j.amc.2025.129345},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129345},
  shortjournal = {Appl. Math. Comput.},
  title        = {Fixed-time stability criteria and adaptive state constrained control for uncertain switched nonlinear systems},
  volume       = {498},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="artmed---13">ARTMED - 13</h2>
<ul>
<li><details>
<summary>
(2025). Sum of similarity-regularized squared correlations for
enhancing SSVEP detection. <em>ARTMED</em>, <em>162</em>, 103100. (<a
href="https://doi.org/10.1016/j.artmed.2025.103100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A brain-computer interface (BCI) provides a direct control pathway between human brain and external devices. Steady-state visual evoked potential based BCI (SSVEP-BCI) has been proven to be a valuable solution due to its advantages of high information transfer rate (ITR) and minimal calibration requirement. Recently, some methods have been proposed based on calibration-training techniques to compute optimal spatial filters from covariances, and have achieved good detection performance. However, these methods ignore the temporally-varying and spatially-coupled characteristics of the EEG signals, which is essentially an important clue for enhancing ITR. More importantly, existing methods cannot well deal with intrinsic noise components of electroencephalogram (EEG) signals, greatly affecting their detection performance. In this paper, we propose a novel method, termed as S um of S imilarity- R egularized S quared C orrelations (SSRSC), which is extended and regularized from the sum of squared correlations. We simultaneously compute the squared correlations for both calibration data and sine-cosine harmonics templates, and mitigate variations by the similarity regularization. Moreover, we extend the SSRSC by adopting the ranking weighted ensemble strategy, termed as weSSCOR. Extensive experiments have been conducted on two benchmark SSVEP datasets, and the results demonstrated that the proposed SSRSC/weSSRSC can significantly improve accuracy and ITR of SSVEP detection with less calibration data, which has great potential in designing high ITR SSVEP-BCIs with less calibration efforts.},
  archive      = {J_ARTMED},
  author       = {Tian-jian Luo and Tao Wu},
  doi          = {10.1016/j.artmed.2025.103100},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {103100},
  shortjournal = {Artif. Intell. Med.},
  title        = {Sum of similarity-regularized squared correlations for enhancing SSVEP detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TDMFS: Tucker decomposition multimodal fusion model for
pan-cancer survival prediction. <em>ARTMED</em>, <em>162</em>, 103099.
(<a href="https://doi.org/10.1016/j.artmed.2025.103099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrated analysis of multimodal data offers a more comprehensive view for cancer survival prediction, yet it faces challenges like computational intensity, overfitting, and challenges in achieving a unified representation due to data heterogeneity. To address the above issues, the first Tucker decomposition multimodal fusion model was hereby proposed for pan-cancer survival prediction (TDMFS). The model employed Tucker decomposition to limit complex tensor parameters during fusion, achieving deep modality integration with reduced computational cost and lower overfitting risk. The individual modality-specific representations were then fully exploited by signal modulation mechanisms in a bilinear pooling decomposition to serve as complementary information for the deep fusion representation. Furthermore, the performance of TDMFS was evaluated using a 5-fold cross-validation method with two modal data, gene expression (GeneExpr), and copy number variation (CNV), for 33 cancers from The Cancer Genome Atlas (TCGA) database. The experiments demonstrated that the proposed TDMFS model achieved an average C-index of 0.757 across 33 cancer datasets, with a C-index exceeding 0.80 on 10 of these datasets. Survival curves for both high and low risk patients plotted on 27 cancer datasets were statistically significant. The TDMFS model demonstrated superior performance in survival prediction, outperforming models like LinearSum and Multimodal Factorisation Higher Order Pooling, making it a valuable asset for advancing clinical cancer research.},
  archive      = {J_ARTMED},
  author       = {Jinchao Chen and Pei Liu and Chen Chen and Ying Su and Enguang Zuo and Min Li and Jiajia Wang and Ziwei Yan and Xinya Chen and Cheng Chen and Xiaoyi Lv},
  doi          = {10.1016/j.artmed.2025.103099},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {103099},
  shortjournal = {Artif. Intell. Med.},
  title        = {TDMFS: Tucker decomposition multimodal fusion model for pan-cancer survival prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint segmentation of retinal layers and fluid lesions in
optical coherence tomography with cross-dataset learning.
<em>ARTMED</em>, <em>162</em>, 103096. (<a
href="https://doi.org/10.1016/j.artmed.2025.103096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background and objectives Age-related macular degeneration (AMD) is the leading cause of irreversible vision loss among people over 50 years old, which manifests in the retina through various changes of retinal layers and pathological lesions. The accurate segmentation of optical coherence tomography (OCT) image features is crucial for the identification and tracking of AMD. Although the recent developments in deep neural network have brought profound progress in this area, accurately segmenting retinal layers and pathological lesions remains a challenging task because of the interaction between these two tasks. Methods In this study, we propose a three-branch, hierarchical multi-task framework that enables joint segmentation of seven retinal layers and three types of pathological lesions. A regression guidance module is introduced to provide explicit shape guidance between sub-tasks. We also propose a cross-dataset learning strategy to leverage public datasets with partial labels. The proposed framework was evaluated on a clinical dataset consisting of 140 OCT B-scans with pixel-level annotations of seven retinal layers and three types of lesions. Additionally, we compared its performance with the state-of-the-art methods on two public datasets. Results Comprehensive ablation showed that the proposed hierarchical architecture significantly improved performance for most retinal layers and pathological lesions, achieving the highest mean DSC of 76.88 %. The IRF also achieved the best performance with a DSC of 68.15 %. Comparative studies demonstrated that the hierarchical multi-task architecture could significantly enhance segmentation accuracy and outperform state-of-the-art methods. Conclusion The proposed framework could also be generalized to other medical image segmentation tasks with interdependent relationships.},
  archive      = {J_ARTMED},
  author       = {Xiayu Xu and Hualin Wang and Yulei Lu and Hanze Zhang and Tao Tan and Feng Xu and Jianqin Lei},
  doi          = {10.1016/j.artmed.2025.103096},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {103096},
  shortjournal = {Artif. Intell. Med.},
  title        = {Joint segmentation of retinal layers and fluid lesions in optical coherence tomography with cross-dataset learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised learning from EEG data for epilepsy: A
systematic literature review. <em>ARTMED</em>, <em>162</em>, 103095. (<a
href="https://doi.org/10.1016/j.artmed.2025.103095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background and objectives Epilepsy is a neurological disorder characterized by recurrent epileptic seizures, whose neurophysiological signature is altered electroencephalographic (EEG) activity. The use of artificial intelligence (AI) methods on EEG data can positively impact the management of the disease, significantly improving diagnostic and prognostic accuracy as well as treatment outcomes. Our work aims to systematically review the available literature on the use of unsupervised machine learning methods on EEG data in epilepsy, focusing on methodological and clinical differences in terms of algorithms used and clinical applications. Methods Following the PRISMA guidelines, a systematic literature search was performed in several databases for papers published in the last 10 years. Studies employing both unsupervised and self-supervised methods for the classification of EEG data in epilepsy patients were included. The main outcomes of the study were: (i) to provide an overview of the datasets used as input to train the algorithms; (ii) to identify trends in pre-processing, algorithm architectures, validation, and metrics for performance estimation; (iii) to identify and review the clinical applications of AI in epilepsy patients. Results A total of 108 studies met the inclusion criteria. Of them, 86 (79.6 %) have been published in the last 5 years and 60 (55.5 %) in the last two years. The most used validation methods were: hold-out in 37 (34.2 %), k-fold-cross validation in 35 (32.4 %), and leave-one-out in 19 (17.6 %) studies, respectively. Accuracy, sensitivity, and specificity were the most used performance metrics being reported in 71 (65.7 %), 62 (57.4 %), and 42 (39.8 %) studies, respectively, followed by F1-score (27 studies; 25 %), precision (26 studies; 24 %), area under the curve (25 studies; 23.1 %), and false positive rate (22 studies; 20.3 %). Furthermore, 42 (38.9 %) compared to 63 (58.3 %) studies used individual patient versus multiple patients models, respectively. Finally, concerning the clinical applications of unsupervised learning methods on epilepsy patients, we identified six main fields of interest: seizure detection (69 studies; 63.9 %), seizure prediction (27 studies; 25 %), signal propagation and characterization (2 studies; 1.8 %), seizure localization (4 studies; 3.7 %), and seizure classification (22 studies; 20.3 %), respectively. Conclusion The results of this review suggest that the interest in the use of unsupervised learning methods in epilepsy has significantly increased in recent years. From a methodological perspective, the input EEG datasets used for training and testing the algorithms remain the hardest challenge. From a clinical standpoint, the vast majority of studies addressed seizure detection, prediction, and classification whereas studies focusing on seizure characterization and localization are lacking. Future work that can potentially improve the performance of these algorithms includes the use of context information via reinforcement learning and a focus on model explainability.},
  archive      = {J_ARTMED},
  author       = {Alexandra-Maria Tautan and Alexandra-Georgiana Andrei and Carmelo Luca Smeralda and Giampaolo Vatti and Simone Rossi and Bogdan Ionescu},
  doi          = {10.1016/j.artmed.2025.103095},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {103095},
  shortjournal = {Artif. Intell. Med.},
  title        = {Unsupervised learning from EEG data for epilepsy: A systematic literature review},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SDMentor: A virtual reality-based intelligent tutoring
system for surgical decision making in dentistry. <em>ARTMED</em>,
<em>162</em>, 103092. (<a
href="https://doi.org/10.1016/j.artmed.2025.103092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background While VR simulation has already had a significant impact on training of psychomotor surgical skills, there is still a lack of work on the use of VR simulation to teach surgical decision making. Since surgical decision making is a cognitive process, a simulation for teaching it must be able to not only accurately simulate the surgical environment but to also represent and reason about the cognitive aspects involved. Materials and methods This paper presents and evaluates SDMentor, a virtual training environment that integrates high-fidelity VR simulation with an intelligent tutoring system for teaching surgical decision making in dentistry. SDMentor provides a virtual dental operating room with 3D stereoscopic graphics and with haptic feedback to realistically render the interaction of dental tools with the patient teeth. The intelligent tutor evaluates the student&#39;s actions and generates a variety of tutorial feedback. To evaluate the teaching effectiveness of the system, we carried out a randomized controlled trial in the domain of root canal treatment. Results In all three aspects of scores: situation awareness ability, procedural knowledge, and overall performance; the post-test scores showed significant improvement over the pre-test scores of students in the same group ( P &lt; .05). The students from the experimental group had significantly higher learning gains than the students in the control group (P &lt; .05). Conclusions The integration of high-fidelity VR simulation with intelligent tutoring is a promising approach to teaching surgical decision making and could be useful for teaching decision making in other high-precision psychomotor tasks.},
  archive      = {J_ARTMED},
  author       = {Narumol Vannaprathip and Peter Haddawy and Holger Schultheis and Siriwan Suebnukarn},
  doi          = {10.1016/j.artmed.2025.103092},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {103092},
  shortjournal = {Artif. Intell. Med.},
  title        = {SDMentor: A virtual reality-based intelligent tutoring system for surgical decision making in dentistry},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-stage multi-modal learning algorithm with adaptive
multimodal fusion for improving multi-label skin lesion classification.
<em>ARTMED</em>, <em>162</em>, 103091. (<a
href="https://doi.org/10.1016/j.artmed.2025.103091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin cancer is frequently occurring and has become a major contributor to both cancer incidence and mortality. Accurate and timely diagnosis of skin cancer holds the potential to save lives. Deep learning-based methods have demonstrated significant advancements in the screening of skin cancers. However, most current approaches rely on a single modality input for diagnosis, thereby missing out on valuable complementary information that could enhance accuracy. Although some multimodal-based methods exist, they often lack adaptability and fail to fully leverage multimodal information. In this paper, we introduce a novel uncertainty-based hybrid fusion strategy for a multi-modal learning algorithm aimed at skin cancer diagnosis. Our approach specifically combines three different modalities: clinical images, dermoscopy images, and metadata, to make the final classification. For the fusion of two image modalities, we employ an intermediate fusion strategy that considers the similarity between clinical and dermoscopy images to extract features containing both complementary and correlated information. To capture the correlated information, we utilize cosine similarity, and we employ concatenation as the means for integrating complementary information. In the fusion of image and metadata modalities, we leverage uncertainty to obtain confident late fusion results, allowing our method to adaptively combine the information from different modalities. We conducted comprehensive experiments using a popular publicly available skin disease diagnosis dataset, and the results of these experiments demonstrate the effectiveness of our proposed method. Our proposed fusion algorithm could enhance the clinical applicability of automated skin lesion classification, offering a more robust and adaptive way to make automatic diagnoses with the help of uncertainty mechanism. Code is available at https://github.com/Zuo-Lihan/CosCatNet-Adaptive_Fusion_Algorithm .},
  archive      = {J_ARTMED},
  author       = {Lihan Zuo and Zizhou Wang and Yan Wang},
  doi          = {10.1016/j.artmed.2025.103091},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {103091},
  shortjournal = {Artif. Intell. Med.},
  title        = {A multi-stage multi-modal learning algorithm with adaptive multimodal fusion for improving multi-label skin lesion classification},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hyperbolic multivariate feature learning in higher-order
heterogeneous networks for drug–disease prediction. <em>ARTMED</em>,
<em>162</em>, 103090. (<a
href="https://doi.org/10.1016/j.artmed.2025.103090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {New drug discovery has always been a costly, time-consuming process with a high failure rate. Repurposing existing drugs offers a valuable alternative and reduces the risks associated with developing new drugs. Various experimental methods have been employed to facilitate drug repositioning; however, associations prediction between drugs and diseases through biological experiments is both expensive and time-consuming. Consequently, it is imperative to develop efficient and highly precise computational methods for predicting these associations. Based on this, we propose a drug–disease associations prediction method based on H yperbolic M ultivariate feature L earning in H igh-order H eterogeneous Networks for Drug–Disease Prediction, called H 3 ML. Our approach begins by mining high-order information from protein–disease and drug–protein networks to construct high-order heterogeneous networks. Subsequently, we employ multivariate feature learning to create hyperbolic representations, and then enhance the features of the heterogeneous network. Finally, we utilize a hyperbolic graph attention network in the hyperbolic space to aggregate neighbor information and perform the final prediction task. In addition, we evaluate the performance of H 3 ML by comparing it with some state-of-the-art methods across different datasets. The case study further validate the effectiveness of H 3 ML. Our implementation will be publicly available at: https://github.com/jianruichen/H-3ML .},
  archive      = {J_ARTMED},
  author       = {Jiamin Li and Jianrui Chen and Junjie Huang and Xiujuan Lei},
  doi          = {10.1016/j.artmed.2025.103090},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {103090},
  shortjournal = {Artif. Intell. Med.},
  title        = {Hyperbolic multivariate feature learning in higher-order heterogeneous networks for drug–disease prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence-driven approaches in antibiotic
stewardship programs and optimizing prescription practices: A systematic
review. <em>ARTMED</em>, <em>162</em>, 103089. (<a
href="https://doi.org/10.1016/j.artmed.2025.103089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Antimicrobial stewardship programs (ASPs) are essential in optimizing the use of antibiotics to address the global concern of antimicrobial resistance (AMR). Artificial intelligence (AI) and machine learning (ML) have emerged as promising tools for enhancing ASPs efficiency by improving antibiotic prescription accuracy, resistance prediction, and dosage optimization. This systematic review evaluated the application of AI-driven ASPs, focusing on their methodologies, outcomes, and challenges. We searched all of the databases in PubMed, Scopus, Web of Science, and Embase using keywords related to “AI” and “antibiotic.” We only included studies that used AI and ML algorithms in ASPs, with the main criteria being empirical antibiotic selection, dose adjustment, and ASP adherence. There were no limits on time, setting, or language. Two authors independently screened studies for inclusion and assessed their risk of bias using the Newcastle Ottawa Scale (NOS) Assessment tool for observational studies. Implementation studies underscored AI&#39;s potential for improving antimicrobial stewardship programs. Two studies showed that logistic regression, boosted-tree models, and gradient-boosting machines could effectively describe the difference between patients who needed to change their antibiotic regimen and those who did not. Twenty-four studies have confirmed the role of machine learning in optimizing empirical antibiotic selection, predicting resistance, and enhancing therapy appropriateness, all of which have the potential to reduce mortality rates. Additionally, machine learning algorithms showed promise in optimizing antibiotic dosing, particularly for vancomycin. This systematic review aimed to highlight various AI models, their applications in ASPs, and the resulting impact on healthcare outcomes. Machine learning and AI models effectively enhance antibiotic stewardship by optimizing patient interventions, empirical antibiotic selection, resistance prediction, and dosing. However, it subtly draws attention to the differences between high-income countries (HICs) and low- and middle-income countries (LMICs), highlighting the structural difficulties that LMICs confront while simultaneously highlighting the progress made in HICs.},
  archive      = {J_ARTMED},
  author       = {Hamid Harandi and Maryam Shafaati and Mohammadreza Salehi and Mohammad Mahdi Roozbahani and Keyhan Mohammadi and Samaneh Akbarpour and Ramin Rahimnia and Gholamreza Hassanpour and Yasin Rahmani and Arash Seifi},
  doi          = {10.1016/j.artmed.2025.103089},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {103089},
  shortjournal = {Artif. Intell. Med.},
  title        = {Artificial intelligence-driven approaches in antibiotic stewardship programs and optimizing prescription practices: A systematic review},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence non-invasive methods for neonatal
jaundice detection: A review. <em>ARTMED</em>, <em>162</em>, 103088. (<a
href="https://doi.org/10.1016/j.artmed.2025.103088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neonatal jaundice is a common and potentially fatal health condition in neonates, especially in low and middle income countries, where it contributes considerably to neonatal morbidity and death. Traditional diagnostic approaches, such as Total Serum Bilirubin (TSB) testing, are invasive and could lead to discomfort, infection risk, and diagnostic delays. As a result, there is a rising interest in non-invasive approaches for detecting jaundice early and accurately. An in-depth analysis of non-invasive techniques for detecting neonatal jaundice is presented by this review, exploring several AI-driven techniques, such as Machine Learning (ML) and Deep Learning (DL), which have demonstrated the ability to enhance diagnostic accuracy by evaluating complex patterns in neonatal skin color and other relevant features. It is identified that AI models incorporating variants of neural networks achieve an accuracy rate of over 90% in detecting jaundice when compared to traditional methods. Furthermore, satisfactory outcomes in field settings have been demonstrated by mobile-based applications that use smartphone cameras to estimate bilirubin levels, providing a practical alternative for resource-constrained areas. The potential impact of AI-based solutions on reducing neonatal morbidity and mortality is evaluated by this review, with a focus on real-world clinical challenges, highlighting the effectiveness and practicality of AI-based strategies as an assistive tool in revolutionizing neonatal care through early jaundice diagnosis, while also addressing the ethical and practical implications of integrating these technologies in clinical practice. Future research areas, such as the development of new imaging technologies and the incorporation of wearable sensors for real-time bilirubin monitoring, are recommended by the paper.},
  archive      = {J_ARTMED},
  author       = {Fati Oiza Salami and Muhammad Muzammel and Youssef Mourchid and Alice Othmani},
  doi          = {10.1016/j.artmed.2025.103088},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {103088},
  shortjournal = {Artif. Intell. Med.},
  title        = {Artificial intelligence non-invasive methods for neonatal jaundice detection: A review},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving unified information extraction in chinese mental
health domain with instruction-tuned LLMs and type-verification
component. <em>ARTMED</em>, <em>162</em>, 103087. (<a
href="https://doi.org/10.1016/j.artmed.2025.103087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: Extracting psychological counseling help-seeker information from unstructured text is crucial for providing effective mental health support. This task involves identifying personal emotions, psychological states, and underlying psychological issues but faces significant challenges. These challenges include the sensitivity of mental health data, the lack of Chinese instruction datasets, and the difficulties large language models (LLMs) encounter with complex natural language understanding tasks. Objective: This study aims to address these challenges by developing a unified information extraction framework for Chinese mental health texts. Specifically, it leverages instruction-tuned LLMs and incorporates a novel type-verification (TV) component to improve performance while minimizing computational demands. Methods: We first constructed a Chinese mental health domain instruction dataset for mental health information extraction using synthetic data generated by ChatGPT, guided by psychology experts. This dataset includes self-reported statements from psychological counseling help-seekers, capturing their personal situations, emotions, thoughts, and experiences. Subsequently, we fine-tuned open-source LLMs on this dataset to perform named entity recognition, relation extraction, and event extraction. To address errors and omissions in the extracted information, we introduced a type-verification component. This component employs a lightweight model with significantly fewer parameters to verify the extracted types. The verification results were then fed back into LLMs for further refinement. Results: Experimental results demonstrate that our framework achieves outstanding performance in mental health information extraction. The type-verification component significantly enhances extraction accuracy while reducing computational resource requirements through the use of a lightweight model. By combining robust instruction-tuned LLMs with an efficient type-verification component, our approach delivers exceptional results. Conclusion: This study presents a novel and efficient framework for tackling the challenges of mental health information extraction in Chinese texts. By integrating instruction-tuned LLMs with a lightweight type-verification component, our approach significantly improves extraction accuracy and computational efficiency. This framework holds promise for supporting scalable, automated mental health support systems, advancing both research and practical applications in the mental health domain.},
  archive      = {J_ARTMED},
  author       = {Zijie Cai and Hui Fang and Jianhua Liu and Ge Xu and Yunfei Long and Yin Guan and Tianci Ke},
  doi          = {10.1016/j.artmed.2025.103087},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {103087},
  shortjournal = {Artif. Intell. Med.},
  title        = {Improving unified information extraction in chinese mental health domain with instruction-tuned LLMs and type-verification component},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BDFormer: Boundary-aware dual-decoder transformer for skin
lesion segmentation. <em>ARTMED</em>, <em>162</em>, 103079. (<a
href="https://doi.org/10.1016/j.artmed.2025.103079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segmenting skin lesions from dermatoscopic images is crucial for improving the quantitative analysis of skin cancer. However, automatic segmentation of skin lesions remains a challenging task due to the presence of unclear boundaries, artifacts, and obstacles such as hair and veins, all of which complicate the segmentation process. Transformers have demonstrated superior capabilities in capturing long-range dependencies through self-attention mechanisms and are gradually replacing CNNs in this domain. However, one of their primary limitations is the inability to effectively capture local details, which is crucial for handling unclear boundaries and significantly affects segmentation accuracy. To address this issue, we propose a novel boundary-aware dual-decoder transformer that employs a single encoder and dual-decoder framework for both skin lesion segmentation and dilated boundary segmentation. Within this model, we introduce a shifted window cross-attention block to build the dual-decoder structure and apply multi-task distillation to enable efficient interaction of inter-task information. Additionally, we propose a multi-scale aggregation strategy to refine the extracted features, ensuring optimal predictions. To further enhance boundary details, we incorporate a dilated boundary loss function, which expands the single-pixel boundary mask into planar information. We also introduce a task-wise consistency loss to promote consistency across tasks. Our method is evaluated on three datasets: ISIC2018, ISIC2017, and PH 2 , yielding promising results with excellent performance compared to state-of-the-art models. The code is available at https://github.com/Yuxuan-Ye/BDFormer .},
  archive      = {J_ARTMED},
  author       = {Zexuan Ji and Yuxuan Ye and Xiao Ma},
  doi          = {10.1016/j.artmed.2025.103079},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {103079},
  shortjournal = {Artif. Intell. Med.},
  title        = {BDFormer: Boundary-aware dual-decoder transformer for skin lesion segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Empowering large language models for automated clinical
assessment with generation-augmented retrieval and hierarchical
chain-of-thought. <em>ARTMED</em>, <em>162</em>, 103078. (<a
href="https://doi.org/10.1016/j.artmed.2025.103078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: Understanding and extracting valuable information from electronic health records (EHRs) is important for improving healthcare delivery and health outcomes. Large language models (LLMs) have demonstrated significant proficiency in natural language understanding and processing, offering promises for automating the typically labor-intensive and time-consuming analytical tasks with EHRs. Despite the active application of LLMs in the healthcare setting, many foundation models lack real-world healthcare relevance. Applying LLMs to EHRs is still in its early stage. To advance this field, in this study, we pioneer a generation-augmented prompting paradigm “GAPrompt” to empower generic LLMs for automated clinical assessment, in particular, quantitative stroke severity assessment, using data extracted from EHRs. Methods: The GAPrompt paradigm comprises five components: (i) prompt-driven selection of LLMs, (ii) generation-augmented construction of a knowledge base, (iii) summary-based generation-augmented retrieval (SGAR); (iv) inferencing with a hierarchical chain-of-thought (HCoT), and (v) ensembling of multiple generations. Results: GAPrompt addresses the limitations of generic LLMs in clinical applications in a progressive manner. It efficiently evaluates the applicability of LLMs in specific tasks through LLM selection prompting, enhances their understanding of task-specific knowledge from the constructed knowledge base, improves the accuracy of knowledge and demonstration retrieval via SGAR, elevates LLM inference precision through HCoT, enhances generation robustness, and reduces hallucinations of LLM via ensembling. Experiment results demonstrate the capability of our method to empower LLMs to automatically assess EHRs and generate quantitative clinical assessment results. Conclusion: Our study highlights the applicability of enhancing the capabilities of foundation LLMs in medical domain-specific tasks, i.e. , automated quantitative analysis of EHRs, addressing the challenges of labor-intensive and often manually conducted quantitative assessment of stroke in clinical practice and research. This approach offers a practical and accessible GAPrompt paradigm for researchers and industry practitioners seeking to leverage the power of LLMs in domain-specific applications. Its utility extends beyond the medical domain, applicable to a wide range of fields.},
  archive      = {J_ARTMED},
  author       = {Zhanzhong Gu and Wenjing Jia and Massimo Piccardi and Ping Yu},
  doi          = {10.1016/j.artmed.2025.103078},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {103078},
  shortjournal = {Artif. Intell. Med.},
  title        = {Empowering large language models for automated clinical assessment with generation-augmented retrieval and hierarchical chain-of-thought},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finger-aware artificial neural network for predicting
arthritis in patients with hand pain. <em>ARTMED</em>, <em>162</em>,
103077. (<a href="https://doi.org/10.1016/j.artmed.2025.103077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Arthritis is an inflammatory condition associated with joint damage, the incidence of which is increasing worldwide. In severe cases, arthritis can result in the restriction of joint movement, thereby affecting daily activities; as such, early and accurate diagnosis crucial to ensure effective treatment and management. Advances in imaging technologies used for arthritis diagnosis, particularly Single Photon Emission Computed Tomography/Computed Tomography (SPECT/CT), have enabled the quantitative measurement of joint inflammation using SUV max . To the best of our knowledge, this is the first study to apply deep learning to SUV max to predict the development of hand arthritis. We developed a transformer-based Finger-aware Artificial Neural Network (FANN) to predict arthritis in patients experiencing hand pain, including finger embedding, and to share unique finger-specific information between hands. Compared to conventional machine learning models, the FANN model demonstrated superior performance, achieving an area under the receiver operating characteristic curve of 0.85, accuracy of 0.79, precision of 0.87, recall of 0.79, and F1-score of 0.83. Furthermore, analysis using the SHapley Additive exPlanations (SHAP) algorithm revealed that the FANN predictions were most significantly influenced by the proximal interphalangeal joints of the right hand, in which arthritis is the most clinically prevalent. These findings indicate that the FANN significantly enhances arthritis prediction, representing a promising tool for clinical decision-making in arthritis diagnosis.},
  archive      = {J_ARTMED},
  author       = {Hwa-Ah-Ni Lee and Geun-Hyeong Kim and Seung Park and In Ah Choi and Hyun Woo Kwon and Hansol Moon and Jae Hyun Jung and Chulhan Kim},
  doi          = {10.1016/j.artmed.2025.103077},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {103077},
  shortjournal = {Artif. Intell. Med.},
  title        = {Finger-aware artificial neural network for predicting arthritis in patients with hand pain},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="asoc---106">ASOC - 106</h2>
<ul>
<li><details>
<summary>
(2025). Data preprocessing techniques and neural networks for
trended time series forecasting. <em>ASOC</em>, <em>174</em>, 113063.
(<a href="https://doi.org/10.1016/j.asoc.2025.113063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on time series forecasting continues to attract significant attention, particularly in the use of Artificial Neural Networks (ANN) due to their ability to model nonlinear behaviors. However, forecasting economic time series with steep upward trends presents challenges, often leading to poorly fitting predictions. This study addresses the issue by applying differentiation as a preprocessing step. Three real-world time series exhibiting this behavior were analyzed and forecasted using two neural network models—Long Short-Term Memory (LSTM) and Multilayer Perceptron (MLP)—with and without preprocessing. The differentiated series were further processed using techniques such as Empirical Mode Decomposition (EMD) and trend-fluctuation decomposition via Moving Average of Wavelet Transform. The results demonstrate that differentiation significantly enhances forecasting accuracy across all tested models, reducing errors by up to 30 % compared to models without preprocessing. This approach effectively mitigates trend-related distortions, leading to more reliable predictions in complex economic time series.},
  archive      = {J_ASOC},
  author       = {Ana Lazcano and Miguel A. Jaramillo-Morán},
  doi          = {10.1016/j.asoc.2025.113063},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113063},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Data preprocessing techniques and neural networks for trended time series forecasting},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unveiling authenticity with diffusion-based face retouching
reversal. <em>ASOC</em>, <em>174</em>, 113062. (<a
href="https://doi.org/10.1016/j.asoc.2025.113062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unveiling the real appearance of retouched faces to prevent malicious users from deceptive advertising and economic fraud has been an increasing concern in the era of digital economics. This article makes the first attempt to investigate the face retouching reversal (FRR) problem. We first build an FRR dataset, named deepFRR, by collecting 50,000 StyleGAN-generated high-resolution (1024 × 1024) facial images and retouching them via a commercial online API. Then, we present a novel diffusion-based FRR network (FRRffusion) for the FRR task. Our FRRffusion consists of a coarse-to-fine two-stage architecture: A diffusion-based Facial Morpho-Architectonic Restorer (FMAR) is constructed to generate the basic contours of low-resolution faces in the first stage, while a Transformer-based Hyperrealistic Facial Detail Generator (HFDG) is designed to create high-resolution facial details in the second stage. Tested on deepFRR, our FRRffusion surpasses the state-of-the-art image restoration method with 22%, 11%, 20%, and 6% performance improvement in SSIM, PSNR, VGGS, and CLIPS, respectively. Especially, the de-retouched images by our FRRffusion are visually much closer to the raw face images than both the retouched face images and those restored by the state-of-the-art, like GP-UNIT and Stable Diffusion, in terms of qualitative evaluation with 85 subjects. These results sufficiently validate the efficacy of our FRRffusion, bridging the gap between the FRR and generic image restoration tasks. The code is available at https://github.com/GZHU-DVL/FRRffusion .},
  archive      = {J_ASOC},
  author       = {Fengchuang Xing and Xiaowen Shi and Yuan-Gen Wang and Chunsheng Yang},
  doi          = {10.1016/j.asoc.2025.113062},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113062},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Unveiling authenticity with diffusion-based face retouching reversal},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nested deep learning with learned network embeddings for
software defect prediction. <em>ASOC</em>, <em>174</em>, 113057. (<a
href="https://doi.org/10.1016/j.asoc.2025.113057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing software (SW) defect prediction approaches and the models are majorly based on features extracted from the code of the software to build defect datasets for predictive modeling. However, these models fail to sufficiently capture the complex, latent dependencies within the software components, which acts as a hindrance in achieving higher predictive accuracy. This study introduces an improved defect prediction model, the Nested Deep Learning (NDL) model, that leverages network embeddings from call graphs for enhanced representation of intricate hierarchical class dependencies and interactions. This work evaluates six network-embedding algorithms by applying them to call graphs of 10 real software projects, generating embeddings of dimensions 32 and 128. A total of 50 NDL models—with and without dropout layers—are developed, and a comparative evaluation of these models is conducted against traditional classifier-based models. This evaluation demonstrated the superiority of the NDL model with dropout, achieving a mean AUC of 0.87, an 8.98 % improvement over the traditional classifier-based models. Among the evaluated embedding methods, LINE embeddings outperformed others, and integrating network embeddings with software metrics led to a 15.85 % AUC improvement over using software metrics alone. The optimal configuration—combining software metrics with LINE embeddings (dimension 128) in an NDL model with three deep learning layers and dropout—achieved a mean AUC of 0.93, surpassing all other configurations by 3.33–14.81 % . This study is the first to validate the effectiveness of a nested deep learning framework for modeling call graph dependencies through network embeddings, providing a scalable and robust approach for improving software defect prediction.},
  archive      = {J_ASOC},
  author       = {Sweta Mehta and Lov Kumar and Sanjay Misra and K.Sridhar Patnaik and Vikram Singh},
  doi          = {10.1016/j.asoc.2025.113057},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113057},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Nested deep learning with learned network embeddings for software defect prediction},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view self-supervised learning on heterogeneous graphs
for recommendation. <em>ASOC</em>, <em>174</em>, 113056. (<a
href="https://doi.org/10.1016/j.asoc.2025.113056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have significantly contributed to data mining but face challenges due to sparse graph data and lack of labels. Typically, GNNs rely on simple feature aggregation to leverage unlabeled information, neglecting the richness inherent in unlabeled data within graphs. Graph self-supervised learning methods effectively capitalize on unlabeled information. Nevertheless, most existing graph self-supervised learning methods focus on homogeneous graphs, ignoring the heterogeneity of graphs and mainly considering the graph structure from a single perspective. These methods cannot fully capture the complex semantics and correlations in heterogeneous graphs. It is challenging to design self-supervised learning tasks that can fully capture and represent complex relationships in heterogeneous graphs. In order to address the above problems, we investigate the problem of self-supervised HGNN and propose a new self-supervised learning mechanism for HGNN called Multi-view Self-supervised Learning on Heterogeneous Graphs for Recommendation (MSRec). We introduce a maximum entropy path sampler to help sample meta-paths containing structural context. Encoding information from diverse views defined by various meta-paths, decoding it into a semantic space different from own and optimizing tasks in both local-view and global-view contrastive learning, which facilitates collaborative and mutually supervisory interactions between the two views, leveraging unlabeled information for node embedding learning effectively. According to experimental results, our method demonstrates an optimal performance improvement of approximately 7% in NDCG@10 and about 8% in Prec@10 compared to state-of-the-art models. The experimental results on three real-world datasets demonstrate the superior performance of MSRec compared to state-of-the-art recommendation methods.},
  archive      = {J_ASOC},
  author       = {Yunjia Zhang and Yihao Zhang and Weiwen Liao and Xiaokang Li and Xibin Wang},
  doi          = {10.1016/j.asoc.2025.113056},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113056},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-view self-supervised learning on heterogeneous graphs for recommendation},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-branch attention coupled convolutional domain
adaptation network for bearing intelligent fault recognition under
unlabeled sample scenarios. <em>ASOC</em>, <em>174</em>, 113053. (<a
href="https://doi.org/10.1016/j.asoc.2025.113053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bearing intelligent fault recognition is important to maintain the healthy and stable operation of mechanical equipment. However, it is difficult to have a consistent distribution of the acquired source and target domain data due to the constantly changing operating state of the equipment. Moreover, the acquisition of sufficient labeled data is constrained by both time and economic costs. Most of the existing recognition methods are difficult to perform effective fault recognition when faced with inconsistent data distribution and unlabeled small sample data. To address these issues, this paper proposes a multi-branch attention coupled convolutional domain adaptation network (MACCDAN) for unsupervised cross-domain fault recognition, which contains three unique parts. A cross-attention coupled module (CACM) is firstly designed between two parallel feature extraction branches to guide the intertwined coupling of the two branch features through a dual synergetic attention mechanism. A global feature aggregation module (GFAM) is further presented to conduct the global information fusion, which integrates the dependencies between different branch features and enhances the perception of key features. Additionally, the maximum-similarity minimum-discrepancy adversarial loss (MSMDAL) is formulated as an optimization objective to reduce the discrepancy between the source and target domain, and promote the learning of domain-invariant and discriminative features. The results of the four performance evaluation metrics (i.e., accuracy, precision, recall and F1 score) of the proposed method are all 1.0000 on two datasets. The F1 score of the proposed method is improved by at least 0.03 compared to other methods.},
  archive      = {J_ASOC},
  author       = {Maoyou Ye and Xiaoan Yan and Dong Jiang and Ning Chen},
  doi          = {10.1016/j.asoc.2025.113053},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113053},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-branch attention coupled convolutional domain adaptation network for bearing intelligent fault recognition under unlabeled sample scenarios},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A morphological difference and statistically sparse
transformer-based deep neural network for medical image segmentation.
<em>ASOC</em>, <em>174</em>, 113052. (<a
href="https://doi.org/10.1016/j.asoc.2025.113052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image segmentation plays a pivotal role in enhancing disease diagnosis and treatment planning. However, existing methods often struggle with the complexity of lesion boundaries and the computational demands of Transformer-based approaches. To address these challenges, we propose a morphological difference and statistically sparse Transformer-based deep neural network for medical image segmentation, termed MD-SSFormer. It comprises two critical modules: the dual branch encoder (DBEncoder) module, and the morphological difference catcher (MDC). To extract abundant information at different aspects, a novel DBEncoder module integrates the capability of the convolutional neural network-based method in capturing local texture and the ability of the Transformer-based method in modeling global information. Compared to the conventional feature extraction methods, DBEncoder achieves comprehensive improvement. Furthermore, the statistics-based sparse Transformer (SSFormer) module develops an innovative statistical analysis and an adaptive patch-dividing strategy to perform attention-computing, which addresses the computational challenges associated with conventional Transformer-based models. Finally, considering the impacts of the blurry and complex boundaries, the MDC module employs the morphological operation and differential information extractor to refine the details, which achieves high-precision boundary understanding. Experimental results on five public datasets demonstrate MD-SSFormer&#39;s superior performance, achieving state-of-the-art Dice scores of 83.60 % on ISIC 2017, 79.52 % on Kvasir-SEG, 61.89 % on BUSI, 78.62 % on BraTS21, and 85.85 % on 3DIRCADb, outperforming other methods in accuracy, precision, and computational efficiency respectively.},
  archive      = {J_ASOC},
  author       = {Dongxu Cheng and Zifang Zhou and Hao Li and Jingwen Zhang and Yan Yang},
  doi          = {10.1016/j.asoc.2025.113052},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113052},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A morphological difference and statistically sparse transformer-based deep neural network for medical image segmentation},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A heuristic-based multi-stage machine learning-based model
to design a sustainable, resilient, and agile reverse corn supply chain
by considering third-party recycling. <em>ASOC</em>, <em>174</em>,
113042. (<a href="https://doi.org/10.1016/j.asoc.2025.113042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the reverse supply chain configuration problem for the agri-food sector with agility, resilience, and sustainability aspects. To do this, this article proposes a heuristic-based multi-stage machine learning-based model to design a corn reverse logistics based on agility, resilience, and sustainability features. In this way, at the first stage, the performance of the potential recycling partners is evaluated by combining the Categorical Boosting Algorithm (CatBoost) method. In the next stage, a multi-objective model is suggested to configure the corn reverse logistics in which the resilience, agility, and sustainability dimensions are incorporated. Afterwards, we deal with uncertainty by developing a data-driven method based on the chance-constrained fuzzy programming method and the seasonal autoregressive integrated moving average approach. Finally, by choosing a real-world case study, the suggested model is solved by developing a heuristic-based solution procedure. The obtained results showed that the developed heuristic-based solution approach able to find optimal and near-optimal solution in a reasonable time. Based on the achieved outputs, increasing the capacity parameter has a positive impact in the efficiency of the supply chain. Also, results show that when the amount of the initial waste increases, the total profit and environmental impacts of the supply chain have increased, too. Also, the achieved outputs confirm the robustness and efficiency of the developed machine learning-based approach. Then, several sensitivity analyses are presented to examine the role of the key parameters in the research problem. Finally, the managerial insights are provided.},
  archive      = {J_ASOC},
  author       = {Fardin Rezaei Zeynali and Mohammad Parvin and Ali Akbar ForouzeshNejad and Emaad Jeyzanibrahimzade and Mohssen Ghanavati-Nejad and AmirReza Tajally},
  doi          = {10.1016/j.asoc.2025.113042},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113042},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A heuristic-based multi-stage machine learning-based model to design a sustainable, resilient, and agile reverse corn supply chain by considering third-party recycling},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multidimensional fitness function based heuristic
algorithm for set covering problems. <em>ASOC</em>, <em>174</em>,
113038. (<a href="https://doi.org/10.1016/j.asoc.2025.113038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The set covering problem (SCP) is a conventional integer programming challenge in combinatorial optimization, with applications spanning fields such as transportation, logistics, and location problems. Solving SCPs efficiently is crucial for optimizing operations in these domains, particularly in location problems, where traditional algorithms often struggle with multidimensional objective spaces. To address such challenges, this study proposes a novel problem-dependent heuristic algorithm to solve SCPs, featuring a new multi-dimensional fitness function, which was evaluated by benchmarking against other heuristic and metaheuristic algorithms. A collection of reproduced and selected OR-library problems of various scales were chosen as benchmark instances to assess the performance of the algorithm. The performance of the algorithm was confirmed as it constructs solutions by leveraging a novel fitness function to address the limitations of time complexity, applicability, and scalability. Computational results demonstrate that the developed algorithm offers competitive solutions for SCPs, showing improvements of up to 88 % and 20 % in terms of time compared to simulated annealing and a preliminary heuristic algorithm, respectively. In terms of quality, the developed algorithm achieved cost reductions of up to 21 % and 11 % compared to these algorithms, respectively.},
  archive      = {J_ASOC},
  author       = {Ahmad Hashemi and Hamed Gholami and Xavier Delorme and Kuan Yew Wong},
  doi          = {10.1016/j.asoc.2025.113038},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113038},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multidimensional fitness function based heuristic algorithm for set covering problems},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessing the industry 4.0 strategies in the automobile
manufacturing firm using a combined compromise solution-based ranking
method. <em>ASOC</em>, <em>174</em>, 113037. (<a
href="https://doi.org/10.1016/j.asoc.2025.113037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Implementing industry 4.0 (I4.0) strategies in automobile manufacturing firm leads to the higher demand for newer services, drives innovation, continuously innovates to meet the changing needs and expectations of customers, and enables the development of sustainable solutions. This paper develops a q-rung orthopair fuzzy information (q-ROFI)-based decision support tool to evaluate I4.0 strategies in the automobile manufacturing firm. The proposed framework firstly calculates weight of decision expert using a procedure considering the q-rung orthopair fuzzy set (q-ROFS). Next, an individual opinions of decision experts are aggregated into single decision through q-ROF weighted averaging operator. Further, criteria weights are computed by a combined weighting procedure involving objective weighting through entropy-based procedure and subjective weighting by stepwise weight assessment ratio analysis (SWARA) model with q-ROFI. In the following purpose, new entropy is introduced based on the cross entropy of q-ROFS and new score function is proposed for q-ROFS to evade the limitation of existing q-ROF-score function. On the basis of these steps, a modified combined compromise solution (CoCoSo) approach is presented to assess and prioritize the alternatives under q-ROFS context. Finally, the proposed framework is applied to a case study of I4.0 strategies evaluation problem in automobile manufacturing firm. According to the outcomes, the most suitable strategy among the other strategies over considered twenty-five evaluation criteria for assessing I4.0 strategies in the automobile manufacturing firms is as new business models development strategies (0.319), improving information systems strategies (0.273) and human resource management (HRM) strategies (0.210), respectively. The most significant criteria for assessing I4.0 strategies in the automobile manufacturing firms are technology (0.055), coordination (0.052), and legal problems (0.048), respectively. Moreover, comparison with different existing methods is presented to validate the robustness of introduced method.},
  archive      = {J_ASOC},
  author       = {Arunodaya Raj Mishra and Pratibha Rani and Ahmad M. Alshamrani and Adel Fahad Alrasheedi and Dragan Pamucar},
  doi          = {10.1016/j.asoc.2025.113037},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113037},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Assessing the industry 4.0 strategies in the automobile manufacturing firm using a combined compromise solution-based ranking method},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A feature engineering based model architecture for modeling
initial public offerings. <em>ASOC</em>, <em>174</em>, 113035. (<a
href="https://doi.org/10.1016/j.asoc.2025.113035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a model architecture for modeling Initial Public Offerings (IPOs) by incorporating a diverse range of data sources, encompassing both textual and numerical inputs. Language models, machine learning models, and deep learning architectures are combined to make the final ensemble predictions. Several rich features are engineered and interpreted while providing scope for debugging using the game theory-based Shapley Additive exPlanations (SHAP) values. The study results indicate that the feature-engineering is highly eloquent in IPO performance modelling. The study findings have high economic implications range from detecting the market trends to overall market stability.},
  archive      = {J_ASOC},
  author       = {Durga Vaidynathan and Parthajit Kayal and Moinak Maiti},
  doi          = {10.1016/j.asoc.2025.113035},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113035},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A feature engineering based model architecture for modeling initial public offerings},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-reference super-resolution reconstruction of remote
sensing images based on hierarchical similarity mapping. <em>ASOC</em>,
<em>174</em>, 113027. (<a
href="https://doi.org/10.1016/j.asoc.2025.113027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To make full use of the details from multi-reference images and improve the quality of super-resolution reconstruction of remote sensing images, a multi-reference super-resolution reconstruction of remote sensing images based on hierarchical similarity mapping is proposed. It is very important in both military and civilian fields. Firstly, one low resolution image and three reference images are used as the input of VGG network to extract their feature maps at 4 × , 2 × , and 1 × scales. These feature maps at each scale are respectively blocked and used as a set of inputs in subsequent operations. Specifically, the low resolution features are divided into N i blocks, and each block is further divided into N c sub-feature-blocks. And the N m reference image features are divided into N r sub-feature-blocks. Then the N c low-resolution sub-feature blocks are mapped for similarity with the reference features within the range of all reference sub-feature blocks, individual reference features, and all reference image features. The outputs of each layer are then iteratively mapped with the low-resolution features as inputs for next layers. Thus the final features include information from all the reference images and low-resolution image. Subsequently, an adaptive transfer module with multi-reference features and channel attention is used to match and transfer the information of each reference image, while achieving edge smoothing and noise filtering between different reference features. Finally, the quadruple super-resolution reconstruct result is got from the multi-scale feature fusion module and decoder. Experimental results show that our improvements can reconstruct better super-resolution results with more details for utilizing information of multi-reference images, which is superior to single image super-resolution methods and single reference super-resolution methods.},
  archive      = {J_ASOC},
  author       = {Fuzhen Zhu and Qi Zhang and Bing Zhu and Chen Wang},
  doi          = {10.1016/j.asoc.2025.113027},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113027},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-reference super-resolution reconstruction of remote sensing images based on hierarchical similarity mapping},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Flight anomaly detection and localization based on flight
data fusion and random channel masking. <em>ASOC</em>, <em>174</em>,
113023. (<a href="https://doi.org/10.1016/j.asoc.2025.113023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flight anomaly detection and localization are critical for enhancing aircraft safety through effective analysis of flight data. However, existing methods only detect the timing of anomalies, failing to identify and recover the specific abnormal parameters necessary for assisting flight control systems in correcting the aircraft&#39;s state. To address these limitations, this paper proposes a novel anomaly detection and localization method based on random channel masking (RCM). The proposed approach integrates a multi-node synchronous prediction (MNSP) model, which combines graph attention networks and convolutional neural networks to extract both normal and anomalous patterns from extensive flight data. RCM is employed to generate pseudo-anomalous data, enabling the MNSP model to accurately localize and recover affected parameters. The effectiveness of proposed method is validated using real flight data from unmanned aerial vehicle, achieving an average anomaly detection accuracy of 95 % across four distinct types of anomalies. Furthermore, the method successfully localizes specific abnormal parameters with a localization accuracy of no less than 92.5 % across three different anomaly scenarios. In single-parameter anomaly scenarios, the mean squared error of data recovery remains below 0.000082. The study also explores the boundaries of anomaly localization in multi-parameter scenarios, highlighting the algorithm&#39;s robustness and applicability under diverse conditions.},
  archive      = {J_ASOC},
  author       = {Jie Zhong and Heng Zhang and Qiang Miao},
  doi          = {10.1016/j.asoc.2025.113023},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113023},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Flight anomaly detection and localization based on flight data fusion and random channel masking},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A quantum entanglement-based optimization method for complex
expensive engineering problems. <em>ASOC</em>, <em>174</em>, 113019. (<a
href="https://doi.org/10.1016/j.asoc.2025.113019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the computational costliness and time-consuming nature of complex and expensive engineering (CEE) problems, this paper proposes a genetic algorithm based on quantum entanglement to address these challenges. This method encodes individuals into quantum genes, where each gene bit stores not 0 or 1, but a superposition state of both. By leveraging the uncertainty of the superposition state during the collapse, this method effectively preserves population diversity even with a very small population size. A smaller population size implies fewer calls to time-consuming simulations. Additionally, quantum entangled states are created for parts of an individual&#39;s gene, utilizing the characteristic that entangled states instantly affect each other upon collapse, to achieve parallel evolution of parts of the genes in multiple individuals. This parallel evolution significantly increases the search speed of the algorithm, thereby reducing the number of iterations. Fewer iterations also mean fewer calls to simulations. Benchmark function experiments demonstrate that the proposed method is significantly superior to other similar algorithms in a 30D solution space with a population size of 20 and also has certain advantages in a 100D solution space.},
  archive      = {J_ASOC},
  author       = {Fengling Peng and Xing Chen},
  doi          = {10.1016/j.asoc.2025.113019},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113019},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A quantum entanglement-based optimization method for complex expensive engineering problems},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). State-space recurrent neural networks for predictive
analytics and latent state estimation. <em>ASOC</em>, <em>174</em>,
113017. (<a href="https://doi.org/10.1016/j.asoc.2025.113017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a framework to predict the remaining life (RL) of degrading systems under sensor condition monitoring. By integrating state-space modeling with stochastic recurrent neural networks, our approach efficiently processes condition-monitoring time-series data and models systems’ latent degradation states. We propose a stochastic model that captures dependencies among latent degradation states, sensor outputs, and RL in a causally coherent manner and utilizes stochastic neural networks to navigate the inherent uncertainties of system dynamics. To enhance the interpretability of RL estimation and latent state modeling, we propose interpretable regularization terms. These terms are incorporated into the loss function to optimize both the prediction precision of estimating remaining life and latent states and control the monotonic behavior of their estimates, thereby improving the model’s overall performance and interpretability. Our methodology is validated through numerical experiments and comparison with benchmark models, demonstrating its potential to improve predictive maintenance strategies by effectively estimating the remaining life and monitoring the state of latent degradation over time.},
  archive      = {J_ASOC},
  author       = {Ramin Moghaddass and Cheng-Bang Chen},
  doi          = {10.1016/j.asoc.2025.113017},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113017},
  shortjournal = {Appl. Soft. Comput.},
  title        = {State-space recurrent neural networks for predictive analytics and latent state estimation},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-label learning for fault diagnosis of pumping units
with one positive label. <em>ASOC</em>, <em>174</em>, 113014. (<a
href="https://doi.org/10.1016/j.asoc.2025.113014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis using the indicator diagram is a fundamental method to evaluate the working status of pumping units. In applications, human experts typically identify only one fault for each indicator diagram. However, multiple types of faults may occur simultaneously. In this paper, we propose a Single-Positive Multi-label learning for Fault Diagnosis of Pumping Units (SPM-FDPU) algorithm to address this issue. Although trained on single-label data, it is capable of multi-label prediction. First, HU invariant moments and convolutional neural networks are used to extract common and label-specific features, respectively. Second, instance, feature, and label correlations are injected into the training process by feature and label manifolds to enhance supervised information. Third, the manifold is used to augment the latent label matrix to help explore discriminant information. Experiments are conducted on the three real indicator diagram data of an oil field and sixteen multi-label benchmark datasets. The results show that the accuracy of the proposed method has achieved 98% in diagnosing multiple faults on indicator diagram datasets, and the mean rank of the proposed method is optimal in terms of six popular evaluation metrics on multi-label benchmark datasets. The source code is available at github.com/Kqian2020/SPM-FDPU .},
  archive      = {J_ASOC},
  author       = {Kun Qian and Jinyu Tang and Qimei Zhao and Shu Zhao and Fan Min},
  doi          = {10.1016/j.asoc.2025.113014},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113014},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-label learning for fault diagnosis of pumping units with one positive label},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-agent modeling for indoor fire risk prediction during
evacuation based on cellular automata and artificial neural network.
<em>ASOC</em>, <em>174</em>, 113013. (<a
href="https://doi.org/10.1016/j.asoc.2025.113013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fire cases have always posed threats to human lives and property safety, and new approaches have been developed to investigate how people behave during the fire process. Understanding the underlying mechanism under specific scenarios and conditions is critical to find possible ways of reducing social losses. Here, we propose a coupled model that combines FDS and CA, to assess fire risks in a multi-story dormitory building at a university. For this real target case, the settings of automatic sprinklers and temperature alarms will be considered in our coupled model. The aim is to investigate how pedestrians behave under the fire emergencies and how fire safety facilities (exits) shape final evacuation outcomes. To analysis the final outcomes and related factors, we use Event Tree and BP neural network methods to assess and predict individual risk levels. It suggests that controlling the number of people in each dormitory will effectively reduce the fire risk, and the existence of safety facilities can significantly contain fire risks. Early fire warning systems and quick response times are critical to reduce casualties during the evacuation process. Individual risk levels can be efficiently calculated by Event Tree method, and BP neural network can accurately predict fire risk levels. By integrating technologies such as FDS, CA, ETA, and BP neural networks, our model can effectively simulate the dynamic process of the fire evacuation while accurately predicting the fire risks, which establishes an effective link between environmental factors and fire risk assessment. This provides a methodological reference for future fire risk assessment research.},
  archive      = {J_ASOC},
  author       = {Peng Lu},
  doi          = {10.1016/j.asoc.2025.113013},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113013},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-agent modeling for indoor fire risk prediction during evacuation based on cellular automata and artificial neural network},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Short-term forecasting of electricity price using ensemble
deep kernel based random vector functional link network. <em>ASOC</em>,
<em>174</em>, 113012. (<a
href="https://doi.org/10.1016/j.asoc.2025.113012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate short-term electricity price forecasting in a deregulated electrical market is a difficult task as the electricity price exhibits high nonlinearity, sharp price spikes, and seasonality in different frequencies, etc. Thus, this study presents a new approach using an Ensemble Deep Kernel Random Vector Functional Link Network (EDKRVFLN) model hybridized with a Chaotic Sine Cosine Improved Firefly Algorithm (CSCIFA) for short-term electricity price forecasting with better generalization capacity, simple structure, and significant accuracy. Unlike the Ensemble Deep Random Vector Functional Link Network (EDRVFLN) where each stacked layer requires proper choice of the number of hidden nodes and manual tuning of random weights and biases along with the pseudoinverse solution of the output weights in each layer leading to suboptimal model generalization. However, the choice of random weights and biases along with the number of hidden neurons in the proposed EDKRVFLN model can be dispensed by using kernel-based transformation and representation learning. Further each stacked layer of the proposed model utilizes kernel based linear features from the direct links and nonlinearly transformed features from the enhancement nodes from the preceding layers of the prediction model. Also, each layer produces an output by simple invertible kernel matrix inversion based on generalized least squares, and the final output is the ensemble of the outputs from each layer, thus simultaneously producing an ensemble and deep learning framework. Seven electricity price datasets are examined to confirm the supremacy of the proposed model in comparison to several benchmark models.},
  archive      = {J_ASOC},
  author       = {Someswari Perla and Ranjeeta Bisoi and P.K. Dash and A.K. Rout},
  doi          = {10.1016/j.asoc.2025.113012},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113012},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Short-term forecasting of electricity price using ensemble deep kernel based random vector functional link network},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing AI safety of machine unlearning for ensembled
models. <em>ASOC</em>, <em>174</em>, 113011. (<a
href="https://doi.org/10.1016/j.asoc.2025.113011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, machine unlearning (MU) has received significant attention for its ability to remove specific undesired knowledge from a trained model, thereby ensuring AI safety. Furthermore, efforts have been made to integrate MU into existing Machine Learning as a Service (MLaaS), allowing users to raise requests to remove the influence of their data used in the training phase, after which the server conducts MU to remove its influence based on the unlearning requests. However, previous research reveals that malicious users may manipulate the requests so that the model utility may be significantly compromised after unlearning, which is known as malicious unlearning. In addition, privacy leakage may be exploited by malicious users by analyzing inference results obtained from the original model and the unlearned model. In this connection, we investigate these potential risks, specifically in ensemble models, which are widely adopted in MU because of their efficiency in unlearning and robustness in learning. However, despite these advantages, their vulnerabilities to malicious unlearning and privacy leakage remain largely unexplored. Our work explores malicious unlearning and malicious inference in ensemble settings. We propose a method in which malicious unlearning requests can trigger hidden poisons in ensembles, causing target images to be misclassified as intended by adversaries. Additionally, we introduce a privacy leakage attack where adversaries with black-box access to voting outputs can infer the unlearned label by analyzing the differences between the original and unlearned ensemble outputs. Experimental results demonstrate that these attacks can be highly stealthy and achieve a high success rate. Furthermore, comparative experiments reveal that these attacks present slightly lower stealthiness in ensemble settings compared to single-model scenarios, suggesting that ensemble models have advantages in detecting such malicious activities. These findings reveal that ensemble models are vulnerable to malicious unlearning and privacy leakage and highlight the urgent need for more robust MU designs to ensure AI safety.},
  archive      = {J_ASOC},
  author       = {Huanyi Ye and Jiale Guo and Ziyao Liu and Yu Jiang and Kwok-Yan Lam},
  doi          = {10.1016/j.asoc.2025.113011},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113011},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Enhancing AI safety of machine unlearning for ensembled models},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual degradation image inpainting method via adaptive
feature fusion and u-net network. <em>ASOC</em>, <em>174</em>, 113010.
(<a href="https://doi.org/10.1016/j.asoc.2025.113010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing image inpainting methods are designed to address a single specific task, such as super-resolution, denoising, or colorization, with few models capable of handling dual degradation simultaneously. Moreover, current algorithms that tackle multiple image degradation problems often suffer from complex structures, prolonged training times, and high labor costs. In this paper, we propose a Dual Degradation Network via Adaptive Feature Fusion and U-Net (AFFU). The network employs a Self-Guided Module (SGM) to fuse multi-scale image information, effectively eliminating certain defects in the image. A coder-decoder module with null convolution is utilized to consolidate the semantic information of the image, enabling intermediate image colorization. Additionally, an Adaptive Multi-feature Fusion Module (AMF) and Information Transfer Mechanism (ITM) are introduced to link these two major structures, adaptively selecting and retaining image features during network progression to prevent the loss of useful information. Experimental results demonstrate that the proposed dual image degradation restoration network model, based on adaptive multi-feature fusion, achieves optimal visual generation. Evaluations on CelebA dataset and Landscape dataset show that the proposed method outperforms comparable approaches in terms of Structural Similarity (SSIM) and Learned Perceptual Image Patch Similarity (LPIPS).},
  archive      = {J_ASOC},
  author       = {Yuantao Chen and Runlong Xia and Kai Yang and Ke Zou},
  doi          = {10.1016/j.asoc.2025.113010},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113010},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dual degradation image inpainting method via adaptive feature fusion and U-net network},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention-aware graph contrastive learning with topological
relationship for recommendation. <em>ASOC</em>, <em>174</em>, 113008.
(<a href="https://doi.org/10.1016/j.asoc.2025.113008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems are a vital tool to guide the overwhelming amount of online information for users, which has been successfully applied to online retail platforms, social networks, etc. Recently, contrastive learning has revealed outstanding performance in recommendation by data augmentation strategies to handle highly sparse data. Most existing work fails to leverage the original network’s topology to construct attention-aware modules that identify user–item interaction importance for guiding node aggregation while preserving key semantics and reducing noise in the reconstructed graph during data augmentation. In this paper, our work proposes an At t e ntion-aware G raph C ontrastive L earning architecture with Topological Relationship (AteGCL) for recommendation. In particular, our AteGCL proposes an attention-aware mechanism with topological relationships to learn the importance between users and items for extracting the local graph dependency, which identifies the importance between nodes by constructing an attention-aware matrix into graph convolutional networks using a random walk with a restart strategy for generating node feature aggregation. We then employ principal component analysis (PCA) for contrastive augmentation and utilize the attention-aware matrix to ease noise from the reconstructed graph generated by PCA and to generate a new view with global collaborative relationships and less noise. Comprehensive experiments on three real-world user–item networks reveal the superiority of our AteGCL over diverse state-of-the-art recommendation approaches. Our code is available at https://github.com/ZZHCodeZera/AteGCL .},
  archive      = {J_ASOC},
  author       = {Xian Mo and Jun Pang and Zihang Zhao},
  doi          = {10.1016/j.asoc.2025.113008},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113008},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Attention-aware graph contrastive learning with topological relationship for recommendation},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Category-level pipe pose and size estimation via
geometry-aware adaptive curvature convolution. <em>ASOC</em>,
<em>174</em>, 113006. (<a
href="https://doi.org/10.1016/j.asoc.2025.113006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pipe pose estimation provides crucial positional information for robots, enhancing assembly efficiency and precision, while its accuracy critically impacts the final product&#39;s reliability and quality. To handle unseen pipes, we propose a category-level pipe pose and size estimation network via Normalized Object Coordinate Space (NOCS) representation. Given an RGB image and its corresponding depth map, our network predicts class labels, bounding boxes and instance masks for detection, as well as NOCS maps for pose estimation. Then these predictions are aligned with the depth map to estimate pipe’s pose and size. To better extract complex and variable pipe morphology, geometry-aware adaptive curvature convolution is introduced to dynamically adapt to the slender structure and improve segmentation performance. Facing the lack of pipe pose datasets with enough instances, pose, clutter, occlusion, and illumination variation, we propose a novel domain randomization mixed reality approach to efficiently generate synthetic data, which addresses the limitations of training datasets, making data generation more time- and effort-efficient. Experimental results demonstrate that our Geometry-Aware Adaptive Convolutional Network (GACNet) outperforms other methods and robustly estimates the pose and size of unseen pipes in real-world environments.},
  archive      = {J_ASOC},
  author       = {Jia Hu and Jianhua Liu and Shaoli Liu and Lifeng Wang},
  doi          = {10.1016/j.asoc.2025.113006},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113006},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Category-level pipe pose and size estimation via geometry-aware adaptive curvature convolution},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discrete differentiated creative search for traveling
salesman problem. <em>ASOC</em>, <em>174</em>, 112998. (<a
href="https://doi.org/10.1016/j.asoc.2025.112998">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel population-based Discrete Differentiated Creative Search (DDCS) is proposed in this paper for solving the traveling salesman problem (TSP). DDCS introduces greedy beam search to adaptively initialize the population and improve the quality of the initial solutions. Second, a multi-edge construction operator, edge-based mathematical operations and a similarity attraction operator are used to guide individuals from different population categories towards higher-quality solutions based on the current solutions. Finally, a random nearest neighbor replacement strategy is used to replace individuals with the same distance heuristically, reducing the assimilation rate of the population. DDCS is tested with 50 instances from TSPLIB and compared with a variety of state-of-the-art and variants of classical algorithms. The results demonstrate that DDCS exhibits superior optimization capability and higher stability.},
  archive      = {J_ASOC},
  author       = {Qi Xu and Kewen Xia and Xiaoyu Chu},
  doi          = {10.1016/j.asoc.2025.112998},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112998},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Discrete differentiated creative search for traveling salesman problem},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long-short term cross echo state network for time series
forecasting task. <em>ASOC</em>, <em>174</em>, 112997. (<a
href="https://doi.org/10.1016/j.asoc.2025.112997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Investigating the dynamics of time series in nonlinear systems has become a prominent research focus in both theoretical and practical domains. Unveiling the intrinsic characteristics of nonlinear time series can significantly enhance the understanding and modelling of nonlinear systems. Among the various time prediction models, Reservoir Computing (RC) has garnered widespread attention due to its distinctive hidden layer architecture. The Echo State Network (ESN) is one of the most representative instances within the RC framework. However, most existing ESNs do not explicitly capture the fixed multi-scale dependencies in time series, and their short-term memory (STM) cannot meet the needs of specific time series. To address these limitations, this paper introduces a novel Echo State Network with a heterogeneous topology, named the Long-short Term Cross Echo State Network (LS-CrossESN). The overall architecture of this model consists of three different types of reservoirs in parallel. And it incorporates a heterogeneous topology structure known as the cross architecture, which merges those of the first reservoir with the state characteristics of the second reservoir, so that the information between the two reservoirs can be transmitted to each other. At the same time, a time-delay operator is inserted in the second reservoir, so that the fused characteristics would not be immediately input to the next layer but transmitted to the deep layer. In this way, the characteristics of input would not decay with the update of the layers. The structure of third reservoir captures the influence of recent historical memory through a specific sliding window technology, and finally the multi-scale states from each layer would be collected for combined prediction. To optimize parameters in this model, an Improved Salp Swarm Algorithm (ISSA) is proposed. The model was tested of eight datasets spanning three categories: Mackey-Glass series, Lorenz chaotic series, Sunspot series, airport temperature series, and two real network traffic datasets. The experimental results demonstrate that the STM of LS-CrossESN is significantly improved compared with Deep-ESN, LS-ESN, DATDR and ADRC. Across all eight datasets, the model exhibits robust performance in both one-step-ahead and multi-step predictions.},
  archive      = {J_ASOC},
  author       = {Dongchen Jiang and Li Cui and Yi Zeng and Meiming You and Guoqiang Wang},
  doi          = {10.1016/j.asoc.2025.112997},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112997},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Long-short term cross echo state network for time series forecasting task},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A crude oil price forecasting framework based on constraint
guarantee and pareto fronts shrinking strategy. <em>ASOC</em>,
<em>174</em>, 112996. (<a
href="https://doi.org/10.1016/j.asoc.2025.112996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of crude oil prices is essential for making informed energy policy decisions and ensuring energy security. However, crude oil price forecasting is inherently challenging due to the volatile, nonlinear, and complex nature of the market. While ensemble learning approaches have shown promise in enhancing forecasting accuracy, many existing models rely on multi-objective optimization techniques that generate a Pareto frontier of optimal solutions, often making it difficult to select the best solution for practical application. This issue is exacerbated by the fact that some Pareto-optimal solutions are not suitable for real-world decision-making, leading to inefficiencies in model performance. To address these limitations, this research proposes a novel ensemble learning framework that incorporates a Constraint Guarantee Strategy (CGS) and a Pareto Front Shrinking Strategy (PFSS) to enhance both the accuracy and stability of crude oil price forecasting models. The CGS filters out inferior solutions during the optimization process, ensuring that the ensemble model outperforms individual models in terms of forecasting accuracy. The PFSS helps decision-makers select the most relevant solutions from the Pareto frontier by balancing trade-offs between objectives and narrowing down the set of solutions. Our framework is evaluated on three widely used datasets: Brent, WTI, and Dubai crude oil prices, and compared with state-of-the-art models from both the general time-series forecasting domain and crude oil price forecasting. It improves prediction accuracy by approximately 23.2% on the Brent dataset, 4.0% on the WTI dataset, and 21.7% on the Dubai dataset, based on improvements in MAPE. Ablation studies confirm the effectiveness of each component. The discussion further emphasizes the practical applicability and robustness of the framework, confirming its potential for real-world crude oil price forecasting.},
  archive      = {J_ASOC},
  author       = {Yujie Chen and Zhirui Tian},
  doi          = {10.1016/j.asoc.2025.112996},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112996},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A crude oil price forecasting framework based on constraint guarantee and pareto fronts shrinking strategy},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating competitive framework into differential
evolution: Comprehensive performance analysis and application in brain
tumor detection. <em>ASOC</em>, <em>174</em>, 112995. (<a
href="https://doi.org/10.1016/j.asoc.2025.112995">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an efficient and effective optimizer based on the Success History Adaptive DE (SHADE) named Competitive Framework DE (CFDE). We integrate three tailored strategies into CFDE: (1) the competitive framework to identify and prioritize potential individuals, (2) the novel DE/loser-to-best/loser-to-winner mutation scheme to fully leverage the information from the population and competition to construct high-quality offspring individuals, and (3) the random memory initialization to diversify the search patterns of the individual. We conduct comprehensive numerical experiments on CEC2017, CEC2020, CEC2022, and eight engineering problems against eleven state-of-the-art optimizers to confirm the superiority and competitiveness of CFDE. Moreover, the sensitivity experiments on hyperparameters validate the robustness of CFDE, and the ablation experiments practically prove the independent contribution of integrated components. Furthermore, we propose a hybrid model named DenseNet-CFDE-ELM for brain tumor detection, where DenseNet-169 is employed for feature selection and CFDE-optimized Extreme Learning Machine (ELM) classifies the brain tumors in MRI scans. Experimental results on the brain tumor dataset downloaded from Kaggle confirm that the proposed DenseNet-CFDE-ELM achieves improvements in accuracy with 1.794%, precision with 1.696%, recall with 1.794%, and F1 score with 1.812% against the second-best ResNet-18 model. These results reveal the potential of CFDE in extensive real-world optimization scenarios. The source code of this research can be downloaded from https://github.com/RuiZhong961230/CFDE .},
  archive      = {J_ASOC},
  author       = {Rui Zhong and Zhongmin Wang and Yujun Zhang and Junbo Jacob Lian and Jun Yu and Huiling Chen},
  doi          = {10.1016/j.asoc.2025.112995},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112995},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Integrating competitive framework into differential evolution: Comprehensive performance analysis and application in brain tumor detection},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fuzzy AHP-based trust management mechanism for
self-sovereign identity in the metaverse. <em>ASOC</em>, <em>174</em>,
112994. (<a href="https://doi.org/10.1016/j.asoc.2025.112994">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-sovereign identity (SSI) technology has advantages and potential for application in the metaverse. However, the decentralization and anonymous interaction of SSI create convenience for malicious attacks, frauds, and conspiracies in the metaverse. It leads to various trust risks and threats to the meta-universe system. To address these challenges, we analyze the risks of SSI systems and constructed a reputation index system. Moreover, we propose a blockchain-based reputation management framework (BBRMF), which can constrain users from engaging in illegal activities such as forgery, fraud, and conspiracy, thereby guaranteeing the security and trustworthiness of the entities involved in the metaverse. In BBRMF, we constructed a reputation evaluation model based on fuzzy analytical hierarchy process (FAHP) to assess the user’s reputation in three dimensions: reliability, trustworthiness and security. To motivate users to accumulate more positive reputation, we set the user’s reputation score into a reputation credential in the form of non-fungible token (NFT), through which users can obtain more benefits and opportunities. Finally, we calculated the reputation value of SSI related entities from multiple perspectives through simulation experiments and comparative analysis. The feasibility of the proposed method is verified, and it is proved that it can effectively resist the interference and attack of malicious scoring nodes. Moreover, the scheme adopts multi-dimensional evaluation indexes and behavioral feature values, which significantly improves the comprehensiveness and accuracy of the reputation assessment. Meanwhile, the weights of the evaluation indexes are derived through objective calculation, ensuring the fairness of the evaluation results, and improving the credibility and repeatability of the reputation assessment.},
  archive      = {J_ASOC},
  author       = {Xiaoling Song and Guangxia Xu and Yongfei Huang},
  doi          = {10.1016/j.asoc.2025.112994},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112994},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A fuzzy AHP-based trust management mechanism for self-sovereign identity in the metaverse},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combination weighting method using z-numbers for
multi-criteria decision-making. <em>ASOC</em>, <em>174</em>, 112992. (<a
href="https://doi.org/10.1016/j.asoc.2025.112992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a hybrid approach to determining criteria weights in Multi-Criteria Decision Making (MCDM), combining subjective weight methods with objective weighting techniques based on Z-number theory. The methodology is applied in a practical context involving the establishment of a bank&#39;s call center data analysis platform. Leveraging the inherent uncertainty and reliability considerations in decision-making processes, the hybrid method offers a robust framework for decision support. Through empirical validation and case study analysis, the effectiveness of the proposed approach is demonstrated, highlighting its ability to balance theoretical robustness with practical applicability. The study underscores the importance of ongoing research in MCDM, particularly in developing innovative methods to address the complexities of decision-making environments. Insights from this research provide valuable guidance for practitioners and researchers seeking to enhance MCDM processes across diverse domains.},
  archive      = {J_ASOC},
  author       = {Huan-Jyh Shyur},
  doi          = {10.1016/j.asoc.2025.112992},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112992},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Combination weighting method using Z-numbers for multi-criteria decision-making},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A three-way decision-based model for occupational risk
assessment and classification in the healthcare industry. <em>ASOC</em>,
<em>174</em>, 112991. (<a
href="https://doi.org/10.1016/j.asoc.2025.112991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, occupational health and safety risk assessment (OHSRA) has gained more importance since occupational hazards can cause loss of life, injuries, delays, and cost overruns in an organization. The OHSRA is a critical activity for identifying, analyzing and reducing the potential occupational hazards arising from workplace for corrective actions. In this study, a new OHSRA model is proposed for the risk assessment and classification of occupational hazards by utilizing the criteria importance through inter-criteria correlation (CRITIC) method and three-way decision (TWD). First, the 2-tuple linguistic variables are utilized to express the complex and uncertain risk assessments of occupational hazards provided by experts. Second, an extended CRITIC method is employed to compute the weights of risk criteria by considering their interactions. Then the TWD is improved to determine the risk classifications of occupational hazards by considering their correlations. Finally, a practical case in the healthcare industry is provided to illustrate the feasibility and strengths of the proposed OHSRA model. The results show that the proposed OHSRA model can generate more credible risk classifications of occupational hazards and offer a flexible way for analyzing the risk of occupational hazards.},
  archive      = {J_ASOC},
  author       = {Ran Liu and Hu-Chen Liu and Qi-Zhen Zhang and Hua Shi},
  doi          = {10.1016/j.asoc.2025.112991},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112991},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A three-way decision-based model for occupational risk assessment and classification in the healthcare industry},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive encoding and comprehensive attention decoding
network for medical image segmentation. <em>ASOC</em>, <em>174</em>,
112990. (<a href="https://doi.org/10.1016/j.asoc.2025.112990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image segmentation involves partitioning different tissues or lesion areas within medical images. Achieving automatic segmentation can markedly improve efficiency and accuracy, which is significant for biomedical clinical diagnosis. With the rapid development of deep convolutional neural networks (DCNN), U-Net has been widely used in medical image segmentation due to its encoder-decoder structure and skip connection. However, it is still hard for U-Net to handle certain challenging cases. In this study, we propose an adaptive encoding and comprehensive attention decoding network (AA-Net), which is derived from U-Net to address the issues of the semantic gap as well as the loss of spatial information during convolutions. AA-Net takes into account the different characteristics of the encoder and decoder. In the encoder, we design a simple Adaptive Calibration Module (ACM) to improve the representation ability of candidate features. In the decoder, we introduce a Comprehensive Attention Feature Extraction (CAFE) module, which employs multiple attention mechanisms after feature fusion to alleviate the semantic gap. Benefiting from CAFE, AA-Net can better handle the challenging cases where the segmentation targets vary in position, size, and scale. Additionally, we suggest a weighted hybrid loss function for precise boundary segmentation. We validate the effectiveness of AA-Net and each component on three biomedical image datasets. The results demonstrate that our method outperforms state-of-the-art methods in different medical segmentation tasks, proving it is lightweight, efficient, and general.},
  archive      = {J_ASOC},
  author       = {Xin Shu and Aoping Zhang and Zhaoyang Xu and Feng Zhu and Wei Hua},
  doi          = {10.1016/j.asoc.2025.112990},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112990},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Adaptive encoding and comprehensive attention decoding network for medical image segmentation},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A nondominated sorting simplified swarm optimization with
local search mechanisms for multi-objective vehicle routing problems
with time windows. <em>ASOC</em>, <em>174</em>, 112989. (<a
href="https://doi.org/10.1016/j.asoc.2025.112989">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In addressing the complexities of modern logistics, this study introduces a novel multi-objective formulation for vehicle routing problems with time windows (MO-VRPTW), targeting minimizing travel distance, enhancing customer satisfaction, and equalizing driver workloads. We introduce an innovative hybrid multi-objective evolutionary algorithm (MOEA) leveraging nondominated sorting simplified swarm optimization to effectively merge the advantages of various optimization strategies. A key aspect of this advancement is the incorporation of the Lin−Kernighan − Helsgaun (LKH) heuristic, which delivers a superior initial solution, thereby markedly enhancing the speed of convergence. Additionally, we pioneered a local search method inspired by the A* algorithm designed to refine the search process&#39;s exploration and exploitation stages. Solomon&#39;s benchmark instances, a recognized standard in the VRPTW field, were used to validate our algorithm&#39;s effectiveness. Our algorithm demonstrated superior performance in addressing MO-VRPTW through meticulous statistical analysis, outperforming state-of-the-art algorithms, such as MOPSO, NSGA-II, MOEA/D, and SPEA2, regarding efficiency and solution diversity. This study not only advances algorithmic performance but also thoughtfully considers the interests of key supply chain stakeholders.},
  archive      = {J_ASOC},
  author       = {Chyh-Ming Lai and Chun-Chih Chiu and Tzu-Li Chen},
  doi          = {10.1016/j.asoc.2025.112989},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112989},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A nondominated sorting simplified swarm optimization with local search mechanisms for multi-objective vehicle routing problems with time windows},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cluster-based prepositioning network for enhanced recovery
resilience of critical infrastructure system using multiplex network.
<em>ASOC</em>, <em>174</em>, 112987. (<a
href="https://doi.org/10.1016/j.asoc.2025.112987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient restoration of critical infrastructures for high-impact-low-frequency events heavily relies on pre-disaster restoration resource prepositioning and post-disaster assignment. To find proper locations of restoration resource depots and optimal assignment schemes, a multiplex network approach is proposed to simultaneously model the critical infrastructure network and restoration resource prepositioning network as a coupled multi-layered network. The proposed approach consists of load-weighted critical infrastructure network modeling, cluster-based restoration resource prepositioning network modeling and recovery resilience optimization of a multiplex network from the two networks. Tested on the Hangzhou metro network located in China, experimental results show that resilience loss optimized based on the proposed cluster-based multiplex network is lower than that based on four centrality-guaranteed competitors for all attack scenarios and significantly lower under random severe attacks representing the most severe scenarios. Link flow fluctuations and higher-order of resilience metrics are discussed to provide an insightful suggestion on the design and intervention decisions of infrastructure restoration.},
  archive      = {J_ASOC},
  author       = {Ying Wang and Ou Zhao and Limao Zhang},
  doi          = {10.1016/j.asoc.2025.112987},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112987},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Cluster-based prepositioning network for enhanced recovery resilience of critical infrastructure system using multiplex network},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-agent reinforcement learning system framework based on
topological networks in fourier space. <em>ASOC</em>, <em>174</em>,
112986. (<a href="https://doi.org/10.1016/j.asoc.2025.112986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, multi-agent reinforcement learning (MARL) has been applied to various domains such as communications, network management, power systems, and autonomous driving, showcasing broad application scenarios and significant research potential. However, in complex decision-making environments, agents that rely solely on temporal value functions often struggle to capture and extract hidden features and dependencies within long sequences in multi-agent settings. Each agent’s decisions are influenced by a sequence of prior states and actions, leading to complex spatiotemporal dependencies that are challenging to analyze directly in the time domain. Addressing these challenges requires a paradigm shift to analyze such dependencies from a novel perspective. To this end, we propose a Multi-Agent Reinforcement Learning system framework based on Fourier Topological Space from the foundational level. This method involves transforming each agent’s value function into the frequency domain for analysis. Additionally, we design a lightweight weight calculation method based on historical topological relationships in the Fourier topological space. This addresses issues of instability and poor reproducibility in attention weights, along with various other interpretability challenges. The effectiveness of this method is validated through experiments in complex environments such as the StarCraft Multi-Agent Challenge (SMAC) and Google Football. Furthermore, in the Non-monotonic Matrix Game, our method successfully overcame the limitations of non-monotonicity, further proving its wide applicability and superiority. On the application level, the proposed algorithm is also applicable to various multi-agent system domains, such as robotics and factory robotic arm control. The algorithm can control each joint in a coordinated manner to accomplish tasks such as enabling a robot to stand upright or controlling the movements of robotic arms.},
  archive      = {J_ASOC},
  author       = {Licheng Sun and Ao Ding and Hongbin Ma},
  doi          = {10.1016/j.asoc.2025.112986},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112986},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-agent reinforcement learning system framework based on topological networks in fourier space},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic light optimization in vertical farming using an
IoT-driven digital twin framework and artificial intelligence.
<em>ASOC</em>, <em>174</em>, 112985. (<a
href="https://doi.org/10.1016/j.asoc.2025.112985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The global agricultural sector faces mounting challenges from climate change, population growth, urbanization, and environmental degradation, necessitating innovative solutions to ensure food security. Urban and peri-urban agriculture, particularly vertical farming, offers a sustainable approach to increase food production while minimizing land use, reducing environmental impact, and enhancing resource efficiency. Unlike conventional vertical farming systems that rely on static spectral recipes with fixed light compositions (e.g., Red-to-Blue ratios derived from historical data), this study introduces an Internet of Things-enabled smart vertical farming system that leverages digital twin technology and a genetic algorithm (GA) to dynamically optimize lettuce growth by adjusting RGB LED spectra throughout the crop cycle. The system monitors and controls key environmental parameters within a growth tower, including temperature, humidity, and lighting. A digital twin facilitates real-time data exchange between physical and virtual components, while the GA iteratively refines the light composition. Over a 34-day cultivation period, the algorithm identified an optimal RGB configuration (R:211, G:169, B:243; maximum intensity: 255) that aligns with spectral values reported in literature for lettuce, despite not directly measuring photobiological metrics such as Photosynthetic Photon Flux Density. To our knowledge, this is the first study to implement a dynamic, GA-driven spectral optimization strategy in vertical farming. While the objective was not to surpass traditional static lighting recipes, the results validate that adaptive methods can reliably converge to established optima. The IoT platform demonstrated robust capabilities in data collection, processing, and actuation, underscoring the promise of adaptive lighting strategies for controlled agriculture. Future research will focus on incorporating additional spectra (e.g., deep red, ultraviolet), automating data collection via image recognition, and analyzing energy efficiency to enhance scalability.},
  archive      = {J_ASOC},
  author       = {Rafael Gomes Alves and Fábio Lima and Ítalo Moraes Rocha Guedes and Salvador Pinillos Gimenez},
  doi          = {10.1016/j.asoc.2025.112985},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112985},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dynamic light optimization in vertical farming using an IoT-driven digital twin framework and artificial intelligence},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neural priority model for agile earth observation
satellite scheduling using deep reinforcement learning. <em>ASOC</em>,
<em>174</em>, 112984. (<a
href="https://doi.org/10.1016/j.asoc.2025.112984">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The agile earth observation satellite scheduling problem (AEOSSP) is a time-dependent and complex combinatorial optimization challenge that has spurred extensive research for decades. Traditional methods have primarily relied on iterative searching processes to approximate near-optimal solutions, but their efficiency remains limited. To address this issue, we propose a Priority Construction Model (PCM) based on deep reinforcement learning (DRL), forming a learning-based, two-stage construction heuristic. The PCM integrates a Priority Construction Neural Network (PCNN) alongside a Backward-Slacken and Top-Insert (BS-TI) scheduling algorithm. In PCM, the PCNN sequences observation requests, while the BS-TI schedules each sequenced request in accordance with specific constraints, thus freeing the neural policy from the burden of complex constraint checking. Experimental results indicate that following a policy-gradient-based DRL training process, PCM outperforms the state-of-the-art AEOSSP iterative algorithm, achieving better average profits within an exceptionally short construction time in most scenarios. The model study further reveals that PCNN outperforms other DRL policies in terms of priority policy representation, while the PCM exhibits superior generalization capabilities across varying scales and distributions. Therefore, our proposed model presents a valuable reference solution that not only meets the large-scale and rapid response requirements of the AEOSSP but also holds potential for application in upcoming large constellations and emerging management paradigms. More importantly, we introduce a novel framework that separates the DRL optimization process from constraint management, lowering the entry barrier for applying DRL to complex problems. This makes the model adaptable to various optimization challenges in engineering and operations research, thus extending its applicability beyond the AEOSSP domain.},
  archive      = {J_ASOC},
  author       = {Ming Chen and Luona Wei and Jie Chun and Lei He and Shang Xiang and Lining Xing and Yingwu Chen},
  doi          = {10.1016/j.asoc.2025.112984},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112984},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A neural priority model for agile earth observation satellite scheduling using deep reinforcement learning},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transferable adversarial attacks against face recognition
using surrogate model fine-tuning. <em>ASOC</em>, <em>174</em>, 112983.
(<a href="https://doi.org/10.1016/j.asoc.2025.112983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Networks have significantly advanced Face Recognition performance yet remain susceptible to adversarial attacks, posing significant security and user privacy threats in real-world applications. In recent years, black box attacks have attracted wide attention to craft highly transferable adversarial examples by training surrogate models. However, most of these methods primarily depend on stealing knowledge by accessing the soft label from the target model using either synthetic training data or data free without awareness of the knowledge type, which can affect the improvement of transferability between the surrogate and the target models. Additionally, these attacks still need to improve the surrogate model’s accuracy without using many queries. To this end, we propose Tune2Transfer, a novel attack method that enhances adversarial transferability by fine-tuning the surrogate model with different types of knowledge with limited queries on the target model by the hard label only. Specifically, it collects a small face image dataset, considering the adversary’s limited knowledge. To overcome the challenge of knowledge type, Tune2Transfer imposes three sampling assumptions: clean images only, the perturbed images, or combining both, generating images on the surrogate model, and then feeding them to the target model to obtain the hard label. The perturbed images are generated by perturbing them using the Covariance Matrix Adaptation Evolution Strategy or Momentum Iteration Fast Gradient Sign Method. Besides, we leverage pre-trained models to fine-tune surrogate models to avoid large queries. In this way, we could leverage knowledge transferred from the target model, resulting in superior transferability. Extensive experiments conducted on two typical datasets demonstrate the efficacy of Tune2Transfer, increasing the attack success rates significantly.},
  archive      = {J_ASOC},
  author       = {Yasmeen M. Khedr and Xin Liu and Haobo Lu and Kun He},
  doi          = {10.1016/j.asoc.2025.112983},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112983},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Transferable adversarial attacks against face recognition using surrogate model fine-tuning},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A semi-supervised non-negative matrix factorization model
for scRNA-seq data analysis. <em>ASOC</em>, <em>174</em>, 112982. (<a
href="https://doi.org/10.1016/j.asoc.2025.112982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-cell RNA sequencing (scRNA-seq) technology enables the measurement of cellular gene expression at the single-cell level, thus facilitating cell clustering at the gene level. Despite numerous dimensionality reduction methods developed for scRNA-seq data, many are limited to analyzing individual gene expression matrices and struggle to address false positives and false zero expression entries effectively. Moreover, existing methods often underutilize prior knowledge of similarity and dissimilarity between multi-omics data, leading to the loss of intercellular correlations and shared structural information, thus hindering desired dimensionality reduction outcomes. To address these limitations, a novel model termed joint non-negative matrix factorization with similarity and dissimilarity constraints (SDJNMF) was proposed to tailor for scRNA-seq data clustering. The model leverages prior knowledge of similarity and dissimilarity across multiple gene expression matrices, facilitating joint non-negative matrix factorization to extract common features from multi-omics data. By preserving shared structural and cellular relevance information, SDJNMF enhances the clustering of similar cells while effectively separating dissimilar ones. Furthermore, the SDJNMF model incorporates sparse Singular Value Decomposition during initialization to mitigate noise and redundancy and ensure robust dimensionality reduction. The experimental results demonstrate that the SDJNMF model exhibits superior performance on the 10 datasets, not only outperforming the other 14 algorithms in terms of clustering accuracy on the 9 datasets, but also enhancing the A R I of SDJNMF by an average of 0.0687 in comparison to the second-best algorithm on each dataset. In the visual representation, the model is able to efficiently and accurately cluster similar cells and effectively discriminate different classes of cells from each other. Additionally, the SDJNMF model was applied to identify informative genes and conduct enrichment analysis, validating that genes identified by SDJNMF significantly influence biological processes. Overall, the SDJNMF offers innovative tools for cell cluster identification and advances biological research. The source code of SDJNMF is available online at https://github.com/Jindsmu/SDJNMF .},
  archive      = {J_ASOC},
  author       = {Junjie Lan and Xiaoling Zhuo and Siman Ye and Jin Deng},
  doi          = {10.1016/j.asoc.2025.112982},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112982},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A semi-supervised non-negative matrix factorization model for scRNA-seq data analysis},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AdvGrid: A multi-view black-box attack on infrared
pedestrian detectors in the physical world. <em>ASOC</em>, <em>174</em>,
112981. (<a href="https://doi.org/10.1016/j.asoc.2025.112981">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physical adversarial attacks in the visible spectrum have been extensively studied, but research on infrared attacks remains limited. Infrared pedestrian detectors are crucial for modern applications yet vulnerable to adversarial attacks, posing significant security risks. Existing methods using physical perturbations like light bulb arrays or hot/cold patches for black-box attacks have shown limitations in practicality and multi-view support. To address these challenges, we introduce Adversarial Infrared Grid (AdvGrid), a novel approach that models perturbations in a grid format and employs a genetic algorithm for black-box optimization. AdvGrid cyclically applies perturbations to various parts of a pedestrian’s clothing, enabling effective multi-view black-box attacks on infrared detectors. Our extensive experiments demonstrate AdvGrid’s superior performance: Effectiveness: Achieves 80.00% attack success rate in digital environments and 91.86% in physical environments. Stealthiness: Maintains high stealthiness, making it difficult for observers to identify the adversarial patterns. Robustness: Exceeds 50% average attack success rate against mainstream detectors, showcasing its robustness across different scenarios. We also conduct ablation studies, transfer attacks, and adversarial defense evaluations, further confirming AdvGrid’s superiority over baseline methods. Our findings highlight AdvGrid as a powerful tool for advancing the understanding and mitigation of adversarial threats in infrared detection systems.},
  archive      = {J_ASOC},
  author       = {Kalibinuer Tiliwalidi and Chengyin Hu and Guangxi Lu and Ming Jia and Weiwen Shi},
  doi          = {10.1016/j.asoc.2025.112981},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112981},
  shortjournal = {Appl. Soft. Comput.},
  title        = {AdvGrid: A multi-view black-box attack on infrared pedestrian detectors in the physical world},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Series clustering and dynamic periodic patching-based
transformer for multivariate time series forecasting. <em>ASOC</em>,
<em>174</em>, 112980. (<a
href="https://doi.org/10.1016/j.asoc.2025.112980">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series forecasting (MTSF) is widely employed in research-intensive domains, such as weather forecasting. Recently, Transformer-based models have outstanding ability to achieve SOTA performance, benefiting from its self-attention mechanism. However, existing models fall short in capturing multivariate inter-dependencies and local semantic representations. To tackle the above limitations, we propose a series clustering and dynamic periodic patching-based Transformer model named CMDPPformer, with two distinctive characteristics: (1) A channel-mixing module based on series clustering is proposed which can strengthen the association between variables with high sequence similarity, and weaken the effect of uncorrelated variables. Concretely, we use whole-time series clustering to group multivariate time series into clusters. After that, variables in the same cluster share the same Transformer backbone while variables in different clusters do not affect each other. (2) A dynamic periodic patching module is introduced which can better capture semantic information and improve Transformer’s local semantic representation. Concretely, multivariate time series after clustering are dynamically segmented into periodic patches as Transformer’s input token. Experimental results show that CMDPPformer can achieve an overall 13.76% and 10.16% relative improvements than SOTA Transformer-based models on seven benchmarks, covering four real-world applications: energy, weather, illness and economic.},
  archive      = {J_ASOC},
  author       = {Yijie Wang and Xiao Wu and Jiaying Zhang and Weiping Wang and Linjiang Zheng and Jiaxing Shang},
  doi          = {10.1016/j.asoc.2025.112980},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112980},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Series clustering and dynamic periodic patching-based transformer for multivariate time series forecasting},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic trend fusion module for traffic flow prediction.
<em>ASOC</em>, <em>174</em>, 112979. (<a
href="https://doi.org/10.1016/j.asoc.2025.112979">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic flow prediction is essential for applications like transport logistics but remains challenging due to complex spatio-temporal correlations and non-linear traffic patterns. Existing methods often model spatial and temporal dependencies separately, failing to effectively fuse them. To overcome this limitation, the D ynamic S patial- T emporal T rend Trans former ( DST 2 former ) is proposed to capture spatio-temporal correlations through adaptive embedding and to fuse dynamic and static information for learning multi-view dynamic features of traffic networks. The approach employs the D ynamic T rend R epresentation Trans former ( DTRformer ) to generate dynamic trends using encoders for both temporal and spatial dimensions, fused via Cross Spatial-Temporal Attention. Predefined graphs are compressed into a representation graph to extract static attributes and reduce redundancy. Experiments on four real-world traffic datasets demonstrate that our framework achieves state-of-the-art performance.},
  archive      = {J_ASOC},
  author       = {Jing Chen and Haocheng Ye and Zhian Ying and Yuntao Sun and Wenqiang Xu},
  doi          = {10.1016/j.asoc.2025.112979},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112979},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dynamic trend fusion module for traffic flow prediction},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Developing a forecasting model for time series based on
clustering and deep learning algorithms. <em>ASOC</em>, <em>174</em>,
112977. (<a href="https://doi.org/10.1016/j.asoc.2025.112977">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a new forecasting model for time series based on the improvement and combination of the cluster analysis (CA) algorithm and deep learning with Convolutional Neural Network (CNN) and Bi-Long Short Term Memory (BiLSTM) model. The proposed model is considered pioneering in this research direction with significant contributions to three main phases. For the first phase, the original series is converted into the percentage change series and is divided into clusters of an appropriate number using the CA algorithm. The next phase involves extracting the features of the new series based on the CNN with suitable parameters and input data enhancement from the results of the first phase. In the final phase, the BiLSTM model is applied to the series established from the second phase, and the forecasting principle for the future is established. The proposed model is detailed in the implementation steps, proving convergence, illustrated by numerical examples, and can be applied to real series using a Matlab procedure. The effectiveness of the proposed model is quite impressive as it surpasses many strong forecasting models on reputable benchmark datasets , including the M3-Competition dataset with 3,003 series, and M4-Competition dataset with 100,000 series.},
  archive      = {J_ASOC},
  author       = {Luan Nguyen-Huynh and Tai Vo-Van},
  doi          = {10.1016/j.asoc.2025.112977},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112977},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Developing a forecasting model for time series based on clustering and deep learning algorithms},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluation of international market entry strategies for
mineral oil companies using a neutrosophic SWARA-CRADIS methodology.
<em>ASOC</em>, <em>174</em>, 112976. (<a
href="https://doi.org/10.1016/j.asoc.2025.112976">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Businesses encounter risks when entering new countries, but there are also opportunities. The strategy a business employs when opting to enter a new market is directly tied to its success. In this regard, the study provides an approach for evaluating new market entry strategies for businesses facilitating in the mineral oil sector and manufacturing industries. The approach includes the development of the type 2 neutrosophic step-wise weight assessment ratio analysis (SWARA)-compromise ranking of alternatives from distance to ideal solution (CRADIS) methodology, which aims to solve the problem by determining the candidate strategies and the criteria to be utilized in their evaluation. The findings revealed that market conditions are the most crucial criterion in selecting strategies for mineral oil companies intending to enter new markets. The magnitude and development potential of the new market to be entered, as well as the status of the actors, all have an impact on market conditions, which are critical for businesses. Moreover, foreign direct investment is found to be the best market entry strategy. This strategy arises because businesses aim to maximize the potential in the market they have recently entered, as well as other factors such as government incentives. The study is expected to benefit production enterprises, the mineral oil sector, the marketing field, and the literature by identifying criteria and option sets, finding the importance degrees of the criteria, selecting the ideal entry strategy, and proposing a methodology for handling uncertain data.},
  archive      = {J_ASOC},
  author       = {Ahmet Aytekin and Hilal Öztürk Küçük and Makbule Aytekin and Vladimir Simic and Dragan Pamucar},
  doi          = {10.1016/j.asoc.2025.112976},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112976},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Evaluation of international market entry strategies for mineral oil companies using a neutrosophic SWARA-CRADIS methodology},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic environment adaptive online learning with fairness
awareness via dual disentanglement. <em>ASOC</em>, <em>174</em>, 112975.
(<a href="https://doi.org/10.1016/j.asoc.2025.112975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread application of Artificial Intelligence (AI) comes with the necessity to consider and mitigate discrimination in machine learning algorithms. Most existing fair machine learning methods are only suitable for short-term and static scenarios, and thus cannot adapt to dynamically changing environments or meet the needs for real-time updates. In open dynamic scenarios, data arriving in batches needs processing in real-time, and the constantly changing environment will lead to data distribution shifts, making it difficult to ensure the fairness of models in the long run. To achieve long-term fairness of models, we propose an online dual disentanglement method that captures fair representations of non-sensitive core information in real-time within constantly changing environments, thereby enhancing the robustness of fair models. Firstly, learned representations are disentangled from environment-specific variation factors through a constrained optimization setup to ensure semantic invariance. Further, a bias disentanglement method based on supervised contrastive learning is designed. While keeping the non-sensitive core information unchanged, the sensitive information is hidden from semantic representations and the spurious correlation with target labels is cut off, so as to achieve the long-term fairness of the model decision. By formulating the fairness-aware online learning problem in dynamic environments as an online optimization problem with the long-term fairness constraint, and theoretically proving that the algorithm achieves sublinear dynamic regret and sublinear violation of cumulative unfairness under certain assumptions. Experimental evaluations on real-world datasets demonstrate the effectiveness of the proposed method, which maintains overall fairness above 80% without compromising utility, outperforming state-of-the-art baseline methods.},
  archive      = {J_ASOC},
  author       = {Qiuling Chen and Ayong Ye and Chuan Huang and Fengyu Wu},
  doi          = {10.1016/j.asoc.2025.112975},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112975},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dynamic environment adaptive online learning with fairness awareness via dual disentanglement},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring coordinated motion patterns of facial landmarks
for deepfake video detection. <em>ASOC</em>, <em>174</em>, 112974. (<a
href="https://doi.org/10.1016/j.asoc.2025.112974">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the rich geometric and motion information they contain, recent studies indicate that facial landmark clues have significant potential for deepfake video detection. In this paper, we make a key observation that there exist coordinated motions among different facial landmarks for real individuals. While the forgery methods focus more on appearance realism, thus likely to disrupt the underlying coordinated motion patterns. Inspired by this observation, this paper explores how to leverage coordinated motion patterns among facial landmarks to enhance deepfake detection. First, we introduce a coordinated motion landmarks mining strategy (CMLMS), to effectively identify correlated landmarks. Utilizing these correlations, we propose a landmark temporal dynamic relation module (LTDRM), which focuses on the coordinated motion patterns between landmarks while extracting their spatiotemporal features. Specifically, LTDRM constructs an adjacency matrix based on the correlated landmarks and uses graph convolution to selectively aggregate information between correlated landmarks. Additionally, LTDRM is a plug-and-play module and can boost the performance of existing deepfake detection methods with minimal computational overhead. Experimental results validate the effectiveness and generalizability of our method.},
  archive      = {J_ASOC},
  author       = {Yue Zhang and Run Niu and Xianlin Zhang and Siqi Chen and Mingdao Wang and Xueming Li},
  doi          = {10.1016/j.asoc.2025.112974},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112974},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Exploring coordinated motion patterns of facial landmarks for deepfake video detection},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generative fuzzer-driven vulnerability detection in the
internet of things networks. <em>ASOC</em>, <em>174</em>, 112973. (<a
href="https://doi.org/10.1016/j.asoc.2025.112973">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) paradigm has displayed tremendous growth in recent years, driving innovations such as Industry 4.0 and the creation of smart environments that enhance efficiency and asset management and enable intelligent decision-making. However, these benefits come with considerable cybersecurity risks due to inherent vulnerabilities within IoT ecosystems. Introducing potentially vulnerable IoT devices into secure environments, like smart airports, introduces new attack surfaces and vectors for exploitation. Identifying such vulnerabilities is challenging, and while traditional methods like penetration testing and vulnerability identification offer solutions, they often fall short due to IoT’s unique data diversity, hardware constraints, and complexity. We propose an intelligent mutation-based fuzzer for IoT vulnerability detection in networks to address these limitations, demonstrated through a smart airport case study. This method leverages Generative Adversarial Network (GAN)-based mutation, utilizing legitimate network communications (i.e., payloads) to produce fuzzed payloads that expose vulnerabilities. Additionally, we incorporate a large language model (LLM)-based risk assessment framework to evaluate the likelihood and impact of identified vulnerabilities, which is crucial for effectively prioritizing threats in interconnected IoT environments. This dual approach of vulnerability detection and LLM-driven risk assessment provides comprehensive insights into IoT security, enabling prioritized response actions. Experiments conducted in the UNSW Canberra IoT testbed confirm that our approach outperforms conventional vulnerability identification methods, offering a scalable solution for effective vulnerability detection and risk prioritization in complex IoT networks.},
  archive      = {J_ASOC},
  author       = {Mohammed Tanvir Masud and Nickolaos Koroniotis and Marwa Keshk and Benjamin Turnbull and Shabnam Kasra Kermanshahi and Nour Moustafa},
  doi          = {10.1016/j.asoc.2025.112973},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112973},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Generative fuzzer-driven vulnerability detection in the internet of things networks},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Target temperature field prediction via a thermodynamic
knowledge-based artificial neural network. <em>ASOC</em>, <em>174</em>,
112972. (<a href="https://doi.org/10.1016/j.asoc.2025.112972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of artificial intelligence, representation-supervised neural networks have been widely used in the fast solution of physical field. However, a large number of temperature prediction networks do not take environmental parameters into account, or only use parameters as simple input conditions, which greatly reduces the accuracy of their results. This paper proposes an accurate and low-cost method for adding the conditional parameters to intelligent prediction networks. A novel parameter encoder block is designed based on the heat transfer theory achieving thermodynamic knowledge-based parameter feature extraction. Meanwhile, an improved method for inputting time condition is proposed to characterize the temporal characteristics, which can reduce the requirement of dataset for transient temperature prediction, compared with LSTM. In addition, a thermal loss for temperature images is introduced to accelerate the convergence process in the model. Moreover, a CycleGAN-based temperature prediction network (CBTPN) is constructed for fast temperature prediction of a cube or different tanks. Temperature or infrared images predicted by our network exhibit MAE of less than 2.33 % and SSIM of more than 80.21 %. By embedding physical mechanisms into neural networks, this study this study pioneers a structured approach to refining physical parameters into thermodynamic knowledge-based signals for improved image generation, addressing the accuracy and efficiency limitations of data-driven algorithms caused by their insufficient understanding of parameter mechanisms. Finally, parameter cognitive evaluation proves that our approach can not only recognize the accurate semantics of heat transfer parameters, but also sense the meteorological laws.},
  archive      = {J_ASOC},
  author       = {Jincheng Chen and Feiding Zhu and Yuge Han and Dengfeng Ren},
  doi          = {10.1016/j.asoc.2025.112972},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112972},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Target temperature field prediction via a thermodynamic knowledge-based artificial neural network},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning in produce perception of harvesting robots: A
comprehensive review. <em>ASOC</em>, <em>174</em>, 112971. (<a
href="https://doi.org/10.1016/j.asoc.2025.112971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the global demand for produce has surged, alongside labor shortages, driving the development of agricultural automation, particularly in harvesting robots. Deep learning-based computer vision algorithms have become key to produce perception, demonstrating significant potential. We systematically review the current application of deep learning in produce perception for harvesting robots, providing an in-depth analysis of existing public datasets, with a focus on 2D produce recognition and 3D produce localization. Furthermore, we review and analyze the existing algorithms, highlighting their limitations and challenges. In addition, we explore future research directions of deep learning in produce perception, aiming to promote the continued advancement and innovation of technologies in this area.},
  archive      = {J_ASOC},
  author       = {Yuhao Jin and Xiaoyu Xia and Qizhong Gao and Yong Yue and Eng Gee Lim and Prudence Wong and Weiping Ding and Xiaohui Zhu},
  doi          = {10.1016/j.asoc.2025.112971},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112971},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Deep learning in produce perception of harvesting robots: A comprehensive review},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unmanned aerial vehicle takeoff point search algorithm with
information sharing strategy of random trees for multi-area coverage
task. <em>ASOC</em>, <em>174</em>, 112970. (<a
href="https://doi.org/10.1016/j.asoc.2025.112970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a novel approach to optimize full-coverage search in distributed task areas using a single Unmanned Ground Vehicle (UGV) to deliver an Unmanned Aerial Vehicle (UAV) to the takeoff points of each task area along the shortest possible path. Unlike the traditional Traveling Salesman Problem (TSP), task areas are not fixed nodes, and obstacles must be considered. To address these challenges, a probability-based Rapid-exploration Random Tree ( p -RRT) with an information-sharing strategy is introduced, significantly improving the efficiency of locating takeoff points in complex environments. A dual optimization method further reduces the number of nodes and path length planned by the D* algorithm, achieving up to an 80 % reduction in nodes and improving path efficiency. Additionally, a simulated annealing (SA) algorithm optimizes the connection sequence of takeoff points, reducing total path length by 35.05 % compared to the initial path and 22.66 % compared to the traditional Random Sampling Method (RSM). Experiments confirm that the proposed algorithms can effectively enhance UGV-UAV collaboration with reducing path complexity and improving energy efficiency, and thus streamline multi-area coverage tasks.},
  archive      = {J_ASOC},
  author       = {Shouwen Yao and Xiaoyu Wang and Siqi Huang and Renjie Xu and Yinghua Zhao},
  doi          = {10.1016/j.asoc.2025.112970},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112970},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Unmanned aerial vehicle takeoff point search algorithm with information sharing strategy of random trees for multi-area coverage task},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive heuristic algorithm with a collaborative search
framework for multi-UAV inspection planning. <em>ASOC</em>,
<em>174</em>, 112969. (<a
href="https://doi.org/10.1016/j.asoc.2025.112969">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-UAV inspection path planning has become an important research topic for completing inspection tasks before the data acquisition deadline. In this study, we propose an adaptive heuristic algorithm with a collaborative search framework named Sa-VCO to solve the multi-UAV inspection path planning problem. Our study includes three main novelties. First, we design a region-gridding disperse approach that transforms the primitive target regions into a set of standard target subregions, allowing the target regions with greater costs to be inspected by multiple UAVs. Second, we propose an adaptive initial solution generation strategy using the information of graph structure constructed by all targets to reduce redundant computing. Third, we established a collaborative search framework to enhance search efficiency and increase population diversity. A large number of multiple-perspective comparative experiments are provided to test Sa-VCO&#39;s performance, and the comparison results demonstrate that Sa-VCO achieves better results than other advanced algorithms, especially on large-scale data sets.},
  archive      = {J_ASOC},
  author       = {Chang He and Haibin Ouyang and Weiqing Huang and Steven Li and Chunliang Zhang and Weiping Ding and Zhi-Hui Zhan},
  doi          = {10.1016/j.asoc.2025.112969},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112969},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An adaptive heuristic algorithm with a collaborative search framework for multi-UAV inspection planning},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficiency analysis of binary metaheuristic optimization
algorithms for uncapacitated facility location problems. <em>ASOC</em>,
<em>174</em>, 112968. (<a
href="https://doi.org/10.1016/j.asoc.2025.112968">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces binary adaptations of four metaheuristic optimization algorithms: the Binary Coati Optimization Algorithm (BCOA), Binary Mexican Axolotl Optimization Algorithm (BMAO), Binary Dynamic Hunting Leadership Optimization (BDHL), and Binary Aquila Optimizer (BAO). These algorithms were evaluated for their effectiveness in solving Uncapacitated Facility Location (UFL) problems, which aim to minimize total costs associated with customer-facility allocations and facility opening expenses by determining the optimal number of open facilities. Using 15 UFL problem instances from the OR-Lib dataset, the study assessed algorithm performance across 17 transfer functions (TFs), including S-shaped, V-shaped, and other variants, to address the binary nature of these problems. Performance metrics such as the best, worst, average, standard deviation, and GAP values were analyzed for each binary algorithm. Additionally, statistical analyses were conducted to further assess algorithmic performance. The Kolmogorov-Smirnov (KS) normality test was applied to determine the distribution characteristics of the results, followed by either ANOVA or Kruskal-Wallis tests, depending on the normality of the distributions. These statistical tests revealed significant differences in algorithm performance across different problem instances. Rank values were calculated based on GAP values and CPU times to facilitate comparisons across algorithm versions for the 15 UFL problems. Results underscored the critical role of TF selection in optimizing algorithm efficiency: BCOA performed best with TF11, BMAO with TF16 and TF17, BAO with TF10, and BDHL with TF15. Finally, a performance comparison on GAP values was conducted with two state-of-the-art PSO variants adapted for binary optimization. The proposed algorithms demonstrated either superior or competitive performance in solving UFL problems, validating their efficacy in complex optimization tasks and highlighting the influence of TFs on their performance.},
  archive      = {J_ASOC},
  author       = {Tahir Sag and Aysegul Ihsan},
  doi          = {10.1016/j.asoc.2025.112968},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112968},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Efficiency analysis of binary metaheuristic optimization algorithms for uncapacitated facility location problems},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph convolutional networks with multi-scale dynamics for
traffic speed forecasting. <em>ASOC</em>, <em>174</em>, 112966. (<a
href="https://doi.org/10.1016/j.asoc.2025.112966">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic speed forecasting remains challenging due to complex and variable road conditions. Prior research often overlooks both coarse-grained and fine-grained features in traffic data, hindering a comprehensive capture of traffic data&#39;s temporal dependencies. While graph convolutional networks (GCNs) are commonly employed to extract spatial dependencies in traffic networks, they typically view these networks from a static standpoint, failing to consider the dynamic nature of traffic network structures. This limitation restricts their effectiveness in modeling traffic networks. To address these issues, this study introduces a novel deep learning-based spatial-temporal model for precise traffic speed forecasting. This model incorporates a newly developed multi-scale transformation method, which enhances the coarse-grained and fine-grained features in traffic speed data by transforming and fusing traffic speed data, and enabling a more thorough modeling of its temporal dependencies. Additionally, we propose an innovative graph interaction strategy, combines the generated graphs with a dynamic graph convolutional network, to effectively mine the dynamic characteristics of traffic network structures, thereby enhancing the model&#39;s accuracy. Extensive experiments on two real-world datasets have demonstrated the robustness and superior performance of the proposed model, with improvements ranging from 2.2 % to 6.1 % over state-of-the-art baselines.},
  archive      = {J_ASOC},
  author       = {Dongping Zhang and Hao Lan and Mengting Wang and Jiabin Yu and Xinghao Jiang and Shifeng Zhang},
  doi          = {10.1016/j.asoc.2025.112966},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112966},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Graph convolutional networks with multi-scale dynamics for traffic speed forecasting},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LOSS-GAT: Label propagation and one-class semi-supervised
graph attention network for fake news detection. <em>ASOC</em>,
<em>174</em>, 112965. (<a
href="https://doi.org/10.1016/j.asoc.2025.112965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s world of social networks, fake news spreads quickly and causes serious problems. This has made it crucial to develop automated systems to detect and combat disinformation. Machine learning and deep learning are often used to identify fake news, but they struggle due to the lack of labeled news datasets. To address this, the One-Class Learning (OCL) approach uses a small set of labeled data. On the other hand, representing data as a graph enables access to diverse content and structural information, and label propagation methods on graphs can be effective in predicting node labels. In this paper, we adopt a graph-based model for data representation and introduce a semi-supervised and one-class approach for fake news detection, called LOSS-GAT. Initially, we employ a two-step label propagation algorithm, utilizing Graph Neural Networks (GNNs) as an initial classifier to categorize news into two groups: interest (fake) and non-interest (real). Subsequently, we enhance the graph structure using structural augmentation techniques. Ultimately, we predict the final labels for all unlabeled data using a GNN that induces randomness within the local neighborhood of nodes through the aggregation function. We evaluate our proposed method on six common datasets and compare the results against a set of baseline models, including both OCL and binary labeled models. The results demonstrate that LOSS-GAT achieves a significant improvement in performance, with enhancements ranging from 5% (on the FEVER dataset) to 20% (on the FakeNewsNet dataset) in terms of the Macro-F1 metric, all while utilizing only a limited set of labeled fake news data. Noteworthy, LOSS-GAT even outperforms binary labeled models.},
  archive      = {J_ASOC},
  author       = {Batool Lakzaei and Mostafa Haghir Chehreghani and Alireza Bagheri},
  doi          = {10.1016/j.asoc.2025.112965},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112965},
  shortjournal = {Appl. Soft. Comput.},
  title        = {LOSS-GAT: Label propagation and one-class semi-supervised graph attention network for fake news detection},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Art style classification via self-supervised dual-teacher
knowledge distillation. <em>ASOC</em>, <em>174</em>, 112964. (<a
href="https://doi.org/10.1016/j.asoc.2025.112964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Art style classification plays a crucial role in computational aesthetics. Traditional deep learning-based methods for art style classification typically require a large number of labeled images, which are scarce in the art domain. To address this challenge, we propose a self-supervised learning method specifically tailored for art style classification. Our method effectively learns image style features using unlabeled images. Specifically, we introduce a novel self-supervised learning approach based on the popular contrastive learning framework, incorporating a unique dual-teacher knowledge distillation technique. The two teacher networks provide complementary guidance to the student network. Each teacher network focuses on extracting distinct features, offering diverse perspectives. This collaborative guidance enables the student network to learn detailed and robust representations of art style attributes. Furthermore, recognizing the Gram matrix’s capability to capture image style through feature correlations, we explicitly integrate it into our self-supervised learning framework. We propose a relation alignment loss to train the network, leveraging image relationships. This loss function has shown promising results compared to the commonly used InfoNCE loss. To validate our proposed method, we conducted extensive experiments on three publicly available datasets: WikiArt, Pandora18k, and Flickr. The experimental results demonstrate the superiority of our method, significantly outperforming state-of-the-art self-supervised learning methods. Additionally, when compared with supervised methods, our approach shows competitive results, notably surpassing supervised learning methods on the Flickr dataset. Ablation experiments further verify the efficacy of each component of our proposed network. The code is publicly available at: https://github.com/lm-oc/dual_signal_gram_matrix .},
  archive      = {J_ASOC},
  author       = {Mei Luo and Li Liu and Yue Lu and Ching Y. Suen},
  doi          = {10.1016/j.asoc.2025.112964},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112964},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Art style classification via self-supervised dual-teacher knowledge distillation},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Saccade inspired attentive visual patch transformer for
image sentiment analysis. <em>ASOC</em>, <em>174</em>, 112963. (<a
href="https://doi.org/10.1016/j.asoc.2025.112963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The generation of image-evoked emotion is usually regarded as a transient process in the image sentiment analysis. However, according to the saccade mechanism of the human visual system, the evoked emotion generated during the saccade process changes over time and attention. Based on above analysis, we propose an Attentive Visual Patch Transformer (AVPT), using visual attention sequence to represent the sentiment context of images and predict the possible distribution of sentiment. In AVPT, the spatial structure in the form of patches are reconstructed and reorganized by visual attention shift sequentially. Simultaneously, the temporal characteristics of attention shift are introduced to the relative position encoding, and merged in a self-attention manner to form a spatial–temporal process similarly to the human visual system. Specifically, we propose a sequence attention shift module to simulate the saccade process, which obtains sequence attention and reduces the computational effort by group attentive convolutional gate recurrent unit. Then, a spatial–temporal correlation encoder module is proposed to encode temporal attention with spatial visual features and obtain the sequential visual features of saccade. Finally, a self-attention fusion module is used to extract the correlation hidden in the relative encoding features. Our proposed AVPT achieves excellent performance on visual sentiment distribution prediction and is comparable to state-of-the-art methods, as demonstrated by extensive experiments on the Flickr_LDL and Twitter_LDL datasets.},
  archive      = {J_ASOC},
  author       = {Jing Zhang and Jixiang Zhu and Han Sun and Xinzhou Zhang and Jiangpei Liu},
  doi          = {10.1016/j.asoc.2025.112963},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112963},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Saccade inspired attentive visual patch transformer for image sentiment analysis},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual linear latent space constrained generative adversarial
networks for hyperspectral image classification. <em>ASOC</em>,
<em>174</em>, 112962. (<a
href="https://doi.org/10.1016/j.asoc.2025.112962">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral image classification is a critical challenge in remote sensing due to the high dimensionality of the data and the scarcity of labeled samples. In this study, we propose a novel Dual-Line Latent Space Constrained Generative Adversarial Network (DLC-GAN) that integrates spatial and spectral feature extraction through dual pathways and incorporates latent space constraints to enhance classification robustness. Unlike existing methods, the DLC-GAN employs a bilinear structure to extract complementary information, improving both feature representation and classification accuracy. The model was evaluated on benchmark datasets such as Indian Pines, Pavia University, and Salinas, achieving state-of-the-art performance. Specifically, the DLC-GAN demonstrated improvements in overall accuracy by 5–11 % compared to recent methods and exhibited superior adaptability to limited training data. These findings underscore the potential of DLC-GAN in addressing critical challenges in hyperspectral image classification, with promising applications in environmental monitoring, agricultural management, and urban planning.},
  archive      = {J_ASOC},
  author       = {Kefen Mou and Sha Gao and Muhammet Deveci and Seifedine Kadry},
  doi          = {10.1016/j.asoc.2025.112962},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112962},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dual linear latent space constrained generative adversarial networks for hyperspectral image classification},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inter-block ladder-style transformer model with
multi-subspace feature adjustment for object re-identification.
<em>ASOC</em>, <em>174</em>, 112961. (<a
href="https://doi.org/10.1016/j.asoc.2025.112961">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object re-identification aims to retrieve specific objects across multiple cameras and has garnered significant attention. Currently, transformer-based methods have taken a dominant position. However, most approaches embed inherent transformer encoders for feature extraction directly. These methods handle all patch tokens uniformly, failing to distinguish salient and non-salient patch tokens for discriminative feature expression. To this end, this work proposes a novel inter-block ladder-style transformer (IBLSFormer) for object re-identification. Firstly, a multi-subspace feature adjustment (MSFA) module is designed to adjust the patch features via class-patch interaction in multiple subspaces including Euclidean distance subspace, cosine distance subspace, and KL divergence subspace. The MSFA module can enhance the salient patch tokens and weaken the non-salient patch tokens simultaneously to focus on discriminative patches. Afterwards, an IBLSFormer is designed by inserting MSFA modules with distinct configurations into the vision transformer. The narrow-to-wide ladder-style constraints are embedded in MSFA modules based on embedding depth to highlight the feature differences across different levels and ameliorate the feature learning. Our method achieves mAP/Rank-1 of 88.7%/95.3%, 81.4%/90.4%, 80.0%/97.1%, and 89.4%/83.6% on four object re-identification datasets. Extensive experiments show IBLSFormer is superior to other methods in learning discriminative and robust representations for object re-identification.},
  archive      = {J_ASOC},
  author       = {Zhi Yu and Zhiyong Huang and Mingyang Hou and Jiaming Pei and Daming Sun},
  doi          = {10.1016/j.asoc.2025.112961},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112961},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Inter-block ladder-style transformer model with multi-subspace feature adjustment for object re-identification},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Geometrical invariant generative invisible hyperlinks based
on feature points. <em>ASOC</em>, <em>174</em>, 112959. (<a
href="https://doi.org/10.1016/j.asoc.2025.112959">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To enhance the visual diversity of Quick Response (QR) codes while ensuring their robust decoding capabilities, this paper introduces an innovative invisible hyperlink generation system. The system can use a message sequence to directly generate a hyperlink image. By harnessing the latent space of a suggested feature point generation network, the system extends the robustness of image feature points to the hyperlink images it generates. Specially, an image generation network is first designed to synthesize high-quality images based on feature point data. Subsequently, a set of lightweight message encoder and decoder are introduced to embed message bits into the latent space of the image generation network. Experimental results show that the proposed invisible hyperlink generation system can successfully generate images containing hyperlinks, exhibiting remarkable resilience against common signal processing and geometric distortions. It harbors diverse potential applications, encompassing website URLs, contact information, product specifics, and numerous other use cases.},
  archive      = {J_ASOC},
  author       = {Zecheng Peng and Bingwen Feng and Xiaotao Xu and Jilian Zhang and Donghong Cai and Wei Lu},
  doi          = {10.1016/j.asoc.2025.112959},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112959},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Geometrical invariant generative invisible hyperlinks based on feature points},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sentiment analysis and emotion recognition in social media:
A comprehensive survey. <em>ASOC</em>, <em>174</em>, 112958. (<a
href="https://doi.org/10.1016/j.asoc.2025.112958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment Analysis (SA) and emotion recognition is the fundamental dialogue system that recently gained more attention. It is applied in many scenarios like mining the opinions of the speaker’s conversation and enhancing the feedback of the robot agent. Furthermore, the live conversation is used to generate the talks through certain sentiments to enhance the human-machine interaction. This survey focuses the researchers on handling the SA and classification of various sentences in social media by reviewing various approaches. This analysis explains the 50 research articles from different methods used for SA and sentiment classification in social media. Finally, the evaluation of this survey is performed based on the publication year, various approaches, evaluation metrics, and tools. Moreover, the collected 50 research papers are categorized into different techniques, such as deep learning (DL) based methods, machine learning (ML) based methods, lexicon-based methods, hybrid-based methods, and dependency-based methods. Therefore, from this survey, it is clearly shown that the DL-based method is the most utilized approach in many research papers. Similarly, python is the most used tool for SA and classification, and real-time dataset is a commonly used dataset for SA and classification. Likewise, accuracy is repeatedly employed in metrics with the highest value.},
  archive      = {J_ASOC},
  author       = {Mrunmayee Bachate and Suchitra S},
  doi          = {10.1016/j.asoc.2025.112958},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112958},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Sentiment analysis and emotion recognition in social media: A comprehensive survey},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Short-term forecasting for port throughput time series based
on multi-modal fuzzy information granule. <em>ASOC</em>, <em>174</em>,
112957. (<a href="https://doi.org/10.1016/j.asoc.2025.112957">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Port throughput forecasting is a crucial task that enables port managers to efficiently plan operations, optimize resource utilization, and manage risks. Simultaneously, accurate throughput predictions can prevent port congestion, reduce logistics delays, and enhance cargo handling efficiency, thereby improving port operational efficiency and customer satisfaction. While the existing models often show poor prediction accuracy, because they fail to capture data information comprehensive and produce the iterative errors in short-term forecasting. To address these challenges, a novel short-term time series prediction model is designed, fuzzy information granule (FIG) based model. Different from the existing models, our model incorporates an algorithm based on l 1 -trend filtering to dissect port throughput data into linear trend series and random series, effectively revealing the multi-modal information within data--linear modality and non-linear modality. These multiple modalities allow for a better understanding of throughput changes. Following such multi-modal characteristics, the multi-modal FIG, comprising Gaussian polynomial FIG and Gaussian FIG, is constructed, where the former reflects data linear modality and the latter reflects non-linear modality. Through meticulous data information mining and description, the innovative model achieves short-term forecasting at the granular level, reducing the cumulative errors in iteration. The novel designed FIG based model demonstrates superior accuracy and reliability compared to other 10 models across four metrics, mean absolute error, root mean squared error, mean absolute percentage error, and Wilcoxon signed rank test, which are tested on the data from ports including Ningbo, New York, Shanghai, Singapore, Qingdao, and Malaysia. The application of our model in short-term port throughput forecasting holds significant potential impact in both port operations management and computer science domains.},
  archive      = {J_ASOC},
  author       = {Fang Li and Wen Tong and Xiyang Yang},
  doi          = {10.1016/j.asoc.2025.112957},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112957},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Short-term forecasting for port throughput time series based on multi-modal fuzzy information granule},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiplex network influence maximization based on
representation learning method. <em>ASOC</em>, <em>174</em>, 112956. (<a
href="https://doi.org/10.1016/j.asoc.2025.112956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influence maximization based on representation learning has garnered significant attention in recent years, with numerous studies focusing on monolayer networks. However, given the inherent complexity and multiplicity of social networks, addressing the Multiplex network Influence Maximization (MIM) problem is more practical. The MIM problem aims to find a set of seed nodes to maximize the spread of influence throughout the multiplex network. To tackle this issue, this paper introduces a reverse random walk centrality method based on multiplex network representation learning. This method leverages multiplex network representation learning to derive node embeddings across different layers of the network. By calculating similarity weights between nodes within each layer, a reverse random walk is performed to quantify node importance based on the frequency of visits. The top-k nodes with the highest visit counts are then selected as seed nodes. Both single influence propagation and a coupled spread model that integrates competitive and cooperative influence dynamics are considered. Extensive experiments on several real-world datasets demonstrate that the proposed method outperforms existing techniques in terms of effectiveness, providing robust seed node selection for influence maximization. These findings highlight the efficiency and applicability of the proposed method for practical multiplex network scenarios.},
  archive      = {J_ASOC},
  author       = {Hegui Zhang and Dapeng Zhang and Yun Wan and Renbin Pan and Gang Kou},
  doi          = {10.1016/j.asoc.2025.112956},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112956},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multiplex network influence maximization based on representation learning method},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal fine-grained reasoning for post quality
evaluation. <em>ASOC</em>, <em>174</em>, 112955. (<a
href="https://doi.org/10.1016/j.asoc.2025.112955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate assessment of post quality frequently necessitates complex relational reasoning skills that emulate human cognitive processes, thereby requiring the modeling of nuanced relationships. However, existing research on post-quality assessment suffers from the following problems: (1) They are often categorization tasks that rely solely on unimodal data, which inadequately captures information in multimodal contexts and fails to differentiate the quality of students’ posts finely. (2) They ignore the noise in the multimodal deep fusion between posts and topics, which may produce misleading information for the model. (3) They do not adequately capture the complex and fine-grained relationships between post and topic, resulting in an inaccurate evaluation, such as relevance and comprehensiveness. Based on the above challenges, the Multimodal Fine-grained Topic-post Relational Reasoning(MFTRR) framework is proposed for modeling fine-grained cues by simulating the human thinking process. It consists of the local–global semantic correlation reasoning module and the multi-level evidential relational reasoning module. Specifically, MFTRR addresses the challenge of unimodal and categorization task limitations by framing post-quality assessment as a ranking task and integrating multimodal data to more effectively distinguish quality differences. To capture the most relevant semantic relationships, the Local–Global Semantic Correlation Reasoning Module enables deep interactions between posts and topics at both local and global scales. It is complemented by a topic-based maximum information fusion mechanism to filter out noise. Furthermore, to model complex and subtle relational reasoning, the Multi-Level Evidential Relational Reasoning Module analyzes topic-post relationships at both macro and micro levels by identifying critical cues and delving into granular relational cues. MFTRR is evaluated using three newly curated multimodal topic-post datasets, in addition to the publicly available Lazada-Home dataset. Experimental results indicate that MFTRR outperforms state-of-the-art baselines, achieving a 9.52% improvement in the NDCG@3 metric compared to the best text-only method on the Art History course dataset.},
  archive      = {J_ASOC},
  author       = {Xiaoxu Guo and Siyan Liang and Yachao Cui and Juxiang Zhou and Lei Wang and Han Cao},
  doi          = {10.1016/j.asoc.2025.112955},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112955},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multimodal fine-grained reasoning for post quality evaluation},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A method based on generative adversarial networks for
disentangling physical and chemical properties of stars in astronomical
spectra. <em>ASOC</em>, <em>174</em>, 112954. (<a
href="https://doi.org/10.1016/j.asoc.2025.112954">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents the design of an autoencoder architecture that uses adversarial training in the context of astrophysical spectral analysis. We aim to develop a middle representation of stellar spectra in which the influence of the most prominent physical properties, such as surface temperature and gravity, is effectively removed. This allows the variance within the representation to primarily reflect the effects of the star’s chemical composition on the spectrum. We apply a scheme of deep learning to unravel in the latent space the desired parameters of the rest of the information contained in the data. This work proposes a version of adversarial training that uses one discriminator per parameter to be disentangled, avoiding the exponential combination that occurs when using a single discriminator. Synthetic astronomical data from the APOGEE and Gaia surveys were used to test the method’s effectiveness. Our approach demonstrates a marked improvement in disentangling, reflected in an improvement in the R 2 score of up to 0.7. Additionally, we introduce an ad-hoc framework, GANDALF, designed to facilitate visualization and adaptation of the methodology to other domains in astronomical spectroscopy.},
  archive      = {J_ASOC},
  author       = {Raúl Santoveña and Carlos Dafonte and Minia Manteiga},
  doi          = {10.1016/j.asoc.2025.112954},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112954},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A method based on generative adversarial networks for disentangling physical and chemical properties of stars in astronomical spectra},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hyperspectral image classification based on ConvGRU and
spectral–spatial joint attention. <em>ASOC</em>, <em>174</em>, 112949.
(<a href="https://doi.org/10.1016/j.asoc.2025.112949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In hyperspectral image classification, methods based on spectral–spatial joint attention mechanisms have demonstrated the ability to effectively enhance feature extraction. However, existing approaches still face limitations: spectral attention mechanisms often lack local–global feature interaction, spatial attention fails to fully exploit multi-scale information, and the joint modeling of spectral and spatial features remains insufficiently explored. To address these issues, this paper proposes a spectral–spatial joint attention network based on Convolutional Gated Recurrent Units (ConvGRU). First, a Local-Global Spectral Attention (LGSA) mechanism is designed, where one-dimensional convolution extracts local spectral features and fully connected layers enable global feature interaction. Second, a Multi-Scale Spatial Attention (MSSA) mechanism is introduced, employing three convolutional branches with different receptive fields to capture spatial features, followed by hierarchical feature fusion via 1 × 1 convolution. Finally, a channel-level feature fusion strategy based on ConvGRU is proposed, leveraging sequence modeling to achieve channel-wise joint enhancement of LGSA and MSSA, thereby enabling deep coupling of spectral and spatial features. Comparative experiments on three public datasets demonstrate that the proposed method outperforms seven state-of-the-art algorithms in terms of classification performance.},
  archive      = {J_ASOC},
  author       = {Ronghua Shang and Jie Yang and Jie Feng and Yangyang Li and Songhua Xu},
  doi          = {10.1016/j.asoc.2025.112949},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112949},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Hyperspectral image classification based on ConvGRU and spectral–spatial joint attention},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptation framework with unified embedding
reconstruction for cross-corpus speech emotion recognition.
<em>ASOC</em>, <em>174</em>, 112948. (<a
href="https://doi.org/10.1016/j.asoc.2025.112948">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is challenging for speech emotion recognition (SER) to maintain robustness under cross-domain scenarios. Unsupervised domain adaptation (UDA) algorithms have been explored to address the domain shift in SER without relying on emotion labels in the target domain. As a promising framework in UDAs, self-supervised learning (SSL)-based domain exploration (SDE) investigates the domain and structural information within the target domain, aligning domain discrepancies while preserving the model’s emotion discrimination capability. However, SSL often inadvertently introduces emotion-irrelevant information, adversely affecting the UDA performance. To resolve this, we introduce a novel UDA framework called unified SDE (U-SDE), where both source and target domains conduct a unified SSL task. In the source domain, U-SDE guides the source SSL to focus on emotion-related information due to supervised emotion classification constraints. Simultaneously, in the target domain, shared network weights enable the target SSL branch to concentrate on intrinsic emotional and domain features. However, simply using existing SSL algorithms to implement this framework might disrupt the training of the supervised SER branch. To overcome this, we propose the embedding reconstruction of masked speech (ERMS) algorithm. In ERMS, the emotion encoder transforms the embedding of the masked speech to match the embedding of its corresponding unmasked speech, thereby capturing the emotion discriminative feature within the sample. Finally, we employ ERMS to realize the proposed U-SDE paradigm, termed unified ERMS (U-ERMS). We conducted systematic cross-domain SER experiments by designing 52 scenarios using seven well-known datasets. Experimental results showed that the proposed U-ERMS achieved state-of-the-art performance in cross-domain SERs.},
  archive      = {J_ASOC},
  author       = {Ruiteng Zhang and Jianguo Wei and Xugang Lu and Yongwei Li and Wenhuan Lu and Lin Zhang and Junhai Xu},
  doi          = {10.1016/j.asoc.2025.112948},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112948},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An adaptation framework with unified embedding reconstruction for cross-corpus speech emotion recognition},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Grey prediction evolution algorithm with a dominator
guidance strategy for solving multi-level image thresholding.
<em>ASOC</em>, <em>174</em>, 112947. (<a
href="https://doi.org/10.1016/j.asoc.2025.112947">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-level thresholding (MLT) stands as a pivotal method for extracting target information from images. Meta-heuristic algorithms provide an efficient way to implement MLT and retains more research space for accuracy optimization of high-dimensional multi-level thresholding (HDMLT) of images than they do for low-dimensional multi-level thresholding (LDMIT). In order to improve the algorithmic accuracy in solving the high-dimensional problems, a grey prediction evolution algorithm with a dominator guidance strategy (GPEdg) is proposed in this paper. GPEdg employs Otsu’s method as its objective function to find the best threshold configuration. The novel operator in the algorithm, i.e., a dominator guidance (dg) strategy, uses a linear combination of three difference vectors to guide the top 50% individuals of populations to learn from the top 20% of them. An efficient balance of search abilities suitable for solving HDMLT problems is expected to be achieved by injecting the local search capability of the dg strategy into GPE’s powerful global search capability. Furthermore, a thresholding morphological profile based method (TMP) leverages the thresholding results generated by GPEdg to train a support vector machine (SVM) for hyperspectral image classification. Numerical experiments are conducted for the newly proposed algorithm and five state-of-the-art algorithms on three image datasets to compare the performance in six metrics, i.e., peak signal-to-noise ratio, structural similarity index, features similarity index, objective function value, stability and time consumption. Overall accuracy and average accuracy are tested on two commonly used hyperspectral image data. The results show that GPEdg exhibits outstanding thresholding performance while TMP enhances the classification accuracy of these images. If this paper is accepted, Matlab_codes associated with this paper will be uploaded to https://github.com/Zhongbo-Hu/Prediction-Evolutionary-Algorithm-HOMEPAGE},
  archive      = {J_ASOC},
  author       = {Peixin Yang and Zhongbo Hu and Yang Zhou and Qinghua Su and Wentao Xiong},
  doi          = {10.1016/j.asoc.2025.112947},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112947},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Grey prediction evolution algorithm with a dominator guidance strategy for solving multi-level image thresholding},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pseudo-deep unsupervised model-based clustering for brain
tumor detection in magnetic resonance images. <em>ASOC</em>,
<em>174</em>, 112940. (<a
href="https://doi.org/10.1016/j.asoc.2025.112940">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel unsupervised pseudo-deep algorithm, Mixtures of Factor Analyzers based on Rows Iterative Clustering with Image Rotation according to Dimension (MFARICIRD), for accurate and automatic detection of brain tumors in grayscale magnetic resonance images. The main goal is to extract the region of interest (ROI) containing tumors using a pseudo-deep framework with iterative clustering. This framework incorporates a layer by layer structure inspired by deep learning, using a mixture of agent analysts to optimize the clustering process. In each computational layer, the algorithm first rotates the image 90 degrees clockwise if the number of rows is greater than the number of columns. Then, it performs clustering on the image using the estimated parameters of optimal clusters and the optimal number of clusters until the tumor-containing cluster is identified. The identified cluster is used as input for the next layer. These computational processes are iterated layer by layer until the proposed convergence criterion, which acts as the stopping rule, is satisfied. The algorithm uses fuzzy c-mean clustering to binarize the output cluster of the final layer (ROI), enabling the exact extraction of the tumor shape. Finally, it localizes the detected tumor within the original image. A comprehensive evaluation of the effectiveness of the proposed algorithm is presented on the BraTS2020, BraTS2019, and BraTS2018 datasets, demonstrating exceptional performance in detecting tumors with different locations, sizes, and complexities. The algorithm achieved an accuracy and Dice similarity coefficient of 99.96 + 0.0073 % and 98.97 % on the BraTS2018, 99.97 + 0.0087 % and 99.22 + 0.0051 % on the BraTS2019, and 99.98 + 0.0038 % and 99.33 + 0.0072 % on the BraTS2020. The results highlight the remarkable capability of the algorithm in dealing with complex and high-dimensional images, especially in detecting small and unclear tumors. Moreover, it outperforms existing diagnostic methods, significantly improving the accuracy and reliability of brain tumor detection.},
  archive      = {J_ASOC},
  author       = {Rahman Farnoosh and Fatemeh Aghagoli},
  doi          = {10.1016/j.asoc.2025.112940},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112940},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Pseudo-deep unsupervised model-based clustering for brain tumor detection in magnetic resonance images},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mindful human digital twins: Integrating theory of mind with
multi-agent reinforcement learning. <em>ASOC</em>, <em>174</em>, 112939.
(<a href="https://doi.org/10.1016/j.asoc.2025.112939">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Agent Reinforcement Learning (MARL) is focused on enabling autonomous agents to learn and adapt to complex environments through interactions with their surroundings and other agents. A key challenge in MARL is developing agents with the human-like capacity to understand, predict, and respond to the intentions and mental states of their peers. This capability, commonly referred to as the Theory of Mind (ToM), is central to fostering more sophisticated and realistic interactions among autonomous agents. In this paper, we propose a novel approach that leverages Theory-Theory (TT) and Simulation-Theory (ST) to enhance ToM within the MARL framework. Building on the Digital Twins (DT) framework, we introduce the Mindful Human Digital Twin (MHDT). These intelligent systems enriched with ToM capabilities bridge the gap between artificial agents and human-like interactions. In this work, we utilized OpenAI Gymnasium to perform simulations and evaluate the effectiveness of our approach. This work represents a significant step forward in Artificial Intelligence (AI), resulting in socially intelligent systems capable of natural and intuitive interactions with both their environment and other agents. This approach is particularly effective in addressing critical social challenges such as school bullying. This research not only advances the growing field of MARL but also paves the way for sophisticated AI systems with enhanced ToM abilities, tailored for complex and sensitive real-world applications.},
  archive      = {J_ASOC},
  author       = {Luis Zhinin-Vera and Elena Pretel and Víctor López-Jaquero and Elena Navarro and Pascual González},
  doi          = {10.1016/j.asoc.2025.112939},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112939},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Mindful human digital twins: Integrating theory of mind with multi-agent reinforcement learning},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A particle swarm optimization and constraint
programming-based approach for integrated process planning and
scheduling with lot streaming problem. <em>ASOC</em>, <em>174</em>,
112938. (<a href="https://doi.org/10.1016/j.asoc.2025.112938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the integrated process planning and scheduling with lot streaming (IPPS-LS) problem, which consists of lot splitting, process planning, and shop scheduling. Although the IPPS-LS problem is common in the manufacturing of flexible process products, it has not been extensively studied due to its high complexity. Hence, this study develops an enhanced particle swarm optimization algorithm based on constraint programming (CP) to minimize makespan. The proposed algorithm employs finite condition and relaxation models for particle reconfiguration and re-optimization. To achieve it, two types of relaxation models are constructed by decomposing the multiple constraints of the CP model. The algorithm dynamically updates particle encoding sequences based on model accuracy, effectively reducing invalid searches and accelerating the search process. The proposed algorithm is compared with models and other metaheuristic algorithms on 120 test instances. The impact of the relaxed CP strategy and particle swarm optimization algorithm on the proposed algorithm performance is also analyzed. Finally, a significance of difference validation is performed. Computational experiments demonstrate the efficiency of the proposed algorithm in solving the IPPS-LS problem of varying scales. In addition, the relaxed CP strategy exhibits a more significant improvement effect for medium-scale problems compared to small and large-scale problems.},
  archive      = {J_ASOC},
  author       = {Mengya Zhang and Xinyu Li and Liang Gao and Qihao Liu},
  doi          = {10.1016/j.asoc.2025.112938},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112938},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A particle swarm optimization and constraint programming-based approach for integrated process planning and scheduling with lot streaming problem},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heuristic-aided fusion serial cascaded deep network for
handwritten character recognition from handwritten images using
optimization strategy. <em>ASOC</em>, <em>174</em>, 112937. (<a
href="https://doi.org/10.1016/j.asoc.2025.112937">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handwritten Character Recognition (HCR) identifies and interprets handwritten text, converting it into machine-readable characters. However, it faces challenges with South Indian languages due to their complex scripts and intricate characters. So, in this work, a novel HCR model was introduced for automatic recognition of handwritten characters in South Indian languages. At first, required Telugu and Kannada handwritten images are collected from standard sources, and given into the segmentation phase using Active Contour. Then, the textural pattern generation is performed using the Adaptive Local Weber Pattern (ALWP). The weights in the ALWP are optimally tuned using the Improved Snow Leopard Optimization Algorithm (ISLOA). Finally, the ALWP generates a textural pattern, and then the generated textural pattern is given to the Hybrid Serial Cascaded Deep Network (HSCDNet) for the final handwritten character recognition process. Here, the Convolutional Autoencoder (CAE) and Deep Belief Network (DBN) are serially connected to the network. Finally, the implemented HCR model’s performance is evaluated by comparing it with various traditional approaches. The developed model attained the accuracy of dataset 1 is 93.45 %, dataset 2 is 93.11 %, and dataset 3 is 94.13 %. Thus, it proved that the developed model can effectively and easily recognize the curves in the Telugu and Kannada handwritten scripts, making it suitable for a wide range of applications.},
  archive      = {J_ASOC},
  author       = {Triveni Banavatu and Govindaswamy Parthasarathy},
  doi          = {10.1016/j.asoc.2025.112937},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112937},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Heuristic-aided fusion serial cascaded deep network for handwritten character recognition from handwritten images using optimization strategy},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized echo state network for error compensation based on
transfer learning. <em>ASOC</em>, <em>174</em>, 112935. (<a
href="https://doi.org/10.1016/j.asoc.2025.112935">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Echo State Network (ESN) is widely applied in nonlinear system modeling, but its performance is often limited by a lack of error autocorrelation analysis, leading to reduced modeling accuracy. Existing extensions, such as SR-ESN and ERBM, primarily focus on structural optimization or feature representation but fail to effectively address autocorrelation errors. To overcome these limitations, we propose a Transfer Learning-based Echo State Network (TLESN) that compensates for errors in realtime to enhance prediction accuracy. The TLESN integrates a computing layer based on ESN and a compensation layer employing transfer learning, which dynamically adjusts output weights. To validate the proposed model, experiments are conducted on the Mackey-Glass time series, a practical Sunspot dataset, and a real-world industrial dataset. Results demonstrate that TLESN effectively mitigates autocorrelation errors, achieving at least a 17% improvement in prediction accuracy compared to existing ESN extensions.},
  archive      = {J_ASOC},
  author       = {Yingqin Zhu and Yue Liu and Zhaozhao Zhang and Wen Yu},
  doi          = {10.1016/j.asoc.2025.112935},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112935},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Optimized echo state network for error compensation based on transfer learning},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain adaptive person re-identification with noise
optimization and dynamic weighting. <em>ASOC</em>, <em>174</em>, 112932.
(<a href="https://doi.org/10.1016/j.asoc.2025.112932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptive person re-identification (Re-ID) faces challenges due to inherent noise from limited domain transferability and the uncertainty in pseudo-label generation. To address this, we propose NODW (Noise Optimization and Dynamic Weighting), a comprehensive domain adaptive person Re-ID framework that systematically tackles these issues through quantitative noise assessment and dynamic optimization. Our method proposes: (1) an enhanced ResNet50-pro backbone specifically designed for cross-domain feature extraction, (2) a silhouette coefficient-based module for pseudo-label quality assessment with dynamic weighting, (3) a Maximum Mean Discrepancy (MMD)-based module for minimizing domain transferability limitations, and (4) a robust consistency supervision mechanism to ensure stable feature learning. Extensive experiments demonstrate state-of-the-art performance across multiple domain transfer tasks, achieving mAP scores of 73.8% (Market to Duke), 84.7% (Duke to Market), 34.2% (Market to MSMT), and 35.6% (Duke to MSMT). These results represent significant improvements over existing methods, particularly in challenging scenarios with large domain gaps, validating the effectiveness of our noise-aware adaptation strategy.},
  archive      = {J_ASOC},
  author       = {Zhengyang Wang and Xiufen Ye and Xue Shang and Shuxiang Guo},
  doi          = {10.1016/j.asoc.2025.112932},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112932},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Domain adaptive person re-identification with noise optimization and dynamic weighting},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Software and hardware synergy for accelerated plant disease
identification. <em>ASOC</em>, <em>174</em>, 112926. (<a
href="https://doi.org/10.1016/j.asoc.2025.112926">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Plant diseases are one of the main causes of reduced crop yields. Therefore, it is necessary to adopt timely and effective identification methods and take corresponding measures. Some physical and biological detection methods have been proposed by researchers, but these methods require specialized techniques and expensive detection costs. Furthermore, the limited number of skilled technicians means that disease identification is not always timely or effective. To achieve real-time identification of plant diseases in remote areas where network and circuit are not well connected, We adopted a hardware and software co-acceleration approach to implement the design. First, we designed a lightweight convolutional neural network (CNN) and trained this network using a knowledge distillation approach. Then, we quantified the model parameters into int8 type using a method of model quantization to further compress the model size. After compression, the model size of the network is 0.035 MB and the recognition accuracy is 94.06% on the test set of the experiment. In order to deploy the proposed network on resource constrained Field-Programmable Gate Array (FPGA) devices, we used time-division multiplexing and feature map segmentation to deploy the network. Finally, our design is implemented on ZYNQ7020 with an inference speed of 35.73ms/frame and a power consumption of 1.97 W. The experimental results show that our design has the advantages of consuming less FPGA resources, low power consumption, high speed and portability. It can be used for disease recognition in multiple plant classes.},
  archive      = {J_ASOC},
  author       = {Hongxing Wen and Chuandong Li and Xinpei Wang and Ling Chen},
  doi          = {10.1016/j.asoc.2025.112926},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112926},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Software and hardware synergy for accelerated plant disease identification},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced function approximation and applications to image
scaling: A new family of exponential sampling neural network kantorovich
operators. <em>ASOC</em>, <em>174</em>, 112923. (<a
href="https://doi.org/10.1016/j.asoc.2025.112923">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel family of exponential sampling type neural network Kantorovich operators, extending the work of Bajpeyi and Kumar (2021) and Bajpeyi (2023). Unlike previous research focused on approximating continuous functions, our operators are designed to handle Lebesgue integrable functions, offering enhanced versatility. We establish convergence theorems, analyze asymptotic behavior, and demonstrate the effectiveness of linear combinations for improving convergence rates. Our analysis extends to the multivariate setting, highlighting the operators’ capability in approximating a wide range of functions. To evaluate the practical performance of our proposed operators, we conducted numerical experiments with different sigmoidal functions and parameter values. Our findings reveal that operators activated by the Parametric sigmoid function consistently outperform those activated by other sigmoidal functions, achieving up to 20.70% reduction in maximum absolute error and 10.03% reduction in root mean squared errors. When applied to image scaling, our operators demonstrated superior performance compared to state-of-the-art methods like nearest neighbor, bilinear, and bicubic interpolation. For the ’Baboon’ image, we observed up to 5.62% increase in Peak Signal-to-Noise Ratio (PSNR) and 5.25% increase in Structural Similarity Index Measure (SSIM). Similar enhancements were observed for the ’Flowers’ and ’Retina’ images. The paper includes a detailed description of the image processing algorithm, along with a flowchart illustrating the implementation. These results underscore the operators’ potential in various machine learning tasks, motivating further research into their applications and optimization.},
  archive      = {J_ASOC},
  author       = {P.N. Agrawal and Behar Baxhaku and Artan Berisha},
  doi          = {10.1016/j.asoc.2025.112923},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112923},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Enhanced function approximation and applications to image scaling: A new family of exponential sampling neural network kantorovich operators},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust ensemble classifier for imbalanced data via
adaptive variety oversampling and embedded sampling rate. <em>ASOC</em>,
<em>174</em>, 112922. (<a
href="https://doi.org/10.1016/j.asoc.2025.112922">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel hybrid approach for addressing imbalanced data classification. The core concept involves devising a data-based oversampling algorithm to partially re-balance the data and employing an ensemble algorithm to enhance model performance. The merits of the proposed hybrid method can be highlighted as follows: (1) rather than re-balancing the data completely, an incomplete yet rational sampling rate is adopted to synthesize new samples, which can reduce the extreme imbalance ratio as well as avoid the overlap and redundancy by the complete re-balance. After oversampling, an improved adaptive boosting method is used to further contribute to the classification result; (2) with the help of temporarily generating samples in a triangular region of four selected target samples, a new synthesizing method is provided, which contributes greatly to the diversity of the new synthetic samples and the guarantee of the correctness and safety; (3) besides the number of correctly classified minority samples, the imbalance ratio of raw data is considered to make the ensemble classifier serve a further focus on minority samples and proved theoretically effective in mitigating the skew of the classification hyperplane on minority samples.},
  archive      = {J_ASOC},
  author       = {Jun Dou and Yan Song and Guoliang Wei and Xinchen Guo},
  doi          = {10.1016/j.asoc.2025.112922},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112922},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A robust ensemble classifier for imbalanced data via adaptive variety oversampling and embedded sampling rate},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forecasting time series using convolutional neural network
with multiplicative neuron. <em>ASOC</em>, <em>174</em>, 112921. (<a
href="https://doi.org/10.1016/j.asoc.2025.112921">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) are proven to be efficient in time series forecasting, however architectural selection remains a challenging task. This work aims to propose CNN, utilizing single multiplicative neuron model in forecasting time series, intended to eliminate architectural complexities of classical CNN ensuring its computational efficiency. Applicability of proposed approach is employed on financial time series datasets such as Index, Stocks, Cryptocurrencies and a commodity in evaluating the model’s performance on the basis of RMSE, MAE and R 2 values. Further, time-delay effects were also observed in datasets which has been analyzed to improve the accuracy of the proposed model. Based on the lowest RMSE and MAE values, and higher R 2 values, the optimal delay value has been analyzed which has been used for forecasting. The result demonstrates that in data sets like NIFTY50, SBI, Bitcoin, and Natural Gas, the forecasting efficiency is improved when compared to classical CNN. The results obtained can be used to draw valuable insights for decision making, which will enable future studies and facilitate easy adaptation in analyzing time series.},
  archive      = {J_ASOC},
  author       = {Shobhit Nigam},
  doi          = {10.1016/j.asoc.2025.112921},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112921},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Forecasting time series using convolutional neural network with multiplicative neuron},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised partially labeled heterogeneous feature
selection based on information-theoretic three-way decision model.
<em>ASOC</em>, <em>174</em>, 112880. (<a
href="https://doi.org/10.1016/j.asoc.2025.112880">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection plays an increasingly vital role in addressing large-scale partially labeled heterogeneous data. Three-way decision (TWD) theory is an important extension of classical two-way decision, which provides an approach to acquire a ternary classification of the universe as acceptance region, rejection region and boundary region, respectively, while the boundary region can capture the uncertain information. In this paper, taking consideration of heterogeneous data possessing tremendous unlabeled samples, we present two kinds of feature representation metric based on unlabeled sample selection mechanism to construct more effective feature selection models. Specifically, a generalized variable-precision neighborhood rough set model is first proposed based on a TWD model developed by optimal threshold pair, which describes the relationships between features and labels from a more fine-grained level. Second, a unlabeled sample selection framework is proposed to comprehensively measure the importance of unlabeled samples based on their uncertainty, graph density and label transfer ability. We then define six TWD-based measures which reveal nonlinear correlation and inconsistency between features and labels by extended information entropy and complementary entropy, respectively. Furthermore, the unified feature measures are established to boost global feature selection in partially labeled heterogeneous datasets. Finally, the corresponding feature selection algorithm is designed, and the comparative experiments demonstrate the effectiveness and efficiency.},
  archive      = {J_ASOC},
  author       = {Qianqian Sun and Hongying Zhang and Weiping Ding},
  doi          = {10.1016/j.asoc.2025.112880},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112880},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Semi-supervised partially labeled heterogeneous feature selection based on information-theoretic three-way decision model},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse-view planar 3D reconstruction method based on
hierarchical token pooling transformer. <em>ASOC</em>, <em>174</em>,
112833. (<a href="https://doi.org/10.1016/j.asoc.2025.112833">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse-view planar 3D reconstruction aims to recover scene information from limited camera frames, which poses a fundamental problem in computer vision. Although previous methods have made significant improvements in this field, they have not adequately considered the multi-scale properties of the surrounding environment, thus limiting the reconstruction performance. Additionally, the conventional feed-forward network in the vanilla Transformer is constructed using fully connected layers, lacking the ability to capture local information from image features. To address these two problems, this paper proposes a sparse-view planar 3D reconstruction method based on hierarchical token pooling Transformer ( i.e . HTP-Formers). Specifically, we utilize average pooling layers with various ratios in Transformer model to capture multi-scale features. Subsequently, we propose a depth-wise convolution based inverted residual feed-forward network to enhance local information extraction performance at negligible computational cost. To demonstrate the effectiveness of HTP-Formers on planar 3D reconstruction tasks, we thoroughly evaluate the proposed model on Matterport3D public dataset. Especially, HTP-Formers improves performance by 6.1% and 18.3% in translational and rotational errors, respectively, outperforming most existing planar 3D reconstruction methods in terms of planar correspondence inference and relative camera pose estimation.},
  archive      = {J_ASOC},
  author       = {Jiahui Zhang and Jinfu Yang and Fuji Fu and Jiaqi Ma},
  doi          = {10.1016/j.asoc.2025.112833},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112833},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Sparse-view planar 3D reconstruction method based on hierarchical token pooling transformer},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-path geometric relation-aware transformer for point
cloud classification and segmentation. <em>ASOC</em>, <em>174</em>,
112801. (<a href="https://doi.org/10.1016/j.asoc.2025.112801">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point cloud analysis is a challenging task due to the disorder and irregularity of the point cloud data. Traditional methods focus on constructing local or global geometric feature extractors to leverage the geometric features of the point cloud. However, traditional methods have the disadvantage of high time complexity and consume numerous resources because of the sophisticated extractors. This paper proposes a dual-path geometric relation-aware transformer network (DuGREAT) to aggregate local and global features, which balances computational cost, efficiency, and accuracy. DuGREAT constructs a channel adaptive multi-layer perceptron module by expanding channels of residual blocks to reinforce the local feature extraction. To obtain the geometric relation of a 3D object, we design a geometric point disentangler to categorize the point cloud into key and non-key points, respectively represented by an object’s local and global regions. With a relation-aware transformer network, the global path processes the non-key points to extract deep-level global features, and the local path focuses on the key points to calculate the difference between the local and global features. To the best of our knowledge, this is one of the successful attempts to capture and enhance geometric relations and feature fusion between key and non-key points, which provides insights for point cloud classification and segmentation. Fitted with a soft geometric affine module to alleviate the irregularity of the point cloud, DuGREAT acts better than several state-of-the-art methods on multiple datasets. Specifically, our DuGREAT achieves 94.6% accuracy on the ModelNet40 classification task and 87.3% accuracy on the ScanObjectNN classification task, outperforming the other transformer models. DuGREAT-simple, a simple version with fewer FLOPs, attains 94.2% and 87.0% accuracy on the ModelNet40 classification and ScanObjectNN classification tasks, respectively, while maintaining a faster inference speed (595.7 samples/s). Furthermore, we validate the effectiveness of the modules in DuGREAT and achieve instance mean Intersection over Union (mIoU) of 86.5% (DuGREAT) and 86.1% (DuGREAT-simple) on the ShapeNetPart segmentation task.},
  archive      = {J_ASOC},
  author       = {Xiangli Li and Qifan Wang and Baozhi Qiu},
  doi          = {10.1016/j.asoc.2025.112801},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112801},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dual-path geometric relation-aware transformer for point cloud classification and segmentation},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-objective multi-task evolutionary algorithm based on
source task transfer. <em>ASOC</em>, <em>174</em>, 112732. (<a
href="https://doi.org/10.1016/j.asoc.2025.112732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the real world, many optimization problems often do not exist in isolation, they usually have complex interactions and dependencies, and have multiple optimization goals. In order to improve the performance of individual task solving, an evolutionary multi-task multi-objective optimization algorithm (MTMOO) is proposed. However, most of the current evolutionary algorithms are based on the assumption that the prior knowledge (experience in solving optimization problems) is zero, which makes the ability of the algorithm to solve problems cannot be improved with the increase of historical experience, and greatly limits the adaptability and learning ability of the algorithm. In order to overcome this limitation, this paper proposed a multi-objective and multi-task adaptive migration Evolutionary algorithm (MOMFEA-STT). The algorithm constructs the parameter sharing model of historical task and target task online. By identifying the degree of association between different tasks, the intensity of cross-task knowledge transfer is automatically adjusted to maximize the capture, sharing and utilization of common useful knowledge to solve related tasks. In addition, in order to strengthen the exploration and exploitation ability of the algorithm and avoid the problem that the algorithm is easy to fall into the local optimum, the MOMFEA-STT adopts a new method of generation of children, generates children by using spiral search mode, and constantly adjusts the search direction of the algorithm. Experimental results show that the proposed method outperforms the existing algorithms on the multi-task optimization benchmark problems.},
  archive      = {J_ASOC},
  author       = {Zheng-Yi Chai and ying Nie and Yan-Lun Li},
  doi          = {10.1016/j.asoc.2025.112732},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112732},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-objective multi-task evolutionary algorithm based on source task transfer},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Calculating forgotten effects using fuzzy numbers based on
embedded experton structures. <em>ASOC</em>, <em>174</em>, 112720. (<a
href="https://doi.org/10.1016/j.asoc.2025.112720">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The method of calculating Forgotten Effects is designed to process a single source of information, preventing the use of multiple sources, which can generate bias in the results and avoid the wide use of this methodology in the investigations. This research aims to establish a mechanism for processing Expertons as structured data in their natural form, without decreasing entropy within the matrices of the Forgotten Effects, and thus be able to process information from many sources. This process aims to maintain the original values during the whole calculating process and avoid distorted information. The presented algorithm for calculating Forgotten Effects in decision-making under uncertainty utilizes fuzzy numbers in Expertons embedded and constitutes an innovative approach. This approach complements conventional methodologies that often rely on averages or weights to derive a single value and confirm hypotheses. This model has a different paradigm, as it detects relationships that are not visible for systematic analysis. Additionally, this research introduces various types of focus based on risk profiles for calculation strategies, yielding prudent, optimistic, and pessimistic scenarios. Moreover, the proposed algorithm provides the flexibility to choose between uncertainty or precision-focused processing to adapt to the specific approach of each context. Ultimately, an applied example is presented to validate the effectiveness and validity of the proposed model. As a contribution, this research offers the novelty of being able to calculate forgotten effects, not only based on one expert but also with an unlimited number by using the algorithm designed through the Expertons.},
  archive      = {J_ASOC},
  author       = {Darley Biviana Pacheco Cubillos and Josefa Boria Reverter and Jaime Gil Lafuente},
  doi          = {10.1016/j.asoc.2025.112720},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112720},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Calculating forgotten effects using fuzzy numbers based on embedded experton structures},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale frequency feature fusion transformer for
pediatric echocardiography analysis. <em>ASOC</em>, <em>173</em>,
112950. (<a href="https://doi.org/10.1016/j.asoc.2025.112950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Congenital heart disease (CHD) is the most common birth defect. Echocardiography analysis is essential for identifying pediatric CHD, yet existing methods often focus on single functions and lack comprehensive analysis. In ultrasound data analysis, low-frequency features reflect the overall structure and morphology of the heart, while high-frequency features emphasize the detailed characteristics of cardiac structures. However, existing intelligent analysis models apply a uniform feature processing approach to all echocardiography features, lacking adaptive learning for features at different frequencies. This limitation reduces the model’s capacity to effectively capture both the global shape and local details of echocardiography target structures. Therefore, this paper proposes a multi-scale frequency feature fusion Transformer (MFT-Former) model for the multi-functional analysis of pediatric echocardiography. Specifically, this paper first effectively implements the extraction and aggregation of coarse and fine-grained features of echocardiography by setting a multi-scale patch embedding unit. Secondly, we design a grouped frequency feature fusion Transformer block (GFFT_Block), which contains two parallel branches: an adaptive frequency feature fusion branch (AFF_Branch) and a cross-learning wavelet Transformer branch (CWT_Branch). The former is used for adaptive learning of different frequency features in a local range. The latter achieves cross-learning of different frequency features on a global range and avoids the loss of information caused by dimensionality reduction operations. Based on the parasternal short-axis view, this model identifies ventricular septal defects via echocardiography classification and realizes quantitative analysis through structural segmentation and measurement. Experimental results demonstrate that the MFT-Former outperforms the state-of-the-art algorithms and offers new perspectives for multi-functional echocardiography analysis.},
  archive      = {J_ASOC},
  author       = {Cheng Zhao and Yuanlin Liu and Weiling Chen and Zhuo Xiang and Yiyao Liu and Bei Xia and Jing Qin and Tianfu Wang and Baiying Lei},
  doi          = {10.1016/j.asoc.2025.112950},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112950},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-scale frequency feature fusion transformer for pediatric echocardiography analysis},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An interpretable dahl-LRN neural-network for accurately
modelling the systems with rate-dependent asymmetric hysteresis.
<em>ASOC</em>, <em>173</em>, 112936. (<a
href="https://doi.org/10.1016/j.asoc.2025.112936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The motion accuracy and stability of piezoelectric positioning systems are significantly compromised by inherent hysteresis and other nonlinearities. This paper presents an innovative method integrating the Dahl model with Layer Recurrent Neural Networks (LRN) to model piezoelectric actuators accurately. Initially, the Dahl model is reformulated into a neural network structure, resulting in the Dahl Neural Network (DahlNN), which strictly adheres to the underlying mathematical equations. The weights of this network directly correspond to the parameters of the Dahl equations, thereby creating a transparent neural network architecture with clear physical significance and interpretability. Subsequently, the DahlNN is enhanced by incorporating feedback mechanisms and recurrent effects from LRN, improving its ability to describe asymmetric and rate-dependent hysteresis characteristics. Extensive experiments demonstrate that, compared to LRN models without physical knowledge guidance, the proposed Dahl-LRN model reduces peak-to-valley fluctuations by 70 % and decreases the average error by approximately 97.3 %, with only a 5 % increase in computational time while maintaining interpretability and achieving superior modelling performance. Through this approach, this paper aims to provide a novel perspective on leveraging physical information to advance the application of deep learning in modelling complex physical phenomena.},
  archive      = {J_ASOC},
  author       = {Lei Ni and Hongfei Wang and Guoqiang Chen and Lanqiang Zhang and Na Yao and Geng Wang},
  doi          = {10.1016/j.asoc.2025.112936},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112936},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An interpretable dahl-LRN neural-network for accurately modelling the systems with rate-dependent asymmetric hysteresis},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous collaborative filtering contrastive learning
for social recommendation. <em>ASOC</em>, <em>173</em>, 112934. (<a
href="https://doi.org/10.1016/j.asoc.2025.112934">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative filtering methods based on Graph Neural Networks (GNNs) have gained increasing popularity in recommendation systems. These methods enhance the representation of users and items by leveraging the information of graph structure from interaction data, improving recommendation performance. However, they often face limitations due to the data sparsity issue that is common in recommendation systems. In the constructed user–item heterogeneous bipartite graph, sparse interaction data leads to a scarcity of neighbor nodes impeding the acquisition of sufficient collaborative signals via the message-passing mechanism among these neighbor nodes. We have observed that users and items can be grouped according to characteristic similarities. These groups’ common feature information can serve as supplementary data to aid in the embedding learning. So, we present the Heterogeneous Collaborative Filtering Contrastive Learning (HCFCL) method, which aims to extract two types of heterogeneous collaborative signals from interaction data: those based on neighbor nodes and those based on group features. Specifically, we design an embedding generative hypergraph network to extract group common feature information founded on the heterogeneous bipartite graph. The group common feature information is transferred via a meta network and personalized bridge functions according to individual characteristics. Additionally, the HCFCL model, combined with contrastive learning, captures the consistency of the heterogeneous collaborative signals to enhance representation. The experiment demonstrates the superior performance of the HCFCL model compared to other methods evaluated on three public datasets, demonstrating excellent and stable performance in mitigating the data sparsity issue.},
  archive      = {J_ASOC},
  author       = {Chaojun Meng and Changfan Pan and Hongji Shu and Qing Wang and Hanghui Guo and Jia Zhu},
  doi          = {10.1016/j.asoc.2025.112934},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112934},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Heterogeneous collaborative filtering contrastive learning for social recommendation},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automatic optimization for generating adversarial malware
based on prioritized evolutionary computing. <em>ASOC</em>,
<em>173</em>, 112933. (<a
href="https://doi.org/10.1016/j.asoc.2025.112933">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning has been widely applied to malware detection tasks; but unfortunately, they exhibit significant vulnerability to adversarial attacks and can be easily circumvented using perturbation carefully crafted. Concurrently, we are witnessing a corresponding increase in the attention dedicated to adversarial attacks against malware detection models. Nevertheless, current research on adversarial examples still faces obstacles such as poor escape effectiveness and difficulty in preserving functionality. Particularly, greedily recruiting the best manipulations from a vast search space often leads to poor diversity of adversarial perturbation sequence. To rectify these shortcomings, this paper proposes an automated, continuously optimized approach for generating malware adversarial examples based on evolutionary computing. Our method filters effective action sequences from a large pool of random manipulations, assigning different priorities to different actions. The generation and optimization of adversarial examples are formalized as a sparse minimization optimization problem based on a fixed-length action vector. We introduce AOP-Mal, a novel genetic framework to automatically generate and optimize adversarial examples. The initialization and evolution of the population depend on the priority of actions, as well as the proposed novel evolutionary operator. The experimental results demonstrate that our attack strategy effectively bypasses the detection mechanisms and outperforms most state-of-the-art malware adversarial frameworks. Our hope is to help researchers understand the intentions of attackers and explore more powerful defense mechanisms.},
  archive      = {J_ASOC},
  author       = {Yaochang Xu and Yong Fang and Yijia Xu and Zhan Wang},
  doi          = {10.1016/j.asoc.2025.112933},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112933},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Automatic optimization for generating adversarial malware based on prioritized evolutionary computing},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online ensemble learning-based anomaly detection for IoT
systems. <em>ASOC</em>, <em>173</em>, 112931. (<a
href="https://doi.org/10.1016/j.asoc.2025.112931">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the modern era of digital transformation, the evolution of fifth-generation (5G) wireless networks has played a pivotal role in revolutionizing communication technology and accelerating the growth of smart technology applications. As an integral element of smart technology, the Internet of Things (IoT) grapples with the problem of limited hardware performance. Cloud and fog computing-based IoT systems offer an effective solution but often encounter concept drift issues in real-time data processing due to the dynamic and imbalanced nature of IoT environments, leading to performance degradation. In this study, we propose a novel framework for drift-adaptive ensemble learning called the Adaptive Exponentially Weighted Average Ensemble (AEWAE), which consists of three stages: IoT data preprocessing, base model learning, and online ensembling. It integrates four advanced online learning methods within an ensemble approach. The crucial parameter of the AEWAE method is fine-tuned using the Particle Swarm Optimization (PSO) technique. Experimental results on four public datasets demonstrate that AEWAE-based anomaly detection effectively detects concept drift and identifies anomalies in imbalanced IoT data streams, outperforming other baseline methods in terms of accuracy, F1 score, false alarm rate (FAR), and latency.},
  archive      = {J_ASOC},
  author       = {Yafeng Wu and Lan Liu and Yongjie Yu and Guiming Chen and Junhan Hu},
  doi          = {10.1016/j.asoc.2025.112931},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112931},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Online ensemble learning-based anomaly detection for IoT systems},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual residual learning of frequency fingerprints in
detecting synthesized biomedical imagery. <em>ASOC</em>, <em>173</em>,
112930. (<a href="https://doi.org/10.1016/j.asoc.2025.112930">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial synthesis of biomedical imagery is an evolving threat yet under-addressed. The integrity of medical imaging is important for accurate diagnosis and treatment. This study addresses the potential threat of fabricated biomedical imagery, focusing on synthetic dermatological lesions and CT nodules. The Representation Similarity Matrix measured the quantitative authenticity to account for similarities of synthesized data with authentic data. The study explores traces of manipulation from frequency signatures of synthesized imagery. We propose a novel combinatorial architecture, the Dual Residual Network (DRN), capturing hidden residual traces from low-frequency fingerprints of synthetic data and exposing hidden forgeries. DRN achieves near-perfect detection rates with an accuracy of 98.80% for CT nodules and 98.97% for lesions. Equal Error Rates of the model on the two datasets exhibited a marginal improvement of 57.87% in the CT nodules compared to the skin lesions. Sensitivity and specificity play a significant role in medical diagnostics. The model achieved sensitivities of 99.31% and 98.45% and specificity of 98.80% and 99.60% for each dataset, respectively. Further verification of the frequency traces was performed by analyzing gradients in the target concepts that led to decision-making. This study equips the medical field with a powerful tool to combat the evolving threat of synthetic fraud, safeguarding patient and client safety. The potential of the technique extends beyond healthcare, offering a blueprint for tackling synthetic data across diverse domains.},
  archive      = {J_ASOC},
  author       = {Misaj Sharafudeen and Vinod Chandra S.S.},
  doi          = {10.1016/j.asoc.2025.112930},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112930},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dual residual learning of frequency fingerprints in detecting synthesized biomedical imagery},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A graph attention-based policy gradient method with an
adaptive embedding strategy for k-center problems. <em>ASOC</em>,
<em>173</em>, 112929. (<a
href="https://doi.org/10.1016/j.asoc.2025.112929">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The k -center problem (KCP) is a well-known NP-hard combinatorial optimization challenge in the field of computer science and operations research, aiming to determine optimal locations for k centers within a given set of nodes to minimize the maximum distance from each node to its nearest center. In contrast to conventional algorithms that have inherent limitations in handling the trade-off between solution quality and computational efficiency, this study proposes a new method based on a graph attention mechanism with an encoder-decoder architecture to find high-quality solutions for KCPs by directly learning heuristics from the graph. Specifically, the encoder processes the input feature of the graph and capture intricate spatial patterns and dependencies among nodes, whereas the decoder leverages the encoded information and attention weights to iteratively generate solutions for the KCP. Moreover, an adaptive embedding strategy is developed to handle the specific attributes and constraints inherent in different KCP instances. To find high-quality solutions, a policy gradient method with an exponential moving average baseline is developed to update and learn the optimal model parameters. A comprehensive set of experiments on multiple problem sizes are conducted to systematically compared the performance of the proposed method with a wide range of baseline methods across four types of KCPs, including the standard KCP, capacitated KCP, non-uniform KCP, and dynamic KCP. The experimental results demonstrate the competitive performance of the graph attention-based method in addressing KCPs.},
  archive      = {J_ASOC},
  author       = {Zhonghao Zhao and Carman K.M. Lee and Xiaoyuan Yan},
  doi          = {10.1016/j.asoc.2025.112929},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112929},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A graph attention-based policy gradient method with an adaptive embedding strategy for k-center problems},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified transductive and inductive learning framework for
few-shot learning using graph neural networks. <em>ASOC</em>,
<em>173</em>, 112928. (<a
href="https://doi.org/10.1016/j.asoc.2025.112928">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have shown their effectiveness in integrating feature embeddings for image and video processing tasks. While initially developed for inductive learning, GNNs have been extended to support transductive learning, enabling them to learn from partially labeled graphs. However, the combination of transductive and inductive learning in existing GNN-based models lacks proper theoretical justification, and GNNs with information propagation mechanisms often encounter the over-smoothing problem, especially in Few-Shot Learning (FSL) tasks. In this paper, we propose a unified transductive and inductive learning GNN model named FGCN for FSL tasks. The proposed FGCN differentiates between the roles of inductive and transductive learning, while quantifying the contributions of intra-properties within entities and inner-relationships between neighboring entities. By addressing the over-smoothing problem comprehensively, the FGCN offers a promising approach for FSL tasks. Our findings demonstrate that the proposed FGCN model achieves a significant improvement in accuracy over state-of-the-art methods, as evidenced by experiments on four standard Few-Shot Learning benchmarks. For example, in the 5-Way 5-Shot scenario, the proposed FGCN achieved an accuracy increase of 7.70% on the Mini-ImageNet, compared to the state-of-the-art result obtained by the MCGN model.},
  archive      = {J_ASOC},
  author       = {Jie Chang and Haodong Ren and Zuoyong Li and Yinlong Xu and Taotao Lai},
  doi          = {10.1016/j.asoc.2025.112928},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112928},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A unified transductive and inductive learning framework for few-shot learning using graph neural networks},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective evolutionary algorithm with two balancing
mechanisms for heterogeneous UAV swarm path planning. <em>ASOC</em>,
<em>173</em>, 112927. (<a
href="https://doi.org/10.1016/j.asoc.2025.112927">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicle (UAV) swarm path planning involves creating efficient routes based on task requirements to enable collaborative flight. Compared to homogeneous UAV swarm, the application scenarios of heterogeneous UAV swarm have become increasingly widespread. They can fully leverage the various capabilities of drones and show higher economic benefits. Existing research mainly focuses on homogeneous UAV swarms, and the model for uniformly describing heterogeneous UAV swarm from a functional perspective is insufficient. Differences in dynamic constraints and energy consumption models create challenges for accurately characterizing the path planning problem of heterogeneous UAV swarm. To supplement the above deficiencies, this article designs the scenario and composition structure of heterogeneous UAV swarm. The path-planning problem of heterogeneous UAV swarm is modeled as a multi-objective optimization (MOO) problem, in which a comprehensive energy consumption objective is constructed. To better balance multiple objectives and obtain high-quality solutions, a MOO evolutionary algorithm based on heterogeneous UAV swarm, namely HMOEA, is proposed. Specifically, HMOEA is implemented by combining the proposed two strategies. To verify the model’s feasibility and the algorithm’s effectiveness, numerical simulations and prototype simulations are provided. In numerical simulations, the proposed algorithm was compared with various advanced algorithms, i.e., NSGA-II, CIACO, AP-GWO, CL-DMSPSO, and DSNSGA-III, in two designed terrain problems. The results demonstrate that HMOEA not only outperforms the compared algorithms on convergence and diversity indicators increased over 4% and 2% respectively. Normal flight results were achieved in the two scenarios served by the prototype simulation, namely, urban buildings and forest scenes. Specific implementation and application can be achieved in military or civilian scenarios like reconnaissance and strike missions, search and rescue missions. The proposed model can adapt to more task scenarios, and the proposed method can provide faster and higher quality results for heterogeneous UAV swarm routes. In actual deployment, adjusting model parameters and optimizing the computing environment according to application requirements are worth further investigation to achieve optimal effect.},
  archive      = {J_ASOC},
  author       = {Xiuju Xu and Chengyu Xie and Linru Ma and Lin Yang and Tao Zhang},
  doi          = {10.1016/j.asoc.2025.112927},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112927},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-objective evolutionary algorithm with two balancing mechanisms for heterogeneous UAV swarm path planning},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A random searching algorithm for efficiently solving the
connectivity-oriented robust optimization problem on large-scale
networked systems. <em>ASOC</em>, <em>173</em>, 112924. (<a
href="https://doi.org/10.1016/j.asoc.2025.112924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By consolidating part of the links to be invulnerable, there will be no connectivity degradation in a network under expected network failure intensity. Although existing link consolidation methods can handle large-scale networks, their solutions are far from optimal. Redundancy in existing solutions can be quantified by the connectivity of the pure graph consisting of the necessary subset of links, and existing methods improve pure graph connectivity to far above the expected value. Fortunately, we have found a special superset of link cuts, and proved that it can reduce consolidation links by removing the right set of links from existing solutions while maintaining the desired connectivity. In response to the high complexity of searching for the optimal superset, we found one kind of superset that is close to the optimal solution and easy to locate, significantly reducing the number of links that need to be consolidated with a slight increase in preprocessing overhead. Experiments have shown that in large networks, the algorithm can provide a protection effect of over 99.9%, and can lead to 60% overhead savings compared to existing high-speed algorithms under the same computing time. On small-scale networks where the optimal algorithm is feasible, the average additional cost compared to the optimal result can be controlled within 1%. Thus, while ensuring accuracy, it can further approach the optimal solution compared to existing algorithms, significantly reducing the overhead of infrastructure consolidation.},
  archive      = {J_ASOC},
  author       = {Wei Wei and Guobin Sun and Qinghui Zhang},
  doi          = {10.1016/j.asoc.2025.112924},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112924},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A random searching algorithm for efficiently solving the connectivity-oriented robust optimization problem on large-scale networked systems},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hesitant fuzzy linguistic mahalanobis distance-based TOPSIS
method for evaluating regional green development levels. <em>ASOC</em>,
<em>173</em>, 112920. (<a
href="https://doi.org/10.1016/j.asoc.2025.112920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objectively understanding regional green development levels (GDLs) is a key prerequisite for the implementation of green development strategies. In this study, we propose an innovative hesitant fuzzy linguistic Mahalanobis distance-based TOPSIS (HLMD-TOPSIS) method to evaluate regional GDLs with hesitant fuzzy linguistic term sets (HFLTSs). The developed HLMD-TOPSIS method can well optimize the weight allocation based on the correlation relationship between criteria under HFLTSs environments. The improved relative closeness index used in the HLMD-TOPSIS method not only optimizes the evaluated index to better adapt the actual contexts but also reflects some balance between the shortest distance from positive ideal solution and the farthest distance from negative ideal solution. More importantly, a new evaluation index system of regional GDLs within twelve criteria is further established from three dimensions of green economy, ecological environment, and green policy. With this new evaluation index system, the developed HLMD-TOPSIS method is applied to evaluate the GDLs of Hubei province in China, and its feasibility is demonstrated. The results show that the innovative HLMD-TOPSIS method is reliable for evaluating regional GDLs, and provides valuable inspiration and references for improving the evaluation efficiency of practical regional GDLs. The advantage of the developed HLMD-TOPSIS method is also indicated with comparison analysis. Besides, a series of new hesitant fuzzy linguistic Mahalanobis distance measures and new statistical measurements are also proposed to measure HFLTSs data, which provide a theoretical basis for the processing of HFLTSs information.},
  archive      = {J_ASOC},
  author       = {Xiaolu Zhang and Haiyan Wu},
  doi          = {10.1016/j.asoc.2025.112920},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112920},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Hesitant fuzzy linguistic mahalanobis distance-based TOPSIS method for evaluating regional green development levels},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating commuters’ travel mode choice using the z-number
extension of parsimonious best worst method. <em>ASOC</em>,
<em>173</em>, 112918. (<a
href="https://doi.org/10.1016/j.asoc.2025.112918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates commuters&#39; travel mode choices in Dublin City, Ireland, using a novel fuzzy multi-criteria decision-making model. The model integrates the Best-Worst Method (BWM) with fuzzy Z-numbers and the Parsimonious concept to handle uncertainties and simplify decision-making. The innovative aspect of this model lies in its ability to combine these methodologies, offering a streamlined yet comprehensive tool for urban transportation analysis. The hypothesis tested is whether the proposed model can effectively evaluate and prioritize travel mode choices while maintaining simplicity and reliability. The methodology involves surveying four experts and applying fuzzy Parsimonious Z-BWM to assess six travel modes. The results indicate that the model provides a robust framework for evaluating travel mode choices, with cars being identified as the most preferred mode. A comparative analysis with traditional BWM and direct evaluation methods demonstrates the model&#39;s efficiency and consistency in ranking preferences.},
  archive      = {J_ASOC},
  author       = {Sarbast Moslem},
  doi          = {10.1016/j.asoc.2025.112918},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112918},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Evaluating commuters&#39; travel mode choice using the Z-number extension of parsimonious best worst method},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel multi-strategy combined whale optimization algorithm
for cascade reservoir operation of complex engineering optimization.
<em>ASOC</em>, <em>173</em>, 112917. (<a
href="https://doi.org/10.1016/j.asoc.2025.112917">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reservoir operation optimization is a complex nonlinear problem involving multiple variables and physical constraints, making it one of the most challenging optimal issues in water resources management. The Whale Optimization Algorithm (WOA) features a straightforward mechanism and exceptional optimization performance. However, with escalating problem complexity, problems such as premature convergence and inadequate global exploration emerge. This study proposes a multi-strategy combined whale optimization algorithm (SCWOA) to address these problems. The approach retains the powerful exploitation mechanism of WOA while implementing the following improvements: introducing parallel multiplication and division operators to enhance global exploration capability, adopting the dual-strategy encirclement mechanism to enrich population diversity, and integrating dynamic spiral mechanism to improve solution accuracy coupling the adaptive escape mechanism to reduce the local stagnation times. Subsequently, numerical experiments are conducted to compare and analyze SCWOA with seven commonly used optimization algorithms across 53 benchmark functions. The analysis results indicate that SCWOA surpasses existing algorithms in global optimization accuracy, robustness, and exploration ability when handling most complex problems with varying dimensions and modes. Furthermore, a generation operation model of a practical hydropower system in China is developed under multiple constraints, such as ice prevention, flood control, and water supply. The operation results show that the schemes of SCWOA generate higher power generation than existing algorithms under different scenarios, effectively improving hydropower utilization rates. Therefore, a novel approach is provided for solving complex reservoir operation optimization problems.},
  archive      = {J_ASOC},
  author       = {Ziqi Hou and Huichun Peng and Jiqing Li},
  doi          = {10.1016/j.asoc.2025.112917},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112917},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A novel multi-strategy combined whale optimization algorithm for cascade reservoir operation of complex engineering optimization},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine-learning component for multi-start metaheuristics to
solve the capacitated vehicle routing problem. <em>ASOC</em>,
<em>173</em>, 112916. (<a
href="https://doi.org/10.1016/j.asoc.2025.112916">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Start metaheuristics (MSM) are commonly used to solve vehicle routing problems (VRPs). These methods create different initial solutions and improve them through local-search. The goal of these methods is to deliver the best solution found. We introduce initial-solution classification (ISC) to predict if a local-search algorithm should be applied to initial solutions in MSM. This leads to a faster convergence of MSM and higher-quality solutions when computation time is limited. In this work, we extract features of a capacitated VRP (CVRP) solution, by transforming the structure of a solution into quantitative metrics (i.e.number of customers in each route, average compactness of a route, or number of intersections between routes). With these features and a machine-learning classifier (random forest), we show how ISC – significantly – improves the performance of greedy randomized adaptive search procedure (GRASP), over benchmark instances from the CVRP literature. With the objective of evaluating ISC’s performance with different local-search algorithms, we implemented a local-search composed of classical neighborhoods from the literature and another local-search with only a variation of Ruin-and-Recreate. In both cases, ISC significantly improves the quality of the solutions found in almost all the evaluated instances.},
  archive      = {J_ASOC},
  author       = {Juan Pablo Mesa and Alejandro Montoya and Raul Ramos-Pollan and Mauricio Toro},
  doi          = {10.1016/j.asoc.2025.112916},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112916},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Machine-learning component for multi-start metaheuristics to solve the capacitated vehicle routing problem},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CaRGI: Causal semantic representation learning via
generative intervention for single domain generalization. <em>ASOC</em>,
<em>173</em>, 112910. (<a
href="https://doi.org/10.1016/j.asoc.2025.112910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single Domain Generalization (SDG) is a realistically challenging case in domain generalization, which has only one available source domain and is committed to generalizing the knowledge acquired from this single domain to unseen target domains. Due to the lack of diversity information, data augmentation to expand the data distribution is the mainstream method for SDG. Most low-level data augmentation methods cannot model large domain shifts and simulated domains are fragile, which prevents the model from thoroughly improving the generalization ability. We bridge SDG to causal concepts, novelly analyzing the reason why limited generated domain shifts restrict the improvement of generalization ability from the view of the backdoor path, and propose a causally stable framework CaRGI ( Ca usal Semantic R epresentation Learning via G enerative I ntervention). Firstly, we construct the inclusive causal directed acyclic graph and utilize causal analysis to gradually explore the relationship between the generated domain shift and generalization ability. We regard domain expansion as the causal intervention and secondly propose the joint generative intervention module with dynamic to enlarge the domain shift with semantic consistency, which is dedicated to eliminating spurious confounding effects by blocking the backdoor path. Thirdly, counterfactual inference is applied to implement causal semantic representation learning. In this process, the min–max game in the latent space plays between the generative intervention module and the prediction module, which engage in alternating training that benefit each other in the spiral development. Specially, we innovatively perform maximization and minimization operations in shallow and deep layers respectively. CaRGI can finally learn causal semantic representations and improve the stable generalization ability. Extensive experimental results on several widely used datasets verify the feasibility and effectiveness of the proposed method.},
  archive      = {J_ASOC},
  author       = {Youjia Shao and Shaohui Wang and Wencang Zhao},
  doi          = {10.1016/j.asoc.2025.112910},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112910},
  shortjournal = {Appl. Soft. Comput.},
  title        = {CaRGI: Causal semantic representation learning via generative intervention for single domain generalization},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive trustworthy prototype learning for
multi-modality myocardial pathology segmentation. <em>ASOC</em>,
<em>173</em>, 112909. (<a
href="https://doi.org/10.1016/j.asoc.2025.112909">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modality Myocardial Pathology Segmentation (MyoPS) is essential for assessing risks and planning treatments in myocardial infarction (MI). However, multi-modality myocardial semantic segmentation remains challenging due to the low contrast of pathologic regions between modalities and limited medical training data. To address these issues, we propose C ontrastive TR ustworthy prototype L earning (CTRL) for the dynamic fusion of multi-modality cardiac MRI images. Specifically, CTRL enhances the contrast of intra-modality features by discriminating the intra-modality contribution to the segmentation effect with instance-level confidence and then introduces contrast loss to constrain the modality-specific pathological region features. To incorporate cross-modality information, we combine frequency and spatial domain features to dynamically aggregate global and specific pathological features between modalities and discriminatively aggregate cross-modality semantic expressions. In addition, we constructed a prototype learning memory module to recall multi-modality data a priori, which enables the model to retain essential information to leverage limited data fully. Extensive experimental results on the available MyoPS 2020 dataset for myocardial pathology segmentation demonstrate that CTRL outperforms state-of-the-art methods by 1.6% and can be adapted for heterogeneous medical image representation.},
  archive      = {J_ASOC},
  author       = {Jingjing Liu and Ao Wei and Lijuan Cao and Xiao He and Chang Tang},
  doi          = {10.1016/j.asoc.2025.112909},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112909},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Contrastive trustworthy prototype learning for multi-modality myocardial pathology segmentation},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An advanced ensemble framework for defending against
obfuscated windows, android, and IoT malware. <em>ASOC</em>,
<em>173</em>, 112908. (<a
href="https://doi.org/10.1016/j.asoc.2025.112908">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection and analysis of malware binaries pose significant challenges due to their obfuscated and packed nature, rendering traditional static analysis techniques ineffective. Extracting static features in a dynamic environment where malware exhibits its actual behavior becomes crucial to detecting malware accurately. This article addresses this challenge by analyzing static features extracted from real-time Windows, Android, and IoT applications within a dynamic environment. To tackle this problem, we propose an Advanced Ensemble Framework (AEF) that combines embedded feature selection and an advanced stacking ensemble technique. The embedded feature selection approach effectively reduces the number of highly correlated features by over 70%, employing a combination of filter and wrapper methods. Furthermore, the advanced stacking ensemble approach combines two-level learners: a base learner with state-of-the-art classifiers adept at handling raw features and meta-learner trains using transfer features and probabilities obtained from the previous base classifiers. A 5-fold cross-training scheme based on cross-validation is introduced to prevent overfitting during the training. It also helps to reduce overfitting by training the model on multiple subsets of the data. The model learns patterns from different parts of the dataset, which can lead to a more generalized model. Pre-processed datasets from the Canadian Institute of Cybersecurity comprising obfuscated Windows malware, Android malware, and IoT malicious attacks are used to evaluate AEF. Additionally, to further assess the efficiency, compatibility, and robustness of AEF, we utilized an additional dataset of obfuscated Windows malware that includes memory dump images. Extensive experiments are conducted to evaluate the proposed defender using publicly available real-time datasets. The results show that AEF effectively counters obfuscation techniques, offering a flexible, practical, and efficient solution for malware detection across various datasets. Furthermore, the prediction time of the proposed approach is 0 . 042 ms for CICMalDroid-2020, 0 . 16 ms for IoMT-2024, 0 . 055 ms for CIC-MalMemory-2022, and 0 . 15 ms for Dumpaware10 malware datasets.},
  archive      = {J_ASOC},
  author       = {Danish Vasan and Junaid Akram and Mohammad Hammoudeh and Adel F. Ahmed},
  doi          = {10.1016/j.asoc.2025.112908},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112908},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An advanced ensemble framework for defending against obfuscated windows, android, and IoT malware},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention-based backdoor attacks against natural language
processing models. <em>ASOC</em>, <em>173</em>, 112907. (<a
href="https://doi.org/10.1016/j.asoc.2025.112907">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Backdoor attacks against natural language processing (NLP) models are surging with enhanced attack success rates. However, these backdoor attacks are limited in sentence fluency, grammar errors, and stealthiness. To address these issues, this study proposes an attention-based backdoor attack that generates high-quality backdoor-poisoned samples. The proposed backdoor employs class activation mapping (CAM) to generate backdoor texts with a baseline convolutional neural network in two steps: trigger generation and trigger insertion. The trigger generation leverages high-frequency words as candidate trigger patterns that are subsequently used to generate poisoned texts with high stealthiness and effectiveness. These candidate words are then inserted into computed positions of clean texts, under a low poisoning rate, based on available positions computed with the CAM-based attention method. Through extensive experiments on five benchmark datasets, the proposed CAM-based backdoor attack demonstrates a more excellent performance than the other five backdoor attacks from multiple aspects, including utility, effectiveness, and stealthiness. The proposed method is more robust than other attacks because it maintains almost the highest attack success rate against four benchmark defense methods.},
  archive      = {J_ASOC},
  author       = {Yunchun Zhang and Qi Wang and Shaohui Min and Ruifeng Zuo and Feiyang Huang and Hao Liu and Shaowen Yao},
  doi          = {10.1016/j.asoc.2025.112907},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112907},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Attention-based backdoor attacks against natural language processing models},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy-preserving federated UAV data collection framework
for autonomous path optimization in maritime operations. <em>ASOC</em>,
<em>173</em>, 112906. (<a
href="https://doi.org/10.1016/j.asoc.2025.112906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring data privacy and operational security has become critical in light of escalating cyber threats and the logistical complexity of autonomous maritime operations. Autonomous maritime systems face such challenges in securely processing and managing large amounts of real-time data while maintaining resilience against cyber attacks. This paper considers these challenges by presenting a federated privacy-preserving UAV data collection framework to optimize autonomous path planning and protect sensitive maritime information. Using UAVs as edge nodes for decentralized data processing allows the framework to integrate federated learning, maintain data privacy, and improve cybersecurity. The proposed framework contains five distinct layers, where the data collection layer’s role is to collect real-time data on vessel and environmental conditions. The privacy-preserving edge intelligence layer enables secure localized data processing at the edge. The threat mitigation and optimization layer performs machine learning models for route optimization and intrusion detection. The orchestration layer is implemented to coordinate UAV operations and manages aggregated model parameters for system-wide efficiency, whereas the user interaction layer provides operators with secure, real-time insights into system performance and operational metrics. Simulations and implementations demonstrate that this multilayered architecture improves route accuracy, fortifies data security, and achieves a 20% reduction in emissions, underscoring its potential to advance autonomous navigation and secure, efficient mission planning in maritime cyber–physical systems. The proposed edge-intelligent federated UAV system demonstrates superior performance compared to other approaches, achieving the highest accuracy (99.1%), F1 score (98.9%), and recall (99.3%), while utilizing a larger hybrid dataset (80,000 samples) with 30 features, optimized through principal component analysis, and addressing multiple target attributes such as C O 2 emissions, energy efficiency, and route accuracy.},
  archive      = {J_ASOC},
  author       = {Wei Min and Mohammed Saleh Ali Muthanna and Maha Ibrahim and Reem Alkanhel and Ammar Muthanna and Abdelkader Laouid},
  doi          = {10.1016/j.asoc.2025.112906},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112906},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Privacy-preserving federated UAV data collection framework for autonomous path optimization in maritime operations},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unknown web attack threat detection based on large language
model. <em>ASOC</em>, <em>173</em>, 112905. (<a
href="https://doi.org/10.1016/j.asoc.2025.112905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unknown attacks pose a significant threat to current cyber defenses. Traditional methods for detecting abnormal user behaviors rely on explicit associations and content information, often overlooking implicit causal relationships. Additionally, the frequent emergence of new attack types and the scarcity of training data limit their effectiveness. The paper proposes a novel approach for detecting abnormal user behaviors using large language models (LLMs), addressing these challenges under low-resource conditions. Our method extracts implicit causal relationships from system logs to build behavior graphs and employs label-free graph contrastive invariant learning to generate causal feature vectors. A multi-agent framework, including narrator and decision-maker agents, is used to improve descriptive text generation, while the Translator more efficiently converts causal vectors into meaningful descriptions. Experimental results on the WAB-dataset demonstrate that implicit causal relationships enhance the graph structure’s ability to represent abnormal behaviors. The integration of LLMs enables superior behavior analysis with fewer resources compared to traditional methods. Additionally, the comprehensibility of the generated texts and the efficiency of the Translator provide a strong foundation for supporting security professionals in understanding and analyzing abnormal behaviors in real-world scenarios.},
  archive      = {J_ASOC},
  author       = {Yijia Xu and Qiang Zhang and Huaxin Deng and Zhonglin Liu and Cheng Yang and Yong Fang},
  doi          = {10.1016/j.asoc.2025.112905},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112905},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Unknown web attack threat detection based on large language model},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A simplified swarm optimization-based restricted boltzmann
machine algorithm for a time series clustering. <em>ASOC</em>,
<em>173</em>, 112903. (<a
href="https://doi.org/10.1016/j.asoc.2025.112903">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series clustering is an important area of research, driven by the prevalence of time series data in domains such as power and maintenance data. However, most existing clustering algorithms are not specialized for time series data. Therefore, this study introduces a metaheuristics-based approach, utilizing a restricted Boltzmann machine (RBM) for feature extraction in time series clustering. The RBM, a neural network algorithm with two layers and undirected weights, is kept simple to avoid complex parameter settings. The study employs the RBM as an encoder, coupled with a K -step contrastive divergence and an improved, simplified swarm optimization (iSSO) algorithm for training. The proposed hybrid of iSSO-based RBM and K -means algorithm is compared with RBM and particle swarm optimization-based RBM across the tested time series datasets. Results indicate that the proposed algorithm yields superior performance, reconstructing time series data with minimal error and achieving the highest clustering accuracy compared to other baseline algorithms.},
  archive      = {J_ASOC},
  author       = {Ferani E. Zulvia and R.J. Kuo},
  doi          = {10.1016/j.asoc.2025.112903},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112903},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A simplified swarm optimization-based restricted boltzmann machine algorithm for a time series clustering},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent decision making under conflicting and
cooperative scenarios with incomplete information. <em>ASOC</em>,
<em>173</em>, 112898. (<a
href="https://doi.org/10.1016/j.asoc.2025.112898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the real business world, banks and firms often need to make decisions under uncertainty using incomplete information. In this study, an intelligent game arena will be established to demonstrate the dynamic decision process with information asymmetry under heterogeneous competition scenarios (Conflicting and Cooperative). The game is such implemented that actions (drawn from a serial of real policies) and the consequenced rewards for banks and firms are first to be linked by a Hybrid Archimedean Copula ( HAC ). Then, the HAC would be further optimized by the Multi-objective Integer Quadratic Programming ( MIQP ) in order to mimic the dynamic decision process in the true business environment. Finally, a Double Deep-Q Network ( DDQN ) algorithm is used to simulate dynamic decision processes. The intelligent dynamic game presented in this study not only shows the outcomes (optimal rewards, actions, and competition strategies) resulting from authenic dynamic human rational intelligent decision-making processes under conflicting and cooperative competitions scenarios with incomplete information, both also give the probabilities of taking such actions and strategies in order to reach the optimal long-term rewards. The area goes one step forward by presenting the entire convergence processes of the games before they could reach equilibriums based on heterogeneous actions and strategies. As a result, the framework proposed in this study would offer a transparent experimentable arena to dissect the black-boxed human decision-making process in the real business world and thus might be of importance for studying organizational behaviors, operations, and strategies.},
  archive      = {J_ASOC},
  author       = {Chang Liu and Bowen Deng and Xuancheng Ye and Min Guo},
  doi          = {10.1016/j.asoc.2025.112898},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112898},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Intelligent decision making under conflicting and cooperative scenarios with incomplete information},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SDSINet: A spatiotemporal dual-scale interaction network for
traffic prediction. <em>ASOC</em>, <em>173</em>, 112892. (<a
href="https://doi.org/10.1016/j.asoc.2025.112892">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic forecasting is essential for smart city development. However, existing spatiotemporal modeling methods often face significant challenges, including limitations in handling complex temporal dependencies, capturing multiscale spatial relationships, and modeling the interaction between temporal and spatial features. These challenges arise due to the reliance on extended historical data, fixed adjacency matrices, and the lack of dynamic spatiotemporal interaction modeling. To address these issues, we propose the Spatiotemporal Dual-Scale Interaction Network (SDSINet). SDSINet introduces an implicit temporal information enhancement method that embeds temporal identity information into feature representations, reducing the computational overhead and improving the modeling of global temporal features. Additionally, SDSINet integrates a dynamic multiscale spatial modeling approach that combines adaptive and scale-specific graphs, enabling the model to capture both local and global spatial dependencies. Furthermore, SDSINet incorporates a dual-scale spatiotemporal interaction learning framework that captures short-term and long-term temporal dependencies as well as multiscale spatial correlations. Extensive experiments on real-world datasets – traffic flow (PeMS04), speed (PeMSD7(M)), and demand (NYCBike Drop-off/Pick-up) – demonstrate that SDSINet outperforms existing state-of-the-art methods in prediction accuracy and computational efficiency. Notably, SDSINet achieves a 14.03% reduction in MAE on the NYCBike Drop-off dataset compared to AFDGCN, setting a new benchmark for traffic forecasting.},
  archive      = {J_ASOC},
  author       = {Shiyu Yang and Qunyong Wu},
  doi          = {10.1016/j.asoc.2025.112892},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112892},
  shortjournal = {Appl. Soft. Comput.},
  title        = {SDSINet: A spatiotemporal dual-scale interaction network for traffic prediction},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Many-objective optimisation of offshore wind farms.
<em>ASOC</em>, <em>173</em>, 112879. (<a
href="https://doi.org/10.1016/j.asoc.2025.112879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design of offshore wind farms is computationally challenging, requiring the simultaneous optimisation of many conflicting objectives. Solving this problem is of paramount importance if society is to meet ambitious net zero goals. The problem is solved by identifying an optimal arrangement of individual turbines such that all objectives are optimised. However, a single solution does not exist due to the inherent conflict between objectives, and a set of solutions must be identified. As well as the challenge in generating optimal solution sets, there exists a decision support task if the solutions are to be effectively presented to a decision maker. This study focuses on six key objectives: wind farm efficiency, annual energy production, electric cable length, number of wind turbines, levelised cost of energy, and total area. Two evolutionary algorithms, NSGA-II and NSGA-III, were employed to explore the solution space efficiently. Performance evaluation was performed using spacing, generational distance, and hypervolume metrics. The aforementioned algorithms and metrics were applied to three wind farm layouts: a discrete layout and two continuous layouts. The NSGA-III algorithm was shown to perform better than its predecessor (NSGA-II). The difference was small, albeit significant. Previous works (e.g., Rodrigues et al. (2016); Mytilinou and Kolios (2017)) in which many-objective optimisations were discussed provided little insight into the visualisation and interpretation of the results. While the mentioned work used parallel coordinate plots, this work provides a deeper insight by presenting the results via Principal Component Analysis (PCA) and Multi Dimensional Scaling (MDS) plots. The best solution, containing 6188 wind farm layouts, was found by the NSGA-III algorithm on a continuous wind farm layout with repair mechanism. From the best solution, the wind farms containing 27, 102 and 160 wind turbines were selected and compared with the real wind farms located around the UK. It was demonstrated that the optimiser could identify better wind farm layouts concerning annual energy production, efficiency, and LCOE than the real wind farm layouts of Rhyl Flats and Greater Gabbard.},
  archive      = {J_ASOC},
  author       = {Pawel L. Manikowski and Matthew J. Craven and David J. Walker},
  doi          = {10.1016/j.asoc.2025.112879},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112879},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Many-objective optimisation of offshore wind farms},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Collaborative transformer u-shaped network for medical image
segmentation. <em>ASOC</em>, <em>173</em>, 112841. (<a
href="https://doi.org/10.1016/j.asoc.2025.112841">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in the Transformer have shown significant ability to understand the relationship between the lesion area and surrounding tissue, especially for medical image analysis. Existing medical image segmentation algorithms based on transformers often suffer from limited feature extraction granularity and overlook the semantic relationships between multi-scale features. To solve the above limitations, we propose CoTransUNet: a collaborative transformer U-shaped network, that effectively captures fine-grained features and long-range dependencies by performing context extraction between multiple scales. The designed Correlation Extraction (CE) module bridges the encoder and decoder to achieve effective interaction and information transfer. Specifically, a collaborative mechanism in the encoder is proposed that can efficiently exploit inductive bias to extract local fine-grained features of the image while having the ability to capture long-distance feature dependencies. Besides, the CE module focuses on deeply integrating contextual information of multi-scale features, which enriches feature representation by exploiting the intrinsic correlation between features at different scales. It can extract not only local and global features but also capture semantic information related to different multi-scale features simultaneously. Compared to TransUNet, CoTransUNet achieves a 4.91% improvement in DSC on the Synapse multi-organ segmentation dataset while using only a quarter of the parameters. The extensive experiments on three datasets, including skin lesion segmentation (ISIC2016, ISIC2017, ISIC2018) demonstrates that CoTransUNet achieves DSC scores of 92.18%, 85.59%, and 88.75%, respectively, and on Synapse multi organ segmentation achieves DSC score of 82.39% , which outperforms the baseline and other promising methods.},
  archive      = {J_ASOC},
  author       = {Yufei Gao and Shichao Zhang and Lei Shi and Guohua Zhao and Yucheng Shi},
  doi          = {10.1016/j.asoc.2025.112841},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112841},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Collaborative transformer U-shaped network for medical image segmentation},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A two-stage coevolutionary algorithm based on adaptive
weights for complex constrained multiobjective optimization.
<em>ASOC</em>, <em>173</em>, 112825. (<a
href="https://doi.org/10.1016/j.asoc.2025.112825">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the constrained multiobjective optimization problems (CMOPs), various complex constraints need to be satisfied simultaneously, which further challenges evolutionary algorithms in balancing feasibility, convergence and diversity. Recent advances in evolutionary computation have led to the development of multi-stage and multi-population strategies for handling CMOPs. However, most algorithms have shown poor performance when dealing with problems with low feasible ratio or discontinuous feasible regions. To address this issue, we propose a two-stage coevolutionary algorithm based on adaptive weights (AW-TCEA), aiming to balance convergence, diversity and feasibility to handle CMOPs with complex Pareto fronts (PFs). Specifically, the first stage uses two populations to explore the objective space and feasible regions respectively, one driven by objective information and the other by feasible information. The second stage adopts a set of weight vectors to search for unexplored feasible regions to enhance diversity. In addition, for handling complex constrained PFs, a novel adaptive weight adjustment strategy is proposed to explore ineffective directions and develop potential regions. Experimental comparisons with multiple state-of-the-art algorithms are performed on 50 test problems and 5 real-world problems. The results show that the proposed algorithm exhibits better performance on various CMOPs.},
  archive      = {J_ASOC},
  author       = {Guangpeng Li and Li Li and Guoyong Cai},
  doi          = {10.1016/j.asoc.2025.112825},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112825},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A two-stage coevolutionary algorithm based on adaptive weights for complex constrained multiobjective optimization},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A TG-AGD anomaly image detection model based on residual
bottleneck attention and time series prediction. <em>ASOC</em>,
<em>173</em>, 112746. (<a
href="https://doi.org/10.1016/j.asoc.2025.112746">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection is a crucial task in the field of deep learning, with applications in security monitoring, quality control, and medical diagnosis. However, existing anomaly detection methods often consume significant computational resources, leading to premature bottlenecks. This study proposes an anomaly image detection method based on residual bottleneck attention integrated with time series prediction. Initially, the study explores several common time series prediction models and establishes a time prediction model tailored to the abnormal characteristics of images. It then examines the limitations of current attention mechanisms in anomaly detection. The proposed method combines the most widely applicable and effective residual bottleneck processing with the previously developed time series prediction model to create the TG-AGD anomaly image detection model. Extensive experiments were conducted using detailed anomaly image data from various fields. The results indicate that the TG-AGD anomaly image detection model significantly outperforms traditional single time series prediction or attention mechanism approaches, demonstrating high accuracy and robustness in detecting anomalies.},
  archive      = {J_ASOC},
  author       = {Yang Li and Suqin Xiong and Qiuyang Li and Zhiru Chen},
  doi          = {10.1016/j.asoc.2025.112746},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112746},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A TG-AGD anomaly image detection model based on residual bottleneck attention and time series prediction},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="autom---33">AUTOM - 33</h2>
<ul>
<li><details>
<summary>
(2025). External bias and opinion clustering in cooperative
networks. <em>AUTOM</em>, <em>175</em>, 112224. (<a
href="https://doi.org/10.1016/j.automatica.2025.112224">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we consider a group of n agents which interact with each other in a cooperative framework. A Laplacian-based model is proposed to govern the evolution of opinions in the group when the agents are subjected to external biases like agents’ traits, news, etc . The objective of the paper is to design a control input which leads to any desired opinion clustering even in the presence of external bias factors. Further, we also determine the conditions which ensure the reachability to any arbitrary opinion states. Note that all of these results hold for any kind of graph structure. Finally, some numerical simulations are discussed to validate these results.},
  archive      = {J_AUTOM},
  author       = {Akshay Nagesh Kamthe and Vishnudatta Thota and Aashi Shrinate and Twinkle Tripathy},
  doi          = {10.1016/j.automatica.2025.112224},
  journal      = {Automatica},
  month        = {5},
  pages        = {112224},
  shortjournal = {Automatica},
  title        = {External bias and opinion clustering in cooperative networks},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal transport of linear systems over equilibrium
measures. <em>AUTOM</em>, <em>175</em>, 112222. (<a
href="https://doi.org/10.1016/j.automatica.2025.112222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the optimal transport problem over convex costs arising from optimal control of linear time-invariant(LTI) systems when the initial and target measures are assumed to be supported on the set of equilibrium points of the LTI system. In this case, the probability measures are singular with respect to the Lebesgue measure, thus not considered in previous results on optimal transport of linear systems. This problem is motivated by applications, such as robotics, where the initial and target configurations of robots, represented by measures, are in equilibrium or stationary. Despite the singular nature of the measures, for many cases of practical interest, we show that the Monge problem has a solution by applying classical optimal transport results. Moreover, the problem is computationally tractable even if the state space of the LTI system is moderately high in dimension, provided the equilibrium set lives in a low dimensional space. In fact, for an important subclass of minimum energy problems, such as control of the double integrator with minimum energy cost, the optimal transport map happens to coincide with that of the square Euclidean cost. We demonstrate our results by computing the optimal transport map for the minimum energy cost for a two dimensional double integrator, despite the fact that the state space is four dimensional due to position and velocity variables.},
  archive      = {J_AUTOM},
  author       = {Karthik Elamvazhuthi and Matt Jacobs},
  doi          = {10.1016/j.automatica.2025.112222},
  journal      = {Automatica},
  month        = {5},
  pages        = {112222},
  shortjournal = {Automatica},
  title        = {Optimal transport of linear systems over equilibrium measures},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gaussian framework for nonlinear state estimation with
stochastic event-trigger and packet losses. <em>AUTOM</em>,
<em>175</em>, 112220. (<a
href="https://doi.org/10.1016/j.automatica.2025.112220">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonlinear state estimation with stochastic event-trigger and packet losses is studied in this paper. To handle the nonlinearity and the uncertainty of the available information, the recursive probability density functions (PDFs) are characterized as Gaussian. Then, an event-trigger and packet losses induced Gaussian filter (EPGF) and its Gaussian smoother (EPGS) are derived to develop a new Gaussian framework. This developed framework is an extension of the standard Gaussian one and suitable for both linear and nonlinear systems. The key to its implementation is calculating a series of integrals with the Gaussian weight form, which can be approximated by various numerical techniques. In addition, according to the rule of three-degree spherical-radial cubature, two specific filtering and smoothing algorithms of the proposed framework are presented. Finally, a numerical simulation illustrates the effectiveness of the developed scheme.},
  archive      = {J_AUTOM},
  author       = {Weijun Lv and Chang Liu and Yong Xu and Renquan Lu and Ling Shi},
  doi          = {10.1016/j.automatica.2025.112220},
  journal      = {Automatica},
  month        = {5},
  pages        = {112220},
  shortjournal = {Automatica},
  title        = {Gaussian framework for nonlinear state estimation with stochastic event-trigger and packet losses},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). State prediction using a high-gain distributed scheme.
<em>AUTOM</em>, <em>175</em>, 112219. (<a
href="https://doi.org/10.1016/j.automatica.2025.112219">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time delays pose unique challenges in control engineering, as inherent delays can introduce instabilities and compromise system performance. To overcome these complexities, the concept of predictors or compensators has been instrumental in stabilising closed-loop systems. Still, it requires an accurate delayed state estimation through the design and implementation of predictors. In this paper, we delve into the design of novel prediction architectures tailored to nonlinear systems with input and output delays that not only ensure stability but also bolster robustness, emphasising their ability to preserve stability despite measurement noises or external perturbations.},
  archive      = {J_AUTOM},
  author       = {Mathieu Bajodek and Fernando Castaños and Sabine Mondié},
  doi          = {10.1016/j.automatica.2025.112219},
  journal      = {Automatica},
  month        = {5},
  pages        = {112219},
  shortjournal = {Automatica},
  title        = {State prediction using a high-gain distributed scheme},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A critical escape probability formulation for enhancing the
transient stability of power systems with system parameter design.
<em>AUTOM</em>, <em>175</em>, 112217. (<a
href="https://doi.org/10.1016/j.automatica.2025.112217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the enhancement of the transient stability of power systems, the key is to define a quantitative optimization formulation with system parameters as decision variables. In this paper, we model the disturbances by Gaussian noise and define a metric named Critical Escape Probability (CREP) based on the invariant probability measure of a linearized stochastic process. CREP characterizes the probability of the state escaping from a critical set. CREP involves all the system parameters and reflects the size of the basin of attraction of the nonlinear systems. An optimization framework that minimizes CREP with the system parameters as decision variables is presented. Simulations show that the mean of the first hitting time when the state hits the boundary of the critical set, that is often used to describe the stability of nonlinear systems, is dramatically increased by minimizing CREP. This indicates that the transient stability of the system is effectively enhanced. It is also shown that suppressing the state fluctuations only is insufficient for enhancing the transient stability. In addition, the famous Braess’ paradox which also exists in power systems is revisited. Surprisingly, it turned out that the paradoxes identified by the traditional metric may not exist according to CREP. This new metric opens a new avenue for the transient stability analysis of future power systems integrated with large amounts of renewable energy.},
  archive      = {J_AUTOM},
  author       = {Xian Wu and Kaihua Xi and Aijie Cheng and Chenghui Zhang and Hai Xiang Lin},
  doi          = {10.1016/j.automatica.2025.112217},
  journal      = {Automatica},
  month        = {5},
  pages        = {112217},
  shortjournal = {Automatica},
  title        = {A critical escape probability formulation for enhancing the transient stability of power systems with system parameter design},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal spatial–temporal triangulation for bearing-only
cooperative motion estimation. <em>AUTOM</em>, <em>175</em>, 112216. (<a
href="https://doi.org/10.1016/j.automatica.2025.112216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision-based cooperative motion estimation is an important problem for many multi-robot systems such as cooperative aerial target pursuit. This problem can be formulated as bearing-only cooperative motion estimation, where the visual measurement is modeled as a bearing vector pointing from the camera to the target. The conventional approaches for bearing-only cooperative estimation are mainly based on the framework of distributed Kalman filtering (DKF). In this paper, we propose a new optimal bearing-only cooperative estimation algorithm, named spatial–temporal triangulation, based on the method of distributed recursive least squares. The design of the algorithm fully incorporates all the available information and the specific triangulation geometric constraint. As a result, the algorithm has superior estimation performance than the state-of-the-art DKF algorithms in terms of both accuracy and convergence speed as verified by numerical simulation. We rigorously prove the exponential convergence of the proposed algorithm. Moreover, to verify the effectiveness of the proposed algorithm under practical challenging conditions, we develop a vision-based cooperative aerial target pursuit system, which is the first of such fully autonomous systems up to now to the best of our knowledge.},
  archive      = {J_AUTOM},
  author       = {Canlun Zheng and Yize Mi and Hanqing Guo and Huaben Chen and Zhiyun Lin and Shiyu Zhao},
  doi          = {10.1016/j.automatica.2025.112216},
  journal      = {Automatica},
  month        = {5},
  pages        = {112216},
  shortjournal = {Automatica},
  title        = {Optimal spatial–temporal triangulation for bearing-only cooperative motion estimation},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Flexible-step model predictive control based on generalized
lyapunov functions. <em>AUTOM</em>, <em>175</em>, 112215. (<a
href="https://doi.org/10.1016/j.automatica.2025.112215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel nonlinear model predictive control (MPC) scheme with relaxed stability criteria, based on the idea of generalized discrete-time control Lyapunov functions. These functions need to satisfy an average descent over a finite window of time, rather than a descent at every time step. One feature of this scheme is that it allows for implementing a flexible number of control inputs in each iteration, in a computationally attractive manner, while guaranteeing recursive feasibility and stability. The benefits of our flexible-step implementation are also demonstrated in an application to nonholonomic systems, where the one-step standard implementation may suffer from lack of asymptotic convergence.},
  archive      = {J_AUTOM},
  author       = {Annika Fürnsinn and Christian Ebenbauer and Bahman Gharesifard},
  doi          = {10.1016/j.automatica.2025.112215},
  journal      = {Automatica},
  month        = {5},
  pages        = {112215},
  shortjournal = {Automatica},
  title        = {Flexible-step model predictive control based on generalized lyapunov functions},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maxentropic continuous-time homogeneous markov chains.
<em>AUTOM</em>, <em>175</em>, 112214. (<a
href="https://doi.org/10.1016/j.automatica.2025.112214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the notion of entropy rate and its maximization for continuous-time time-homogeneous irreducible finite-state Markov chains. The definitions available in continuous-time suffer from an apparent paradox, as they do not properly account for the role of the average commutation frequency. In fact, we show that the entropy rate is the sum of a finite and an infinite component, the latter depending on the average commutation frequency. Thus, entropy maximization is meaningful only between chains that share the same average frequency. After settling this issue, we address entropy rate maximization under different constraints on the stationary probability: unconstrained, completely fixed, partially fixed. Closed-form solutions and provably convergent iterative algorithms are provided. The results are illustrated through several examples, including chains with string and lattice graph topology. Interesting connections with quantum mechanics topics (particle-in-a-box model, Born rule, and Anderson localization property) are highlighted.},
  archive      = {J_AUTOM},
  author       = {Paolo Bolzern and Patrizio Colaneri and Giuseppe De Nicolao},
  doi          = {10.1016/j.automatica.2025.112214},
  journal      = {Automatica},
  month        = {5},
  pages        = {112214},
  shortjournal = {Automatica},
  title        = {Maxentropic continuous-time homogeneous markov chains},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed optimal coordination of multi-agent systems with
coupled objective functions: A fixed-time estimation-based approach.
<em>AUTOM</em>, <em>175</em>, 112213. (<a
href="https://doi.org/10.1016/j.automatica.2025.112213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores a class of distributed optimal coordination problems with coupled objectives, incorporating features of distributed optimization and non-cooperative game. In this context, the local objective functions of agents depend on their own decisions as well as the decisions made by other agents. The objective of the agents is to achieve optimal coordination by minimizing the team objective function, which represents the average of all agents’ local objective functions. The main challenge lies in obtaining the partial derivatives of the team objective function, which are aggregations of all local objective functions’ partial derivatives and cannot be directly obtained by the agents. To tackle this problem, distributed optimal coordination control laws based on fixed-time estimation are developed. These control laws utilize distributed fixed-time estimators that enable agents to estimate the team decision and partial derivatives of the team objective function within a fixed time. The proposed distributed optimal coordination control laws guarantee the exponential convergence of the agents to the optimal states when the constraint sets are independent. Under the condition of a common constraint set, the proposed laws further ensure fixed-time optimal coordination. A numerical example involving coordinated dynamic positioning of a multi-agent system is presented to demonstrate the effectiveness of the proposed algorithms.},
  archive      = {J_AUTOM},
  author       = {Xiao Fang and Guanghui Wen},
  doi          = {10.1016/j.automatica.2025.112213},
  journal      = {Automatica},
  month        = {5},
  pages        = {112213},
  shortjournal = {Automatica},
  title        = {Distributed optimal coordination of multi-agent systems with coupled objective functions: A fixed-time estimation-based approach},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic dissipativity for systems with probabilistic
input delays. <em>AUTOM</em>, <em>175</em>, 112212. (<a
href="https://doi.org/10.1016/j.automatica.2025.112212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work considers stochastic operators in Hilbert spaces, and in particular, systems with stochastically time-varying input delays of a known probability distribution. Stochastic dissipativity and stability are defined from an operator-theoretic perspective, and the well-known open-loop dissipativity conditions for closed-loop/network stability are extended to the stochastic case. Criteria are derived to identify dissipative nonlinear systems with stochastic input delays, and this result is used to find delay-distribution-dependent linear matrix inequality conditions for stochastic dissipativity of a linear system with input delays of a known probability distribution. A numerical experiment demonstrates the utility of the resulting criteria for robust plant analysis and controller design, highlighting significantly reduced conservatism compared to deterministic methods.},
  archive      = {J_AUTOM},
  author       = {Ethan J. LoCicero and Amy K. Strong and Leila J. Bridgeman},
  doi          = {10.1016/j.automatica.2025.112212},
  journal      = {Automatica},
  month        = {5},
  pages        = {112212},
  shortjournal = {Automatica},
  title        = {Stochastic dissipativity for systems with probabilistic input delays},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Projection-free computation of robust controllable sets with
constrained zonotopes. <em>AUTOM</em>, <em>175</em>, 112211. (<a
href="https://doi.org/10.1016/j.automatica.2025.112211">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of computing robust controllable sets for discrete-time linear systems with additive uncertainty. We propose a tractable and scalable approach to inner- and outer-approximate robust controllable sets using constrained zonotopes, when the additive uncertainty set is a symmetric, convex, and compact set. Our least-squares-based approach uses novel closed-form approximations of the Pontryagin difference between a constrained zonotopic minuend and a symmetric, convex, and compact subtrahend. We obtain these approximations using two novel canonical representations for full-dimensional constrained zonotopes. Unlike existing approaches, our approach does not rely on convex optimization solvers, and is projection-free for ellipsoidal and zonotopic uncertainty sets. We also propose a least-squares-based approach to compute a convex, polyhedral outer-approximation to constrained zonotopes, and characterize sufficient conditions under which all these approximations are exact. We demonstrate the computational efficiency and scalability of our approach in several case studies, including the design of abort-safe rendezvous trajectories for a spacecraft in near-rectilinear halo orbit under uncertainty. Our approach can inner-approximate a 20-step robust controllable set for a 100-dimensional linear system in under 15 s on a standard computer.},
  archive      = {J_AUTOM},
  author       = {Abraham P. Vinod and Avishai Weiss and Stefano Di Cairano},
  doi          = {10.1016/j.automatica.2025.112211},
  journal      = {Automatica},
  month        = {5},
  pages        = {112211},
  shortjournal = {Automatica},
  title        = {Projection-free computation of robust controllable sets with constrained zonotopes},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accelerated forward–backward and douglas–rachford splitting
dynamics. <em>AUTOM</em>, <em>175</em>, 112210. (<a
href="https://doi.org/10.1016/j.automatica.2025.112210">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We examine convergence properties of continuous-time variants of accelerated Forward–Backward (FB) and Douglas–Rachford (DR) splitting algorithms for nonsmooth composite optimization problems. When the objective function is given by the sum of a quadratic and a nonsmooth term, we establish accelerated sublinear and exponential convergence rates for convex and strongly convex problems, respectively. Moreover, for FB splitting dynamics, we demonstrate that accelerated exponential convergence rate carries over to general strongly convex problems. In our Lyapunov-based analysis we exploit the variable-metric gradient interpretations of FB and DR splittings to obtain smooth Lyapunov functions that allow us to establish accelerated convergence rates. We provide computational experiments to demonstrate the merits and the effectiveness of our analysis},
  archive      = {J_AUTOM},
  author       = {Ibrahim K. Ozaslan and Mihailo R. Jovanović},
  doi          = {10.1016/j.automatica.2025.112210},
  journal      = {Automatica},
  month        = {5},
  pages        = {112210},
  shortjournal = {Automatica},
  title        = {Accelerated forward–backward and Douglas–Rachford splitting dynamics},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven dynamic optimal allocation for uncertain
over-actuated linear systems. <em>AUTOM</em>, <em>175</em>, 112208. (<a
href="https://doi.org/10.1016/j.automatica.2025.112208">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dynamic control allocation problem for LTI systems is addressed in an uncertain setting. In the presence of unstructured uncertainties affecting the underlying plant, a completely data-driven strategy is envisioned to optimally allocate the control action in the presence of non-constant steady-state behavior of the plant, while leaving untouched the regulated output response induced by an a priori given controller. Compared with the current state of the art, the proposed solution exhibits several appealing features. Such features are: complete invisibility of the allocator’s action (after a training interval if the plant is unknown), exact optimization of the periodic steady-state evolution, arbitrary speed of the allocation action; while all of them are achieved even for unknown plants in this paper, in the current literature they are impossible to achieve or just obtainable for a perfectly known plant.},
  archive      = {J_AUTOM},
  author       = {Sergio Galeani and Roberto Masocco and Mario Sassano},
  doi          = {10.1016/j.automatica.2025.112208},
  journal      = {Automatica},
  month        = {5},
  pages        = {112208},
  shortjournal = {Automatica},
  title        = {Data-driven dynamic optimal allocation for uncertain over-actuated linear systems},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive non-cooperative differential games with a
regulator. <em>AUTOM</em>, <em>175</em>, 112201. (<a
href="https://doi.org/10.1016/j.automatica.2025.112201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers linear–quadratic non-cooperative non-zero-sum stochastic differential games with a regulator and analyzes the adaptive problem when the systems matrices are unknown to both the regulator and the players. It is a typical problem of game-based control systems(GBCS) introduced and studied recently, which have a hierarchical decision-making structure. The main purpose of the paper is to study how the adaptive strategies can be designed to make the GBCS globally stable and at the same time to ensure a Nash equilibrium reached by both the regulator and the players. Under some suitable conditions on the system matrices, it is shown that the closed-loop adaptive GBCS will be globally stable, and at the same time reach a Nash equilibrium by both the regulator and the players, where the adaptive strategies are constructed based on the least squares estimator, the switching method and the diminishing excitation.},
  archive      = {J_AUTOM},
  author       = {Nian Liu and Shaolin Tan and Ye Tao and Jinhu Lü},
  doi          = {10.1016/j.automatica.2025.112201},
  journal      = {Automatica},
  month        = {5},
  pages        = {112201},
  shortjournal = {Automatica},
  title        = {Adaptive non-cooperative differential games with a regulator},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed online path-length-independent algorithm for
noncooperative games over unbalanced digraphs. <em>AUTOM</em>,
<em>175</em>, 112200. (<a
href="https://doi.org/10.1016/j.automatica.2025.112200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies online noncooperative games with dynamic regrets. Existing online noncooperative games rely on the sublinear growth of the path-length of Nash equilibrium sequences when considering dynamic regrets, which implies that their cost functions cannot be rapidly time-varying. Moreover, most of related results depend on undirected communication graphs. However, in many engineering practices, the cost functions may change greatly over time and the communication graphs may be directed. Here our problem involves rapidly time-varying cost functions, i.e., the path-length of Nash equilibrium sequences at least linearly grows, and the interaction topologies are unbalanced digraphs. In order to make decisions online without regrets, we develop a distributed algorithm based on multi-step mirror descents. Under the algorithm, sublinear dynamic regret bounds are established. More importantly, the dynamic regrets are independent of the path-length of Nash equilibrium sequences, compared with existing results. Finally, the simulation results validate the effectiveness of our algorithm, and demonstrate that our algorithm has better performance than other related algorithms.},
  archive      = {J_AUTOM},
  author       = {Zhenhua Deng},
  doi          = {10.1016/j.automatica.2025.112200},
  journal      = {Automatica},
  month        = {5},
  pages        = {112200},
  shortjournal = {Automatica},
  title        = {Distributed online path-length-independent algorithm for noncooperative games over unbalanced digraphs},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Power and bit scheduling of markov jump systems with
convergence rate as an optimization index. <em>AUTOM</em>, <em>175</em>,
112199. (<a
href="https://doi.org/10.1016/j.automatica.2025.112199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing power and bit scheduling algorithms mostly focus on open-loop system performance, i.e., improving estimation accuracy. This paper focuses on the scheduling methods for the closed-loop Markov jump systems in the unreliable transmission environments to improve the system stability and save energy. First, a control unit including feedback controller and predictive controller is proposed which improves the system performance while reducing the complexity of predictive controller design. Second, we design a novel optimization indicator based on time-varying convergence rate and sensor energy consumption. Third, by analyzing the relationship between Lyapunov function and the system state, an explicit expression of the time-varying convergence rate is gained. Next, a constant χ is introduced to obtain the effective power set, in which the convergence rate is always less than 1, thereby ensuring the system stability. Based on this, the optimal power and bit scheduling algorithm is obtained, which improves the system convergence speed while reducing energy consumption. Last, a two-tanks system is used to verify the effectiveness and superiority of the main algorithms.},
  archive      = {J_AUTOM},
  author       = {Jingjing Yan and Yuanqing Xia and Xinjing Wang and Li Ma},
  doi          = {10.1016/j.automatica.2025.112199},
  journal      = {Automatica},
  month        = {5},
  pages        = {112199},
  shortjournal = {Automatica},
  title        = {Power and bit scheduling of markov jump systems with convergence rate as an optimization index},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DualBi: A dual bisection algorithm for non-convex problems
with a scalar complicating constraint. <em>AUTOM</em>, <em>175</em>,
112198. (<a
href="https://doi.org/10.1016/j.automatica.2025.112198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses non-convex constrained optimization problems that are characterized by a scalar complicating constraint. We propose an iterative bisection method for the dual problem (DualBi Algorithm) that recovers a feasible primal solution, with a performance that progressively improves throughout iterations. Application to multi-agent problems with a scalar coupling constraint results in a decentralized resolution scheme where a central unit is in charge of updating the (scalar) dual variable while agents compute their local primal variables. In the case of multi-agent MILPs, simulations showcase the performance of the proposed method compared with state-of-the-art duality-based approaches.},
  archive      = {J_AUTOM},
  author       = {Lucrezia Manieri and Alessandro Falsone and Maria Prandini},
  doi          = {10.1016/j.automatica.2025.112198},
  journal      = {Automatica},
  month        = {5},
  pages        = {112198},
  shortjournal = {Automatica},
  title        = {DualBi: A dual bisection algorithm for non-convex problems with a scalar complicating constraint},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Direct data-driven discounted infinite horizon linear
quadratic regulator with robustness guarantees. <em>AUTOM</em>,
<em>175</em>, 112197. (<a
href="https://doi.org/10.1016/j.automatica.2025.112197">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a one-shot learning approach with performance and robustness guarantees for the linear quadratic regulator (LQR) control of stochastic linear systems. Even though data-based LQR control has been widely considered, existing results suffer either from data hungriness due to the inherently iterative nature of the optimization formulation (e.g., value learning or policy gradient reinforcement learning algorithms) or from a lack of robustness guarantees in one-shot non-iterative algorithms. To avoid data hungriness while ensuing robustness guarantees, an adaptive dynamic programming formalization of the LQR is presented that relies on solving a Bellman inequality. The control gain and the value function are directly learned by using a control-oriented approach that characterizes the closed-loop system using data and a decision variable from which the control is obtained. This closed-loop characterization is noise-dependent. The effect of the closed-loop system noise on the Bellman inequality is considered to ensure both robust stability and suboptimal performance despite ignoring the measurement noise. To ensure robust stability, it is shown that this system characterization leads to a closed-loop system with multiplicative and additive noise, enabling the application of distributional robust control techniques. The analysis of the suboptimality gap reveals that robustness can be achieved by construction without the need for regularization or parameter tuning. The simulation results on the active car suspension problem demonstrate the superiority of the proposed method in terms of robustness and performance gap compared to existing methods.},
  archive      = {J_AUTOM},
  author       = {Ramin Esmzad and Hamidreza Modares},
  doi          = {10.1016/j.automatica.2025.112197},
  journal      = {Automatica},
  month        = {5},
  pages        = {112197},
  shortjournal = {Automatica},
  title        = {Direct data-driven discounted infinite horizon linear quadratic regulator with robustness guarantees},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the detection of markov decision processes.
<em>AUTOM</em>, <em>175</em>, 112196. (<a
href="https://doi.org/10.1016/j.automatica.2025.112196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the detection problem for a finite set of Markov decision processes (MDPs) where the MDPs have the same state and action spaces but possibly different probabilistic transition functions. Any one of these MDPs could be the model for some underlying controlled stochastic process, but it is unknown a priori which MDP is the ground truth. We investigate whether it is possible to asymptotically detect the ground truth MDP model perfectly based on a single observed history (state–action sequence). Since the generation of histories depends on the policy adopted to control the MDPs, we discuss the existence and synthesis of policies that allow for perfect detection. We start with the case of two MDPs and establish a necessary and sufficient condition for the existence of policies that lead to perfect detection. Based on this condition, we then develop an algorithm that efficiently (in time polynomial in the size of the MDPs) determines the existence of policies and synthesizes one when they exist. We further extend the results to the more general case where there are more than two MDPs in the candidate set, and we develop a policy synthesis algorithm based on the breadth-first search and recursion. We demonstrate the effectiveness of our algorithms through numerical examples.},
  archive      = {J_AUTOM},
  author       = {Xiaoming Duan and Yagiz Savas and Rui Yan and Zhe Xu and Ufuk Topcu},
  doi          = {10.1016/j.automatica.2025.112196},
  journal      = {Automatica},
  month        = {5},
  pages        = {112196},
  shortjournal = {Automatica},
  title        = {On the detection of markov decision processes},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-informed neural network lyapunov functions: PDE
characterization, learning, and verification. <em>AUTOM</em>,
<em>175</em>, 112193. (<a
href="https://doi.org/10.1016/j.automatica.2025.112193">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide a systematic investigation of using physics-informed neural networks to compute Lyapunov functions. We encode Lyapunov conditions as a partial differential equation (PDE) and use this for training neural network Lyapunov functions. We analyze the analytical properties of the solutions to the Lyapunov and Zubov PDEs. In particular, we show that employing the Zubov equation in training neural Lyapunov functions can lead to verifiable approximate regions of attraction close to the true domain of attraction. We also examine approximation errors and the convergence of neural approximations to the unique solution of Zubov’s equation. We then provide sufficient conditions for the learned neural Lyapunov functions that can be readily verified by satisfiability modulo theories (SMT) solvers, enabling formal verification of both local stability analysis and region-of-attraction estimates in the large. Through a number of nonlinear examples, ranging from low to high dimensions, we demonstrate that the proposed framework can outperform traditional sum-of-squares (SOS) Lyapunov functions obtained using semidefinite programming (SDP).},
  archive      = {J_AUTOM},
  author       = {Jun Liu and Yiming Meng and Maxwell Fitzsimmons and Ruikun Zhou},
  doi          = {10.1016/j.automatica.2025.112193},
  journal      = {Automatica},
  month        = {5},
  pages        = {112193},
  shortjournal = {Automatica},
  title        = {Physics-informed neural network lyapunov functions: PDE characterization, learning, and verification},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scheduling-based stabilization for networked stochastic
systems with control-dependent noise. <em>AUTOM</em>, <em>175</em>,
112192. (<a
href="https://doi.org/10.1016/j.automatica.2025.112192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Communication constraint is prominent under the networked architecture, for which the scheduling problem needs to be considered. This paper aims at validating scheduling-based stabilization for networked stochastic systems (NSSs) characterized by the presence of control-dependent noise. Remarkably, control-dependent noise has never been taken into account in the context of scheduling-based control. Such noise has intricate impact on system stability, and should not be simply treated as an unfavorable factor. As such, sophisticated analysis is entailed for scheduling-based control in the stochastic setting. However, no available theory on stochastic stability could support the application of dynamic scheduling protocols confronted with control-dependent noise, while the case via static scheduling protocols can resort to the existing results on stochastic differential equations with bounded-delay dependent diffusion coefficients. As the main contribution, a framework of scheduling-based stabilization is established for the NSSs, covering the architecture where a certain dynamic protocol rules the scheduling of sensor-to-controller information transmission. Crucially, a distinct pattern of stability analysis is proposed based on delicate comparison between the solutions under scheduling-based (discrete-time) and network-free (continuous-time) controls. As a consequence, an intrinsic relation between the system stability rendered by two types of controls is revealed, with the network-induced error on measured output suitably exploited. Based on the relation, we further propose several directly-verifiable conditions of achieving almost sure exponential stability for the NSSs with scheduling-based control via try-once-discard protocol, the most typical one among dynamic scheduling protocols. Particularly, incorporating the underlying positive effect of the stochastic noise, one of the conditions allows the Lyapunov function candidates to have non-negative infinitesimal under corresponding continuous-time control, while no counterpart exists in the non-stochastic setting.},
  archive      = {J_AUTOM},
  author       = {Fengzhong Li and Yungang Liu},
  doi          = {10.1016/j.automatica.2025.112192},
  journal      = {Automatica},
  month        = {5},
  pages        = {112192},
  shortjournal = {Automatica},
  title        = {Scheduling-based stabilization for networked stochastic systems with control-dependent noise},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust model reference adaptive control for square MIMO LTI
systems with uniform vector relative degree of zero. <em>AUTOM</em>,
<em>175</em>, 112190. (<a
href="https://doi.org/10.1016/j.automatica.2025.112190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a systematic procedure for robust model reference adaptive control design for uncertain square multiple-input multiple-output (MIMO) continuous-time linear time-invariant (LTI) systems that admit uniform vector relative degree of zero, under the assumptions of minimum phase and that the upper bounds for the observability indices of all measurement channels are known. We assume that the unknown parameter vector lies in a convex compact set such that the high-frequency gain matrix remains invertible for any parameter vector value in the set. These assumptions allow for a successful design of a robust model reference adaptive controller. A numerical example is included to fully illustrate the controller design and the effectiveness of the controller. As compared with the recent paper Pan and Başar (2023), the problem with uniform vector relative degree of zero allows us to relieve the block diagonally identical backbone structure for the measurement channels, choose a general quadratic cost structure that weighs the tracking errors arbitrarily, and achieve optimality for the control design.},
  archive      = {J_AUTOM},
  author       = {Zigang Pan and Sheng Zeng and Tamer Başar},
  doi          = {10.1016/j.automatica.2025.112190},
  journal      = {Automatica},
  month        = {5},
  pages        = {112190},
  shortjournal = {Automatica},
  title        = {Robust model reference adaptive control for square MIMO LTI systems with uniform vector relative degree of zero},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online mixed discrete and continuous optimization:
Algorithms, regret analysis and applications. <em>AUTOM</em>,
<em>175</em>, 112189. (<a
href="https://doi.org/10.1016/j.automatica.2025.112189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study an online mixed discrete and continuous optimization problem where a decision maker interacts with an unknown environment over T rounds. At each round, the decision maker needs to jointly choose a discrete action and a continuous action and receives a reward associated with the chosen actions. The decision maker seeks to maximize the accumulative reward after T rounds. We propose algorithms to solve the online mixed discrete and continuous optimization problem that yield regret sublinear in T . We apply our algorithms to solve some important applications in practice with regret guarantees. We validate our theoretical results with numerical experiments.},
  archive      = {J_AUTOM},
  author       = {Lintao Ye and Ming Chi and Zhi-Wei Liu and Xiaoling Wang and Vijay Gupta},
  doi          = {10.1016/j.automatica.2025.112189},
  journal      = {Automatica},
  month        = {5},
  pages        = {112189},
  shortjournal = {Automatica},
  title        = {Online mixed discrete and continuous optimization: Algorithms, regret analysis and applications},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simultaneous distributed localization and formation tracking
control via matrix-weighted position constraints. <em>AUTOM</em>,
<em>175</em>, 112188. (<a
href="https://doi.org/10.1016/j.automatica.2025.112188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the problem of 3-D relative-measurement-based leader–follower simultaneous distributed localization and formation tracking control. The position information is only available to the leaders, and the followers have inter-agent relative measurements and communication with their neighbors. The key contribution is the development of a weight-matrix-based position constraint, which can make use of relative measurements such as bearing, ratio-of-distance, angle, distance, relative position and their mixture to describe the position relationship among each follower and its neighbors in 3-D space. A bearing-based distributed protocol is proposed for each follower to estimate its position and track its target position, which can drive the followers from their unlocalizable positions to localizable positions. The proposed algorithm is then extended to the case that both bearing and ratio-of-distance measurements are available, where the followers are localizable at all times if the followers and their neighbors are not collocated. In addition, the proposed method is also applicable to homogeneous or heterogeneous angle, distance, and relative position measurements as the ratio-of-distances or bearings can be obtained indirectly by these relative measurements. A remarkable advantage is that the proposed method can be implemented without persistently exciting motions. Some illustrative simulations are presented to verify the theoretical results.},
  archive      = {J_AUTOM},
  author       = {Xu Fang and Lihua Xie and Dimos V. Dimarogonas},
  doi          = {10.1016/j.automatica.2025.112188},
  journal      = {Automatica},
  month        = {5},
  pages        = {112188},
  shortjournal = {Automatica},
  title        = {Simultaneous distributed localization and formation tracking control via matrix-weighted position constraints},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust moving horizon estimation for nonlinear systems: From
perfect to imperfect optimization. <em>AUTOM</em>, <em>175</em>, 112187.
(<a href="https://doi.org/10.1016/j.automatica.2025.112187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines the robust stability of moving-horizon estimators for nonlinear discrete-time systems that are detectable in the sense of incremental input/output-to-state stability and are affected by disturbances. The estimate of a moving-horizon estimator is derived from the on-line solution of a least-squares minimization problem at each time instant. The resulting stability guarantees depend on the optimization tolerance in solving these minimization problems. Specifically, two main contributions are established: (i) the robust stability of the estimation error, assuming the on-line minimization problem is solved exactly; (ii) the practical robust stability of the estimation error with state estimates obtained through imperfect minimization. Finally, the construction of such robust moving-horizon estimators and the performance resulting from the design based on the theoretical findings are showcased with two numerical examples.},
  archive      = {J_AUTOM},
  author       = {Angelo Alessandri},
  doi          = {10.1016/j.automatica.2025.112187},
  journal      = {Automatica},
  month        = {5},
  pages        = {112187},
  shortjournal = {Automatica},
  title        = {Robust moving horizon estimation for nonlinear systems: From perfect to imperfect optimization},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A delay-derivative-dependent switched system model method
for stability analysis of linear systems with time-varying delay.
<em>AUTOM</em>, <em>175</em>, 112183. (<a
href="https://doi.org/10.1016/j.automatica.2025.112183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the issue of delay- and its derivative-dependent stability of a linear system with a time-varying delay. Based on the sign of the delay derivative, the time-varying delay is divided into two modes, namely a monotone increasing mode and a monotone decreasing mode. Then the original delay system is described as a switched system with two modes. This description motivates to construct a monotone-mode-based switching Lyapunov–Krasovskii functional, which allows different Lyapunov matrices for each mode in stability analysis of time-delay systems. By employing the average dwell time technique, several sufficient stability criteria are presented for the system under study. Over two extensively studied examples, we demonstrate that the proposed stability criteria can deliver larger delay upper bounds than some existing methods.},
  archive      = {J_AUTOM},
  author       = {Hong-Bing Zeng and Yu-Jie Chen and Yong He and Xian-Ming Zhang},
  doi          = {10.1016/j.automatica.2025.112183},
  journal      = {Automatica},
  month        = {5},
  pages        = {112183},
  shortjournal = {Automatica},
  title        = {A delay-derivative-dependent switched system model method for stability analysis of linear systems with time-varying delay},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conditions for global synchronization in networks of
heterogeneous kuramoto oscillators. <em>AUTOM</em>, <em>175</em>,
112180. (<a
href="https://doi.org/10.1016/j.automatica.2025.112180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Kuramoto model is essential for studying synchronization. In this work, we present sufficient conditions for global synchronization in networks of heterogeneous Kuramoto oscillators in the absence of homoclinic and heteroclinic cycles. The result is established by constructing a suitable Leonov function candidate for the Kuramoto model, which provides sufficient conditions for almost global synchronization in networks with acyclic and meshed topologies. The synchronization property is accompanied by necessary and sufficient conditions to guarantee the existence of equilibria, which are satisfied if the conditions for synchronization hold. The implications of the main conditions and their relationship with the network topology and parameters are discussed. Finally, the results are illustrated via a numerical example.},
  archive      = {J_AUTOM},
  author       = {Angel Mercado-Uribe and Jesus Mendoza-Avila and Denis Efimov and Johannes Schiffer},
  doi          = {10.1016/j.automatica.2025.112180},
  journal      = {Automatica},
  month        = {5},
  pages        = {112180},
  shortjournal = {Automatica},
  title        = {Conditions for global synchronization in networks of heterogeneous kuramoto oscillators},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed fault-tolerant control of multi-UAV formation
for dynamic leader tracking: A lyapunov-based MPC framework.
<em>AUTOM</em>, <em>175</em>, 112179. (<a
href="https://doi.org/10.1016/j.automatica.2025.112179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the formation tracking control problem of multiple unmanned aerial vehicles (UAVs) interconnected through a directed communication graph. The objective is to ensure that the vehicles attain a predetermined geometric configuration while simultaneously tracking a dynamic virtual leader in the presence of unexpected actuator faults. A novel distributed model predictive control (MPC) framework is proposed, where each UAV is equipped with an individual controller that adopts a hierarchical architecture comprising three sequentially connected control layers. The outer layer, integrating the Lyapunov-based MPC method with an adaptive parameter estimator, determines translation tracking control actions. The intermediate layer enforces the convergence of actual rotation angles toward the desired ones determined by the outer layer. The inner layer generates the torque control commands for rapid convergence of the angular velocities. The closed-loop stability of the entire multi-UAV system is rigorously analyzed, and sufficient conditions regarding the selection of user-defined parameters are established. Simulation results are provided to demonstrate the effectiveness of the proposed design.},
  archive      = {J_AUTOM},
  author       = {Binyan Xu and Yufan Dai and Afzal Suleman and Yang Shi},
  doi          = {10.1016/j.automatica.2025.112179},
  journal      = {Automatica},
  month        = {5},
  pages        = {112179},
  shortjournal = {Automatica},
  title        = {Distributed fault-tolerant control of multi-UAV formation for dynamic leader tracking: A lyapunov-based MPC framework},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Corrigendum to “identification of ARMA models with
binary-valued observations” [automatica 149(2023) 110832].
<em>AUTOM</em>, <em>175</em>, 112177. (<a
href="https://doi.org/10.1016/j.automatica.2025.112177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AUTOM},
  author       = {Xin Li and Ting Wang and Jin Guo and Yanlong Zhao},
  doi          = {10.1016/j.automatica.2025.112177},
  journal      = {Automatica},
  month        = {5},
  pages        = {112177},
  shortjournal = {Automatica},
  title        = {Corrigendum to “Identification of ARMA models with binary-valued observations” [Automatica 149(2023) 110832]},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). General multi-step value iteration for optimal learning
control. <em>AUTOM</em>, <em>175</em>, 112168. (<a
href="https://doi.org/10.1016/j.automatica.2025.112168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning control methods have been widely enhanced by reinforcement learning, but it is challenging to analyze the effects of incorporating extra system information. This paper presents a novel multi-step framework that utilizes extra multi-step system information to solve optimal control problems. Within this framework, we establish and classify general multi-step value iteration (MsVI) algorithms based on the uniformity between policy evaluation and improvement stages. According to this uniformity concept, the convergence condition and the acceleration conclusion are analyzed for different kinds of MsVI algorithms. Besides, we introduce a swarm policy optimizer to relieve limitations of the traditional gradient optimizer. Specifically, we implement general MsVI using an actor–critic scheme, where the swarm optimizer and neural networks are employed for policy improvement and evaluation, respectively. Furthermore, the approximation error caused by the approximator is also considered to verify the advantage of using multi-step system information. Finally, we apply the proposed method to a nonlinear benchmark system, demonstrating superior learning ability and control performance compared to traditional methods.},
  archive      = {J_AUTOM},
  author       = {Ding Wang and Jiangyu Wang and Derong Liu and Junfei Qiao},
  doi          = {10.1016/j.automatica.2025.112168},
  journal      = {Automatica},
  month        = {5},
  pages        = {112168},
  shortjournal = {Automatica},
  title        = {General multi-step value iteration for optimal learning control},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exponential synchronization of networked systems under
asynchronous sampled-data coupling. <em>AUTOM</em>, <em>175</em>,
112157. (<a
href="https://doi.org/10.1016/j.automatica.2025.112157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel approach towards synchronization analysis of nonlinear networked systems, directionally coupled via a generic network topology, under asynchronous, aperiodic sampled-data linear coupling. The synchronization dynamics of the networked system is remodelled as a feedback-interconnection of an operator that captures the continuous-time synchronization dynamics, i.e., in the absence of sampled data transmission, and an operator that accounts for these communication constraints. By studying the properties of this feedback-interconnection in the framework of dissipativity theory, we provide a novel criterion that guarantees exponential synchronization. The provided criterion also aids in deciding the trade-off between bounds on time-varying, uncertain sampling intervals, the coupling gain, and the desired transient rate of synchronization, while taking into account the network topology. The theoretical results are illustrated using a networked FitzHugh–Nagumo neuron system.},
  archive      = {J_AUTOM},
  author       = {Jijju Thomas and Erik Steur and Christophe Fiter and Laurentiu Hetel and Nathan van de Wouw},
  doi          = {10.1016/j.automatica.2025.112157},
  journal      = {Automatica},
  month        = {5},
  pages        = {112157},
  shortjournal = {Automatica},
  title        = {Exponential synchronization of networked systems under asynchronous sampled-data coupling},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A rolling horizon game considering network effect in cluster
forming for dynamic resilient multiagent systems. <em>AUTOM</em>,
<em>175</em>, 112137. (<a
href="https://doi.org/10.1016/j.automatica.2025.112137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A two-player game-theoretic problem on resilient graphs in a multiagent consensus setting is formulated. An attacker is capable to disable some of the edges of the network with the objective to divide the agents into clusters by emitting jamming signals while, in response, the defender recovers some of the edges by increasing the transmission power for the communication signals. Specifically, we consider repeated games between the attacker and the defender where the optimal strategies for the two players are derived in a rolling horizon fashion based on utility functions that take both the agents’ states and the sizes of clusters (known as network effect) into account. The players’ actions at each discrete-time step are constrained by their energy for transmissions of the signals, with a less strict constraint for the attacker. Necessary conditions and sufficient conditions of agent consensus are derived, and the number of clusters of agents at infinite time in the face of attacks and recoveries is also characterized. Simulation results are provided to demonstrate the effects of players’ actions on the cluster forming and to illustrate the players’ performance for different horizon parameters.},
  archive      = {J_AUTOM},
  author       = {Yurid E. Nugraha and Ahmet Cetinkaya and Tomohisa Hayakawa and Hideaki Ishii and Quanyan Zhu},
  doi          = {10.1016/j.automatica.2025.112137},
  journal      = {Automatica},
  month        = {5},
  pages        = {112137},
  shortjournal = {Automatica},
  title        = {A rolling horizon game considering network effect in cluster forming for dynamic resilient multiagent systems},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-level scheduling schemes for minimizing estimation
error: A game-theoretic approach. <em>AUTOM</em>, <em>175</em>, 112014.
(<a href="https://doi.org/10.1016/j.automatica.2024.112014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper designs scheduling schemes for a sensor with multiple power levels to minimize estimation error over a finite time. Under the sensor energy constraint, two algorithms are proposed to design scheduling schemes. One is a dynamic programming algorithm that constructs optimal scheduling schemes, but it is time-consuming and sensitive to the initial estimation error covariance. To address this, the second algorithm based on Nash equilibrium is developed to construct approximately optimal schemes. This algorithm not only ensures time-efficient but also allows for changes in the initial estimation error covariance. Finally, one numerical example illustrates the superiority of our proposed algorithms.},
  archive      = {J_AUTOM},
  author       = {Kaiyun Xie and Junlin Xiong},
  doi          = {10.1016/j.automatica.2024.112014},
  journal      = {Automatica},
  month        = {5},
  pages        = {112014},
  shortjournal = {Automatica},
  title        = {Multi-level scheduling schemes for minimizing estimation error: A game-theoretic approach},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="cma---12">CMA - 12</h2>
<ul>
<li><details>
<summary>
(2025). Integral transform technique for determining stress
intensity factor in wave propagation through functionally graded
piezoelectric-viscoelastic structure. <em>CMA</em>, <em>186</em>,
130–154. (<a href="https://doi.org/10.1016/j.camwa.2025.03.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study employs an integral transform approach for Love wave propagation in a rotating composite structure having an interfacial crack. The structure comprises an initially stressed functionally graded piezoelectric-viscoelastic half-space bonded to a piezoelectric-viscoelastic half-space, and is subjected to anti-plane mechanical loading and in-plane electrical loading. The study focuses on two material systems: the first material system consists of Epoxy-BNKLBT and Epoxy-KNLNTS, where BNKLBT stands for 0.885 ( Bi 0.5 Na 0.5 ) TiO 3 − 0.05 ( Bi 0.5 K 0.5 ) TiO 3 − 0.015 ( Bi 0.5 Li 0.5 ) TiO 3 − 0.05 BaTiO 3 , and KNLNTS represents ( K 0.475 Na 0.475 Li 0.05 ) ( Nb 0.92 Ta 0.05 Sb 0.03 ) O 3 , doped with 0.4 wt% CeO 2 and 0.4 wt% MnO 2 . The second material system has Epoxy-BNKLBT and Epoxy-PZT7A, where PZT7A denotes Lead Zirconate Titanate. The viscoelastic materials are modeled to reflect their complex behavior under rotational and stress conditions. The Galilean transformation is applied to convert the Cartesian coordinate system into a moving reference frame aligned with the Love wave&#39;s propagation. Employing Bessel function properties, the system is converted into a set of double integral equations and subsequently reformulated into simultaneous Fredholm integral equations. Numerical solutions to these Fredholm integral equations are employed to compute the electric displacement intensity factor and the stress intensity factor near the interfacial crack. These factors are also used to derive the expression for the energy density factor, thereby demonstrating the intrinsic coupling between the stress intensity factor and the electric displacement intensity factor. The key objective of this study is to visualize the impact of different material parameters, including piezoelectric constants, dielectric constants, initial stress, electric displacement at the interface, as well as interface stress and rotation on the stress intensity, electric displacement intensity, and energy density factors. The investigations of this study will be helpful for advanced technologies like surface acoustic wave sensors and piezoelectric actuators, as well as to enhance surface acoustic wave bio-sensor sensitivity and stability for early cancer detection and biomedical implants.},
  archive      = {J_CMA},
  author       = {Diksha and Soniya Chaudhary and Pawan Kumar Sharma and Qasem M. Al-Mdallal},
  doi          = {10.1016/j.camwa.2025.03.021},
  journal      = {Computers &amp; Mathematics with Applications},
  month        = {5},
  pages        = {130-154},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Integral transform technique for determining stress intensity factor in wave propagation through functionally graded piezoelectric-viscoelastic structure},
  volume       = {186},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Phase field lattice boltzmann method for liquid-gas flows in
complex geometries with efficient and consistent wetting boundary
treatment. <em>CMA</em>, <em>186</em>, 101–129. (<a
href="https://doi.org/10.1016/j.camwa.2025.03.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the application of wetting boundary conditions for modelling flows in complex curved geometries, such as rough fractures. It implements and analyses two common variants of the wetting boundary condition within the three-dimensional (3D) phase field lattice Boltzmann method. It provides a straightforward and novel extension of the geometrical approach to curved three-dimensional surfaces. It additionally implements surface-energy approach. A novel interpolation-based mitigation of the staircase approximation for curved boundaries is then developed and consistently applied to both wetting boundary conditions. The objectives of simplicity and parallel compute efficiency in implementation are emphasised. Through detailed validation on a series of 3D benchmark cases involving curved surfaces, such as droplet spread on a sphere, capillary intrusion, and droplet impact on a sphere, the behaviour of the wetting boundary conditions are validated and the differences between methods are highlighted. To demonstrate the applicability of the proposed approach in complex geometries with varying surface curvatures, two-phase flow through a synthetic rough fracture is presented. The suitability of the methods for complex simulations is also verified by comparing the computational performance between all investigated methods using this fracture flow test case. The present work thus contributes to the field of multiphase flow modelling with the lattice Boltzmann method in realistic applications where addressing the impact of complex geometries is essential.},
  archive      = {J_CMA},
  author       = {Dmytro Sashko and Travis R. Mitchell and Łukasz Łaniewski-Wołłk and Christopher R. Leonardi},
  doi          = {10.1016/j.camwa.2025.03.014},
  journal      = {Computers &amp; Mathematics with Applications},
  month        = {5},
  pages        = {101-129},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Phase field lattice boltzmann method for liquid-gas flows in complex geometries with efficient and consistent wetting boundary treatment},
  volume       = {186},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-material topology optimization of thermoelastic
structures by an ordered SIMP-based phase field model. <em>CMA</em>,
<em>186</em>, 84–100. (<a
href="https://doi.org/10.1016/j.camwa.2025.03.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a phase field approach to multi-material topology optimization of thermo-elastic structures. Based on the ordered Solid Isotropic Material with Penalization (ordered SIMP) model, the phase field variable is interpreted as the normalized density, which is used as the design variable in topology optimization. The material properties are interpolated in each interval of the normalized density. The advantage of ordered SIMP is that the number of design variables does not depend on the number of materials. In the proposed method, phase field evolution is governed by one Allen-Cahn type equation, with the introduction of a multiple-well potential function to take into account multiple material phases. This feature makes the current approach different from previous works, where numerous phase field evolution equations are needed. In contrast to the original ordered SIMP model, which was developed for structures subjected to only mechanical load, the current approach incorporates interpolation schemes to account for both thermal conductivity and thermal stress coefficient. An assessment of the feasibility and performance of the developed method is conducted via various benchmark examples and comparison with available reference results in the literature.},
  archive      = {J_CMA},
  author       = {Minh Ngoc Nguyen and Nhon Nguyen-Thanh and Shunhua Chen and Tinh Quoc Bui},
  doi          = {10.1016/j.camwa.2025.03.005},
  journal      = {Computers &amp; Mathematics with Applications},
  month        = {5},
  pages        = {84-100},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Multi-material topology optimization of thermoelastic structures by an ordered SIMP-based phase field model},
  volume       = {186},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Primal-mixed finite element methods for the coupled biot and
poisson–nernst–planck equations. <em>CMA</em>, <em>186</em>, 53–83. (<a
href="https://doi.org/10.1016/j.camwa.2025.03.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose mixed finite element methods for the coupled Biot poroelasticity and Poisson–Nernst–Planck equations (modeling ion transport in deformable porous media). For the poroelasticity, we consider a primal-mixed, four-field formulation in terms of the solid displacement, the fluid pressure, the Darcy flux, and the total pressure. In turn, the Poisson–Nernst–Planck equations are formulated in terms of the electrostatic potential, the electric field, the ionized particle concentrations, their gradients, and the total ionic fluxes. The weak formulation, posed in Banach spaces, exhibits the structure of a perturbed block-diagonal operator consisting of perturbed and generalized saddle-point problems for the Biot equations, a generalized saddle-point system for the Poisson equations, and a perturbed twofold saddle-point problem for the Nernst–Planck equations. One of the main novelties here is the well-posedness analysis, hinging on the Banach fixed-point theorem along with small data assumptions, the Babuška–Brezzi theory in Banach spaces, and a slight variant of recent abstract results for perturbed saddle-point problems, again in Banach spaces. The associated Galerkin scheme is addressed similarly, employing the Banach fixed-point theorem to yield discrete well-posedness. A priori error estimates are derived, and simple numerical examples validate the theoretical error bounds, and illustrate the performance of the proposed schemes.},
  archive      = {J_CMA},
  author       = {Gabriel N. Gatica and Cristian Inzunza and Ricardo Ruiz-Baier},
  doi          = {10.1016/j.camwa.2025.03.004},
  journal      = {Computers &amp; Mathematics with Applications},
  month        = {5},
  pages        = {53-83},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Primal-mixed finite element methods for the coupled biot and Poisson–Nernst–Planck equations},
  volume       = {186},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Superconvergnce analysis of an energy-stable implicit scheme
with variable time steps and anisotropic spatial nonconforming finite
elements for the nonlinear sobolev equations. <em>CMA</em>,
<em>186</em>, 37–52. (<a
href="https://doi.org/10.1016/j.camwa.2025.03.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A fully discrete implicit scheme is presented and analyzed for the nonlinear Sobolev equations, which combines an anisotropic spatial nonconforming FEM with the variable-time-step BDF2 such that nonuniform meshes can be adopted in both time and space simultaneously. We prove that the fully discrete scheme is uniquely solvable, possesses the modified discrete energy dissipation law, and achieves second-order accuracy in both temporal and spatial directions under mild meshes conditions (adjacent time-step ratio condition 0 &lt; r n : = τ n τ n − 1 &lt; r max ≈ 4.8645 and anisotropic space meshes). The analysis approach involves a priori boundedness of the finite element solution, anisotropic properties of the element, energy projection error, DOC kernels and a modified discrete Grönwall inequality. Theoretical results reveal that the error in H 1 -norm is sharp in time and optimal or even superconvergent in space. Abundant numerical experiments verify the theoretical results, and demonstrate the efficiency and accuracy of the proposed fully discrete scheme.},
  archive      = {J_CMA},
  author       = {Lifang Pei and Ruixue Li and Jiwei Zhang and Yanmin Zhao},
  doi          = {10.1016/j.camwa.2025.03.002},
  journal      = {Computers &amp; Mathematics with Applications},
  month        = {5},
  pages        = {37-52},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Superconvergnce analysis of an energy-stable implicit scheme with variable time steps and anisotropic spatial nonconforming finite elements for the nonlinear sobolev equations},
  volume       = {186},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conservative primal hybrid finite element method for weakly
damped klein-gordon equation. <em>CMA</em>, <em>186</em>, 16–36. (<a
href="https://doi.org/10.1016/j.camwa.2025.03.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on the primal hybrid finite element method (FEM) to discretize spatial variables, a semi-discrete scheme is obtained for the weakly damped Klein-Gordon equation. It is shown that this method is energy-conservative, and optimal error estimates in the energy norm are proved with the help of a modified elliptic projection. Moreover, a superconvergence result is derived, and as a consequence, the maximum norm estimate is obtained. Then, a non-standard type argument shows optimal error analysis in the L ∞ ( L 2 ) -norm with reduced regularity assumption on the solution. Further, the optimal order of convergence for the Lagrange multiplier is also established, and a superconvergence result for the gradient of the error between the modified elliptic projection and the primal hybrid finite element solution in maximum norm is derived. For a complete discrete scheme, an energy-conservative finite difference method is applied in the temporal direction, and the well-posedness of the discrete system is shown using a variant of the Brouwer fixed point theorem. The optimal rate of convergence for the primal variable in energy and L 2 -norm for the fully discrete problem are established. Both semidiscrete and fully discrete schemes are analyzed for polynomial non-linearity, which is of the locally Lipschitz type. Finally, some numerical experiments are conducted to validate our theoretical findings.},
  archive      = {J_CMA},
  author       = {Sanjib K. Acharya and Amiya K. Pani and Ajit Patel and Ravina Shokeen},
  doi          = {10.1016/j.camwa.2025.03.003},
  journal      = {Computers &amp; Mathematics with Applications},
  month        = {5},
  pages        = {16-36},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Conservative primal hybrid finite element method for weakly damped klein-gordon equation},
  volume       = {186},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explicit solution of high-dimensional parabolic PDEs:
Application of kronecker product and vectorization operator in the haar
wavelet method. <em>CMA</em>, <em>186</em>, 1–15. (<a
href="https://doi.org/10.1016/j.camwa.2025.03.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a numerically stable and efficient method based on Haar wavelets for solving high-dimensional second-order parabolic partial differential equations (PDEs). In the proposed framework, the spatial second-order derivatives in the governing equation are approximated using the Haar wavelet series. These approximations are subsequently integrated to obtain the corresponding lower-order derivatives. By substituting these expressions into the governing equation, the PDE is transformed into a system of first-order ordinary differential equations. This resulting system is then advanced in time using Euler&#39;s scheme. Conventional Haar wavelet methods transform the given PDEs into a system with a large number of equations, which makes them computationally expensive. In contrast, the present Haar wavelets method (HWM) significantly reduces the number of algebraic equations. Moreover, the incorporation of the Kronecker product and vectorization operator properties in the HWM substantially decreases the computational cost compared to existing Haar wavelet methods in the literature (e.g., [25] , [34] , [35] ). The HWM achieves second-order accuracy in spatial variables. We demonstrate the effectiveness of the HWM through various multi-dimensional problems, including two-, three-, four-, and ten-dimensional cases. The numerical results confirm the accuracy and efficiency of the proposed approach.},
  archive      = {J_CMA},
  author       = {Masood Ahmad and Muhammad Ahsan and Zaheer Uddin},
  doi          = {10.1016/j.camwa.2025.03.001},
  journal      = {Computers &amp; Mathematics with Applications},
  month        = {5},
  pages        = {1-15},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Explicit solution of high-dimensional parabolic PDEs: Application of kronecker product and vectorization operator in the haar wavelet method},
  volume       = {186},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design and time-domain finite element analysis of a carpet
thermal concentrator in metamaterials. <em>CMA</em>, <em>185</em>,
94–109. (<a href="https://doi.org/10.1016/j.camwa.2025.03.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional transform thermodynamic devices are designed from anisotropic materials which are difficult to fabricate. In this paper, we design and simulate a carpet thermal concentrator. Based on existing transformation thermodynamic techniques, we have derived the perfect parameters required for carpet heat concentrators. In order to eliminate the anisotropy of perfect parameters, we designed a heat concentration device for isotropic materials using the effective medium theory, and a posterior error analysis of the finite element discretization scheme in the metamaterial region is provided. Finally, we present the numerical simulation results to verify the correctness of the analysis and the performance of the designed heat concentration device.},
  archive      = {J_CMA},
  author       = {Bin He and Shouzhu Bao},
  doi          = {10.1016/j.camwa.2025.03.016},
  journal      = {Computers &amp; Mathematics with Applications},
  month        = {5},
  pages        = {94-109},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Design and time-domain finite element analysis of a carpet thermal concentrator in metamaterials},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing variational physics-informed neural networks
using least squares. <em>CMA</em>, <em>185</em>, 76–93. (<a
href="https://doi.org/10.1016/j.camwa.2025.02.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variational Physics-Informed Neural Networks often suffer from poor convergence when using stochastic gradient-descent-based optimizers. By introducing a least squares solver for the weights of the last layer of the neural network, we improve the convergence of the loss during training in most practical scenarios. This work analyzes the computational cost of the resulting hybrid least-squares/gradient-descent optimizer and explains how to implement it efficiently. In particular, we show that a traditional implementation based on backward-mode automatic differentiation leads to a prohibitively expensive algorithm. To remedy this, we propose using either forward-mode automatic differentiation or an ultraweak-type scheme that avoids the differentiation of trial functions in the discrete weak formulation. The proposed alternatives are up to one hundred times faster than the traditional one, recovering a computational cost-per-iteration similar to that of a conventional gradient-descent-based optimizer alone. To support our analysis, we derive computational estimates and conduct numerical experiments in one- and two-dimensional problems.},
  archive      = {J_CMA},
  author       = {Carlos Uriarte and Manuela Bastidas and David Pardo and Jamie M. Taylor and Sergio Rojas},
  doi          = {10.1016/j.camwa.2025.02.022},
  journal      = {Computers &amp; Mathematics with Applications},
  month        = {5},
  pages        = {76-93},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Optimizing variational physics-informed neural networks using least squares},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Space-time finite element analysis of the
advection-diffusion equation using galerkin/least-square stabilization.
<em>CMA</em>, <em>185</em>, 52–75. (<a
href="https://doi.org/10.1016/j.camwa.2025.02.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a full space-time numerical solution of the advection-diffusion equation using a continuous Galerkin finite element method on conforming meshes. The Galerkin/least-square method is employed to ensure stability of the discrete variational problem. In the full space-time formulation, time is considered another dimension, and the time derivative is interpreted as an additional advection term of the field variable. We derive a priori error estimates and illustrate spatio-temporal convergence with several numerical examples. We also derive a posteriori error estimates, which coupled with adaptive space-time mesh refinement provide efficient and accurate solutions. The accuracy of the space-time solutions is illustrated by comparing against analytical solutions as well as against numerical solutions using a conventional time-marching algorithm.},
  archive      = {J_CMA},
  author       = {Biswajit Khara and Kumar Saurabh and Robert Dyja and Anupam Sharma and Baskar Ganapathysubramanian},
  doi          = {10.1016/j.camwa.2025.02.020},
  journal      = {Computers &amp; Mathematics with Applications},
  month        = {5},
  pages        = {52-75},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Space-time finite element analysis of the advection-diffusion equation using galerkin/least-square stabilization},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new family of b-spline based explicit time integration
methods for linear structural dynamic analysis. <em>CMA</em>,
<em>185</em>, 29–51. (<a
href="https://doi.org/10.1016/j.camwa.2025.02.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study develops a new family of explicit time integration methods for linear structural dynamic analysis. The proposed method is formulated using cubic B-spline interpolation. Several cases of algorithm parameters are identified by theoretical analysis to improve stability and accuracy. The explicit method exhibits desirable algorithmic properties, including stability and accuracy. The numerical examples demonstrate that the proposed method can achieve desirable stability, accuracy and efficiency for linear structural dynamic analysis.},
  archive      = {J_CMA},
  author       = {Yanqun Han and Tianhao Liu and Weibin Wen and Xiaomin Liu},
  doi          = {10.1016/j.camwa.2025.02.017},
  journal      = {Computers &amp; Mathematics with Applications},
  month        = {5},
  pages        = {29-51},
  shortjournal = {Comput. Meth. Appl.},
  title        = {A new family of B-spline based explicit time integration methods for linear structural dynamic analysis},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An asymptotic preserving scheme for the
euler-poisson-boltzmann system in the quasineutral limit. <em>CMA</em>,
<em>185</em>, 1–28. (<a
href="https://doi.org/10.1016/j.camwa.2025.02.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study an asymptotic preserving (AP), energy stable and positivity preserving semi-implicit finite volume scheme for the Euler-Poisson-Boltzmann (EPB) system in the quasineutral limit. The key to energy stability is the addition of appropriate stabilisation terms into the convective fluxes of mass and momenta, and the source term. The space-time fully-discrete scheme admits the positivity of the mass density, and is consistent with the weak formulation of the EPB system upon mesh refinement. In the quasineutral limit, the numerical scheme yields a consistent, semi-implicit discretisation of the isothermal compressible Euler system, thus leading to the AP property. Several benchmark numerical case studies are performed to confirm the robustness and efficacy of the proposed scheme in the dispersive as well as the quasineutral regimes. The numerical results also corroborates scheme&#39;s ability to very well resolve plasma sheaths and the related dynamics, which indicates its potential to applications involving low-temperature plasma problems.},
  archive      = {J_CMA},
  author       = {K.R. Arun and R. Ghorai},
  doi          = {10.1016/j.camwa.2025.02.021},
  journal      = {Computers &amp; Mathematics with Applications},
  month        = {5},
  pages        = {1-28},
  shortjournal = {Comput. Meth. Appl.},
  title        = {An asymptotic preserving scheme for the euler-poisson-boltzmann system in the quasineutral limit},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="cmame---41">CMAME - 41</h2>
<ul>
<li><details>
<summary>
(2025). Implicit stabilized non-ordinary state-based peridynamics
for finite deformation and fracture analysis of nearly incompressible
materials. <em>CMAME</em>, <em>438</em>, 117879. (<a
href="https://doi.org/10.1016/j.cma.2025.117879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents an implicit stabilized non-ordinary state-based peridynamic method (ImNSPD) to simulate the finite deformation and crack propagation in nearly incompressible hyperelastic materials. Firstly, a mixed displacement-pressure ( u - p ) formulation of the ImNSPD is derived to mitigate the volumetric locking issues expected in a purely displacement formulation near the incompressibility limit. Additionally, the shape-associated micromodulus and the dilatation-associated micromodulus are introduced as penalty factors in the modified force vector state and the modified hydrostatic pressure scalar state, respectively, to enhance the numerical stabilization. Subsequently, an incremental-iterative solution scheme based on the Newton-Raphson algorithm and the Newmark-beta method is proposed to capture the nonlinear response of hyperelastic materials in the time domain. The stability and robustness of the ImNSPD are assessed by studying several representative numerical examples involving the finite deformation of nearly incompressible hyperelastic material models. Moreover, an equivalent strain function is introduced as a failure criterion for nearly incompressible hyperelastic materials, and the good performance of the ImNSPD in predicting crack propagation is demonstrated through the fracture analysis of the twisting column test.},
  archive      = {J_CMAME},
  author       = {Chengxuan Li and Hanbo Zhang and Cunliang Pan and Hongfei Ye and Hongwu Zhang and Yonggang Zheng},
  doi          = {10.1016/j.cma.2025.117879},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117879},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Implicit stabilized non-ordinary state-based peridynamics for finite deformation and fracture analysis of nearly incompressible materials},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid quantum genetic algorithm for structural damage
identification. <em>CMAME</em>, <em>438</em>, 117866. (<a
href="https://doi.org/10.1016/j.cma.2025.117866">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum computing, as an emerging technology, has experienced rapid development and attracted widespread attention across various disciplines over the past four decades. In the field of damage identification, as the demand for damage detection efficiency in real-world engineering continues to rise, the application of this fast computing technology also deserves attention. As a combination of genetic algorithm and quantum computing, the hybrid quantum genetic algorithm (HQGA) utilizes quantum superposition and entanglement to implement evolutionary optimization on quantum computers. Due to its flexibility in performing a global adaptive search without relying on the specific nature of the problem or the form of the objective function, the HQGA demonstrates the potential to solve complex optimization problems. In this paper, a mapping relationship is established between quantum bits and the stiffness reduction factors of elements, leading to the development of the HQGA for solving the damage identification problem based on measured strain responses. The performance of the proposed method is tested by damage identification for three distinct structures. The results show that the proposed method can enhance detection efficiency greatly while maintaining its effectiveness and stability.},
  archive      = {J_CMAME},
  author       = {Lianming Xu and Xiaojun Wang and Zhenghuan Wang and Geyong Cao},
  doi          = {10.1016/j.cma.2025.117866},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117866},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Hybrid quantum genetic algorithm for structural damage identification},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Addressing concave boundaries in two-dimensional pointwise
contact detection under the common-normal concept. <em>CMAME</em>,
<em>438</em>, 117865. (<a
href="https://doi.org/10.1016/j.cma.2025.117865">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contact search, the step where pairs of interacting points are identified, is crucial in computer methods for contact mechanics. This work explores the properties of contact pairs in a specific approach known as master-master method, combined with a hybrid-barrier enforcement method. The scope is on two-dimensional non-conformal contact, modeled as pointwise. Line-to-line and other instances of flat contact, for which a distribution of pressure over a region of finite size better represents their physics, are avoided. The main goal is to overcome the non-uniqueness of solutions when considering concave geometries. The bodies are defined by parameterized plane curves composed of strictly convex segments that represent either convex or concave boundaries. In the master-master approach, contact pairs are characterized by the common normal concept. Within this framework, contact pairs are classified into four types: convex-convex, matchable convex-concave, non-matchable convex-concave, and concave-concave. The Hessian of the squared distance function is analyzed for each type to further characterize them. Characterization using the Hessian matrix reveals that convex-convex and matchable convex-concave pairs are local minimizers of the squared distance function, while the other two types are either saddle points or maximizers. This enables a demonstration of the uniqueness of solutions for convex bodies. In the convex-concave case, projecting the concave boundary onto the convex one results in a univariate restricted objective function that distinguishes matchable pairs as minimizers and non-matchable pairs as maximizers. This function is used to propose a robust search algorithm that includes subdividing the domain into intervals with at most one minimizer, enabling the practical use of iterative minimization techniques to find all desired contact solutions. An algorithm for contact search that accommodates concave geometries is especially valuable in multibody applications.},
  archive      = {J_CMAME},
  author       = {Lucas da Silva and Marina Vendl Craveiro and Alfredo Gay Neto},
  doi          = {10.1016/j.cma.2025.117865},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117865},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Addressing concave boundaries in two-dimensional pointwise contact detection under the common-normal concept},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Octree-based scaled boundary finite element approach for
polycrystal RVEs: A comparison with traditional FE and FFT methods.
<em>CMAME</em>, <em>438</em>, 117864. (<a
href="https://doi.org/10.1016/j.cma.2025.117864">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finite Element Method (FEM) is one of the most widely used numerical techniques for solving partial differential equations. Despite its popularity, FEM faces challenges such as automatic mesh generation, handling stress singularities, and adaptive meshing. The recently developed Scaled Boundary Finite Element Method (SBFEM) overcomes these challenges by utilizing polyhedral elements, such as octree elements. SBFEM, combined with octree meshes, offer significant advantages over FEM, including rapid mesh transition, automatic mesh generation, adaptive meshing, and enhanced computational efficiency. Octree-based SBFEM has been successfully implemented and tested in various applications, such as homogenization, elastoplasticity, and adaptive phase-field fracture. However, its application to polycrystal representative volume elements (RVEs) remains unexplored. In this work, we implemented octree-based SBFEM for polycrystal RVEs and evaluated its performance for elasticity. A detailed algorithm is provided to generate balanced periodic octree meshes for polycrystal RVEs. The homogenized response and local stress fields are compared with those obtained from FEM and fast Fourier transforms (FFT). The results demonstrate that SBFEM closely matches with FEM and FFT while offering the added advantage of computational efficiency over FEM.},
  archive      = {J_CMAME},
  author       = {Shiva Kumar Gaddam and Sundararajan Natarajan and Anand K. Kanjarla},
  doi          = {10.1016/j.cma.2025.117864},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117864},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Octree-based scaled boundary finite element approach for polycrystal RVEs: A comparison with traditional FE and FFT methods},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forward and inverse simulation of pseudo-two-dimensional
model of lithium-ion batteries using neural networks. <em>CMAME</em>,
<em>438</em>, 117856. (<a
href="https://doi.org/10.1016/j.cma.2025.117856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we address the challenges posed by the high nonlinearity of the Butler–Volmer (BV) equation in forward and inverse simulations of the pseudo-two-dimensional (P2D) model using the physics-informed neural network (PINN) framework. The BV equation presents significant challenges for PINNs, primarily due to the hyperbolic sine term, which renders the Hessian of the PINN loss function highly ill-conditioned. To address this issue, we introduce a bypassing term that improves numerical stability by substantially reducing the condition number of the Hessian matrix. Furthermore, the small magnitude of the ionic flux j often leads to a common failure mode where PINNs converge to incorrect solutions. We demonstrate that incorporating a secondary conservation law for the solid-phase potential ψ effectively prevents such convergence issues and ensures solution accuracy. The proposed methods prove effective for solving both forward and inverse problems involving the BV equation. Specifically, we achieve precise parameter estimation in inverse scenarios and reliable solution predictions for forward simulations.},
  archive      = {J_CMAME},
  author       = {Myeong-Su Lee and Jaemin Oh and Dong-Chan Lee and KangWook Lee and Sooncheol Park and Youngjoon Hong},
  doi          = {10.1016/j.cma.2025.117856},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117856},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Forward and inverse simulation of pseudo-two-dimensional model of lithium-ion batteries using neural networks},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A nonlocal mixed-mode fatigue crack growth model based on
peridynamic differential operator theory. <em>CMAME</em>, <em>438</em>,
117855. (<a href="https://doi.org/10.1016/j.cma.2025.117855">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel peridynamics (PD) fatigue model for the fatigue crack growth analysis under mixed-mode loading conditions. The foundational aspect of this work involves the application of Peridynamic Differential Operator (PDDO) theory, based on which the analytical relationships between the non-local bond deformations and local strain/stress tensors are first established with the consideration of bond rotation kinematics. Furthermore, the correlations between the bond stretch and Stress Intensity Factors (SIFs) within the crack tip field are rigorously derived, which facilitates the description of fatigue damage in alignment with the classical Linear Elastic Fracture Mechanics (LEFM) theory. The PD fatigue model is implemented through a coupled PDDO and finite element (FE) approach to achieve higher numerical efficiency. Finally, the model&#39;s validity is demonstrated through high-fidelity simulation of several benchmark mixed-mode fatigue examples. A notable advantage of the proposed PD fatigue model is its seamless integration of peridynamic theory with classical fracture mechanics, and the model parameters can be rigorously and accurately calibrated for mixed-mode fatigue problems.},
  archive      = {J_CMAME},
  author       = {Jianrui Liu and Junxiang Wang and Zhaobo Song and Liang Wang},
  doi          = {10.1016/j.cma.2025.117855},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117855},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A nonlocal mixed-mode fatigue crack growth model based on peridynamic differential operator theory},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel coupled clustering FFT2 multiscale method for
modeling the nonlinear behavior and failure of composites.
<em>CMAME</em>, <em>438</em>, 117854. (<a
href="https://doi.org/10.1016/j.cma.2025.117854">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel FFT 2 parallel multiscale computational method to predict the nonlinear behavior and failure of composite materials. Unlike traditional multiscale methods, the proposed approach reformulates the mechanical boundary value problem into Lippmann-Schwinger type integral equations at both the micro- and macro-scale, thereby leveraging the numerical efficiency of the fast Fourier transform (FFT) method at both scales. The application of generic (e.g. non-periodic) boundary conditions at the macro-scale is carried out by using the virtual boundary technique and buffer zones. In addition, the introduction of a clustering algorithm further improves the computational efficiency of the numerical method during the information transfer between scales. To ensure accurate damage prediction and mitigate spurious strain localization at both scales, suitable regularization techniques are employed. The proposed multiscale method is applied to investigate the transverse tension of unidirectional composite dog-bone specimens. After experimental verification, the method is applied to simulate 2D and 3D brittle fracture, elasto-plastic damage, and examples with non-uniform material orientation. The results demonstrate the robustness and adaptability of the clustering approach, which achieves up to 65.90-fold speedup and 81.62-fold reduction in memory usage compared to non-clustered multiscale methods, while maintaining a comparable level of accuracy.},
  archive      = {J_CMAME},
  author       = {Menglei Li and Marco Magri and Bing Wang and Bing Wang},
  doi          = {10.1016/j.cma.2025.117854},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117854},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A novel coupled clustering FFT2 multiscale method for modeling the nonlinear behavior and failure of composites},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Based on purely physical information in deep learning
optimizes soliton system parameter identification problem.
<em>CMAME</em>, <em>438</em>, 117852. (<a
href="https://doi.org/10.1016/j.cma.2025.117852">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solitons find widespread applications across diverse disciplines. Accurate identification of the internal parameters within soliton systems allows us for precise comprehension and effective regulation of these systems. The introduction of deep learning has revolutionized the way to address the issue of parameter identification in soliton systems. However, the lack of suitable weight initialization schemes leads to the identification outcomes being prone to blurriness and errors. Consequently, we propose a novel initialization method: physical meta-learning(PML). The unique approach which relies solely on the physical information related to the system allows us to obtain the initialization weights without relying on any labeled data. In basic soliton systems experiments, PML reduces the identification error by 25% to 80%. Regarding the parameter identification task of dissipative soliton system in mode-locked lasers, the PML method significantly reduces the identification error by 98.1%. In addition to the application scenarios, we also examine the effectiveness of the PML method in different parameter identification methods. Overall, our research provides a method for optimizing the identification and simulation of complex soliton systems.},
  archive      = {J_CMAME},
  author       = {Zhiyang Zhang and Muwei Liu and Xiaowei Xing and Shuzhuang Zhang and Zhenya Yan and Wenjun Liu},
  doi          = {10.1016/j.cma.2025.117852},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117852},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Based on purely physical information in deep learning optimizes soliton system parameter identification problem},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hemodynamics modeling with physics-informed neural networks:
A progressive boundary complexity approach. <em>CMAME</em>,
<em>438</em>, 117851. (<a
href="https://doi.org/10.1016/j.cma.2025.117851">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hemodynamic analysis is essential for assessing cardiovascular health. Computational fluid dynamics (CFD) methods, while precise, are computationally expensive and lack transfer learning capabilities, requiring recalculation for varying boundaries. Machine-learning methods, despite powerful data-fitting abilities, heavily rely on labeled datasets, limiting their use in clinical settings where data is scarce. To alleviate data dependency, Physics-Informed Neural Networks (PINNs) embed physical laws directly into the loss function, allowing model parameter transfer across varying geometries. However, traditional PINNs struggle with complex domains like stenosed vessels, leading to inefficiency and reduced accuracy. To tackle this challenge, we propose the Boundary Progressive PINN (BP-PINN). By introducing boundary complexity, BP-PINN reconstructs vascular boundaries at varying smoothness levels. Training begins with simple models and progressively incorporating boundary details to capture complex flow characteristics. Without any labeled data, BP-PINN was successfully applied to 22 patient-specific cases, achieving L2 errors of 0.036 for velocity and 0.057 for pressure compared to CFD ground truth. Furthermore, compared to fractional flow reserve (FFR), the invasive gold standard for diagnosing myocardial ischemia, the non-invasive FFR predicted by BP-PINN attained the highest overall diagnostic accuracy of 90.9 %, outperforming vanilla-PINNs (81.8 %). Additionally, BP-PINN leveraged pretrained models with similar boundary complexities, enabling efficient stent preoperative planning. The proposed method evaluated the effects of five stenting strategies on the hemodynamic environment, achieving an average computation time of under 3 min per case. Finally, the framework was extended to solve heat equation, Poisson equation and Helmholtz equation in irregular domains, demonstrating superior accuracy compared to baseline methods.},
  archive      = {J_CMAME},
  author       = {Xi Chen and Jianchuan Yang and Xu Liu and Yong He and Qiang Luo and Mao Chen and Wenqi Hu},
  doi          = {10.1016/j.cma.2025.117851},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117851},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Hemodynamics modeling with physics-informed neural networks: A progressive boundary complexity approach},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bioinspired multi-layer assembly method for mechanical
metamaterials with extreme properties using topology optimization.
<em>CMAME</em>, <em>438</em>, 117850. (<a
href="https://doi.org/10.1016/j.cma.2025.117850">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the hierarchical distribution pattern of natural bamboo, this study presents a multi-layer assembly strategy for the design of mechanical metamaterials with extreme properties. Firstly, the material spatial layout is constructed by employing a bio-inspired arrangement with two types of cells distributed in a staggered manner. Based on this arrangement, a new theoretical model for evaluating material properties is then developed, which in turn determines the requirements of extreme material properties on cell properties. Finally, to obtain materials with extreme mechanical properties, a topology optimization method is adopted for the generation of cell geometries with the needed properties. The numerical experiment results indicate that compared to the homogeneous material consisting of basic cells, the Young&#39;s modulus of assembled metamaterials with similar density is enhanced by more than three orders of magnitude and up to 6273 times. Further, a series of materials with extreme Young&#39;s modulus approaching the theoretical limit are identified by geometric parameter optimization for specific topologies. Such metamaterials based on assembly strategies are capable of taking full advantage of geometric variations to enhance mechanical properties, thus having a wide range of applications in various fields such as energy absorption, impact protection, and strain sensing.},
  archive      = {J_CMAME},
  author       = {Peng Yin and Baotong Li and Yue Zhang and Bang Li and Jun Hong and Xiaohu Li and Xiaoming Chen and Jinyou Shao},
  doi          = {10.1016/j.cma.2025.117850},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117850},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A bioinspired multi-layer assembly method for mechanical metamaterials with extreme properties using topology optimization},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-talk effects in trimmed isogeometric shells and the
control point duplication approach. <em>CMAME</em>, <em>438</em>,
117849. (<a href="https://doi.org/10.1016/j.cma.2025.117849">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finite element and isogeometric methods with non-boundary-conforming meshes, also known as immersed, embedding or trimming approaches, offer a fast and simple model generation process and thus became an attractive alternative to conventional boundary-fitted methods. One challenge inherent to these methods is the accurate modeling of discontinuities, such as small, narrow trimming features and cracks. Such discontinuities can split the support domain of a basis function into multiple disjoint regions, leading to a spurious mechanical coupling between physically separated material regions, which may compromise the predictive quality of the simulation model. Isogeometric Analysis (IGA), with its higher-order and higher-continuity spline bases possessing larger support domains, is even more prone to such spurious effects. This phenomenon is known as ”cross-talk”, and can be solved via adequate (local) mesh refinement, as shown by Coradello et al. [Computational Mechanics 66 (2020): 431-447]. However, the focus of our work is on explicit dynamics such as crash simulations. In such cases, mesh refinement is unfavorable because it halves the critical time step size for each level of h -refinement, and therefore substantially increases the computational cost. To this end, we propose an effective and efficient control point duplication (CPD) approach that mitigates the effects of cross-talk caused by narrow trimming features, while maintaining the feasible critical time step size in explicit dynamic analysis. CPD locally decouples the disjoint material regions by duplicating certain control points and modifying the connectivity of the affected elements. Furthermore, since cross-talk has only received limited attention in the literature, we also present a systematic study to elaborate on its characteristics and mechanisms. Following this, we provide a formal mathematical definition, a classification criterion, as well as a detection method for cross-talk in trimmed NURBS shells. Finally, we demonstrate the efficiency and effectiveness of the CPD approach through four numerical examples with varying complexities. We also show that CPD is not limited to explicit dynamics and that apart from narrow trimming features, it can potentially also mitigate cross-talk caused by element erosion and sharp crack interfaces.},
  archive      = {J_CMAME},
  author       = {Z. Lian and L.F. Leidinger and S. Hartmann and F. Bauer and M. Pabst and C. Krisadawat and R. Wüchner},
  doi          = {10.1016/j.cma.2025.117849},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117849},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Cross-talk effects in trimmed isogeometric shells and the control point duplication approach},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Univariate conditional variational autoencoder for
morphogenic pattern design in frontal polymerization-based
manufacturing. <em>CMAME</em>, <em>438</em>, 117848. (<a
href="https://doi.org/10.1016/j.cma.2025.117848">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under some initial and boundary conditions, the rapid reaction-thermal diffusion process taking place during frontal polymerization (FP) destabilizes the planar mode of front propagation, leading to spatially varying, complex hierarchical patterns in thermoset polymeric materials. Although modern reaction–diffusion models can predict the patterns resulting from unstable FP, the inverse design of patterns, which aims to retrieve process conditions that produce a desired pattern, remains an open challenge due to the non-unique and non-intuitive mapping between process conditions and manufactured patterns. In this work, we propose a probabilistic generative model named univariate conditional variational autoencoder (UcVAE) for the inverse design of hierarchical patterns in FP-based manufacturing. Unlike the cVAE, which encodes both the design space and the design target, the UcVAE encodes only the design space. In the encoder of the UcVAE, the number of training parameters is significantly reduced compared to the cVAE, resulting in a shorter training time while maintaining comparable performance. Given desired pattern images, the trained UcVAE can generate multiple process condition solutions that produce high-fidelity hierarchical patterns.},
  archive      = {J_CMAME},
  author       = {Qibang Liu and Pengfei Cai and Diab Abueidda and Sagar Vyas and Seid Koric and Rafael Gomez-Bombarelli and Philippe Geubelle},
  doi          = {10.1016/j.cma.2025.117848},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117848},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Univariate conditional variational autoencoder for morphogenic pattern design in frontal polymerization-based manufacturing},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The rationality of using dynamic relaxation method for
failure simulation in peridynamics. <em>CMAME</em>, <em>438</em>,
117847. (<a href="https://doi.org/10.1016/j.cma.2025.117847">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In peridynamics, a large amount of research related to material failure has applied the dynamic relaxation (DR) method under static or quasi-static loading conditions. However, as a pseudo-dynamic method that converts static problems into dynamic problems by introducing fictitious inertia and damping terms, the intermediate attenuation process of the DR method is not realistic. Whether it is truly suitable for simulating the irreversible mechanical behavior of material failure, which closely depends on the real process and has significant dynamic effects in the later stage of failure, is still a debatable issue. This article first derives the prerequisite for applying the DR method to solve static or quasi-static problems, which is to ensure that the load and system stiffness remain constant during the solving process. However, material damage will inevitably weaken the stiffness of the system and break this prerequisite. In view of this, using explicit dynamic algorithm for failure simulation is worthy of being reconsidered. Secondly, the DR method is used to simulate the failure of l -shaped concrete specimen, and it is found that selecting different fictitious damping coefficients may lead to different crack propagation paths, resulting in uncertainty in the simulation results. It is also found that due to the use of fictitious damping in the DR method to suppress the acceleration effect in the accelerated failure stage, the dynamic effect of the system is not fully utilized, which leads to distortion of simulation results. At last, a two-stage joint algorithm is proposed suitable for material failure problems under static or quasi-static loading conditions. The DR method is only applied to the continuous deformation stage of materials without any damage, while the explicit dynamic algorithm is applied to the crack initiation and propagation stage after damage occurs. The numerical examples illustrate the effectiveness of the joint algorithm.},
  archive      = {J_CMAME},
  author       = {Xiaohua Huang and Ting Hu and Yanli Jin and Shuang Li and Dong Yang and Zhi Zheng},
  doi          = {10.1016/j.cma.2025.117847},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117847},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {The rationality of using dynamic relaxation method for failure simulation in peridynamics},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global-local adaptive meshing method for phase-field
fracture modeling. <em>CMAME</em>, <em>438</em>, 117846. (<a
href="https://doi.org/10.1016/j.cma.2025.117846">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work develops a global-local adaptive meshing method for the phase-field model of brittle fracture, offering flexible adjustment of mesh density to produce seamless and high-quality adaptive meshes. The method first establishes a direct mapping from phase-field values and displacement errors to a normalized nodal density field, which is used to control the computational accuracy. On this basis, a sampling procedure is performed by detecting the maximum value to progressively place sampling nodes, ensuring that first-level nodes are placed globally while preserving crack location information. Subsequently, a hexagonal seeding algorithm is used to multiply nodes, where the spacing of generated seeds (i.e., higher-level nodes) is adaptively adjusted based on local nodal density requirements to regulate element sizes. A spatial assessment algorithm is utilized to compare the expected nodal spacing of the newly generated node with its distance to existing nodes, which serves as a termination criterion for the loop of the seeding algorithm and effectively prevents the occurrence of low-quality elements. After the seeding process of all nodes is completed, all generated nodes are connected by constrained Delaunay triangulation. This method has been discussed under classical brittle fracture cases with various control parameters (e.g., the mapping function, the expected maximum/minimum element size, and the distance factor) to validate its advantage of reducing degrees of freedom and improving solution efficiency.},
  archive      = {J_CMAME},
  author       = {FengYu Cheng and Hao Yu and Quan Wang and HanWei Huang and WenLong Xu and HengAn Wu},
  doi          = {10.1016/j.cma.2025.117846},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117846},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Global-local adaptive meshing method for phase-field fracture modeling},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accurate, scalable, and efficient bayesian optimal
experimental design with derivative-informed neural operators.
<em>CMAME</em>, <em>438</em>, 117845. (<a
href="https://doi.org/10.1016/j.cma.2025.117845">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider optimal experimental design (OED) problems in selecting the most informative observation sensors to estimate model parameters in a Bayesian framework. Such problems are computationally prohibitive when the parameter-to-observable (PtO) map is expensive to evaluate, the parameters are high-dimensional, and the optimization for sensor selection is combinatorial and high-dimensional. To address these challenges, we develop an accurate, scalable, and efficient computational framework based on derivative-informed neural operators (DINO). We propose to use derivative-informed dimension reduction to reduce the parameter dimensions, based on which we train DINO with derivative information as an accurate and efficient surrogate for the PtO map and its derivative. Moreover, we derive DINO-enabled efficient formulations in computing the maximum a posteriori (MAP) point, the eigenvalues of approximate posterior covariance, and three commonly used optimality criteria for the OED problems. Furthermore, we provide detailed error analysis for the approximations of the MAP point, the eigenvalues, and the optimality criteria. We also propose a modified swapping greedy algorithm for the sensor selection optimization and demonstrate that the proposed computational framework is scalable to preserve the accuracy for increasing parameter dimensions and achieves high computational efficiency, with an over 1000 × speedup accounting for both offline construction and online evaluation costs, compared to high-fidelity Bayesian OED solutions for a three-dimensional nonlinear convection–diffusion–reaction example with tens of thousands of parameters at the same resolution.},
  archive      = {J_CMAME},
  author       = {Jinwoo Go and Peng Chen},
  doi          = {10.1016/j.cma.2025.117845},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117845},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Accurate, scalable, and efficient bayesian optimal experimental design with derivative-informed neural operators},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced deep learning framework for multi-scale prediction
of mechanical properties from microstructural features in
polycrystalline materials. <em>CMAME</em>, <em>438</em>, 117844. (<a
href="https://doi.org/10.1016/j.cma.2025.117844">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intricate relationship between the microstructure of materials and their mechanical properties remains a significant challenge in the field of materials science. This study introduces a novel deep learning framework aimed at predicting mechanical properties from both global and local perspectives. Taking the dual-phase Ti-6Al-4V alloy as an example, we first predict stress–strain curves and yield strength under complex microstructural conditions to describe global mechanical behavior, followed by an analysis of the distribution of the local stress field and stress concentration phenomena. To achieve this, we employ an improved graph attention network (IGAT), which effectively captures complex intergranular relationships and enables accurate predictions of global properties by integrating node features with graph structural information. Additionally, a three-dimensional conditional denoising diffusion probabilistic model (3D-cDDPM) was developed for local stress field analysis, generating detailed stress field distributions through an iterative denoising process and capturing stress concentration phenomena in critical microstructural regions. The results demonstrate that this framework effectively predicts multiscale mechanical responses in various microstructural configurations. The IGAT model achieves a mean relative error (MRE) of 0. 399% on the set of tests for global performance prediction, outperforming both the graph convolutional network (GCN) and the three-dimensional convolutional neural network (3D-CNN). For local stress field predictions, the 3D-cDDPM maintains an error range of 0.4% to 7%, with the generated stress distribution maps closely matching the ground truth. This work advances the development of material design and performance optimization methods, providing critical insights into the integration of computational modeling with materials science.},
  archive      = {J_CMAME},
  author       = {Zihao Gao and Changsheng Zhu and Canglong Wang and Yafeng Shu and Shuo Liu and Jintao Miao and Lei Yang},
  doi          = {10.1016/j.cma.2025.117844},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117844},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Advanced deep learning framework for multi-scale prediction of mechanical properties from microstructural features in polycrystalline materials},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three dimensional isogeometric boundary element method for
acoustic problems with viscothermal losses. <em>CMAME</em>,
<em>438</em>, 117843. (<a
href="https://doi.org/10.1016/j.cma.2025.117843">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An isogeometric analysis is proposed for solving acoustic problems in fluids with significant thermal and viscous dissipation. The approach is based on the Kirchhoff decomposition, which simplifies the governing linearized conservation laws for mass, momentum, and energy by dividing the physical problem into three superimposed modal wave fields; acoustic, thermal, and viscous fields. The wave fields are coupled by boundary conditions and solved as time-harmonic Helmholtz problems using an isogeometric boundary element method. The proposed solution benefits from isogeometric analysis in modeling exact geometries with high continuity, achieving accurate results while adopting moderate degrees of freedom. The basic idea of isogeometric analysis is to use the same spline basis functions to approximate both the geometry and the physical variables, allowing for a direct connection between computer-aided design tools and analysis models. Moreover, the solution profits from the boundary element approach not requiring volumetric domain discretization or far-field truncation. 3D exterior and interior test cases are discussed to validate the proposed method. The results are verified by an analytical solution and other competing numerical methods showing significant savings in degrees of freedom. Furthermore, an interior field analysis reveals the dissipative behavior inside thin boundary layers at the fluid–structure interface. A comparison with the lossless case emphasizes the added value of accounting for viscothermal losses, which were previously neglected in isogeometric analysis of acoustic problems. Despite the ill-conditioning of the system combining the acoustic, thermal, and viscous contributions, the problem can be solved via LU decomposition with iterative refinement.},
  archive      = {J_CMAME},
  author       = {Ahmed Mostafa Shaaban and Simone Preuss and Steffen Marburg},
  doi          = {10.1016/j.cma.2025.117843},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117843},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Three dimensional isogeometric boundary element method for acoustic problems with viscothermal losses},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian model updating with variational inference and
gaussian copula model. <em>CMAME</em>, <em>438</em>, 117842. (<a
href="https://doi.org/10.1016/j.cma.2025.117842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian model updating based on variational inference (VI-BMU) methods have attracted widespread attention due to their excellent computational tractability. Traditional VI-BMU methods often employ the mean-field assumption, which simplifies computation by treating model parameters as independent. Recent advances in variational inference have introduced more flexible variational distributions, enabling accurate modeling of parameter dependencies. To further address the limitations of traditional VI-BMU methods, this paper introduces a novel Bayesian model updating framework based on variational inference and Gaussian copula model (VGC-BMU). This framework incorporates Gaussian copula model to simulate the dependency relationships between model parameters, significantly improving the accuracy of posterior distribution estimation. The theoretical relationship between the VGC-BMU and traditional VI-BMU is derived, and the necessity and advantages of parameter dependency modeling are elucidated. Moreover, a simplified computational approach is developed by introducing Jacobian matrix transformations and parameter expansion techniques to address the high computational complexity of the VGC-BMU. The method&#39;s capability to identify parameter dependencies is first demonstrated through two simple numerical models. Subsequently, two engineering case studies—a four-story shear frame model and a steel pedestrian bridge model—are selected to evaluate the performance of VGC-BMU in parameter identification and dependency modeling. The results demonstrate that VGC-BMU significantly improves parameter identification accuracy compared to traditional VI-BMU methods. Furthermore, VGC-BMU exhibits superior accuracy and robustness in response prediction by incorporating parameter dependency modeling, making it a more effective and reliable approach for engineering applications.},
  archive      = {J_CMAME},
  author       = {Qiang Li and Pinghe Ni and Xiuli Du and Qiang Han},
  doi          = {10.1016/j.cma.2025.117842},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117842},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Bayesian model updating with variational inference and gaussian copula model},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-support structure topology optimization for multi-axis
additive manufacturing incorporated with curved layer slicing.
<em>CMAME</em>, <em>438</em>, 117841. (<a
href="https://doi.org/10.1016/j.cma.2025.117841">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-axis additive manufacturing significantly surpasses traditional 3-axis systems by utilizing multiple axes of motions that constructs complex three-dimensional structures with reduced need of supports. However, process planning for the curved layer slicing determines the interactions between the part and supports, and consequently, self-support topology optimization requires a numerically tractable process planning algorithm to derive the sensitivities, which however, has yet been achieved. To fill the gap, we develop a structural topology optimization method for multi-axis additive manufacturing, which features in achieving the self-support effect by deeply incorporating the curved layer slicing. Specifically, a process scalar field is generated on top of a domain of pseudo-densities by solving a heat diffusion equation and a Poisson equation, through which the geodesics included in the scalar field facilitate the curved layer slicing and any geometric information about the layers are derivable on the pseudo-densities because of the tractable numerical processing routine. Then, self-support constraints for multi-axis additive manufacturing can be established by measuring the curved layer normals and the part boundary gradients. Coupled with the density variables for topology optimization, our proposed method could concurrently optimize the part structure and its curved slicing pattern, maximizing the structural physical performance while eliminating the need of supports. Finally, we validated and discussed the effectiveness of our method through a series of numerical tests and provided a workflow to show the strong correlation between our optimized results and the actual spatial paths.},
  archive      = {J_CMAME},
  author       = {Shuzhi Xu and Jikai Liu and Dong He and Kai Tang and Kentaro Yaji},
  doi          = {10.1016/j.cma.2025.117841},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117841},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Self-support structure topology optimization for multi-axis additive manufacturing incorporated with curved layer slicing},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An inter-system iteration technique in the whole time domain
implemented by the coupling of FEM and TD-BEM. <em>CMAME</em>,
<em>438</em>, 117840. (<a
href="https://doi.org/10.1016/j.cma.2025.117840">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper introduces an innovative coupling technique, termed the Inter-System Iteration Technique (ISIT) in the whole time domain, which is effectively implemented by the coupling of the Finite Element Method (FEM) and Time Domain Boundary Element Method (TD-BEM) for dynamic analysis of intricate engineering problems. This approach divides the entire system into distinct FEM and TD-BEM parts, computed separately across the whole time domain using an optimal solution strategy. Its notable strength lies in achieving exceptional computational efficiency and accuracy by minimizing iterative calculations for each individual time step and employing iterative computations between the FEM and TD-BEM sub-systems. Notably, this method offers versatility, adaptable to various numerical algorithms and facilitating straightforward computation with commercial structural analysis software. The implemented ISIT in the whole time domain can also be used to couple arbitrarily two numerical algorithms. The paper validates its efficacy through two numerical applications, affirming its high computational efficiency and potential for addressing complex engineering challenges.},
  archive      = {J_CMAME},
  author       = {Xiaofei Qin and Hongjun Li and Changnv Zeng},
  doi          = {10.1016/j.cma.2025.117840},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117840},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {An inter-system iteration technique in the whole time domain implemented by the coupling of FEM and TD-BEM},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stabilization-free virtual element method for 2D second
order elliptic equations. <em>CMAME</em>, <em>438</em>, 117839. (<a
href="https://doi.org/10.1016/j.cma.2025.117839">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we present and analyze a Stabilization-free Virtual Element high order scheme for 2D second order elliptic equation. This method is characterized by the definition of new polynomial projections that allow the definition of structure-preserving schemes. We provide a necessary and sufficient condition on the polynomial projection space that ensure the well-posedness of the scheme and we derive optimal a priori error estimates. Several numerical tests assess the stability of the method and the robustness in solving problems characterized by anisotropies.},
  archive      = {J_CMAME},
  author       = {Stefano Berrone and Andrea Borio and Davide Fassino and Francesca Marcon},
  doi          = {10.1016/j.cma.2025.117839},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117839},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Stabilization-free virtual element method for 2D second order elliptic equations},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust equilibrium optimization method for dynamic
characteristics of mechanical structures with hybrid uncertainties.
<em>CMAME</em>, <em>438</em>, 117838. (<a
href="https://doi.org/10.1016/j.cma.2025.117838">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For complex products such as high-speed presses, it is imperative to optimize the dynamic characteristics of their moving components to avoid resonance, thereby ensuring safe and stable operation. Dynamic characteristic optimization of mechanical structures considering multi-source uncertainties remains a challenging task due to the violent confliction among multiple objectives and multiple constraints. In this paper, a novel robust equilibrium optimization method for dynamic characteristics of mechanical structures with hybrid uncertainties is proposed. Firstly, the dynamic robust equilibrium optimization model is established with multi-source uncertainties described as truncated probabilistic variables and interval variables. Subsequently, a novel angular proximity coefficient is defined to assess the constraint feasibility of design vectors. Further, a quantitative metric named the overall robust equilibrium degree (ORED) is proposed to evaluate the overall robustness of all objective and constraint performance indices for feasible design vectors. On this basis, all the feasible design vectors are directly ranked according to their OREDs, thereby achieving the optimal design of mechanical structures. The robust equilibrium optimization is realized by integrating Kriging models, Monte Carlo simulation (MCS) and nested genetic algorithm (GA). The effectiveness and feasibility of the proposed method are demonstrated through a numerical example and two engineering case studies involving a high-speed press slider and an unmanned aerial vehicle (UAV).},
  archive      = {J_CMAME},
  author       = {Jin Cheng and Honghui Wang and Shuoshuo Shen and Weifei Hu and Zhenyu Liu and Jianrong Tan},
  doi          = {10.1016/j.cma.2025.117838},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117838},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Robust equilibrium optimization method for dynamic characteristics of mechanical structures with hybrid uncertainties},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven reliability-based topology optimization by using
the extended multi scale finite element method and neural network
approach. <em>CMAME</em>, <em>438</em>, 117837. (<a
href="https://doi.org/10.1016/j.cma.2025.117837">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving reliability-based topology optimization (RBTO) problems requires highly computational demand in finite element and sensitivity analyses, particularly for obtaining high-resolution results. To overcome this issue, a new data-driven RBTO framework is introduced by using the problem-independent machine learning method, which aims to significantly decrease the computational time incurred by finite element and sensitivity analyses. Subsequently, a novel neural networks model is established by using deep learning techniques, while the offline training serves as a surrogate model for calculating the numerical basic function. Furthermore, a novel sensitivity analysis method has been developed, which utilizes the basic function and deep learning neural networks to map the sensitivity information from the macroscopic level to the microscopic level. The results illustrate that the proposed method can substantially decrease the computational time of RBTO with high-resolution results.},
  archive      = {J_CMAME},
  author       = {Zeng Meng and Shunsheng Lv and Yongxin Gao and Changting Zhong and Kang An},
  doi          = {10.1016/j.cma.2025.117837},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117837},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Data-driven reliability-based topology optimization by using the extended multi scale finite element method and neural network approach},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal solutions employing an algebraic variational
multiscale approach part i: Steady linear problems. <em>CMAME</em>,
<em>438</em>, 117832. (<a
href="https://doi.org/10.1016/j.cma.2025.117832">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work extends our previous study from S. Shrestha et al. (2024) by introducing a new abstract framework for Variational Multiscale (VMS) methods at the discrete level. We introduce the concept of what we define as the optimal projector and present a discretisation approach that yields a numerical solution closely approximating the optimal projection of the infinite-dimensional continuous solution. In this approach, the infinite-dimensional unresolved scales are approximated in a finite-dimensional subspace using the numerically computed Fine-Scale Greens’ function of the underlying symmetric problem. The proposed approach involves solving the VMS problem on two separate meshes: a coarse mesh for the full PDE and a fine mesh for the symmetric part of the continuous differential operator. We consider the 1D and 2D steady advection–diffusion problems in both direct and mixed formulations as the test cases in this paper. We first present an error analysis of the proposed approach and show that the projected solution is achieved as the approximate Greens’ function converges to the exact one. Subsequently, we demonstrate the working of this method where we show that it can exponentially converge to the chosen optimal projection. We note that the implementation of the present work employs the Mimetic Spectral Element Method (MSEM), although, it may be applied to other Finite/Spectral Element or Isogeometric frameworks. Furthermore, we propose that VMS should not be viewed as a stabilisation technique; instead, the base scheme should be inherently stable, with VMS enhancing the solution quality by supplementing the base scheme.},
  archive      = {J_CMAME},
  author       = {Suyash Shrestha and Marc Gerritsma and Gonzalo Rubio and Steven Hulshoff and Esteban Ferrer},
  doi          = {10.1016/j.cma.2025.117832},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117832},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Optimal solutions employing an algebraic variational multiscale approach part i: Steady linear problems},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A high-order implicit time integration method for linear and
nonlinear dynamics with efficient computation of accelerations.
<em>CMAME</em>, <em>438</em>, 117831. (<a
href="https://doi.org/10.1016/j.cma.2025.117831">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An algorithm for a family of self-starting high-order implicit time integration schemes with controllable numerical dissipation is proposed for both linear and nonlinear transient problems. This work builds on the previous works of the authors on elastodynamics by presenting a new algorithm that eliminates the need for factorization of the mass matrix providing benefit for the solution of nonlinear problems. The improved algorithm directly obtains the acceleration at the same order of accuracy of the displacement and velocity using vector operations (without additional equation solutions). The nonlinearity is handled by numerical integration within a time step to achieve the desired order of accuracy. The new algorithm fully retains the desirable features of the previous works: 1. The order of accuracy is not affected by the presence of external forces and physical damping; 2. The amount of numerical dissipation in the algorithm is controlled by a user-specified parameter ρ ∞ , leading to schemes ranging from perfectly nondissipative A -stable to L -stable; 3. The effective stiffness matrix is a linear combination of the mass, damping, and stiffness matrices as in the trapezoidal rule, leading to high efficiency for large-scale problems. The proposed algorithm, with its elegance and computational advantages, is shown to replicate the numerical results demonstrated on linear problems in previous works. Additional numerical examples of linear and nonlinear vibration and wave propagation are presented herein. Notably, the proposed algorithms show the same convergence rates for nonlinear problems as linear problems, and very high accuracy. It was found that second-order time integration methods commonly used in commercial software produce significantly polluted acceleration responses for a common class of wave propagation problems. The high-order time integration schemes presented here perform noticeably better at suppressing spurious high-frequency oscillations and producing reliable and usable acceleration responses. The source code written in MATLAB is available for download at: https://github.com/ChongminSong/HighOrderTimeIngt_PartialFraction.git .},
  archive      = {J_CMAME},
  author       = {Daniel O’Shea and Xiaoran Zhang and Shayan Mohammadian and Chongmin Song},
  doi          = {10.1016/j.cma.2025.117831},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117831},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A high-order implicit time integration method for linear and nonlinear dynamics with efficient computation of accelerations},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simultaneous shape and topology optimization on unstructured
grids. <em>CMAME</em>, <em>438</em>, 117830. (<a
href="https://doi.org/10.1016/j.cma.2025.117830">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we present a simultaneous shape and topology optimization framework that generates large-scale 3D designs on unstructured grids. We consider a “parameter-free” shape optimization approach, wherein the nodal coordinates in the finite element mesh serve as design variables. To regularize the design changes we use a PDE-based filter, similar to the filtering techniques used in topology optimization. We present a variant of the “parameter-free” shape optimization where we allow not only design variables on the surface, but also in the bulk of the domain. To combat mesh quality issues we employ adaptive mesh refinement based on a Riemannian metric. The numerical algorithm is implemented in C++ and uses PETSc for efficient shape and topology optimization of complex 3D geometries on unstructured grids. We verify our “parameter-free” shape optimization on two examples, and compare different variations of the shape filter. Finally, we demonstrate the power and flexibility of our simultaneous shape and topology optimization framework on a dam-like geometry.},
  archive      = {J_CMAME},
  author       = {Vilmer Dahlberg and Anna Dalklint and Mathias Wallin},
  doi          = {10.1016/j.cma.2025.117830},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117830},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Simultaneous shape and topology optimization on unstructured grids},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The frenet immersed finite element method for elliptic
interface problems: An error analysis. <em>CMAME</em>, <em>438</em>,
117829. (<a href="https://doi.org/10.1016/j.cma.2025.117829">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents an error analysis of the recently introduced Frenet immersed finite element (IFE) method. The Frenet IFE space employed in this method is constructed to be locally conforming to the function space of the associated weak form for the interface problem. This article further establishes a critical trace inequality for the Frenet IFE functions. These features enable us to prove that the Frenet IFE method converges optimally under mesh refinement in both L 2 and energy norms.},
  archive      = {J_CMAME},
  author       = {Slimane Adjerid and Tao Lin and Haroun Meghaichi},
  doi          = {10.1016/j.cma.2025.117829},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117829},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {The frenet immersed finite element method for elliptic interface problems: An error analysis},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of evolving plasticity in rails under steady
state rolling contact based on reduced-order modeling. <em>CMAME</em>,
<em>438</em>, 117828. (<a
href="https://doi.org/10.1016/j.cma.2025.117828">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting railhead damage due to multiple wheel passes in railway operations can be computationally demanding, especially when accounting for the rail’s inelastic material response. In this paper, we use a steady-state assumption within a convective coordinate system and employ Reduced-Order Modeling (ROM) through the Proper Generalized Decomposition (PGD) method to increase the computational efficiency. Our approach solves a nonlinear reduced-order problem for the displacements in a 3D railhead with elastic–plastic material properties considering various contact scenarios. The ROM framework includes domain decomposition and a parametric loading framework using PGD. It accounts for the elastic–plastic rail material through three key features: (1) treatment of the moving load under the assumption of steady state, by using a convective coordinate system along the railhead to convert the problem into a stationary contact load problem, (2) implementation of PGD to solve the 3D displacement field efficiently, and (3) use of fixed-point iterations to treat the coupling for solving plastic strains and displacements. In this iterative process, plastic strains are solved from displacements, and displacements are solved based on a loading scenario and updated plastic strains. The accuracy and computational efficiency are assessed by comparing our strategy with 3D finite element simulations for moving contact loads. The results show convergence with only a few fixed-point iterations for each over rolling, which results in a solution that is 63 times faster. This efficiency is crucial for assessing the accumulated plastic deformation from multiple wheel passes.},
  archive      = {J_CMAME},
  author       = {Caroline Ansin and Fredrik Larsson and Ragnar Larsson},
  doi          = {10.1016/j.cma.2025.117828},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117828},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Prediction of evolving plasticity in rails under steady state rolling contact based on reduced-order modeling},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning-accelerated peridynamics model for
mechanical and failure behaviors of materials. <em>CMAME</em>,
<em>438</em>, 117826. (<a
href="https://doi.org/10.1016/j.cma.2025.117826">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational mechanics is essential for understanding and predicting complex material behaviors, particularly in areas such as material fracture mechanics and structural engineering. However, the high computational costs associated with traditional methods, especially for large-scale simulations, present significant challenges. Peridynamics (PD) offers a compelling alternative to classical continuum mechanics by effectively modeling discontinuities such as cracks. Despite its strengths, PD is computationally intensive, limiting its broader application. To address these challenges, we introduce a machine learning-accelerated PD model that significantly reduces computational time while maintaining high accuracy. Our method integrates a machine learning-based surrogate model trained on displacement field data, which efficiently approximates the behaviors of material points, bypassing the iterative processes of conventional PD simulations. This approach is validated through a series of benchmark tests, ranging from one-dimensional bars to three-dimensional beams, demonstrating speedups of over six times compared to traditional methods. The integration of machine learning with PD not only enhances computational efficiency but also expands the practical applicability of PD to large-scale engineering problems, making it a viable tool for a wide range of scientific and industrial applications.},
  archive      = {J_CMAME},
  author       = {Jiasheng Huang and J.X. Liew and Binbin Yin and K.M. Liew},
  doi          = {10.1016/j.cma.2025.117826},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117826},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Machine learning-accelerated peridynamics model for mechanical and failure behaviors of materials},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adjoint-based recovery of thermal fields from displacement
or strain measurements. <em>CMAME</em>, <em>438</em>, 117818. (<a
href="https://doi.org/10.1016/j.cma.2025.117818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A finite-element method dependent adjoint-based procedure to determine the temperature field of structures based on measured displacements/strains and a set of standard loads is developed and tested. Given a series of force and deformation measurements, the temperature field is obtained by minimizing the adequately weighted differences between the measured and computed values. Three numerical examples — a Plate With a Hole, a Bridge, and a Hoover Dam example — each with multiple sensors distributed in different configurations, demonstrate the procedure’s capabilities. A target temperature distribution is prescribed in all cases, and the displacement sensor data is recorded. The optimization algorithm (here, steepest descent with Barzilai–Borwein step) uses this data to optimize the temperatures such that the same deformation is obtained at the sensor locations. Vertex Morphing is used as a filter to mitigate the ill-conditioning. Results show that the proposed approach can accurately reconstruct the target thermal distribution, especially when more sensors are used. Additionally, it is observed that the sensors do not need to be positioned in the region of interest; the method remains effective as long as the sensors can detect changes related to that area. A comparison with standard spatial interpolation techniques, namely, k-nearest neighbors and ordinary and universal kriging, is performed using temperature sensors in the same configurations. The proposed approach performs remarkably better than the interpolation techniques with a reduction in the L 2 norm of up to 41.3%, 93.9%, and 41.3%, for the Plate With a Hole, the Bridge, and the Dam examples, respectively.},
  archive      = {J_CMAME},
  author       = {Talhah Shamshad Ali Ansari and Rainald Löhner and Roland Wüchner and Harbir Antil and Suneth Warnakulasuriya and Ihar Antonau and Facundo Airaudo},
  doi          = {10.1016/j.cma.2025.117818},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117818},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Adjoint-based recovery of thermal fields from displacement or strain measurements},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of an efficient shock sensor for high-order
multi-species compressible flow solvers on unstructured grids.
<em>CMAME</em>, <em>438</em>, 117816. (<a
href="https://doi.org/10.1016/j.cma.2025.117816">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many fluid flows of engineering interest involve high-density ratios, the formation of shock waves, and the presence of multiple chemical species. In these situations, obtaining accurate results depends on the computational fluid dynamics (CFD) algorithm’s ability to ensure stable and robust time and space discretization of the governing equations, effectively minimizing numerical diffusion. In this work, we develop and evaluate a low-dissipation, high-order solver for the Navier–Stokes equations applicable to compressible, multi-species flows within the OpenFOAM library. We introduce a new shock sensor specifically designed for high-order discretization methods, which guarantees accuracy up to the fourth order in both space and time when using unstructured grids. Additionally, this approach is compatible with real-gas equations of state. We evaluated the solver performances on three test cases, each chosen for its relevance to real-world engineering problems: a 1D multi-specie shock tube, a 2D shock tube where Richtmyer–Meshkov instability develops as a consequence of bubble-shock interaction, and, finally, the flow through the complex 3D geometry of a high-pressure fuel injector used in propulsion applications, to investigate its performances on unstructured grids. The results confirm the effectiveness of the proposed sensor in scenarios characterized by field discontinuities, shock waves, high-density ratio, and distorted grids. This means that our solver can accurately simulate complex fluid flows in engineering applications where these conditions are often encountered. The developed high-order scheme and shock sensor were implemented in an OpenFoam solver called rhoCubic4kFoam .},
  archive      = {J_CMAME},
  author       = {Francesco Duronio and Andrea Di Mascio},
  doi          = {10.1016/j.cma.2025.117816},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117816},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Development of an efficient shock sensor for high-order multi-species compressible flow solvers on unstructured grids},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust and efficient rate-independent crystal plasticity
model based on successive one-dimensional solution steps.
<em>CMAME</em>, <em>438</em>, 117815. (<a
href="https://doi.org/10.1016/j.cma.2025.117815">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An efficient stress update algorithm for rate-independent crystal plasticity is presented. A series of successive one-dimensional solution (SODS) steps traces the hypersurfaces describing the slip state for which the yield criteria of individual slip systems are fulfilled to identify the intersection of all hypersurfaces. This provides both the active set and all slip components without requiring iterative active set search procedures or inducing spurious slip on inactive systems. The basic SODS algorithm is accelerated by tracking the evolution of the active set. A fast Newton–Raphson procedure enables to obtain the solution for an unchanging active set directly, while line search and extrapolation procedures direct the SODS steps towards the solution faster. A regularised tangent modulus is proposed that eliminates stiffness jumps upon changes in active set to improve the convergence behaviour of outer (equilibrium) iterations conducted with the algorithm. The resulting stress update algorithm is highly stable and efficient, making it an attractive candidate for use in large-scale crystal plasticity FE simulations and homogenisation algorithms.},
  archive      = {J_CMAME},
  author       = {B. Nijhuis and E.S. Perdahcıoğlu and A.H. van den Boogaard},
  doi          = {10.1016/j.cma.2025.117815},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117815},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A robust and efficient rate-independent crystal plasticity model based on successive one-dimensional solution steps},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective optimization-inspired set theory-based
regularization approach for force reconstruction with bounded
uncertainties. <em>CMAME</em>, <em>438</em>, 117814. (<a
href="https://doi.org/10.1016/j.cma.2025.117814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In force reconstruction, multi-source incomplete information makes it difficult for traditional methods to model and solve the problem accurately, especially with noise or measurement errors. Inspired by multi-objective optimization, this paper proposes a novel set theory-based regularization approach (STR) to enhance adaptability to uncertainties and improve reconstruction accuracy and robustness. The nominal force inversion is constituted and then extended into the interval uncertainty framework, and an effective orthogonal sampling-based interval prediction method is proposed to analyze the coupled effect of force inversion and uncertainty propagation. Once the uncertainty level of the complex structure is known, this prediction method can accurately and quickly estimate the fluctuation bound of the identified force. Enlightened by the completely same logic between the regularization method used in force inversion and multi-objective optimization problem, namely, simultaneously satisfying the norm minimization of the solution and the residual parameter, this study develops a novel multi-objective optimization-inspired set theory-based regularization parameter selection method. This method incorporates the interval dominance relationship to select the most competitive regularization parameter under interval uncertainties. Therefore, an accurate reconstuction framework with bounded uncertainties is finally proposed and verified by two numerical examples.},
  archive      = {J_CMAME},
  author       = {Chen Yang and Qianqian Yu},
  doi          = {10.1016/j.cma.2025.117814},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117814},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Multi-objective optimization-inspired set theory-based regularization approach for force reconstruction with bounded uncertainties},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid isogeometric collocation method on implicitly
trimmed domains. <em>CMAME</em>, <em>438</em>, 117812. (<a
href="https://doi.org/10.1016/j.cma.2025.117812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel isogeometric collocation method (IGA-C) for trimmed domains, using weighted extended B-splines (WEB-splines). Our approach employs the implicit representations of the trimming boundaries to construct the weighted basis, which allows for the subsequent calculations based on a parametrization over a single tensor-product patch, despite the nontrivial shape of the domain. The stabilization of the weighted basis is accomplished by means of extension. We present the classification criterion and the calculation procedure for the extension coefficients of the inner B-splines. The utilization of WEB-splines in analysis enables a natural application of the Dirichlet boundary conditions. Additionally, we adopt a hybrid collocation–Galerkin approach to impose the Neumann boundary conditions on the trimming boundaries. Our proposed method combines the advantages of WEB-splines and IGA-C in terms of straightforward implementation, well-conditioned system matrices and high computational efficiency, which we illustrate by numerical tests on 2D and 3D trimmed geometries. The numerical results further demonstrate that our methodology guarantees the same convergence rates as IGA-C.},
  archive      = {J_CMAME},
  author       = {Jingjing Yang and Pei Zhou and Lin Lan and Chun-Gang Zhu},
  doi          = {10.1016/j.cma.2025.117812},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117812},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A hybrid isogeometric collocation method on implicitly trimmed domains},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variational multiscale evolve and filter strategies for
convection-dominated flows. <em>CMAME</em>, <em>438</em>, 117811. (<a
href="https://doi.org/10.1016/j.cma.2025.117811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evolve-filter (EF) model is a filter-based numerical stabilization for under-resolved convection-dominated flows. EF is a simple, modular, and effective strategy for both full-order models (FOMs) and reduced-order models (ROMs). It is well-known, however, that when the filter radius is too large, EF can be overdiffusive and yield inaccurate results. To alleviate this, EF is usually supplemented with a relaxation step. The relaxation parameter, however, is very sensitive with respect to the model parameters. In this paper, we propose a novel strategy to alleviate the EF overdiffusivity. Specifically, we leverage the variational multiscale (VMS) framework to separate the large resolved scales from the small resolved scales in the evolved velocity, and we use the filtered small scales to correct the large scales. Furthermore, in the new VMS-EF strategy, we use two different approaches to decompose the evolved velocity: the VMS Evolve-Filter-Filter-Correct (VMS-EFFC) and the VMS Evolve-Postprocess-Filter-Correct (VMS-EPFC) algorithms. The new VMS-based algorithms yield significantly more accurate results than the standard EF in both the FOM and the ROM simulations of a flow past a cylinder at Reynolds number Re = 1000.},
  archive      = {J_CMAME},
  author       = {Maria Strazzullo and Francesco Ballarin and Traian Iliescu and Tomás Chacón Rebollo},
  doi          = {10.1016/j.cma.2025.117811},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117811},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Variational multiscale evolve and filter strategies for convection-dominated flows},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parallel spatiotemporal order-reduced gaussian process for
dynamic full-field multi-physics prediction of hypervelocity collisions
in real-time with limited data. <em>CMAME</em>, <em>438</em>, 117810.
(<a href="https://doi.org/10.1016/j.cma.2025.117810">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven evaluation of full-field variables over time poses considerable challenges and little explored. Therefore, we propose a novel dynamic parallel spatiotemporal order reduced Gaussian Process scheme (Dyna-PSTORGP) to accurately predict the full-field, time-sequenced multi-physics responses of hypervelocity collisions in real-time using limited data. In which, we first propose parallel and reduction in space and temporal dimensionalities and investigate the optimal temporal reconstruction method, establishing the spatial-temporal unified latent (feature) spaces that efficiently decouple the strong nonlinear and multi-physics dynamic responses. Next, we propose a hierarchical parallel multi-Gaussian Processes model, emulating the maps from initial input conditions to spatiotemporal order-reduced dynamic response. This hierarchical parallelism operates on two levels: an inner parallel modeling across each component of order-reduced spatial output within individual time steps, and an outer parallel modeling across the reduced time steps. This dual-layered structure not only enhances computational efficiency and enables accurate dynamic response predictions across spatiotemporal scales, effectively addressing the common issue of error accumulation in sequential prediction, but also ensures rapid training and prediction with confidence intervals. Moreover, we investigated different kernels and sensitivity to assess the effects of varying initial conditions in hypervelocity collisions, revealing the collision inclination angle exerts a greater influence on the damage response than both the direction angle and collision velocity. Numerical examples, including simulations on the Whipple shield and space station, validate the Dyna-PSTORGP model&#39;s capability for rapid parallel construction and training, completing in seconds (e.g., 12.8 s) with a limited dataset (e.g., 125 samples). The model achieves real-time, high-precision multi-physics predictions for complex nonlinear hypervelocity collisions (e.g., 1.9 s) and consistently maintains high accuracy (e.g., relative errors &lt;5 %) across full-field, high-dimensional scenarios (e.g., 1,134,172 degrees of freedom).},
  archive      = {J_CMAME},
  author       = {Zhuosen Wang and Yunguo Cheng and Chensen Ding},
  doi          = {10.1016/j.cma.2025.117810},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117810},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Parallel spatiotemporal order-reduced gaussian process for dynamic full-field multi-physics prediction of hypervelocity collisions in real-time with limited data},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A discrete fiber dispersion model with octahedral symmetry
quadrature for mechanical analyses of skin corrective surgeries.
<em>CMAME</em>, <em>438</em>, 117809. (<a
href="https://doi.org/10.1016/j.cma.2025.117809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced simulations of the mechanical behavior of soft tissues frequently rely on structure-based constitutive models, including smeared descriptions of collagen fibers. Among them, the so-called Discrete Fiber Dispersion (DFD) modeling approach is based on a discrete integration of the fiber-strain energy over all the fiber directions. In this paper, we review the theoretical framework of the DFD model, including a derivation of the stress and stiffness tensors required for the finite element implementation. Specifically, their expressions for incompressible plane stress problems are obtained. The use of a Lebedev quadrature, built exploiting the octahedral symmetry, is then proposed, illustrating the particular choice adopted for the orientation of the integration points. Next, the convergence of this quadrature scheme is assessed by means of three numerical benchmark tests, highlighting the advantages with respect to other angular integration methods available in the literature. Finally, using the implemented model, we analyze the mechanical properties of the Z-plasty, a technique commonly used in reconstructive skin surgery, considering multiple geometrical configurations, orientations of the fibers, and levels of skin prestress. The results are presented in the form of mechanical quantities relevant to surgical practice.},
  archive      = {J_CMAME},
  author       = {Riccardo Alberini and Michele Terzano and Gerhard A. Holzapfel and Andrea Spagnoli},
  doi          = {10.1016/j.cma.2025.117809},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117809},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A discrete fiber dispersion model with octahedral symmetry quadrature for mechanical analyses of skin corrective surgeries},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiscale topology optimization of functionally graded
lattice structures based on physics-augmented neural network material
models. <em>CMAME</em>, <em>438</em>, 117808. (<a
href="https://doi.org/10.1016/j.cma.2025.117808">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a new framework for the simultaneous optimization of both the topology as well as the relative density grading of cellular structures and materials, also known as lattices. Due to manufacturing constraints, the optimization problem falls into the class of mixed-integer nonlinear programming problems. Since no algorithm is capable of solving these problems in polynomial time, we obtain a relaxed problem from a multiplicative split of the relative density and a penalization approach. The sensitivities of the objective function are derived such that any gradient-based solver might be applied for the iterative update of the design variables. In a next step, we introduce a material model that is parametric in the design variables of interest and suitable to describe the isotropic deformation behavior of quasi-stochastic lattices. For that, we derive and implement further physical constraints and enhance a physics-augmented neural network from the literature that was formulated initially for rhombic materials. Finally, to illustrate the applicability of the method, we incorporate the material model into our computational framework and exemplary optimize two-and three-dimensional benchmark structures as well as a complex aircraft component.},
  archive      = {J_CMAME},
  author       = {Jonathan Stollberg and Tarun Gangwar and Oliver Weeger and Dominik Schillinger},
  doi          = {10.1016/j.cma.2025.117808},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117808},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Multiscale topology optimization of functionally graded lattice structures based on physics-augmented neural network material models},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A parametric non-linear non-intrusive reduce-order model
using deep transfer learning. <em>CMAME</em>, <em>438</em>, 117807. (<a
href="https://doi.org/10.1016/j.cma.2025.117807">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reduced order modelling is popular and widely used in engineering as it has the potential to gain several orders of magnitude CPU speedup for simulations with different parameters such as different initial or boundary conditions. This work presents a new parametric non-linear non-intrusive reduced-order model (P-NLNIROM) for the fluid problems, which extends the capabilities for non-linear NIROM Fuet al. (2023) on parametric problems. The Deep Auto-Encoder (DAE), Deep Residual Learning Neural network (ResNet), and deep transfer learning are used to construct the P-NLNIROM. The DAE is developed to project or map the original high-dimensional dynamical systems into a much lower dimensional nonlinear reduced latent space and the deep ResNet is used to construct a set of functions that represents the relationships between model input parameters (such as initial or boundary conditions) and extracted representations in the latent or reduced space (reduced representation of fluid dynamics). Transfer learning is used to extend the predictive capability of the model for different parameters. The novelty of this work lies in that ResNet and transfer learning are used to predict different parametric conditions for the AutoEncoder-based, non-linear, non-intrusive reduced-order model (NLNIROM). Transfer learning expands the predictive range of parametric space and makes the transferred P-NLNIROM perform well with much less data. The capability of this new P-NLNIROM is illustrated numerically by two test cases: a lock exchange, and a flow past a cylinder. The results obtained show that the P-NLNIROM performs well and the transferred model shows more promising results under new parameter conditions.},
  archive      = {J_CMAME},
  author       = {R. Fu and D. Xiao and A.G. Buchan and X. Lin and Y. Feng and G. Dong},
  doi          = {10.1016/j.cma.2025.117807},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117807},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A parametric non-linear non-intrusive reduce-order model using deep transfer learning},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving hp-variational physics-informed neural networks
for steady-state convection-dominated problems. <em>CMAME</em>,
<em>438</em>, 117797. (<a
href="https://doi.org/10.1016/j.cma.2025.117797">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes and studies two extensions of applying hp-variational physics-informed neural networks, more precisely the FastVPINNs framework, to convection-dominated convection–diffusion–reaction problems. First, a term in the spirit of a SUPG stabilization is included in the loss functional and a network architecture is proposed that predicts spatially varying stabilization parameters. Having observed that the selection of the indicator function in hard-constrained Dirichlet boundary conditions has a big impact on the accuracy of the computed solutions, the second novelty is the proposal of a network architecture that learns good parameters for a class of indicator functions. Numerical studies show that both proposals lead to noticeably more accurate results than approaches that can be found in the literature.},
  archive      = {J_CMAME},
  author       = {Thivin Anandh and Divij Ghose and Himanshu Jain and Pratham Sunkad and Sashikumaar Ganesan and Volker John},
  doi          = {10.1016/j.cma.2025.117797},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117797},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Improving hp-variational physics-informed neural networks for steady-state convection-dominated problems},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Empowering approximate bayesian neural networks with
functional priors through anchored ensembling for mechanics surrogate
modeling applications. <em>CMAME</em>, <em>438</em>, 117645. (<a
href="https://doi.org/10.1016/j.cma.2024.117645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, neural networks (NNs) have become increasingly popular for surrogate modeling tasks in mechanics and materials modeling applications. While traditional NNs are deterministic functions that rely solely on data to learn the input–output mapping, casting NN training within a Bayesian framework allows to quantify uncertainties, in particular epistemic uncertainties that arise from lack of training data, and to integrate a priori knowledge via the Bayesian prior. However, the high dimensionality and non-physicality of the NN parameter space and the complex relationship between parameters (NN weights) and predicted outputs renders both prior design and posterior inference challenging. In this work, we present a novel BNN training scheme based on anchored ensembling that can integrate a priori information available in the function space from, e.g., low-fidelity models. The anchoring scheme makes use of low-rank correlations between NN parameters, learned from pre-training to realizations of the functional prior. We also perform a study to demonstrate how correlations between NN weights, which are often neglected in existing BNN implementations, are critical to appropriately transfer knowledge between the function-space and parameter-space priors. The performance of our novel approximate BNN algorithm is first studied on a small 1D example to illustrate the algorithm’s behavior in both interpolation and extrapolation settings. Then, a thorough assessment is performed on a multi-input–output materials surrogate modeling example, where we demonstrate the algorithm’s capabilities both in terms of accuracy and quality of the uncertainty estimation for both in-distribution and out-of-distribution data.},
  archive      = {J_CMAME},
  author       = {Javad Ghorbanian and Nicholas Casaprima and Audrey Olivier},
  doi          = {10.1016/j.cma.2024.117645},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {4},
  pages        = {117645},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Empowering approximate bayesian neural networks with functional priors through anchored ensembling for mechanics surrogate modeling applications},
  volume       = {438},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="comcom---27">COMCOM - 27</h2>
<ul>
<li><details>
<summary>
(2025). Research on intelligent ship resilient network architecture
based on SDN. <em>COMCOM</em>, <em>236</em>, 108151. (<a
href="https://doi.org/10.1016/j.comcom.2025.108151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the extensive adoption of information and communication technology (ICT) in the maritime field, intelligent ships are increasingly dependent on system integration, control, and data collection from devices. Real-time data transmission is essential for ensuring stable ship system operations. However, communication link failures frequently become key factors impacting data transmission. To this end, we propose an SDN-based intelligent ship network architecture, SDN-Intelligent Ship Network Architecture (SDISN), to simplify network management and enable centralized control of intelligent ships. On this basis, we design a link failure recovery model tailored for different maritime communication services to address the issue of sudden communication link failures. The model begins by collecting the status of the intelligent ship network and pre-defining backup flow rules for different maritime communication service flows. Considering the service flow characteristics, the optimization aims to minimize transmission delay and maximize switch TCAM utilization for life-safety communication flows and ship operational communication flows, respectively. For life-safety communication flows, we introduce a heuristic algorithm that progressively relaxes constraints. Meanwhile, we preload backup flow rules into switches. For ship operational communication flows, we apply a two-stage optimization algorithm, storing the relevant backup flow rules in the controller. Additionally, we propose a backup storage strategy for commercial communication flows based on dynamically adjusting the memory load of switches. Compared to existing approaches, the SDISN satisfies the need for real-time data transmission in intelligent ships while balancing resource consumption and fault response time in its link failure recovery mechanism. Lastly, experiments conduct on a testbed in a real network environment further validate the model&#39;s efficacy and efficiency.},
  archive      = {J_COMCOM},
  author       = {Qing Hu and Jiabing Liu and Zhengfei Wang and Haoyu Si and Sinian Jin and Ying Zhang and Jinhai Li},
  doi          = {10.1016/j.comcom.2025.108151},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108151},
  shortjournal = {Comput. Commun.},
  title        = {Research on intelligent ship resilient network architecture based on SDN},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LBMDTE: Multi-domain traffic engineering in distributed
software-defined networks. <em>COMCOM</em>, <em>236</em>, 108147. (<a
href="https://doi.org/10.1016/j.comcom.2025.108147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale Software-Defined Networks (SDN) applications rely on a distributed control architecture to manage network resources collaboratively among multiple subdomains. This requires multi-domain traffic engineering (TE) for reliable, comprehensive, and efficient traffic scheduling. However, the impact of control message traffic on link load has been ignored in previous multi-domain TE studies. Here, we explore a multi-objective load balancing scheme to address the traffic scheduling imbalance problem for the flat distributed architecture. First, we introduce four types of control message traffic and rules for intra-domain and inter-domain communication. Second, we develop a traffic optimization model to balance the controller load and minimize the maximum link utilization. Third, we propose a hierarchical routing algorithm to compute inter-domain routing, and then propose a heuristic Load Balancing Based Multi-Domain Traffic Engineering (LBMDTE) algorithm to address the optimization objective. Experiments conducted on three real networks and one synthetic network demonstrate that the control link traffic accounts for up to 11.32% of the total link traffic. Our proposed LBMDTE is able to jointly balance the controller load and the link load in comparison with other TE mechanisms.},
  archive      = {J_COMCOM},
  author       = {Kun Wang and Guanghong Lv},
  doi          = {10.1016/j.comcom.2025.108147},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108147},
  shortjournal = {Comput. Commun.},
  title        = {LBMDTE: Multi-domain traffic engineering in distributed software-defined networks},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive survey of network digital twin architecture,
capabilities, challenges, and requirements for edge–cloud continuum.
<em>COMCOM</em>, <em>236</em>, 108144. (<a
href="https://doi.org/10.1016/j.comcom.2025.108144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network Digital Twin (NDT) collects data from physical, virtual, and software components and supports real-time network performance analysis, emulation, and intelligent physical network control. This paper surveys the current state of NDT specifications and explores NDT benefits for Network Operators (NOs) and its possible roles in future network management. It discusses the NDT key components, architecture, and integration of Machine Learning and Artificial Intelligence models in the NDT. Further, it covers virtualization technology management, suitability of Software-Defined Networking capabilities, and simulation tools to empower NDT. Two perspectives make the position of this survey different from existing studies; first, it highlights NDT limitations regarding Edge–Cloud Continuum (ECC) contextualization. ECC is a purposeful trending integration of Edge and Cloud Computing, involving multiple stakeholders like Service Providers, Customers, and Platform or Infrastructure Providers. However, current NDT specifications have not mentioned the ways to benefit stakeholders other than NOs. We also discuss notable computing and communication technologies transformations necessary to consider during NDT modeling, the existing data models, and reusable vocabularies that can be extended to achieve a detailed ECC representation for all stakeholders, essentially for Service Providers and Customers. Secondly, a data model is proposed that covers descriptive and prescriptive features and aims to provide a granular representation of ECC components to meet stakeholders’ requirements and render particular user information views. Different explored NDT perspectives, and proposed data model reduces the impact of existing NDT limitations in ECC representation.},
  archive      = {J_COMCOM},
  author       = {Syed Mohsan Raza and Roberto Minerva and Noel Crespi and Maira Alvi and Manoj Herath and Hrishikesh Dutta},
  doi          = {10.1016/j.comcom.2025.108144},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108144},
  shortjournal = {Comput. Commun.},
  title        = {A comprehensive survey of network digital twin architecture, capabilities, challenges, and requirements for Edge–Cloud continuum},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). INT-LLPP: Lightweight in-band network-wide telemetry with
low-latency and low-overhead path planning. <em>COMCOM</em>,
<em>236</em>, 108142. (<a
href="https://doi.org/10.1016/j.comcom.2025.108142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing complexity of networks, network telemetry becomes a critical part of network management. However, existing network telemetry systems still suffer from excessive control overhead, forwarding overhead, and latency. In this paper, we propose INT-LLPP, a novel in-band network-wide telemetry system with low-latency and low-overhead path planning. The network telemetry architecture of INT-LLPP is unique in that it only requires a set of probes to collect telemetry items for multiple service flows. Moreover, the proposed Probe Path Generation (PPG) algorithm optimizes the probe paths to reduce the forwarding overhead and achieve full network coverage. To balance the telemetry latency and control overhead, we propose an efficient algorithm called the Simulated Annealing Maximum Latency Setting (SAMLS) algorithm, which controls the length of the probe paths. Simulation results show that INT-LLPP can reduce network telemetry control overhead by over 50% and reduce forwarding overhead by 5% to 10%. Moreover, INT-LLPP can lower telemetry latency by 30% to 40%.},
  archive      = {J_COMCOM},
  author       = {Penghui Zhang and Hua Zhang and Yuqi Dai and Cheng Zeng and Jingyu Wang and Jianxin Liao},
  doi          = {10.1016/j.comcom.2025.108142},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108142},
  shortjournal = {Comput. Commun.},
  title        = {INT-LLPP: Lightweight in-band network-wide telemetry with low-latency and low-overhead path planning},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient paths determining strategies in mobile
crowd-sensing networks with AI-based sensors forwarding data.
<em>COMCOM</em>, <em>236</em>, 108138. (<a
href="https://doi.org/10.1016/j.comcom.2025.108138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selecting a sufficient number of mobile users to collect and upload collected data to the server is a critical issue in the Mobile Crowd-sensing Networks (MCN). Previous studies have assumed that mobile users upload collected data over cellular networks, which could cause heavily burden to users. This work focus on how to forward collected data by pre-deployed wireless sensors which can fuse collected data and operate as edge nodes. Specifically, given the reward paid to each mobile user depends on the time he spends on data collection and uploading, this work investigates the problem how to select Points of Interest (PoIs) and edge nodes for participants who already have schedules with the objective of minimizing the total reward paid to all participants. We boil down this problem to the problem of determining path for each participant which connects participant’s initial location to PoI, then to an edge node and finally to participant’s destination. We formulate it as Paths determination with Cost Minimization problem. We can prove that this problem is an NP-Complete problem. Considering that the sensors acted as edge nodes which may be rechargeable or have limited energy, we design three heuristic algorithms: Minimum Cost Algorithm (MCA), Minimum Cost with Energy Consideration Algorithm (MCECA), and Energy Balance Algorithm (EBA) to address this problem. Finally, we conduct extensive simulations to validate the efficiency of the proposed algorithms. The results demonstrate that MCA finds paths for users with lower cost, while EBA effectively balances the energy consumption of edge nodes.},
  archive      = {J_COMCOM},
  author       = {Jiaoyan Chen and Jin Liu and Zhehao Cheng and Laurence Tianruo Yang and Xianjun Deng and Yihong Chen},
  doi          = {10.1016/j.comcom.2025.108138},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108138},
  shortjournal = {Comput. Commun.},
  title        = {Efficient paths determining strategies in mobile crowd-sensing networks with AI-based sensors forwarding data},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PDSLS: An approximation SINR-based shortest link scheduling
algorithm with power control. <em>COMCOM</em>, <em>236</em>, 108137. (<a
href="https://doi.org/10.1016/j.comcom.2025.108137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we examine the Shortest Link Scheduling (SLS) issue in wireless networks within the context of the Signal-to-Interference-plus-Noise-Ratio ( SINR ) interference model with oblivious power control, and propose an approximation Diamond-based SLS with Power control (PDSLS) algorithm. Given that numerous nodes within wireless networks operate on battery power, minimizing the transmission power not only reduces interference but also conserves energy. We adopt a novel link classification approach, reducing nodes’ transmission power without generating “black and gray” links. We schedule links belonging to each class by dividing the link deployment plane into diamonds. The validity and efficacy of our algorithm are demonstrated through theoretical analysis and simulation outcomes. Numerical analysis shows that our approximation ratio is tighter than the best known ones in state-of-the-art algorithms. Simulation results demonstrate that the proposed algorithm effectively reduces the transmission power and the number of required time slots compared to the state-of-the-art algorithms.},
  archive      = {J_COMCOM},
  author       = {Neda Mohammadi and Bahram Sadeghi Bigham and Mehdi Kadivar},
  doi          = {10.1016/j.comcom.2025.108137},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108137},
  shortjournal = {Comput. Commun.},
  title        = {PDSLS: An approximation SINR-based shortest link scheduling algorithm with power control},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI-powered resilience: A dual-approach for outage management
in dense cellular networks. <em>COMCOM</em>, <em>236</em>, 108129. (<a
href="https://doi.org/10.1016/j.comcom.2025.108129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As 5G evolves to 6G, network management faces growing challenges with increasing base station density, leading to more frequent outages. To address this, we introduce a robust, automated two-tier framework for outage management. The first tier involves an artificial intelligence-based outage detection scheme using an enhanced XGBoost model (Impv-XGBoost), which incorporates autoencoder outputs for hyperparameter tuning. The analysis shows Impv-XGBoost’s superior performance in high shadowing conditions and with sparse data, outperforming existing methods. The second tier adopts an actor–critic reinforcement learning strategy for outage compensation by adjusting the tilt of the neighboring base station and power. To prevent service declines to connected user equipment, our compensation scheme accounts for both outage-affected users and those connected to compensating base stations. We design a reward scheme that combines Jain’s fairness index and the geometric mean of the reference signal received power to ensure fairness and enhance convergence. Performance evaluations for single and multiple base station failures show coverage improvements for outage-affected users without compromising the coverage of the users in compensating base stations.},
  archive      = {J_COMCOM},
  author       = {Waseem Raza and Muhammad Umar Bin Farooq and Aneeqa Ijaz and Marvin Manalastas and Ali Imran},
  doi          = {10.1016/j.comcom.2025.108129},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108129},
  shortjournal = {Comput. Commun.},
  title        = {AI-powered resilience: A dual-approach for outage management in dense cellular networks},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SQID: A deep learning and network design synergy for
next-generation IoT resource allocation management. <em>COMCOM</em>,
<em>236</em>, 108128. (<a
href="https://doi.org/10.1016/j.comcom.2025.108128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential growth of mobile broadband and Internet of Things (IoT) devices has pushed traditional IoT models to their operational limits, necessitating more efficient data management strategies. This research introduces the SQID framework, a solution that integrates advanced techniques, including Sierpinski triangle design (STD) for network optimization, quantum density peak clustering (QDPC) for intelligent device clustering, and improved deep deterministic policy gradient (IDDPG) for deep learning-driven traffic prediction. By utilizing STD to optimize device communication, the framework applies the QDPC algorithm to efficiently cluster devices, ensuring balanced packet distribution and minimizing latency. Additionally, IDDPG enhances network performance by enabling accurate traffic prediction and resource allocation, optimizing data transmission. Extensive simulations reveal that SQID outperforms existing methods in critical metrics such as time efficiency, latency reduction, throughput maximization, and packet loss. These results indicate that SQID has the potential to significantly improve data management in IoT networks, paving the way for next-generation IoT advancements.},
  archive      = {J_COMCOM},
  author       = {Ali. M.A. Ibrahim and Zhigang Chen and Yijie Wang and Hala A. Eljailany},
  doi          = {10.1016/j.comcom.2025.108128},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108128},
  shortjournal = {Comput. Commun.},
  title        = {SQID: A deep learning and network design synergy for next-generation IoT resource allocation management},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Target wake time in IEEE 802.11 WLANs: Survey, challenges,
and opportunities. <em>COMCOM</em>, <em>236</em>, 108127. (<a
href="https://doi.org/10.1016/j.comcom.2025.108127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wi-Fi has become the most widely used Wireless Local Area Network (WLAN) technology, but as the density of WLAN deployments and the number of devices per network increase, congestion has become a significant issue. Scheduling features in Wi-Fi have the potential to alleviate these issues by managing medium access more efficiently. While there have been other scheduling features in Wi-Fi in the past, none were widely adopted and were limited in functionality. Target Wake Time (TWT) introduces powerful scheduling capabilities to Wi-Fi as part of Wi-Fi 6, representing a fundamental shift in how Wi-Fi Access Points (APs) manage channel access for Stations (STAs) while improving energy efficiency. TWT is extremely versatile and is poised to play a crucial role in reducing contention and enhancing performance, especially in dense network environments. The potential benefits are particularly valuable for Internet of Things (IoT) scenarios, where low power consumption and efficient medium access are essential due to the large number of connected devices. This paper presents an in-depth survey of the research on TWT, categorizing and analyzing existing literature while identifying practical challenges often overlooked due to idealized assumptions. We introduce comprehensive models of infrastructure-mode APs and STAs to facilitate discussions of current and future work. We provide a detailed analysis of the challenges and issues that must be addressed to fully realize the performance gains promised by TWT. Furthermore, we explore the potential future applications of TWT, particularly in conjunction with upcoming features in IEEE 802.11 such as multi-link operation (MLO) and multi-AP coordination, offering insights into novel uses of TWT for enhancing Wi-Fi performance.},
  archive      = {J_COMCOM},
  author       = {Shyam Krishnan Venkateswaran and Ching-Lun Tai and Atif Ahmed and Raghupathy Sivakumar},
  doi          = {10.1016/j.comcom.2025.108127},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108127},
  shortjournal = {Comput. Commun.},
  title        = {Target wake time in IEEE 802.11 WLANs: Survey, challenges, and opportunities},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards green networking: Efficient dynamic radio resource
management in open-RAN slicing using deep reinforcement learning and
transfer learning. <em>COMCOM</em>, <em>236</em>, 108126. (<a
href="https://doi.org/10.1016/j.comcom.2025.108126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Next Generation Wireless Networks (NGWNs) are characterized by agility and flexibility. It introduces new technologies such as network slicing (NS) and Open Radio Access Network (O-RAN). NS supports multiple services with different requirements whereas O-RAN supports different network suppliers and provides Mobile Network Operators (MNOs) more intelligent control. Deep Reinforcement Learning (DRL) techniques have been presented to address resource management and other problems in NGWNs in recent years. However, instability and lateness in convergence are the main obstacles against their adoption in live networks. Moreover, deep learning models consume lots of energy and emit significant amounts of carbon dioxide which badly impacts climate. This paper addresses solving the dynamic radio resource management (RRM) problem in O-RAN slicing with DRL and Transfer Learning (TL), focusing on proposing a green model that minimizes power and energy consumption, decreasing the carbon footprint. A new latency-and-reliability-based reward function is designed. Then, a variable threshold action filtration mechanism is proposed, and a policy TL approach is proposed to accelerate the performance in commercial networks. Compared with the state-of-the-art, this work significantly improved exploration stability, convergence speed, Quality of Service (QoS) satisfaction, power and energy consumption, and emitted carbon footprint.},
  archive      = {J_COMCOM},
  author       = {Heba Sherif and Eman Ahmed and Amira M. Kotb},
  doi          = {10.1016/j.comcom.2025.108126},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108126},
  shortjournal = {Comput. Commun.},
  title        = {Towards green networking: Efficient dynamic radio resource management in open-RAN slicing using deep reinforcement learning and transfer learning},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IoT edge network interoperability. <em>COMCOM</em>,
<em>236</em>, 108125. (<a
href="https://doi.org/10.1016/j.comcom.2025.108125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network interoperability is crucial for achieving seamless communication across Internet of Things (IoT) environments. IoT comprises heterogeneous devices and systems supporting diverse technologies, protocols, and manufacturers. Enabling devices to communicate and exchange data effectively, regardless of underlying protocols, is key to building cohesive and integrated IoT networks. IoT has transformed multiple sectors ranging from home automation to healthcare—by harnessing a vast array of sensors and actuators that communicate through cloud, fog, and edge layers. However, the variety in device manufacturing and communication standards demands interoperable interfaces, and most current solutions depend on cloud-based centralised architectures. These architectures introduce latency and scalability challenges, particularly for resource-constrained IoT devices that often struggle to communicate with the cloud due to limited resources. This paper addresses network interoperability at the IoT edge level, focusing on resource-efficient communication by integrating Wi-Fi and Bluetooth, two commonly used protocols in IoT ecosystems. We have implemented a network edge interoperability solution that supports effective data exchange between devices operating on these distinct protocols, enhancing the overall efficiency, flexibility, and scalability of IoT systems. Our approach allows devices interoperate by addressing network latency and bandwidth limitations, incorporating an integrated controller to facilitate broader applications and enhance performance across IoT networks. Our findings illustrate how bridging protocol differences can foster more resilient and adaptable IoT solutions, advancing the deployment of IoT applications across various domains and use cases.},
  archive      = {J_COMCOM},
  author       = {Tanzima Azad and M.A. Hakim Newton and Jarrod Trevathan and Abdul Sattar},
  doi          = {10.1016/j.comcom.2025.108125},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108125},
  shortjournal = {Comput. Commun.},
  title        = {IoT edge network interoperability},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A stochastic analysis of the gasper protocol.
<em>COMCOM</em>, <em>236</em>, 108123. (<a
href="https://doi.org/10.1016/j.comcom.2025.108123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ethereum has recently switched to a Proof of Stake consensus protocol called Gasper. We analyze Gasper using PRISM+ , an extension of the probabilistic model checker PRISM with primitives for modeling blockchain data types. PRISM+ is therefore used to rapidly and automatically analyze the robustness of Gasper when tuning, up or down, several basic parameters of the protocol, such as network latencies and number of validators. We also study the effectiveness of Gasper in updating stakes and its resilience to three attacks: the balance, bouncing and time attacks.},
  archive      = {J_COMCOM},
  author       = {Cosimo Laneve and Adele Veschetti},
  doi          = {10.1016/j.comcom.2025.108123},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108123},
  shortjournal = {Comput. Commun.},
  title        = {A stochastic analysis of the gasper protocol},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy efficient LEO satellite communications: Traffic-aware
payload switch-off techniques. <em>COMCOM</em>, <em>236</em>, 108122.
(<a href="https://doi.org/10.1016/j.comcom.2025.108122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low Earth orbit (LEO) satellite constellations have a pivotal role in shaping the future of communication networks by providing extensive global coverage. However, ensuring the long-term viability of LEO constellations relies on addressing significant challenges, particularly in the domains of energy efficiency and maximizing the lifespan of satellites. This paper introduces a novel approach that considers user traffic demands to optimize power consumption. By implementing a traffic-aware strategy, redundant satellites can be intelligently switched-off, resulting in significant power savings within the LEO constellation. To accomplish this objective, we formulate the problem of joint satellite beam assignment and beam power allocation as a mixed binary integer optimization problem while carefully considering the constraints imposed by satellite-user visibility and the need to fulfill the data traffic requirements of all ground users. To tackle the formulated problem, we employ a framework called the Difference of Convex Programming and Multiplier Penalty (DCMP) based convexification approach, which ensures convergence to a local optimum. The reformulated convex problem is solved using the low-complexity iterative algorithm, Successive Convex Approximation (SCA). Additionally, we propose a heuristic algorithm based on slant distance, which offers a simplified and efficient solution to the joint problem. To corroborate the effectiveness and validity of the proposed techniques, we assess and compare their performance via simulations, considering practical constellation patterns and realistic user traffic distribution. It has been shown that approximately 43% of the satellite nodes can be switched-off for energy saving, and thus, extending the constellation lifetime and reducing the aggregated interference from multi-beam satellites.},
  archive      = {J_COMCOM},
  author       = {Vaibhav Kumar Gupta and Hayder Al-Hraishawi and Eva Lagunas and Symeon Chatzinotas},
  doi          = {10.1016/j.comcom.2025.108122},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108122},
  shortjournal = {Comput. Commun.},
  title        = {Energy efficient LEO satellite communications: Traffic-aware payload switch-off techniques},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A defense mechanism for federated learning in AIoT through
critical gradient dimension extraction. <em>COMCOM</em>, <em>236</em>,
108114. (<a href="https://doi.org/10.1016/j.comcom.2025.108114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leveraging the distributed nature of the Internet of Things (IoT), Federated Learning (FL) facilitates knowledge transfer among heterogeneous IoT devices, enhancing the capabilities of Artificial Intelligence of Things (AIoT) while preserving data privacy. However, FL is susceptible to poisoning attacks such as label flipping, Gaussian, and backdoor attacks. Most existing defense strategies rely on robust aggregation algorithms that use the statistical properties of gradient vectors to counteract poisoning attacks, however, they often overlook the non-independent and identically distributed (non-iid) nature of client data, limiting their effectiveness in the IoT. We propose a method that combines cross-node Top-k gradient vector compression and Principal Component Analysis (PCA) dimensionality reduction to extract critical gradient dimensions. By clustering these essential dimensions and performing filtering, our approach effectively distinguishes malicious from benign clients in non-iid data scenarios. Additionally, we introduce a client trust-score assessment mechanism that continuously monitors client behavior and applies secondary filtering, further improving the identification of malicious clients. Experimental results on the CIFAR-10, MNIST, DomainNet, and Flowers102 datasets demonstrate that our method achieves higher model accuracy and robustness in non-iid data settings compared to existing defense strategies.},
  archive      = {J_COMCOM},
  author       = {Jian Xu and Bing Guo and Fei Chen and Yan Shen and Shengxin Dai and Cheng Dai and Yuchuan Hu},
  doi          = {10.1016/j.comcom.2025.108114},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108114},
  shortjournal = {Comput. Commun.},
  title        = {A defense mechanism for federated learning in AIoT through critical gradient dimension extraction},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing UAV delivery for pervasive systems through
blockchain integration and adversarial machine learning.
<em>COMCOM</em>, <em>236</em>, 108113. (<a
href="https://doi.org/10.1016/j.comcom.2025.108113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicles (UAVs), play a significant role in the advancement of pervasive systems by providing efficient, scalable, and innovative solutions in various sectors, such as smart cities or location-based services. However, the current UAV delivery scenario presents various challenges for recipients, including lengthy identity verification processes, privacy concerns, and risks of fraud and theft. In response to these issues, this paper proposes an innovative system that leverages Blockchain technology and Adversarial Machine Learning (AML) to tackle these problems effectively. The proposed system streamlines the verification process, enhances privacy safeguards, and reduces fraud risks. The integration of AML is crucial as it enables users to have greater control over their personal data, boosting privacy and security. AML also plays a critical role in this system by creating test scenarios that reinforce the machine learning model against adversarial threats, ensuring its precision and dependability in the face of malicious manipulations. The paper also provides details on the practical implementation and evaluation of this system in real-life adversarial situations. The evaluation results demonstrate superior performance on selected metrics, highlighting the potential of this system as an effective solution for verifying recipients in UAV delivery.},
  archive      = {J_COMCOM},
  author       = {Chengzu Dong and Shantanu Pal and Aiting Yao and Frank Jiang and Shiping Chen and Xiao Liu},
  doi          = {10.1016/j.comcom.2025.108113},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108113},
  shortjournal = {Comput. Commun.},
  title        = {Optimizing UAV delivery for pervasive systems through blockchain integration and adversarial machine learning},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decentralized coordination for resilient federated learning:
A blockchain-based approach with smart contracts and decentralized
storage. <em>COMCOM</em>, <em>236</em>, 108112. (<a
href="https://doi.org/10.1016/j.comcom.2025.108112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine Learning (ML) in distributed environments increasingly deals with sensitive data (like healthcare or financial records) that cannot be centrally stored or processed due to privacy concerns. Federated Learning (FL) addresses this by enabling model training across decentralized devices, but faces significant challenges including system reliability, node failures, and trust issues among participants. Traditional FL approaches often rely on centralized coordinators, creating single points of failure and potential security vulnerabilities. This paper presents a novel approach to FL that leverages smart contracts, blockchain, and decentralized storage to enhance the traceability and reliability of the learning process. Our proposed system architecture is fully decentralized, eliminating single points of failure and promoting cooperation through a rewarding mechanism. Unlike previous approaches that neglect node fault tolerance, we introduce a smart contract based scheme for managing node failures and electing the aggregator node. The presence of the smart contract, executed on a decentralized permissioned blockchain, provides reliability guarantees and eliminates the need for costly distributed algorithms in terms of message exchange. An experimental study is conducted to evaluate various aspects of the FL system. We present results related to the accuracy and effectiveness of the FL system on ML models. We also examine the performance related to the distribution of the weights of the ML model based on the use of IPFS. Furthermore, we analyze the performance of the smart contract in terms of gas consumption. Lastly, we investigate the impact of failures combined with incentive policies and aggregator election algorithms on the FL system. Our findings demonstrate the viability of the proposed approach, paving the way for more robust, reliable, and efficient FL systems.},
  archive      = {J_COMCOM},
  author       = {Stefano Ferretti and Lorenzo Cassano and Gabriele Cialone and Jacopo D’Abramo and Filippo Imboccioli},
  doi          = {10.1016/j.comcom.2025.108112},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108112},
  shortjournal = {Comput. Commun.},
  title        = {Decentralized coordination for resilient federated learning: A blockchain-based approach with smart contracts and decentralized storage},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Resiliency focused proactive lifecycle management for
stateful microservices in multi-cluster containerized environments.
<em>COMCOM</em>, <em>236</em>, 108111. (<a
href="https://doi.org/10.1016/j.comcom.2025.108111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Containerization has become fundamental to deploying cloud-native applications, allowing for the packaging and independent execution of applications. This approach speeds up deployment processes and facilitates the creation of various environments for feature testing. However, the ephemeral nature of containers poses a significant challenge to data persistence, especially during container restarts or migrations across different hosts. This paper proposes a proactive zero-touch management solution for stateful microservices applications, ensuring seamless application lifecycle management. Our solution integrates seamlessly with container platforms such as Kubernetes and supports multi-cluster environments, enhancing fault tolerance and data persistence in stateful applications. The solution has been thoroughly tested on different hardware configurations in the public cloud and with our on-premises servers.},
  archive      = {J_COMCOM},
  author       = {Abd Elghani Meliani and Mohamed Mekki and Adlen Ksentini},
  doi          = {10.1016/j.comcom.2025.108111},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108111},
  shortjournal = {Comput. Commun.},
  title        = {Resiliency focused proactive lifecycle management for stateful microservices in multi-cluster containerized environments},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Authenticated data visualization for hybrid blockchain-based
digital product passports. <em>COMCOM</em>, <em>236</em>, 108110. (<a
href="https://doi.org/10.1016/j.comcom.2025.108110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Digital Product Passport (DPP), introduced by the European Green Deal in 2022, is a key innovation designed to improve product sustainability and circularity by enabling secure and transparent communication among stakeholders. Despite its potential, existing blockchain-based implementations of the DPP face significant limitations, such as scalability challenges and usability issues, which hinder widespread adoption. To address these shortcomings, this paper proposes a hybrid blockchain-based implementation of the DPP that enhances data transparency, integrity, and accessibility while minimizing common drawbacks. The proposed solution utilizes a hybrid blockchain architecture, where data is collected and managed within a private blockchain network and notarized on a public blockchain. Additionally, the central problem of authenticated blockchain data visualization is addressed by proposing a new solution that not only ensures the provenance, integrity, and history consistency of DPP data, but also preserves these properties throughout data processing and visualization. Our experiments demonstrates the effectiveness of our approach, achieving low time consumption and storage overhead. To further promote transparency and collaboration, a selection of the implementation has been made available as open-source projects. We show that hybrid blockchains offer a promising path for realizing the full potential of the Digital Product Passport.},
  archive      = {J_COMCOM},
  author       = {Domenico Tortola and Claudio Felicioli and Andrea Canciani and Fabio Severino},
  doi          = {10.1016/j.comcom.2025.108110},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108110},
  shortjournal = {Comput. Commun.},
  title        = {Authenticated data visualization for hybrid blockchain-based digital product passports},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Active queue management in 5G and beyond cellular networks
using machine learning. <em>COMCOM</em>, <em>236</em>, 108108. (<a
href="https://doi.org/10.1016/j.comcom.2025.108108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a state-of-the-art framework for adapting Active Queue Management (AQM) in 5G and beyond cellular networks with disaggregated Radio Access Network (RAN) deployments. While existing AQM algorithms effectively mitigate bufferbloat in monolithic RAN deployments, their potential in disaggregated ones remains largely unexplored. This gap particularly relates to AQM algorithms relying on communication between layers distributed across distinct network entities to operate. Our research explores the current literature on AQM, identifies the gaps regarding disaggregated deployments, and introduces a comprehensive framework that employs Artificial Intelligence (AI) and Machine Learning (ML) within the RAN Intelligent Controller (RIC) for adapting AQM in such deployments. We evaluate our novel solution on a previously proposed AQM algorithm which requires cross-layer communication, using OpenAirInterface5G (OAI5G) to deploy a disaggregated RAN and a connected User Equipment (UE) that experiences realistic network conditions, including noise and mobility. Finally, we assess its accuracy through the Quality of Service (QoS) achieved for our disaggregated deployment on the NITOS testbed.},
  archive      = {J_COMCOM},
  author       = {Alexandros Stoltidis and Kostas Choumas and Thanasis Korakis},
  doi          = {10.1016/j.comcom.2025.108108},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108108},
  shortjournal = {Comput. Commun.},
  title        = {Active queue management in 5G and beyond cellular networks using machine learning},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). In-time conditional handover for B5G/6G. <em>COMCOM</em>,
<em>236</em>, 108107. (<a
href="https://doi.org/10.1016/j.comcom.2025.108107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conditional Handover (CHO) by the 3rd Generation Partnership Project (3GPP) enables efficient user mobility between Base Stations (BSs) by preselecting and preparing Target BSs (T-BSs). However, CHO relies on signal strength for T-BS selection, leading to resource blocking on multiple T-BSs due to signal fluctuations. Existing state-of-the-art methods use deep learning to narrow the list of T-BSs but still lack an effective method for resource reservation timing. This paper presents in-time CHO (iCHO) which exploits historical mobility data to estimate user dwell time at the current BS to reduce resource reservation duration. The proposed iCHO employs a Multivariate Multi-output Single-step Prediction (MMSP) model that leverages a multi-task learning approach to simultaneously predict the minimal list of required T-BSs together with the user dwell time. The model demonstrates remarkable performance across two mobility datasets of different scales, achieving T-BS prediction accuracies of 98% and 95%. It also ensures a 100% handover success rate with a minimum of three and four predicted T-BSs for both datasets, respectively, significantly limiting the list of T-BSs. Moreover, the MMSP model achieves a Mean Absolute Error (MAE) of 19 s and 45 s when predicting the user’s dwell time at the current BS. By utilizing these predictions, iCHO reserves resources at the minimum number of T-BSs immediately before handover. Thus, iCHO can save up to 99% of resources from blockage as compared to the CHO, enabling operators to increase revenue by serving up to eighteen more users with the saved resources.},
  archive      = {J_COMCOM},
  author       = {Sardar Jaffar Ali and Syed M. Raza and Huigyu Yang and Duc Tai Le and Rajesh Challa and Moonseong Kim and Hyunseung Choo},
  doi          = {10.1016/j.comcom.2025.108107},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108107},
  shortjournal = {Comput. Commun.},
  title        = {In-time conditional handover for B5G/6G},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing the ACME protocol to automate the management of
all x.509 web certificates (extended version). <em>COMCOM</em>,
<em>236</em>, 108106. (<a
href="https://doi.org/10.1016/j.comcom.2025.108106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {X.509 Public Key Infrastructures (PKIs) are widely used for managing X.509 Public Key Certificates (PKCs) to allow for secure communications and authentication on the Internet. PKCs are issued by a trusted third-party Certification Authority (CA), which is responsible for verifying the certificate requester’s information. Recent developments in web PKI show a high proliferation of Domain Validated (DV) certificates but a decline in Extended Validated (EV) certificates, indicating poor authentication of the entities behind web services. The ACME protocol facilitates the deployment of Web Certificates by automating their management. However, it is only limited to DV certificates. This paper proposes an enhancement to the ACME protocol for automating all types of Web X.509 PKCs by using W3C Verifiable Credentials (VCs) to assert a requester’s claims. We argue that any CA’s requirements for issuing a PKC can be expressed as a set of VCs returned in a Verifiable Presentation (VP) that could facilitate the issuance of high-profile certificates such as EV certificates. We also propose a generic communication workflow to request and present VPs, which interact with our ACME enhancement. In this regard, we present proof of our approach by using the OpenID for Verifiable Presentation protocol (OID4VP) to request and present VPs. To assess the feasibility of our solution, we conduct a complexity analysis, evaluating both computational and communication overhead compared to the standard ACME protocol. Finally, we present an implementation of our solution as proof-of-concept.},
  archive      = {J_COMCOM},
  author       = {David A. Cordova Morales and Ahmad Samer Wazan and David W. Chadwick and Romain Laborde and April Rains Reyes Maramara},
  doi          = {10.1016/j.comcom.2025.108106},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108106},
  shortjournal = {Comput. Commun.},
  title        = {Enhancing the ACME protocol to automate the management of all x.509 web certificates (Extended version)},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-layer guided reinforcement learning task offloading
based on softmax policy in smart cities. <em>COMCOM</em>, <em>235</em>,
108105. (<a href="https://doi.org/10.1016/j.comcom.2025.108105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge computing is an effective measure for addressing the high demand for computing power on the end-side due to dense task distribution in the mobile Internet. In the case of limited device resources and computing power, how to optimize the task offloading decision has become an important issue for improving computing efficiency. We improve the heuristic algorithm by combining the characteristics of intensive tasks, and optimize the task offloading decision at a lower cost. To overcome the limitation of requiring a large amount of real-time information, we utilize the RL algorithm and design a new reward function to enable the agent to learn from its interactions with the environment. Aiming at the poor performance of the system in the uncertain initial environment, we propose a Q-learning scheme based on the Softmax strategy for the multi-layer agent RL framework. The offloading process is optimized by coordinating agents with different views of the environment between each layer, while balancing the exploration and utilization relationship to improve the performance of the algorithm in a more complex dynamic environment. The experimental results show that in the mobile environment with high device density and diverse tasks, the proposed algorithm achieves significant improvements in key indicators such as task success rate, waiting time, and energy consumption. In particular, it exhibits excellent robustness and efficiency advantages in complex dynamic environments, far exceeding the current benchmark algorithm.},
  archive      = {J_COMCOM},
  author       = {Bin Wu and Liwen Ma and Yu Ji and Jia Cong and Min Xu and Jie Zhao and Yue Yang},
  doi          = {10.1016/j.comcom.2025.108105},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108105},
  shortjournal = {Comput. Commun.},
  title        = {Multi-layer guided reinforcement learning task offloading based on softmax policy in smart cities},
  volume       = {235},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DFFL: A dual fairness framework for federated learning.
<em>COMCOM</em>, <em>235</em>, 108104. (<a
href="https://doi.org/10.1016/j.comcom.2025.108104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is an emerging paradigm of distributed machine learning that facilitates collaborative training of a global model across multiple clients while preserving client-side data privacy. However, current equality fairness methodologies aim to maintain a more uniform performance distribution across clients, but they fail to consider the varying contributions of different clients. In contrast, collaboration fairness takes into account the contributions of clients but may exclude low-contributing clients in pursuit of the interests of high-contributing clients. To address these concerns, this paper proposes a novel Dual Fair Federated Learning (DFFL) framework. Specifically, we combine the concept of cosine annealing to evaluate each client’s contribution from two perspectives. Then, we utilize client’s contribution as the aggregation weight of the global model to improve the global model accuracy. Additionally, we introduce a personalized design and utilize client’s contribution as a regularization coefficient to achieve dual fairness. Furthermore, we conduct a theoretical analysis of the convergence of the global model. Finally, through comprehensive experiments on benchmark datasets, we demonstrate that our method achieves competitive predictive accuracy and dual fairness.},
  archive      = {J_COMCOM},
  author       = {Kaiyue Qi and Tongjiang Yan and Pengcheng Ren and Jianye Yang and Jialin Li},
  doi          = {10.1016/j.comcom.2025.108104},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108104},
  shortjournal = {Comput. Commun.},
  title        = {DFFL: A dual fairness framework for federated learning},
  volume       = {235},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cloud-edge-end integrated artificial intelligence based on
ensemble learning. <em>COMCOM</em>, <em>235</em>, 108103. (<a
href="https://doi.org/10.1016/j.comcom.2025.108103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have been extensively used in the domains of artificial intelligence (AI) applications. Their inherent complexity primarily drives the deployment of DNN models in cloud environments. However, the geographical distance between the cloud and the end-users fails to meet the low-latency requirements of time-sensitive applications. Edge computing has emerged as a viable way to address this issue, nevertheless, the inherent constraints of limited resources on edge servers pose challenges in supporting intricate models. Solutions relying on network compression or model segmentation often fall short in meeting both performance and reliability needs. For the few ensemble-based solutions, the diversity between base models is not fully explored, and the low-latency advantage of edge computing is not fully utilized. In this paper, we propose a cloud–edge-end integrated approach for building an efficient and reliable DNN inference platform based on ensemble learning. In this design, heterogeneous models are trained on the cloud according to the resource constraints of edge servers, and the inference process is performed independently on each edge server, whose outputs are combined at the end-user side to get the final result. Furthermore, a diversity-based deployment scheme is proposed to build a user-centric network for edge AI. The generation of base models is explored, and the effectiveness of the proposed approach is demonstrated through two case studies.},
  archive      = {J_COMCOM},
  author       = {Zhen Gao and Daning Su and Shuang Liu and Yuqi Zhang and Chenyang Wang and Cheng Zhang and Xiaofei Wang and Tarik Taleb},
  doi          = {10.1016/j.comcom.2025.108103},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108103},
  shortjournal = {Comput. Commun.},
  title        = {Cloud-edge-end integrated artificial intelligence based on ensemble learning},
  volume       = {235},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Load-balanced multi-user mobility-aware task offloading in
multi-access edge computing. <em>COMCOM</em>, <em>235</em>, 108102. (<a
href="https://doi.org/10.1016/j.comcom.2025.108102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In scenarios with dense user network service requests, multi-access edge computing demonstrates significant advantages in reducing user device load and decreasing service response time. However, the dynamic changes in user trajectories cause edge server load fluctuations, inevitably impacting the overall service processing performance. To tackle this problem, this paper introduces a load-balanced multi-user mobility-aware service request offloading method, achieving efficient service request offloading in mobile user scenarios. Specifically, this paper divides the service request offloading problem into two stages: dynamic edge server allocation and real-time offloading decision generation. In the first stage, users are allocated edge servers based on their location distribution, implementing an adaptive decreasing variance optimization server load balancing algorithm to achieve edge server load balancing. In the second stage, based on the edge server allocation results from the first stage, a latency performance self-optimizing task offloading decision-making algorithm is employed to minimize the processing latency of user requests, utilizing dueling double deep Q-network to generate real-time decisions on whether to offload service requests to the corresponding edge servers. According to experimental results, the proposed algorithm markedly decreases the processing latency of user network service requests in scenarios of different scales, with an average task completion rate of 99.94%. This effectively addresses the problem of inefficient processing requests caused by load fluctuations due to user movement in multi-access edge computing.},
  archive      = {J_COMCOM},
  author       = {Shanchen Pang and Meng Zhou and Haiyuan Gui and Xiao He and Nuanlai Wang and Luqi Wang},
  doi          = {10.1016/j.comcom.2025.108102},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108102},
  shortjournal = {Comput. Commun.},
  title        = {Load-balanced multi-user mobility-aware task offloading in multi-access edge computing},
  volume       = {235},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Secrecy performance optimization for UAV-based relay NOMA
systems with friendly jamming. <em>COMCOM</em>, <em>235</em>, 108086.
(<a href="https://doi.org/10.1016/j.comcom.2025.108086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Friendly jamming and relay are effective schemes in physical layer security (PLS) for enhancing security in wireless communication. By deploying unmanned aerial vehicle (UAV)-assisted Non-Orthogonal Multiple Access (NOMA) transmission can extend coverage and enhancing spectrum efficiency. This paper studies the physical layer security of an UAV-based relay NOMA system, consisting of a source, multiple users, and an eavesdropper. To enhance secrecy performance, an additional UAV is employed to transmit jamming signals to the eavesdropper. Moreover, for a more practical approach, we also consider the imperfect collaboration between the jammer device and the legitimate user. The minimum average secrecy rate (MASR) of the users is maximized, assuming that the eavesdropper is capable of intercepting signals both from the source and from the relay UAV. An efficient iterative algorithm is proposed to solve the MASR maximum problem by optimizing UAV trajectories, transmit power, and power allocation coefficients. Simulation results demonstrate that the proposed system achieves 238% better MASR than the system without friendly jamming signals and 633% better than the non-optimal system. In addition, the ability to decode the received signal using successive interference cancellation also significantly affects the MASR of users in the system.},
  archive      = {J_COMCOM},
  author       = {Thanh Trung Nguyen and Tran Manh Hoang and Phuong T. Tran},
  doi          = {10.1016/j.comcom.2025.108086},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108086},
  shortjournal = {Comput. Commun.},
  title        = {Secrecy performance optimization for UAV-based relay NOMA systems with friendly jamming},
  volume       = {235},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incentive mechanisms for non-proprietary vehicles in
vehicular crowdsensing with budget constraints. <em>COMCOM</em>,
<em>235</em>, 108083. (<a
href="https://doi.org/10.1016/j.comcom.2025.108083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicular crowdsensing (VCS) utilizes the onboard sensors and computational capabilities of smart vehicles to collect data across diverse regions. Non-dedicated vehicles, due to their lower cost and broad distribution, have emerged as a central focus in VCS research. However, their trajectories are often concentrated in urban areas, resulting in uneven data coverage. Existing incentive mechanisms primarily rely on platforms to dynamically adjust task allocation based on vehicle trajectory predictions. Yet, they frequently neglect the influence of geographic locations on vehicle routing choices and fail to incentivize proactive route planning. To address this, we propose a novel two-phase incentive mechanism that, for the first time, incorporates a willingness to traverse factor. This mechanism aims to maximize spatial coverage within a limited budget by encouraging vehicles to voluntarily traverse remote areas to complete tasks. In the initial phase, a multi-agent deep reinforcement learning algorithm dynamically adjusts each vehicle’s route and quote price, which is then reported to the platform. In the second phase, the platform allocates tasks and adjusts compensation based on the provided routes and quotes to optimize overall platform benefits. Experimental results show that our mechanism effectively balances platform and vehicle benefits, achieving optimal outcomes even under budget constraints.},
  archive      = {J_COMCOM},
  author       = {Zhirui Feng and Yantao Yu and Guojin Liu and Yang Jiang and TianCong Huang},
  doi          = {10.1016/j.comcom.2025.108083},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108083},
  shortjournal = {Comput. Commun.},
  title        = {Incentive mechanisms for non-proprietary vehicles in vehicular crowdsensing with budget constraints},
  volume       = {235},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="cor---16">COR - 16</h2>
<ul>
<li><details>
<summary>
(2025). Logic-based benders decomposition methods for the
distributed permutation flow shop scheduling problem with production and
transportation cost. <em>COR</em>, <em>179</em>, 107044. (<a
href="https://doi.org/10.1016/j.cor.2025.107044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed manufacturing mode can significantly enhance production flexibility and efficiency. Considering that factories and customers in distributed manufacturing environments may be geographically dispersed, we address a distributed permutation flow shop scheduling problem (DPFSP) with direct transportation under different cost of production and transportation while the goal is to minimize of weighted sum cost and makespan (DPFSP-PTM). First, we formulate two mixed-integer linear programming (MILP) models and one constraint programming (CP) model to optimize the objective simultaneously. Then, by decomposing DPFSP-PTM into an order assignment master problem (AMP) and a series of scheduling subproblems (SSPs), we develop two exact methods based on logic-based Benders decomposition (LBBD) and Branch-and-Check (BCH). To accelerate convergence, we propose three strong SSP relaxations based on the single-machine bottleneck to enhance the MILP models and AMP. Additionally, we introduce an initial solution generated by the iterated greedy (IG) algorithm to warm-start the LBBD. Finally, we demonstrate the effectiveness of the proposed methods in achieving competitive average optimality gaps and lower bounds across both small-scale and large-scale instances.},
  archive      = {J_COR},
  author       = {Fuli Xiong and Jiangbo Shi and Lin Jing and An Ping},
  doi          = {10.1016/j.cor.2025.107044},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {107044},
  shortjournal = {Comput. Oper. Res.},
  title        = {Logic-based benders decomposition methods for the distributed permutation flow shop scheduling problem with production and transportation cost},
  volume       = {179},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scheduling moldable tasks on homogeneous multi-cluster
platforms with GPUs. <em>COR</em>, <em>179</em>, 107041. (<a
href="https://doi.org/10.1016/j.cor.2025.107041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines task scheduling in homogeneous multi-cluster platforms, equipped with Graphics Processing Units (GPUs), with the aim of minimizing the makespan. We assume that tasks can be parallelized across these platforms under the moldable model. Recognizing the NP-hard nature of the problem, our goal is to develop algorithms that provide approximation ratios. While existing research has established algorithms for single-cluster GPU environments, scaling these to multi-cluster platforms introduces new challenges, especially due to the restriction that tasks cannot use processors from different clusters. We propose an integer programming-based algorithm that achieves an approximation ratio of 3 2 + ϵ , trading off runtime for an improved approximation ratio. Additionally, leveraging recent theoretical advancements, we have created a polynomial-time algorithm with an approximation ratio of 2 + ϵ . Empirical computational experiments show that our algorithms surpass their counterparts in empirical approximation ratios.},
  archive      = {J_COR},
  author       = {Fangfang Wu and Run Zhang and Xiandong Zhang},
  doi          = {10.1016/j.cor.2025.107041},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {107041},
  shortjournal = {Comput. Oper. Res.},
  title        = {Scheduling moldable tasks on homogeneous multi-cluster platforms with GPUs},
  volume       = {179},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-armed bandit for the cyclic minimum sitting
arrangement problem. <em>COR</em>, <em>179</em>, 107034. (<a
href="https://doi.org/10.1016/j.cor.2025.107034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs are commonly used to represent related elements and relationships among them. Signed graphs are a special type of graphs that can represent more complex structures, such as positive or negative connections in a social network. In this work, we address a combinatorial optimization problem, known as the Cyclic Minimum Sitting Arrangement, that consists of embedding a signed input graph into a cycle host graph, trying to locate in the embedding positive connected vertices closer than negative ones. This problem is a variant of the well-known Minimum Sitting Arrangement where the host graph has the structure of a path graph. To tackle the problem, we propose an algorithm based on the Multi-Armed Bandit method that combines three greedy-randomized constructive procedures with a Variable Neighborhood Descent local search algorithm. To assess the merit of our proposal, we compare it with the state-of-the-art method. Our experiments show that our algorithm outperforms the best-known method in the literature to date, and the results are statistically significant, establishing itself as the new state of the art for the problem.},
  archive      = {J_COR},
  author       = {Marcos Robles and Sergio Cavero and Eduardo G. Pardo and Oscar Cordón},
  doi          = {10.1016/j.cor.2025.107034},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {107034},
  shortjournal = {Comput. Oper. Res.},
  title        = {Multi-armed bandit for the cyclic minimum sitting arrangement problem},
  volume       = {179},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient iterated local search for the minimum
quasi-clique partitioning problem. <em>COR</em>, <em>179</em>, 107033.
(<a href="https://doi.org/10.1016/j.cor.2025.107033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a simple undirected graph G and a real constant γ ∈ ( 0 , 1 ] , a γ -quasi-clique is defined as a subset of vertices that induces a subgraph with an edge density of at least γ . The minimum quasi-clique partitioning problem (MQCPP) seeks to identify the minimum cardinality of γ -quasi-clique partitions in G . This work presents an efficient iterated local search (ILS) method to address MQCPP by using a two-phase local search procedure for local improvement, and a greedy-based perturbation procedure for diversifying the search process. An evaluation function that records the number of intra edges of each quasi-clique is used for neighboring solution evaluation, and a fast incremental evaluation technique is employed to speed up the evaluation. Numerical results on three sets of 321 benchmark instances demonstrate the superior performance of the proposed algorithm compared with state-of-the-art approaches. Specifically, ILS reports 153 (47.7%) new upper bounds and fails to reach the best known solution for only 2 instances. Additional analysis experiments are conducted to evaluate the effects of the key components of ILS, including the two-phase local search procedure, the greedy-based perturbation procedure, and the fast incremental evaluation technique.},
  archive      = {J_COR},
  author       = {Qing Zhou and Tongtong Zhu and Qinghua Wu and Zhong-Zhong Jiang and Wenjie Wang},
  doi          = {10.1016/j.cor.2025.107033},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {107033},
  shortjournal = {Comput. Oper. Res.},
  title        = {An efficient iterated local search for the minimum quasi-clique partitioning problem},
  volume       = {179},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Autonomous delivery vehicle routing problem with drones
based on multiple delivery modes. <em>COR</em>, <em>179</em>, 107032.
(<a href="https://doi.org/10.1016/j.cor.2025.107032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous delivery vehicles (ADVs) and drones have gained widespread attention in the last-mile delivery due to their efficiency, environmental sustainability, and convenience. Moreover, the cooperative delivery between ADVs and drones is very complex, and most of the existing studies are focused on the cooperative delivery between trucks and drones in a single delivery mode. In contrast, this paper introduces a new vehicle routing problem for an unmanned delivery system consisting of ADVs and heterogeneous drones based on multiple delivery modes. A mixed integer programming (MIP) model is constructed for the autonomous delivery vehicle routing problem with drones based on multiple delivery modes (ADVRPD-MDM) with the objective of minimizing cost. We design a randomized variable neighborhood search (RVNS) algorithm that incorporates 12 specific neighborhood structures, a random variable neighborhood descent (RVND) mechanism and a random shaking strategy to solve the model. We evaluate the application effects of each operator and verify the effectiveness of the RVNS algorithm by the improved Solomon instances. Furthermore, when compared to the large neighborhood search (LNS) algorithm in 56 instances, the RVNS algorithm demonstrates an average improvement of 3.86% in its lowest solution, thereby confirming its superior performance. Through a series of experiments, it has been observed that the integration of collaborative drones and parallel drones within the unmanned delivery system can effectively reduce the cost. The results of the sensitivity analysis demonstrate that factors such as the multi-visit capability, the utilization of multiple drones, the high payload capacity, the long endurance, and the rapid charging rate are critical in reducing the cost. Finally, we verify through a case study that the unmanned delivery system with the ADV as carrier offers cost advantages compared to those employing trucks.},
  archive      = {J_COR},
  author       = {Jili Kong and Hao Wang and Minhui Xie},
  doi          = {10.1016/j.cor.2025.107032},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {107032},
  shortjournal = {Comput. Oper. Res.},
  title        = {Autonomous delivery vehicle routing problem with drones based on multiple delivery modes},
  volume       = {179},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards more efficient local search for weighted graph
coloring problem in massive graphs. <em>COR</em>, <em>179</em>, 107031.
(<a href="https://doi.org/10.1016/j.cor.2025.107031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The weighted graph coloring problem (WGCP) is a well-known NP-hard combinatorial optimization problem with various practical applications. Due to its theoretical significance and practical relevance, numerous algorithms have been developed to address the WGCP. In the past, both exact and heuristic algorithms have primarily focused on solving classic benchmarks, with relatively few efforts dedicated to tackling the challenges posed by massive WGCP real-world applications. In our work, we propose an effective local search algorithm for the WGCP based on three main ideas. First, we introduce a new variant of configuration checking to escape from local optima. Second, we devise a novel method for selecting vertex movements that guides the search towards more favorable directions. Third, we propose a novel deep optimization strategy to perturb the solution. Extensive experiments demonstrate that our proposed algorithm outperforms several state-of-the-art algorithms on both classic and massive benchmarks. This indicates the effectiveness and superiority of our approach in solving the WGCP.},
  archive      = {J_COR},
  author       = {Shiwei Pan and Yujiao Zhao and Jiangnan Li and Yiyuan Wang and Ye Zhang and Wenbo Zhou and Minghao Yin},
  doi          = {10.1016/j.cor.2025.107031},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {107031},
  shortjournal = {Comput. Oper. Res.},
  title        = {Towards more efficient local search for weighted graph coloring problem in massive graphs},
  volume       = {179},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feasible and infeasible region search for the maximally
diverse grouping problem. <em>COR</em>, <em>179</em>, 107030. (<a
href="https://doi.org/10.1016/j.cor.2025.107030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The maximally diverse grouping problem (MDGP) involves assigning elements into disjoint groups, and its objective is to maximize the total diversity of the groups where each pair of elements in a group has a certain diversity. MDGP has broad application and is known to be an NP-hard problem. In this paper, we integrate infeasible region search, exploration, and exploitation into a new algorithm called the feasible and infeasible region (FIFR) algorithm. The FIFR algorithm is significantly better than three state-of-the-art algorithms on 500 instances widely used in the literature.},
  archive      = {J_COR},
  author       = {Xiaofan Wu and Jiejian Feng and Jinglei Yang and Yang Zhang},
  doi          = {10.1016/j.cor.2025.107030},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {107030},
  shortjournal = {Comput. Oper. Res.},
  title        = {Feasible and infeasible region search for the maximally diverse grouping problem},
  volume       = {179},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using machine learning to identify hidden constraints in
vehicle routing problems. <em>COR</em>, <em>179</em>, 107029. (<a
href="https://doi.org/10.1016/j.cor.2025.107029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Last-mile delivery involves a series of complex tasks in an unpredictable environment. Decision support tools based on optimization algorithms construct efficient routes for drivers, optimizing the cost of making deliveries. However, drivers often deviate from these routes due to factors not considered in the decision-making process. This discrepancy raises the question of how to identify routes that are useable in real-world scenarios. Our research proposes using modern machine learning techniques to classify routes based on their practical usability. In a controlled environment, we demonstrate that machine learning can learn hidden factors influencing route viability by focusing on variants of the vehicle routing problem with additional constraints like time window, capacity and precedence. For each underlying constraint, we show that a machine learning model can be trained to classify routes based on whether or not they violate the constraint. Using datasets generated from well-known benchmark instances, we present computational experiments to evaluate model performance. We discuss which types of constraints are more challenging to recognize and how large a dataset must be to allow for accurate classification. This research has the potential to improve existing decision tools, enabling them to generate routes that better account for real-world complexities.},
  archive      = {J_COR},
  author       = {Anna Konovalenko and Lars Magnus Hvattum and Mohamed Kais Msakni},
  doi          = {10.1016/j.cor.2025.107029},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {107029},
  shortjournal = {Comput. Oper. Res.},
  title        = {Using machine learning to identify hidden constraints in vehicle routing problems},
  volume       = {179},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online order acceptance and scheduling in a single machine
environment. <em>COR</em>, <em>179</em>, 107028. (<a
href="https://doi.org/10.1016/j.cor.2025.107028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the online order acceptance and scheduling (OAS) problem, a widely studied problem in its offline counterpart, where orders arrive online sequentially with associated rewards, arrival times, and due dates in a finite planning horizon. The objective is to make real-time order acceptance and scheduling decisions so as to maximize the total profit. To tackle this problem, we derive an upper bound on the competitive ratio of any online algorithm for the online OAS problem and introduce three algorithms (online greedy, online learning, and delay). For the online greedy algorithm, we provide a performance guarantee under the mild conditions via theoretical analysis. Furthermore, through computational studies we highlight that both the urgency of due dates of the orders and the workload level of the system can significantly influence the performance of the online algorithms. Since each proposed algorithm has its advantages and disadvantages, we categorize different scenarios for using the suitable algorithm, aiming at offering managerial insights for firms to make informed decisions.},
  archive      = {J_COR},
  author       = {Chunyan Zheng and Jin Yu and Guohua Wan},
  doi          = {10.1016/j.cor.2025.107028},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {107028},
  shortjournal = {Comput. Oper. Res.},
  title        = {Online order acceptance and scheduling in a single machine environment},
  volume       = {179},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective flexible job shop scheduling based on
feature information optimization algorithm. <em>COR</em>, <em>179</em>,
107027. (<a href="https://doi.org/10.1016/j.cor.2025.107027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective optimization methods are increasingly used in job shop scheduling optimization strategies. However, in the design process of multi-objective optimization strategies, a neighborhood search is performed on all solutions in the optimization algorithm, resulting in a time-consuming search. In the algorithm selection process, feature information carried by individuals is often ignored, leading to a lack of targeted guidance ability in the algorithm. To address the limitations of the existing methods, a multi-objective flexible job shop scheduling method based on a feature information optimization algorithm (FIOA) was proposed. First, a framework of multiple group optimization algorithms was applied to construct diverse groups. Subsequently, a representative individual selection strategy was applied to mine individual offspring information and accelerate population convergence. To balance the exploration ability and computational resources of the FIOA, multiple neighborhood search rules were used to improve the utilization rate of individual offspring. In this study, the parameter configuration of the proposed algorithm was calibrated using the Taguchi method. To evaluate the effectiveness and superiority of the FIOA, each improvement of the FIOA algorithm was evaluated. In addition, it was compared with state-of-the-art algorithms in benchmark tests, and the results showed that the FIOA outperformed the other algorithms in solving flexible job shop scheduling.},
  archive      = {J_COR},
  author       = {Zeyin Guo and Lixin Wei and Jinlu Zhang and Ziyu Hu and Hao Sun and Xin Li},
  doi          = {10.1016/j.cor.2025.107027},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {107027},
  shortjournal = {Comput. Oper. Res.},
  title        = {Multi-objective flexible job shop scheduling based on feature information optimization algorithm},
  volume       = {179},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bidding in day-ahead electricity markets: A dynamic
programming framework. <em>COR</em>, <em>179</em>, 107024. (<a
href="https://doi.org/10.1016/j.cor.2025.107024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Strategic bidding problems have gained a lot of attention with the introduction of deregulated electricity markets where producers and retailers trade electricity in a day-ahead market run by a Market Operator (MO). All actors propose bids composed of a unit production price and a quantity of electricity to the MO. Based on these bids, the MO selects the most interesting ones and defines the spot price of electricity at which all actors are paid. As the bids of all actors determine the price of electricity, a bidding Generation Company (GC) faces a high risk regarding its profit when placing bids as the bids of competitors are not known in advance. This paper proposes a novel dynamic programming framework for a GC’s Stochastic Bidding Problem (SBP) in the day-ahead market considering uncertainty over the competitor bids. We prove this problem is NP-hard and study two variants of this problem solved with the dynamic programming framework. Firstly, a relaxation provides an upper bound solved in polynomial time (SBP-R). Secondly, we consider a bidding problem using fixed bidding quantities (SBP-Q) that has previously been solved through heuristic methods. We prove that SBP-Q is NP-hard and solve it to optimality in pseudo-polynomial time. SBP-Q is solved on much larger instances than in previous studies. We show on realistic instances that its optimal value is typically under 1% of the optimal value of SBP by using the upper bound provided by SBP-R.},
  archive      = {J_COR},
  author       = {Jérôme De Boeck and Bernard Fortz and Martine Labbé and Étienne Marcotte and Patrice Marcotte and Gilles Savard},
  doi          = {10.1016/j.cor.2025.107024},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {107024},
  shortjournal = {Comput. Oper. Res.},
  title        = {Bidding in day-ahead electricity markets: A dynamic programming framework},
  volume       = {179},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The two-echelon vehicle routing problem with pickups,
deliveries, and deadlines. <em>COR</em>, <em>179</em>, 107016. (<a
href="https://doi.org/10.1016/j.cor.2025.107016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the Two-Echelon Vehicle Routing Problem with Pickups, Deliveries, and Deadlines (2E-VRP-PDD), an emerging routing variant addressing the operations of logistics companies connecting consumers and suppliers in metropolitan areas. Logistics companies typically organize their logistics in such metropolitan areas via multiple geographically dispersed two-echelon distribution systems. The 2E-VRP-PDD is the practical problem that needs to be solved within each of such a single two-echelon distribution system, thereby merging first and last-mile logistics operations. Specifically, it integrates the distribution of last-mile parcels from the hub via satellites to the consumers with the collection of first-mile parcels from the suppliers via satellites that return to the hub. Moreover, it considers deadlines before first-mile parcels arrive at the hub, which must be transported further in the network. We solve the 2E-VRP-PDD with a newly developed Adaptive Large Neighborhood Search (ALNS) combined with a post-process integer programming model. Our ALNS provides high-quality solutions on established benchmark instances from the literature. On a new benchmark set for the 2E-VRP-PDD, we find that modifying time restrictions, such as parcel delivery deadlines at the city hub, can lead to an 8.27% cost increase, highlighting the overhead associated with same-day delivery compared to next-day delivery operations. Finally, by analyzing real-life instances containing up to 2150 customers obtained from our industry collaborator in Jakarta, Indonesia, we show that our ALNS can reduce the cost of operations by up to 17.54% compared to current practice.},
  archive      = {J_COR},
  author       = {M. Arya Zamal and Albert H. Schrotenboer and Tom Van Woensel},
  doi          = {10.1016/j.cor.2025.107016},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {107016},
  shortjournal = {Comput. Oper. Res.},
  title        = {The two-echelon vehicle routing problem with pickups, deliveries, and deadlines},
  volume       = {179},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive stochastic programming model for transfer
synchronization in transit networks. <em>COR</em>, <em>179</em>, 107015.
(<a href="https://doi.org/10.1016/j.cor.2025.107015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the stochastic transfer synchronization problem, which seeks to synchronize the timetables of different routes in a transit network to reduce transfer waiting times, delay times, and unnecessary in-vehicle times. We present a sophisticated two-stage stochastic mixed-integer programming model that takes into account variability in passenger walking times between bus stops, bus running times, dwell times, and demand uncertainty. Our model incorporates new features related to dwell time determination by considering passenger arrival patterns at bus stops which have been neglected in the literature on transfer synchronization and timetabling. We solve a sample average approximation of our model using a problem-based scenario reduction approach, and the progressive hedging algorithm. As a proof of concept, our computational experiments on instances using transfer nodes in the City of Toronto, with a mixture of low- and high-frequency routes, demonstrate the potential advantages of the proposed model. Our findings highlight the necessity and value of incorporating stochasticity in transfer-based timetabling models.},
  archive      = {J_COR},
  author       = {Zahra Ansarilari and Merve Bodur and Amer Shalaby},
  doi          = {10.1016/j.cor.2025.107015},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {107015},
  shortjournal = {Comput. Oper. Res.},
  title        = {A comprehensive stochastic programming model for transfer synchronization in transit networks},
  volume       = {179},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). General polyhedral approximation of two-stage robust linear
programming for budgeted uncertainty. <em>COR</em>, <em>179</em>,
107014. (<a href="https://doi.org/10.1016/j.cor.2025.107014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider two-stage robust linear programs with uncertain righthand side. We develop a General Polyhedral Approximation (GPA), in which the uncertainty set U is substituted by a finite set of polytopes derived from the vertex set of an arbitrary polytope that dominates U . The union of the polytopes need not contain U . We analyze and computationally test the performance of GPA for the frequently used budgeted uncertainty set U (with m rows). For budgeted uncertainty affine policies are known to be best possible approximations (if coefficients in the constraints are nonnegative for the second-stage decision). In practice calculating affine policies typically requires inhibitive running times. Therefore an approximation of U by a single simplex has been proposed in the literature. GPA maintains the low practical running times of the simplex based approach while improving the quality of approximation by a constant factor. The generality of our method allows to use any polytope dominating U (including the simplex). We provide a family of polytopes that allows for a trade-off between running time and approximation factor. The previous simplex based approach reaches a threshold at Γ &gt; m after which it is not better than a quasi nominal solution. Before this threshold, GPA significantly improves the approximation factor. After the threshold, it is the first fast method to outperform the quasi nominal solution. We exemplify the superiority of our method by a fundamental logistics problem, namely, the Transportation Location Problem, for which we also specifically adapt the method and show stronger results.},
  archive      = {J_COR},
  author       = {Lukas Grunau and Tim Niemann and Sebastian Stiller},
  doi          = {10.1016/j.cor.2025.107014},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {107014},
  shortjournal = {Comput. Oper. Res.},
  title        = {General polyhedral approximation of two-stage robust linear programming for budgeted uncertainty},
  volume       = {179},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel hyper-heuristic based on surrogate genetic
programming for the three-dimensional spatial resource-constrained
project scheduling problem under uncertain environments. <em>COR</em>,
<em>179</em>, 107013. (<a
href="https://doi.org/10.1016/j.cor.2025.107013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a class of large and complex engineering projects with limited construction sites, three-dimensional (3D) spatial resources usually become a bottleneck that hinders their smooth implementation. A project schedule is easily disturbed by space conflicts and uncertain environments if these factors are not considered in advance. Firstly, we extend the traditional resource-constrained project scheduling problem (RCPSP) by considering 3D spatial resource constraints under uncertain environments, and propose a new three-dimensional spatial resource-constrained project scheduling problem with stochastic activity durations (3D-sRCPSPSAD). The activity schedule and the space allocation need to be decided simultaneously, so we design the first-fit and the best-fit strategies, and integrate them into the traditional resource-based policy to schedule activities and allocate 3D space. Secondly, a novel hyper-heuristic based on surrogate genetic programming (HH-SGP) is designed to evolve rules automatically for the 3D-sRCPSPSAD. The main goal of the surrogate model in HH-SGP is to construct an approximate model of the fitness function based on the random forest technique. Therefore, it can be used as an efficient alternative to the more expensive fitness function in the evolutionary process. More importantly, the weak elitism mechanism and other modified techniques are designed to improve the performance of HH-SGP. Thirdly, we configure the parameters of 3D spatial resources and generate numerical instances. Finally, from the aspects of solution quality and stability, we verify the efficiency, quality and convergence rate of HH-SGP under different uncertain environments. The effectiveness of the surrogate model, and the performance of the first-fit and the best-fit strategies are also analyzed through extensive numerical experiments. The results indicate that our designed HH-SGP algorithm performs better than traditional heuristics for the 3D-sRCPSPSAD, and the performance of the fitness function surrogate model in HH-SGP is generally better than without it. This study can also help project practitioners schedule activities and allocate spatial resources more effectively under various uncertain scenarios.},
  archive      = {J_COR},
  author       = {Lubo Li and Jingwen Zhang and Haohua Zhang and Roel Leus},
  doi          = {10.1016/j.cor.2025.107013},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {107013},
  shortjournal = {Comput. Oper. Res.},
  title        = {A novel hyper-heuristic based on surrogate genetic programming for the three-dimensional spatial resource-constrained project scheduling problem under uncertain environments},
  volume       = {179},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ship emission monitoring with a joint mode of motherships
and unmanned aerial vehicles. <em>COR</em>, <em>179</em>, 107012. (<a
href="https://doi.org/10.1016/j.cor.2025.107012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ship emission monitoring is crucial for improving compliance with emission control area (ECA) policies. To address the limitations of traditional base station-based monitoring methods, we propose a highly maneuverable mothership-based unmanned aerial vehicle (UAV) monitoring mode. We develop a mixed integer non-linear programming model to maximize the total profit (i.e., the revenues of ship emission monitoring minus the fixed costs of motherships and UAVs, the fuel cost of motherships, and the electricity cost of UAVs). Three types of integer variables are relaxed to continuous variables based on the model properties. We then design a tailored Benders decomposition algorithm to solve the model. Moreover, to improve the performance of the algorithm, we also present a variety of acceleration strategies, including lower bound limit inequalities and knapsack inequalities. Finally, we verify the effectiveness of the proposed algorithm using experimental instances based on the North American ECA. We also find a relationship between the width of emission inspection area and the total monitoring cost.},
  archive      = {J_COR},
  author       = {Dan Zhuge and Jianhui Du and Lu Zhen and Shuaian Wang and Peng Wu},
  doi          = {10.1016/j.cor.2025.107012},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {107012},
  shortjournal = {Comput. Oper. Res.},
  title        = {Ship emission monitoring with a joint mode of motherships and unmanned aerial vehicles},
  volume       = {179},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="csda---5">CSDA - 5</h2>
<ul>
<li><details>
<summary>
(2025). Regression analysis of elliptically symmetric directional
data. <em>CSDA</em>, <em>208</em>, 108167. (<a
href="https://doi.org/10.1016/j.csda.2025.108167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A comprehensive toolkit is developed for regression analysis of directional data based on a flexible class of angular Gaussian distributions. Informative testing procedures to assess rotational symmetry around the mean direction, and the dependence of model parameters on covariates are proposed. Bootstrap-based algorithms are provided to assess the significance of the proposed test statistics. Moreover, a prediction region that achieves the smallest volume in a class of ellipsoidal prediction regions of the same coverage probability is constructed. The efficacy of these inference procedures is demonstrated in simulation experiments. Finally, this new toolkit is used to analyze directional data originating from a hydrology study and a bioinformatics application.},
  archive      = {J_CSDA},
  author       = {Zehao Yu and Xianzheng Huang},
  doi          = {10.1016/j.csda.2025.108167},
  journal      = {Computational Statistics &amp; Data Analysis},
  month        = {8},
  pages        = {108167},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Regression analysis of elliptically symmetric directional data},
  volume       = {208},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exact designs for order-of-addition experiments under a
transition-effect model. <em>CSDA</em>, <em>208</em>, 108162. (<a
href="https://doi.org/10.1016/j.csda.2025.108162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the chemical, pharmaceutical, and food industries, sometimes the order of adding a set of components has an impact on the final product. These are instances of the Order-of-Addition (OofA) problem, which aims to find the optimal sequence of the components. Extensive research on this topic has been conducted, but almost all designs are found by optimizing the D −optimality criterion. However, when prediction of the response is important, there is still a need for I −optimal designs. Furthermore, designs are needed for experiments where some orders are infeasible due to constraints. A new model for OofA experiments is presented that uses transition effects to model the effect of order on the response. Three algorithms are proposed to find D − and I −efficient exact designs under this new model: Simulated Annealing, a metaheuristic algorithm, Bubble Sorting, a greedy local optimization algorithm, and the Greedy Randomized Adaptive Search Procedure (GRASP), another metaheuristic algorithm. These three algorithms are generalized to handle block constraints, where components are grouped into blocks with a fixed order. Finally, two examples are shown to illustrate the effectiveness of the proposed designs and models, even under block constraints.},
  archive      = {J_CSDA},
  author       = {Jiayi Zheng and Nicholas Rios},
  doi          = {10.1016/j.csda.2025.108162},
  journal      = {Computational Statistics &amp; Data Analysis},
  month        = {8},
  pages        = {108162},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Exact designs for order-of-addition experiments under a transition-effect model},
  volume       = {208},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An accurate computational approach for partial likelihood
using poisson-binomial distributions. <em>CSDA</em>, <em>208</em>,
108161. (<a href="https://doi.org/10.1016/j.csda.2025.108161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a Cox model, the partial likelihood, as the product of a series of conditional probabilities, is used to estimate the regression coefficients. In practice, those conditional probabilities are approximated by risk score ratios based on a continuous time model, and thus result in parameter estimates from only an approximate partial likelihood. Through a revisit to the original partial likelihood idea, an accurate partial likelihood computing method for the Cox model is proposed, which calculates the exact conditional probability using the Poisson-binomial distribution. New estimating and inference procedures are developed, and theoretical results are established for the proposed computational procedure. Although ties are common in real studies, current theories for the Cox model mostly do not consider cases for tied data. In contrast, the new approach includes the theory for grouped data, which allows ties, and also includes the theory for continuous data without ties, providing a unified framework for computing partial likelihood for data with or without ties. Numerical results show that the proposed method outperforms current methods in reducing bias and mean squared error, while achieving improved confidence interval coverage rates, especially when there are many ties or when the variability in risk scores is large. Comparisons between methods in real applications have been made.},
  archive      = {J_CSDA},
  author       = {Youngjin Cho and Yili Hong and Pang Du},
  doi          = {10.1016/j.csda.2025.108161},
  journal      = {Computational Statistics &amp; Data Analysis},
  month        = {8},
  pages        = {108161},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {An accurate computational approach for partial likelihood using poisson-binomial distributions},
  volume       = {208},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Communication-efficient estimation and inference for
high-dimensional longitudinal data. <em>CSDA</em>, <em>208</em>, 108154.
(<a href="https://doi.org/10.1016/j.csda.2025.108154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth in modern science and technology, distributed longitudinal data have drawn attention in a wide range of aspects. Realizing that not all effects of covariates are our parameters of interest, we focus on the distributed estimation and statistical inference of a pre-conceived low-dimensional parameter in the high-dimensional longitudinal GLMs with canonical links. To mitigate the impact of high-dimensional nuisance parameters and incorporate the within-subject correlation simultaneously, a decorrelated quadratic inference function is proposed for enhancing the estimation efficiency. Two communication-efficient surrogate decorrelated score estimators based on multi-round iterative algorithms are proposed. The error bounds and limiting distribution of the proposed estimators are established and extensive numerical experiments demonstrate the effectiveness of our method. An application to the National Longitudinal Survey of Youth Dataset is also presented.},
  archive      = {J_CSDA},
  author       = {Xing Li and Yanjing Peng and Lei Wang},
  doi          = {10.1016/j.csda.2025.108154},
  journal      = {Computational Statistics &amp; Data Analysis},
  month        = {8},
  pages        = {108154},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Communication-efficient estimation and inference for high-dimensional longitudinal data},
  volume       = {208},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Testing the constancy of the variance for time series with a
trend. <em>CSDA</em>, <em>208</em>, 108147. (<a
href="https://doi.org/10.1016/j.csda.2025.108147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The assumption of constant variance is fundamental in numerous statistical procedures for time series analysis. Nonlinear time series may exhibit time-varying local conditional variance, even when they are globally homoscedastic. Two novel tests are proposed to assess the constancy of variance in time series with a possible time-varying mean trend. Unlike previous approaches, the new tests rely on Walsh transformations of squared processes after recentering the time series data. It is shown that the corresponding Walsh coefficients have desirable properties, such as asymptotic independence. Both a max-type statistic and an order selection statistic are developed, along with their asymptotic null distributions. Furthermore, the consistency of the proposed statistics under a sequence of local alternatives is established. An extensive simulation study is conducted to examine the finite-sample performance of the procedures in comparison with existing methodologies. The empirical results show that the proposed methods are more powerful in many situations while maintaining reasonable Type I error rates, especially for nonlinear time series. The proposed methods are applied to test the global homoscedasticity of a financial time series, a well log time series with a non-constant mean structure, and a vibration time series.},
  archive      = {J_CSDA},
  author       = {Lei Jin and Li Cai and Suojin Wang},
  doi          = {10.1016/j.csda.2025.108147},
  journal      = {Computational Statistics &amp; Data Analysis},
  month        = {8},
  pages        = {108147},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Testing the constancy of the variance for time series with a trend},
  volume       = {208},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="cviu---5">CVIU - 5</h2>
<ul>
<li><details>
<summary>
(2025). Adversarial style mixup and improved temporal alignment for
cross-domain few-shot action recognition. <em>CVIU</em>, <em>255</em>,
104341. (<a href="https://doi.org/10.1016/j.cviu.2025.104341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-Domain Few-Shot Action Recognition (CDFSAR) aims at transferring knowledge from base classes to novel ones with limited labeled data, under distribution shift between base (source domain) and novel (target domain) classes. This paper addresses the issues of insufficient style coverage for the target domain and potential temporal misalignment with chronological order in existing methods. To mitigate distribution shifts across domains, we propose an Adversarial Style Mixup (ASM) module, which enriches the diversity of style distributions covering the target domain. ASM mixes up source and target domain styles through statistical means and variances, with the adversarially learned mixup ratio and style noise. On the other hand, we design an Improved Temporal Alignment (ITA) module to address the issue of temporal misalignment between videos. In the proposed ITA, keyframes are extracted as priors for better temporal alignment with a temporal mixer to reduce the misalignment noise. Extensive experiments on video action recognition datasets demonstrates the superiority of our method compared with the state of the arts for the challenging problem of CDFSAR. Ablation study validates that both the proposed ASM and ITA modules contribute to performance improvement by style distribution expansion and keyframe-based temporal alignment.},
  archive      = {J_CVIU},
  author       = {Kaiyan Cao and Jiawen Peng and Jiaxin Chen and Xinyuan Hou and Andy J. Ma},
  doi          = {10.1016/j.cviu.2025.104341},
  journal      = {Computer Vision and Image Understanding},
  month        = {4},
  pages        = {104341},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Adversarial style mixup and improved temporal alignment for cross-domain few-shot action recognition},
  volume       = {255},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Syntactically and semantically enhanced captioning network
via hybrid attention and POS tagging prompt. <em>CVIU</em>,
<em>255</em>, 104340. (<a
href="https://doi.org/10.1016/j.cviu.2025.104340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video captioning has become a thriving research area, with current methods relying on static visuals or motion information. However, videos contain a complex interplay between multiple objects with unique temporal patterns. Traditional techniques struggle to capture this intricate connection, leading to inaccurate captions due to the gap between video features and generated text. Analyzing these temporal variations and identifying relevant objects remains a challenge. This paper proposes SySCapNet, a novel deep-learning architecture for video captioning, designed to address this limitation. SySCapNet effectively captures objects involved in motions and extracts spatio-temporal action features. This information, along with visual features and motion data, guides the caption generation process. We introduce a groundbreaking hybrid attention module that leverages both visual saliency and spatio-temporal dynamics to extract highly detailed and semantically meaningful features. Furthermore, we incorporate part-of-speech tagging to guide the network in disambiguating words and understanding their grammatical roles. Extensive evaluations on benchmark datasets demonstrate that SySCapNet achieves superior performance compared to existing methods. The generated captions are not only informative but also grammatically correct and rich in context, surpassing the limitations of basic AI descriptions.},
  archive      = {J_CVIU},
  author       = {Deepali Verma and Tanima Dutta},
  doi          = {10.1016/j.cviu.2025.104340},
  journal      = {Computer Vision and Image Understanding},
  month        = {4},
  pages        = {104340},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Syntactically and semantically enhanced captioning network via hybrid attention and POS tagging prompt},
  volume       = {255},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FrTrGAN: Single image dehazing using the frequency component
of transmission maps in the generative adversarial network.
<em>CVIU</em>, <em>255</em>, 104336. (<a
href="https://doi.org/10.1016/j.cviu.2025.104336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hazy images, particularly in outdoor scenes, have reduced visibility due to atmospheric particles, making image dehazing a critical task for enhancing visual clarity. The main challenges in image dehazing involve accurately detecting and removing haze while preserving fine details and maintaining overall image quality. Many existing dehazing methods struggle with varying haze conditions, often compromising the structural and perceptual integrity of the restored images. In this paper, we introduce FrTrGAN, a framework for single-image dehazing that leverages the frequency components of transmission maps. This novel framework addresses these challenges by integrating the Fourier Transform within an enhanced CycleGAN architecture. Unlike traditional spatial-domain dehazing methods, FrTrGAN operates in the frequency domain, where it isolates low-frequency haze components – responsible for blurring fine details – and removes them more precisely. The Inverse Fourier Transform is then applied to map the refined data back to the spatial domain, ensuring that the resulting images maintain clarity, sharpness, and structural integrity. We evaluate our method on multiple datasets, including HSTS, SOTS Outdoor, O-Haze, I-Haze, D-Hazy, BeDDE and Dense-Haze using PSNR and SSIM for quantitative performance assessment. Additionally, we include results based on non-referential metrics such as FADE, SSEQ, BRISQUE and NIQE to further evaluate the perceptual quality of the dehazed images. The results demonstrate that FrTrGAN significantly outperforms existing methods while effectively restoring both frequency components and perceptual image quality. This comprehensive evaluation highlights the robustness of FrTrGAN in diverse haze conditions and underscores the effectiveness of a frequency-domain approach to image dehazing, laying the groundwork for future advancements in the field.},
  archive      = {J_CVIU},
  author       = {Pulkit Dwivedi and Soumendu Chakraborty},
  doi          = {10.1016/j.cviu.2025.104336},
  journal      = {Computer Vision and Image Understanding},
  month        = {4},
  pages        = {104336},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {FrTrGAN: Single image dehazing using the frequency component of transmission maps in the generative adversarial network},
  volume       = {255},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hexagonal mesh-based neural rendering for real-time
rendering and fast reconstruction. <em>CVIU</em>, <em>255</em>, 104335.
(<a href="https://doi.org/10.1016/j.cviu.2025.104335">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although recent neural rendering-based methods can achieve high-quality geometry and realistic rendering results in multi-view reconstruction, they incur a heavy computational burden on rendering and training, which limits their application scenarios. To address these challenges, we propose an effective mesh-based neural rendering approach which leverages the characteristic of meshes being able to achieve real-time rendering. Besides, a coarse-to-fine scheme is introduced to efficiently extract the initial mesh so as to significantly reduce the reconstruction time. More importantly, we suggest a hexagonal mesh model to preserve surface regularity by constraining the second-order derivatives of its vertices, where only low level of positional encoding is engaged for neural rendering. Experiments show that our approach significantly reduces the rendering time from several tens of seconds to 0.05s compared to methods based on implicit representation. And it can quickly achieve state-of-the-art results in novel view synthesis and reconstruction. Our full implementation will be made publicly available at https://github.com/FuchengSu/FastMesh .},
  archive      = {J_CVIU},
  author       = {Yisu Zhang and Jianke Zhu and Lixiang Lin},
  doi          = {10.1016/j.cviu.2025.104335},
  journal      = {Computer Vision and Image Understanding},
  month        = {4},
  pages        = {104335},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Hexagonal mesh-based neural rendering for real-time rendering and fast reconstruction},
  volume       = {255},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic anchor: Density map guided small object detector for
tiny persons. <em>CVIU</em>, <em>255</em>, 104325. (<a
href="https://doi.org/10.1016/j.cviu.2025.104325">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the application of aerial and space-based equipments, such as drones in the search and rescue process, there is an increasing demand on the detection of small and even tiny human targets. However, most existing detectors rely on generating smaller and denser anchors for small target detection, which introduces a high number of redundant negative anchor samples. To alleviate this issue, we propose a novel density map-guided tiny person detector with dynamic anchor. Specifically, we elaborately design an Anchor Proposals Mask (APM) module to effectively eliminate negative anchor samples and adaptively adjust anchor distribution with the guidance of density maps produced by Density Map Generator (DMG). To promote the quality of the density map, we develop a Multi-Scale Feature Distillation (MSFD) module and incorporate the Focal Inverse Distance Transform (FIDT) map to conduct knowledge distillation for DMG with the assistance of the crowd counting network. Extensive experiments on the TinyPerson and VisDrone datasets demonstrate that our method significantly enhances the performance of two-stage detectors in terms of average precision (AP) and average recall (AR) while effectively reducing the impact of negative anchor boxes.},
  archive      = {J_CVIU},
  author       = {Xingzhou Xu and Zhaoyong Mao and Xin Wang and Qinhao Tu and Junge Shen},
  doi          = {10.1016/j.cviu.2025.104325},
  journal      = {Computer Vision and Image Understanding},
  month        = {4},
  pages        = {104325},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Dynamic anchor: Density map guided small object detector for tiny persons},
  volume       = {255},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="dke---10">DKE - 10</h2>
<ul>
<li><details>
<summary>
(2025). An MDA approach for robotic-based real-time business
intelligence applications. <em>DKE</em>, <em>157</em>, 102418. (<a
href="https://doi.org/10.1016/j.datak.2025.102418">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industry 4.0, the fourth industrial revolution, has emerged from the convergence of robotics, automation, and the Internet of Things (IoT), transforming industrial processes with intelligent systems and digital integration. This revolution also brings with it Business Intelligence (BI) systems that enable the analysis of IoT and robotic data. The data architectures employed for BI in Industry 4.0 contexts are often intricate, typically comprising robots software, DBMSs, message brokers, and data stream management systems. Consequently, designing BI data-centric applications for Industry 4.0 presents a significant challenge. Inspired by the absence of modeling approaches for this type of application and by the well-established advantages of Model-Driven Architecture (MDA), this paper introduces a novel UML profile for real-time robotic data-driven BI applications. Our profile enables the representation of robotic and transactional data within a unified and consistent framework, enabling continuous queries over these streams. Additionally, we propose an automated method to implement UML class diagrams onto a technological stack featuring ROS, Apache Kafka, PostgreSQL, and Apache Flink. An experimental evaluation in the agricultural application domain confirms the merits of our approach.},
  archive      = {J_DKE},
  author       = {Houssam Bazza and Sandro Bimonte and Zakaria Gourti and Stefano Rizzi and Hassan Badir},
  doi          = {10.1016/j.datak.2025.102418},
  journal      = {Data &amp; Knowledge Engineering},
  month        = {5},
  pages        = {102418},
  shortjournal = {Data Knowl. Eng.},
  title        = {An MDA approach for robotic-based real-time business intelligence applications},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Aspect-level recommendation fused with review and rating
representations. <em>DKE</em>, <em>157</em>, 102417. (<a
href="https://doi.org/10.1016/j.datak.2025.102417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Review contains user opinions about different aspects of an item, which is essential data for aspect-level recommendation. Most existing aspect-level recommendation algorithms are concerned with the degree to which user and item aspects match. However, even if an item is extremely popular due to its high quality, it may only partially match the aspects of a user. A tolerant user may like the item, whereas a strict user may dislike it. This implies that these works disregard the personalized behavior patterns of the user. In this paper, we propose a new A spect-level R ecommendation model fused with R eview and R ating, namely ARRR , to address the recommendation bias. First, we introduce rating to explore user behavior patterns and item quality. Then, we present a personalized attention mechanism that generates a set of aspect-level user or item representations from reviews. Finally, we obtain comprehensive user or item representations by combining rating- and review-based representations. In the experiments, the proposed model is compared with seven state-of-the-art recommendation algorithms on seven datasets. The results show that our model outperforms on seven metrics. The source code of ARRR is available at https://github.com/alinn00/ARRR .},
  archive      = {J_DKE},
  author       = {Heng-Ru Zhang and Ling Lin and Fan Min},
  doi          = {10.1016/j.datak.2025.102417},
  journal      = {Data &amp; Knowledge Engineering},
  month        = {5},
  pages        = {102417},
  shortjournal = {Data Knowl. Eng.},
  title        = {Aspect-level recommendation fused with review and rating representations},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). How well can a large language model explain business
processes as perceived by users? <em>DKE</em>, <em>157</em>, 102416. (<a
href="https://doi.org/10.1016/j.datak.2025.102416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) are trained on a vast amount of text to interpret and generate human-like textual content. They are becoming a vital vehicle in realizing the vision of the autonomous enterprise, with organizations today actively adopting LLMs to automate many aspects of their operations. LLMs are likely to play a prominent role in future AI-augmented business process management systems (ABPMSs) catering functionalities across all system lifecycle stages. One such system’s functionality is Situation-Aware eXplainability (SAX), which relates to generating causally sound and yet human-interpretable explanations that take into account the process context in which the explained condition occurred. In this paper, we present the SAX4BPM framework developed to generate SAX explanations. The SAX4BPM suite consists of a set of services and a central knowledge repository. The functionality of these services is to elicit the various knowledge ingredients that underlie SAX explanations. A key innovative component among these ingredients is the causal process execution view. In this work, we integrate the framework with an LLM to leverage its power to synthesize the various input ingredients for the sake of improved SAX explanations. Since the use of LLMs for SAX is also accompanied by a certain degree of doubt related to its capacity to adequately fulfill SAX along with its tendency for hallucination and lack of inherent capacity to reason, we pursued a methodological evaluation of the perceived quality of the generated explanations. To this aim, we developed a designated scale and conducted a rigorous user study. Our findings show that the input presented to the LLMs aided with the guard-railing of its performance, yielding SAX explanations having better-perceived fidelity. This improvement is moderated by the perception of trust and curiosity. More so, this improvement comes at the cost of the perceived interpretability of the explanation.},
  archive      = {J_DKE},
  author       = {Dirk Fahland and Fabiana Fournier and Lior Limonad and Inna Skarbovsky and Ava J.E. Swevels},
  doi          = {10.1016/j.datak.2025.102416},
  journal      = {Data &amp; Knowledge Engineering},
  month        = {5},
  pages        = {102416},
  shortjournal = {Data Knowl. Eng.},
  title        = {How well can a large language model explain business processes as perceived by users?},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modelling and solving industrial production tasks as
planning-scheduling tasks. <em>DKE</em>, <em>157</em>, 102415. (<a
href="https://doi.org/10.1016/j.datak.2025.102415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial production planning or manufacturing concerns the selection of activities that can produce a desired product and scheduling them on resources that perform these activities. To deal with such problems techniques in the fields of Automated Planning and Scheduling might be leveraged, which are usually pursued separately even though they are (very) complementary. In manufacturing, the activities represent elementary steps in the production and each activity requires a specific input in order to produce a desired output. From that perspective, activities resemble actions in planning as they can capture such a requirement. Selecting proper activities including their (partial) ordering can be understood as a planning task while allocating the activities to the resources can be understood as a scheduling task. This paper formalises the concept of “combined” planning and scheduling tasks by defining planning-scheduling tasks that are suitable for problems concerning industrial production or manufacturing. In particular, we define two types of activities – production and maintenance activities – where the former describes elementary production tasks while the latter modifies attributes of the resources (e.g. changing the configuration of reconfigurable machines). We introduce an extension of Planning Domain Definition Language (PDDL), a well-known language for describing planning tasks, to support modelling of planning-scheduling tasks. To tackle planning-scheduling tasks we propose two compilation schemes, one into temporal planning (in PDDL 2.1) and one into classical planning. We evaluated our approaches in three use cases of industrial production planning — Reconfigurable Machines, Woodworking, and Tube Factory domains. The results showed that solving planning-scheduling tasks by compiling them into planning tasks in order to use off-the-shelf planning engines is suitable as it scales reasonably well with the size of the actual tasks (although the resulting solutions are suboptimal).},
  archive      = {J_DKE},
  author       = {Andrii Nyporko and Lukáš Chrpa},
  doi          = {10.1016/j.datak.2025.102415},
  journal      = {Data &amp; Knowledge Engineering},
  month        = {5},
  pages        = {102415},
  shortjournal = {Data Knowl. Eng.},
  title        = {Modelling and solving industrial production tasks as planning-scheduling tasks},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating diabetes dataset for knowledge graph embedding
based link prediction. <em>DKE</em>, <em>157</em>, 102414. (<a
href="https://doi.org/10.1016/j.datak.2025.102414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For doing any accurate analysis or prediction on data, a complete and well-populated dataset is required. Medical based data for any disease like diabetes is highly coupled and heterogeneous in nature, with numerous interconnections. This inherently complex data cannot be analysed by simple relational databases making knowledge graphs an ideal tool for its representation which can efficiently handle intricate relationships. Thus, knowledge graphs can be leveraged to analyse diabetes data, enhancing both the accuracy and efficiency of data-driven decision-making processes. Although substantial data exists on diabetes in various formats, the availability of organized and complete datasets is limited, highlighting the critical need for creation of a well-populated knowledge graph. Moreover while developing the knowledge graph, an inevitable problem of incompleteness is present due to missing links or relationships, necessitating the use of knowledge graph completion tasks to fill in this absent information which involves predicting missing data with various Link Prediction (LP) techniques. Among various link prediction methods, approaches based on knowledge graph embeddings have demonstrated superior performance and effectiveness. These knowledge graphs can support in-depth analysis and enhance the prediction of diabetes-associated risks in this field. This paper introduces a dataset specifically designed for performing link prediction on a diabetes knowledge graph, so that it can be used to fill the information gaps further contributing in the domain of risk analysis in diabetes. The accuracy of the dataset is assessed through validation with state-of-the-art embedding-based link prediction methods.},
  archive      = {J_DKE},
  author       = {Sushmita Singh and Manvi Siwach},
  doi          = {10.1016/j.datak.2025.102414},
  journal      = {Data &amp; Knowledge Engineering},
  month        = {5},
  pages        = {102414},
  shortjournal = {Data Knowl. Eng.},
  title        = {Evaluating diabetes dataset for knowledge graph embedding based link prediction},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Static and dynamic techniques for iterative test-driven
modelling of dynamic condition response graphs. <em>DKE</em>,
<em>157</em>, 102413. (<a
href="https://doi.org/10.1016/j.datak.2025.102413">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Test-driven declarative process modelling combines process models with test traces and has been introduced as a means to achieve both the flexibility provided by the declarative approach and the comprehensibility of the imperative approach. Open test-driven modelling adds a notion of context to tests, specifying the activities of concern in the model, and has been introduced as a means to support both iterative test-driven modelling, where the model can be extended without having to change all tests, and unit testing, where tests can define desired properties of parts of the process without needing to reason about the details of the whole process. The openness however makes checking a test more demanding, since actions outside the context are allowed at any point in the test execution and therefore many different traces may validate or invalidate an open test. In this paper we combine previously developed static techniques for effective open test-driven modelling for Dynamic Condition Response Graphs with a novel efficient implementation of dynamic checking of open tests based on alignment checking. We illustrate the static techniques on an example based on a real-life cross-organizational case management system and benchmark the dynamic checking on models and tests of varying size.},
  archive      = {J_DKE},
  author       = {Axel K.F. Christfort and Vlad Paul Cosma and Søren Debois and Thomas T. Hildebrandt and Tijs Slaats},
  doi          = {10.1016/j.datak.2025.102413},
  journal      = {Data &amp; Knowledge Engineering},
  month        = {5},
  pages        = {102413},
  shortjournal = {Data Knowl. Eng.},
  title        = {Static and dynamic techniques for iterative test-driven modelling of dynamic condition response graphs},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning for optimizing responses in care
processes. <em>DKE</em>, <em>157</em>, 102412. (<a
href="https://doi.org/10.1016/j.datak.2025.102412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prescriptive process monitoring aims to derive recommendations for optimizing complex processes. While previous studies have successfully used reinforcement learning techniques to derive actionable policies in business processes, care processes present unique challenges due to their dynamic and multifaceted nature. For example, at any stage of a care process, a multitude of actions is possible. In this study, we follow the Reinforcement Learning (RL) approach and present a general approach that uses event data to build and train Markov decision processes. We proposed three algorithms including one that takes the elapsed time into account when transforming an event log into a semi-Markov decision process. We evaluated the RL approach using an aggression incident data set. Specifically, the goal is to optimize staff member actions when clients are displaying different types of aggressive behavior. The Q-learning and SARSA are used to find optimal policies. Our results showed that the derived policies align closely with current practices while offering alternative options in specific situations. By employing RL in the context of care processes, we contribute to the ongoing efforts to enhance decision-making and efficiency in dynamic and complex environments.},
  archive      = {J_DKE},
  author       = {Olusanmi A. Hundogan and Bart J. Verhoef and Patrick Theeven and Hajo A. Reijers and Xixi Lu},
  doi          = {10.1016/j.datak.2025.102412},
  journal      = {Data &amp; Knowledge Engineering},
  month        = {5},
  pages        = {102412},
  shortjournal = {Data Knowl. Eng.},
  title        = {Reinforcement learning for optimizing responses in care processes},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Symmetric non negative matrices factorization applied to the
detection of communities in graphs and forensic image analysis.
<em>DKE</em>, <em>157</em>, 102411. (<a
href="https://doi.org/10.1016/j.datak.2025.102411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the proliferation of data, particularly on social networks, the accuracy of the information becomes uncertain. In this context, a major challenge lies in detecting image manipulations, where alterations are made to deceive observers. Aligning with the anomaly detection issue, recent methods approach the detection of image transformations as a community detection problem within graphs associated with the images. In this study, we propose using a community clustering method based on non-negative symmetric matrix factorization. By examining several experiments detecting alterations in manipulated images, we assess the method’s robustness and discuss potential enhancements. We also present a process for automatically generating visually and semantically coherent forged images. Additionally, we provide a web application to demonstrate this process.},
  archive      = {J_DKE},
  author       = {Gaël Marec and Nédra Mellouli},
  doi          = {10.1016/j.datak.2025.102411},
  journal      = {Data &amp; Knowledge Engineering},
  month        = {5},
  pages        = {102411},
  shortjournal = {Data Knowl. Eng.},
  title        = {Symmetric non negative matrices factorization applied to the detection of communities in graphs and forensic image analysis},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). REDIRE: Extreme REduction DImension for extRactivE
summarization. <em>DKE</em>, <em>157</em>, 102407. (<a
href="https://doi.org/10.1016/j.datak.2025.102407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an automatic unsupervised summarization model capable of extracting the most important sentences from a corpus. The unsupervised aspect makes it possible to do away with large corpora, made up of documents and their reference summaries, and to directly process documents potentially made up of several thousand words. To extract sentences in a summary, we use pre-entrained word embeddings to represent the documents. From this thick cloud of word vectors, we apply an extreme dimension reduction to identify important words, which we group by proximity. Sentences are extracted using linear constraint solving to maximize the information present in the summary. We evaluate the approach on large documents and present very encouraging initial results.},
  archive      = {J_DKE},
  author       = {Christophe Rodrigues and Marius Ortega and Aurélien Bossard and Nédra Mellouli},
  doi          = {10.1016/j.datak.2025.102407},
  journal      = {Data &amp; Knowledge Engineering},
  month        = {5},
  pages        = {102407},
  shortjournal = {Data Knowl. Eng.},
  title        = {REDIRE: Extreme REduction DImension for extRactivE summarization},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Logic-infused knowledge graph QA: Enhancing large language
models for specialized domains through prolog integration. <em>DKE</em>,
<em>157</em>, 102406. (<a
href="https://doi.org/10.1016/j.datak.2025.102406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficiently answering questions over complex, domain-specific knowledge graphs remain a substantial challenge, as large language models (LLMs) often lack the logical reasoning abilities and particular knowledge required for such tasks. This paper presents a novel framework integrating LLMs with logical programming languages like Prolog for Logic-Infused Knowledge Graph Question Answering (KGQA) in specialized domains. The proposed methodology uses a transformer-based encoder–decoder architecture. An encoder reads the question, and a named entity recognition (NER) module connects entities to the knowledge graph. The extracted entities are fed into a grammar-guided decoder, producing a logical form (Prolog query) that captures the semantic constraints and relationships. The Prolog query is executed over the knowledge graph to perform symbolic reasoning and retrieve relevant answer entities. Comprehensive experiments on the MetaQA benchmark dataset demonstrate the superior performance of this logic-infused method in accurately identifying correct answer entities from the knowledge graph. Even when trained on a limited subset of annotated data, it outperforms state-of-the-art baselines, achieving 89.60 % and F1-scores of up to 89.61 %, showcasing its effectiveness in enhancing large language models with symbolic reasoning capabilities for specialized question-answering tasks. The seamless integration of LLMs and logical programming enables the proposed framework to reason effectively over complex, domain-specific knowledge graphs, overcoming a key limitation of existing KGQA systems. In specialized domains, the interpretability provided by representing questions such as Prologue queries is a valuable asset.},
  archive      = {J_DKE},
  author       = {Aneesa Bashir and Rong Peng and Yongchang Ding},
  doi          = {10.1016/j.datak.2025.102406},
  journal      = {Data &amp; Knowledge Engineering},
  month        = {5},
  pages        = {102406},
  shortjournal = {Data Knowl. Eng.},
  title        = {Logic-infused knowledge graph QA: Enhancing large language models for specialized domains through prolog integration},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="dss---14">DSS - 14</h2>
<ul>
<li><details>
<summary>
(2025). Are helpful reviews indeed helpful? Analyzing the
information and economic value of contextual cues in user-generated
images. <em>DSS</em>, <em>191</em>, 114426. (<a
href="https://doi.org/10.1016/j.dss.2025.114426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When shopping online, customers may find user-generated images (UGIs) where existing buyers share their product experiences in an actual setting. Drawing on the constructivist theory of visual perception, we propose a cognitive inference process in which shoppers utilize the background objects in UGIs that contextualize a product (e.g., a snow-covered mountain implying cold weather) to infer its features (e.g., the warmth of a jacket). As a result, the contextual cues in UGIs play a critical role in facilitating future buyers&#39; purchase decision-making. Our empirical probes using data from an online outdoor gear and clothing retailer confirm this conjecture by demonstrating that product contextualization in UGIs increases a review&#39;s perceived helpfulness and improves sales. By contrast, the contextual cues in the review text only assist buyers&#39; purchase decision process when they contextualize product functionality (e.g., the windproof of a coat). Yet, they do not work for aesthetic attributes (e.g., the color of a coat). We leverage an experiment to explore the relevant mechanism. In the sales analysis, we reveal that not all image content considered helpful would positively affect sales. For example, after we account for the contextual cues in the UGI, the mere presence of an image in product reviews does not affect sales. On the other hand, although illustrating product malfunction in a UGI does not increase its helpfulness, such content hurts sales. We offer managerial implications based on the empirical findings for review platforms that aim to assist online shoppers in making informed purchases.},
  archive      = {J_DSS},
  author       = {Youngeui Kim and Yang Wang},
  doi          = {10.1016/j.dss.2025.114426},
  journal      = {Decision Support Systems},
  month        = {4},
  pages        = {114426},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Are helpful reviews indeed helpful? analyzing the information and economic value of contextual cues in user-generated images},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Balancing the costs and benefits of resilience-based
decision making. <em>DSS</em>, <em>191</em>, 114425. (<a
href="https://doi.org/10.1016/j.dss.2025.114425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most decision models of system resilience use static, deterministic optimization techniques while focusing on resilience assessment. At present, we lack appropriate decision support methodologies and computational tools that can offer dynamic control of resilience and balance the costs of resilience assurance. This paper presents a stochastic dynamic optimization model, based on an infinite horizon Continuous-Time Markov Decision Process, to balance the intervention costs and reduce the total recovery time ensuing a disruption of a social-physical system. We aim to offer a model that can facilitate its application to different disruption scenarios. Our state-space formulation of the recovery process uses discrete performance intervals, whereby actions and resulting rewards/costs are related to investment resources, which govern state transitions. We illustrate the model via a case study based on the 2010 Northern Colombia Dique Canal breach. Our results show that the optimal policy reduced the recovery time and restoration investment by approximately 40% and 10%, respectively, when compared to the efficiency of the government interventions. The proposed model features dynamic control of recovery resources and considers the costs of resilience assurance. The model can inform policymakers of ways to improve system resilience using balanced disruption recovery strategies.},
  archive      = {J_DSS},
  author       = {Weimar Ardila-Rueda and Alex Savachkin and Daniel Romero-Rodriguez and Jose Navarro},
  doi          = {10.1016/j.dss.2025.114425},
  journal      = {Decision Support Systems},
  month        = {4},
  pages        = {114425},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Balancing the costs and benefits of resilience-based decision making},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Is ambiguity always adverse? Empirical evidence from the
wireless emergency alerts during the pandemic. <em>DSS</em>,
<em>191</em>, 114424. (<a
href="https://doi.org/10.1016/j.dss.2025.114424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless emergency alerts (WEAs) have become a crucial information system to notify residents of potential hazards in their vicinity. Using a large transaction dataset, we investigate (1) how WEAs influence offline and online transactions as a proxy to public mobility, and (2) how different types of information in WEAs affect transactions. Our results indicate that WEAs that only notify the occurrence of confirmed cases can significantly reduce public mobility compared to those that provide information on the exact movement of the patient. Further analysis suggests that the treatment effects of such WEAs are more pronounced in high-income areas.},
  archive      = {J_DSS},
  author       = {Jaeho Myeong and Yongjin Park and Jae-Hyeon Ahn},
  doi          = {10.1016/j.dss.2025.114424},
  journal      = {Decision Support Systems},
  month        = {4},
  pages        = {114424},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Is ambiguity always adverse? empirical evidence from the wireless emergency alerts during the pandemic},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Metaverse technology in sustainable supply chain management:
Experimental findings. <em>DSS</em>, <em>191</em>, 114423. (<a
href="https://doi.org/10.1016/j.dss.2025.114423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The metaverse is a transformative force in supply chain information systems, particularly in the context of decision-making processes focusing on sustainable development goals. Thus, this study examines: How does the metaverse among stakeholders contribute to the supply chain decision-making processes regarding sustainable development goals ? This study is among the first to provide empirical data examining the impact of the metaverse on stakeholders&#39; sustainability assessment. Additionally, we examine how the metaverse influences supply chain collaboration and logistics decisions efficiency, particularly concerning their significant environmental implications. Through the lens of the practice-based theory, we test the proposed relationships using empirical data collected through a scenario-based survey. Furthermore, we analyzed tweets containing the keywords “metaverse” and “supply chain” to identify related topics and sentiments regarding the metaverse. The text mining analysis revealed three primary topics: logistics, digitalization, and sustainability. Results from the sentiment analysis indicated a predominantly positive attitude towards the metaverse within supply chains.},
  archive      = {J_DSS},
  author       = {Kiarash Sadeghi R. and Divesh Ojha and Puneet Kaur and Raj V. Mahto and Amandeep Dhir},
  doi          = {10.1016/j.dss.2025.114423},
  journal      = {Decision Support Systems},
  month        = {4},
  pages        = {114423},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Metaverse technology in sustainable supply chain management: Experimental findings},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring the impact of free live-streamed medical
consultation on patient engagement and patient satisfaction in the
multistage online consultation process: A quasi-experimental design.
<em>DSS</em>, <em>191</em>, 114422. (<a
href="https://doi.org/10.1016/j.dss.2025.114422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, many online healthcare communities (OHCs) in China introduced the feature of free live-streamed medical consultations (FLSMC), which allows patients to communicate with physicians and have an interactive consultation for free through live streaming. Despite the rapid growth of FLSMC, little is known about whether FLSMC can bring benefits to patients when they have online consultation needs in the future. Drawing on signaling theory, this study examines the impact of FLSMC on patient engagement and patient satisfaction in the multistage online consultation process. We further explore the moderating effects of physician&#39;s owned and earned signals in the pre-consultation stage by integrating social capital theory with signaling theory. We collect a panel data set of 16,151 physicians from a leading OHC in China. Based on the DID method, a quasi-experimental design, and the instrumental variable method, we demonstrate that FLSMC has a positive effect on patient choice, patient messaging, and patient satisfaction. In addition, we find that the physician&#39;s title and online rating can positively moderate the effects of FLSMC on patient choice. This study not only sheds light on the literature on online healthcare by identifying the role of signals in the context of FLSMC, but also provides decision support for patients, physicians, and OHC managers.},
  archive      = {J_DSS},
  author       = {Haochen Song and Xitong Guo and Tianshi Wu},
  doi          = {10.1016/j.dss.2025.114422},
  journal      = {Decision Support Systems},
  month        = {4},
  pages        = {114422},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Exploring the impact of free live-streamed medical consultation on patient engagement and patient satisfaction in the multistage online consultation process: A quasi-experimental design},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DECEN: A deep learning model enhanced by depressive emotions
for depression detection from social media content. <em>DSS</em>,
<em>191</em>, 114421. (<a
href="https://doi.org/10.1016/j.dss.2025.114421">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depression is a serious and recurrent mental illness that significantly affects an individual&#39;s life and the society as a whole. Automatic detection of depression is crucial for early intervention and minimizing negative consequences. Existing studies on building deep learning models for automated depression detection have mainly used post-level emotion polarity (i.e., positive and negative emotions) and word embeddings as predictive features. Few have considered depressive emotions (e.g., anhedonia) expressed in those posts, despite that depressive emotions are essential to clinical depression diagnosis. Moreover, existing approaches for depression detection often ignore the relationship between emotions and their context. This study proposes a Depressive Emotion-Context Enhanced Network (DECEN) that consists of a pre-trained depressive emotion recognition module and an emotion-context enhanced representation module to address those limitations. DECEN first integrates semantic and syntactic structure representations of textual content of social media posts to identify depressive emotions conveyed through terms either explicitly or implicitly, rather than general emotion words. Furthermore, we propose an emotion-context enhanced representation method to enhance the role of the context of depressive emotions in depression detection. The evaluation using real social media data demonstrates that DECEN outperforms the state-of-the-art models in depression detection. The results of an ablation experiment also reveal that the proposed depressive emotion recognition and emotion-context enhanced representation modules, the two novel design artifacts, improve model performance. This study contributes to depression diagnostic decisions by introducing a novel method and providing new technical and practical insights for detecting depression from social media content.},
  archive      = {J_DSS},
  author       = {Zhijun Yan and Fei Peng and Dongsong Zhang},
  doi          = {10.1016/j.dss.2025.114421},
  journal      = {Decision Support Systems},
  month        = {4},
  pages        = {114421},
  shortjournal = {Decis. Supp. Syst.},
  title        = {DECEN: A deep learning model enhanced by depressive emotions for depression detection from social media content},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding physicians’ noncompliance use of AI-aided
diagnosis—a mixed-methods approach. <em>DSS</em>, <em>191</em>, 114420.
(<a href="https://doi.org/10.1016/j.dss.2025.114420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the pervasiveness of artificial intelligence (AI) technologies in the healthcare industry, physicians are reluctant to follow the recommendations suggested by AI-aided diagnostic systems. We conceptualize physicians&#39; noncompliance use of AI-aided diagnostic systems and draw on the technology threat avoidance theory (TTAT) to investigate the phenomenon of interest. Specifically, we leverage a mixed-methods approach to develop and test a comprehensive research model of physicians&#39; noncompliance use of AI under the overarching theory of TTAT. With an exploratory qualitative study by interviewing ten physicians with experience in using AI-aided diagnostic systems, we observe that (1) physicians experience two distinct types of threats imposed by AI, namely AI threats to diagnostic process and outcome, (2) physicians&#39; resistance to AI-aided diagnostic systems is the underlying psychological mechanism that turns their AI threat perceptions into noncompliance usage behavior, and (3) physicians&#39; professional capital serves as an essential boundary condition in understanding the impacts of AI threats on resistance. In a confirmatory quantitative survey with 160 physicians, we find that (1) both AI threats to diagnostic process and outcome arouse physicians&#39; psychological resistance, (2) such resistance to AI-aided diagnosis leads to noncompliance usage behavior, (3) noncompliance use of AI-aided diagnosis decreases physicians&#39; diagnostic performance enhanced by AI, and (4) physicians&#39; professional capital weakens the positive impact of AI threat to diagnostic process on resistance, but strengthens the positive impact of AI threat to diagnostic outcome on resistance. Our research advances the understanding of post-adoption noncompliance use of AI technology and enriches TTAT in health AI use. Our empirical findings offer practical suggestions for implementing and managing AI technology in the healthcare industry.},
  archive      = {J_DSS},
  author       = {Jiaoyang Li and Xixi Li and Cheng Zhang},
  doi          = {10.1016/j.dss.2025.114420},
  journal      = {Decision Support Systems},
  month        = {4},
  pages        = {114420},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Understanding physicians&#39; noncompliance use of AI-aided diagnosis—A mixed-methods approach},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Is seeing the same as doing? An evaluation of vicarious
experiences in the metaverse. <em>DSS</em>, <em>191</em>, 114419. (<a
href="https://doi.org/10.1016/j.dss.2025.114419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the recent explosion of vicarious experiences in the metaverse (e.g. twitch, YouTube gaming, Facebook gaming, etc.), understanding the underlying mechanism of this phenomenon is key for researchers and practitioners. This research examines the rising phenomenon of vicarious experiences within the metaverse. Using a three-study experimental approach, results show that subjects attain equal levels of embodied social presence (ESP) whether passively viewing or actively engaging with the metaverse. Since embodied social presence is a combination of activity theory and social presence, theory would suggest it cannot occur in purely vicarious experiences that do not involve direct engagement; however, our findings contradict both theory and previous research. Given these findings, we suggest users seek vicarious experiences not just to experience content they enjoy, but to have perceptually similar experiences as those actively participating in the metaverse.},
  archive      = {J_DSS},
  author       = {Caleb Krieger and Andy Luse and Ghazal Abdolhossein Khani and Rathindra Sarathy},
  doi          = {10.1016/j.dss.2025.114419},
  journal      = {Decision Support Systems},
  month        = {4},
  pages        = {114419},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Is seeing the same as doing? an evaluation of vicarious experiences in the metaverse},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep learning–based method to predict the length of stay
for patients with traumatic fall injuries in support of physicians’
clinical decisions and patient management. <em>DSS</em>, <em>191</em>,
114411. (<a href="https://doi.org/10.1016/j.dss.2025.114411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate estimates of the length of stay (LOS) for patients who suffer traumatic fall injuries are crucial to inform physicians&#39; clinical decisions and patient management. They also have important implications for resource utilization efficiency and cost containment efforts by healthcare organizations. Effective predictions should consider essential relationships across different variables pertaining to patient demographics, clinical history, injury severity, and physiology. A proposed deep learning–based method incorporates these relationships and can predict LOS more accurately, as demonstrated by a comparative evaluation involving 3722 patients who suffered traumatic fall injuries between 2011 and 2017. The results show the superior performance of the proposed method, relative to eleven prevalent methods that represent different analytics approaches. Our method demonstrates superior predictive performance, as manifested by the highest F-measure values and area under the curve. It is particularly efficacious for patients likely in need of longer LOS, which is relatively more important to physicians and healthcare organizations. This study underscores the value of incorporating important relationships and interactions among distinct patient variables to estimate LOS, with a particular emphasis on the inter-disease relationships, physiology-severity interactions, and patient information in clinical notes. The proposed method can be implemented as a decision support system to enhance physicians&#39; clinical decisions and patient management, and improve healthcare organizations&#39; resource planning and utilization efficiency, with nontrivial cost containment implications.},
  archive      = {J_DSS},
  author       = {Jiaxuan Peng and Da Xu and Paul Jen-Hwa Hu and Jessica Qiuhua Sheng and Ting-Shuo Huang},
  doi          = {10.1016/j.dss.2025.114411},
  journal      = {Decision Support Systems},
  month        = {4},
  pages        = {114411},
  shortjournal = {Decis. Supp. Syst.},
  title        = {A deep learning–based method to predict the length of stay for patients with traumatic fall injuries in support of physicians&#39; clinical decisions and patient management},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contending with coronaries: May HIT be with you.
<em>DSS</em>, <em>191</em>, 114410. (<a
href="https://doi.org/10.1016/j.dss.2025.114410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Health Information Technology (HIT) is revolutionizing healthcare by serving as the backbone for various decision support activities across the healthcare continuum, particularly within hospital settings. While existing literature highlights its positive impact on patient satisfaction, costs, and quality, its role in complementing other crucial hospital inputs to influence clinical healthcare outcomes has been relatively understudied. In this study, we explore the complementary effects of a specific type of HIT, Clinical Decision Support Systems (CDSS) on cardiac mortality rates (CMR) in hospitals. Though hospital personnel and cardiac medical services (CMS) are pivotal in reducing CMR, CDSS plays a complementary role by providing information and decision support throughout the cardiac care delivery process. Leveraging panel data spanning from 2016 to 2020, our analysis reveals that CDSS complements CMS and hospital personnel in mitigating CMR. These findings provide theoretical insights into the benefits facilitated by CDSS in cardiac care and hold managerial implications for the effective deployment of this technology within hospital settings. Through our analysis, we aim to elucidate the synergistic effects of CDSS, cardiac medical services, and healthcare personnel in improving clinical healthcare outcomes, particularly in the management of cardiac disease.},
  archive      = {J_DSS},
  author       = {Nirup Menon and Amitava Dutta and Sidhartha Das},
  doi          = {10.1016/j.dss.2025.114410},
  journal      = {Decision Support Systems},
  month        = {4},
  pages        = {114410},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Contending with coronaries: May HIT be with you},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Should a better-informed manufacturer hold pricing power for
the direct channel: The role of consumer reviews. <em>DSS</em>,
<em>191</em>, 114408. (<a
href="https://doi.org/10.1016/j.dss.2025.114408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manufacturers can effectively obtain precise demand information through the utilization of data analysis technologies. These better-informed manufacturers commonly distribute their products not only through traditional offline retailers but also via direct sales channels. In this context, distinct pricing strategies for online channels, namely holding pricing power and giving up pricing power, can be observed in practice. Furthermore, these online channels also enable consumers to post consumer reviews, which significantly impacts consumers’ purchasing decisions. By applying a signaling game, our study examines the interaction between pricing strategy of a direct sales channel and consumer reviews. Our findings indicate that consumer reviews significantly influence the determination of the optimal pricing strategy of direct channel for a better-informed manufacturer. Holding pricing power is always the optimal strategy when the direct channel functions as an authentic distribution channel. However, giving up pricing power can be optimal when the direct channel personates a competitive threat, conditional on the travel cost of traditional channel and the information disclosed through consumer reviews. Contrary to expectations, manufacturer’s retention of pricing power for the direct channel can benefit the retailer when the travel cost to the traditional channel is moderate and the information disclosed in consumer reviews does not exhibit extreme negativity or positivity. Additionally, our findings indicate that the chain members can acquire an agreement on the direct channel’s pricing strategy, which results in a win-win outcome, thereby improving supply chain efficiency.},
  archive      = {J_DSS},
  author       = {Musen Xue and Jiahui Guo and Lin Feng},
  doi          = {10.1016/j.dss.2025.114408},
  journal      = {Decision Support Systems},
  month        = {4},
  pages        = {114408},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Should a better-informed manufacturer hold pricing power for the direct channel: The role of consumer reviews},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal review helpfulness prediction with a multi-level
cognitive reasoning mechanism: A theory-driven graph learning model.
<em>DSS</em>, <em>191</em>, 114406. (<a
href="https://doi.org/10.1016/j.dss.2025.114406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Customers&#39; perception of review helpfulness entails a cognitive reasoning process influenced by the contextual information of reviews including product descriptions and review neighbors. Current studies on helpfulness prediction primarily focus on static features of individual reviews, neglecting the dynamic interaction among products, reviews and their contextual neighbors. To address this gap, we propose a theory-driven deep learning model for multimodal review helpfulness prediction (DeepMRHP-MCR). The model can collectively simulate human cognitive processes when voting on whether a review is helpful. Specifically, this study presents a multi-level cognitive reasoning mechanism that reconciles the inconsistencies among product descriptions, reviews and their neighbors from the modality, individual and contextual level, respectively. A case study is conducted on the real-world datasets collected from Amazon.com . Empirical results show that the proposed model can improve the quality and interpretability of review prediction process, and present a deep comprehension of consumer&#39;s cognitive decision-making process when evaluating reviews.},
  archive      = {J_DSS},
  author       = {Hai Wei and Ying Yang and Yu-Wang Chen},
  doi          = {10.1016/j.dss.2025.114406},
  journal      = {Decision Support Systems},
  month        = {4},
  pages        = {114406},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Multimodal review helpfulness prediction with a multi-level cognitive reasoning mechanism: A theory-driven graph learning model},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Does the most popular answer lead to the best answer: The
moderating roles of tenure, social closeness, and cultural tightness.
<em>DSS</em>, <em>191</em>, 114405. (<a
href="https://doi.org/10.1016/j.dss.2025.114405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online question and answer (Q&amp;A) communities rely on the general audience or the question asker to determine the best answer. However, limited attention has been directed toward understanding the influence of the general audience-favored answer (i.e., most popular answer) on the question asker-selected best answer (i.e., best answer). This study examines whether and how the general audience-favored answer influences the question asker-selected best answer. Drawing upon uncertainty reduction theory (URT), this paper investigates how three uncertainty reduction strategies (i.e. question askers&#39; tenure, social closeness between the question asker and question answerer, and cultural tightness of the question asker&#39;s region) moderate the relationship between the general audience-favored answer and the question asker-selected best answer. To test the theoretical model, we used a dataset from an online Q&amp;A community comprising 161,695 observations. Our results reveal that the general audience-favored answer more likely leads to the question asker-selected best answer. Furthermore, we find that the question asker&#39;s tenure and the social closeness between the question asker and question answerer negatively moderate the above relationship, while the cultural tightness of question asker&#39;s region positively moderates the above relationship. This research offers a new perspective on the mechanisms through which the general audience-favored answer leads to question asker-selected best answer. By identifying the critical roles of uncertainty reduction strategies during the best answer selection process, our research provides valuable insights for online Q&amp;A community managers to optimize user engagement and satisfaction.},
  archive      = {J_DSS},
  author       = {Yuxin Cai and Xiayu Chen and Shaobo Wei},
  doi          = {10.1016/j.dss.2025.114405},
  journal      = {Decision Support Systems},
  month        = {4},
  pages        = {114405},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Does the most popular answer lead to the best answer: The moderating roles of tenure, social closeness, and cultural tightness},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tell me a story! Narrative-driven XAI with large language
models. <em>DSS</em>, <em>191</em>, 114402. (<a
href="https://doi.org/10.1016/j.dss.2025.114402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing Explainable AI (XAI) approaches, such as the widely used SHAP values or counterfactual (CF) explanations, are arguably often too technical for users to understand and act upon. To enhance comprehension of explanations of AI decisions and the overall user experience, we introduce XAIstories, which leverage Large Language Models (LLMs) to provide narratives about how AI predictions are made: SHAPstories based on SHAP and CFstories on CF explanations. We study the impact of our approach on users’ experience and understanding of AI predictions. Our results are striking: over 90% of the surveyed general audience finds the narratives generated by SHAPstories convincing, and over 78% for CFstories, in a tabular data experiment. More than 75% of the respondents in an image experiment find CFstories more or equally convincing as their own crafted stories. We also find that the generated stories help users to more accurately summarize and understand AI decisions than they do when only SHAP values are provided. The results indicate that combining LLM generated stories with current XAI methods is a promising and impactful research direction.},
  archive      = {J_DSS},
  author       = {David Martens and James Hinns and Camille Dams and Mark Vergouwen and Theodoros Evgeniou},
  doi          = {10.1016/j.dss.2025.114402},
  journal      = {Decision Support Systems},
  month        = {4},
  pages        = {114402},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Tell me a story! narrative-driven XAI with large language models},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="eaai---150">EAAI - 150</h2>
<ul>
<li><details>
<summary>
(2025). Multimodal data imputation and fusion for trustworthy fault
diagnosis of mechanical systems. <em>EAAI</em>, <em>150</em>, 110663.
(<a href="https://doi.org/10.1016/j.engappai.2025.110663">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The presence of missing values in the collected data due to sensor failure, communication interruption, or environmental interference can greatly diminishes the trustworthiness of fault diagnosis for mechanical systems. Therefore, this study proposes and evaluates a novel multimodal data imputation and fusion method to perform the trustworthy fault diagnosis of mechanical systems. First, a generative adversarial imputation network, termed as the L2 regularization temporal–spatial generative adversarial imputation network (L2-TSGAIN), is developed. This L2-TSGAIN network, based on a temporal–spatial feature extraction module and L2 regularization loss function, can comprehensively extract data features from both temporal and spatial perspectives, thus achieving high-quality imputation of anomalous sensor data. Subsequently, a multi-input single-output autoencoder (MISO-AE) is designed to extract a universal representation of the imputed data from different modalities and recover features in the fusion data. Finally, the fusion data from different health states of mechanical systems are input into a convolutional neural network classifier to perform fault diagnosis. Experiment validations, considering the presence of missing values in sensor data, have been carried out on the planetary transmission system and gearbox test bench. Compared with several mainstream data imputation methods for fault diagnosis, the optimal diagnostic accuracy of 99.68 % and 100 % on these two datasets can be obtained using the proposed method, respectively, confirming its superior performance and reliability. Thus, the proposed method can provide a trustworthy fault diagnosis tool for mechanical systems in industrial scenarios considering anomalous sensor data.},
  archive      = {J_EAAI},
  author       = {Jie Zhang and Yun Kong and Qinkai Han and Tianyang Wang and Mingming Dong and Hui Liu and Fulei Chu},
  doi          = {10.1016/j.engappai.2025.110663},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110663},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multimodal data imputation and fusion for trustworthy fault diagnosis of mechanical systems},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Atrous spatial pyramid pooling with swin transformer model
for classification of gastrointestinal tract diseases from videos with
enhanced explainability. <em>EAAI</em>, <em>150</em>, 110656. (<a
href="https://doi.org/10.1016/j.engappai.2025.110656">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and early identification of gastrointestinal (GI) lesions is crucial for treating and preventing GI diseases, including cancer. Automated computer-aided diagnosis methods can assist physicians in early and accurate detection. Video classification of GI endoscopic videos is challenging due to the complexity and variability of visual data. This research proposes a novel method for classifying GI diseases using endoscopic videos. Leveraging the public HyperKvasir dataset, we applied preprocessing algorithms to enhance GI frames by removing noise and artifacts with morphological opening and closing techniques, ensuring high-quality visuals. We addressed dataset imbalance by proposing a novel algorithm. Our hybrid model, Atrous Spatial Pyramid Pooling with Swin Transformer (ASPPST), combines advanced Convolutional Neural Networks and the Swin Transformer to classify GI videos into 30 distinct classes. We incorporated Gradient-Class Activation Mapping (Grad-CAM) in ASPPST&#39;s final layer to improve model explainability. The proposed model achieved 97.49 % accuracy in classifying 30 GI diseases, outperforming other transfer learning models and transformers by 8.04 % and 3.99 %, respectively. It also demonstrated a precision of 97.80 %, recall of 97.77 %, and an F1 score of 97.75 %, showcasing robustness across metrics. The high accuracy of ASPPST makes it suitable for real-world use, delivering fewer errors and more precise results in GI endoscopy video classification. Our approach advances artificial intelligence (AI) in computer vision and deep learning for biomedical engineering applications. Grad-CAM integration enhances transparency, boosting clinician trust and adoption of AI tools in diagnostic workflows.},
  archive      = {J_EAAI},
  author       = {Arefin Ittesafun Abian and Mohaimenul Azam Khan Raiaan and Mirjam Jonkman and Sheikh Mohammed Shariful Islam and Sami Azam},
  doi          = {10.1016/j.engappai.2025.110656},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110656},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Atrous spatial pyramid pooling with swin transformer model for classification of gastrointestinal tract diseases from videos with enhanced explainability},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solution and application of two-dimensional seismic
wavefield evolution based on physics-informed neural networks.
<em>EAAI</em>, <em>150</em>, 110652. (<a
href="https://doi.org/10.1016/j.engappai.2025.110652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-Informed Neural Networks (PINN) integrate partial differential equations, initial conditions, and boundary conditions into the loss function to predict the solutions of partial differential equations, and have already demonstrated their value in solving two-dimensional (2D) seismic wavefields. However, when dealing with wave problems involving boundary conditions, the added complexity of boundary conditions can lead to imbalanced convergence rates among different loss terms, which may affect both the efficiency and accuracy of the computations. Moreover, the need to retrain the model for different problems limits the flexibility of its application. Therefore, this paper introduces an adaptive weight balancing method and presents a 2D wave simulation based on Self-Adaptive PINN (SA-PINN). This method automatically adjusts the weights in the loss function, improving the solving performance. Additionally, to improve the computational efficiency of PINN in solving similar wave problems, a transfer learning strategy is adopted. By leveraging the similarities between the PINN models of related wave problems, this strategy enhances the generalization ability of PINN when dealing with variations in source location and medium wave speed. Numerical examples in semi-infinite domains and V-shaped valleys demonstrate that this method effectively achieves intelligent and efficient simulation of 2D seismic wavefields, providing a more efficient and intelligent solution for complex seismic wave problems.},
  archive      = {J_EAAI},
  author       = {Zhihui Zhu and Zong Wang and Yang Feng and Weiqi Zheng},
  doi          = {10.1016/j.engappai.2025.110652},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110652},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Solution and application of two-dimensional seismic wavefield evolution based on physics-informed neural networks},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive human in the loop system for identifying
non-optimal states in natural product manufacturing process.
<em>EAAI</em>, <em>150</em>, 110650. (<a
href="https://doi.org/10.1016/j.engappai.2025.110650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the extraction of natural products, the identification of non-optimal production states is pivotal for ensuring consistent product quality. Currently, there is a deficiency in online, automated detection methods. This study introduces an online machine vision strategy in a real industrial setting to maintain optimal production state. Specifically, the strategy incorporates an adaptive human in the loop deep learning approach to select high-value samples. This method achieves over 90 % accuracy with fewer training samples, effectively addressing the challenges posed by the low-value density characteristic of industrial data. Additionally, a convolutional neural networks-transformer framework is employed as a classifier for video data to meet the demands of time-series data. To enhance the efficiency of processing multiple video streams, we have implemented a knowledge distillation technique to lighten the model. Finally, this model has been deployed in an actual industrial environment for online monitoring of three extraction devices. The system encapsulates the expertise of engineers to standardize the criteria for assessing production states. This integration of innovative technologies ensures a more reliable and efficient extraction process, meeting the industry&#39;s need for consistent product quality.},
  archive      = {J_EAAI},
  author       = {Qilong Xue and Yang Yu and Shixin Cen and Yequan Yan and Jiping Pang and Ping Li and Yehan Hou and Lei Wang and Zheng Li},
  doi          = {10.1016/j.engappai.2025.110650},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110650},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive human in the loop system for identifying non-optimal states in natural product manufacturing process},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A chinese medical named entity recognition method
considering length diversity of entities. <em>EAAI</em>, <em>150</em>,
110649. (<a
href="https://doi.org/10.1016/j.engappai.2025.110649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting clinical entity concepts from professional medical materials is crucial for medical information analysis and knowledge extraction. Whereas, the Chinese medical named entity recognition (CMNER) task faces challenges due to the knowledge specialization and the diversity in entity lengths. To address these challenges, a novel method by considering length diversity of entities for CMNER is proposed, focusing on the integration of local information based on the predominance of large language models (LLMs). The method pre-trains a bidirectional encoder representation from transformers (BERT) based on open Chinese medical texts and designs a multi-dimensional convolutional residual module to enhance the semantic information for characters. This module effectively mines local information across various ranges and employs a local channel self-attention block to integrate this information, establishing a link between local information and entity length. Meanwhile, an adaptive optimization strategy for a learning rate is designed to improve the method&#39;s ability to search for the optimal solution. Experimental results reveal that, compared with state-of-the-art models, our approach achieves the optimal Recall and F1 , especially Recalls achieve 94.50 % (p &lt; 0.05) and 93.51 % (p &lt; 0.05) with effective performance in current task. The ablation results suggest that incorporating local information within 1–7 characters effectively addresses the challenges mentioned, highlighting the potential of our method to advance CMNER task.},
  archive      = {J_EAAI},
  author       = {Hongyu Zhang and Long Lyu and Weifu Chang and Yuexin Zhao and Xiaoqing Peng},
  doi          = {10.1016/j.engappai.2025.110649},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110649},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A chinese medical named entity recognition method considering length diversity of entities},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving weak magnetic detection of ferromagnetic material
defects diagnostics via transfer learning-enhanced residual networks.
<em>EAAI</em>, <em>150</em>, 110647. (<a
href="https://doi.org/10.1016/j.engappai.2025.110647">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of weak magnetic detection technology to identify defect sizes in ferromagnetic materials poses significant challenges due to the large volume of data and the relatively low prediction accuracy of conventional methods. Therefore, this paper proposes an improved Residual Networks (ResNet18) model that integrates transfer learning and channel attention mechanisms. Compared to traditional methods, the following improvements have been made: First, transfer learning has significantly reduced the data volume and time cost required for training from scratch, enhancing the model&#39;s generalization capability. Second, we have added a channel attention mechanism to the ResNet18 model, which involves calculating the importance of each channel through adaptive average pooling and fully connected layers, and generating channel weights using a Sigmoid function. This improvement allows the model to more accurately focus on features with higher relevance to defect sizes. Experimental results demonstrate that for grayscale images with defect lengths of 50 mm, depths of 2 mm, and widths of 1, 2, 3, 4, and 5 mm, the prediction accuracies reached 100 %, 100 %, 98.84 %, 99.58 %, and 100 %, respectively. For grayscale images with defect lengths of 50 mm, widths of 2 mm, and depths of 1, 2, 3, 4, and 5 mm, the prediction accuracies were 99.68 %, 100 %, 99.63 %, 100 %, and 99.60 %, respectively. Compared to the traditional ResNet18 model, the improved model not only enhances the accuracy of defect size prediction but also exhibits greater robustness, providing a new and effective method for defect classification in weak magnetic detection of ferromagnetic materials.},
  archive      = {J_EAAI},
  author       = {Yu Chen and Liangliang Li and Zhengxiang Ma and Xinling Wen and Jiabao Pang and Weitao Yuan},
  doi          = {10.1016/j.engappai.2025.110647},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110647},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improving weak magnetic detection of ferromagnetic material defects diagnostics via transfer learning-enhanced residual networks},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-adaptive production scheduling for discrete
manufacturing workshop using multi-agent cyber physical system.
<em>EAAI</em>, <em>150</em>, 110638. (<a
href="https://doi.org/10.1016/j.engappai.2025.110638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, the production control process of a discrete manufacturing workshop is characterized by high concurrency, mixed production lines and difficulty in prediction, which lead to uncertainty caused by dynamic disturbances and challenges in production control. Traditional system architectures struggle to handle these uncertainties flexibly and adaptively. To address these issues, an adaptive production scheduling system for the workshop is proposed, utilizing the Multi-agent Cyber Physical System (CPS-MAS) framework. This system integrates self-organization mechanisms and self-adaptive decision-making mechanisms to achieve cooperative optimal control of manufacturing resources. Using multi-agent technology, the resource model in the information space is encapsulated into an intelligent Cyber Physical System (CPS)-Agent model with cognitive interaction and autonomous decision-making capabilities. The improved contract network protocol (CNP) is utilized to the constructed agent, enabling their collaboration and competition to support the self-organization, negotiation, and assignment of manufacturing tasks. Based on multi-agent real-time perception and interactive negotiation, an adaptive control model of the manufacturing process is constructed based on Proportion Integration Differentiation (PID) control principle. This model is trained with the multi-layer perceptron that integrates an attention mechanism. The production strategy and parameters of the agent cooperative network are dynamically adjusted to enable dynamic decision-making optimization under disturbances. The proposed method is verified by experiments in scenarios involving machine failure, emergency order insertion and due date changes, proving its effectiveness.},
  archive      = {J_EAAI},
  author       = {Jie Chen and Zequn Zhang and Liping Wang and Dunbing Tang and Qixiang Cai and Kai Chen},
  doi          = {10.1016/j.engappai.2025.110638},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110638},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-adaptive production scheduling for discrete manufacturing workshop using multi-agent cyber physical system},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A pencil lead break-triggered, adversarial autoencoder-based
approach for rapid and robust rail damage detection. <em>EAAI</em>,
<em>150</em>, 110637. (<a
href="https://doi.org/10.1016/j.engappai.2025.110637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting early-stage damage is essential for railway maintenance, ruling out potential risks that could undermine railway ride comfort and safety. Ultrasonic testing methods, featuring high precision and non-destructive characteristics, have gained widespread use for on-site inspections in modern railway systems. However, current ultrasonic testing remains a highly complex technique that requires expensive ultrasonic devices and trained professionals for operation. This study presents a novel approach for rail damage detection utilizing a disposable mechanical pencil. By intentionally breaking the pencil lead on rail surface, the accumulated potential energy is released in the form of ultrasonic bursts which are acquired by sensors mounted on the rail. The rail damage diagnosis is empowered by an adversarial autoencoder (AAE) which learns representations of ultrasonic signals induced by pencil lead break (PLB). A damage-sensitive indicator is developed based on the Jensen-Shannon Divergence (JSD) between the AAE model output distributions of the baseline and an unknown signal, facilitating rapid and accurate damage diagnosis. Both laboratory experiments and on-site verifications were conducted to validate the proposed approach. The results demonstrate the effectiveness of the damage detection framework in identifying rail damage, exhibiting excellent robustness and reliability. Comparative studies are also conducted to demonstrate the adaptability and effectiveness of the proposed method against field testing environments. The research outcomes of this study will significantly contribute to the development of more efficient on-site inspection techniques for railway maintenance and sustainability.},
  archive      = {J_EAAI},
  author       = {Da-Zhi Dang and Bo-Yang Su and You-Wu Wang and Wai Kei Ao and Yi-Qing Ni},
  doi          = {10.1016/j.engappai.2025.110637},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110637},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A pencil lead break-triggered, adversarial autoencoder-based approach for rapid and robust rail damage detection},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-dimensional temperature field prediction with in-situ
data in metal additive manufacturing using physics-informed neural
networks. <em>EAAI</em>, <em>150</em>, 110636. (<a
href="https://doi.org/10.1016/j.engappai.2025.110636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately predicting the temperature field in metal additive manufacturing (AM) processes is critical for preventing overheating, adjusting process parameters, and ensuring process stability. While physics-based computational models offer precision, they are often time-consuming and unsuitable for real-time predictions. Machine learning models, on the other hand, rely heavily on high-quality datasets, which can be costly and difficult to obtain in the metal AM domain. Existing studies on physics-informed neural networks (PINNs) have made progress in integrating physics with machine learning but often lack in-situ data integration, which is essential for capturing real-time thermal dynamics. Additionally, their methodologies are typically heavily dependent on specific process characteristics, limiting their flexibility. Our work addresses these gaps by introducing a PINN-based framework specifically designed for temperature field prediction in metal AM. The framework incorporates in-situ temperature data gathered during the manufacturing process, combining it with physics-informed inputs and a custom loss function. The approach is demonstrated through two case studies. In the first case, using a small set of experimental data, the model achieves an error below 3 % with a mean absolute error (MAE) of 11 °C. In the second case, using simulation data, the model achieves an error below 1 % with an MAE of 7 °C. In addition, the framework shows promising adaptability for different metal AM scenarios with different geometries, deposition patterns, and process parameters.},
  archive      = {J_EAAI},
  author       = {Pouyan Sajadi and Mostafa Rahmani Dehaghani and Yifan Tang and G. Gary Wang},
  doi          = {10.1016/j.engappai.2025.110636},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110636},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Two-dimensional temperature field prediction with in-situ data in metal additive manufacturing using physics-informed neural networks},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A real-time onboard compressor stall warning method based on
attention multiple sensors fusion and lightweight network.
<em>EAAI</em>, <em>150</em>, 110635. (<a
href="https://doi.org/10.1016/j.engappai.2025.110635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compressor stall is one of the critical faults in aero-engines. An effective stall warning model can assist operators and aviation power systems in taking timely measures to avoid or minimize the impact of compressor stall on flight. Real-time onboard stall warning systems for compressors demand models that possess sufficient accuracy, high reliability, and fast execution speed. Therefore, this paper proposes a novel lightweight network based on attention mechanism for multiple sensors feature fusion, named attention feature fusion lightweight network (AFF-LWNet). Specifically, the network first accomplishes multi-sensor feature fusion through an attention feature fusion block. It then learns input features through a lightweight network with two lightweight feature extraction units and finally employs a multi-layer perceptron (MLP) to output stall warning signals. To verify the feasibility of this approach, the proposed method is evaluated on the aero-engine compressor stall dataset. The results demonstrate that the proposed method achieves an average testing accuracy of 99.453 % and an actual average lead time of 241.87ms on the stall dataset, which surpasses the other five competing methods. Therefore, we believe that the proposed method can effectively achieve real-time onboard stall warning for aero-engine compressors with outstanding performance.},
  archive      = {J_EAAI},
  author       = {Huijie Jin and Yong-Ping Zhao and Zhiqiang Wang},
  doi          = {10.1016/j.engappai.2025.110635},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110635},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A real-time onboard compressor stall warning method based on attention multiple sensors fusion and lightweight network},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable graph convolutional network based on catastrophe
theory and its application to group activity recognition. <em>EAAI</em>,
<em>150</em>, 110634. (<a
href="https://doi.org/10.1016/j.engappai.2025.110634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks (graph models for short) are crucial for understanding model decisions through mathematical white-box interpretation, which can radically improve the performance and credibility of downstream artificial intelligence applications. To address the limitations of existing interpretability of over-smoothing and over-squashing, we propose an explainable graph model based on nonlinear catastrophe theory and apply it to group activity recognition to validate the usefulness of interpretability. (1) We introduce catastrophe mathematical theory to explore the internal processes of graph models and construct the explainable dynamical equations of the graph convolutional network; (2) When graph node features lose uniqueness, leading to over-smoothing, which reduces the discriminative power of the graph model, we propose a mathematical method to predict over-smoothing; (3) In response to the over-squashing of the node feature values that is excessively compressed, we design a channel expansion unit to extend the transmission paths of graph nodes and alleviate the over-squashing in the graph structure. Finally, we apply our model to group activity recognition tasks to capture complex interactions within groups. We obtain the competitive results on five publicly available graph structure datasets (Actor, Chameleon, Texas, Cornell, Cora) and our self-built group activity dataset. Our model can effectively capture node and graph-level features with stronger generalization capabilities. For complex and diverse real-world group activity data, our model offers intuitive graph-level explanations for group activity analysis. Through the analysis of over-smoothing and over-squashing, our method extends new theoretical approaches in explainable artificial intelligence.},
  archive      = {J_EAAI},
  author       = {Junpeng Kang and Jing Zhang and Lin Chen and Hui Zhang and Li Zhuo},
  doi          = {10.1016/j.engappai.2025.110634},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110634},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Explainable graph convolutional network based on catastrophe theory and its application to group activity recognition},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A knowledge graph for the vulnerability of construction
safety system in megaprojects based on accident inversion.
<em>EAAI</em>, <em>150</em>, 110630. (<a
href="https://doi.org/10.1016/j.engappai.2025.110630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing vulnerability of construction safety systems in megaprojects (CSSMs) poses significant challenges to their safety management and control. To address this obstacle, this study retrodicts the accidents based on text mining using the Bidirectional Encoder Repre-sentations from Transformers Topic (BER-Topic) model to uncover topic and topic words related to the vulnerabilities of CSSMs. The vulnerability indicator system (VIS) is established by considering the exposure, sensitivity, and adaptability of the vulnerability of CSSMs. Subsequently, an improved Decision-making Trial and Evaluation Laboratory (DEMATEL) method based on association rules is proposed to reduce the subjectivity in assigning weights to vulnerability indicators, and a topological network based on complex network is constructed to identify the characteristics of VIS. Based on this, a knowledge graph of vulnerabilities in CSSMs is developed. Finally, taking into account the occurrence probability and the actual losses incurred of vulnerability indicators, a vulnerability assessment model for CSSMs is proposed. The research findings are: 1) Based on the BER-Topic model, 32 topics and topic words related to the vulnerability of CSSMs are mined. 2) A VIS for CSSMs is constructed, including 42 indicators across three dimensions of exposure (19), sensitivity (14), and adaptability (9), involving four aspects: humans, machines, environment, and management. 3) The key points for vulnerability management and control in CSSMs are Inaccurate implementation of geological remediation plans, Rusting of connecting components, and Unlicensed personnel operating, among others, which have strong intermediary roles.},
  archive      = {J_EAAI},
  author       = {Yingliu Yang and Pengcheng Xiang},
  doi          = {10.1016/j.engappai.2025.110630},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110630},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A knowledge graph for the vulnerability of construction safety system in megaprojects based on accident inversion},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust sparse discriminative least squares regression for
image classification. <em>EAAI</em>, <em>150</em>, 110626. (<a
href="https://doi.org/10.1016/j.engappai.2025.110626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discriminative Least Squares Regression (DLSR) is a method used for multi-class classification tasks that expands the distance between different classes through an ε -dragging technique. However, it also amplifies the differences in intra-class regression targets. Moreover, the samples contain a significant amount of noise, which negatively affect the classification performance. To mitigate these problems, we propose Robust Sparse Discriminative Least Squares Regression (RSDLSR) approach to enhance the model&#39;s discriminative power. Firstly, we maintain the original data structure by matrix decomposition in the label space. Secondly, the noise is fitted using sparse constrained noise matrix to enhance the model&#39;s denoising ability. Furthermore, we select important features from label space using a linear discriminant analysis criterion to minimize the influence of redundant features. Finally, l 2 , 1 norm constraint is imposed on the relaxation matrix to improve the sparsity and robustness of the model. Comparative evaluations demonstrate that our proposed method exhibits significant advantages over various existing methods across different classification tasks.},
  archive      = {J_EAAI},
  author       = {Zhangjing Yang and Dingan Wang and Pu Huang and Minghua Wan and Fanlong Zhang},
  doi          = {10.1016/j.engappai.2025.110626},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110626},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust sparse discriminative least squares regression for image classification},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A physics informed convolution neural network for
spatiotemporal temperature analysis of concrete dams. <em>EAAI</em>,
<em>150</em>, 110624. (<a
href="https://doi.org/10.1016/j.engappai.2025.110624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural health monitoring is indispensable throughout the life cycle of dams, and the loading conditions determines the reliability of the assessment. Among them, temperature plays an important role on the behavior of arch dams, which are sparsely monitored in practice. How to use these sparsely measured data to obtain the accurate spatiotemporal temperature field becomes a critical problem. This study proposes a physics informed convolutional neural network for spatiotemporal temperature field of arch dams. A dual thread convolutional neural network considers the effects of spatiotemporal and temporal variables distinctively. The proposed model is validated using measured data from an existing arch dam. Compared with applied convolutional neural network, the proposed model improves the accuracy of temperature field reconstruction by 18 % and reduces reliance on measured data. Benefit of consideration of the continuity and heat transfer, the spatial distribution of the temperature field is more reasonable in continuity, and can retain accuracy even with limited monitoring data. The proposed model can provide the actual spatiotemporal non-uniform temperature field of the arch dam, providing basic data for the analysis and safety evaluation of arch dams throughout their life-cycle.},
  archive      = {J_EAAI},
  author       = {Jiaqi Yang and Jinting Wang and Feng Jin and Jianwen Pan},
  doi          = {10.1016/j.engappai.2025.110624},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110624},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A physics informed convolution neural network for spatiotemporal temperature analysis of concrete dams},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A decision modeling approach for the development of
sustainable transportation oil companies. <em>EAAI</em>, <em>150</em>,
110623. (<a
href="https://doi.org/10.1016/j.engappai.2025.110623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constructing sustainable transportation infrastructure to address climate change by reducing carbon dioxide and greenhouse gas emissions is unfeasible without the involvement of international oil companies (IOCs). Identifying the most sustainable IOC can significantly enhance legitimacy, corporate image, brand value, transparency, and reputation. The environmental impact of oil transportation is crucial to the sector&#39;s long-term growth, and modeling IOCs can guide decision-making that aligns with regulatory, environmental, and societal expectations, ensuring successful project implementation. Modeling IOCs presents multiple-attribute decision-analysis (MADA) challenges. Previous research proposed a decision matrix that crossed IOC alternatives with attributes, sub-attributes, and measurement items, utilizing assessments from 483 experts across 11 IOCs based on 2 attributes, 9 sub-attributes, and 47 measurements. Despite the literature review, challenges such as score deviations in the ranking method, as well as informational vagueness, ambiguity, and uncertainty in both weighting and ranking processes, remain unsolved, and early MADA methods exhibit theoretical flaws. This study aims to formulate and develop a decision modeling approach using multi-attribute ideal-real comparative analysis (MAIRCA) and fuzzy weighted zero inconsistency (FWZIC) within a homogeneous interval-valued intuitionistic fuzzy rough set (IIFRS) environment. This solution addresses the limitations in the literature and effectively handles the complexity of the decision matrix. The findings reveal that cost leadership under a hybrid competitive strategy (HCS-CL) emerged as the most sensitive attribute, holding the highest weight, highlighting the importance of cost efficiency and competitive pricing. IOC11 ranked highest, followed by IOC3 and IOC10, providing benchmarks for other companies. Lesser-ordered companies, such as IOC4, preserve employ these comprehensions to recognize intentional gaps and embrace best attempts from extraordinary-ordered participants. Sensitivity-analysis, Spearman&#39;s-correlation, and comparative-analysis proven the robustness of the proposed approach. The study highlights the require for oil and gas administrators to spotlight cost leadership advantages, raise-efficiency, lower-production costs, and influence economies of ratio to maintain a reasonable edge and enhance-market-positioning.},
  archive      = {J_EAAI},
  author       = {Hassan A. Alsattar and Sarah Qahtan and Nahia Mourad and A.A. Zaidan and Muhammet Deveci and Dragan Pamucar and Jurgita Antucheviciene and Weiping Ding},
  doi          = {10.1016/j.engappai.2025.110623},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110623},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A decision modeling approach for the development of sustainable transportation oil companies},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving model calibration in bone marrow cell
classification through mixup and center loss fusion. <em>EAAI</em>,
<em>150</em>, 110620. (<a
href="https://doi.org/10.1016/j.engappai.2025.110620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The analysis of bone marrow cell morphology is essential for the accurate diagnosis of hematological disorders. Traditional manual classification methods are time-consuming and labor-intensive. Although current automatic deep learning techniques mitigate these issues, they may still present significant risks in critical medical diagnostics due to overconfidence in predictions. To tackle these challenges, this paper proposes a novel calibration method called MixCL (Mix-Center Loss). MixCL combines the simple and effective data augmentation method Mixup with deep metric learning Center Loss, achieved through the design of a new loss function. By utilizing Mixup to generate mixing centers that enrich the feature sampling in the feature space, and leveraging the clustering effect of Center Loss to enhance the grouping of similar samples, MixCL combines the strengths of both methods. The effectiveness of MixCL is validated using three real bone marrow cell image datasets, demonstrating significant reductions in Expected Calibration Error (ECE) and Overconfidence Error (OE) for in-distribution samples. For example, in Shifted Windows Transformer model, ECE and OE metrics decreased across all datasets, with reductions averaging 1.72% in ECE and 2.10% in OE. The confidence Kernel Density Estimation (KDE) plot reveals that models using MixCL more effectively manage uncertainty in out-of-distribution samples, ensuring better differentiation between in-distribution and out-of-distribution samples. Thus, the proposed method effectively improves the calibration performance of the model while exhibiting better generalization performance, significantly improved when compared with current advanced bone marrow cell classification methods. Moreover, it has potential applications in various image classification fields, providing reliable confidence estimates.},
  archive      = {J_EAAI},
  author       = {Shuming Cheng and Qinghang Lu and Qianhang Guo and Yunqi Lin and Mingxin Li and Xingyu Zhao and Liang Guo and Jiaming Li and Jie Li and Qingmao Zhang and Qiongxiong Ma},
  doi          = {10.1016/j.engappai.2025.110620},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110620},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improving model calibration in bone marrow cell classification through mixup and center loss fusion},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Precise step counting algorithm for pedestrians using
ultra-low-cost foot-mounted accelerometer. <em>EAAI</em>, <em>150</em>,
110619. (<a
href="https://doi.org/10.1016/j.engappai.2025.110619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-velocity update (ZUPT) is one of the most widely used step counting methods in pedestrian inertial navigation. Existing accelerometer-based methods encounter issues with misjudgments of zero velocity and step counting errors in various activities. To tackle these challenges, we present a precise step counting algorithm leveraging ultra-low-cost foot-mounted accelerometer for pedestrians with extremely low complexity. This algorithm mainly contains two key points: adaptive acceleration threshold selection and state vector update, implemented by twice zero-velocity detections (ZVD, generating state vectors to depict pedestrian&#39;s status) and length comparisons. Accelerations undergo gravity correction, magnitude calculation, data smoothing, and parameters initialization. Subsequently, the zero-acceleration threshold is adaptively selected through ZVD, and the length of state intervals (LSI) is compared with the first length threshold. Then, the state vector is updated by ZVD, and the LSI is compared with the second length threshold. Finally, the number of state intervals is interpreted as step counts. Step counting experiments were conducted utilizing three diverse datasets, which comprised a self-constructed ultra-low-cost accelerometer-based dataset and two public datasets. These datasets covered various activities, such as normal walking, fast walking, running, multiple turns in a corridor, stationary stepping, and upstairs/downstairs. The proposed algorithm could achieve an accuracy of 100 % under the above situations. Compared to long short term memory (LSTM) and other algorithms, it exhibited an accuracy improvement of at least 13.05 %, with a processing time only 0.07 % of that required by LSTM. The proposed algorithm enables accurate step counting across a range of activities performed by different pedestrians with high precision, low complexity, and robust applicability.},
  archive      = {J_EAAI},
  author       = {Jingxue Bi and Jianhui Wang and Baoguo Yu and Guobiao Yao and Yunjia Wang and Hongji Cao and Lu Huang and Huaqiao Xing},
  doi          = {10.1016/j.engappai.2025.110619},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110619},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Precise step counting algorithm for pedestrians using ultra-low-cost foot-mounted accelerometer},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-stream structure-oriented neighbor enhancement network
for dental model segmentation. <em>EAAI</em>, <em>150</em>, 110618. (<a
href="https://doi.org/10.1016/j.engappai.2025.110618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary objective of digital orthodontic treatment is to achieve accurate tooth segmentation of the three-dimensional (3D) dental mesh model obtained from oral scanning equipment. However, current advanced deep learning-based methods often consolidate all features into a single vector during the feature learning process, thus overlooking the distinct information among features and subsequently weakening their complementary roles. To address this issue, we propose a two-stream structure-oriented neighbor enhancement network (TSNEN) to improve the complementary effect among different features. Specifically, TSNEN develops an input-specific two-stream structure and feature enhancement modules to emphasize the geometric disparities among various meshes and achieve the complementary enhancement of different features, respectively. Furthermore, the self-attention module is modified to fully integrate the local features derived from the branches of the two streams, which effectively balances the data differences among different features to mitigate feature confusion, and ultimately achieves accurate segmentation of the dental model. The real dental model dataset is analyzed to verify the effectiveness and capability of the proposed method which reached an overall accuracy (OA) at 96.83 % and mean over union (mIoU) at 92.06 %. Finally, the comparative analysis is implemented and the results further show that the proposed method has better performance both in prediction accuracy and robustness.},
  archive      = {J_EAAI},
  author       = {Zhihua Liu and Hao Tang and Jiutao Xue and Yuhe Liao},
  doi          = {10.1016/j.engappai.2025.110618},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110618},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Two-stream structure-oriented neighbor enhancement network for dental model segmentation},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time prediction of axial force in concrete-filled steel
tubular columns under fire conditions using modular artificial
intelligence techniques. <em>EAAI</em>, <em>150</em>, 110617. (<a
href="https://doi.org/10.1016/j.engappai.2025.110617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The axial force plays a critical role in assessing the functional integrity of columns within a building in fire. However, it cannot be measured directly and is influenced by factors such as temperature, load ratio, and axial restraint. This study proposes a real-time methodology to predict the axial force of restrained concrete-filled steel tubular (CFST) columns exposed to real fires, utilizing modular artificial intelligence. A module is developed that combines a convolutional neural network (CNN) and long short-term memory (LSTM) networks to predict the temperature field of CFST columns caused by fire in real time. This module estimates the current temperature field using past data and the current surface temperature, which is continuously monitored with inherent noise. It effectively mitigates noise interference, achieving an R 2 of 0.97 on the test dataset, which ensures accurate estimations. Additionally, a separate LSTM module with a skip connection is employed to predict the axial force ratio, integrating temperature predictions and real-time measurements of axial deformation. Finally, the accuracy of this modular model demonstrates better performance in predicting real-time axial force compared to the conventional integrated deep learning model, achieving an R 2 of 0.99. The proposed approach enables accurate prediction of axial force in restrained CFST columns across various fire scenarios and structural conditions, aiming at increasing the scientificity of fire rescue decisions.},
  archive      = {J_EAAI},
  author       = {Hong-Hui Qi and Guo-Qiang Li and Shaojun Zhu},
  doi          = {10.1016/j.engappai.2025.110617},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110617},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Real-time prediction of axial force in concrete-filled steel tubular columns under fire conditions using modular artificial intelligence techniques},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A real-time prediction model for instantaneous dam-break
flood evolution of concrete gravity dams based on attention mechanism
and spatiotemporal multiple features. <em>EAAI</em>, <em>150</em>,
110616. (<a
href="https://doi.org/10.1016/j.engappai.2025.110616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simulating the flood evolution following the sudden breach of concrete gravity dams is crucial for enabling prompt emergency flood control decisions. The real-time performance and reliability of these flood propagation simulations are essential for improving the accuracy and speed of emergency responses. This study introduces a deep learning model that integrates an attention mechanism to predict flood evolution parameters in real time. Initially, parameters such as water depth and flow rate were measured under 32 distinct dam-break scenarios using a hydrodynamic model. By combining terrain data with time-series flood discharge data, we compiled a dataset containing 1984 entries, enhanced through reduced-order methods. A novel deep learning model, the Flood-Swin-Transformer, was then developed to predict the spatiotemporal evolution of dam-break floods. This model was benchmarked against 11 baseline models and four state-of-the-art deep learning models. The results indicate: (1) Baseline models accurately predict water depth but are less effective at predicting flow rate parameters; (2) Deep learning models outperform baseline models in both accuracy and classification capabilities for water depth and flow rate parameters, showing robust performance; (3) Extensive analyses, including error, classification accuracy, effectiveness, robustness, and flood parameter error mapping, demonstrate the superior performance of the proposed model; (4) The proposed model predicts flood evolution up to 43.75 times faster than traditional hydrodynamic models, facilitating real-time prediction capabilities.},
  archive      = {J_EAAI},
  author       = {Chao Wang and Yaofei Zhang and Sherong Zhang and Xiaohua Wang and Xingbo Zhou and Yishu Lai},
  doi          = {10.1016/j.engappai.2025.110616},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110616},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A real-time prediction model for instantaneous dam-break flood evolution of concrete gravity dams based on attention mechanism and spatiotemporal multiple features},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dialogue response coherency evaluation with feature
sensitive negative sample using multi list-wise ranking loss.
<em>EAAI</em>, <em>150</em>, 110609. (<a
href="https://doi.org/10.1016/j.engappai.2025.110609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic evaluation of dialogue coherency is crucial for developing high-quality dialogue systems. However, traditional evaluation metrics such as Bilingual Evaluation Understudy (BLEU) and Recall-Oriented Understudy for Gisting Evaluation (ROUGE) have limitations when it comes to assessing diverse and creative responses because they heavily rely on reference responses. For learnable metrics which utilize contrastive learning, challenges are encountered due to the use of randomly selected negative samples that do not reflect conversational features (i.e. topic, emotion, intention) and the lack of granularity in assessing response appropriateness. To address these limitations, we propose the Feature sensitive Multi-Listwise Ranking (FMListR) response coherency evaluation model. This model aims to evaluate dialogue coherency in degrees while considering conversational sensitive features. This approach involves sampling feature-sensitive responses that share conversational features with ground truth responses and utilizing them as hard negative samples. The model is trained using Multi-Listwise Ranking (MListR) loss, which is designed to learn the ranking between negative samples and identify response features. The experimental results demonstrate that Feature sensitive Multi-Listwise Ranking exhibits stronger correlations with human judgment compared to other response coherency evaluation metrics. By considering conversational features and training the model using a specialized loss function, FMListR provides a more robust and accurate evaluation of dialogue coherency.},
  archive      = {J_EAAI},
  author       = {YeongJun Hwang and Dongjun Kang and JinYeong Bak},
  doi          = {10.1016/j.engappai.2025.110609},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110609},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dialogue response coherency evaluation with feature sensitive negative sample using multi list-wise ranking loss},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comprehensive assessment of failure mode and shear capacity
of reinforced concrete circular columns based on data-driven machine
learning methods. <em>EAAI</em>, <em>150</em>, 110603. (<a
href="https://doi.org/10.1016/j.engappai.2025.110603">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforced concrete (RC) columns are critical elements in frame structures. A common challenge in structural engineering is estimating the seismic capacity of circular RC columns, as existing methods typically require transforming circular columns into equivalent square sections due to the absence of direct formulas. To address this, this study introduces data-driven machine learning (ML) methods to directly assess both failure modes and seismic shear capacity of circular RC columns. With the help of automated machine learning (AutoML), seven ML algorithms were selected and fine-tuned, resulting in 40 distinct models that were analyzed and compared in detail. The results indicate that the Multilayer Perceptron (MLP) model outperforms others in predicting seismic failure modes, achieving a high accuracy of 88 %. For seismic shear capacity predictions, the Weighted Ensemble (WE) model achieved the best performance with Root Mean Squared Error of 53.49, Mean Absolute Error of 39.23, Coefficient of Determination of 0.88 and Mean Squared Error of 2861.18 among all the ML models. Furthermore, the results (the predicted maximum lateral force/the experimental results) of the WE model, with a mean value of 0.98, a standard deviation of 0.11, and a coefficient of variation (mean/standard deviation) of 12.8 %, surpass those of traditional theoretical and empirical models. Besides, the ML models offer fast, accurate seismic performance evaluations for circular RC columns, eliminating the need for complex and time-consuming calculations. Furthermore, SHapley Additive exPlanations (SHAP) analysis provided visual insights into parameter contributions, enhancing model transparency and trust for engineering applications.},
  archive      = {J_EAAI},
  author       = {Yue Wen and Shiqiao Zhou and Gaochuang Cai and Zhili He and Amir Si Larbi},
  doi          = {10.1016/j.engappai.2025.110603},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110603},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Comprehensive assessment of failure mode and shear capacity of reinforced concrete circular columns based on data-driven machine learning methods},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging large language models to examine the interaction
between investor sentiment and stock performance. <em>EAAI</em>,
<em>150</em>, 110602. (<a
href="https://doi.org/10.1016/j.engappai.2025.110602">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the relationship between investor sentiment and stock performance is crucial in dynamic financial markets. Existing researches often focus on financial news and stock prices, while studies on investor sentiment typically rely on traditional machine learning models that require extensive data labeling. Additionally, most researches focus on single stock indices, overlooking the impact of brand popularity. To address these gaps, this study proposes a novel framework to analyze the interaction between investor sentiment and stock performance, using Chinese Baijiu industry stocks as a case example. It further explores how brand popularity influences this relationship, offering insights for informed investment decisions through artificial intelligence technology. In this study, we leverage Generative Pre-trained Transformer 4 (GPT-4), a state-of-the-art black-box large language model, to process vast volumes of unstructured text data from stock forums. By employing in-context learning with human-labeled examples, GPT-4 generates weak labels that are subsequently used to fine-tune Large Language Model Meta AI (LLaMA), a smaller and more efficient open-source LLM from Meta AI, thereby enabling sentiment-driven decision-making in real-world scenarios. To construct a comprehensive sentiment indicator, we integrate both direct and indirect factors influencing sentiment and use principal component analysis to combine them effectively. To examine interaction between sentiment and stock yield, we apply the Granger causality test and vector autoregression models across stocks with different brand popularity levels. The results show that our framework achieves state-of-the-art performance investor sentiment analysis. Moreover, with brand popularity significantly amplifying the interaction between investor sentiment and stock yield, it leads to bidirectional Granger causality in highly popular brands.},
  archive      = {J_EAAI},
  author       = {Yong Zhuang and Feilong Wang and Dickson K.W. Chiu and Kevin K.W. Ho},
  doi          = {10.1016/j.engappai.2025.110602},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110602},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Leveraging large language models to examine the interaction between investor sentiment and stock performance},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lane change trajectory planning based on improved model
predictive control with artificial potential field for autonomous
vehicles in medium-high speed scenarios. <em>EAAI</em>, <em>150</em>,
110601. (<a
href="https://doi.org/10.1016/j.engappai.2025.110601">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the design of a lane change control system for autonomous vehicles (AVs) in medium-high speed scenarios. A lane change trajectory planning method based on the combination of artificial potential field (APF) and model predictive control (MPC), referred to as APF-MPC, is proposed. To ensure a smooth transition at the beginning and end of the lane change, a reference trajectory based on a sinusoidal curve is designed. The obstacle potential field, constructed using a two-dimensional joint probability density function, is combined with the road potential field to enhance lane change safety. The potential field function is integrated into the MPC optimal control problem, which is constructed based on the point-mass model. This problem is then solved to obtain the planned trajectory within the predicted time domain. The lateral and longitudinal tracking controllers, designed using linear MPC, are employed to track the planned trajectory in real-time, thereby demonstrating the real-time performance of this method. The feasibility of the APF-MPC method is verified through a co-simulation platform. The simulation results indicate that the trajectories planned by the APF-MPC method meet the requirements of safety, occupant comfort, and lane change efficiency. In different scenarios, the front wheel angle of the AV during the lane change ranges from -2 to 2 degrees. Compared with non-adaptive APF and traditional MPC methods, the maximum lateral acceleration, maximum lateral velocity, and maximum front wheel steering angle of the AV during lane changing are reduced by more than 40%.},
  archive      = {J_EAAI},
  author       = {Zhaojun Zhang and Jiale Qin and Simeng Tan and Hongjie Luo},
  doi          = {10.1016/j.engappai.2025.110601},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110601},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lane change trajectory planning based on improved model predictive control with artificial potential field for autonomous vehicles in medium-high speed scenarios},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Input parameterized physics informed neural networks for de
noising, super-resolution, and imaging artifact mitigation in time
resolved three dimensional phase-contrast magnetic resonance imaging.
<em>EAAI</em>, <em>150</em>, 110600. (<a
href="https://doi.org/10.1016/j.engappai.2025.110600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivation: Hemodynamic analysis is crucial for diagnosing and predicting cardiovascular diseases. However, methods relying on fluid flow simulations or blood flow imaging are complex, time-consuming, and require specialized expertise, limiting their clinical use. Goal: This research aims to automate the enhancement of blood flow images, providing clinicians with a fast, accurate tool for hemodynamic analysis without requiring advanced expertise. Objectives: A software tool based on physics-constrained neural networks was developed to enable clinicians to easily select and process regions of interest (ROIs) in time-resolved three-dimensional phase contrast magnetic resonance imaging (4D-Flow MRI) blood flow images for quick, accurate analysis. Methods: The Input Parameterized Physics-Informed Neural Network (IP-PINN) was introduced to improve the spatio-temporal resolution of 4D-Flow MRI. IP-PINN mitigates noise, velocity aliasing, and phase errors. A convolutional neural network processes ROI data into latent vectors, which are then used to predict velocity, pressure, and spin density via a multi-layer perceptron. The method is trained with synthetic blood flow data using an innovative loss function that addresses noise and artifacts. Results: IP-PINN successfully enhanced image resolution, reducing noise and artifacts when tested on synthetic 4D-Flow MRI data derived from blood flow simulations of intracranial aneurysms. For data with 20 decibels (dB) signal-to-noise ratio, results closely matched the ground truth with less than 5.5% relative error. Processing took under two minutes. The method also has the potential to reduce data acquisition time by 25%. Conclusions: IP-PINN could significantly enhance the clinical use of 4D-Flow MRI for personalized hemodynamic analysis in cardiovascular diseases.},
  archive      = {J_EAAI},
  author       = {Amin Pashaei Kalajahi and Hunor Csala and Zayeed Bin Mamun and Sangeeta Yadav and Omid Amili and Amirhossein Arzani and Roshan M. D’Souza},
  doi          = {10.1016/j.engappai.2025.110600},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110600},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Input parameterized physics informed neural networks for de noising, super-resolution, and imaging artifact mitigation in time resolved three dimensional phase-contrast magnetic resonance imaging},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing machine learning algorithms for fault
classification in rolling bearings: A bayesian optimization approach.
<em>EAAI</em>, <em>150</em>, 110597. (<a
href="https://doi.org/10.1016/j.engappai.2025.110597">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern power machinery is inherently complex and operates under dynamic operating conditions, so they demand advanced solutions based on deep learning to diagnose bearing faults inside rotating equipment that cause unplanned downtime and safety issues, leading to operational challenges. However, most deep learning approaches aim to improve performance by incorporating hybrid neural networks that rely on multiple convolutional and temporal units, often overlooking optimizing the large number of hyperparameters that define the structure and performance of hybrid models along with the associated computational constraints. To address this gap, this study presents an innovative approach for the detection and classification of bearing faults by integrating an optimized sparse deep autoencoder (DAE) with a Bidirectional Long Short-Term Memory model (Bi-LSTM). The optimal network structure and hyperparameters are determined through Bayesian optimization (BO) with parallel settings, which automatically searches for network configurations that improve the feature extraction ability of the DAE and the generalization ability of the Bi-LSTM for more efficient fault classification in rolling bearings. Parallel optimization accelerates network structure and hyperparameter tuning by evaluating multiple configurations at once. It leverages the full potential of available multi-core Central Processing Units (CPUs)/Graphics Processing Units (GPUs) in conjunction with a lightweight BO surrogate model. This autonomous and user-friendly framework generates inputs from principal component analysis for linear and BO-DAE for non-linear feature extraction and selection, which are then used to train a BO-enhanced Bi-LSTM. This three-stage optimized method effectively captures spatial and temporal dependencies in vibrational signals, achieving superior efficiency, accuracy, and reliability compared to shallow and deep learning models. Evaluation metrics, including macro precision (99.50 %), recall (99.60 %), F1-Score (99.57 %), and Cohen&#39;s Kappa metric (Cκ = 99.53 %), demonstrate the efficacy of our approach for bearing fault classification in industrial applications.},
  archive      = {J_EAAI},
  author       = {Muhammad Zain Yousaf and Josep M. Guerrero and Muhammad Tariq Sadiq},
  doi          = {10.1016/j.engappai.2025.110597},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110597},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimizing machine learning algorithms for fault classification in rolling bearings: A bayesian optimization approach},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic scheduling in flexible and hybrid disassembly
systems with manual and automated workstations using reward-shaping
enhanced reinforcement learning. <em>EAAI</em>, <em>150</em>, 110588.
(<a href="https://doi.org/10.1016/j.engappai.2025.110588">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As e-waste grows at an alarming rate, efficient disassembly systems have become crucial for sustainable production practices. Existing disassembly systems rely heavily on fixed automation and limited manual intervention, making it challenging to adapt to dynamic issues such as workstation failures and system bottlenecks, leading to inefficiencies and suboptimal resource allocation. To address these issues, a hybrid disassembly system is developed that integrates manual and automated workstations, allowing for the flexible variation of manual resources as needed to optimize the disassembly process, with a focus on reducing time and maximizing profit. Through the proposal of a Proximal Policy Optimization (PPO) algorithm enhanced with Reward-Shaping, the research effectively tackles key challenges of uncertainty and dynamic conditions in disassembly systems, including workstation failures and system bottlenecks. These issues are explored through a refrigerator disassembly simulation model. The results demonstrate that the PPO algorithm significantly outperforms traditional rule-based methods and two other reinforcement learning techniques in managing complex dynamic scheduling and resource allocation tasks, offering greater efficiency and flexibility. These findings contribute to the advancement of automated disassembly processes and their integration into modern industrial systems.},
  archive      = {J_EAAI},
  author       = {Jinlong Wang and Qihuiyang Liang and Min Li and Zelin Qu and Yuanyuan Zhang},
  doi          = {10.1016/j.engappai.2025.110588},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110588},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic scheduling in flexible and hybrid disassembly systems with manual and automated workstations using reward-shaping enhanced reinforcement learning},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Soft actor-critic enhanced nonsingular terminal synergetic
control for serial manipulators with quantized input and state.
<em>EAAI</em>, <em>150</em>, 110587. (<a
href="https://doi.org/10.1016/j.engappai.2025.110587">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synergetic control is vulnerable to model uncertainty, which affects control performances and stability. In addition, quantized sensor measurements and control signals compound these challenges. Equally important, a unique problem in serial manipulator robots is the varying control response across joints, which affects the end effector’s pose when moving to the desired position. The mentioned challenges motivate this study to propose soft actor-critic reinforcement learning as a novel adaptive approach for nonsingular terminal synergetic control on a 4-degree-of-freedom serial manipulator robot. The control law is designed based on the nonsingular terminal synergetic control evolution constraint, manifold, and macrovariable. Subsequently, the soft actor-critic reinforcement learning dynamically adjusts the evolution constraint parameters, adapting to the changing state of the environment. The Lyapunov stability theorem proves the control law stability. This study also introduces a novel reinforcement learning reward function that encourages state convergence using the Cauchy probability density function and macrovariable. The agent training environment accounts for state and input quantization, enabling a seamless sim-to-real transition. The simulations and physical experiments validate the effectiveness of the proposed controller in improving transient response, tracking response, and uniform performance across joints. Additionally, online training validates the safe exploration property of the proposed adaptive control.},
  archive      = {J_EAAI},
  author       = {Muhammad Auzan and Yong-Lin Kuo},
  doi          = {10.1016/j.engappai.2025.110587},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110587},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Soft actor-critic enhanced nonsingular terminal synergetic control for serial manipulators with quantized input and state},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial neural networks for finger vein recognition: A
survey. <em>EAAI</em>, <em>150</em>, 110586. (<a
href="https://doi.org/10.1016/j.engappai.2025.110586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finger vein recognition is an emerging biometric recognition technology. Different from the other biometric features on the body surface, the venous vascular tissue of the fingers is buried deep inside the skin. Due to this advantage, finger vein recognition is highly stable and private. Finger veins are virtually impossible to steal and difficult to interfere with by external conditions. Unlike the finger vein recognition methods based on traditional machine learning, the artificial neural network technique, especially deep learning, does not rely on feature engineering and has superior performance. To summarize the development of finger vein recognition based on artificial neural networks,this paper collects 174 related papers. First, we introduce the background of finger vein recognition and the motivation for this survey. Then, the development history of artificial neural networks and the representative networks on finger vein recognition tasks are introduced. The public datasets widely used in finger vein recognition are then described. After that, we summarize the related finger vein recognition tasks based on classical neural networks and deep neural networks, respectively. Finally, the challenges and potential development directions in finger vein recognition are discussed. This paper provides a comprehensive and novel summary of the application of artificial neural networks in the finger vein recognition field.},
  archive      = {J_EAAI},
  author       = {Yimin Yin and Renye Zhang and Pengfei Liu and Wanxia Deng and Dayu Hu and Siliang He and Chen Li and Jinghua Zhang},
  doi          = {10.1016/j.engappai.2025.110586},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110586},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Artificial neural networks for finger vein recognition: A survey},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-module cooperative control method for on-ramp area in
heterogeneous traffic flow using reinforcement learning. <em>EAAI</em>,
<em>150</em>, 110584. (<a
href="https://doi.org/10.1016/j.engappai.2025.110584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the on-ramp area, vehicle conflicts significantly reduce traffic efficiency and increase collision risks. This study introduces a novel dual-module cooperative control approach designed for on-ramps that accommodate heterogeneous traffic flows, including connected and automated vehicles (CAVs) and human driving vehicles (HDVs). By utilizing reinforcement learning techniques, the approach aims to enhance both traffic efficiency and safety. The approach comprises two key modules: the merging control module and the lane-changing control module. The merging control module facilitates cooperation between mainline and ramp vehicles, while the lane-changing control module assists mainline CAVs in making informed lane-change decisions. Agents within these modules are trained using the proximal policy optimization algorithm, known for its strong convergence properties. After 100 to 200 training episodes, the agents achieve stable peak average rewards. Simulation results demonstrate significant improvements in traffic efficiency and safety with the dual-module control method in on-ramp areas, especially in scenarios involving CAV-HDV heterogeneous traffic flows. With a CAV penetration rate of just 0.2, average vehicle delay is reduced by 26 %. Furthermore, from a safety perspective, when the CAV penetration rate reaches or exceeds 0.3, the time-exposed time-to-collision decreases by approximately 45 %. Transferability analysis indicates that integrating reinforcement learning agents into the control strategy produces positive results across varying maximum speeds and flow rates. In heterogeneous traffic environments, it is advisable to train agents at high CAV penetration rates. Comparative studies further show that the proposed method significantly enhances traffic efficiency and safety, maintaining robust performance even at lower CAV penetration rates.},
  archive      = {J_EAAI},
  author       = {Wenzhang Yang and Changyin Dong and Ziqian Zhang and Xu Chen and Hao Wang},
  doi          = {10.1016/j.engappai.2025.110584},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110584},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A dual-module cooperative control method for on-ramp area in heterogeneous traffic flow using reinforcement learning},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Class imbalance-aware domain specific transfer learning
approach for medical image classification: Application on COVID-19
detection. <em>EAAI</em>, <em>150</em>, 110583. (<a
href="https://doi.org/10.1016/j.engappai.2025.110583">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional Neural Networks (CNNs) show promise in medical image classification; however, their effectiveness is often constrained by the availability of large, annotated datasets, which are not always accessible. Additionally, the lack of medically relevant transfer models limits the potential of Transfer Learning (TL) in addressing this challenge. Existing TL methods typically employ conventional approaches that result in suboptimal performance and exhibit issues related to network bias, especially in imbalanced datasets. To overcome these limitations, we introduce a novel class imbalance-aware, domain-specific transfer learning framework (CIDSTL-Net) designed specifically for medical imaging tasks. CIDSTL-Net adopts a two-stage training approach: initially developing domain-specific models followed by fine-tuning on targeted medical datasets. This method incorporates an innovative class weighting strategy in its loss calculation to address dataset bias and enhances the transfer head network with a novel combination of fully connected, batch normalization, and dropout layers. Additionally, CIDSTL-Net employs cyclically scheduled learning rates to optimize parameter exploration and exploitation during training. We have rigorously evaluated CIDSTL-Net on four publicly available COVID-related datasets, covering chest X-ray and Computed Tomography (CT) images for the classification of COVID, Non-COVID, Normal, Pneumonia, and Lung Opacity conditions. The results demonstrate state-of-the-art performance with 5-fold cross-validation mean accuracies of 96.87 %, 96.50 %, 99.70 %, and 99.55 % for the respective datasets, marking significant improvements over existing methods. Among various CNN architectures tested, DenseNet-121 proved to be the most effective, offering superior accuracy with fewer parameters. Given the pressing global challenge posed by the COVID-19 pandemic, CIDSTL-Net holds significant potential to aid medical practitioners in the rapid and accurate classification of COVID-19 cases.},
  archive      = {J_EAAI},
  author       = {Marut Jindal and Birmohan Singh},
  doi          = {10.1016/j.engappai.2025.110583},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110583},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Class imbalance-aware domain specific transfer learning approach for medical image classification: Application on COVID-19 detection},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent evaluation of pavement friction at high speeds
with artificial intelligence powered three-dimensional laser imaging
technology. <em>EAAI</em>, <em>150</em>, 110580. (<a
href="https://doi.org/10.1016/j.engappai.2025.110580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate non-contact pavement friction evaluation at high speeds faces many challenges when using low-resolution (LR) three-dimensional (3D) texture images or other deficient texture data. With artificial intelligence (AI) powered 0.1-mm (0.1-mm) 3D laser imaging technology, this paper proposed a two-step deep learning (DL) network, named Friction-8KNet, for accurate and intelligent non-contact pavement friction evaluation at high speeds. Particularly, a 3D laser imagining device was employed to collect LR texture images at a speed of 30 mph, which were processed via a DL-based super-resolution (SR) algorithm to obtain 0.1 mm high-resolution (HR) images with a size of 8192 × 4096 (8K) pixels. The Friction-8KNet comprises a network backbone for texture feature extraction in Step 1 and a triple attention network for friction evaluation in Step 2. The network backbone is developed to precisely extract features of an HR image without requiring large graphics processing unit (GPU) memory. The triple attention net is designed with three function-specific attention modules to utterly mine the extracted features for accurate friction prediction. Experimental results show that Friction-8KNet can achieve 99.19 % prediction accuracy and transcends models using other texture data, including small HR 3D images, LR 3D images, and two-dimensional (2D) texture profiles. This research promotes an accurate and efficient measurement of pavement friction for production level in a non-contact manner in the future.},
  archive      = {J_EAAI},
  author       = {Guolong Wang and Kelvin C.P. Wang and Guangwei Yang},
  doi          = {10.1016/j.engappai.2025.110580},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110580},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent evaluation of pavement friction at high speeds with artificial intelligence powered three-dimensional laser imaging technology},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Corrigendum to “understanding the disparities in mathematics
performance: An interpretability-based examination” [eng. Appl. Artif.
Intell. 133 part b (2024) 108109]. <em>EAAI</em>, <em>150</em>, 110579.
(<a href="https://doi.org/10.1016/j.engappai.2025.110579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EAAI},
  author       = {Ismael Gómez-Talal and Luis Bote-Curiel and José Luis Rojo-Álvarez},
  doi          = {10.1016/j.engappai.2025.110579},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110579},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Corrigendum to “Understanding the disparities in mathematics performance: An interpretability-based examination” [Eng. appl. artif. intell. 133 part b (2024) 108109]},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Standalone and hybrid machine learning approaches to predict
sediment load in an alluvial channel. <em>EAAI</em>, <em>150</em>,
110578. (<a
href="https://doi.org/10.1016/j.engappai.2025.110578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A significant amount of sediment transported in an alluvial river can alter the morphology and shape of the river. Accurate prediction of sediment load is essential in studying the change in geomorphology and dynamics of rivers and also to evaluate its impact on aquatic ecosystems, infrastructure, and human activities dependent on water resources. The present study demonstrates framework for predicting sediment load in alluvial channels using both standalone and hybrid machine learning (ML) models. Multiple datasets collected from various river surveys and flume studies were used to evaluate the significance of key variables such as friction slope ( Sf ), channel discharge ( Q ), and bed shear stress ( τ b ) affecting the sediment transport employing ML models (Bagging (BA), Random Committee (RC)) and the standalone ML models (Multi-Layer Perceptron Regression (MLPR) and Reduced Error Pruning Tree (REPT). The hybrid Bagging-REPT (BA-REPT) model outperformed other models with a Nash-Sutcliffe Efficiency (NSE) of 0.915, followed by RC-REPT (NSE = 0.906). Among the various variables, friction slope ( S f ) was identified as the most influential variable affecting sediment transport behavior. It was also observed that Hybrid models can predict sediment transport behavior more accurately as compared to standalone models and empirical equations. The findings of the study thus demonstrate the importance of hybrid learning in addressing the nonlinear complexity of sediment transport processes.},
  archive      = {J_EAAI},
  author       = {Sanjit Kumar and Vishal Deshpande and Mayank Agarwal},
  doi          = {10.1016/j.engappai.2025.110578},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110578},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Standalone and hybrid machine learning approaches to predict sediment load in an alluvial channel},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight vision transformer with embedded hybrid
attention for quick response code defect classification. <em>EAAI</em>,
<em>150</em>, 110575. (<a
href="https://doi.org/10.1016/j.engappai.2025.110575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quick Response (QR) code label printing quality is crucial to product control. Due to the limited number of defect samples, unclear features, and the need to detect a large number of labels in real time, automated visual inspection faces challenges. For efficient and accurate automated visual defect recognition of printed QR code production, we propose a lightweight Vision Transformer network, Vision Transformer with Embedded Hybrid Attention (ViT-EHA). First, the Mixed Depthwise Convolution Block (MDConvBlock) is introduced to capture QR code defect details and feature information. This method additionally reduces the number of model parameters and computational costs. Furthermore, the LeAttention-Local Convolution-Multilayer Perceptron (LeALCM) module is proposed to enhance the ability to capture global information of the model and improve the effect of minor defect recognition. Ultimately, a hybrid attention (HA) module has been integrated to enhance the processing of low-level image features and to strengthen the interplay between shallow and deep features. To verify the validity and generalization of the model, the experimental results show that the proposed ViT-EHA method achieved an accuracy of 99.00% and a parameter count of 4.198 million (M) on the self-constructed dataset Code-10 (QR Code Dataset with 10 Classes), and the accuracy reached 98.33% and 97.73% on the public datasets NEU-CLS (Northeastern University Classification Dataset) and NEU-CLS-64 (Northeastern University Classification Dataset with 64 × 64 images), respectively.},
  archive      = {J_EAAI},
  author       = {Dianlu Hu and Lun Zhao and Yu Ren and Sen Wang and Xuanlin Ye and Haohan Zhang and Changqing Peng},
  doi          = {10.1016/j.engappai.2025.110575},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110575},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight vision transformer with embedded hybrid attention for quick response code defect classification},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating pre-trained convolutional neural networks and
foundation models as feature extractors for content-based medical image
retrieval. <em>EAAI</em>, <em>150</em>, 110571. (<a
href="https://doi.org/10.1016/j.engappai.2025.110571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image retrieval refers to the task of finding similar images for given query images in a database, with applications such as diagnosis support. While traditional medical image retrieval relied on clinical metadata, content-based medical image retrieval (CBMIR) depends on image features, which can be extracted automatically or semi-automatically. Many approaches have been proposed for CBMIR, and among them, using pre-trained convolutional neural networks (CNNs) is a widely utilized approach. However, considering the recent advances in the development of foundation models for various computer vision tasks, their application for CBMIR can also be investigated. In this study, we used several pre-trained feature extractors from well-known pre-trained CNNs and pre-trained foundation models and investigated the CBMIR performance on eight types of two-dimensional (2D) and three-dimensional (3D) medical images. Furthermore, we investigated the effect of image size on the CBMIR performance. Our results show that, overall, for the 2D datasets, foundation models deliver superior performance by a large margin compared to CNNs, with the general-purpose self-supervised model for computational pathology (UNI) providing the best overall performance across all datasets and image sizes. For 3D datasets, CNNs and foundation models deliver more competitive performance, with contrastive learning from captions for histopathology model (CONCH) achieving the best overall performance. Moreover, our findings confirm that while using larger image sizes (especially for 2D datasets) yields slightly better performance, competitive CBMIR performance can still be achieved even with smaller image sizes. Our codes to reproduce the results are available at: https://github.com/masih4/MedImageRetrieval .},
  archive      = {J_EAAI},
  author       = {Amirreza Mahbod and Nematollah Saeidi and Sepideh Hatamikia and Ramona Woitek},
  doi          = {10.1016/j.engappai.2025.110571},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110571},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Evaluating pre-trained convolutional neural networks and foundation models as feature extractors for content-based medical image retrieval},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Thermal image-guided complementary masking with multiscale
fusion for multi-spectral image semantic segmentation. <em>EAAI</em>,
<em>150</em>, 110569. (<a
href="https://doi.org/10.1016/j.engappai.2025.110569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation of visible and thermal image is a kind of significant method for harsh environments. Most existing works focus on designing a multi-modal feature fusion module. However, these works may result in over-dependence on a specific modality and a lack of consideration for local and global context-aware information. Motivated by these issues, (1) a thermal image-guided complementary masking strategy is proposed to encourage the network to focus on regions with abundant semantic information; (2) a multi-modal fusion module is developed to integrate both local and global information and ensure consistency for semantic segmentation; (3) a self-distillation loss between unmasked and masked input modalities is introduced to enhance the robustness and consistency of the network. Particularly, the proposed masking strategy can force the network to concentrate on the meaningful area in all modalities, and thus the network can enhance the ability to connect context information. Experimental results on three public datasets demonstrate the superiority of our model.},
  archive      = {J_EAAI},
  author       = {Zeyang Chen and Mingnan Hu and Bo Chen},
  doi          = {10.1016/j.engappai.2025.110569},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110569},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Thermal image-guided complementary masking with multiscale fusion for multi-spectral image semantic segmentation},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An electric vehicle sales hybrid forecasting method based on
improved sentiment analysis model and secondary decomposition.
<em>EAAI</em>, <em>150</em>, 110561. (<a
href="https://doi.org/10.1016/j.engappai.2025.110561">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The swift proliferation of electric vehicles has triggered profound shifts in consumer behavior, emphasizing the critical role of precise sales forecasts as the cornerstone for data-driven policy and production planning by both governments and electric vehicle manufacturers. However, extant forecasting models face challenges in accurately capturing consumer sentiment conveyed by online reviews and effectively extracting multiscale features of high-frequency sequences. Therefore, an electric vehicle sales hybrid forecasting method based on BERT-Bi-LSTM (Bidirectional Encoder Representations from Transformers-Bidirectional long short-term memory) sentiment analysis and secondary decomposition is proposed. First, the BERT-Bi-LSTM model is developed to perform sentiment analysis on online reviews. The model can better capture the relationship between each word and its surrounding words in text information. Second, a secondary decomposition model is constructed to decompose multisource data series, it can extract the seasonal components of the series and high-frequency complex data features, also solve potential issues of incomplete decomposition that may arise from a single decomposition. Finally, machine learning methods are utilized for hybrid forecasting. To verify the effectiveness of the proposed model, multiple sets of comparative experiments are conducted. The empirical results indicate the proposed model has higher prediction accuracy and robustness.},
  archive      = {J_EAAI},
  author       = {Jinpei Liu and Hui Pan and Rui Luo and Huayou Chen and Zhifu Tao and Zhijing Wu},
  doi          = {10.1016/j.engappai.2025.110561},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110561},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An electric vehicle sales hybrid forecasting method based on improved sentiment analysis model and secondary decomposition},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Causal explanation of nitrogen oxide emission predictions
for fluid catalytic cracking unit based on convergent cross mapping:
Predict the future and explain how. <em>EAAI</em>, <em>150</em>, 110560.
(<a href="https://doi.org/10.1016/j.engappai.2025.110560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial chemical processes are inherently intricate, characterized by prolonged operational sequences and correlations among features. Solely utilizing temporal information limits the prediction precision of deep learning methods. Moreover, causative features identified based on data may not align with the principles of chemical process. To solve these problems, this study proposes a spatial–temporal information based deep learning method, attention-based temporal graph convolutional network and convergent cross mapping (ATGCN-CCM). The devices are abstracted as nodes in a computational graph (CG) to represent the process, enabling the incorporation of spatial information into the predictive model. Attention mechanism is conducted within each node to dynamically weight the features. The CG is also used to select input features for causal analysis, ensuring that the identified causative features are not only consistent with the characteristics of the data, but also with the prior knowledge of the process. ATGCN-CCM is applied to datasets from industrial fluid catalytic cracking (FCC) units for nitrogen oxides (NOx) concentration prediction and causative feature identification. The prediction results demonstrate superior precision of ATGCN-CCM compared to some state-of-the-art spatial feature based, temporal feature based and hybrid methods. The identified features exhibit strong alignment with the principles of the chemical processes and the field experiences, thereby significantly enhancing model interpretability. The proposed ATGCN-CCM method illustrate its advanced capabilities in both precision and robustness, compared with attention-based methods and other causal analysis methods.},
  archive      = {J_EAAI},
  author       = {Han Jiang and Shucai Zhang and Jingru Liu and Xin Peng and Weimin Zhong},
  doi          = {10.1016/j.engappai.2025.110560},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110560},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Causal explanation of nitrogen oxide emission predictions for fluid catalytic cracking unit based on convergent cross mapping: Predict the future and explain how},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Keypoint-guided feature enhancement and alignment for
cross-resolution vehicle re-identification. <em>EAAI</em>, <em>150</em>,
110557. (<a
href="https://doi.org/10.1016/j.engappai.2025.110557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resolution mismatch between low-resolution query images and high-resolution gallery images in vehicle re-identification is rarely studied but ubiquitous in real-world applications. An intuitive approach to solving cross-resolution vehicle re-identification is to utilize super-resolution algorithms to recover detailed information from low-resolution query images. However, vehicle super-resolution algorithms not only recover the detailed information of the vehicle but also enhance the background noise, which would degrade the re-identification performance. In addition, the view mismatch problem also significantly limits the performance of vehicle re-identification. To handle these problems, we propose a novel Keypoint Guiding Network, which simultaneously addresses the problems of resolution mismatch and view mismatch from the perspective of keypoints in an end-to-end learning framework, for cross-resolution vehicle re-identification. In particular, we first generate a set of vehicle keypoints via an effective Gaussian localization method, and then adaptively construct two keypoint-based guidances using attention models. We integrate these two guidances into vehicle super-resolution and view alignment to handle the problems of resolution mismatch and view mismatch respectively. Moreover, to alleviate the heterogeneity between super-resolution query images and high-resolution gallery ones, we design a dual-path teacher–student distillation scheme to narrow their feature distributions. Comprehensive experiments on two down-sampled benchmark datasets demonstrate the effectiveness of our Keypoint Guiding Network against the state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Aihua Zheng and Longfei Zhang and Weijun Zhang and Zi Wang and Chenglong Li and Xiaofei Sheng},
  doi          = {10.1016/j.engappai.2025.110557},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110557},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Keypoint-guided feature enhancement and alignment for cross-resolution vehicle re-identification},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Runner system geometry prediction using variational
autoencoder deep learning model. <em>EAAI</em>, <em>150</em>, 110555.
(<a href="https://doi.org/10.1016/j.engappai.2025.110555">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The novelty of this article is the choice of the architecture of neural networks for fluid channel topology optimization and its application in the design of multi-cavity injection molds. A generative deep learning model was developed to extract characteristics representing the inverse field of the permeability of a fluid in a porous medium, which in turn represents the runner system geometry of a thermoplastic injection mold. The model comprises a variational autoencoder network and multilayer perceptron. The characteristics extracted from the variational autoencoder are used as a set of multilayer perceptron output vectors, whereas the input data are determined by the positions of the input and outputs of the injection channels. The field of the inverse permeability in each case was obtained by topology optimization using a heuristic algorithm. The trained model displayed statistical metrics indicating good performance and task generalizability. The mean absolute error was 0.0106 for the entire dataset. Speed up compared to traditional computational fluid dynamics software was 625 times faster in one case. For 150 cases, it was 76907 times faster⁠. The purpose of generating a deep learning model in this area is to reduce the design time of injection molds and the computational requirements. The developed neural network reduces the runner system volume by 16% or its hydraulic resistance by 25%.},
  archive      = {J_EAAI},
  author       = {Evgenii Kurkin and Jose Gabriel Quijada Pioquinto and Vladislava Chertykovtseva and Evgenii Minaev},
  doi          = {10.1016/j.engappai.2025.110555},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110555},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Runner system geometry prediction using variational autoencoder deep learning model},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature selection considering synergy between features based
on soft neighborhood rough sets. <em>EAAI</em>, <em>150</em>, 110553.
(<a href="https://doi.org/10.1016/j.engappai.2025.110553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neighborhood entropy-based measures provide a powerful framework for feature selection to select features that are more useful for classification. However, most of these feature selection methods do not pay attention to the complementarities and synergies between features, as well as the interactions between them. In addition, most existing neighborhood rough sets are subjective in the determination of neighborhood radius when dealing with classification problems, which may lead to the omission of useful information. To solve these problems, a soft neighborhood rough set model-based feature selection method (SNCMI) is proposed. Firstly, the method dynamically adjusts the neighborhood radius, significantly minimizing its influence on the uncertainty measurement. Secondly, it comprehensively considers the correlation, redundancy, complementarity, and synergy between features through soft neighborhood uncertainty measures. Thirdly, an innovative objective evaluation function is introduced to evaluate the interactions between features. Finally, we compare the proposed SNCMI algorithm with several well-known feature selection algorithms on twenty public datasets and demonstrate the effectiveness of SNCMI.},
  archive      = {J_EAAI},
  author       = {Lubin Chen and Jinkun Chen and Yaojin Lin},
  doi          = {10.1016/j.engappai.2025.110553},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110553},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature selection considering synergy between features based on soft neighborhood rough sets},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forecasting train travel times of china–europe railway
express through a hybrid deep learning model optimized with a
bandit-based approach. <em>EAAI</em>, <em>150</em>, 110552. (<a
href="https://doi.org/10.1016/j.engappai.2025.110552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the globalization of economic trade, the China–Europe Railway Express (CRE) has emerged as a crucial means of international freight transportation. However, since the travel process of CRE trains is subject to various factors (e.g., customs clearance efficiency, weather changes, etc.), existing models struggle to handle the complex nonlinear characteristics of the travel time data, failing to achieve accurate train travel time predictions. This significantly affects the scheduling and utilization of capacity resources along the CRE routes. To address this issue, this study proposes a novel hybrid deep learning model, i.e., Discrete Wavelet Transform (DWT)-Convolutional Neural Networks (CNN)-Bidirectional Gated Recurrent Unit (BiGRU) (DWT-CNN-BiGRU). Specifically, the DWT technique is first used to preprocess historical train travel time data to reduce noise interference and improve data quality. Then, the CNN module focuses on extracting local spatial features from the data, whereas the BiGRU module emphasizes its long-term temporal dependencies. Furthermore, a bandit-based approach is applied to hyperparameter optimization to further exploit model potentials. By testing on a real-life CRE dataset, the DWT-CNN-BiGRU model demonstrates superior prediction accuracy with root mean square error (RMSE), mean absolute error (MAE), and mean absolute percentage error (MAPE) values respectively equal to 10.7347 h, 7.5482 h, and 2.2034%, and it outperforms the other ten popular baseline models. In conclusion, the proposed DWT-CNN-BiGRU model features a lightweight structure and strong robustness, offering reliable technical support to alleviate capacity resource shortages and improve the service quality of CRE.},
  archive      = {J_EAAI},
  author       = {Yongxiang Zhang and Liting Gu and Jingwei Guo and Xu Yan and Xin Hu and Zhen-Song Chen},
  doi          = {10.1016/j.engappai.2025.110552},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110552},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Forecasting train travel times of China–Europe railway express through a hybrid deep learning model optimized with a bandit-based approach},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid architecture of sparse convolutional neural
network-transformer for enhanced spatial-geometric feature learning in
surface reconstruction. <em>EAAI</em>, <em>150</em>, 110550. (<a
href="https://doi.org/10.1016/j.engappai.2025.110550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning-based methods have garnered significant attention in indoor scene reconstruction tasks. However, researchers have often overlooked the crucial role of the surface prediction stage. Our study specifically focuses on this phase. According to our experiments and analysis, this phase primarily addresses spatial voxel occupancy and geometric structure maintenance. Simple structural designs are insufficient to effectively solve these problems. To address these challenges, we propose a hybrid model, which combines the strengths of Convolution Neural Networks and Transformer architectures for fine reconstruction. Additionally, we introduce several new techniques, including the Sparse Positional Attention mechanism, Sparse Channel Decoding Block, and Mixed Feature Fusion mechanism. These techniques, leveraging the characteristics of sparse computation, enhance feature utilization in both spatial and channel dimensions. With limited training and testing resources, our network achieves optimal results on the ScanNet dataset, improving precision and F-score by 2.1% and 1.6%, respectively, and reducing the Chamfer distance to 0.055 m. To our knowledge, our model is the first use of hybrid structures in the surface prediction phase of an indoor scene reconstruction task. Moreover, we hope that our design and analysis can provide a new paradigm for task network design in this phase.},
  archive      = {J_EAAI},
  author       = {Mingyang Li and Wei Zhang and Yanyan Liu and Xiang Feng and Changsong Liu and Yimeng Fan and Lixue Xu},
  doi          = {10.1016/j.engappai.2025.110550},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110550},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid architecture of sparse convolutional neural network-transformer for enhanced spatial-geometric feature learning in surface reconstruction},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing pose estimation for mobile robots: A comparative
analysis of deep reinforcement learning algorithms for adaptive extended
kalman filter-based estimation. <em>EAAI</em>, <em>150</em>, 110548. (<a
href="https://doi.org/10.1016/j.engappai.2025.110548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Extended Kalman Filter (EKF) is a widely used algorithm for state estimation in control systems. However, its lack of adaptability limits its performance in dynamic and uncertain environments. To address this limitation, we used an approach that leverages Deep Reinforcement Learning (DRL) to achieve adaptive state estimation in the EKF. By integrating DRL techniques, we enable the state estimator to autonomously learn and update the values of the system dynamics and measurement noise covariance matrices, Q and R, based on observed data, which encode environmental changes or system failures. In this research, we compare the performance of four DRL algorithms, namely Deep Deterministic Policy Gradient (DDPG), Twin Delayed Deep Deterministic Policy Gradient (TD3), Soft Actor-Critic (SAC), and Proximal Policy Optimization (PPO), in optimizing the EKF’s adaptability. The experiments are conducted in both simulated and real-world settings using the Gazebo simulation environment and the Robot Operating System (ROS). The results demonstrate that the DRL-based adaptive state estimator outperforms traditional methods in terms of estimation accuracy and robustness. The comparative analysis provides insights into the strengths and limitations of different DRL agents, showing that the TD3 and the DDPG are the most effective algorithms, with TD3 achieving superior performance, resulting in a 91% improvement over the classic EKF, due to its delayed update mechanism that reduces training noise. This research highlights the potential of DRL to advance state estimation algorithms, offering valuable insights for future work in adaptive estimation techniques.},
  archive      = {J_EAAI},
  author       = {Islem Kobbi and Abdelhak Benamirouche and Mohamed Tadjine},
  doi          = {10.1016/j.engappai.2025.110548},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110548},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing pose estimation for mobile robots: A comparative analysis of deep reinforcement learning algorithms for adaptive extended kalman filter-based estimation},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph neural networks with scattering transform for network
anomaly detection. <em>EAAI</em>, <em>150</em>, 110546. (<a
href="https://doi.org/10.1016/j.engappai.2025.110546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As cyber-attacks become increasingly sophisticated and frequent, the demand for advanced and proactive Network Intrusion Detection Systems (NIDS) has become more urgent than ever. To address critical shortcomings in existing NIDS approaches, such as high false-positive rates that trigger unnecessary alerts, inability to capture complex relationships between network nodes, and oversimplified node representation initialization that fails to reflect real-world network behaviors, we introduce a novel solution called Scattering Transform Edge Graph (STEG). STEG harnesses the wavelet scattering transform to extract edge feature information and employs a graph-based representation to effectively capture the topological relationships between network nodes. Additionally, we enhance STEG by incorporating node embedding techniques like DeepWalk for initializing node representations, moving beyond conventional uniform initialization methods. Comprehensive evaluations on benchmark NIDS datasets reveal that STEG outperforms current state-of-the-art methods. Moreover, the integration of Node2Vec-based initialization further boosts performance, marking a significant advancement in the effectiveness of network intrusion detection systems.},
  archive      = {J_EAAI},
  author       = {Abdeljalil Zoubir and Badr Missaoui},
  doi          = {10.1016/j.engappai.2025.110546},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110546},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Graph neural networks with scattering transform for network anomaly detection},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparative analysis and evaluation of ageing forecasting
methods for semiconductor devices in online health monitoring.
<em>EAAI</em>, <em>150</em>, 110545. (<a
href="https://doi.org/10.1016/j.engappai.2025.110545">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semiconductor devices, especially MOSFETs (Metal–oxide–semiconductor field-effect transistor), are crucial in power electronics, but their reliability is affected by ageing processes influenced by cycling and temperature. The primary ageing mechanism in discrete semiconductors and power modules is the bond wire lift-off, caused by crack growth due to thermal fatigue. The process is empirically characterized by exponential growth and an abrupt end of life, making long-term ageing forecasts challenging. This research presents a comprehensive comparative assessment of different forecasting methods for MOSFET failure forecasting applications. Classical tracking, statistical forecasting and Neural Network (NN) based forecasting models are implemented along with novel Temporal Fusion Transformers (TFTs). A comprehensive comparison is performed assessing their MOSFET ageing forecasting ability for different forecasting horizons. For short-term predictions, all algorithms result in acceptable results, with the best results produced by classical NN forecasting models at the expense of higher computations. For long-term forecasting, only the TFT is able to produce valid outcomes owing to the ability to integrate covariates from the expected future conditions. Additionally, TFT attention points identify key ageing turning points, which indicate new failure modes or accelerated ageing phases.},
  archive      = {J_EAAI},
  author       = {Adrian Villalobos and Iban Barrutia and Rafael Peña-Alzola and Tomislav Dragicevic and Jose I. Aizpurua},
  doi          = {10.1016/j.engappai.2025.110545},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110545},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Comparative analysis and evaluation of ageing forecasting methods for semiconductor devices in online health monitoring},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of the flexural strength and elastic modulus of
cementitious materials reinforced with carbon nanotubes: An approach
with artificial intelligence. <em>EAAI</em>, <em>150</em>, 110544. (<a
href="https://doi.org/10.1016/j.engappai.2025.110544">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, researchers investigated incorporating carbon nanotubes (CNTs) to improve the mechanical properties of cementitious materials. Recently, few studies developed Machine Learning (ML)-based predictive models to maximize insights from limited experimental data. However, these models often fail to identify key parameters and their complex correlations with mechanical properties. This study aims to improve the prediction of the mechanical properties of CNT-reinforced cementitious materials, specifically, elastic modulus and flexural strength, by leveraging multiple predictive Artificial Intelligence (AI)-based models. Deep Neural Networks (DNN), ensemble-bagging, and Support Vector Regression (SVR) were proposed and rigorously tested to predict the flexural strength and elastic modulus of the composite material. The feature selection was performed based on the domain knowledge and the informative metrics including the permutation importance analyses and Pearson&#39;s correlation analyses. The research identified several parameters that have traditionally been overlooked but proved to be critical. With a total of nineteen input parameters analyzed, the findings indicate that the mechanical properties of the composite material are primarily influenced by surfactant-to-CNT mass ratio, CNT content and physical properties, as well as ultrasonication process. Conversely, sand type and CNT purity are found to have minimal importance to the change in mechanical properties. In addition, the proposed DNN models outperform other ML models in predicting both flexural strength and elastic modulus, achieving R-squared values of 0.93 and 0.86 with mean absolute percentage errors of 8.16% and 7.22%, respectively.},
  archive      = {J_EAAI},
  author       = {Mahyar Ramezani and Do-Eun Choe and Abdur Rasheed},
  doi          = {10.1016/j.engappai.2025.110544},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110544},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Prediction of the flexural strength and elastic modulus of cementitious materials reinforced with carbon nanotubes: An approach with artificial intelligence},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reparameterization convolutional neural networks for
handling imbalanced datasets in solar panel fault classification.
<em>EAAI</em>, <em>150</em>, 110541. (<a
href="https://doi.org/10.1016/j.engappai.2025.110541">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solar photovoltaic technology has grown significantly as a renewable energy, with unmanned aerial vehicles equipped with thermal infrared cameras effectively inspecting solar panels. However, long-distance capture and low-resolution infrared cameras make the targets small, complicating feature extraction. Additionally, the large number of normal photovoltaic modules results in a significant imbalance in the dataset. Furthermore, limited computing resources on unmanned aerial vehicles further challenge real-time fault classification. These factors limit the performance of current fault classification systems for solar panels. The multi-scale and multi-branch Reparameterization of convolutional neural networks can improve model performance while reducing computational demands at the deployment stage, making them suitable for practical applications. This study proposes an efficient framework based on reparameterization for infrared solar panel fault classification. We propose a Proportional Balanced Weight asymmetric loss function to address the class imbalance and employ multi-branch, multi-scale convolutional kernels for extracting tiny features from low-resolution images. The designed models were trained with Exponential Moving Average for better performance and reparameterized for efficient deployment. We evaluated the designed models using the Infrared Solar Module dataset. The proposed framework achieved an accuracy of 83.8% for the 12-Class classification task and 74.0% for the 11-Class task, both without data augmentation to enhance generalization. The accuracy improvements of up to 16.4% and F1-Score gains of up to 18.7%. Additionally, we achieved an inference speed that is 3.4 times faster than the training speed, while maintaining high fault classification performance.},
  archive      = {J_EAAI},
  author       = {Jielong Guo and Chak Fong Chong and Pedro Henriques Abreu and Chao Mao and Jiaxuan Li and Chan-Tong Lam and Benjamin K. Ng},
  doi          = {10.1016/j.engappai.2025.110541},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110541},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reparameterization convolutional neural networks for handling imbalanced datasets in solar panel fault classification},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Blockchain data with ransomware detection based on deep feed
forward maxout network. <em>EAAI</em>, <em>150</em>, 110538. (<a
href="https://doi.org/10.1016/j.engappai.2025.110538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread use of the internet and technology has become more common and essential in daily life. The main risk to the network is malware, and ransomware is considered a destructive kind of malware. The ransomware resulted in massive data losses and produced huge financial losses. In order to overcome this issue, the Deep Feed Forward Maxout Network (DFFMN) is developed to detect ransomware using blockchain data in this study. To accomplish this, initially, the input data from the blockchain is given to feature extraction to extract features. Then, data normalization is performed and the extracted features are fused together using a Deep Belief Network (DBN) with Lorentzian similarity. Lastly, ransomware detection is executed by utilizing the DFFMN technique, which is created by the integration of Deep Maxout Network and Deep Feedforward Neural Network. The experimental results exemplify that the proposed DFFMN acquired accuracy value of 91.57 %, sensitivity value of 91.04 %, precision value of 89.35 %, False Negative Rate (FNR) of 0.086, False Positive Rate (FPR) of 0.090 and F-Measure of 89.44 %.},
  archive      = {J_EAAI},
  author       = {Vemireddi Srinadh and Buddi Padmaja and Dhanunjaya Rao Chigurukota and Mallikharjuna Rao Karreddula and Balajee Maram and Smritilekha Das},
  doi          = {10.1016/j.engappai.2025.110538},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110538},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Blockchain data with ransomware detection based on deep feed forward maxout network},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025a). Dual-branch crack segmentation network with multi-shape
kernel based on convolutional neural network and mamba. <em>EAAI</em>,
<em>150</em>, 110536. (<a
href="https://doi.org/10.1016/j.engappai.2025.110536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cracks are one of the most common pavement diseases. If not promptly repaired, they will hasten the deterioration of the road. Semantic segmentation is the most convenient pavement crack detection method to assess the damage level. Convolutional neural networks (CNN) excel at extracting local spatial information, but they have limitations in capturing global contextual information. Therefore, a dual-branch crack segmentation network (DBCNet) with Mamba and multi-shape convolutional kernels is proposed. First, a dual-branch encoder is employed to extract both spatial and contextual information, consisting of the spatial branch and the context branch. The cross-like block (CrossBlock) that excels in extracting spatial information horizontally and vertically from cracks is proposed. Multiple CrossBlocks are stacked to construct a lightweight network as a spatial branch. The improved Visual State Space Model (VMamba) serves as a context branch for modeling long-range dependencies for more accurate pixel-by-pixel segmentation. Second, the Feature Fusion Module (FFM), based on squeeze-and-excitation attention, is constructed to dynamically fuse the features from the two branches layer by layer. Third, a Cross-aware Mamba Module (CMM) with the hybrid CNN-Mamba architecture is proposed to compose the decoder. Fourth, comprehensive evaluations were conducted on three public datasets. Performs on multiple metrics achieved considerable progress, outperforming the seven state-of-the-art models. The mean intersection over union (mIoU) on Deepcrack, CrackTree 260, and CFD reached 87.87%, 85.34%, and 81.35%, respectively. Code and data will be available at https://github.com/name191/DBCNet .},
  archive      = {J_EAAI},
  author       = {Jianming Zhang and Dianwen Li and Zhigao Zeng and Rui Zhang and Jin Wang},
  doi          = {10.1016/j.engappai.2025.110536},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110536},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dual-branch crack segmentation network with multi-shape kernel based on convolutional neural network and mamba},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FA-SconvAE-LSTM: Feature-aligned stacked convolutional
autoencoder with long short-term memory network for soft sensor
modeling. <em>EAAI</em>, <em>150</em>, 110535. (<a
href="https://doi.org/10.1016/j.engappai.2025.110535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement of soft sensor technology has enabled the real-time estimation of critical parameters in complex industrial processes, where direct measurement through hardware sensors is often infeasible. Industrial process data typically exhibit both spatial correlations and temporal dependencies, necessitating sophisticated modeling approaches to capture these characteristics effectively. In this study, a spatio-temporal model, termed the feature-aligned stacked convolutional autoencoder with long short-term memory, is proposed to develop soft sensors for nonlinear dynamic industrial processes. The proposed model begins with the systematic training of a stacked convolutional autoencoder using a layer-by-layer pre-training technique. This approach facilitates the extraction of high-level spatial feature representations from the process variables. To address the issue of feature misalignment in the spatial features extracted by the stacked convolutional autoencoder, a feature alignment strategy is implemented, ensuring that the extracted spatial features are properly aligned. Subsequently, the aligned spatial features are fed into a long short-term memory network to capture temporal dependencies, with quality variables serving as the output for soft sensor development. The effectiveness and superiority of the proposed method are demonstrated through experiments conducted on two industrial processes: the sulfur recovery unit and the multiphase flow process. Comparative analyses with other state-of-the-art methods reveal that the proposed model achieves the highest performance, with R 2 values of 0.86222 for the sulfur recovery unit and 0.94307 for the multiphase flow process, outperforming all compared methods.},
  archive      = {J_EAAI},
  author       = {Ping Wu and Zengdi Miao and Ke Wang and Jinfeng Gao and Xujie Zhang and Siwei Lou and Chunjie Yang},
  doi          = {10.1016/j.engappai.2025.110535},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110535},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {FA-SconvAE-LSTM: Feature-aligned stacked convolutional autoencoder with long short-term memory network for soft sensor modeling},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Surrogate-assisted motion planning and layout design of
robotic cellular manufacturing systems. <em>EAAI</em>, <em>150</em>,
110530. (<a
href="https://doi.org/10.1016/j.engappai.2025.110530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A surrogate-assisted multi-objective evolutionary algorithm is proposed for simultaneous optimization of robot motion planning and layout design in robotic cellular manufacturing systems. A sequence-pair is used to represent the layout of components in a robotic cell to avoid overlapping in the evolutionary computation. The robot motion planning with Rapidly exploring Random Trees Star (RRT*) is applied to compute the total operation time of a robot arm for each layout. Non-dominated Sorting Genetic Algorithm II (NSGA-II) is used to minimize the total required layout area and the operation time for a robot arm. The proposed surrogate model can estimate the robot’s operation time with 98% of accuracy without explicit computations of the motion planning algorithm. The experimental results with a physical 6 Degree of Freedom (DOF) manipulator show that the total computation time is approximately 1/400, significantly shorter than the conventional methods.},
  archive      = {J_EAAI},
  author       = {Tomoya Kawabe and Tatsushi Nishi and Ziang Liu and Tomofumi Fujiwara},
  doi          = {10.1016/j.engappai.2025.110530},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110530},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Surrogate-assisted motion planning and layout design of robotic cellular manufacturing systems},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-labeled framework with semi-supervised ball k-means
clustering-based synthetic example generation for semi-supervised
classification in industrial applications. <em>EAAI</em>, <em>150</em>,
110528. (<a
href="https://doi.org/10.1016/j.engappai.2025.110528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While self-labeled methods can exploit labeled and unlabeled instances to train classifiers, they are severely restricted by the labeled instance number and distribution. One category of the existing solutions tends to combine oversampling techniques, with the goal of creating labeled synthetic instances to improve the labeled instance number and distribution. The synthetic example generation-based framework for semi-supervised classification (SEG-SSC) is the only state-of-the-art instance of the above category. Nevertheless, it still suffers from the following issues: a) relying on 7 hyper-parameters, b) ineffectively improving the labeled instance number and distribution in sparser regions with fewer labeled instances, and c) having a relatively high time complexity of O ( nlogn + G×n ). To this end, a self-labeled framework with semi-supervised ball k -means clustering-based synthetic example generation (SEGBallKmeans-SSC), having only one hyper-parameter and the time complexity of O ( n ), is proposed for semi-supervised classification. The main uniqueness is that: a) firstly, a semi-supervised ball k -means clustering (SSBallKmeans) with a compact-cluster assumption is proposed to divide semi-supervised data into compact ball clusters, intending to reveal regions with different labeled instance numbers; b) secondly, an SSBallKmeans-based oversampling method (OMSSBallKmean) is proposed to create more labeled synthetic instances on compact ball clusters with fewer labeled instances, intending to improve the labeled instance number and distribution, especially on sparser regions with fewer labeled instances. After that, any self-labeled method are executed on improved labeled instances and unlabeled instances to train more accurate classifiers. Experiments have proven that SEGBallKmeans-SSC outperforms 7 state-of-the-art self-labeled frameworks on extensive benchmark datasets from various industrial applications.},
  archive      = {J_EAAI},
  author       = {Junnan Li and Lufeng Wang and Shun Fu ( Revision ) and Wei Fu and Xin Pan},
  doi          = {10.1016/j.engappai.2025.110528},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110528},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-labeled framework with semi-supervised ball K-means clustering-based synthetic example generation for semi-supervised classification in industrial applications},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep learning-based sentiment flow analysis model for
predicting financial risk of listed companies. <em>EAAI</em>,
<em>150</em>, 110522. (<a
href="https://doi.org/10.1016/j.engappai.2025.110522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of natural language processing technology, more studies are applying deep learning models to extract features from unstructured data and predict corporate financial risk through horizontal comparisons. This paper proposes the Sentiment Flow Analysis (SFA) model designed to capture the nuanced emotional dynamics present in corporate annual reports and analyst reports from a longitudinal perspective. By leveraging advanced contextual embeddings from a Transformer architecture and employing a sophisticated recurrent neural network, the model effectively processes sequential data, allowing for a comprehensive understanding of sentiment trends over a five-year period. The effectiveness of our model was validated through experiments predicting the removal of special treatment (ST) status for 344 listed companies under special treatment in 2022 and 2023, achieving a prediction accuracy of up to 82.27%. Compared to state-of-the-art models in the same field, our model demonstrates improvements in prediction accuracy and recall, showcasing the application of Artificial Intelligence (AI) in financial risk assessment.},
  archive      = {J_EAAI},
  author       = {Feifei Tao and Wenya Wang and Rongke Lu},
  doi          = {10.1016/j.engappai.2025.110522},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110522},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep learning-based sentiment flow analysis model for predicting financial risk of listed companies},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient self-learning disturbance-resistant control for
high-speed flight vehicle based on dual heuristic dynamic programming.
<em>EAAI</em>, <em>150</em>, 110521. (<a
href="https://doi.org/10.1016/j.engappai.2025.110521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in high-speed flight vehicles (HSFVs) have sparked significant interest due to their strategic importance and emerging civilian applications. These vehicles exhibit strong nonlinearities and multi-axis interactions and are usually influenced by uncertainties such as modeling errors, parameter perturbations, and external disturbances. Neglecting these challenges in attitude controller design can lead to trajectory tracking deviations and potential mission failure due to instability. Motivated by this issue, an efficient disturbance-resistant control method with online self-learning capability is proposed. Firstly, a feedback linearization baseline controller combined with finite-time extended state observers (FESOs) is designed to ensure stability. Next, a dual heuristic dynamic programming (DHP) controller with critic-only structure is developed for online performance optimization. Update laws of the critic neural network (NN) are derived based on policy iteration, and zero-sum game (ZSG) theory is incorporated to enhance the system’s adaptive capacity to uncertainties. Lyapunov theory is subsequently employed to validate the convergence of network weights and the system stability. The proposed method, compared to common adaptive dynamic programming (ADP) approaches for attitude control, demonstrates superior learning efficiency and guarantees the convergence of online learning without the necessity for pre-training. Simulation results indicate that the method equips the HSFV with robust dynamic performance throughout a broad flight envelope, with attitude tracking errors constrained to less than 0.5°. Future research will focus on developing fault-tolerant and prescribed performance control frameworks with online learning ability, representing an advancement in the current technique.},
  archive      = {J_EAAI},
  author       = {Xu Huang and Jiarun Liu and Yue Peng and Yuan Zhang and Zhaolei Wang and Weimin Bao},
  doi          = {10.1016/j.engappai.2025.110521},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110521},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Efficient self-learning disturbance-resistant control for high-speed flight vehicle based on dual heuristic dynamic programming},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Remote sensing scene classification with relation-aware
dynamic graph neural networks. <em>EAAI</em>, <em>150</em>, 110513. (<a
href="https://doi.org/10.1016/j.engappai.2025.110513">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote sensing scene classification (RSSC) is challenging due to the complexity and diversity of scenes. Existing methods need help to capture long-range and structural relationships among image regions, limiting their performance. This paper proposes a novel graph-based model that learns relation-aware dynamic graph representations for remote sensing scene classification tasks. The proposed model consists of three main components: Multi-Scale Feature Extraction (MSFE), Relation-Aware Graph Processing (RAGP), and Scene Classification with Weighted Pooling (SCWP). MSFE uses a multi-scale feature extraction strategy to generate low-level feature nodes from remote sensing images. RAGP applies several cascaded graph processing blocks to dynamically learn the relations between nodes in high-level semantic spaces using relation-aware graph convolutional and node feature update operators. SCWP performs weighted pooling on the learned node features from RAGP to obtain global representations of remote sensing images and makes scene decisions using a fully feed-forward network-based classifier. We evaluate our model on three benchmark datasets and compare it with state-of-the-art RSSC methods. Our experimental results show that our model outperforms existing methods on all three datasets, demonstrating the effectiveness of a graph-based model with the proposed techniques for RSSC tasks.},
  archive      = {J_EAAI},
  author       = {Qionghao Huang and Fan Jiang and Changqin Huang},
  doi          = {10.1016/j.engappai.2025.110513},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110513},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Remote sensing scene classification with relation-aware dynamic graph neural networks},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning adaptive distractor-aware-suppression appearance
model for visual tracking. <em>EAAI</em>, <em>150</em>, 110511. (<a
href="https://doi.org/10.1016/j.engappai.2025.110511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some algorithms based on Siamese networks aim to improve the representation of target by combining background and target information, but they seldom consider adjusting the influence of background distractors on appearance modeling. In this paper, we propose an adaptive distractor suppression appearance model for robust visual tracking. Firstly, to fully utilize the valuable clues provided by the background, a new distractor model is specially designed to determine the weight of each distractor based on the similarity between the distractor and the target. This model adaptively fuses the distractors according to their weights, thereby focusing on distractors that are highly similar to the target. Secondly, a distractor model transformation strategy is constructed to rank the influence of the distractor model on appearance modeling, which mines the similarity relationship between the background distractor and target using regularized linear regression, effectively controlling the influence of the distractor model. Finally, we unify them into a learning adaptive distractor-aware-suppression appearance model for improving the discriminant ability of the appearance model, which selectively introduces the distractor model to suppress distractors according to the intensity of the distractor, achieving robust tracking in the presence of background interference. Experimental results on six benchmarks demonstrate that the proposed tracker achieves excellent performance in various challenging tracking tasks, particularly when facing background interference, where the tracking precision and success rate of our algorithm reach state-of-the-art levels.},
  archive      = {J_EAAI},
  author       = {Huanlong Zhang and Linwei Zhu and Yanchun Zhao and Fusheng Li and Deshuang Huang},
  doi          = {10.1016/j.engappai.2025.110511},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110511},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning adaptive distractor-aware-suppression appearance model for visual tracking},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multiagent architecture for industrial internet of things
safety applications. <em>EAAI</em>, <em>150</em>, 110495. (<a
href="https://doi.org/10.1016/j.engappai.2025.110495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial Internet of Things (IIoT) is a key technological pillar of the Fourth Industrial Revolution, also known as Industry 4.0. In this context, an area of considerable interest is human safety technology. Solutions rely on multiple sensors connected to a central monitoring system and supported with software to autonomously or semi-autonomously identify safety hazards. To this end, Computer vision systems are leveraged. However, streaming continuous video from numerous sensors can strain network resources, risking timely hazard response in large industrial setups. This work proposes a reference IIoT architecture based on Multi-Agent Systems to manage safety risks. It allows for scalable sensor integration and dynamically assesses sensor input based on risk levels. To prevent network overload, the architecture uses sensor-level intelligence at the edge layer to assess situational risks and decide whether to forward video signals to a centralized local cloud agent. The central cloud agent, using strategies like ensemble learning, selectively requests additional data from distributed edge agents based on the diagnosed risk. This approach was tested in monitoring safety during aircraft assembly, showing that edge processing reduces network load by limiting unnecessary data transmission without compromising accuracy. This architecture effectively distributes processing to the edge, maintaining detection accuracy while minimizing network traffic compared to continuous centralized video transmission.},
  archive      = {J_EAAI},
  author       = {Gibson Barbosa and Djamel F.H. Sadok and Judith Kelner and Luis Ribeiro},
  doi          = {10.1016/j.engappai.2025.110495},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110495},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multiagent architecture for industrial internet of things safety applications},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A systematic review of end-to-end framework for contactless
fingerprint recognition: Techniques, challenges, and future directions.
<em>EAAI</em>, <em>150</em>, 110493. (<a
href="https://doi.org/10.1016/j.engappai.2025.110493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contactless fingerprint biometrics have seen rapid advancements in the recent years due to its intrinsic advantages such as resilience against latent fingerprints, and enhanced hygiene due to the absence of physical contact between a finger and the sensor. These advantages boosted the development of novel techniques for contactless fingerprint recognition. An exponentially increasing number of publications related to these developments are becoming part of the literature. However, no systematic review that consolidates these developments has been presented to date, thereby leaving a significant void. Hence, there is a need to fill this void by presenting a comprehensive review of contactless fingerprint biometric technology. A review of this kind will be highly beneficial for individuals keen on pursuing research in this domain. This study presents a systematic review of the methods used in an end-to-end framework for contactless fingerprint recognition, including acquisition, segmentation, enhancement, feature extraction, and matching, using both traditional and deep learning techniques. As per the review protocol and inclusion-exclusion criteria, 112 papers have been finally included in this review. The primary focus of the review is to present the underlying methods, their reported performance outcomes, and their strengths and weaknesses. The review evaluates the recent research findings, highlights the research issues that have been effectively addressed, presents the biases in the studies, identifies ongoing challenges that remain in the field, and provides the future research directions.},
  archive      = {J_EAAI},
  author       = {Pooja Kaplesh and Aastha Gupta and Divya Bansal and Sanjeev Sofat and Ajay Mittal},
  doi          = {10.1016/j.engappai.2025.110493},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110493},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A systematic review of end-to-end framework for contactless fingerprint recognition: Techniques, challenges, and future directions},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Thoughtful and cautious reasoning: A fine-tuned knowledge
graph-based multi-hop question answering framework. <em>EAAI</em>,
<em>150</em>, 110479. (<a
href="https://doi.org/10.1016/j.engappai.2025.110479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of Knowledge Graph Question Answering (KGQA) is to find the answer entity by utilizing the Knowledge Graph (KG). Despite remarkable successes in recent years, the existing multi-hop KGQA research still faces numerous challenges. First, a multi-hop question often contains multiple entities and their relationships, and the semantic information is complex. The current methods extract the semantics of the question through an encoder that cannot completely extract the complex and rich semantic information in the multi-hop questions. Second, current question answering models use the coarse information filtering mechanism in the process of reasoning, which lead to the loss of effective information and introduce additional noise. To address these issues, we propose a Thoughtful and Cautious Reasoning framework for Knowledge Graph Question Answering (TCR-KGQA). We design a new question encoder that can extract and fully fuse the local semantic information of the question at different levels, focusing on the unique local features of the multi-hop question text. Based on the advantages of Gated Recurrent Unit (GRU) for information filtering, we propose a loop instruction update framework based on residual-GRU to effectively capture key information in the reasoning process. Extensive experiments on three broad benchmark datasets demonstrate the effectiveness of our model on KGQA tasks, and it also yields excellent results in the case of incomplete knowledge graphs with missing question–answer pairs.},
  archive      = {J_EAAI},
  author       = {Yinghao Zheng and Ling Lu and Yang Hu and Yinong Chen and Aijuan Wang},
  doi          = {10.1016/j.engappai.2025.110479},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110479},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Thoughtful and cautious reasoning: A fine-tuned knowledge graph-based multi-hop question answering framework},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A surrogate-assist quasi-affine transformation evolutionary
for multi-objective optimization of empty train deployment on heavy-haul
railways. <em>EAAI</em>, <em>150</em>, 110475. (<a
href="https://doi.org/10.1016/j.engappai.2025.110475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surrogate-assisted evolutionary algorithms have become increasingly popular for solving expensive and time-consuming single-objective and multi-objective problems. However, in multi-objective optimization, the Pareto non-dominated solution set space can quickly become computationally intractable, making it challenging to select which samples to evaluate using the expensive fitness function. In this paper, we propose a Surrogate-Assist Quasi-Affine Transformation Evolutionary algorithm (SA-QUATRE/MO) for solving multi-objective optimization problems. The SA-QUATRE/MO algorithm uses a radial basis function network as a surrogate model to improve the speed of the algorithm operation by replacing the expensive fitness evaluation with the surrogate model. To ensure the excellence and diversity of the selected samples while keeping the archived sample space fixed, we propose a technique called Vector Space Sampling, which samples objective points in the current set of non-dominated solutions by dividing several sub-vector spaces. Additionally, we propose an uncertain sample infilling strategy to select samples for real fitness evaluation using a designed uncertainty function. We compare the SA-QUATRE/MO algorithm with three state-of-the-art algorithms for multi-objective problems in three test function suites. Finally, we applied the SA-QUATRE/MO algorithm to optimize empty train deployment in a heavy-haul railway at the loading end and build a model based on the S12 section of a specific railway. The final experimental results demonstrate the practicality and effectiveness of our proposed method.},
  archive      = {J_EAAI},
  author       = {Zhi-Gang Du and Jeng-Shyang Pan and He-Ying Xu and Shu-Chuan Chu and Shao-Quan Ni},
  doi          = {10.1016/j.engappai.2025.110475},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110475},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A surrogate-assist quasi-affine transformation evolutionary for multi-objective optimization of empty train deployment on heavy-haul railways},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Navigating beyond the training set: A deep learning
framework for inverse design of architected composite materials.
<em>EAAI</em>, <em>150</em>, 110473. (<a
href="https://doi.org/10.1016/j.engappai.2025.110473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a deep learning (DL)-based inverse design framework for two-phase composite materials. The artificial intelligence (AI) contribution lies in the integration of Deep Convolutional Generative Adversarial Networks (DCGAN) and Convolutional Neural Networks (CNN) into a framework that enhances material discovery and design, particularly for out-of-distribution (OOD) targets. The major contribution is the development of a strategy that balances latent space exploration and optimization, achieving low design errors – below 10% – for targeted properties located in near- and extreme-OOD regions of the material property space (MPS). The engineering application focuses on designing composites with tailored linear elastic properties, accelerating inverse design and reducing reliance on traditional simulation-based approaches. An image dataset of 12,000 Representative Unit Cells (RUCs) was assembled using a parametric Voronoi diagram generator, with elastic responses computed through finite element (FE) simulations. The DCGAN generated synthetic samples with novel features not present in the original dataset, demonstrating interpolation and extrapolation capabilities. A single round of Active Learning (AL) and Transfer Learning (TL) enhanced the CNN’s predictive accuracy on synthetic data. The framework offers significant computational efficiency, with optimization complexity O ( m ⋅ n 2 ) , where m is the number of iterations and n the latent vector dimensionality. This complexity is considerably lower than that of direct FE-based topology optimization, which ranges from O ( m ⋅ N 4 ) to O ( m ⋅ N 6 ) , where N × N represents the RUC grid size. These findings demonstrate the scalability and adaptability of the framework for advanced material design and engineering applications.},
  archive      = {J_EAAI},
  author       = {José Pablo Quesada-Molina and Hossein Mofatteh and Abdolhamid Akbarzadeh and Stefano Mariani},
  doi          = {10.1016/j.engappai.2025.110473},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110473},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Navigating beyond the training set: A deep learning framework for inverse design of architected composite materials},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Thermal buckling of graphene platelets reinforced
microplates with piezoelectric layers using artificial neural network.
<em>EAAI</em>, <em>150</em>, 110469. (<a
href="https://doi.org/10.1016/j.engappai.2025.110469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Functionally graded microplates are extensively employed in advanced engineering applications, including aerospace, micro-electromechanical systems, and smart structures, due to their exceptional mechanical performance, thermal resistance, and adaptability to multifunctional environments. This study examines the thermal buckling behavior of functionally graded graphene platelet-reinforced composite microplates integrated with piezoelectric layers under externally applied voltage. The modified couple stress theory is utilized to account for micro-scale effects, and the material properties of the composite layers are determined using the Halpin-Tsai micromechanical model. The governing equations based on first shear deformation theory are solved using the Ritz method to generate training data for an artificial neural network (ANN). To address computational challenges inherent in conventional methods, an ANN-based framework, leveraging the Levenberg-Marquardt algorithm, is developed to predict the critical buckling temperature with high precision and significantly reduced computational effort. The nanofiller dimensions, weight fraction, and piezoelectric layer thickness serve as inputs, while the thermal buckling load is the output. The obtained results show that the ANN offers a significant reduction in computational time, achieving speed improvements of over 85% across all cases. Also, the ANN reliably predicts the critical buckling temperatures, achieving a maximum discrepancy of only 0.26% when compared with the Ritz method. The novelty of this work lies in combining modified couple stress theory with ANN-assisted prediction models for efficient thermal buckling analysis. This methodology offers a practical solution for the rapid and reliable design of graphene platelet-reinforced composite microplates integrated with piezoelectric layers in applications demanding high precision and performance under thermal loading.},
  archive      = {J_EAAI},
  author       = {Hongxia Liu and Qiyu Wang and Zilin Zhang},
  doi          = {10.1016/j.engappai.2025.110469},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110469},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Thermal buckling of graphene platelets reinforced microplates with piezoelectric layers using artificial neural network},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization strategy for batch-stochastic configuration
network models and their application in component content prediction.
<em>EAAI</em>, <em>150</em>, 110461. (<a
href="https://doi.org/10.1016/j.engappai.2025.110461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the challenges of inefficiency and uncertain quality in incrementally adding hidden layer nodes to a stochastic configuration network (SCN). An optimized approach for batch-wise stochastic configuration network (BSCN) using an enhanced differential evolution (DE)algorithm is introduced. Initially, the inequality constraints of SCN is studied to analyze and establish the correlation between objective parameters and network residuals. Subsequently, to speed the network’s training velocity, a BSCN is utilized for developing the regression model. Combining the DE algorithm with regional contraction and greedy selection strategies. Specifically it leverages the robust global search prowess of the standard DE while mitigating its limitations in local search and ensuring global convergence. The formulation of this enhanced DE, termed regional contraction and greedy selection differential evolution (SGDE), is elaborated in detail, and an analysis and validation of its global convergence are conducted. Comparative experiments with the conventional DE underscore the superior optimization efficacy of SGDE. The applicability of SGDE enhanced BSCN (SGDE-BSCN) is corroborated through six real-world regression tasks. These tasks demonstrate that SGDE-BSCN not only excels in configuring hidden layer nodes but also exhibits enhanced error minimization and superior generalization capabilities with an equivalent number of hidden layer nodes. Additionally, a practical case study focused on predicting component content in rare earth extraction processes validates the effectiveness of the proposed method. The empirical results show that the application of SGDE-BSCN to artificial intelligence (AI) and artificial intelligence in the field of rare earth extraction shows high prediction accuracy and fast processing speed.},
  archive      = {J_EAAI},
  author       = {RongXiu Lu and XingRong Hu and Cong Pei and Hui Yang and WenHao Dai and JianYong Zhu},
  doi          = {10.1016/j.engappai.2025.110461},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110461},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimization strategy for batch-stochastic configuration network models and their application in component content prediction},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Continual learning for behavior-based driver identification.
<em>EAAI</em>, <em>150</em>, 110459. (<a
href="https://doi.org/10.1016/j.engappai.2025.110459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Behavior-based Driver Identification is an emerging technology that recognizes drivers based on their unique driving behaviors, offering important applications such as vehicle theft prevention and personalized driving experiences. However, most studies fail to account for the real-world challenges of deploying Deep Learning models within vehicles. These challenges include operating under limited computational resources, adapting to new drivers, and changes in driving behavior over time. The objective of this study is to evaluate if Continual Learning (CL) is well-suited to address these challenges, as it enables models to retain previously learned knowledge while continually adapting with minimal computational overhead and resource requirements. We tested several CL techniques across three scenarios of increasing complexity based on a well-known dataset for the Driver Identification problem. This work provides an important step forward in scalable driver identification solutions, demonstrating that CL approaches, such as Dark Experience Replay (DER), can obtain strong performance with only an 11% reduction in accuracy compared to the static scenario. Furthermore, to enhance the performance, we propose two new methods, Smooth Experience Replay (SmooER) and Smooth Dark Experience Replay (SmooDER), that leverage the temporal continuity of driver identity over time to enhance classification accuracy. Our novel method, SmooDER, achieves optimal results with only a 2% accuracy reduction compared to the 11% of the DER approach. In conclusion, this study proves the feasibility of CL approaches to address the challenges of Driver Identification in dynamic environments, making them suitable for deployment on cloud infrastructure or directly within vehicles.},
  archive      = {J_EAAI},
  author       = {Mattia Fanan and Davide Dalle Pezze and Emad Efatinasab and Ruggero Carli and Mirco Rampazzo and Gian Antonio Susto},
  doi          = {10.1016/j.engappai.2025.110459},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110459},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Continual learning for behavior-based driver identification},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised contrastive representation learning for
classifying internet of things malware. <em>EAAI</em>, <em>150</em>,
110299. (<a
href="https://doi.org/10.1016/j.engappai.2025.110299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid increase in malware prevalence poses a substantial security threat to Internet of Things (IoT) devices. Classifying IoT malware has emerged as a crucial area, essential for identifying attack patterns and developing effective defense strategies. Many methods for classifying malware utilize supervised learning. However, supervised learning in malware classification requires a considerable amount of labeled samples, which poses challenges and costs in acquiring and labeling malware samples. Furthermore, Some malware classification models struggle to fully extract features. This article proposes a self-supervised contrastive learning framework. Initially, the malware is converted to greyscale. The encoder is then pre-trained by self-supervised contrastive learning. The encoder with the new structure is able to extract features more comprehensively, while the projection header with attention is enabled to project features into the low-dimensional space more efficiently. Finally, the pre-trained encoder and classifier are fine-tuned to form a classification model using labeled samples. Experiments have shown that the proposed method has better accuracy regardless of the number of labeled samples. Experiments conducted using the publicly benchmarked datasets, Malware Image (Malimg) and the Microsoft Malware Classification Challenge (BIG2015), demonstrate that our framework outperforms state-of-the-art deep learning models and traditional methods in terms of accuracy, with achieved rates of 99.46% and 99.22%, respectively. Using only 5% of the labels from BIG2015, the proposed framework produces an impressive accuracy of 94.76%. Furthermore, it also outperforms baseline methods in identifying evolving malware, as indicated by its accuracy of 79% in a benchmarked dataset for trustworthy malware family classification (BenchMFC-G1P1P2).},
  archive      = {J_EAAI},
  author       = {Fangwei Wang and Yinhe Chen and Hongfeng Gao and Qingru Li and Changguang Wang},
  doi          = {10.1016/j.engappai.2025.110299},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110299},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-supervised contrastive representation learning for classifying internet of things malware},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid rough aggregation approach for the selection of
artificial intelligence-based industrial cleaning robots used in public
spaces from the perspective of urban waste management. <em>EAAI</em>,
<em>150</em>, 109566. (<a
href="https://doi.org/10.1016/j.engappai.2024.109566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Waste management is becoming increasingly complex and challenging, especially in megacities with large populations. Unlike the past, when urban waste was simply collected and disposed of, modern waste management requires careful planning and execution of collection, separation, recycling, and reuse processes. Effective management of this complex system now needs more than just human effort. Integrating artificial intelligence (AI)-based systems into waste management can enhance waste reduction, reuse, and recycling effectiveness and efficiency. Selecting suitable AI-based cleaning robots (AI-ICR) for crowded public spaces, such as stations, train stations, and airports, poses complex decision-making challenges. The primary challenge is the novelty of the technology, which leads to uncertainties in selecting AI-ICRs. To address this challenge, we have developed a decision-making approach based on rough Archimedean-Dombi partitioned aggregation. This approach, termed “rough Archimedean-Dombi partitioned aggregation,” combines the flexibility of Archimedean operators, the smoothness of Dombi operators, and the structured decomposition of Partitioned operators. This model is mainly chosen for its ability to handle the uncertainty and complexity inherent in multiple criteria decision-making (MCDM) processes. Leveraging rough numbers provides a robust framework for evaluating AI-ICRs under uncertain conditions. The main advantage of this model is its robustness, consistency, stability, and ability to handle complex uncertainties. We applied the proposed model to assess four AI-ICR alternatives identified through extensive research. We evaluated these alternatives using eighteen criteria established through comprehensive field studies. Based on the results, “Recycling cost (B12)” emerged as the most crucial criterion for selecting AI-ICRs. Additionally, the research identifies the SD45 manufactured by Peppermint Robotics Co. as the optimal AI-ICR candidate. Finally, the sensitivity and benchmark analyses to validate the proposed model confirm its robustness, consistency, and reliability.},
  archive      = {J_EAAI},
  author       = {Ömer Faruk Görçün and Abhijit Saha and Pydimarri Venkata Ravi Kumar and Bijoy Krishna Debnath},
  doi          = {10.1016/j.engappai.2024.109566},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {109566},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid rough aggregation approach for the selection of artificial intelligence-based industrial cleaning robots used in public spaces from the perspective of urban waste management},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A study on sustainable system for managing municipal solid
waste through a multi-criteria group decision-making technique.
<em>EAAI</em>, <em>150</em>, 109393. (<a
href="https://doi.org/10.1016/j.engappai.2024.109393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Municipal solid waste management, a unique aspect of sustainable development, is a crucial social-ecological system that intersects with the economy, society, and environment. The introduction of volume-based waste fees in some developed countries has been a step towards promoting recycling and waste reduction. However, the sustainability of high recycling targets and the impact of public satisfaction on waste management efficiency are areas that demand further exploration. A review of the literature on municipal solid waste management and technology selection from various countries reveals that many studies need more precise justification and a resolution to the ambiguity in decision-making. Meanwhile, some researchers have developed the fuzzy multi-criteria decision-making technique in the context of waste management. However, significant performance criteria for ’5R’s (refuse, reduce, reuse, repurpose, recycle)’ waste management technology selection and cause-and-effect group criteria still need to be identified. This study strongly emphasizes the potential of the ’5R’s’ waste management system to revolutionize waste management practices. The ’5R’s’ waste management system uses a multi-criteria group decision-making technique using fuzzy-based artificial intelligence methods, employing the novel fuzzy technique for order of preference by similarity to the ideal solution. This study also proposes a new way to rank generalized interval type-2 trapezoidal fuzzy numbers and defuzzifies them to address the uncertainties that arise when using fuzzy linguistic terms to make decisions. Finally, a numerical example of the ’5R’s’ waste management problem is discussed with new ranking methods and compared with existing methods, underscoring the significant potential of the ’5R’s’ waste management system.},
  archive      = {J_EAAI},
  author       = {Marimuthu Dharmalingam and Daekook Kang},
  doi          = {10.1016/j.engappai.2024.109393},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {109393},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A study on sustainable system for managing municipal solid waste through a multi-criteria group decision-making technique},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A graph convolutional network and gated recurrent unit-based
surrogate for agent-based diffusion models. <em>EAAI</em>, <em>149</em>,
110610. (<a
href="https://doi.org/10.1016/j.engappai.2025.110610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the challenge of high computational costs in agent-based diffusion models (ABMs), which are widely used for simulating complex diffusion processes but become prohibitively expensive in large-scale applications. To mitigate this issue, we introduce a Graph Convolutional Network (GCN) and Gated Recurrent Unit (GRU)-based Surrogate Network (G2SN) for ABMs. The GCN module captures the social network structure and seed set, while the GRU module models the diffusion time series. Computational complexity analysis demonstrates that G2SN significantly outperforms ABM simulations in efficiency. Experimental results confirm that G2SN accurately predicts ABM dynamics, reducing the mean absolute deviation (MAD) by 71.7 % on training sets and 77.7 % on test sets compared to traditional machine learning surrogate models. Case studies on new product diffusion further illustrate the effectiveness of the G2SN-based calibration approach, improving parameter search efficiency by 50.8 % and 37.2 % over alternative surrogate model-based methods. Additionally, these studies underscore the critical importance of social network and seed set in enhancing ABM prediction accuracy. This approach provides a more efficient and scalable tool for ABM calibration and new product diffusion forecasting, aiding managers in production, inventory, and marketing decisions.},
  archive      = {J_EAAI},
  author       = {Yu Xiao and Yuanyuan Zhou and Ziyi Wang},
  doi          = {10.1016/j.engappai.2025.110610},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110610},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A graph convolutional network and gated recurrent unit-based surrogate for agent-based diffusion models},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertainty-aware focal loss for object segmentation.
<em>EAAI</em>, <em>149</em>, 110599. (<a
href="https://doi.org/10.1016/j.engappai.2025.110599">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the loss function of object segmentation models, misclassified pixels whose prediction are opposite to the ground truth and uncertain pixels whose predicted probability is close to 0.5 are more important for model training. Focusing on misclassified pixels can improve the segmentation accuracy of the model, and focusing on uncertain pixels can help the model to form better decision surfaces. However, existing methods fail to take both types of pixels into account simultaneously. To enhance the learning on these two types of important pixels, the Uncertainty-aware Focal Loss (UFL) is proposed based on the analysis of Uncertainty-aware Loss (UAL). Then, by leveraging the S-shaped property of the sigmoid function, a loss function is constructed that can simultaneously increase the loss and loss derivatives of misclassified and uncertain pixels. In order to solve the gradient vanishing problem of the sigmoid function on well-classified pixels, a regularization constraint term is defined, whose value is the square of predicted probability. Finally, the pixel loss value is dynamically adjusted at different stages of training according to the changes in the contributions of misclassified and uncertain pixels to the model training, which improves the targeted learning for misclassified and uncertain pixels. Experimental results on two different types of network structures and six datasets demonstrate that the proposed method can better segment the uncertain and misclassified pixels. Especially, on the DUT-O dataset, UFL improves mean Intersection over Union (mIoU ) by almost 2.7 % compared to UAL.},
  archive      = {J_EAAI},
  author       = {Lei Chen and Yang Wang and Jibin Yang and Yunfei Zheng and Tong Han and Bo Zhang and Tieyong Cao},
  doi          = {10.1016/j.engappai.2025.110599},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110599},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Uncertainty-aware focal loss for object segmentation},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised combustion state diagnosis using a
noise-augmented generative adversarial network and flame image
sequences. <em>EAAI</em>, <em>149</em>, 110574. (<a
href="https://doi.org/10.1016/j.engappai.2025.110574">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliable diagnosis of combustion states, particularly distinguishing between stable and unstable flame conditions, is crucial for maintaining power generation efficiency and stability. However, accurate detection of unseen unstable combustion states remains challenging due to the complex dynamics of flames and the limited availability of unstable flame data. To address this challenge, this study proposes a self-supervised combustion state diagnosing method based on a noise-augmented generative adversarial network (NAGAN) and flame image sequences. The proposed method employs a convolutional autoencoder (CAE) and principal component analysis (PCA) to extract abstract flame features from image sequences. A novel multi-generator NAGAN architecture, comprising a long short-term memory (LSTM)-based generator and two Gaussian noise-augmented generators, is designed to synthesize diverse unstable flame feature sequences with temporal dynamics and identify the combustion state. A Gaussian abnormal flame feature generator (GAFG) leveraging Gaussian noise and binary masking is introduced to simulate a wide range of anomalies, enabling the discriminator to learn diverse representations of unstable combustion states. Experimental results on methane-air flames show that the proposed NAGAN achieves an accuracy of 0.978 and an F1 score of 0.986 on the flame stability diagnosis, with a recall rate of 0.975 for unseen unstable flames, outperforming most existing unsupervised machine learning and deep-learning based diagnostic methods. These results demonstrate the potential of the proposed method to improve combustion state monitoring, enhancing the reliability and efficiency of power generation systems.},
  archive      = {J_EAAI},
  author       = {Xiaojing Bai and Liwen Fei and Weiqi Liu and Hua Wu and Yong Yan and Weicheng Xu},
  doi          = {10.1016/j.engappai.2025.110574},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110574},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-supervised combustion state diagnosis using a noise-augmented generative adversarial network and flame image sequences},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An extended multi-criteria group decision-making method
based on preference ranking under z-number environments. <em>EAAI</em>,
<em>149</em>, 110573. (<a
href="https://doi.org/10.1016/j.engappai.2025.110573">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared with traditional fuzzy numbers, using Z-numbers to illustrate fuzzy events offers two key advantages. It makes fuzzy events more intuitive for decision-makers, and the second component of Z-numbers acts as a measure of the reliability of the first component. While significant progress has been made on Z-numbers, from the theoretical and practical perspectives, some gaps remain. For example, scholars have seldom focused on the likelihood of Z-numbers, most existing decision-making methods with Z-numbers rarely consider the consensus-reaching processes, and little has been reported on the superior ordering methods in the Z-number environment. To overcome these limitations, first, the likelihood of Z-numbers is defined in combination with the preference ranking organization method for enrichment evaluations (PROMETHEE) type V preference function. Second, the ordering rules for PROMETHEE are discussed. Then, a procedure of the feedback-adjustment method is introduced to help the consensus level of group-alternative ranking reach the threshold. On these bases, an extended PROMETHEE multi-criteria group decision-making method with Z-numbers is proposed. Finally, to verify the feasibility and effectiveness of the proposed method, we examined an intelligent medical-diagnostic-system selection problem and conducted a comparison analysis. We applied the Z-number PROMETHEE approach to a challenging case study requiring a dual-data-driven application. Furthermore, the study suggests future directions for improving the proposed framework in other related contexts.},
  archive      = {J_EAAI},
  author       = {Jian Li and Yuanyuan Xiang and Honggang Peng and Jianqiang Wang},
  doi          = {10.1016/j.engappai.2025.110573},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110573},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An extended multi-criteria group decision-making method based on preference ranking under Z-number environments},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigating the effectiveness of hybrid gradient boosting
models and optimization algorithms for concrete strength prediction.
<em>EAAI</em>, <em>149</em>, 110568. (<a
href="https://doi.org/10.1016/j.engappai.2025.110568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to evaluate and predict the compressive strength of concrete using 8 different machine learning (ML) models, including Extreme Gradient Boosting (XGBoost), Light Gradient Boosting machine (LightGBM), Gradient Boosting with Categorical features support (CatBoost), Gradient Boosting Regressor (GBR), Adaptive Boosting (AdaBoost), Decision Tree (DT), Random Forest (RF), and Support Vector Machine Regression (SVR). The study employed Bayesian optimisation process with two surrogate models (Gaussian Processes and Random Forest) and Random Search optimisation process to optimise the hyperparameters of these ML models. 1030 data samples were used to train the models and analyse the feature importance of each input variable using SHapley Additive exPlanations (SHAP). The results indicated that all 8 hybrid ML models performed well with R2 values larger than 0.80 and four models (XGBoost, CatBoost, GBR, and LightGBM) being the standout models, achieving R2 values of 0.94, 0.94, 0.92, and 0.92 on testing dataset, respectively. The four leading models (XGBoost, CatBoost, GBR, LightGBM) were applied to six sub-databases of concrete types, significantly enhancing accuracy with all models achieving R2 values over 0.98 on the testing dataset. The study also found that curing age, cement content, and amount of water were the most important variables affecting compressive strength while fly ash was the least important. By deploying the three best models to the cloud, it is now possible to make predictions using any web browser on any device.},
  archive      = {J_EAAI},
  author       = {Khuong Le Nguyen and Mahmoud Shakouri and Lanh Si Ho},
  doi          = {10.1016/j.engappai.2025.110568},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110568},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Investigating the effectiveness of hybrid gradient boosting models and optimization algorithms for concrete strength prediction},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An agent-based emotional persuasion model driven by
integrated trust assessment. <em>EAAI</em>, <em>149</em>, 110567. (<a
href="https://doi.org/10.1016/j.engappai.2025.110567">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research on automated negotiation has primarily focused on improving the artificial intelligence of agents and equipping them with more flexible internal mechanisms to facilitate high-quality negotiations. However, the study on the systematic modeling of human-like psychological and behavioral activities and their role in the negotiation process is still in its early stages. In light of this, this paper proposes an emotional persuasion model that takes into account the effect of negotiators&#39; integrated trust assessments on negotiation. Firstly, the paper presents a negotiation agent with both cognitive and emotional functions, detailing its internal system and operating mechanism. Secondly, the integrated trust of a negotiator is obtained by evaluating multiple single trusts, and the mapping of the integrated trust to the negotiation round parameter is modeled. Integrated trust is also parameterized into the agent&#39;s cognitive processes. Finally, the paper introduces a new framework for the generation of emotional persuasive behavior to assist agents in making new proposals. A series of experiments were conducted, yielding the following results: Compared with the non-emotional model, the performance of negotiation rounds and utility differences improved by 7.97 % and 4.81 %, respectively. Furthermore, the trust-driven emotional persuasion model outperformed the several existing competing models by at least 31.1 % in utility difference and 81.0 % in negotiation rounds. Additionally, a case study of human-computer negotiation demonstrated that the agent designed using the proposed method has negotiating capabilities comparable to those of a real human, which further showcases the application effect of the artificial intelligence agent in practice.},
  archive      = {J_EAAI},
  author       = {Jinghua Wu and Ya Zhang and Ruiyang Cao and Yan Li},
  doi          = {10.1016/j.engappai.2025.110567},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110567},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An agent-based emotional persuasion model driven by integrated trust assessment},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Strength prediction of recycled concrete using hybrid
artificial intelligence models with gaussian noise addition.
<em>EAAI</em>, <em>149</em>, 110566. (<a
href="https://doi.org/10.1016/j.engappai.2025.110566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research uses machine learning and computational techniques to investigate methods for the compressive strength of recycled concrete prediction. Waste management and environmental sustainability are addressed using construction and mineral waste as aggregate. Previous attempts with traditional linear and polynomial models were insufficient for capturing complex data relationships, achieving R-squared (R 2 ) values of only 0.22. Therefore, advanced models were employed, including support vector regression (SVR), one-dimensional convolutional neural networks (1D-CNN), and a multi-model hybrid approach. Combining Elastic Networks, Random Forest Algorithm, and Light Gradient Boosting Decision (LGBM), the hybrid model demonstrated exceptional performance, achieving an R 2 value of 0.9072 - a 312 % improvement over traditional methods. Gaussian noise augmentation during training enhanced the model&#39;s generalization capabilities. Experimental data validation confirmed the hybrid model&#39;s predictive accuracy. The potential of computational methods is highlighted to optimize the use of recycled materials in concrete, promoting sustainable construction practices and laying the foundation for selecting recycled materials for future practical civil engineering applications. Future research should focus on expanding datasets and exploring additional data augmentation techniques to improve model accuracy further.},
  archive      = {J_EAAI},
  author       = {Yuzheng Geng and Yongcheng Ji and Dayang Wang and Hecheng Zhang and Zhizhu Lu and Aotian Xing and Mingjie Gao and Maoyang Chen},
  doi          = {10.1016/j.engappai.2025.110566},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110566},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Strength prediction of recycled concrete using hybrid artificial intelligence models with gaussian noise addition},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast stereo conformer: Real-time stereo matching with
enhanced feature fusion for autonomous driving. <em>EAAI</em>,
<em>149</em>, 110565. (<a
href="https://doi.org/10.1016/j.engappai.2025.110565">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate stereo matching is critical for depth estimation in autonomous driving, yet remains challenging in weakly-textured regions where conventional convolutional neural networks (CNNs) lack global context and Transformers overlook local details. We propose Fast Stereo Conformer Net (FSCN), a real-time parallel network integrating CNNs and Transformers, enhanced by a Convolutional Coupling Transformer (CCT) for synergistic local-global feature fusion. To address data scarcity, we introduce random translation transformations (RTTs) during pretraining and fine-tuning. On the Karlsruhe Institute of Technology and Toyota Technological Institute at Chicago 2015 Dataset (KITTI 2015) benchmark, FSCN achieves a 3-pixel error rate of 1.79 %, representing a 7.25 % improvement over the baseline and a 5.29 % superior performance compared to state-of-the-art real-time methods, while processing frames efficiently in 57 milliseconds (ms). It also demonstrates outstanding generalization on other datasets, achieving improvements of 6.98 % on KITTI 2012, 9.72 % on Middlebury, and 9.30 % on Swiss Federal Institute of Technology in Zurich 3D Dataset (ETH3D) compared to the baseline. These results highlight the synergistic effectiveness of CNNs and Transformers in feature extraction and the significant potential of our approach for advancing stereo matching technology in autonomous driving applications.},
  archive      = {J_EAAI},
  author       = {Yunhua Lu and Xianzhong He and Qingwei Zhang and Ding Zhang},
  doi          = {10.1016/j.engappai.2025.110565},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110565},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fast stereo conformer: Real-time stereo matching with enhanced feature fusion for autonomous driving},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Speech signal-based accurate neurological disorders
detection using convolutional neural network and recurrent neural
network based deep network. <em>EAAI</em>, <em>149</em>, 110558. (<a
href="https://doi.org/10.1016/j.engappai.2025.110558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neurological diseases often manifest in subtle alterations to the human voice due to damage in the sound-related regions of the brain. Leveraging advancements in artificial intelligence (AI) technologies, computers can discern minute variations in sound imperceptible to the human ear, enabling rapid and precise diagnostic support. This paper presents a novel approach to neurological disease classification utilizing voice recordings of individuals diagnosed with various neurological conditions alongside healthy controls. By employing AI techniques, particularly a hybrid deep network framework integrating Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN), we aimed to classify one-sentence audio inputs of Multiple Sclerosis (MS) patients, healthy individuals, and other neurological diseases. In our dataset, we have compiled audio recordings from 95 healthy individuals, 99 individuals diagnosed with multiple sclerosis (MS), and 96 individuals with other neurological disorders. Of these, 20 % of the data was reserved for testing. Our proposed architecture achieved remarkable performance metrics in experimental evaluations, exhibiting 96.55 % accuracy, 98.25 % specificity, 96.49 % sensitivity, 96.97 % precision, and 96.56 % F1-Score. The results obtained are more successful compared to the methods of AlexNet from scratch, fine-tuned AlexNet, Long Short-Term Memory (LSTM) based CNN, and Gated Recurrent Unit (GRU) based CNN. The results of our study highlight the potential of this framework to be integrated into clinical diagnostic workflows, providing clinicians with an effective tool for early and precise detection of neurological diseases, ultimately improving patient outcomes through timely intervention and personalized treatment strategies.},
  archive      = {J_EAAI},
  author       = {Emel Soylu and Sema Gül and Kübra Aslan Koca and Muammer Türkoğlu and Murat Terzi and Abdulkadir Şengür},
  doi          = {10.1016/j.engappai.2025.110558},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110558},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Speech signal-based accurate neurological disorders detection using convolutional neural network and recurrent neural network based deep network},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel multimodal deep learning framework for predicting
residual strength of corroded rectangular hollow-section columns.
<em>EAAI</em>, <em>149</em>, 110554. (<a
href="https://doi.org/10.1016/j.engappai.2025.110554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Corrosion, recognized as a thermodynamically spontaneous process, is one of the key issues affecting the health of rectangular hollow steel section columns under working conditions, and has attracted much attention in recent years. Traditional approaches, such as multi-layer perceptron, often rely solely on the degree of volume loss to predict residual strength, overlooking the spatial complexity of actual corrosion patterns. To address these limitations, this study presents a novel multimodal deep learning network for accurately predicting the residual strength of corroded hollow steel section columns with random, nonuniform corrosion distributions. Our approach integrates (i) image‐based corrosion distributions on four steel walls, and (ii) tabular geometric parameters, through five distinct data-fusion methods proposed in this work, three employing Late Fusion (via a novel multi‐head attention module) and two using Early Fusion (via pixel−level merging). The image information extraction core is built upon a lightweight convolutional neural network and a channel−spatial attention block, while the tabular extraction module leverages a revised multi-layer perceptron architecture. After Bayesian hyperparameter optimization, the best‐performing model achieves a coefficient of determination of 0.971 on the test set, surpassing conventional machine learning and other multimodal fusion techniques by 0.01–0.161. Further analysis shows that the reverse visualization technique highlights corrosion−critical regions that closely coincide with the experimentally validated failure zones. Consequently, the proposed framework not only predicts residual strength with high accuracy but also localizes vulnerable areas for targeted reinforcement. This methodology holds promise for large‐scale corrosion monitoring and structural health assessment of steel infrastructure.},
  archive      = {J_EAAI},
  author       = {Yu-Jia Zhang and Lei Zhang and Yu Zhou and Tian-Xiang Li and Reece Lincoln and Jing-Zhong Tong and Jia-Jia Shen},
  doi          = {10.1016/j.engappai.2025.110554},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110554},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel multimodal deep learning framework for predicting residual strength of corroded rectangular hollow-section columns},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025b). Comprehensive evaluation of deep reinforcement learning for
permanent magnet synchronous motor current tracking and speed control
applications. <em>EAAI</em>, <em>149</em>, 110551. (<a
href="https://doi.org/10.1016/j.engappai.2025.110551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Permanent Magnet Synchronous Motors (PMSMs) are indispensable in industrial applications, requiring precise control to ensure optimal performance. Traditional model-based methods, such as Proportional-Integral (PI) control and Model Predictive Control (MPC), face inherent limitations in robustness and adaptability under complex conditions. Deep Reinforcement Learning (DRL), as a model-free, data-driven approach, offers a transformative solution for PMSM control. This study proposes a DRL-based current control strategy and systematically evaluates the performance of three representative DRL algorithms: Deep Q-Network (DQN), Proximal Policy Optimization (PPO), and Advantage Actor-Critic (A2C) in PMSM control tasks. Key contributions include hyperparameter sensitivity analysis, transfer learning for improved training efficiency, and the application of DRL to multi-objective speed control under varying operational scenarios. Experimental results reveal the hyperparameter sensitivities of different DRL algorithms and provide theoretical insights. The findings demonstrate that transfer learning significantly improves DRL training efficiency and control performance. DRL outperforms traditional controllers in current and speed control, achieving superior dynamic response, tracking accuracy, and adaptability to complex conditions. This study offers new insights into the application of DRL in industrial PMSM control and serves as a reference for its further optimization and practical deployment.},
  archive      = {J_EAAI},
  author       = {Yiming Zhang and Jingxiang Li and Hao Zhou and Chin-Boon Chng and Chee-Kong Chui and Shengdun Zhao},
  doi          = {10.1016/j.engappai.2025.110551},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110551},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Comprehensive evaluation of deep reinforcement learning for permanent magnet synchronous motor current tracking and speed control applications},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient boundary prediction method based on
multi-fidelity gaussian classification process for class-imbalance.
<em>EAAI</em>, <em>149</em>, 110549. (<a
href="https://doi.org/10.1016/j.engappai.2025.110549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Failure boundary prediction aims to explore the boundary between failure and safety limit states in a given problem. In recent years, the use of surrogate models instead of physical experiments to explore the failure boundary has become one of the promising methods to reduce costs. Among various surrogate models, multi-fidelity Gaussian process classification (MFGPC) can produce accurate predictions while reducing simulation expenses by using a small set of high-fidelity samples and a larger set of low-fidelity samples. However, the current MFGPC model primarily utilizes Markov chain Monte Carlo sampling to estimate the model hyperparameters. The modeling process involves a significant amount of calculation and slow convergence speed. Additionally, the practical application of MFGPC in the engineering field is limited, and the presence of a class imbalance in real data can lead to poor model training performance. Therefore, to improve the modeling efficiency of MFGPC, this paper proposes an improved MFGPC method for the imbalanced problem. The improved MFGPC model utilizes the Stein variational gradient descent algorithm to reduce the computational cost of the model. Additionally, it incorporates a synthetic sampling algorithm to effectively handle class-imbalance issues in real-world engineering cases. Two engineering examples are solved, including the failure boundary prediction of the zero Poisson ratio structure and the operating boundary of an axial flow compressor. It is demonstrated that the proposed method can accelerate the convergence speed of the model by tens of magnitudes while maintaining good prediction accuracy.},
  archive      = {J_EAAI},
  author       = {Jinlang Luo and Lingzhi Liu and Youwei He and Kuan Tan},
  doi          = {10.1016/j.engappai.2025.110549},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110549},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An efficient boundary prediction method based on multi-fidelity gaussian classification process for class-imbalance},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Flow field reconstruction and prediction of the
two-dimensional cylinder flow using data-driven physics-informed neural
network combined with long short-term memory. <em>EAAI</em>,
<em>149</em>, 110547. (<a
href="https://doi.org/10.1016/j.engappai.2025.110547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-informed neural network (PINN) has attracted significant attention for various fluid related problems in recent years. Although the basic principle allows the PINN to require less data to train a reliable model, data-driven PINN often suffers from the quantity and quality of the training data, without which will result in diminishing fitting capability in the edge regions and extrapolation beyond the dataset. To address this issue, a new coupled model called LSTM-PINN (LP) is proposed, which combines the advantages of Long Short-Term Memory (LSTM) in handling long-term dependencies for time-sequenced data with the existing PINN framework. By incorporating the time-sequenced predictions at different spatial points generated by the LSTM into the training set of the PINN, the edge errors that refer to errors at boundary of space or time are reduced and the time-sequenced prediction capability of flow field is enhanced. The comparative study is conducted on the velocities along two directions predicted by the coupled model with those obtained from the benchmark PINN model, while the numerical solutions in the case of 2D (two-dimensional) flow around cylinder described by the Navier-Stokes (NS) equations are selected as training dataset. The results demonstrate that the proposed LP model improves the accuracy of prediction compared to the conventional PINN model, showing great potential for flow field reconstruction and time series prediction.},
  archive      = {J_EAAI},
  author       = {Yehao Dou and Xun Han and Pengzhi Lin},
  doi          = {10.1016/j.engappai.2025.110547},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110547},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Flow field reconstruction and prediction of the two-dimensional cylinder flow using data-driven physics-informed neural network combined with long short-term memory},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A large-scale mobile application knowledge graph for the
research of cybersecurity: Construction and application. <em>EAAI</em>,
<em>149</em>, 110543. (<a
href="https://doi.org/10.1016/j.engappai.2025.110543">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale datasets for mobile applications (terms as “apps”) have been developed and become important assets for malware identification and other tasks of cybersecurity. However, existing datasets focus on extending the scale of apps, while ignoring the relevance among apps. On the other hand, several works try to integrate different metadata of apps to discover the relevance among apps, but most of them pay little attention to the roles such as normal users, developers, cybersecurity analysts, and they do not take full advantage of these metadata so that the fine-grained correlations among apps are difficult to be captured. To fill these gaps, we present a mobile application knowledge graph, which collects millions of apps’ information from various resources, including application markets, encyclopedias and news. Precisely, a lightweight ontology is designed for our knowledge graph. It defines a unified semantic schema of collected apps so that more linkages of these apps can be shared with each other. Moreover, we employ several promising algorithms of information extraction and knowledge alignment, and evaluate their performances during the process of construction. To detect more relevance with respect to sensitive apps, we propose a hybrid embedding-based method, in which the vector representations of apps are iteratively encoded with knowledge graph embedding methods and network embedding models. Experimental results show that our hybrid method can obtain better performances than several existing models for the relevance detection of sensitive apps. Finally, we list three use cases of mobile application knowledge graph for cybersecurity and discuss their limitations that would be improved in future works.},
  archive      = {J_EAAI},
  author       = {Weizhuo Li and Heng Zhou and Yiming Tan and Weiqi Luo and Qiu Ji and Yuyang Bian},
  doi          = {10.1016/j.engappai.2025.110543},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110543},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A large-scale mobile application knowledge graph for the research of cybersecurity: Construction and application},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-layer knowledge graph transformer network-based question
and answer explainable recommendation. <em>EAAI</em>, <em>149</em>,
110542. (<a
href="https://doi.org/10.1016/j.engappai.2025.110542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The question and answer (Q&amp;A) recommendation in community question answering (CQA) helps users quickly and accurately find the desired Q&amp;A. However, existing studies face the problems of sparse interaction data, cold starts, and a lack of explanations. This paper proposes a novel Q&amp;A explainable recommendation approach based on a two-layer knowledge graph transformer network. It alleviates the sparse data and cold start problem by the novel two-layer knowledge graph. First, a two-layer knowledge graph in CQA is constructed. The interaction layer helps to enrich the associations between users and questions and answers (Q&amp;As). The semantic layer provides semantic associations and reflects contextual domain knowledge. Second, a critical meta-path recognition module is constructed to learn the critical meta-paths between users and documents from the interaction layer. Then, a user and Q&amp;A embedding method based on a two-layer knowledge graph is proposed to enhance the user and Q&amp;A representations. Finally, a recommendation and explanation layer is established to obtain personalized Q&amp;A recommendation results and corresponding explanations. Compared with the baselines, the proposed method shows superior performance. It achieves average improvements of 21.28%, 28.41% and 27.18% in precision, recall and F1-measure, respectively, in the top- K Q&amp;A recommendation separately. It improves the area under the curve and F1-measure of the click-through rate prediction recommendation by 11.32% and 23.06%, respectively.},
  archive      = {J_EAAI},
  author       = {Ying Li and Ming Li and Jin Ding and Yixue Bai},
  doi          = {10.1016/j.engappai.2025.110542},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110542},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Two-layer knowledge graph transformer network-based question and answer explainable recommendation},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Metal oxide semiconductor based electronic nose data
pre-processing, review. <em>EAAI</em>, <em>149</em>, 110540. (<a
href="https://doi.org/10.1016/j.engappai.2025.110540">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metal Oxide Semiconductor (MOS) based Electronic Nose (E-nose) mimics Human Olfaction mechanisms in Odor Detection by creating a Unique Odor-Print that is processed by Pattern Recognition (PARC) algorithms. Odor Metal Oxide Semiconductor sensors do not behave as independent sensors. Each gas sensor in E-nose responds more selectively to a certain group of Volatile Organic Compounds (VOCs) but also shows a broad, overlapping response and sensitivity to the other Gas Compounds. Like in Natural Olfaction, a key role is played by Data Analysis. In this comprehensive literature review, the current state of different design stages in Metal Oxide Semiconductor (MOS)-based Electronic Nose Raw Data Pre-processing to condition input data prior to array processing and pattern recognition were thoroughly discussed. In depth technical application of various data pre-processing techniques to both static and dynamic sensor responses, emphasizing their importance in improving the sensors&#39; performance and pattern recognition accuracy were provided. A use case has been attempted, discussing data samples, feature extraction processes, and dimensionality reduction. A sample MATLAB code was provided to show cluster formations. Transient feature extraction improved classification accuracy by up to 30 %, while piecemeal signal feature extraction proved highly effective. Multivariate analysis and chemometric methods reduced data dimensionality by approximately 50–80 %, for creating Parsimonious Odor Classification Models.},
  archive      = {J_EAAI},
  author       = {Meisam Vajdi},
  doi          = {10.1016/j.engappai.2025.110540},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110540},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Metal oxide semiconductor based electronic nose data pre-processing, review},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tube-LaneNet: Predict each three-dimensional lane as a
completed structure via geometric priors. <em>EAAI</em>, <em>149</em>,
110539. (<a
href="https://doi.org/10.1016/j.engappai.2025.110539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monocular three-dimensional lane detection is a critical task for intelligent vehicles. However, most current methods, which mainly extend the two-dimensional paradigms, regard lanes as separated points set and constrain loss through the orthogonal projection on the two-dimensional plane. In this work, a novel deep learning framework is proposed to detect each lane as a continuous completed three-dimensional spatial structure. Concretely, three-dimensional lane anchors are implemented to extract proposal features through geometric priors to guarantee the continuous linear spatial structure. To enhance the feature of proposals, a relation-aware mechanism is further introduced to extract the spatial relationship between three-dimensional lanes. In particular, a novel tube-like intersection over union (TubeIOU) is proposed, which extends each three-dimensional lane to the tube-like structure as a completed unified entity in the three-dimensional space. Experiments on different datasets demonstrate the state-of-art performance of the proposed framework, especially achieves the fastest efficiency with 69 frames per second. The code will be made publicly available.},
  archive      = {J_EAAI},
  author       = {Genghua Kou and Shihao Wang and Ying Li},
  doi          = {10.1016/j.engappai.2025.110539},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110539},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Tube-LaneNet: Predict each three-dimensional lane as a completed structure via geometric priors},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Q-learning based estimation of distribution algorithm for
scheduling distributed heterogeneous flexible flow-shop with mixed
buffering limitation. <em>EAAI</em>, <em>149</em>, 110537. (<a
href="https://doi.org/10.1016/j.engappai.2025.110537">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are growing interests in the distributed shop scheduling research owing to the diversification of market demand. However, most prevailing studies disregard the synergistic influence of mixed buffering and due window on production efficiency. To reduce cost loss caused by delay in due window, this paper studies a distributed heterogeneous flexible flow-shop scheduling with mixed buffering limitation, i.e., finite buffers and no-wait requirements. The motivation of this work is to fill in void and offer practical insights for exploring how to intelligently implement, optimize and deploy a distributed production system. A mathematical model is established, aiming to minimize total weighted earliness and tardiness cost. An innovative Q-learning based estimation of distribution algorithm (QLEDA) is well-designed to address this problem. The QLEDA proposes well-tailored three-stage dynamic decoding and opposition-based learning to decode and promote the job sequence group. To balance global and local searchability of QLEDA, we introduce problem-specific Q-learning and Chebyshev chaotic mapping. To build a probability model of self-adaptation and self-selection, the job sequence group implements discrete actions by interacting with distributed environment and state space through Q-learning. Numerous experiments demonstrate that the QLEDA can generate more satisfactory results over other three well-performing rivals. The finding corroborates the applicability and effectiveness of presented QLEDA in solving the considered problem.},
  archive      = {J_EAAI},
  author       = {Hua Xuan and Qian-Qian Zheng and Lin Lv and Bing Li},
  doi          = {10.1016/j.engappai.2025.110537},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110537},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Q-learning based estimation of distribution algorithm for scheduling distributed heterogeneous flexible flow-shop with mixed buffering limitation},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). State of the art: Application of machine learning in ground
motion modeling. <em>EAAI</em>, <em>149</em>, 110534. (<a
href="https://doi.org/10.1016/j.engappai.2025.110534">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a detailed review of the application of machine learning (ML) techniques in Ground Motion Models (GMMs), which are vital tools for predicting seismic responses during earthquakes. Traditional GMMs, or Ground Motion Prediction Equations (GMPEs), rely on statistical regression methods that use predefined functional forms to estimate ground motion intensity measures (IMs), such as peak ground acceleration (PGA) and pseudo-spectral acceleration (PSA). While effective, these models often struggle with limitations, including handling nonlinear relationships and managing large datasets as earthquake catalogs grow. In response to these challenges, researchers have turned to ML methods, which offer the flexibility to model complex patterns without requiring predefined forms. This article explores various ML techniques, such as artificial neural networks (ANNs), support vector regression (SVR), random forest (RF), and gradient boosting (GB), and their application in GMMs. The paper also discusses the advantages of ML, such as improved accuracy and the ability to process extensive data, alongside challenges like interpretability issues and the risk of overfitting. Several case studies are provided to illustrate the practical benefits of ML in enhancing GMMs, particularly in reducing residuals and variability, ultimately contributing to more accurate seismic hazard assessments.},
  archive      = {J_EAAI},
  author       = {Najme Alidadi and Shahram Pezeshk},
  doi          = {10.1016/j.engappai.2025.110534},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110534},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {State of the art: Application of machine learning in ground motion modeling},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing accuracy of one-dimensional characteristic
predictions for axial compressors using deep learning. <em>EAAI</em>,
<em>149</em>, 110533. (<a
href="https://doi.org/10.1016/j.engappai.2025.110533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To enhance the accuracy of one-dimensional (1D) characteristic predictions for multistage axial flow compressors and improve design efficiency, this paper presents a deviation angle prediction model based on deep learning, utilizing data generated from Computational Fluid Dynamics (CFD) simulations. This model was integrated into a compressor characteristic calculation program. A CFD simulation dataset was created with National Advisory Committee for Aeronautics 65-series (NACA65) blade profiles, parameterized through a Latin hypercube design. After solving blade cascade flow fields, deviation angles under various conditions were obtained, establishing a mapping between design variables and deviation angles using deep learning. Test results showed a correlation coefficient of 0.9978 and a mean absolute error of 0.0785°. The surrogate model was embedded into the axial flow compressor 1D calculation program (HARIKA), replacing the original deviation angle model. Performance calculations on transonic two-stage and high-subsonic eight-stage compressors at different speeds demonstrated that the updated HARIKA program provided predictions closer to experimental values at high speeds, though slightly overestimated at lower speeds. These results confirm the model’s accuracy and practicality, suggesting that the improved HARIKA algorithm has potential for engineering applications in predicting the aerodynamic performance of multistage axial flow compressors.},
  archive      = {J_EAAI},
  author       = {Yulin Ma and Zhou Du and Quanyong Xu},
  doi          = {10.1016/j.engappai.2025.110533},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110533},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing accuracy of one-dimensional characteristic predictions for axial compressors using deep learning},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel adaptive gating neurons model with physical features
weighted for bearing fault diagnosis under strong noise. <em>EAAI</em>,
<em>149</em>, 110532. (<a
href="https://doi.org/10.1016/j.engappai.2025.110532">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Learning (DL) has made significant progress in the field of intelligent diagnosis. However, existing intelligent diagnosis models encounter challenges, including inadequate fault feature extraction capability, poor generalization performance, and unclear diagnostic mechanisms, especially under strong noise interference. To address these issues, we first propose a novel adaptive gating neuron with physical features weighted, which can adaptively adjust the combination of quadratic convolutions based on the physical features of the signals. On this basis, we establish a mathematical connection between the physical features-weighted adaptive gating neuron and learnable weighted autocorrelation, and theoretically demonstrate its superior feature extraction capability, which assigns higher weights to periodic features in bearing time-domain signals. Secondly, an adaptive gating neurons convolutional network (AGNCN) with physical features weighted was proposed, incorporating a residual structure. By decomposing the physical features-weighted adaptive gating neuron, we reveal an embedded attention mechanism, which enhances the intrinsic interpretability of the AGNCN model for diagnosing bearing faults in the presence of noise interference. Experiments conducted on both public datasets and our proprietary dataset demonstrate that our proposed method can efficiently and reliably diagnose bearing faults under strong noise interference.},
  archive      = {J_EAAI},
  author       = {Panpan Guo and Weiguo Huang and Ning Jia and Chuancang Ding and Yifan Huangfu and Xingxing Jiang and Juanjuan Shi},
  doi          = {10.1016/j.engappai.2025.110532},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110532},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel adaptive gating neurons model with physical features weighted for bearing fault diagnosis under strong noise},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Loss of coolant accident monitoring and pipe break diagnosis
in pressurized water reactors using bayesian-optimized long short-term
memory models. <em>EAAI</em>, <em>149</em>, 110531. (<a
href="https://doi.org/10.1016/j.engappai.2025.110531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While safety systems have been established for nuclear power plant accidents, the risk of human error remains ever present, particularly in high-pressure situations. This work utilizes the long short-term memory model (LSTM) as surrogate for monitoring loss of coolant accidents (LOCA) and diagnosing pipe breaks, aiding operators in assessing LOCAs more accurately. The models were trained using simulated accident scenarios covering the entire range of hot leg and cold leg pipe break extents. To ensure generalizability, Bayesian optimization was implemented as an automatic hyperparameter tuning method to optimize each model. In total, 15 LSTM forecasters with varying lookbacks and epochs and 20 LSTM predictors with varying trimmed sizes were developed. The forecasters showed excellent results in the water level and hot leg temperature forecasting tasks with average root mean squared error (RMSE) values of 4% and 4 °C, respectively. The overall best forecasting model was determined to have a lookback of 7 and 100 epochs, and trends relating accuracy to the epochs and lookbacks were also identified. The study also showed that LSTM predictors can provide early pipe break diagnosis accurately, using only at least 4% of the accident time series data from the onset. These predictors were able to predict the extent of pipe break with RMSE ranging from 0.57% to 1.77% and the location of pipe break with classification accuracy from 94% to 99%. Lastly, the robustness of the pipe break extent predictions were verified within expected noise levels. This study has further demonstrated the potential of artificial intelligence methods in reinforcing nuclear safety and effective accident diagnostics.},
  archive      = {J_EAAI},
  author       = {Johndel Obra and Shuichiro Miwa},
  doi          = {10.1016/j.engappai.2025.110531},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110531},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Loss of coolant accident monitoring and pipe break diagnosis in pressurized water reactors using bayesian-optimized long short-term memory models},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Skyline recency–frequency–monetary pattern mining based on
different constraint degrees. <em>EAAI</em>, <em>149</em>, 110529. (<a
href="https://doi.org/10.1016/j.engappai.2025.110529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge discovery plays a pivotal role in the field of Artificial Intelligence as it involves extracting valuable and previously unknown patterns (information, insights) from vast datasets. Skyline pattern mining emerges to deal with multiple-objective knowledge discovery in a threshold-free manner. Existing Skyline pattern mining methods mainly have two limitations: they only settle the problem with the restriction in dimension two, which is not applicable in dimension three or more; they focus on frequency and utility (monetary) without considering the temporal information. In this paper, we aim to overcome those limitations by proposing the problem model for finding skyline patterns considering three dimensions: recency, frequency, and monetary. We also define degrees of constraints to formulate strict/weak skyline patterns and present algorithms to mine them. Several pruning strategies are designed to reduce the search space. The max monetary score matrix structure and corresponding sparse storage are designed to facilitate the implementation of the pruning strategies. The skyline pattern storage matrix helps to add and delete patterns in the mining process efficiently. Experimental results show that the proposed algorithms discover more patterns without losing to the baseline. The runtime difference is usually within 10s without a clear winner. The proposed method wins tens to hundreds of megabytes of memory in most cases.},
  archive      = {J_EAAI},
  author       = {Xiaojie Zhang and Guoting Chen and Linqi Song and Wensheng Gan},
  doi          = {10.1016/j.engappai.2025.110529},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110529},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Skyline recency–frequency–monetary pattern mining based on different constraint degrees},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identification of martian minerals based on multiscale
spatial-spectral fusion network. <em>EAAI</em>, <em>149</em>, 110527.
(<a href="https://doi.org/10.1016/j.engappai.2025.110527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate identification of Martian surface minerals is crucial for analyzing the planet&#39;s geological environment and resource potential. Deep learning offers a powerful solution for automating Martian mineral identification. However, existing methods suffer from recognition inaccuracies due to the insufficient representation of the multiscale spectral and spatial features. In this article, a multiscale spatial-spectral fusion network (MSSFNet) is proposed to identify Martian minerals from hyperspectral images. In MSSFNet, the spectral multiscale feature extraction (Spe-MFE) module is proposed to extract multiscale spectral features from adjacent mineral bands in the spectral dimension. The spatial multiscale feature extraction (Spa-MFE) module extracts the spatial correlations of minerals from low-frequency and high-frequency features and retains more spatial information. At the end of the model, the spatial-spectral feature adaptive fusion (SSFAF) module utilizes attention-based feature weighting to fuse spectral and spatial features, improving its representation ability. Experimental results demonstrate that the proposed method achieved 99.51% accuracy on a constructed Martian mineral identification dataset, improving the precision of deep learning models in Martian surface mineral recognition. On the benchmark hyperspectral datasets of Indian Pines and Pavia University, MSSFNet achieved overall accuracies of 98.87% and 99.42%, respectively, outperforming state-of-the-art methods and validating its effectiveness and superiority.},
  archive      = {J_EAAI},
  author       = {Kai Wang and Xubing Zhang and Xianmin Wang and Zhouyuan Qian},
  doi          = {10.1016/j.engappai.2025.110527},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110527},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Identification of martian minerals based on multiscale spatial-spectral fusion network},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention based spatial-temporal multi-graph ordinary
differential equation network for traffic flow prediction.
<em>EAAI</em>, <em>149</em>, 110526. (<a
href="https://doi.org/10.1016/j.engappai.2025.110526">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction plays an important role in the intelligent transportation systems. Most of the current state-of-the-art traffic flow prediction models extract the spatial and temporal features of traffic flow data through graph neural network (GNN) and temporal extraction module. However, the semantic relevance of road network nodes and historical data relevance are ignored in those models. Moreover, there exists an over-smoothing problem as the number of GNN layers increases, and it is impossible to capture spatial relevance of long-range nodes through modeling. To address this challenge, we propose an attention based spatial-temporal multi-graph ordinary differential equation network (ASTMGODE). Specifically, ASTMGODE mainly consists of three independent components, to jointly model the spatial-temporal correlations and semantic correlations with various features in the traffic flow. The three spatial attributes are distance matrix, semantical matrix and historical data correlation matrix, respectively, based on the distance between road nodes, functional similarities and historical data. Each component can effectively capture the spatial-temporal correlations in the traffic data via the spatial-temporal attention mechanism. Subsequently, spatial-temporal features are characterized by temporal and spatial extraction modules, in which the temporal extraction module is composed of temporal attention mechanism and temporal convolution (TCN), while the spatial extraction module comprises tensor-based ordinary differential equation (ODE) and graph convolution network (GCN). During experiments on six real-world traffic datasets, the ASTMGODE model reduced root mean square error (RMSE) by approximately 7.65% compared to the state-of-the-art known models.},
  archive      = {J_EAAI},
  author       = {Ying-Ting Chen and Cheng Li and Shuang Li},
  doi          = {10.1016/j.engappai.2025.110526},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110526},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Attention based spatial-temporal multi-graph ordinary differential equation network for traffic flow prediction},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Django-based framework database for leakage detection using
machine learning for water distribution networks. <em>EAAI</em>,
<em>149</em>, 110525. (<a
href="https://doi.org/10.1016/j.engappai.2025.110525">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leakage in water supply pipe networks is a critical issue, with traditional detection methods being inefficient and error-prone. Acoustic-based leak detection often lacks standardized databases, limiting its effectiveness. This study proposes an integrated system using MySQL, Python, and Django for managing and analyzing acoustic leakage data. The system incorporates Variable Modal Decomposition (VMD), Wavelet Threshold Noise Reduction, Feature Extraction, and Support Vector Machine (SVM) for accurate leak detection. Experimentation on 413 labeled acoustic samples achieved classification accuracies of 96.1% (training set) and 97.4% (test set). This approach enhances detection precision and offers a scalable solution for real-time monitoring, with significant practical implications for improving water distribution system management and decision-making.},
  archive      = {J_EAAI},
  author       = {Yiwei Xie and Mengze Gao and Fan Luo and Ao Zhou and Yunfeng Yang and Jian Hu and Wei Jiang and Yuanyao Ye},
  doi          = {10.1016/j.engappai.2025.110525},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110525},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Django-based framework database for leakage detection using machine learning for water distribution networks},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maneuvering target interception via deep reinforcement
learning guidance using only line-of-sight rate measurement.
<em>EAAI</em>, <em>149</em>, 110523. (<a
href="https://doi.org/10.1016/j.engappai.2025.110523">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intercepting a maneuvering target based solely on line-of-sight (LOS) rate measurement constitutes a classic partially observable Markov decision process (POMDP), posing significant challenges in formulating the interceptor&#39;s guidance law. To improve the interception probability, reduce energy consumption, and enhance the robustness of the guidance law for intercepting maneuvering targets, a deep reinforcement learning (DRL) compensated guidance law based on the gated recurrent unit (GRU) neural network is proposed. Firstly, based on the collision triangle, a three-dimensional uncertain confrontation model of maneuvering target and interceptor is established, and then the compensation of proportional guidance law is designed as the DRL action, which effectively improves the learning efficiency of the agent. Finally, a POMDP model for interception is established, and a process reward model with energy consumption and a soft terminal reward model with a “transition section&quot; is proposed. GRU is used to fully mine the characteristics of the LOS rate time series, and a high-performance interception policy is explored based on the proximal policy optimization algorithm. Monte Carlo simulation results reveal that the novel guidance law achieves an average miss distance value of 0.091 m (m) and energy consumption of 192.26 m per second ( m ⋅ s − 1 ), outperforming traditional guidance laws with improved interception probability and lower energy consumption.},
  archive      = {J_EAAI},
  author       = {Leliang Ren and Yong Xian and Zhenyu Liu and Shaopeng Li and Daqiao Zhang and Weilin Guo},
  doi          = {10.1016/j.engappai.2025.110523},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110523},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Maneuvering target interception via deep reinforcement learning guidance using only line-of-sight rate measurement},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). What is behind the curtain? Increasing transparency in
reinforcement learning with human preferences and explanations.
<em>EAAI</em>, <em>149</em>, 110520. (<a
href="https://doi.org/10.1016/j.engappai.2025.110520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we investigate whether the transparency of a robot’s behaviour is improved when human preferences on the actions the robot performs are taken into account during the learning process. For this purpose, a shielding mechanism called Preference Shielding is proposed and included in a reinforcement learning algorithm to account for human preferences. We also use the shielding to decide when to provide explanations of the robot’s actions. We carried out a within-subjects study involving 26 participants to evaluate the robot’s transparency. Results indicate that considering human preferences during learning improves legibility compared with providing only explanations. In addition, combining human preferences and explanations further amplifies transparency. Results also confirm that increased transparency leads to an increase in people’s perception of the robot’s safety, comfort, and reliability. These findings show the importance of transparency during learning and suggest a paradigm for robotic applications when a robot has to learn a task in the presence of or in collaboration with a human.},
  archive      = {J_EAAI},
  author       = {Georgios Angelopoulos and Luigi Mangiacapra and Alessandra Rossi and Claudia Di Napoli and Silvia Rossi},
  doi          = {10.1016/j.engappai.2025.110520},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110520},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {What is behind the curtain? increasing transparency in reinforcement learning with human preferences and explanations},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing histopathological image analysis: An explainable
vision transformer approach with comprehensive interpretation methods
and evaluation of explanation quality. <em>EAAI</em>, <em>149</em>,
110519. (<a
href="https://doi.org/10.1016/j.engappai.2025.110519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models are increasingly reshaping medical imaging, with growing attention on ensuring transparency and trust in their decision-making processes. This study presents the Explainable Vision Transformer (XViT), a model specifically designed for histopathological image analysis. By incorporating advanced interpretability techniques, the XViT model addresses three core aspects: feature learning and classification, generating explainable outputs, and qualitatively evaluating these explanations. Three novel interpretability methods are introduced: attention-based, model-agnostic, and gradient-based, offering diverse perspectives on model behavior. The model&#39;s performance and generalizability were rigorously evaluated on two histopathological datasets: lung colon 25000 (LCS25000) with 96.2% accuracy across three classes and Kangbuk Samsung Hospital (KBSMC) with 88.6% accuracy across four classes. XViT provides actionable insights by highlighting diagnostically relevant regions in input images, significantly enhancing clinical trust and decision-making. The evaluation of its explainability methods through metrics like sensitivity, faithfulness, and complexity demonstrated that layer-wise relevance propagation for transformers outperforms standard techniques like local interpretable model-agnostic explanations (LIME) and attention visualization. This robust performance underscores the XViT model&#39;s potential to bridge the gap between AI accuracy and interpretability in medical imaging. Our findings emphasize the need for well-defined evaluation criteria when comparing interpretability methods and highlight the model&#39;s potential for integration into clinical workflows. This work represents a step forward in creating reliable and interpretable AI solutions, ensuring that the benefits of advanced deep learning models extend seamlessly into practical healthcare settings.},
  archive      = {J_EAAI},
  author       = {Aqib Nazir Mir and Danish Raza Rizvi and Md Rizwan Ahmad},
  doi          = {10.1016/j.engappai.2025.110519},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110519},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing histopathological image analysis: An explainable vision transformer approach with comprehensive interpretation methods and evaluation of explanation quality},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automated processing of eXplainable artificial intelligence
outputs in deep learning models for fault diagnostics of large
infrastructures. <em>EAAI</em>, <em>149</em>, 110518. (<a
href="https://doi.org/10.1016/j.engappai.2025.110518">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Learning (DL) models processing images to recognize the health state of large infrastructure components can exhibit biases and rely on non-causal shortcuts. eXplainable Artificial Intelligence (XAI) can address these issues but manually analyzing explanations generated by XAI techniques is time-consuming and prone to errors. This work proposes a novel framework that combines post-hoc explanations with semi-supervised learning to automatically identify anomalous explanations that deviate from those of correctly classified images and may therefore indicate model abnormal behaviors. This significantly reduces the workload for maintenance decision-makers, who only need to manually reclassify images flagged as having anomalous explanations. The proposed framework is applied to drone-collected images of insulator shells for power grid infrastructure monitoring, considering two different Convolutional Neural Networks (CNNs), GradCAM explanations and Deep Semi-Supervised Anomaly Detection. The average classification accuracy on two faulty classes is improved by 8 % and maintenance operators are required to manually reclassify only 15 % of the images. We compare the proposed framework with a state-of-the-art approach based on the faithfulness metric: the experimental results obtained demonstrate that the proposed framework consistently achieves F 1 scores larger than those of the faithfulness-based approach. Additionally, the proposed framework successfully identifies correct classifications that result from non-causal shortcuts, such as the presence of ID tags printed on insulator shells.},
  archive      = {J_EAAI},
  author       = {G. Floreale and P. Baraldi and E. Zio and O. Fink},
  doi          = {10.1016/j.engappai.2025.110518},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110518},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automated processing of eXplainable artificial intelligence outputs in deep learning models for fault diagnostics of large infrastructures},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessment of hybrid kernel function in extreme support
vector regression model for streamflow time series forecasting based on
a bayesian estimator decomposition algorithm. <em>EAAI</em>,
<em>149</em>, 110514. (<a
href="https://doi.org/10.1016/j.engappai.2025.110514">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diverse decomposition algorithms have been widely employed to streamflow time series forecasting. Their applications, however, are hindered by the plausible high accuracy in the overall decomposition-based framework. This paper firstly introduces a novel decomposition algorithm named Bayesian estimator of abrupt change, seasonality and trend (BEAST) into streamflow forecasting to alleviate the boundary effect. Practical samples are generated under the modified two-stage decomposition prediction (TSDP) framework. A hybrid kernel function, which benefits from two different standalone ones, is designed for kernel extreme support vector regression and the HKESVR model is trained on the samples using 10-fold cross-validation strategy. Comparative experiments are conducted on three monthly streamflow series from basins with diverse hydroclimatic conditions. The results in different lead times (1-, 3-, and 5-month-ahead) show that the BEAST algorithm imposes an average improvement of 5.14% and 12.25% for the root-mean-square error and Nash-Sutcliffe efficiency coefficient respectively on the standalone models and shares a comprehensive similar performance on the mean absolute percentage error. And the nonparametric test results reveal that the BEAST method shows a significant improvement on the comprehensive performance compared with a conventional decomposition method. By contrast, the differences between machine learning models are much smaller. The hybrid kernel function works well in some specific cases in which the standalone kernel function fails. The hybrid BEAST-HKESVR is reliable enough to rank the second place among the fifteen tested models. Finally, the effects of hyperparameters in the BEAST algorithm are discussed and relevant suggestions on them are provided.},
  archive      = {J_EAAI},
  author       = {Peng Shi and Lei Xu and Simin Qu and Hongshi Wu and Qiongfang Li and Yiqun Sun and Xiaoqiang Yang and Wei Gao},
  doi          = {10.1016/j.engappai.2025.110514},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110514},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Assessment of hybrid kernel function in extreme support vector regression model for streamflow time series forecasting based on a bayesian estimator decomposition algorithm},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-stage manifold preserving mixed supervised learning for
bogie fault diagnosis under variable conditions. <em>EAAI</em>,
<em>149</em>, 110512. (<a
href="https://doi.org/10.1016/j.engappai.2025.110512">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bogie fault diagnosis for bogie is crucial to the safety of rail systems. However, since bogies work under normal states most of the time, the sporadic faulty samples are often submerged in massive normal samples, which are difficult to be distinguished and labeled. Therefore, the labeled training data are always insufficient or even lack of some certain fault states (novel faults), which brings great challenges to fault diagnosis, especially under variable working conditions. Therefore, this paper proposes a new framework named dual-stage manifold preserving mixed supervised learning (d-MMSL) to simultaneously absorb from labeled and unlabeled data effectively. Firstly, manifold similarity (MSLP) is presented to cluster unlabeled samples according to one-off calculation of the manifold similarity. In MSLP, the Best-versus-Second-Best differences and uncertain values are utilized to measure manifold distance and maintain the inherent structure of data. Secondly, Local manifold regularization - broad learning system (LMR-BLS) is presented to o deal with the problem of linear and nonlinear function transformation using simple incremental structure, which could further separate fuzzy sets from MSLP and distinguish the operation conditions of known states accurately. The proposed framework has been verified by a classical dataset and actual vibration data collected from bogies, which achieves a F1-score of 0.99. It is proven that this framework outperforms traditional methods in accuracy and efficiency.},
  archive      = {J_EAAI},
  author       = {Ning Wang and Limin Jia and Yong Qin and Dechen Yao and Jianwei Yang and Zhipeng Wang},
  doi          = {10.1016/j.engappai.2025.110512},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110512},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dual-stage manifold preserving mixed supervised learning for bogie fault diagnosis under variable conditions},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weighted class-aware matching adaptation network for
aero-engine imbalanced multi-source cross-domain fault diagnosis under
class shift. <em>EAAI</em>, <em>149</em>, 110510. (<a
href="https://doi.org/10.1016/j.engappai.2025.110510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation methods have been effectively applied in aero-engine fault diagnosis to address the issue of data distribution shifts. In practice, fault data for aero-engines are often collected from multiple source domains, each containing only a subset of health states, leading to class shift. Furthermore, the collection of fault data is costly, resulting in a long-tail distribution. However, most existing research focuses on single-source domain settings and lacks a unified framework to address both class shift and class imbalance. To address this gap, a weighted class-aware matching adaptation network is proposed. By leveraging the maximum mean discrepancy metric, we design a class-aware domain discrepancy metric that models class discrepancies between the source and target domains, enhancing alignment at class boundaries. This metric also integrates class balance weights to emphasize minority classes in a cost-sensitive manner. Moreover, a class-aware health state recognition loss encourages the model to focus on source domains resembling the target domain, enhancing knowledge transfer. Finally, the proposed method is validated through cross-domain fault diagnosis experiments using the turbofan engine fault dataset and the Case Western Reserve University bearing dataset, demonstrating its effectiveness compared to several advanced methods.},
  archive      = {J_EAAI},
  author       = {Yu-Qiang Wang and Yong-Ping Zhao and Bo-Yu Liang and Tian-Ding Zhang and Kuan-Xin Hou},
  doi          = {10.1016/j.engappai.2025.110510},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110510},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Weighted class-aware matching adaptation network for aero-engine imbalanced multi-source cross-domain fault diagnosis under class shift},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Applications of artificial intelligence in industry 4.0 and
smart manufacturing. <em>EAAI</em>, <em>149</em>, 110509. (<a
href="https://doi.org/10.1016/j.engappai.2025.110509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This special issue was initiated at the 10th IFAC triennial conference MIM 2022 concerning the topics dealing with applications of artificial intelligence in Industry 4.0, for especially process planning, reconfigurable manufacturing, robotics, production planning, fault detection and diagnostics.},
  archive      = {J_EAAI},
  author       = {Audrey Cerqueus and Alexandre Dolgui and Dmitry Ivanov and Alexandr Klimtchik and David Lemoine and Anatol Pashkevich},
  doi          = {10.1016/j.engappai.2025.110509},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110509},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Applications of artificial intelligence in industry 4.0 and smart manufacturing},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hyperspectral image mixed noised removal via jointly spatial
and spectral difference constraint with low-rank tensor factorization.
<em>EAAI</em>, <em>149</em>, 110508. (<a
href="https://doi.org/10.1016/j.engappai.2025.110508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The denoising of hyperspectral image (HSI) plays a crucial role in the subsequent interpretation and application. The rise of artificial intelligence technology has brought new opportunities for hyperspectral image denoising, and its potential and advantages in this field are gradually changing the traditional denoising pattern. This paper proposes a jointly spatial and spectral difference constraints with low-rank tensor factorization. Firstly, the spatial and spectral difference is combined in the framework of low-rank tensor factorization, to fully mine global spatial–spectral information and improve the removal ability of complex distribution noise. Secondly, based on the premise of effectively preserving HSI intrinsic three-dimensional structure, the spatial horizontal and vertical difference constraints are used to mine the local smoothness and similarity of spatial. Thirdly, the full-band spectral difference constraint could not only characterize the continuity and sparsity of the whole spectral domain, but also effectively characterize the noise distribution with linear structure. Finally, experiments on simulated and real HSIs show that the proposed method outperforms state-of-the-art methods in removing mixed noise performance.},
  archive      = {J_EAAI},
  author       = {Qiang Zhang and Yaming Zheng and Yushuai Dong and Chunyan Yu and Qiangqiang Yuan},
  doi          = {10.1016/j.engappai.2025.110508},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110508},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hyperspectral image mixed noised removal via jointly spatial and spectral difference constraint with low-rank tensor factorization},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An image segmentation method for solid-liquid separation on
shale shaker based on an improved U2Net. <em>EAAI</em>, <em>149</em>,
110507. (<a
href="https://doi.org/10.1016/j.engappai.2025.110507">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the actual production process of shale shakers, detecting the solid-liquid separation state of the screen surface faces numerous challenges, such as difficulty in recognizing the mud boundary, insufficient anti-interference ability, and misjudgment caused by background interference. To address these issues, this paper proposes a screen surface mud image segmentation method based on U 2 Net, namely CBAM-U 2 Net. By introducing the Convolutional Block Attention Module (CBAM) and combining it with Multi-layer Recursive Residual Blocks (RSU), a network structure is designed that can efficiently fuse global and local features, significantly improving segmentation accuracy and robustness. The network includes encoder and decoder parts, employing convolution, batch normalization, ReLU activation, and multi-scale feature fusion strategies. Experimental results show that the CBAM-U 2 Net method demonstrates excellent segmentation performance under various working conditions, achieving outstanding results with mIoU, F1-score, Precision, and Recall at 83.38%, 89.75%, 89.38%, and 92.64%, respectively, with significantly enhanced anti-interference capability. The CBAM-U 2 Net method provides an efficient and reliable solution for the intelligent monitoring of the solid-liquid separation state in shale shakers, offering significant practical application value.},
  archive      = {J_EAAI},
  author       = {Wenbin Wang and Yongjun Hou and Rui Jiang and Pan Fang and Hong Peng and Qing Li and Huachuan Li},
  doi          = {10.1016/j.engappai.2025.110507},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110507},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An image segmentation method for solid-liquid separation on shale shaker based on an improved U2Net},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient kriging-based wall deflection prediction in braced
excavation considering model and measurement errors. <em>EAAI</em>,
<em>149</em>, 110506. (<a
href="https://doi.org/10.1016/j.engappai.2025.110506">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The deflection prediction of diaphragm walls stands as a critical aspect of safety management for excavation construction. Bayesian updating holds a prominent position among several existing prediction methods, owing to its probabilistic predictions and the ability to simultaneously consider prior knowledge and observational data. This paper develops a comprehensive Bayesian updating framework for wall deflection prediction in braced excavation, taking into account both model error associated with the prediction model chosen and measurement error. Further, both of these errors typically exhibit depth dependency and spatial correlation and thus are modeled as stochastic processes. An innovative efficient Kriging (e-Kriging) surrogate model and an Expectation-Maximum algorithm based adaptive importance sampling (AIS) method are proposed to improve computational efficiency. The prediction performance of this proposed framework is verified via an exhaustively reported Taipei National Enterprise Center (TNEC) excavation project. Moreover, this paper compares the influences of different selections of prior distributions and measurement data on the predictions. Results suggest that using only a subset of the middle portion of measurement data for updating is often a more appropriate choice.},
  archive      = {J_EAAI},
  author       = {Xiong Xiao and Quanwang Li and Hao Zhang},
  doi          = {10.1016/j.engappai.2025.110506},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110506},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Efficient kriging-based wall deflection prediction in braced excavation considering model and measurement errors},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Consistency-based decision-making method with linguistic
q-rung orthopair fuzzy preference relation for power battery selection
of new energy vehicles. <em>EAAI</em>, <em>149</em>, 110505. (<a
href="https://doi.org/10.1016/j.engappai.2025.110505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of global petrochemical depletion and increasingly serious environmental pollution, new energy vehicles, as a key industry to build a sustainable low-carbon society, have been paid more and more attention by countries all over the world. As the “heart” of new energy vehicles, power battery plays an important role in the core competitiveness of enterprises. Aiming at the fuzziness and uncertainty of complex power battery selection, a two-stage consistency optimization model based on preference relations and an interactive consistency improvement process are established in this paper. Firstly, by considering the interaction between membership and non-membership, this paper proposes an improved linguistic q-rung orthopair fuzzy weighted averaging operator. Then, the concept of linguistic q-rung orthopair fuzzy preference relation (Lq-ROFPR) is proposed, and its additive consistency index is given based on linguistic scaling function. Whereafter, for the Lq-ROFPR with unacceptable consistency, an interactive mechanism is proposed to improve the consistency level, which considers the minimum adjustment size of preference modification and the minimum number of adjustment elements in turn. Moreover, the method for solving the multi-attribute decision-making problems is formed and applied to the selection of power batteries in XP automobile company. Finally, the simulation experiment and comparative analysis with other methods show the effectiveness and rationality of this method in consistency optimization.},
  archive      = {J_EAAI},
  author       = {Xin Dong and Peide Liu and Peng Wang and Xiaoming Wu},
  doi          = {10.1016/j.engappai.2025.110505},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110505},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Consistency-based decision-making method with linguistic Q-rung orthopair fuzzy preference relation for power battery selection of new energy vehicles},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Syn-rPPG: Improving unsupervised remote photoplethysmography
extraction with synthesized videos using generative models.
<em>EAAI</em>, <em>149</em>, 110504. (<a
href="https://doi.org/10.1016/j.engappai.2025.110504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote photoplethysmography (rPPG) is a non-contact technology used to capture cardiac activity from the face, providing measurements of physiological parameters. Current unsupervised methods for rPPG tasks often focus on contrastive learning, which highlights relationships between samples but struggles with a lack of diverse training data, particularly in terms of varying skin colors and motion types. This limits model effectiveness in complex real-world scenarios. Generative models offer a potential solution by creating synthetic samples to enrich the training data. In this study, we explore the impact of using synthetic videos generated by style transfer and motion transfer techniques to enhance unsupervised rPPG tasks. We generate two types of synthetic videos: skin color synthetic videos and motion synthetic videos. These address the key challenges in rPPG, namely skin color variations and motion artifacts. Our analysis shows that these synthetic videos provide valuable physiological information, improving the performance and robustness of unsupervised models. Additionally, we propose a novel lightweight rPPG network, Style-Aware rPPG Fusion Net (SAFNet), based on an encoder–decoder structure, which is optimized for joint training with synthetic videos. By incorporating a feature fusion approach, SAFNet captures richer spatiotemporal information, resulting in superior performance and robustness. Extensive experiments on four public benchmark datasets demonstrate that our method achieves excellent results, particularly in challenging conditions, proving the effectiveness of using synthetic data to enhance remote physiological measurements.},
  archive      = {J_EAAI},
  author       = {Tianqi Liu and Hanguang Xiao and Yisha Sun and Kun Zuo and Qihang Zhang and Zhipeng Li and Feizhong Zhou},
  doi          = {10.1016/j.engappai.2025.110504},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110504},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Syn-rPPG: Improving unsupervised remote photoplethysmography extraction with synthesized videos using generative models},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Democratizing eye-tracking? Appearance-based gaze estimation
with improved attention branch. <em>EAAI</em>, <em>149</em>, 110494. (<a
href="https://doi.org/10.1016/j.engappai.2025.110494">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Appearance-based gaze estimation in 2-dimensional screen coordinates–the prediction of the users’ gaze from webcam footage–cannot yet compete in accuracy with infrared (IR) eye trackers. Yet by circumventing the constraints of requiring dedicated hardware, it shows great potential in many technological industries, as evidenced by some readily available commercial solutions, bringing democratization of eye tracking closer to the people. We present Residual Appearance-based Gaze Estimation network (RAGE-net), a novel convolutional neural network for gaze estimation without need of calibration, utilizing a fraction of computational resources required by similar networks, while also achieving competitive accuracy. The angular error is measured as 4.08°in the MPIIFaceGaze dataset (Max Planck Institute for Informatics Faze Gaze) and 3.96°in the MPIIGaze dataset. The architecture’s principles, covered by a comprehensive ablation study, include an attention branch, residual learning, weight sharing between eye channels, batch normalization and an eye image input normalization pipeline that removes dependence on full face input. With RAGE-net, we conduct an applicability study for gaze estimation approaches of similar accuracy for interpreting on-screen gaze in praxis. Findings demonstrate low heatmap validity, with coarse heatmaps as potential adaptation to approximate IR eye tracking. The effects of environmental factors such as camera position, illumination, distance and glasses are analyzed in-depth.},
  archive      = {J_EAAI},
  author       = {Eduard Kuric and Peter Demcak and Jozef Majzel and Giang Nguyen},
  doi          = {10.1016/j.engappai.2025.110494},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110494},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Democratizing eye-tracking? appearance-based gaze estimation with improved attention branch},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A three-dimensional dynamic spatial-temporal graph neural
network for ocean temperature field prediction. <em>EAAI</em>,
<em>149</em>, 110492. (<a
href="https://doi.org/10.1016/j.engappai.2025.110492">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of the ocean temperature field is vital for the protection of marine ecosystems under climate change. However, most existing methods only consider temporal changes, ignoring the rich three-dimensional (3D) dynamic spatial characteristics of the ocean temperature field. To improve prediction accuracy, we propose a fine-grained modeling method that uses the spatial correlations in the ocean temperature field, called the 3D Dynamic Spatial-Temporal Graph Neural Network (3D-DSTGN). Specifically, according to the 3D spatial features and dynamic spatial dependencies of the ocean temperature field, we first decompose the spatial correlation of the ocean temperature field into long-term static and short-term dynamic parts through statistical analysis of real ocean temperature datasets. We then build a 3D dynamic graph structure learning module to create static and dynamic graph structures with 3D spatial features to model and capture the corresponding spatial correlations. Next, based on the two graph structures, we apply a dual-mode graph convolution block to fully capture the dynamic spatial dependencies of the ocean temperature field. Furthermore, we use a multi-scale temporal convolution block to capture complex temporal dependencies from historical ocean temperature data. Finally, the dual-mode graph convolution block and the multi-scale temporal convolution block construct the spatio-temporal recurrent module, which extracts complex dynamic spatio-temporal contextual dependencies. On a large-scale real ocean temperature dataset from the sea surface to a subsurface depth of approximately 2,000 m, 3D-DSTGN outperforms other baselines in experiments across different temporal and spatial scales, effectively modeling the dynamic three-dimensional spatial relationships of the ocean temperature field.},
  archive      = {J_EAAI},
  author       = {Shuai Zhang and ZhuoLin Li and XiaoYu He and Jie Yu and LingYu Xu},
  doi          = {10.1016/j.engappai.2025.110492},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110492},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A three-dimensional dynamic spatial-temporal graph neural network for ocean temperature field prediction},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ergonomic conscious scheduling of maintenance activities in
marine vehicles using an optimized non-dominated sorting genetic
algorithm-II – an application of job-shop scheduling. <em>EAAI</em>,
<em>149</em>, 110491. (<a
href="https://doi.org/10.1016/j.engappai.2025.110491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incorporating ergonomics in marine activities is critical due to the extreme working conditions and limited crew in marine vehicles, aiming to enhance productivity and job performance by reducing the risks of fatigue, stress, and work-related musculoskeletal disorders. This paper introduces an innovative analogy of the flexible job-shop scheduling problem with ergonomic considerations (AFJSP-ER) to schedule maintenance activities in marine systems, addressing the dual objectives of optimizing productivity and promoting ergonomic relief. A novel metric, ‘ergonomic impact load’ is introduced to assess the actual workload of the crew by combining the processing time and the rapid entire body assessment (REBA) score of an operation. To solve the AFJSP-ER, an optimized non-dominated sorting genetic algorithm-II (ONSGA) is proposed, incorporating an optimized random crossover (ORX) operator. The ORX operator is fine-tuned using the Taguchi method to determine the optimal number of elements for crossover, while non-dominated sorting ensures the selection of superior individuals after crossover and mutation. The effectiveness of the proposed ONSGA has been validated through extensive experiments on newly developed test instances and using an industrial case study from the ship engine compartment. The results also indicate that the AFJSP-ER approach effectively optimizes productivity and promotes ergonomic relief, offering a practical solution for scheduling in ergonomically challenging marine environments.},
  archive      = {J_EAAI},
  author       = {Shaban Usman and Cong Lu},
  doi          = {10.1016/j.engappai.2025.110491},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110491},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Ergonomic conscious scheduling of maintenance activities in marine vehicles using an optimized non-dominated sorting genetic algorithm-II – an application of job-shop scheduling},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-stage feature aggregation transformer for image rain
and haze joint removal. <em>EAAI</em>, <em>149</em>, 110490. (<a
href="https://doi.org/10.1016/j.engappai.2025.110490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the complex meteorological phenomenon of rain-haze mixtures, resulting from water vapor condensation in real-world rainy environments. Current methodologies predominantly focus on rain removal, often neglecting the image degradation caused by haze. We propose a multi-stage feature aggregation transformer (MFAFormer). The model consists of multiple stages, each comprising an information calibration module and a feature aggregation module. Specifically, the information calibration module extracts local high-frequency rain features, whereas the feature aggregation module extracts global low-frequency haze features and integrates features across stages. Benefiting from multi-stage feature extraction and aggregation, MFAFormer can efficiently and robustly address the complex degradations caused by the simultaneous presence of rain and haze. Additionally, we propose a novel rain and haze mixed dataset RainHaze Synscapes. The dataset contains large variations in rain streaks, haze density, and scene contents. Experimental results indicate that the model surpasses other methods on the dataset. MFAFormer demonstrates a remarkable improvement, achieving a 37.46% increase in peak signal-to-noise ratio (PSNR) and a 10.48% increase in structural similarity (SSIM) compared to the baseline model on the RainHaze Synscapes dataset. This accomplishment offers valuable insights for the research of rain and haze joint removal domain.},
  archive      = {J_EAAI},
  author       = {Zhengran Xia and Lei Dai and Zhihua Chen and Kai Chen and Ran Li},
  doi          = {10.1016/j.engappai.2025.110490},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110490},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-stage feature aggregation transformer for image rain and haze joint removal},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An end-to-end semantic-guided infrared and visible
registration-fusion network for advanced visual tasks. <em>EAAI</em>,
<em>149</em>, 110489. (<a
href="https://doi.org/10.1016/j.engappai.2025.110489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of infrared and visible images is key to complex visual tasks, with image registration as a fundamental initial step. We explore these tasks as a unified registration-fusion process. Traditional global registration may use a multitude of feature points for alignment, achieving global optimality. However, for advanced tasks like pose recognition, object tracking, and person re-identification, the relevant semantic information may not align accurately, impacting fusion effectiveness and task performance. To address this issue, we propose a Semantic-Aware on-Demand registration-fusion network. 1) We design the Semantic-Aware Module, employing Grounding DINO and Segment Anything to capture semantic regions of interest needed for advanced tasks. 2) Combining with the Semantic-Aware Module, we design a Hierarchical Orientation Line operator and a Deep Hybrid Matching to ensure precise feature matching within semantic regions of interest. 3) To enhance fusion visual effects, a novel image fusion module is designed to facilitate high-quality image fusion within these regions. This method is versatile and applicable to a wide range of advanced visual tasks. We compare this method with six image matching and nine image fusion methods, underscoring its efficacy in advanced visual tasks. The experimental results indicate that both the registration module and the fusion module achieve optimal performance individually. When it comes to joint tasks of registration and fusion in visual tasks, our method similarly exhibits the best performance in the 6 × 10 joint tasks.},
  archive      = {J_EAAI},
  author       = {Meng Sang and Housheng Xie and Jingrui Meng and Yukuan Zhang and Junhui Qiu and Shan Zhao and Yang Yang},
  doi          = {10.1016/j.engappai.2025.110489},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110489},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An end-to-end semantic-guided infrared and visible registration-fusion network for advanced visual tasks},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiscale self-attention for unmanned ariel vehicle-based
infrared thermal images detection. <em>EAAI</em>, <em>149</em>, 110488.
(<a href="https://doi.org/10.1016/j.engappai.2025.110488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection and recognition in unmanned aerial vehicle-based images is critical for various applications but is often challenged by complex backgrounds, diverse object scales, densely clustered small objects, and uneven object distributions. This paper introduces a novel deep learning-based artificial intelligence framework that integrates the Multiscale Self-Attention Guidance and Feature Fusion Network with the You Only Look Once model, tailored explicitly for artificial intelligence-driven unmanned aerial vehicle-based infrared thermal image analysis. The proposed methodology offers four key advancements in the You Only Look Once architecture to enhance object detection performance. First, the Multi-Head Self-Attention Transformer module combines global and local information, enabling precise object localization while mitigating the influence of complex backgrounds. Second, the Multiscale Parallel Sampling Feature Fusion module optimizes the fusion of multiscale features. Third, fine-grained shallow feature maps are integrated into the fusion process to detect densely packed small objects accurately. Lastly, the Inverse-Residual Feature Enhancement module, positioned before the detection head, enhances feature extraction for small objects. Experimental evaluations on the High Altitude Infrared Thermal Unmanned Aerial Vehicle dataset demonstrate significant improvements, achieving a Mean Average Precision of 95.1%, Recall of 92.0%, and F1-Score of 91.0%. The framework’s robustness is further validated on the Wildland-fire Infrared Thermal Unmanned Aerial System dataset, achieving a Mean Average Precision of 82.1%, Recall of 88.0%, and F1-Score of 82.0%. Comparative analyses with state-of-the-art methods confirm its superiority and offer a scalable artificial intelligence-driven solution for unmanned aerial vehicle applications, advancing object detection capabilities in critical scenarios.},
  archive      = {J_EAAI},
  author       = {Muhammad Shahroze Ali and Afshan Latif and Muhammad Waseem Anwar and Muhammad Hashir Ashraf},
  doi          = {10.1016/j.engappai.2025.110488},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110488},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multiscale self-attention for unmanned ariel vehicle-based infrared thermal images detection},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent fault diagnosis of nonlinear uncertain
industrial processes based on kernel local–global interval embedding
algorithm. <em>EAAI</em>, <em>149</em>, 110486. (<a
href="https://doi.org/10.1016/j.engappai.2025.110486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of a new generation of Big Data and artificial intelligence, intelligent fault diagnosis of industrial processes including chemical processes, coal mining equipment operations, etc., has become increasingly important. The local–global interval embedding algorithm (LGIEA) has attracted significant attention for its capability to simultaneously extract local and global features from interval data. However, this method can only process linear interval data and performs poorly in terms of extracting strong nonlinear features. To solve the problem, this study proposes a new intelligent fault diagnosis method based on kernel LGIEA (KLGIEA), which extends the linear process monitoring model to nonlinearity. First, the interval inner product estimation (IIPE) is transformed into the kernel IIPE by introducing kernel function, which can not only inherit the advantage that LGIEA can extract both global and local features of data simultaneously, but also has stronger applicability to nonlinear data in industrial processes. Second, the four statistics defined can effectively monitor the fault of industrial equipment under strong interference environment such as noises, and the nonlinear reconstruction contribution (NRC) can effectively identify the fault variables, improve the fault diagnosis ability of KLGIEA. Finally, two cases of the Tennessee Eastman process (TEP) simulation data from Eastman Company and site shearer fault data obtained from Shaqu No. 2 coal mine show that KLGIEA is significantly superior to complete information principal component analysis (PCA), midpoint-radius kernel PCA, and LGIEA in processing nonlinear interval data, improving accuracy, applicability, and reliability of algorithm.},
  archive      = {J_EAAI},
  author       = {Ning Li and Hua Ding and Xiaochun Sun and Zeping Liu},
  doi          = {10.1016/j.engappai.2025.110486},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110486},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent fault diagnosis of nonlinear uncertain industrial processes based on kernel local–global interval embedding algorithm},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed data-driven iterative learning consensus
tracking for unknown multi-agent systems using evolutionary neural
networks. <em>EAAI</em>, <em>149</em>, 110485. (<a
href="https://doi.org/10.1016/j.engappai.2025.110485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides a data-driven distributed parameter adaptive iterative learning consensus tracking strategy for nonlinear nonaffine discrete-time multi-agent systems with unknown dynamics. By transforming the ideal learning controller on the timeline into a direct iterative learning control strategy in the iterative domain, the design of the control protocol is only data-driven. Unlike existing parameter tuning control methods, the parameter tuning approach presented in this paper adjusts the parameters online through topological information, eliminating the need for multiple trials and adjustments based on experience. The gain time variability of multi-agent systems is learned and compensated by the extended generalized regression neural networks evolution control. By introducing a limited incremental evolution mechanism, the optimal control parameters can be adjusted online during the control process to find the system trajectory to achieve optimal output synchronization, so as to improve the control efficiency of iterative learning control. Different from the existing directed fixed topology works of multi-agent systems, the consensus convergence properties of fixed directed communication topologies and iterative time-varying communication topologies along the iterative domain are established by contraction mapping theorem. Two numerical simulation examples are conducted to validate the effectiveness of the proposed control protocol.},
  archive      = {J_EAAI},
  author       = {Kechao Xu and Bo Meng and Zhen Wang},
  doi          = {10.1016/j.engappai.2025.110485},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110485},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Distributed data-driven iterative learning consensus tracking for unknown multi-agent systems using evolutionary neural networks},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-point dam deformation prediction model based on
spatiotemporal graph convolutional network. <em>EAAI</em>, <em>149</em>,
110483. (<a
href="https://doi.org/10.1016/j.engappai.2025.110483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dams are essential for services such as water supply and flood protection, making their structural health and safety crucial to prevent catastrophic failures. Monitoring dam displacement is a critical method for assessing its current condition and predicting future behavior. Most displacement monitoring models primarily focus on temporal features and the relationship between environmental factors and dam displacement, often overlooking the spatial relationships in the data. Even multi-point models, designed to handle multiple measurement locations, struggle to effectively account for the spatial coordination between these points. To address these challenges, this paper proposes a multi-point displacement monitoring model based on a variational auto-encoder (VAE) and a spatiotemporal graph convolutional network (STGCN). The graph structure is utilized to represent the coordinated deformation relationships among monitoring points, while also capturing temporal features and nonlinear relationships between environmental factors and dam displacement. The VAE model is first used to extract latent feature representations from historical monitoring data and monitoring point coordinates. The K-nearest neighbors (KNN) method is then applied to calculate the connection weights between monitoring points, constructing the adjacency matrix. Graph convolutional network (GCN) is utilized to extract spatial features, while gated recurrent units (GRU) capture temporal dependencies, enabling accurate multi-point displacement prediction. The model&#39;s effectiveness and accuracy are validated through comparisons with both single-point and multi-point models, while the impact of K-nearest neighbors and learnable position encoding on model performance is also evaluated. The results demonstrate that the proposed model significantly outperforms others, showing superior predictive accuracy and generalization capabilities.},
  archive      = {J_EAAI},
  author       = {Taiqi Lu and Hao Gu and Chongshi Gu and Chenfei Shao and Dongyang Yuan},
  doi          = {10.1016/j.engappai.2025.110483},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110483},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-point dam deformation prediction model based on spatiotemporal graph convolutional network},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Visual object tracking using learnable target-aware token
emphasis. <em>EAAI</em>, <em>149</em>, 110482. (<a
href="https://doi.org/10.1016/j.engappai.2025.110482">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual object tracking, which involves tracking the spatial location of a target object either within a single viewpoint or across various camera perspectives, is an important task in computer vision. Deep neural networks, especially vision transformers, typically outperform traditional methods and have thus become the preferred choice for visual object tasks. However, existing visual object tracking frameworks still struggle to adapt to targets with continuously changing appearances within the current frame, as they rely heavily on the static initial target template rather than continuously emphasizing the evolving target features. In this paper, we introduce a visual object tracking network with a learnable target-aware token emphasis, which is composed of vision transformer backbone embedded in the token emphasizer, localization head and target template update decision module. The learnable target-aware token emphasizer and target template update decision modules in the proposed model contribute to stabilizing visual object tracking across various scenarios. This is achieved not only by emphasizing features that have a relationship between the target template and the search region but also by reducing irrelevant features and consistently updating the high-quality target template online during the process. Qualitative and quantitative analyses, including ablation analysis across a diverse set of tracking benchmark datasets, validate the robustness of the proposed tracking framework. The code and trained models are available at https://github.com/qkdkralsgh/TETrack .},
  archive      = {J_EAAI},
  author       = {Minho Park and Jinjoo Song and Sang Min Yoon},
  doi          = {10.1016/j.engappai.2025.110482},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110482},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Visual object tracking using learnable target-aware token emphasis},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Phased noise enhanced multiple feature discrimination
network for fabric defect detection. <em>EAAI</em>, <em>149</em>,
110480. (<a
href="https://doi.org/10.1016/j.engappai.2025.110480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fabric defect detection is crucial for evaluating the quality of textile products. However, the subtlety and scarcity of fabric defects pose challenges to the task of detecting. Therefore, we propose a P hased N oise Enhanced M ultiple F eature D iscrimination Network, which is based on phased noise enhancement strategy and multiple feature discrimination module to improve the model’s ability to identify complex and subtle flaws. Specifically, we propose the phased noise enhancement strategy in the feature space to simulate feature-level anomalies that are closer to reality. This strategy can improve the input quality of the feature reconstructor, so that helps its perception and reconstruction ability. Then, we propose the multiple feature discrimination module, which has dual feature branches to improve its ability to distinguish more complex detailed texture features. In addition, we propose a subsampling module to reduce feature redundancy and ensure efficient inference speed. Finally, we conduct extensive experiments and ablation studies on two publicly available fabric datasets, AITEX and Kaggle Fabric. The experimental results show that the proposed method achieved 92% and 100% image level metrics and 97.5% and 67.1% pixel level metrics on two datasets, respectively, which is superior to the current state-of-the-art methods. In addition, our method also demonstrated significant performance in generalization experiments.},
  archive      = {J_EAAI},
  author       = {Haoran Ma and Zuoyong Li and Haoyi Fan and Xiangpan Zheng and Jiaquan Yan and Rong Hu},
  doi          = {10.1016/j.engappai.2025.110480},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110480},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Phased noise enhanced multiple feature discrimination network for fabric defect detection},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Information extraction from multi-layout invoice images
using FATURA dataset. <em>EAAI</em>, <em>149</em>, 110478. (<a
href="https://doi.org/10.1016/j.engappai.2025.110478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document analysis and understanding models often require extensive annotated data to be trained. However, various document-related tasks extend beyond mere text transcription, requiring both textual content and precise bounding-box annotations to identify different document elements. Collecting such data becomes particularly challenging, especially in the context of invoices, where privacy concerns add an additional layer of complexity. Invoices are critical documents in many business processes, but existing datasets for invoice analysis are limited in size and diversity, hindering the development of robust models. Current datasets do not adequately address the need for diverse layouts and comprehensive annotations, which are essential for training models capable of handling real-world variations in invoice documents. In this paper, we introduce FATURA, a pivotal resource for researchers in the field of document analysis and understanding. FATURA is a highly diverse dataset featuring multi-layout, annotated invoice document images. Comprising 10,000 invoices with 50 distinct layouts, it represents the largest openly accessible image dataset of invoice documents known to date. We provide an extensive evaluation using different information extraction methods under diverse training and evaluation scenarios, including precision, recall, and F1-score. The evaluation includes a visual-based approach using object detection for text region classification, a multi-modal strategy integrating visual and textual data for granular content comprehension, and a hybrid approach combining these methods. The dataset is freely accessible at this https://zenodo.org/record/8261508 , empowering researchers to advance the field of document analysis and understanding.},
  archive      = {J_EAAI},
  author       = {Mahmoud Limam and Marwa Dhiaf and Yousri Kessentini},
  doi          = {10.1016/j.engappai.2025.110478},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110478},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Information extraction from multi-layout invoice images using FATURA dataset},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite time multilayer neural network command filter
backstepping controller design for large scale uncertain nonlinear
systems. <em>EAAI</em>, <em>149</em>, 110474. (<a
href="https://doi.org/10.1016/j.engappai.2025.110474">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel dynamical multilayer neural network finite time command filter backstepping control scheme. This method realizes the finite time robust tracking control of uncertain nonlinear system. The uncertainty in system varies in large scale around system states. Its boundary is unknown and unavailable before design. The multilayer neural network (MNN) approximater is redesigned into the backstepping controller instead of the common radial basis function (RBF) neural network (NN) and Fuzzy System (FS) to realize the accuracy approximation of the large scale uncertain structure. The introduction of the MNN approximater overcomes the drawback of local identification constraint of RBF NN and Fuzzy System without the structure knowledge and boundary of uncertainty before design. Otherwise, owing to the MNN structure is more complex than common three layer RBF NN, the approximation costs more time to dynamically tune weight parameters online. In order to make up the time consistent between the MNN approximation and the backstepping process, the finite time (FT) command filter (CF) backstepping control strategy balancing the two distinct procedures guarantees the MNN identification of larger scale uncertainty and backstepping control process consistently convergence into a smaller area in uniform finite time interval. Finally, through a practical example, the effectiveness and advantages of are illustrated by comparison between this mechanism and traditional RBF NN method.},
  archive      = {J_EAAI},
  author       = {Qitian Yin and Quanqi Mu and Jianbai Yang},
  doi          = {10.1016/j.engappai.2025.110474},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110474},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Finite time multilayer neural network command filter backstepping controller design for large scale uncertain nonlinear systems},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HT-AggNet: Hierarchical temporal aggregation network with
near-zero-cost layer stacking for human activity recognition.
<em>EAAI</em>, <em>149</em>, 110465. (<a
href="https://doi.org/10.1016/j.engappai.2025.110465">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the steady growth of sensor technology and wearable devices in pervasive computing applications, sensor-based human activity recognition has gained attention in fields such as healthcare monitoring and fitness tracking. This has resulted in an increased need for accurate and real-time systems. Recent studies to satisfy the real-time conditions have attempted to design lightweight neural networks by mainly restricting the number of layers shallowly, which has decreased both inference time and accuracy. To recover the loss of accuracy, we propose an innovative hierarchical temporal aggregation network (HT-AggNet) that allows the network architecture to be deeper, leading to an accuracy gain with only a near-zero increase in computational cost. Furthermore, a temporal glance convolution is presented to model the global context information of the signal patterns. Consequently, the HT-AggNet hierarchically extracts the local and global temporal information and then merges them based on hierarchical temporal aggregation. In our experiments, the HT-AggNet outperformed existing methods on seven publicly available datasets and achieved state-of-the-art performance. The source code for the HT-AggNet is publicly available at https://github.com/jgpark92/HT-AggNet .},
  archive      = {J_EAAI},
  author       = {Jaegyun Park and Dae-Won Kim and Jaesung Lee},
  doi          = {10.1016/j.engappai.2025.110465},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110465},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {HT-AggNet: Hierarchical temporal aggregation network with near-zero-cost layer stacking for human activity recognition},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reliability evaluation of solar integrated power
distribution systems using an evolutionary swarm algorithm.
<em>EAAI</em>, <em>149</em>, 110464. (<a
href="https://doi.org/10.1016/j.engappai.2025.110464">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The reliability of solar-integrated power distribution systems is significantly affected by intermittent solar generation and its impact on feeder voltages. While existing adequacy studies account for intermittency, they frequently overlook feeder voltages due to the computational burden of the Alternating Current Optimal Power Flow (AC-OPF) analysis. Addressing this gap, we propose an efficient framework based on an Evolutionary Swarm Algorithm (ESA) to integrate AC-OPF analysis into the reliability evaluation of power distribution systems. The sampling mechanism of ESA reduces the application of time-consuming AC-OPF and allows the fast estimation of reliability indices. The performance of the proposed framework is compared with Sequential Monte Carlo Simulation (SMCS), classical meta-heuristics, and three state-of-the-art meta-heuristics. Results demonstrate that our proposed framework can estimate the reliability indices approximately 34 times faster than SMCS without sacrificing accuracy. Furthermore, the ESA outperforms classical and state-of-the-art methods by over 23% in event sampling efficiency. Friedman and Nemenyi post-hoc tests conclude that ESA’s results significantly differ from others. We utilize the proposed framework in a case study to analyze the influence of solar photovoltaic integration on distribution system reliability. Another case study investigates the impact of dynamic tap changing of power transformers on the reliability improvement of distribution systems.},
  archive      = {J_EAAI},
  author       = {P.A.G.M. Amarasinghe and S.K. Abeygunawardane and C. Singh},
  doi          = {10.1016/j.engappai.2025.110464},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110464},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reliability evaluation of solar integrated power distribution systems using an evolutionary swarm algorithm},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic feature capturing in a fluid flow reduced-order
model using attention-augmented autoencoders. <em>EAAI</em>,
<em>149</em>, 110463. (<a
href="https://doi.org/10.1016/j.engappai.2025.110463">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study looks into how adding adaptive attention to convolutional autoencoders can help reconstruct flow fields in fluid dynamics applications. The study compares the effectiveness of the proposed adaptive attention mechanism with the convolutional block attention module approach using two different sets of datasets. The analysis encompasses the evaluation of reconstruction loss, latent space characteristics, and the application of attention mechanisms to time series forecasting. Combining adaptive attention with involution layers enhances its ability to identify and highlight significant features, surpassing the capabilities of the convolutional block attention module. This result demonstrates an increase of over 20% in the accuracy of reconstruction. Latent space analysis shows the adaptive attention mechanism’s complex and flexible encoding, which makes it easier for the model to represent different types of data. The study also looks at how attention works and how it affects time series forecasting. It shows that a new method that combines multi-head attention and bidirectional long-short-term memory works well for forecasting over 5 s of futures of flow fields. This research provides valuable insights into the role of attention mechanisms in improving model accuracy, generalization, and forecasting capabilities in the field of fluid dynamics.},
  archive      = {J_EAAI},
  author       = {Alireza Beiki and Reza Kamali},
  doi          = {10.1016/j.engappai.2025.110463},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110463},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic feature capturing in a fluid flow reduced-order model using attention-augmented autoencoders},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient generation of power system topology diagrams based
on graph neural network. <em>EAAI</em>, <em>149</em>, 110462. (<a
href="https://doi.org/10.1016/j.engappai.2025.110462">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Power system topology diagrams illustrate the physical and spatial relationship of system nodes and are widely used as a basic tool for displaying system structure. Well-presented topology diagrams provide better situational awareness for the operators, but their efficient generation remains a challenge. Existing approaches struggle to find a balance between visual aesthetics and the generation speed of the diagram. With the rapid changes in power system topology, there is a higher demand for the rendering speed of the graph data. To satisfy both the real-time requirement and the aesthetic quality, this paper proposes an integrated framework for efficiently generating power system topology diagrams. It consists of a Graph Neural Network (GNN) model and a graph fine-tuning model. This framework can directly optimize the raw topology diagram while preserving the relative positions of nodes in the initial layout. It achieves a decent trade-off between layout quality and computational expenses, enabling the generation of aesthetically satisfactory diagrams in a short time. Due to the strong generalization ability of GNN, the proposed model can be trained on small system datasets and used for inference on large systems. Case studies verify that the proposed GNN model can optimize the aesthetic metrics of topology diagram layouts within seconds to an average value of 0.55. Finally, it can be used in power system applications as a fundamental tool for topology diagram generation and optimization.},
  archive      = {J_EAAI},
  author       = {Chen Yang and Shengyang Wu and Tao Liu and Yixuan He and Jingyu Wang and Dongyuan Shi},
  doi          = {10.1016/j.engappai.2025.110462},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110462},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Efficient generation of power system topology diagrams based on graph neural network},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing small satellite image resolution via shrinking
rearranged mechanism and multiscale reparameterized attention.
<em>EAAI</em>, <em>149</em>, 110460. (<a
href="https://doi.org/10.1016/j.engappai.2025.110460">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small satellites, weighing under 1,000 kg, are increasingly used in defense, civil, and commercial sectors due to their cost-effectiveness and portability. However, their imaging resolution is limited by the size and cost of their apertures. Existing super-resolution (SR) algorithms struggle to reconstruct large-area surface information and fine local textures, and often require high computing power, making them unsuitable for small satellites. This study proposes a lightweight super-resolution network, MSRN (Multiscale Shrinking Rearranged Attention Network), engineered for deployment on small satellites. Specifically, MSRN employs a shrinking window-partition strategy to extract different ranges of feature priors and capture local high-frequency details. It also uses a channel rearranged mechanism to expand the receptive field and extract global context information. Additionally, a multiscale reparameterized attention group is designed to efficiently extract features and contours of objects at various scales, enhancing channel information representation. The use of reparameterization technology simplifies the model and enables fast response and processing of small satellite image data. Multiple comparisons on several popular public remote sensing datasets demonstrate that MSRN outperforms mainstream methods in terms of resource occupancy and reconstruction performance, and exhibits strong robustness and generalization across different scenarios.},
  archive      = {J_EAAI},
  author       = {Zhibo Zhao and Hu Liang and Yuchen Liu and Shengrong Zhao},
  doi          = {10.1016/j.engappai.2025.110460},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110460},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing small satellite image resolution via shrinking rearranged mechanism and multiscale reparameterized attention},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantically complex audio to video generation with audio
source separation. <em>EAAI</em>, <em>149</em>, 110457. (<a
href="https://doi.org/10.1016/j.engappai.2025.110457">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in artificial intelligence for audio-to-video generation have shown the ability to generate high-quality videos from audio, particularly by focusing on temporal semantics and magnitude. However, existing works struggle to capture all semantics from audio, as real world audios often consist of mixed sources, making it challenging to generate semantically aligned videos. To solve this problem, we present a novel multi-source audio-to-video generation framework that incorporates decomposed multiple audio sources into video generative models. Specifically, our proposed Attention Mosaic directly maps each decomposed audio feature to the corresponding spatial attention feature. In addition, our condition injection module is helpful for producing more natural contexts with non-audible objects by leveraging the knowledge of existing generative models. Our experiments show that the proposed framework achieves state-of-the-art performance in representing both multi- and single-source audio-to-video generation methods.},
  archive      = {J_EAAI},
  author       = {Sieun Kim and Jaehwan Jeong and Sumin In and Seung Hyun Lee and Seungryong Kim and Saerom Kim and Wooyeol Baek and Sang Ho Yoon and Eugenio Culurciello and Sangpil Kim},
  doi          = {10.1016/j.engappai.2025.110457},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110457},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Semantically complex audio to video generation with audio source separation},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel multivariate nonlinear time-delayed grey model for
forecasting electricity consumption. <em>EAAI</em>, <em>149</em>,
110452. (<a
href="https://doi.org/10.1016/j.engappai.2025.110452">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and stable annual electricity consumption forecasting play vital role in modern social and economic development, which can provide effective planning and guaranteeing a reliable supply of sustainable electricity. Given that electricity consumption series present nonlinearity, poor information, and time-delayed characteristics, this paper proposes a multivariate nonlinear time-delayed grey model. Three primary efforts have been made as follows. First, we introduce the nonlinear and time-delayed terms into the typical multivariate grey model to identify the relationship between electricity consumption sequence and its driving factor sequence. Second, based on the Monte-Carlo simulation, an intelligent algorithm matching framework is designed to seek for the optimal model parameters of the model, which enhances the model’s applicability and flexibility. Third, we use datasets of China’s and America’s electricity consumption from 2000 to 2021 to validate the effectiveness of the newly-proposed model. Additionally, sensitivity analysis under different time horizons further verifies the model’s robustness. The experiment results indicates the superior prediction accuracy and robustness when comparing with other prevailing benchmarks. Overall, the newly-designed model is an effective technique for forecasting electricity consumption in China and America. Based on this, the forecasts of China’s and America’s electricity consumption in the following years can serve as a valuable reference for formulating related policies.},
  archive      = {J_EAAI},
  author       = {Wen-Ze Wu and Naiming Xie},
  doi          = {10.1016/j.engappai.2025.110452},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110452},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel multivariate nonlinear time-delayed grey model for forecasting electricity consumption},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep reinforcement learning assisted adaptive genetic
algorithm for flexible job shop scheduling. <em>EAAI</em>, <em>149</em>,
110447. (<a
href="https://doi.org/10.1016/j.engappai.2025.110447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The flexible job shop scheduling problem (FJSP) is a challenging combinatorial optimization problem in manufacturing systems. Existing intelligent optimization algorithms for FJSP are often hard to tune key parameters and operations efficiently, which losses the optimality of the obtained solution. To address the issues of genetic algorithms (GA) being prone to local optima and slow convergence, this paper proposes a deep reinforcement learning-assisted adaptive genetic algorithm (DRL-A-GA) for solving FJSP. In the proposed algorithm, continuous state vectors are used to represent the population state of the GA, and four mutation operations with respect to FJSP are designed as actions. Deep reinforcement learning is employed to adaptively tune the key parameters of the GA and dynamically select appropriate genetic operations. To validate the performance of DRL-A-GA, three sets of benchmark instances are selected for testing, and the results are compared with those of classical optimization algorithms and hybrid algorithms. The experimental results demonstrate that the proposed DRL-A-GA significantly outperforms both traditional optimization and intelligent hybrid optimization algorithms for solving FJSP, effectively improving solution quality and accelerating convergence.},
  archive      = {J_EAAI},
  author       = {Jian Ma and Weinan Gao and Weitian Tong},
  doi          = {10.1016/j.engappai.2025.110447},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110447},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep reinforcement learning assisted adaptive genetic algorithm for flexible job shop scheduling},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An enhanced artificial bee colony algorithm with
self-learning optimization mechanism for multi-objective path planning
problem. <em>EAAI</em>, <em>149</em>, 110444. (<a
href="https://doi.org/10.1016/j.engappai.2025.110444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, path planning has been one of the most concerned problems in mobile robotics. This study investigates a multi-objective path planning problem focused on minimizing path length and maximizing path safety. Based on the characteristics of this problem, a mathematical model is established, and then an enhanced artificial bee colony algorithm is proposed to solve this problem. In the proposed algorithm, a new hybrid initialization strategy is designed to generate a high-quality initial population. In the employed bee phase, in addition to the crossover and mutation operators, two objective-oriented evolutionary operators are developed. In the onlooker bee phase, two self-learning optimization mechanisms are applied to the non-dominated and dominated individuals, respectively. Specifically, the collaborative-based optimization mechanism is designed to improve the quality of the non-dominated individuals. The dominance-guide optimization mechanism is developed to guide the dominated individuals to learn from the non-dominated ones. In the scout bee phase, a novel individual-restart strategy that considers the useful information of global best solutions is investigated, which increases the proposed algorithm’s exploration ability. Finally, the proposed algorithm is compared with five state-of-the-art algorithms on sixteen instances from four representative environments. Simulation results show that the proposed algorithm achieved average improvements of 2.60% and 90.77% on the hypervolume and inverted generational distance metrics, respectively, compared with the algorithm with the second-best performance. These demonstrate the effectiveness and high performance of the proposed algorithm for solving multi-objective path planning problems in terms of both population diversity and solution quality.},
  archive      = {J_EAAI},
  author       = {Fan Ye and Peng Duan and Leilei Meng and Hongyan Sang and Kaizhou Gao},
  doi          = {10.1016/j.engappai.2025.110444},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110444},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An enhanced artificial bee colony algorithm with self-learning optimization mechanism for multi-objective path planning problem},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An effective exploration method based on n-step updated
dirichlet distribution and dempster–shafer theory for deep reinforcement
learning. <em>EAAI</em>, <em>149</em>, 110443. (<a
href="https://doi.org/10.1016/j.engappai.2025.110443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning (DRL) has been regarded as a promising approach for solving decision-making problems. However, how to enhance the agent exploration ability is still an extremely challenging issue for existing methods, especially under sparse rewards. Facing with this challenge, we propose a novel efficient exploration method, which can comprehensively consider the uncertainty of the environment and the uncertainty of Q function, so as to improve the agent exploration efficiency. Specifically, we first construct an exploration policy by n-step updated Dirichlet distribution to implement the adaptive exploration of the agent to the environment, which can reduce the uncertainty of the agent about the environment to achieve global efficient exploration. Next, a state–action basic probability assignment (BPA) is constructed based on the Dempster–Shafer theory. On this basis, an interval Q function is designed by combining BPA and belief interval, which can effectively characterize the uncertainty of the Q function to achieve deep exploration. Then, the proposed method is applied to classic DRL algorithms, deep Q-network (DQN) and double DQN (DDQN), two novel algorithms are proposed. Finally, under a series of sparse external reward tasks, experimental results show that our proposed algorithms outperform several state-of-the-art DRL algorithms in term of exploring efficiency.},
  archive      = {J_EAAI},
  author       = {Fanghui Huang and Yixin He and Yu Zhang and Bin Chen and Lina Yang},
  doi          = {10.1016/j.engappai.2025.110443},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110443},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An effective exploration method based on N-step updated dirichlet distribution and Dempster–Shafer theory for deep reinforcement learning},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HMKRec: Optimize multi-user representation by hypergraph
motifs for knowledge-aware recommendation. <em>EAAI</em>, <em>149</em>,
110441. (<a
href="https://doi.org/10.1016/j.engappai.2025.110441">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph-based recommender systems can explore users’ potential interests by learning user similarities, thereby further improving recommendation performance. However, existing methods focus only on the similarity between two users without considering the interaction patterns among multiple users, which overlook the influence of other users in user representation modeling. In this paper, we propose a novel framework using Hypergraph Motifs to optimize Multi-users representation for Recommendation (HMKRec). Specifically, HMKRec constructs a user–item hypergraph and maps it into a user–user adjacency graph. Then, it utilizes hypergraph motifs to model the interaction patterns of multiple users and reconstructs an implicit relationship network with weights and directions to explore high-order associations among multiple users. To learn the features of items and user relationships, we design a hierarchical graph convolution that integrates hypergraph convolutional networks and graph convolutional networks to obtain high-order representations of users. Finally, we propagate user preferences in the knowledge graph using the attention mechanism to obtain high-order representations of items for recommendation. Extensive experiments on three real-world datasets indicate that our method achieves at least a 1% performance improvement over the best-performing state-of-the-art baselines.},
  archive      = {J_EAAI},
  author       = {Di Wu and Mingjing Tang and Shu Zhang and Wei Gao},
  doi          = {10.1016/j.engappai.2025.110441},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110441},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {HMKRec: Optimize multi-user representation by hypergraph motifs for knowledge-aware recommendation},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive traffic signal control scheme with proximal
policy optimization based on deep reinforcement learning for a single
intersection. <em>EAAI</em>, <em>149</em>, 110440. (<a
href="https://doi.org/10.1016/j.engappai.2025.110440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive traffic signal control (ATSC) is an important means to alleviate traffic congestion and improve the quality of road traffic. Although deep reinforcement learning (DRL) technology has shown great potential in solving traffic signal control problems, the state representation and reward design, as well as action interval time, still need to be further studied. The advantages of policy learning have not been fully applied in TSC. To address the aforementioned issues, we propose a DRL-based traffic signal control scheme with Poximal Policy Optimization (PPO-TSC). We use the waiting time of vehicles and the queue length of lanes represented the spatiotemporal characteristics of traffic flow to design the simplified traffic states feature vectors, and define the reward function that is consistent with the state. Additionally, we compare and analyze the performance indexes obtained by various methods using action intervals of 5s, 10s, and 15s. The algorithm is implemented based on the Actor-Critic architecture, using the advantage estimation and the clip mechanism to constrain the range of gradient updates. We validate the proposed scheme at a single intersection in Simulation of Urban MObility (SUMO) under two different traffic demand patterns of flat traffic and peak traffic. The experimental results show that the proposed method is significantly better than other compared methods. Specifically, PPO-TSC demonstrates a reduction of 24% in average travel time (ATT), a decrease of 45% in the average time loss (ATL), and an increase of 16% in average speed (AS) compared with the existing methods under peak traffic condition.},
  archive      = {J_EAAI},
  author       = {Lijuan Wang and Guoshan Zhang and Qiaoli Yang and Tianyang Han},
  doi          = {10.1016/j.engappai.2025.110440},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110440},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An adaptive traffic signal control scheme with proximal policy optimization based on deep reinforcement learning for a single intersection},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generative adversarial network-based inverse design of
self-deploying soft kirigami composites for targeted shape
transformation. <em>EAAI</em>, <em>149</em>, 110417. (<a
href="https://doi.org/10.1016/j.engappai.2025.110417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design and development of morphing structures that transition from compact, transportable forms to stable, deployable configurations is crucial for advances in soft robotics, healthcare applications, and biomimetic systems. These structures often require customized functionalities and must self-deploy into precise target shapes. Therefore, the deformed shapes of such structures are usually prescribed and the parameters for their design are unknown. To obtain the fabrication parameters, the inverse problem needs to be solved, which quickly becomes quite challenging using conventional methods due to the high-dimensional nature of the inverse problem as well as the material and geometric nonlinearities. To overcome these challenges, we combine the best of the two worlds – physics and data – and present a data-driven approach for the inverse design of two-layered soft composites that utilize the principles of kirigami and strain mismatch to self-deploy into different three-dimensional shapes. At the center of our methodology is the generative adversarial network, designed to generate the necessary fabrication parameters. By using a pre-trained simulator network, we condition the generative model to generate feasible and accurate fabrication parameters that are used to make composites that deploy into the target shapes. Our findings demonstrate that the generative model is able to effectively predict kirigami patterns and pre-stretch values required to realize complex three-dimensional shapes from simple and diverse planar designs. By performing simulations and precise desktop experiments, we compare the target with deployed shapes and demonstrate the predictive capacity of the method.},
  archive      = {J_EAAI},
  author       = {Tomaž Brzin and M. Khalid Jawed and Miha Brojan},
  doi          = {10.1016/j.engappai.2025.110417},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110417},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Generative adversarial network-based inverse design of self-deploying soft kirigami composites for targeted shape transformation},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image retrieval using deep saliency edge feature.
<em>EAAI</em>, <em>149</em>, 110416. (<a
href="https://doi.org/10.1016/j.engappai.2025.110416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploiting a compact representation has become a hotspot in deep learning-based image retrieval. Fine-tuning the deep networks can provide the high discriminating representations, but it is very difficult to obtain sufficient labeled data. However, using the unsupervised methods to provide efficient representations remains challenging. Therefore, we propose a compact and robust representation, namely deep saliency edge feature (DSEF), to image retrieval. Its main highlights are: (1) Color differences, spatial layout, and edge cues within various object regions are combined into saliency edge feature maps. It can reflect a large amount of discriminative information contain in deep feature maps, thereby improving the discriminative power of deep features. (2) Edge cues are utilized to highlight the rough targets contained in deep feature maps. It can reduce the semantic disconnect exists in the different kinds of features and promote the compatibility of deep features and handcrafted features, thereby providing convenience to combine them. (3) A feature aggregation method, namely crucial cues aggregation, is proposed to aggregate crucial cues hidden inside handcrafted features and deep feature maps into a compact and high discriminating representation. Comparative experiments demonstrated that our method has provided the outstandingly retrieval performance on some benchmark datasets. The mean average precision of our method is 2.9%, 4.6%, 3.2%, 6.0% and 3.7% higher than that of most methods on the Oxford5K, Paris6K, Oxford105K, Paris106K and Holidays datasets, respectively.},
  archive      = {J_EAAI},
  author       = {Zhou Lu and Guang-Hai Liu and Zuo-Yong Li and Bo-Jian Zhang},
  doi          = {10.1016/j.engappai.2025.110416},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110416},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Image retrieval using deep saliency edge feature},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SlimDL: Deploying ultra-light deep learning model on
sweeping robots. <em>EAAI</em>, <em>149</em>, 110415. (<a
href="https://doi.org/10.1016/j.engappai.2025.110415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced object detection methods have yielded impressive progress in recent years. However, the computational constraints of edge mobile devices present significant deployment challenges for state-of-the-art algorithms. We propose a deep learning deployment framework with two stages: model adaptation and compression. Our method enhance “You Only Look Once version 5” (YOLOv5) with lightweight modules, which improves detection performance while reducing computational load. Additionally, we present a pruning algorithm, employing adaptive batch normalization and iterative pruning. Our evaluation on “Microsoft Common Objects in Context” (MSCOCO) dataset and custom SweepRobot datasets demonstrates that our method consistently outperforms state-of-the-art approaches. On the SweepRobot dataset, our method doubled YOLOv5’s detection speed on the sweeping robot from 15.69 frames per second (FPS) to 30.77 FPS, maintaining 97.3% performance at 20% of the computational cost. Even on Graphics Processing Unit equipped devices, our method achieved 1.8% and 2.8% higher Average Precision compared to direct scaling and pruning with the original pruning algorithm.},
  archive      = {J_EAAI},
  author       = {Xudong Sun and Yu Wang and Zhanglin Liu and Shaoxuan Gao and Wenbo He and Chao Tong},
  doi          = {10.1016/j.engappai.2025.110415},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110415},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {SlimDL: Deploying ultra-light deep learning model on sweeping robots},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel group decision-making method for incomplete
interval-valued intuitionistic multiplicative linguistic preference
relations. <em>EAAI</em>, <em>149</em>, 110412. (<a
href="https://doi.org/10.1016/j.engappai.2025.110412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By conducting pairwise comparisons, decision-makers can construct interval-valued intuitionistic multiplicative linguistic preference relations (IVIMLPRs) to express the asymmetrically uncertain preferred and non-preferred qualitative judgments. Based on the consistency and consensus analysis, this paper proposes a new group decision-making (GDM) method with incomplete IVIMLPRs. Firstly, a reasonable and rational concept for IVIMLPR is defined. Inspired by the consistent intuitionistic multiplicative linguistic preference relations (IMLPRs), the consistency of IVIMLPRs is expressed by considering the corresponding lower and upper IMLPRs. After that, the acceptably consistent IVIMLPR is further introduced. Based on these concepts, two optimization models are constructed to estimate the missing linguistic variables and adjust an unacceptably consistent IVIMLPR, respectively. To obtain the priority weights from IVIMLPR in a reliable way, the consistency modeling method is employed. Before calculating the collective IVIMLPR, the weights of decision-makers are determined. Subsequently, the consensus analysis is conducted. If the consensus of an IVIMLPR is insufficient, a mathematical model is established to enhance the consensus level. Finally, the applications of the proposed GDM approach are offered and the comparative analysis is discussed. Compared with some existing methods, the proposed decision-making algorithm can perform a rational and effective process in the field of artificial intelligence computing.},
  archive      = {J_EAAI},
  author       = {Tao Li and Liyuan Zhang},
  doi          = {10.1016/j.engappai.2025.110412},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110412},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel group decision-making method for incomplete interval-valued intuitionistic multiplicative linguistic preference relations},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High frequency volatility forecasting and risk assessment
using neural networks-based heteroscedasticity model. <em>EAAI</em>,
<em>149</em>, 110397. (<a
href="https://doi.org/10.1016/j.engappai.2025.110397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High frequency volatility forecasting is essential for timely risk management and informed decision-making in dynamic financial markets. However, accurate forecasting is challenging due to the rapid nature of market movements and the complexity of underlying economic factors. This paper introduces a novel architecture combining Generalized Autoregressive Conditional Heteroscedasticity (GARCH) and Multi-layer Perceptron (MLP)-based models for enhanced volatility forecasting and risk assessment, where input variables are processed through GARCH-type models for volatility forecasting. The proposed GARCH-based MLP-Mixer (GaMM) model incorporates the stacking of multi-layer perceptrons, enabling deep representation learning, facilitating the extraction of temporal and feature information through operations along both time and feature dimensions, and addressing the complexity of high-frequency time-series data. The proposed model is evaluated on three high frequency financial times series datasets over three different years. The computational results demonstrate the proposed model’s superior performance over sixteen forecasting methods in three error metrics, Value-at-risk, and statistical tests for high frequency volatility forecasting and risk assessment tasks.},
  archive      = {J_EAAI},
  author       = {Aryan Bhambu and Koushik Bera and Selvaraju Natarajan and Ponnuthurai Nagaratnam Suganthan},
  doi          = {10.1016/j.engappai.2025.110397},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110397},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {High frequency volatility forecasting and risk assessment using neural networks-based heteroscedasticity model},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning based multi-perspective motion
planning of manned electric vertical take-off and landing vehicle in
urban environment with wind fields. <em>EAAI</em>, <em>149</em>, 110392.
(<a href="https://doi.org/10.1016/j.engappai.2025.110392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electric vertical-takeoff and landing (eVTOL) aircraft, known for their maneuverability and flexibility, offer a promising alternative to traditional transportation systems. However, these aircraft face significant challenges from various perspectives, including the need to increase energy efficiency, enhance passenger experience, and mitigate noise impact on urban environments. While mathematical modeling-based approaches have been employed for flight motion planning, they often struggle to adapt to dynamic and complex environments. In this work, we introduce a three-dimensional motion planning method based on deep reinforcement learning (DRL), tailored for manned eVTOL flights through urban wind fields. Our approach considers three crucial aspects: aircraft energy consumption, passenger experience, and noise impact on urban environment. We modify the Proximal Policy Optimization (PPO) algorithm and design comprehensive reward function that considers these objectives. By incorporating energy efficiency, passenger experience, and noise impact into our reward function, our method demonstrates improved policy learning compared to existing approaches. Comparative experiments conducted under various wind conditions show that our method outperforms commonly used techniques, effectively optimizing multiple objectives in challenging urban environments. Code of our work are available at https://github.com/cgchrfchscyrh/eVTOL_RL/tree/main.},
  archive      = {J_EAAI},
  author       = {Songyang Liu and Weizi Li and Haochen Li and Shuai Li},
  doi          = {10.1016/j.engappai.2025.110392},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110392},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reinforcement learning based multi-perspective motion planning of manned electric vertical take-off and landing vehicle in urban environment with wind fields},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leverage points in the bitcoin ecosystem: Impact on price
and climate change using dynamic systems and spherical fuzzy sets.
<em>EAAI</em>, <em>149</em>, 110390. (<a
href="https://doi.org/10.1016/j.engappai.2025.110390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the significant increase in Bitcoin&#39;s price to around $108,000 in 2025 and its growth of 100% in 2024, scrutiny of the Bitcoin ecosystem and its influencing factors is of particular importance. The research aims to provide a comprehensive model for analyzing the Bitcoin ecosystem in forecasting the factors affecting it.This research used the Total Interpretive Structural Modeling method (TISM) to come up with ideas, the Spherical Fuzzy Decision Making Trial And Evaluation method (SF-DEMATEL) to find and look into how the indices related to each other, and the Spherical Fuzzy Step-Wise Weight Assessment Ratio Analysis method (SF-SWARA) to figure out how important the indices were. The findings identify control rules (0.222) and network security (0.196) as the most fundamental factors.Also, price (0.107) and Bitcoin value (0.089) are the most important among the influencing factors, while other cryptocurrencies have a lesser impact on the Bitcoin ecosystem (0.037). Analyses conducted using System Dynamics (SD) modeling showed that policies that increase control rules or improve tool quality by 50% can directly affect Bitcoin&#39;s price and climate change. The leverage point&#39;s analysis showed that stakeholders can contribute to the long-term sustainability of the Bitcoin ecosystem by strategically managing control rules, tool quality, network capacity, and turnover. The research presents a hybrid approach (SF &amp; SD) to analyze the complexities and uncertainties of the Bitcoin ecosystem.The research implications can aid market participants in comprehending the Bitcoin ecosystem, forecasting Bitcoin prices, and assisting policymakers in implementing suitable regulations for the sustainable growth of this sector.},
  archive      = {J_EAAI},
  author       = {Saeed Alinejad and Zahra Khoshsepehr and Javad Nazarian-Jashnabadi and Samira Ebrahimi},
  doi          = {10.1016/j.engappai.2025.110390},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110390},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Leverage points in the bitcoin ecosystem: Impact on price and climate change using dynamic systems and spherical fuzzy sets},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Influence factor-based transformation method for translating
mass function to probability in dempster–shafer evidence theory.
<em>EAAI</em>, <em>149</em>, 110385. (<a
href="https://doi.org/10.1016/j.engappai.2025.110385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dempster–Shafer evidence theory provides an effective mathematical tool to represent uncertain information by assigning information into power set. Among its associated studies, a pivotal challenge is the transformation of mass functions into probability distributions which can enhance the robustness and reliability of decision-making. In this paper, influence factor is constructed by considering the impact of transformation between multi-element propositions and single-element propositions. Then based on influence factor, the novel transformation method is proposed. In addition, some numerical examples are used to explain effectiveness of new method by analyzing the probability information capacity of different methods. Finally, this paper applies the novel method to target recognition and validates its effectiveness as well as its enhanced support for decision-making through the utilization of real-world datasets.},
  archive      = {J_EAAI},
  author       = {Haocheng Shao and Lipeng Pan and Jiahui Chen and Xiaozhuan Gao and BingYi Kang},
  doi          = {10.1016/j.engappai.2025.110385},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110385},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Influence factor-based transformation method for translating mass function to probability in Dempster–Shafer evidence theory},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). REDIBAGG: Reducing the training set size in ensemble machine
learning-based prediction models. <em>EAAI</em>, <em>149</em>, 110382.
(<a href="https://doi.org/10.1016/j.engappai.2025.110382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning-based algorithms have gained wide acceptance over the years due to their high generalization capabilities for a wide range of classification applications. Although these algorithms demonstrate potential and promising performance, they are often limited by speed, particularly when training on large databases. Big data sets with many instances have storage requirements and execution times that can be excessive. This study proposes reducing the sample size generated by the bootstrap resampling method in Ensemble Machine Learning-based models and evaluates their generalization capability on unknown data. Reduced bootstrap samples are employed in the training phase of the Bagging ensemble model. This approach reduces execution times and, consequently, storage requirements. The proposed method was tested on classification tasks, effectively reducing training subset size without compromising performance. Experimental results demonstrate that this approach achieves execution times reductions of up to 70% for some data sets. This reduction has no impact on accuracy, whereas maintaining levels comparable to classical Bagging and its variants. On average, the training subset size was reduced by 25% compared to the original size.},
  archive      = {J_EAAI},
  author       = {Esther-Lydia Silva-Ramírez and Juan-Francisco Cabrera-Sánchez and Manuel López-Coello},
  doi          = {10.1016/j.engappai.2025.110382},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110382},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {REDIBAGG: Reducing the training set size in ensemble machine learning-based prediction models},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating permutation feature importance with conformal
prediction for robust explainable artificial intelligence in predictive
process monitoring. <em>EAAI</em>, <em>149</em>, 110363. (<a
href="https://doi.org/10.1016/j.engappai.2025.110363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As artificial intelligence (AI) systems are increasingly deployed in high-stakes environments, the need for explanations that convey uncertain information has become evident. Conventional explainable AI (XAI) methods often overlook uncertainty, focusing solely on point predictions. To address this gap, we propose using permutation feature importance (PFI) combined with predictive uncertainty evaluation measures. This novel approach examines the significance of features by relating them to the model’s confidence in its predictions. By using split conformal prediction (SCP) to quantify predictive uncertainty and integrating the outcomes to PFI, we aim to enhance the robustness and interpretability of machine learning (ML) algorithms. More importantly, we examine three scenarios for conformal prediction-based PFI explanations: permuting feature values in the test data, the calibration data, and both. These scenarios assess the impact of feature permutations from different perspectives, revealing feature sensitivity and the importance of features in various settings. We also perform a series of sensitivity analyses, particularly exploring calibration data size and computational efficiency, to demonstrate the robustness and scalability of our approach for industrial applications. Our comprehensive evaluation offers insights into feature impact on predictions and their associated confidence levels. We validate our proposed approach through a real-world predictive process monitoring use case in manufacturing.},
  archive      = {J_EAAI},
  author       = {Nijat Mehdiyev and Maxim Majlatow and Peter Fettke},
  doi          = {10.1016/j.engappai.2025.110363},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110363},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Integrating permutation feature importance with conformal prediction for robust explainable artificial intelligence in predictive process monitoring},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust sparse identification of nonlinear dynamics
approach by combining neural networks and an integral form.
<em>EAAI</em>, <em>149</em>, 110360. (<a
href="https://doi.org/10.1016/j.engappai.2025.110360">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One widely used methodology for uncovering governing equations from data is sparse regression for nonlinear dynamics, commonly known as Sparse Identification of Nonlinear Dynamics ( SINDy ). However, noisy and limited data remain a significant challenge for the success of the SINDy approach. In this work, we propose a robust strategy to discover nonlinear governing equations from both noisy and scarce data. Specifically, we employ neural networks to learn an implicit representation from measurement data, thereby ensuring that the network output remains close to the measurements while also admitting a dynamical system interpretation for its time evolution. Moreover, we identify this dynamical system in the spirit of the SINDy framework. By leveraging the neural network’s implicit representation, we employ automatic differentiation to obtain the derivative information required by SINDy . To further enhance the robustness of our approach, we incorporate an integral constraint on the output of the implicit networks. In addition, we extend our method to handle data acquired from multiple initial conditions. Through several examples, we demonstrate the proposed method’s effectiveness in discovering governing equations under noisy, data-scarce conditions and compare its performance against existing methods.},
  archive      = {J_EAAI},
  author       = {Ali Forootani and Pawan Goyal and Peter Benner},
  doi          = {10.1016/j.engappai.2025.110360},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110360},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A robust sparse identification of nonlinear dynamics approach by combining neural networks and an integral form},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-domain facial expression recognition: Bi-directional
fusion of active and stable information. <em>EAAI</em>, <em>149</em>,
110357. (<a
href="https://doi.org/10.1016/j.engappai.2025.110357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial expression recognition (FER) algorithms often encounter obstacles in cross-domain scenarios, attributed to variations in collection conditions such as lighting, weather, age, gender, and skin color of subjects. Unlike existing approaches that primarily focus on extracting globally invariant features and aligning domain distributions, we propose a novel framework that fundamentally shifts the approach to cross-domain FER. Our proposed algorithm, termed Bi-Directional Fusion of Active and Stable Information (FER-DAS), uniquely combines three innovative components: the Active Assessment Strategy (AAS), Cross-Domain Dynamic Class Threshold (CD-DCT), and Weighted Cross-Domain Alignment (WCDA). The AAS component selectively identifies and enhances active samples in the target domain, providing precise annotations for improved model robustness. Samples with the highest uncertainty are deemed active, indicating low prediction confidence and high informational value for model training. These are then filtered using a predefined threshold to ensure only the most informative samples are included in training iterations. In contrast to conventional static threshold techniques, our dynamic class threshold strategy (CD-DCT) adaptively filters stable samples across domains, thereby ensuring that only the most reliable information is utilized in training. The WCDA strategy further refines this process by dynamically assessing and weighting the contribution of target domain samples to class centers, effectively mitigating domain distribution discrepancies. Extensive experiments on multiple benchmark datasets confirm that FER-DAS sets a new standard in cross-domain FER, consistently outperforming existing state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Yanan Zhu and Jiaqiu Ai and Weibao Xue and Mingyang Wu and Sen Yang and Wei Jia and Min Hu},
  doi          = {10.1016/j.engappai.2025.110357},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110357},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cross-domain facial expression recognition: Bi-directional fusion of active and stable information},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Depression and anxiety detection method based on serialized
facial expression imitation. <em>EAAI</em>, <em>149</em>, 110354. (<a
href="https://doi.org/10.1016/j.engappai.2025.110354">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial recognition techniques are widely employed for automatic detection of depression and anxiety. However, current studies overlook the impact of varying spatial resolutions on model performance and lack a mechanism to share attention regions across sequential data. To advance research in this area, we conducted the Voluntary Facial Expression Mimicry Experiment (VFEM) and constructed the VFEM dataset. We also introduce the SFE-Former, a sequential facial expression recognition model designed for detecting depression and anxiety. SFE-Former features a mechanism that shares attention regions across sequence data, allowing each data point to enhance its features by leveraging shared information. Additionally, the model integrates features from different scales using fusion and weighting strategies. The experimental results indicate that SFE-Former achieved impressive accuracy rate: 0.893 for depression detection, 0.889 for anxiety detection, and 0.780 for co-occurrence detection of depression and anxiety. Meanwhile, SFE-Former also obtained state-of-the-art (SOAT) results on AVEC2014 dataset. This work can enhance the accuracy of identifying patients with depression and anxiety, providing doctors with reliable auxiliary diagnosis. The source code for SFE-Former is accessible at https://github.com/lulin-6k/SFE-Former .},
  archive      = {J_EAAI},
  author       = {Lin Lu and Yan Jiang and Xingyun Li and Hao Wang and Qingzhi Zou and Qingxiang Wang},
  doi          = {10.1016/j.engappai.2025.110354},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110354},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Depression and anxiety detection method based on serialized facial expression imitation},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Goal-oriented graph generation for transmission expansion
planning. <em>EAAI</em>, <em>149</em>, 110350. (<a
href="https://doi.org/10.1016/j.engappai.2025.110350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The electrification strategies that are being designed to meet sustainability objectives and rising energy demands pose significant challenges for power systems worldwide and require Transmission Expansion Planning (TEP). This study adopts a risk-informed approach to TEP, formulated as a multi-objective optimization problem that concurrently minimizes systemic risks and expansion costs. Given the intractability of this problem with conventional solvers, we turn to artificial intelligence techniques. In particular, we conceptualize power grids as graphs and introduce a goal-oriented graph generation methodology using deep reinforcement learning. We extend welfare-Q learning, a modified variant of Q-learning tailored to yield high rewards across multiple dimensions, by incorporating geometric deep learning for function approximation. This allows us to account for system security while minimizing grid expansion costs. Notably, system risk is evaluated by incorporating a Graph Neural Network (GNN) cascading failure meta-model into the proposed approach. The TEP method is applied to the IEEE 118-bus system, and the efficacy of this novel technique is compared against the state of the art. We conclude that the deep reinforcement learning method can compete with established methods for multi-objective optimization, identifying expansion strategies that improve system security at reduced costs. Furthermore, we test the robustness of the meta-model against topology changes in the transmission network, demonstrating its applicability to novel grid configurations.},
  archive      = {J_EAAI},
  author       = {Anna Varbella and Blazhe Gjorgiev and Federico Sartore and Enrico Zio and Giovanni Sansavini},
  doi          = {10.1016/j.engappai.2025.110350},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110350},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Goal-oriented graph generation for transmission expansion planning},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dealing with zero-inflated data: Achieving state-of-the-art
with a two-fold machine learning approach. <em>EAAI</em>, <em>149</em>,
110339. (<a
href="https://doi.org/10.1016/j.engappai.2025.110339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many cases, a machine learning model must learn to correctly predict a few data points with particular values of interest in a broader range of data where many target values are zero. Zero-inflated data can be found in diverse scenarios, such as lumpy and intermittent demands, power consumption for home appliances being turned on and off, impurities measurement in distillation processes, and even airport shuttle demand prediction. The presence of zeroes affects the models’ learning and may result in poor performance. Furthermore, zeroes also distort the metrics used to compute the model’s prediction quality. This paper showcases two real-world use cases (home appliances classification and airport shuttle demand prediction) where a hierarchical model applied in the context of zero-inflated data leads to considerable performance improvements. In particular, for home appliances classification, the weighted average of Precision, Recall, F1, and Area Under the Receiver Operating Characteristic Curve (AUC ROC) was increased by 39%, 49%, 88%, and 48%, respectively. Furthermore, it is estimated that the proposed approach is also four times more energy efficient than the state-of-the-art (SOTA) approach against which it was compared to. Two-fold modeling approaches significantly outperform regular regression, especially when predicting the occurrence of demand events. SOTA results were achieved using Gradient Boosting trees to determine whether an event will occur and Visual Geometry Group (VGG) or Support Vector Regressor (SVR) models for the subsequent classification/regression. The code has been released at two separate repositories.},
  archive      = {J_EAAI},
  author       = {Jože M. Rožanec and Gašper Petelin and João Costa and Gregor Cerar and Blaž Bertalanič and Marko Guček and Gregor Papa and Dunja Mladenić},
  doi          = {10.1016/j.engappai.2025.110339},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110339},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dealing with zero-inflated data: Achieving state-of-the-art with a two-fold machine learning approach},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid EfficientNet feed forward neural network for
ransomware detection in blockchain. <em>EAAI</em>, <em>149</em>, 110292.
(<a href="https://doi.org/10.1016/j.engappai.2025.110292">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ransomware, a type of malware, threatens to encrypt or block access to data until a ransom is paid, causing severe financial and operational impacts. Detecting ransomware in blockchain environments is crucial due to its increasing prevalence and the need for robust security measures. This research proposes an EfficientNet Feed Forward Neural Network (EFFNN) model for ransomware detection in blockchain. Initially, sequence-based statistical features are extracted from blockchain data and normalized using linear normalization. Feature selection is performed with Kumar Hassebrook and Czekanowski’s similarity measures to enhance relevant feature identification. The Hybrid EFFNN, integrating EfficientNet and Deep Feed Forward Neural Networks (DFFNN), is employed for detection. The model achieved high performance, with a True Negative Rate (TNR) of 0.960, accuracy of 0.955, and True Positive Rate (TPR) of 0.821, demonstrating its efficacy in identifying ransomware in blockchain systems.},
  archive      = {J_EAAI},
  author       = {Balajee Maram and Neelima Gullipalli and Rudra Kalyan Nayak and Ramamani Tripathy and Satish Muppidi and Madan Lal Saini},
  doi          = {10.1016/j.engappai.2025.110292},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110292},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybrid EfficientNet feed forward neural network for ransomware detection in blockchain},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unlocking language barriers: Assessing pre-trained large
language models across multilingual tasks and unveiling the black box
with explainable artificial intelligence. <em>EAAI</em>, <em>149</em>,
110136. (<a
href="https://doi.org/10.1016/j.engappai.2025.110136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have revolutionized many industrial applications and paved the way for fostering a new research direction in many fields. Conventional Natural Language Processing (NLP) techniques, for instance, are no longer necessary for many text-based tasks, including polarity estimation, sentiment and emotion classification, and hate speech detection. However, training a language model for domain-specific tasks is hugely costly and requires high computational power, thereby restricting its true potential for standard tasks. This study, therefore, provides a comprehensive analysis of the latest pre-trained LLMs for various NLP-related applications without fine-tuning them to evaluate their effectiveness. Five language models are thus employed in this study on six distinct NLP tasks (including emotion recognition, sentiment analysis, hate speech detection, irony detection, offensiveness detection, and stance detection) for 12 languages from low- to medium- and high-resource. Generative Pre-trained Transformer 4 (GPT-4) and Gemini Pro outperform state-of-the-art models, achieving average F1 scores of 70.6% and 68.8% on the Tweet Sentiment Multilingual dataset compared to the state-of-the-art average F1 score of 66.8%. The study further interprets the findings obtained by the LLMs using Explainable Artificial Intelligence (XAI). To the best of our knowledge, it is the first time any study has employed explainability on pre-trained language models.},
  archive      = {J_EAAI},
  author       = {Muhamet Kastrati and Ali Shariq Imran and Ehtesham Hashmi and Zenun Kastrati and Sher Muhammad Daudpota and Marenglen Biba},
  doi          = {10.1016/j.engappai.2025.110136},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110136},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unlocking language barriers: Assessing pre-trained large language models across multilingual tasks and unveiling the black box with explainable artificial intelligence},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ejor---46">EJOR - 46</h2>
<ul>
<li><details>
<summary>
(2025). Diversification for infinite-mean pareto models without risk
aversion. <em>EJOR</em>, <em>323</em>(1), 341–350. (<a
href="https://doi.org/10.1016/j.ejor.2025.01.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study stochastic dominance between portfolios of independent and identically distributed (iid) extremely heavy-tailed (i.e., infinite-mean) Pareto random variables. With the notion of majorization order, we show that a more diversified portfolio of iid extremely heavy-tailed Pareto random variables is larger in the sense of first-order stochastic dominance. This result is further generalized for Pareto random variables caused by triggering events, random variables with tails being Pareto, bounded Pareto random variables, and positively dependent Pareto random variables. These results provide an important implication in investment: Diversification of extremely heavy-tailed Pareto profits uniformly increases investors’ profitability, leading to a diversification benefit. Remarkably, different from the finite-mean setting, such a diversification benefit does not depend on the decision maker’s risk aversion.},
  archive      = {J_EJOR},
  author       = {Yuyu Chen and Taizhong Hu and Ruodu Wang and Zhenfeng Zou},
  doi          = {10.1016/j.ejor.2025.01.039},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {341-350},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Diversification for infinite-mean pareto models without risk aversion},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sustainable optimal stock portfolios: What relationship
between sustainability and performance? <em>EJOR</em>, <em>323</em>(1),
323–340. (<a href="https://doi.org/10.1016/j.ejor.2025.01.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is to compare different strategies to combine sustainability and optimality in stock portfolios to assess whether there is an association between their average ESG (Environmental, Social, Governance) score and their financial performance and, if so, whether it depends on the specific strategy used. To this end, we confront the risk-adjusted performance of three ESG-compliant optimal portfolios resulting from: (i) optimizing on an ESG-screened sample, (ii) including a portfolio ESG-score constraint in the optimization on an unscreened sample, (iii) our original proposal of optimizing with an ESG-score constraint (so as to reach a target) over a slightly screened sample (so as to exclude companies with lowest sustainability). The optimization is implemented with Bloomberg ESG scores over a sample from the EURO STOXX Index in the period January 2007–August 2022 by minimizing portfolio residual risk. Two are the main conclusions from our results. First, we never find a significant negative association between portfolios’ average ESG score and performance independently of the strategy used. Second, we find a positive association when the first and the third strategy are implemented with a high screening level. To be noted that the relationship between the ESG score and the risk-return ratio in the initial investment set plays a relevant role. If, as in our dataset, this relationship is essentially convex, with an appropriate level of screening portfolios are composed only by stocks whereby a higher ESG score is associated with a higher risk-return profile.},
  archive      = {J_EJOR},
  author       = {Beatrice Bertelli and Costanza Torricelli},
  doi          = {10.1016/j.ejor.2025.01.021},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {323-340},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Sustainable optimal stock portfolios: What relationship between sustainability and performance?},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predictive distributions and the market return: The role of
market illiquidity. <em>EJOR</em>, <em>323</em>(1), 309–322. (<a
href="https://doi.org/10.1016/j.ejor.2025.01.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper evaluates the role of volatility-free stock market illiquidity proxies in forecasting monthly stock market returns. We adopt a probabilistic approach to multivariate time-series modelling using Bayesian nonparametric vector autoregressions. These models flexibly capture complex joint dynamics among financial variables through data-driven regime switching. Out-of-sample forecasts maintain accuracy as the horizon increases. Adding illiquidity generates statistical improvements in out-of-sample predictive accuracy. We highlight the operational importance of market illiquidity after selecting the most appropriate forecasting model that delivers profitable strategies that outperform a range of multivariate models; as well as the historical mean.},
  archive      = {J_EJOR},
  author       = {Michael Ellington and Maria Kalli},
  doi          = {10.1016/j.ejor.2025.01.006},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {309-322},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Predictive distributions and the market return: The role of market illiquidity},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A machine learning approach for solution space reduction in
aircraft disruption recovery. <em>EJOR</em>, <em>323</em>(1), 297–308.
(<a href="https://doi.org/10.1016/j.ejor.2024.11.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aircraft recovery, a critical step in airline operations recovery, aims to minimize the cost of disrupted aircraft schedules. The exact methods for aircraft recovery are computationally expensive and operationally infeasible in practice. Heuristics and hybrid approaches offer faster solutions but have inconsistent solution quality, often leading to large losses. We propose a supervised machine learning approach to accelerate aircraft recovery by pruning the solution space of the optimization problem. It leverages similarities with previously solved problem instances through an offline model-training phase, identifies components of the optimal solutions for new problem instances in the online phase, and links them to the optimization model to rapidly generate high-quality solutions. Computational results, from multiple historical disruption instances for a large US airline, demonstrate that this approach significantly outperforms exact methods on computational runtime while producing similarly high-quality solutions. It also outperforms existing heuristics due to its ability to prune solution spaces in a more principled manner, leading to higher quality solutions in similarly short runtimes. For a runtime budget of two minutes, our approach provides a solution within 1.5% of the true optimal cost, resulting in an average daily saving of over $390,000 compared to all existing approaches. The main drivers of these improvements are explainable in terms of key airline operational metrics and are validated through extensive sensitivity and robustness tests.},
  archive      = {J_EJOR},
  author       = {Navid Rashedi and Nolan Sankey and Vikrant Vaze and Keji Wei},
  doi          = {10.1016/j.ejor.2024.11.025},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {297-308},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A machine learning approach for solution space reduction in aircraft disruption recovery},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A rolling horizon heuristic approach for a multi-stage
stochastic waste collection problem. <em>EJOR</em>, <em>323</em>(1),
276–296. (<a href="https://doi.org/10.1016/j.ejor.2024.11.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we present a multi-stage stochastic optimization model to solve an inventory routing problem for the collection of recyclable municipal waste. The objective is the maximization of the total expected profit of the waste collection company. The decisions are related to the selection of the bins to be visited and the corresponding routing plan in a predefined time horizon. Stochasticity in waste accumulation is modeled through scenario trees generated via conditional density estimation and dynamic stochastic approximation techniques. The proposed formulation is solved through a rolling horizon approach, providing a rigorous worst-case analysis on its performance. Extensive computational experiments are carried out on small- and large-sized instances based on real data provided by a large Portuguese waste collection company. The impact of stochasticity on waste generation is examined through stochastic measures, showing the importance of adopting a stochastic model over a deterministic formulation when addressing a waste collection problem. The performance of the rolling horizon approach is evaluated, demonstrating that this heuristic provides cost-effective solutions in short computational time. Managerial insights related to different geographical configurations of the instances and varying levels of uncertainty are finally discussed.},
  archive      = {J_EJOR},
  author       = {Andrea Spinelli and Francesca Maggioni and Tânia Rodrigues Pereira Ramos and Ana Paula Barbosa-Póvoa and Daniele Vigo},
  doi          = {10.1016/j.ejor.2024.11.041},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {276-296},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A rolling horizon heuristic approach for a multi-stage stochastic waste collection problem},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed solution of the day-ahead pump and valve
scheduling problem for dynamically adaptive water distribution networks
with storage. <em>EJOR</em>, <em>323</em>(1), 267–275. (<a
href="https://doi.org/10.1016/j.ejor.2024.11.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the computation of daily schedules of pumps and boundary valves for the minimization of energy costs in water distribution networks (WDN) with dynamically adaptive configurations. The considered problem combines integer (“on”/“off”) pump control variables, non-convex energy conservation constraints and time-coupling mass conservation constraints. For operational WDNs, the resulting non-convex mixed-integer non-linear program (MINLP) is too large to be solved using available methods. We propose a tailored heuristic solution method based on the Alternating Direction Method of Multipliers which distributes and coordinates the solution of smaller problems corresponding to individual time steps of the original MINLP. The proposed method is applied to a large-scale WDN from the UK. The daily schedule of pumps and boundary valves obtained for the dynamically adaptive network configuration, computed in 12 min, is shown to be at most 6% suboptimal and nearly 5% cheaper than the globally optimal schedule corresponding to the traditional (sectorized) network configuration. The proposed algorithm outperforms alternative off-the-shelf and tailored approaches, providing a scalable method to compute good solutions to the complex day-ahead pump and valve scheduling problem in operational dynamically adaptive WDNs.},
  archive      = {J_EJOR},
  author       = {Aly-Joy Ulusoy and Ivan Stoianov},
  doi          = {10.1016/j.ejor.2024.11.035},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {267-275},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Distributed solution of the day-ahead pump and valve scheduling problem for dynamically adaptive water distribution networks with storage},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adoption model of cryptocurrencies. <em>EJOR</em>,
<em>323</em>(1), 253–266. (<a
href="https://doi.org/10.1016/j.ejor.2024.11.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The network effect, measured by users’ adoption, is considered an important driver of cryptocurrency market dynamics. This study examines the role of adoption timing in cryptocurrency markets by decomposing total adoption into two components: innovators (early adopters) and imitators (late adopters). We find that the innovators’ component is the primary driver of the association between user adoption and cryptocurrency returns, both in-sample and out-of-sample. Next, we show that innovators’ adoption improves price efficiency, while imitators’ adoption contributes to noisier prices. Furthermore, we demonstrate that the adoption model captures significant cryptocurrency market phenomena, such as herding behaviour, more effectively, making it better suited for forecasting models in cryptocurrency pricing. These results suggest that our methodology for linking early and late adopters to market dynamics can be applied to various domains, offering a framework for future research at the intersection of operational research and financial markets.},
  archive      = {J_EJOR},
  author       = {Khaladdin Rzayev and Athanasios Sakkas and Andrew Urquhart},
  doi          = {10.1016/j.ejor.2024.11.024},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {253-266},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An adoption model of cryptocurrencies},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal co-development contracts for companion diagnostics.
<em>EJOR</em>, <em>323</em>(1), 241–252. (<a
href="https://doi.org/10.1016/j.ejor.2024.11.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The market for companion diagnostics is expected to be a US$10.07 billion by 2026. Companion diagnostics have the potential to make expensive drugs cost-effective by identifying patients who would benefit from them. We consider the contract design problem between a pharmaceutical company which owns a drug that is effective for a particular subset of the patient population and a biotech company which owns some technology that could facilitate the development of a companion diagnostic. We obtain theoretical and practical results. We determine when both parties enter such a contract and fully characterize the optimal solutions in closed-form. We find sufficient conditions under which the optimal contract exhibits a particular structure. We show that the first-best can be achieved in some cases and identify sufficient conditions under which the biotech company would not work alone but participates in the project with the pharmaceutical company’s subsidy. We find that heuristics based on practical preferences could be costly to the pharmaceutical company and hence the principal should use the second-best solution; and contract type depends heavily on the biotech company’s workforce level, unit cost of workforce and information level.},
  archive      = {J_EJOR},
  author       = {Sakine Batun and Mehmet A. Begen and Gregory S. Zaric},
  doi          = {10.1016/j.ejor.2024.11.031},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {241-252},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal co-development contracts for companion diagnostics},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Estimating non-overfitted convex production technologies: A
stochastic machine learning approach. <em>EJOR</em>, <em>323</em>(1),
224–240. (<a href="https://doi.org/10.1016/j.ejor.2024.11.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Overfitting is a classical statistical issue that occurs when a model fits a particular observed data sample too closely, potentially limiting its generalizability. While Data Envelopment Analysis (DEA) is a powerful non-parametric method for assessing the relative efficiency of decision-making units (DMUs), its reliance on the minimal extrapolation principle can lead to concerns about overfitting, particularly when the goal extends beyond evaluating the specific DMUs in the sample to making broader inferences. In this paper, we propose an adaptation of Stochastic Gradient Boosting to estimate production possibility sets that mitigate overfitting while satisfying shape constraints such as convexity and free disposability. Our approach is not intended to replace DEA but to complement it, offering an additional tool for scenarios where generalization is important. Through simulation experiments, we demonstrate that the proposed method performs well compared to DEA, especially in high-dimensional settings. Furthermore, the new machine learning-based technique is compared to the Corrected Concave Non-parametric Least Squares (C 2 NLS), showing competitive performance. We also illustrate how the usual efficiency measures in DEA can be implemented under our approach. Finally, we provide an empirical example based on data from the Program for International Student Assessment (PISA) to demonstrate the applicability of the new method.},
  archive      = {J_EJOR},
  author       = {Maria D. Guillen and Vincent Charles and Juan Aparicio},
  doi          = {10.1016/j.ejor.2024.11.030},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {224-240},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Estimating non-overfitted convex production technologies: A stochastic machine learning approach},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond leagues: A single incomplete round robin tournament
for multi-league sports timetabling. <em>EJOR</em>, <em>323</em>(1),
208–223. (<a href="https://doi.org/10.1016/j.ejor.2024.11.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most sports associations regularly face the problem of determining and scheduling games for dozens if not hundreds of non-professional (youth) teams. For practical reasons and player convenience, it is key that the schedule respects venue capacities and minimizes travel distance. A classic approach is to split up teams over leagues, and then have each league play a round robin tournament. In a round robin tournament, each team competes against every other team in the tournament an equal number of times. This paper proposes an alternative approach, organizing a single yet incomplete round robin tournament involving all teams. In this format, which can be seen as a static Swiss system tournament, each team plays the same number of games, but teams are not required to face the same opponents. We exploit this flexibility to reduce the total travel distance and venue capacity conflicts. We provide theoretical results on the computational complexity of finding an incomplete round robin tournament, as well as sufficient conditions on its existence. Besides a Benders’ decomposition for the classic round robin approach, we develop a relax-and-fix and an iterative two-phase decomposition metaheuristic for the incomplete round robin approach. The metaheuristic first determines the home-away status of teams based on their club’s venue capacity, and thereafter selects suitable opponents while minimizing travel distances. Extensive experiments using real-life benchmark instances from the literature confirm the advantage of an incomplete round robin tournament compared to the classic multi-league round robin approach and validate the effectiveness of the proposed heuristics.},
  archive      = {J_EJOR},
  author       = {Miao Li and David Van Bulck and Dries Goossens},
  doi          = {10.1016/j.ejor.2024.11.007},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {208-223},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Beyond leagues: A single incomplete round robin tournament for multi-league sports timetabling},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Consensus modeling for maximum expert with quadratic cost
under various uncertain contexts: A data-driven robust approach.
<em>EJOR</em>, <em>323</em>(1), 192–207. (<a
href="https://doi.org/10.1016/j.ejor.2024.10.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consensus optimization models are valuable tools for addressing negotiated group decision-making challenges, particularly those involving critical decision-related data such as costs and preferences. However, the idealized approach to information fusion in consensus decision-making presents challenges in adapting to practical conditions, leading to less credible consensus solutions. To simulate a more realistic decision-making scenario, this study integrates unit adjustment costs in a quadratic form into a maximum expert consensus model. This quadratic cost formulation captures the complex resistance to cost changes encountered by experts when adjusting solutions, promoting a deliberate approach to solution updates and facilitating improved decision-making. Moreover, economic insights elucidate the effect of quadratic costs on decision-making behavior. Additionally, the feasibility of reaching a consensus may be impeded by high uncertainty in real-world decision-making scenarios. This study separately tackles decision environments characterized by unit adjustment costs and individual preference uncertainty. It employs a robust optimization approach to incorporate uncertain costs and preferences into the optimization model. Data-driven robust maximum expert consensus models are then developed to objectively manage available historical data. An enhanced genetic algorithm is introduced as a solution method to address the proposed models. The proposed models are ultimately applied to evaluate policy options for the development of new energy vehicles in Changsha. Comparative and sensitivity analyses are conducted, showing the superior performance of the proposed models.},
  archive      = {J_EJOR},
  author       = {Jinpeng Wei and Xuanhua Xu and Shaojian Qu and Qiuhan Wang},
  doi          = {10.1016/j.ejor.2024.10.034},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {192-207},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Consensus modeling for maximum expert with quadratic cost under various uncertain contexts: A data-driven robust approach},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bi-attribute utility preference robust optimization: A
continuous piecewise linear approximation approach. <em>EJOR</em>,
<em>323</em>(1), 170–191. (<a
href="https://doi.org/10.1016/j.ejor.2024.11.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider a bi-attribute decision making problem where the decision maker’s (DM’s) objective is to maximize the expected utility of outcomes with two attributes but where the true utility function which captures the DM’s risk preference is ambiguous. To tackle this ambiguity, we propose a maximin bi-attribute utility preference robust optimization (BUPRO) model where the optimal decision is based on the worst-case utility function in an ambiguity set of plausible utility functions constructed using partially available information such as the DM’s specific preference for certain lotteries. Specifically, we consider a BUPRO model with two attributes, where the DM’s risk attitude is bivariate risk-averse and the ambiguity set is defined by a linear system of inequalities represented by the Lebesgue–Stieltjes integrals of the DM’s utility functions. To solve the inner infinite-dimensional minimization problem, we propose a continuous piecewise linear approximation approach to approximate the DM’s unknown true utility. Unlike the univariate case, we partition the domain of the utility function into a set of small non-overlapping rectangles and then divide each rectangle into two triangles by either the main diagonal (Type-1) or the counter diagonal (Type-2). The inner minimization problem based on the piecewise linear utility function can be reformulated as a mixed-integer linear program and the outer maximization problem can be solved efficiently by the derivative-free method. In the case that all the small triangles are partitioned either in Type-1 or in Type-2, the inner minimization can be formulated as a finite dimensional linear program and the overall maximin as a single mixed-integer program. To quantify the approximation errors, we derive, under some mild conditions, the error bound for the difference between the BUPRO model and the approximate BUPRO model in terms of the ambiguity set, the optimal value and the optimal solutions. Finally, we carry out some numerical tests to examine the performance of the proposed models and computational schemes. The results demonstrate the efficiency of the computational schemes and highlight the stability of the BUPRO model against data perturbations.},
  archive      = {J_EJOR},
  author       = {Qiong Wu and Wei Wang and Sainan Zhang and Huifu Xu},
  doi          = {10.1016/j.ejor.2024.11.001},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {170-191},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Bi-attribute utility preference robust optimization: A continuous piecewise linear approximation approach},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tactical workforce sizing and scheduling decisions for
last-mile delivery. <em>EJOR</em>, <em>323</em>(1), 153–169. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We tackle the problems of workforce sizing and shift scheduling of a logistic operator delivering parcels in the last-mile segment of the supply chain. Our working hypothesis is that the relevant decisions are affected by two main trade-offs: workforce size and shift stability. A large workforce can deal with demand fluctuations but incurs higher fixed costs; by contrast, a small workforce might require excessive outsourcing to third-party logistic providers. Stable shifts, i.e., with predictable start times and lengths, improve worker satisfaction and reduce turnover; at the same time, they might be less able to adapt to an unsteady demand. We test these assumptions through an extensive computational campaign based on a novel mathematical formulation. We find that extreme shift stability is, indeed, unsuitable for last-mile operations. At the same time, introducing a very limited amount of flexibility achieves similar effects as moving to a completely flexible system while ensuring a better work-life balance for the workers. Several recent studies in the social sciences have warned about the consequences of precarious working conditions for couriers and retail workers and have recommended — among other things — stable work schedules. Our work shows that it is possible to offer better working conditions in terms of shift stability without sacrificing the company’s bottom line. Thus, companies prioritising profitability (as is often the case) can improve workers’ well-being and increase retention with a negligible cost impact.},
  archive      = {J_EJOR},
  author       = {Minakshi Punam Mandal and Alberto Santini and Claudia Archetti},
  doi          = {10.1016/j.ejor.2024.12.006},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {153-169},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Tactical workforce sizing and scheduling decisions for last-mile delivery},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic scheduling and routing decisions in online meal
delivery platforms with mixed force. <em>EJOR</em>, <em>323</em>(1),
139–152. (<a href="https://doi.org/10.1016/j.ejor.2024.11.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates stochastic scheduling and routing problems in the online meal delivery (OMD) service. The huge increase in meal delivery demand requires the service providers to construct a highly efficient logistics network to deal with a large-volume of time-sensitive and fluctuating fulfillment, often using inhouse and crowdsourced drivers to secure the ambitious service quality. We aim to address the problem of developing an effective scheduling and routing policy that can handle real-life situations. To this end, we first model the dynamic problem as a Markov Decision Process (MDP) and analyze the structural properties of the optimal policy. Then we propose four integrated approaches to solve the operational level scheduling and routing problem. In addition, we provide a continuous approximation formula to estimate the bounds of required fleet size for the inhouse drivers. Numerical experiments based on a real dataset show the effectiveness of the proposed solution approaches. We also obtain several managerial insights that can help decision makers in solving similar resource allocation problems in real-time.},
  archive      = {J_EJOR},
  author       = {Yanlu Zhao and Laurent Alfandari and Claudia Archetti},
  doi          = {10.1016/j.ejor.2024.11.028},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {139-152},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Stochastic scheduling and routing decisions in online meal delivery platforms with mixed force},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Information sharing across competing platforms with varying
information capabilities. <em>EJOR</em>, <em>323</em>(1), 125–138. (<a
href="https://doi.org/10.1016/j.ejor.2024.11.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Competing online retail platforms frequently function as both agency and reselling channels. This paper explores a manufacturer’s channel selection strategy in the context of downstream platform competition and information sharing, taking into account the platforms’ varying levels of information capability. Our research indicates that the manufacturer opts for a hybrid channel approach. Competing platforms aim to be selected as agency channels by offering information sharing and reduced commission fees. Interestingly, the manufacturer chooses the platform with lesser information capability as her agency channel to gain access to shared demand data, while opting for the platform with greater capability as reselling channel without accessing his demand data. The platform with inferior information capability is more inclined to establish a revenue-sharing partnership with the manufacturer to mitigate risks, leading him to decrease his commission rate to attract the manufacturer to select him as the agency channel. We demonstrate that, under conditions of demand uncertainty, a significant distinction between agency and reselling channels lies in the distribution of risk, i.e., whether the platform assumes the risk alone or shares it with the manufacturer. Furthermore, we highlight the free-ride effect , wherein an agency platform can benefit from his rival’s superior information capability. As a result, a complex relationship, characterized by both cooperation and rivalry, may develop between the two platforms.},
  archive      = {J_EJOR},
  author       = {Haoruo Zhu and Yaodong Ni and Yongbo Xiao},
  doi          = {10.1016/j.ejor.2024.11.048},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {125-138},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Information sharing across competing platforms with varying information capabilities},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing bus bridging services with mode choice in
response to urban rail transit emergencies. <em>EJOR</em>,
<em>323</em>(1), 108–124. (<a
href="https://doi.org/10.1016/j.ejor.2024.11.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During urban rail transit (URT) emergencies, stranded passengers may choose to seek alternative modes of transportation instead of waiting in the URT system for the bus bridging service to commence. To tackle this challenge, we present an optimization-based approach focused on identifying promising bus bridging lines and devising efficient services. Specifically, we introduce a candidate line generation (CLG) model designed to identify potential bus bridging lines. This model is akin to solving a k-all pair elementary shortest path problem with resource constraints ( k -APESPPRC). We develop an exact algorithm based on the label setting algorithm and Lawler&#39;s algorithm to solve this model effectively. Subsequently, our approach allocates limited bus resources to determine line selection, frequency determination, bus deployment, and passenger assignment on the integrated network (i.e., partial URT network and bus network) with the consideration of mode choice. Given the inherent complexity of this problem, we introduce an optimization-based tabu search method ( opt -tabu) designed to efficiently solve real-size instances. To demonstrate the effectiveness of our approach, we present a real case study conducted in Hong Kong, showcasing its efficiency and practicality. In summary, this study makes a valuable contribution to the transportation industry by providing a practical and efficient approach to managing URT emergencies, emphasizing the significance of considering mode choice in the context of bus bridging services.},
  archive      = {J_EJOR},
  author       = {Yun Wang and Yu Zhou and Hai Yang and Bin Yu and Xiaobing Liu},
  doi          = {10.1016/j.ejor.2024.11.042},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {108-124},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimizing bus bridging services with mode choice in response to urban rail transit emergencies},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The location routing problem with time windows and
load-dependent travel times for cargo bikes. <em>EJOR</em>,
<em>323</em>(1), 97–107. (<a
href="https://doi.org/10.1016/j.ejor.2024.11.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Last-mile delivery with traditional delivery trucks is ecologically unfriendly and leads to high road utilization. Thus, cities seek for different delivery options to solve these problems. One promising option is the use of cargo bikes in last-mile delivery. These bikes are typically released at micro hubs, which are small containers or facilities located at advantageous places in the city center. Since the bike’s travel speed depends on its remaining load and the street gradient, placing the hubs at valleys might cause additional work for rides. Therefore, the following question arises: How high is the impact of load-dependent travel times on micro hubs’ cost-optimal placements? To answer this question, we introduce the location routing problem with time windows and load-dependent travel times. We formulate the problem as a mixed-integer linear program and introduce an adaptive large neighborhood search with a problem-specific procedure for micro hub placements and problem-specific operators to solve larger instances. In a numerical study, we find that load-dependent travel times significantly influence the location of hubs, following that hubs with a higher elevation are preferably used. Moreover, customers are served from hubs with a similar elevation. This would not be the case if load-dependent travel times are ignored, resulting in an increase in costs by up to 2.7 % or, instead, to up to 26 % infeasible solutions as time windows are not adhered to.},
  archive      = {J_EJOR},
  author       = {Alexander Rave and Pirmin Fontaine},
  doi          = {10.1016/j.ejor.2024.11.040},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {97-107},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The location routing problem with time windows and load-dependent travel times for cargo bikes},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven ordering policies for target oriented newsvendor
with censored demand. <em>EJOR</em>, <em>323</em>(1), 86–96. (<a
href="https://doi.org/10.1016/j.ejor.2024.10.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s fiercely competitive business environment, meeting and surpassing earnings expectations is paramount for public companies. This study focuses on how companies selling newsvendor-type products determine the order quantity to maximize the probability of achieving a target profit (known as profitability). Decision-makers often face challenges in real-life situations where the true demand distributions are unknown, and they have to rely on historical demand data. In some cases, they may only have access to sales data, which is referred to as censored demand. We propose data-driven ordering policies that aim to maximize profitability based solely on historical demand data and sales data respectively. Specifically, we first develop a data-driven nonparametric model using historical demand data, and then present a mixed-integer programming to solve the model. In the case of censored demand, we further propose an enhanced data-driven nonparametric model that leverages the Kaplan–Meier estimator to correct sales data. We prove that the proposed data-driven ordering policies are asymptotically optimal and consistent, regardless of whether the demand is censored or not. To avoid overestimation of true profitability due to sampling error, we propose nonparametric bootstrap methods to estimate the lower confidence bound of profitability, providing a conservative estimate. We also demonstrate the consistency of the lower confidence bound of profitability obtained through the bootstrap-based numerical methods. Finally, we conduct numerical experiments using synthetic data to showcase the effectiveness of the proposed methods.},
  archive      = {J_EJOR},
  author       = {Wanpeng Wang and Shiming Deng and Yuying Zhang},
  doi          = {10.1016/j.ejor.2024.10.045},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {86-96},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Data-driven ordering policies for target oriented newsvendor with censored demand},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). One benders cut to rule all schedules in the neighbourhood.
<em>EJOR</em>, <em>323</em>(1), 62–85. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Logic-Based Benders Decomposition (LBBD) and its Branch-and-Cut variant, namely Branch-and-Check, enjoy an extensive applicability on a broad variety of problems, including scheduling. As the application of LBBD to resource-constrained scheduling remains less explored, we propose a position-based Mixed-Integer Linear Programming (MILP) formulation for scheduling on unrelated parallel machines. To improve upon it, we notice that certain k − OPT neighbourhoods could be explored by regular local search operators, thus allowing us to integrate Local Branching into Branch-and-Check. After enumerating such neighbourhoods and obtaining their local optima – hence, proving that they are suboptimal – a local branching cut (applied as a Benders cut) eliminates all their solutions at once, thus avoiding an overload of the master problem with Benders cuts. However, to guarantee convergence to optimality, the constructed neighbourhood should be exhaustively explored, hence this time-consuming procedure must be accelerated by domination rules or selectively implemented on nodes which are more likely to reduce the optimality gap. In this study, we apply this idea on the ‘internal (job) swaps’ to construct formulation-specific 4-OPT neighbourhoods. We experiment extensively with the minimisation of total completion times and total tardiness on unrelated machines with sequence-dependent and resource-constrained setups. Our results show that our proposed use of local branching reduces optimality gaps considerably compared to standard Branch-and-Check or a monolithic Constraint Programming implementation. The simplicity of our approach allows its transferability to other neighbourhoods of the same or analogous formulations.},
  archive      = {J_EJOR},
  author       = {Ioannis Avgerinos and Ioannis Mourtos and Stavros Vatikiotis and Georgios Zois},
  doi          = {10.1016/j.ejor.2024.12.009},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {62-85},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {One benders cut to rule all schedules in the neighbourhood},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A three-phase algorithm for the three-dimensional loading
vehicle routing problem with split pickups and time windows.
<em>EJOR</em>, <em>323</em>(1), 45–61. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a survey of Belgian logistics service providers, the efficiency of first-mile pickup operations was identified as a key area for improvement, given the increasing number of returns in e-commerce, which has a significant impact on traffic congestion, carbon emissions, energy consumption and operational costs. However, the complexity of first-mile pickup operations, resulting from the small number of parcels to be collected at each pickup location, customer time windows, and the need to efficiently accommodate the highly heterogeneous cargo inside the vans, has hindered the development of real-world solution approaches. This article tackles this operational problem as a vehicle routing problem with time windows, time-dependent travel durations, and split pickups and integrates practical 3D container loading constraints such as vertical and horizontal stability as well as a more realistic reachability constraint to replace the classical “Last In First Out” (LIFO) constraint. To solve it, we propose a three-phase heuristic based on a savings constructive heuristic, an extreme point concept for the loading aspect and a General Variable Neighborhood Search as an improvement phase for both routing and packing. Numerical experiments are conducted to assess the performance of the algorithm on benchmark instances and new instances are tested to validate the positive managerial impacts on cost when allowing split pickups and on driver working duration when extending customer time windows. In addition, we show the impacts of considering the reachability constraint on cost and of the variation of speed during peak hours on schedule feasibility.},
  archive      = {J_EJOR},
  author       = {Emeline Leloup and Célia Paquay and Thierry Pironet and José Fernando Oliveira},
  doi          = {10.1016/j.ejor.2024.12.005},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {45-61},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A three-phase algorithm for the three-dimensional loading vehicle routing problem with split pickups and time windows},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-index rule for managing temporary congestion.
<em>EJOR</em>, <em>323</em>(1), 34–44. (<a
href="https://doi.org/10.1016/j.ejor.2024.11.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent work in healthcare operations provide empirical evidence for the deterioration of service quality due to congestion. Motivated by these findings, we formulate a novel scheduling problem to study how a service provider should prioritize jobs in order to mitigate the impact of temporary congestion-related issues. We analyze the model and show that the optimal policy can be interpreted as a dynamic priority rule that operates in two phases. When the system is overloaded, it is optimal to process jobs according to an index that generalizes Smith’s rule by incorporating the congestion cost. Once the system is no longer overloaded, Smith’s rule becomes optimal. However, the decision about which job to process earlier versus later appears to be challenging (we establish a polynomial time reduction from the partition problem). Our work shows that to respond to congestion, the decision maker should deviate from default scheduling practices and adjust jobs’ urgency at times of congestion to account for potential congestion-related costs. This increases the priority that should be given to shorter jobs (which reduces the time the system is congested), while still taking into account other job characteristics.},
  archive      = {J_EJOR},
  author       = {Yaron Shaposhnik},
  doi          = {10.1016/j.ejor.2024.11.045},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {34-44},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A dual-index rule for managing temporary congestion},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiskilled workforce staffing and scheduling: A
logic-based benders’ decomposition approach. <em>EJOR</em>,
<em>323</em>(1), 20–33. (<a
href="https://doi.org/10.1016/j.ejor.2024.11.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the staffing and scheduling problem of a multiskilled workforce with uncertain demand. We formulate the problem as a two-stage stochastic integer program. The first stage considers strategic decisions, including recruiting permanent staff from an available pool and training them with additional skills, and the second stage focuses on operational decisions, involving the allocation of the multiskilled workforce and the hiring of temporary staff to accommodate uncertain demand. To effectively solve problems of practical sizes, we develop a novel solution algorithm based on the logic-based Benders’ decomposition (LBBD) approach, incorporating a customized analytical cut. We validate our approach through a case study using the data from a prefabrication company, demonstrating the significant cost savings achieved through workforce multiskilling. Our experimental results show that the proposed method is substantially more efficient than the latest Gurobi solver, up to 133 times faster and on average 29 times faster than directly solving the monolithic deterministic equivalent problem (MDEP).},
  archive      = {J_EJOR},
  author       = {Araz Nasirian and Lele Zhang and Alysson M. Costa and Babak Abbasi},
  doi          = {10.1016/j.ejor.2024.11.033},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {20-33},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multiskilled workforce staffing and scheduling: A logic-based benders’ decomposition approach},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cost efficiency in water supply systems: An applied review
on optimization models for the pump scheduling problem. <em>EJOR</em>,
<em>323</em>(1), 1–19. (<a
href="https://doi.org/10.1016/j.ejor.2024.07.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The need for efficient pump operation in water supply systems (WSS) has become increasingly important over time, driven by the growing energy consumption and the associated energy costs. Forecasts for 2050 anticipate a global increase in water demand by 55%, indicating an increasing surge in WSS energy consumption. Control of pumping stations, which consume 70% of the energy in WSS, is the most critical area for optimization. This optimization challenge is commonly referred as the pump scheduling problem (PSP), and can be addressed using a variety of mathematical formulations. While numerous formulations exist to solve this optimization problem, the large majority of the studies are focus on the optimization techniques, sidelining the problem formulation. Due to the unique physical characteristics of each WSS, individual mathematical formulations may exhibit different levels of performance. In addition to general pumps’ operation optimization, the employment of variable speed pumps (VSP) can lead to significant energy savings compared to fixed speed pumps (FSP). However, despite their apparent benefits, many established optimization models for the PSP have not yet incorporated VSP decision variables into their formulations. Therefore, this work aims to review the main mathematical formulations for the pump scheduling problem for WSS with VSP and to present a quantitative comparative study of three mathematical formulations applied to a case study in the literature. The comparative analysis here presented revealed that the optimization model based on duty cycles is more cost-efficient when compared to alternative approaches discussed in the literature.},
  archive      = {J_EJOR},
  author       = {Marlene Brás and Ana Moura and António Andrade-Campos},
  doi          = {10.1016/j.ejor.2024.07.039},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Cost efficiency in water supply systems: An applied review on optimization models for the pump scheduling problem},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A study of asset and liability management applied to
brazilian pension funds. <em>EJOR</em>, <em>322</em>(3), 1059–1076. (<a
href="https://doi.org/10.1016/j.ejor.2024.11.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Asset and Liability Management (ALM) is a critical framework for pension funds, ensuring they have sufficient assets to meet future liabilities (pension payments) while managing investment risks effectively. This paper utilizes Brazilian data to develop an ALM model specifically for pension funds in the country. The model employs an optimization strategy that minimizes expected contributions made by individuals throughout their working lives. This optimization adheres to cash flow limitations and regulatory restrictions. The objective function leverages a min–max robust optimization approach based on a three-scenario planning scheme inspired by Brazil’s Interbank Rate. We incorporate a machine learning approach based on CMARS to predict confidence intervals for the key stochastic model parameters, particularly those related to the real returns of Brazilian investment classes. The findings empower pension fund managers to formulate well-informed investment strategies. We highlight allocation strategies that can reduce contribution rates without jeopardizing fund solvency, even for managers with a more aggressive risk profile favoring higher stock market allocations. Additionally, the study is enriched by an empirical analysis using data from a Brazilian pension fund, demonstrating the model’s practical application. In short, this model offers valuable insights that can benefit a wide range of pension funds in the Brazilian market, and it could also be applied to similar situations globally.},
  archive      = {J_EJOR},
  author       = {Wilton Bernardino and Rodrigo Falcão and João Jr. and Raydonal Ospina and Filipe Costa de Souza and José Jonas Alves Correia},
  doi          = {10.1016/j.ejor.2024.11.016},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {1059-1076},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A study of asset and liability management applied to brazilian pension funds},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integration of support vector machines and mean-variance
optimization for capital allocation. <em>EJOR</em>, <em>322</em>(3),
1045–1058. (<a
href="https://doi.org/10.1016/j.ejor.2024.11.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work introduces a novel methodology for portfolio optimization that is the first to integrate support vector machines (SVMs) with cardinality-constrained mean–variance optimization. We propose augmenting cardinality-constrained mean–variance optimization with a preference for portfolios with the property that a low-dimensional hyperplane can separate assets eligible for investment from those ineligible. We present convex mixed-integer quadratic programming models that jointly select a portfolio and a separating hyperplane. This joint selection optimizes a tradeoff between risk-adjusted returns, hyperplane margin, and classification errors made by the hyperplane. The models are amenable to standard commercial branch-and-bound solvers, requiring no custom implementation. We discuss the properties of the proposed optimization models and draw connections between existing portfolio optimization and SVM approaches. We develop a parameter selection strategy to address the selection of big- M s and provide a financial interpretation of the proposed approach’s parameters. The parameter strategy yields valid big- M values, ensures the risk of the resulting portfolio is within a factor of the lowest possible risk, and produces informative hyperplanes for practitioners. The mathematical programming models and the associated parameter selection strategy are amenable to financial backtesting. The models are evaluated in-sample and out-of-sample on two distinct datasets in a rolling horizon backtesting framework. The portfolios resulting from the proposed approach display improved out-of-sample risk-adjusted returns compared to cardinality-constrained mean–variance optimization.},
  archive      = {J_EJOR},
  author       = {David Islip and Roy H. Kwon and Seongmoon Kim},
  doi          = {10.1016/j.ejor.2024.11.022},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {1045-1058},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Integration of support vector machines and mean-variance optimization for capital allocation},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The yin and yang of banking: Modeling desirable and
undesirable outputs. <em>EJOR</em>, <em>322</em>(3), 1025–1044. (<a
href="https://doi.org/10.1016/j.ejor.2024.11.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel by-production approach to modeling desirable and undesirable output production processes in the US banking sector. We utilize the structural proxy variable framework in which desirable outputs (different types of loans and other income-generating activities) are exogenous, which is a common practice in the banking literature. The undesirable output is non-performing loans (NPLs). To address the endogeneity of variable inputs (purchased funds and core deposits) in the production of desirable outputs, we employ an input distance function and rely on the bank’s cost-minimizing behavioral assumption. We specify the undesirable output technology as a function of desirable outputs as well as other factors such as total non-transaction accounts, undivided profits, and capital reserves. Using US commercial bank data from 2001 to 2020, we find that bank productivity exhibits steady growth in desirable outputs. Banks prioritize reducing the overall productivity impact of NPLs post-crisis, shifting focus from pre-crisis service provision.},
  archive      = {J_EJOR},
  author       = {Yulu Wang and Subal C. Kumbhakar and Man Jin},
  doi          = {10.1016/j.ejor.2024.11.004},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {1025-1044},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The yin and yang of banking: Modeling desirable and undesirable outputs},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the valuation of legacy power production in liberalized
markets via option-pricing. <em>EJOR</em>, <em>322</em>(3), 1005–1024.
(<a href="https://doi.org/10.1016/j.ejor.2024.10.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Legacy assets can constitute entry barriers in liberalized power markets. Regulations pertaining to such assets have many objectives, the most important of which are to transfer the benefits of an economical production technology to consumers and foster competition. To that end, countries have adopted various regulations but there is no consensus today on identifying the first best solution. Inspired by the French regulation of historical nuclear production and considering the market risk that now prevails in the sector, we propose an option-based approach to regulating legacy assets that reflects production costs and encompasses optionality at the same time. To achieve that aim, we study a competitive, but financially incomplete market where the incumbent and several competitors exchange legacy production via a regulated call option. Agents do not face the same risk exposure and their attitudes toward risk, which we model by coherent risk measures, might differ. The result is a stochastic equilibrium model of regulated option-pricing in incomplete markets that we calibrate numerically and solve for the French market. We quantify the option value and assess its impact on the system for various regimes of the spot market, including the one of very high and volatile prices of the recent energy crisis. We also analyze the impacts of risk aversion and the option’s maturity. Based on our analysis, we provide recommendations for enhancing the current French regulation of historical nuclear production.},
  archive      = {J_EJOR},
  author       = {Ibrahim Abada and Mustapha Belkhouja and Andreas Ehrenmann},
  doi          = {10.1016/j.ejor.2024.10.033},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {1005-1024},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On the valuation of legacy power production in liberalized markets via option-pricing},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Risk-averse algorithmic support and inventory management.
<em>EJOR</em>, <em>322</em>(3), 993–1004. (<a
href="https://doi.org/10.1016/j.ejor.2024.11.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study how managers allocate resources in response to algorithmic recommendations that are programmed with specific levels of risk aversion. Using the anchoring and adjustment heuristic, we derive our predictions and test them in a series of multi-item newsvendor experiments. We find that highly risk-averse algorithmic recommendations have a strong and persistent influence on order decisions, even after the recommendations are no longer available. Furthermore, we show that these effects are similar regardless of factors such as source of advice (i.e., human vs. algorithm) and decision autonomy (i.e., whether the algorithm is externally assigned or chosen by the subjects themselves). Finally, we disentangle the effect of risk attitude from that of anchor distance and find that subjects selectively adjust their order decisions by relying more on algorithmic advice that contrasts with their inherent risk preferences. Our findings suggest that organizations can strategically utilize risk-averse algorithmic tools to improve inventory decisions while preserving managerial autonomy.},
  archive      = {J_EJOR},
  author       = {Pranadharthiharan Narayanan and Jeeva Somasundaram and Matthias Seifert},
  doi          = {10.1016/j.ejor.2024.11.013},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {993-1004},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Risk-averse algorithmic support and inventory management},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Implementing no free disposability in data envelopment
analysis. <em>EJOR</em>, <em>322</em>(3), 978–992. (<a
href="https://doi.org/10.1016/j.ejor.2024.11.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data envelopment analysis (DEA) relies on two main postulates of convexity and inefficiency (free disposability). No free disposability postulate is suggested to address undesirable measures. In this study, we demonstrate how no-disposability assumption can be correctly integrated into the DEA framework. We propose the appropriate constraints that should be used in the absence of the free disposability postulate in a DEA model. The additional constraints bound the previously unbounded feasible region (production technology) rather than altering the strongly efficient frontier. We also discuss that treating an undesirable output (input) as a desirable input (output) does not affect the corresponding efficient frontier of a dataset, but misrepresents its corresponding production technology in the presence of free disposability postulate. We provide numerical examples to clarify the concerns in treating an undesirable measure as a desirable measure. A real-life example of United States’ electric power plants is also discussed.},
  archive      = {J_EJOR},
  author       = {Dariush Khezrimotlagh and Joe Zhu},
  doi          = {10.1016/j.ejor.2024.11.029},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {978-992},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Implementing no free disposability in data envelopment analysis},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective route planning of an unmanned air vehicle in
continuous terrain: An exact and an approximation algorithm.
<em>EJOR</em>, <em>322</em>(3), 960–977. (<a
href="https://doi.org/10.1016/j.ejor.2024.11.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicles (UAVs) are widely used for military and civilian purposes. Effective route planning is an important component of their successful missions. In this study, we address the route planning problem of a UAV tasked with collecting information from various target locations in a protected terrain. We consider multiple targets, three objectives, and time-dependent information availability. Modeling the movement of UAVs in a continuous terrain in the presence of multiple objectives is complex. Conflicting objectives typically lead to a continuum of efficient trajectory options between two targets. We formulate the routing problem as a mixed-integer programming (MIP) model that captures the movement in the continuous terrain. We demonstrate the superiority of the continuous terrain formulation over the simplified discretized terrain formulation. We also develop an approximation algorithm that reduces the computational requirements of the MIP model substantially while ensuring a desired level of precision.},
  archive      = {J_EJOR},
  author       = {Erdi Dasdemir and Murat Köksalan and Diclehan Tezcaner Öztürk},
  doi          = {10.1016/j.ejor.2024.11.015},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {960-977},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multi-objective route planning of an unmanned air vehicle in continuous terrain: An exact and an approximation algorithm},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effectiveness of social distancing under partial compliance
of individuals. <em>EJOR</em>, <em>322</em>(3), 949–959. (<a
href="https://doi.org/10.1016/j.ejor.2024.11.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social distancing reduces infectious disease transmission by limiting contact frequency and proximity within a community. However, compliance varies due to its impact on daily life. This paper explores the effects of compliance on social distancing effectiveness through a “social distancing game”, where community members make decisions based on personal utility. We conducted numerical experiments to evaluate how different policy settings for social distancing affect disease transmission. Our findings suggest several key points for developing effective social distancing policies. Firstly, while generally effective, overly strict policies may lead to noncompliance and reduced effectiveness. Secondly, the public health benefits of social distancing need to be balanced against social costs, emphasizing policy efficiency. Lastly, for diseases with low reinfection risk, a segmented policy exempting immune individuals could lessen both infections and socioeconomic costs.},
  archive      = {J_EJOR},
  author       = {Hyelim Shin and Taesik Lee},
  doi          = {10.1016/j.ejor.2024.11.006},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {949-959},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Effectiveness of social distancing under partial compliance of individuals},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Process improvement under the reference price effect.
<em>EJOR</em>, <em>322</em>(3), 937–948. (<a
href="https://doi.org/10.1016/j.ejor.2024.10.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cost-reducing process improvement, leading to price reductions and consequently sales growth, is becoming increasingly relevant in today’s uncertain economic environment. However, existing process improvement studies involving sales growth typically assume that consumers only consider the current price of a product when making a purchase. In reality, sales growth also often stems from the reference price effect, where consumers factor in both the current and past prices. By incorporating the reference price effect, we examine the process improvement investment decisions and pricing strategies in a decentralized supply chain. We develop a two-period game-theoretic model, where the supplier invests in process improvement to reduce production costs, and the supplier and the retailer set their prices. This approach differs from existing reference price effect literature, where prices are predetermined exogenously in a decentralized supply chain. We find that the reference price effect stimulates process improvement investment, making both firms more profitable. However, a more prominent reference price effect may significantly decrease supply chain efficiency in the presence of process improvement, resulting in lower profits that move away from what an integrated firm would achieve. When firms set their own prices, the reference price effect intensifies competition for profits and worsens misalignment caused by process improvement. This outcome contrasts with existing studies, which usually argue that the reference price effect increases efficiency. Therefore, managers should consider consumer responses to price changes when making process improvement investment decisions and analyze their impacts on both supply chain profitability and efficiency.},
  archive      = {J_EJOR},
  author       = {Zeming Wang and Jasper Veldman and Ruud Teunter},
  doi          = {10.1016/j.ejor.2024.10.037},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {937-948},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Process improvement under the reference price effect},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust multilinear target-based decision analysis
considering high-dimensional interactions. <em>EJOR</em>,
<em>322</em>(3), 920–936. (<a
href="https://doi.org/10.1016/j.ejor.2024.10.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Multilinear Target-based Preference Functions (MTPFs) support multi-attribute decision problems characterized by attribute interactions and targets. However, existing research falls short in flexibly modeling high-dimensional interactions and lacks robustness in decision-making recommendations when faced with uncertain parameters and targets. The paper proposes a robust multilinear target-based decision analysis framework considering high-dimensional interactions, along with uncertainties in parameters and targets. First, the necessity of high-dimensional interactions and the limitations of available MTPFs in modeling high-dimensional interactions are demonstrated. Second, the MTPFs based on the 2-interactive fuzzy measure and the Nonmodularity index are proposed to model the high-dimensional interactions and simultaneously reduce the computational challenges of parameter identification. Third, new descriptive measures are proposed based on the Stochastic Multicriteria Acceptability Analysis to evaluate the robustness of decision recommendations subject to uncertain targets and parameters. The validation and advantages of the framework are illustrated with simulation studies and an application in customer competitive evaluation of smart thermometer patches.},
  archive      = {J_EJOR},
  author       = {Qiong Feng and Shurong Tong and Salvatore Corrente and Xinwei Zhang},
  doi          = {10.1016/j.ejor.2024.10.036},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {920-936},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robust multilinear target-based decision analysis considering high-dimensional interactions},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Queues with service resetting. <em>EJOR</em>,
<em>322</em>(3), 908–919. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Service time fluctuations heavily affect the performance of queueing systems, causing long waiting times and backlogs. Recently, it was shown that when service times are solely determined by the server, service resetting can mitigate the deleterious effects of service time fluctuations and drastically improve queue performance (Bonomo et al., 2022). Yet, in many queueing systems, service times have two independent sources: the intrinsic server slowdown ( S ) and the jobs’ inherent size ( X ). In these, so-called S &amp; X queues (Gardner et al., 2017), service resetting results in a newly drawn server slowdown while the inherent job size remains unchanged. Remarkably, resetting can be useful even then. To show this, we develop a comprehensive theory of S &amp; X queues with service resetting. We consider cases where the total service time is either a product or a sum of the service slowdown and the jobs’ inherent size. For both cases, we derive expressions for the total service time distribution and its mean under a generic service resetting policy. Two prevalent resetting policies are discussed in more detail. We first analyze the constant-rate (Poissonian) resetting policy and derive explicit conditions under which resetting reduces the mean service time and improves queue performance. Next, we consider the sharp (deterministic) resetting policy. While results hold regardless of the arrival process, we dedicate special attention to the S &amp; X -M/G/1 queue with service resetting, and obtain the distribution of the number of jobs in the system and their sojourn time. Our analysis highlights situations where service resetting can be used as an effective tool to improve the performance of S &amp; X queueing systems. Several examples are given to illustrate our analytical results, which are corroborated using numerical simulations.},
  archive      = {J_EJOR},
  author       = {Ofek Lauber Bonomo and Uri Yechiali and Shlomi Reuveni},
  doi          = {10.1016/j.ejor.2024.12.044},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {908-919},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Queues with service resetting},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximating g(t)/GI/1 queues with deep learning.
<em>EJOR</em>, <em>322</em>(3), 889–907. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world queueing systems exhibit a time-dependent arrival process and can be modeled as a G ( t ) / G I / 1 queue. Despite its wide applicability, little can be derived analytically about this system, particularly its transient behavior. Yet, many services operate on a schedule where the system is empty at the beginning and end of each day; thus, such systems are unlikely to enter a steady state. In this paper, we apply a supervised machine learning approach to solve a fundamental problem in queueing theory: estimating the transient distribution of the number in the system for a G ( t ) / G I / 1 . We develop a neural network mechanism that provides a fast and accurate predictor of these distributions for moderate horizon lengths and practical settings. It is based on using a Recurrent Neural Network (RNN) architecture based on the first several moments of the time-dependent inter-arrival and the stationary service time distributions; we call it the Moment-Based Recurrent Neural Network (RNN) method ( MBRNN ). Our empirical study suggests MBRNN requires only the first four inter-arrival and service time moments. We use simulation to generate a substantial training dataset and present a thorough performance evaluation to examine the accuracy of our method using two different test sets. We perform sensitivity analysis over different ranges of Squared Coefficient of Variation (SCV) of the inter-arrival and service time distribution and average utilization level. We show that even under the configuration with the worst performance errors, the mean number of customers over the entire timeline has an error of less than 3%. We further show that our method outperforms fluid and diffusion approximations. While simulation modeling can achieve high accuracy (in fact, we use it as the ground truth), the advantage of the MBRNN over simulation is runtime. While the runtime of an accurate simulation of a G ( t ) / G I / 1 queue can be measured in hours, the MBRNN analyzes hundreds of systems within a fraction of a second. We demonstrate the benefit of this runtime speed when our model is used as a building block in optimizing the service capacity for a given time-dependent arrival process. This paper focuses on a G ( t ) / G I / 1 , however the MBRNN approach demonstrated here can be extended to other queueing systems, as the training data labeling is based on simulations (which can be applied to more complex systems) and the training is based on deep learning, which can capture very complex time sequence tasks. In summary, the MBRNN has the potential to revolutionize our ability for transient analysis of queueing systems.},
  archive      = {J_EJOR},
  author       = {Eliran Sherzer and Opher Baron and Dmitry Krass and Yehezkel Resheff},
  doi          = {10.1016/j.ejor.2024.12.030},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {889-907},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Approximating G(t)/GI/1 queues with deep learning},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Risk-sharing in energy communities. <em>EJOR</em>,
<em>322</em>(3), 870–888. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy communities are considered one of the pillars of the energy transition, owing to the rapid development of digital smart appliances and metering. They benefit from strong political support to accommodate their penetration in Europe. Nevertheless, the pace at which they have developed has been very slow compared with what was expected a decade ago. Many articles have revealed some of the underlying reasons, among which are social heterogeneity among participants, unfavorable local regulations, and inadequate governance. Most recently, a nascent body of research has highlighted the need to find adequate sharing rules for the benefits of community projects. Because of the complexity of these rules, the appointment of a community manager or coordinator may be necessary. This paper follows suit by providing guidance to policy makers or community managers about optimal risk-sharing schemes among members of an energy community. By modeling and simulating energy communities that invest in a rooftop photo-voltaic project and face some degree of production and remuneration risk, we find that a high level of risk aversion makes it impossible to allocate the risk in a stable way. Furthermore, we show that some communities whose members’ risk aversion is too heterogeneous cannot form successfully. Besides, even when risk can be allocated in a stable manner, we show that fair allocations are so complex that they require the intervention of a coordinator or a community manager. Finally, we analyze the advantages of developing judicious risk-sharing instruments between communities and a central entity for providing stability.},
  archive      = {J_EJOR},
  author       = {Ibrahim Abada and Andreas Ehrenmann and Xavier Lambin},
  doi          = {10.1016/j.ejor.2024.12.029},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {870-888},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Risk-sharing in energy communities},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Truck–drone routing problem with stochastic demand.
<em>EJOR</em>, <em>322</em>(3), 854–869. (<a
href="https://doi.org/10.1016/j.ejor.2024.11.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Truck–drone combination involves launch/retrieval of rotary-wing drones on trucks, which can address the issues of limited endurance and capacity of rotary-wing drones in delivery systems. Truck–drone combination technologies provide a compelling alternative to traditional emergency logistics systems that rely on on-ground transportation networks. Thus far, little research has been conducted on the truck–drone routing variant with stochastic demand, which is closely related to emergency logistics systems. Herein, we formally define the truck–drone routing problem with stochastic demand (TDRP-SD), which involves drones responding quickly to stochastic demands and restocking the supply. In particular, a new restocking policy, termed the truck–drone synchronized (TDS) restocking policy, is introduced to complement the traditional restocking operations that rely on ground vehicles. We analyze the characteristics of the introduced restocking policy and develop several propositions to address the computational burden caused by the dynamic programming computation of the expected cost. We propose a hybrid heuristic that combines the state-of-the-art Slack Induction by String Removals (SISRs) and greedy insertion utilizing blink rules. Several mechanisms, such as short-route deep search, lower-bound and upper-bound guiding, and simulated annealing, are adopted to ensure the algorithm performance. In computational experiments, the hybrid heuristic solves two types of benchmark instances and achieves new solutions. In addition, a collection of converted instances with up to 302 customers is effectively solved. The sensitivity analysis demonstrates the performance of the TDS restocking policy.},
  archive      = {J_EJOR},
  author       = {Feilong Wang and Hongqi Li and Hanxi Xiong},
  doi          = {10.1016/j.ejor.2024.11.036},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {854-869},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Truck–drone routing problem with stochastic demand},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Impact of vendor preferences on commission policy of
e-commerce platform. <em>EJOR</em>, <em>322</em>(3), 841–853. (<a
href="https://doi.org/10.1016/j.ejor.2024.11.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the prevalent online marketplaces, vendors manage daily operations while e-commerce platforms (EPs) that provide auxiliary services and charge commission fees. Two commission policies are examined in this article: Fixed Commission Policy (FCP), involving a fixed usage fee, and Ordinary Commission Policy (OCP), incorporating an additional fee proportional to sales revenue alongside the fixed usage fee, with this proportion referred to as the commission rate. We develop a two-stage game-theoretical model of an e-commerce supply chain, wherein the EP sets the commission policy and a risk-sensitive vendor determines its stock level. The vendor&#39;s risk attitude is characterized by three key preferences: reference preference, utility weight preference, and loss aversion preference. Under reasonable assumptions, we establish the existence and uniqueness of the game equilibrium, yielding several key insights: (i) Vendor preferences significantly influence the commission policy, with reference preference being central in shaping the optimal commission rate. Specifically, while the FCP is optimal for risk-neutral vendors, it may not be suitable when vendors are risk-sensitive. (ii) The ratio of unit cost to retail price is the primary driver of variations in optimal commission rate. Moreover, the optimal commission rate tends to decrease as this ratio increases. (iii) In the presence of risk sensitivity, a commission policy maximizing the EP&#39;s profit can lead to Pareto improvement compared to one aimed at centralized profit maximization. Our analysis offers valuable insights into the design of commission policies for EPs, providing credible explanations for various economic phenomena associated with these policies in e-commerce practices.},
  archive      = {J_EJOR},
  author       = {Jiansheng Dai and Xinyu Zhang},
  doi          = {10.1016/j.ejor.2024.11.037},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {841-853},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Impact of vendor preferences on commission policy of E-commerce platform},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Resilient transportation network design with disruption
uncertainty and lead times. <em>EJOR</em>, <em>322</em>(3), 827–840. (<a
href="https://doi.org/10.1016/j.ejor.2024.11.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cost-efficient and reliable transports are needed to supply products competitively. Thus, particularly in increasingly complex and global supply chains, identifying the optimal transportation mode is a critical decision. Transportation modes, however, are prone to disruptions, such as hurricanes, low water levels, or port shutdowns, resulting in transportation stops and cost increases. To counteract these disruptions, different resilience strategies are studied to increase the capability of a network to withstand, adapt, and recover from disruptions. For a cost-optimal use, it is necessary to determine the optimal mix of strategic, tactical, and operational strategies. We provide a decision-support model that decides on the optimal mix of resilience strategies, such as multi-sourcing, inventory, or operational re-routing, for a supply chain with transportation disruption uncertainty to minimize total expected costs. The problem is formulated as a two-stage stochastic mixed-integer linear program that explicitly considers lead times. To handle large instances, we propose a Benders decomposition approach enhanced through lower-bound lifting and valid inequalities, branch-and-benders-cut, and a warm-start heuristic. Computational experiments show that large instances can be solved to near-optimality, whereas a commercial solver does not find feasible solutions. We present a case study for a company’s inbound supply chain design with recurring transportation cost uncertainty. Considering disruption and lead time effects, a mix of resilience strategies from strategic to operational level leads to cost improvements of up to 50%. Furthermore, we show that the ability to predict disruptions can further reduce resilience-related costs by 10% if sufficient operational re-routing capacities are available.},
  archive      = {J_EJOR},
  author       = {Daniel Müllerklein and Pirmin Fontaine},
  doi          = {10.1016/j.ejor.2024.11.021},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {827-840},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Resilient transportation network design with disruption uncertainty and lead times},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The impact of channel role on the outsourcing of after-sales
service with asymmetric retailer competition. <em>EJOR</em>,
<em>322</em>(3), 812–826. (<a
href="https://doi.org/10.1016/j.ejor.2024.11.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {After-sales service is support provided to a customer after purchase, which potentially leads to higher customer satisfaction and is demand-enhancing. Using a game-theoretic model in which a manufacturer determines its after-sales service and distribution channel strategies in the presence of two asymmetric retailers, we identify channel position as an important criterion in determining the outsourcing of after-sales service. Specifically, outsourcing to a third-party provider, due to its lack of channel interaction, is never an optimal choice for the manufacturer unless the third-party has a significant cost advantage in providing after-sales service. However, because of the channel role of the retailers, the manufacturer outsources to the large retailer rather than undertaking the after-sales service in-house, when the competing small retailer is less competitive and the cost of service provision is high. The trade-off between the manufacturer outsourcing the service and undertaking that in-house involves whether the manufacturer accommodates the small retailer in the market. When service provision is outsourced, the large retailer enjoys a lower wholesale price if the small retailer is present, and therefore the large retailer subsidizes the manufacturer to induce the manufacturer to accommodate the small retailer. However, the manufacturer, when undertaking the service by itself, forgoes the small retailer. Finally, we show that when the manufacturer adopts a multi-retailer distribution channel, the large retailer benefits because improved after-sales service increases demand and consumer valuation of the product. We also demonstrate the robustness of our key results in multiple extensions.},
  archive      = {J_EJOR},
  author       = {Shuguang Zhang and Wei Shi Lim and Ziqiu Ye},
  doi          = {10.1016/j.ejor.2024.11.020},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {812-826},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The impact of channel role on the outsourcing of after-sales service with asymmetric retailer competition},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retailer involvement in eco-conscious consumer-oriented
carbon footprint reduction. <em>EJOR</em>, <em>322</em>(3), 795–811. (<a
href="https://doi.org/10.1016/j.ejor.2024.10.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retailer involvement and consumer eco-consciousness are two critical considerations for firms when designing comprehensive carbon footprint reduction (CFR) plans. This paper constructs a supply chain (SC) where one manufacturer and one retailer make CFR and pricing strategies in response to eco-conscious consumers. Eco-conscious consumers form a reference carbon footprint to assess the product&#39;s green level. To achieve SC coordination, a cost-sharing contract is introduced. Our results suggest that retailer involvement in CFR always benefits the environment, SC performance, consumer surplus, and social welfare. During CFR cooperation, the manufacturer strategically affects the retailer&#39;s CFR decision by adjusting the CFR level, impacting environmental and economic outcomes. Although higher CFR efficiency by the manufacturer can benefit the environment, SC performance, consumer surplus, and social welfare, a similar emphasis by the retailer may have adverse effects. Surprisingly, a lower reference carbon footprint for eco-conscious consumers may be worse for the environment, depending on the retailer&#39;s CFR efficiency. Furthermore, implementing a cost-sharing contract under the retailer&#39;s different CFR efficiency yields two distinct impacts: a multi-win situation or an incentive conflict. Extended studies are further examined to validate the robustness of these main results.},
  archive      = {J_EJOR},
  author       = {Feiying Jiang and Weilai Huang and Jun Yang and Hongchen Duan},
  doi          = {10.1016/j.ejor.2024.10.030},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {795-811},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Retailer involvement in eco-conscious consumer-oriented carbon footprint reduction},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A speed-up procedure and new heuristics for the classical
job shop scheduling problem: A computational evaluation. <em>EJOR</em>,
<em>322</em>(3), 783–794. (<a
href="https://doi.org/10.1016/j.ejor.2024.11.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The speed-up procedure proposed for the permutation flowshop scheduling problem with makespan minimisation (commonly denoted as Taillard’s acceleration) remains, after 30 years, one of the most important and relevant studies in the scheduling literature. Since its proposal, this procedure has been included in countless approximate optimisation algorithms, and its use is mandatory for several scheduling problems. Unfortunately, despite the importance of such a procedure in solving scheduling problems, we are not aware of any related speed-up procedure proposed for the classical job-shop scheduling problem. First, this study aims to fill this gap by proposing a novel speed-up procedure for the job-shop scheduling problem with makespan minimisation, capable of reducing the complexity of insertion-based procedures n times. Second, to test its performance, the procedure is embedded in a critical-path-based local search method. Furthermore, we thirdly propose five constructive and composite heuristics to obtain high-quality solutions in short time intervals. The composite heuristics apply the previous procedure to reduce their computational efforts. Finally, to complete the study, we conduct an extensive computational evaluation on 243 test instances from eight distinct benchmarks. In this evaluation, 30 heuristics are re-implemented and compared under the same computer conditions. The results indicate the superiority of the proposed approaches compared to the competitive algorithms for the problem under study.},
  archive      = {J_EJOR},
  author       = {Victor Fernandez-Viagas and Carla Talens and Bruno de Athayde Prata},
  doi          = {10.1016/j.ejor.2024.11.026},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {783-794},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A speed-up procedure and new heuristics for the classical job shop scheduling problem: A computational evaluation},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). One-dimensional bin packing with pattern-dependent
processing time. <em>EJOR</em>, <em>322</em>(3), 770–782. (<a
href="https://doi.org/10.1016/j.ejor.2024.11.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper the classical one-dimensional bin packing problem is integrated with scheduling elements: a due date is assigned to each item and the time required to process each bin depends on the pattern being used. The objective is to minimize a convex combination of the material waste and the delay costs, both significant in many real-world contexts. We present a novel pattern-based mixed integer linear formulation suitable for different classical scheduling objective functions, and focus on the specific case where the delay cost corresponds to the maximum tardiness. The formulation is tackled by a branch-and-price algorithm where the pricing of the column generation scheme is a quadratic problem solved by dynamic programming. A sequential value correction heuristic (SVC) is used to feed with warm starting solutions the column generation which, in turn, feeds the SVC with optimal prices so as to compute refined feasible solutions during the enumeration. Computational tests show that both column generation and branch-and-price substantially outperform standard methods in computing dual bounds and exact solutions. Additional tests are presented to analyze the sensitivity to parameters’ changes.},
  archive      = {J_EJOR},
  author       = {Fabrizio Marinelli and Andrea Pizzuti and Wei Wu and Mutsunori Yagiura},
  doi          = {10.1016/j.ejor.2024.11.023},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {770-782},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {One-dimensional bin packing with pattern-dependent processing time},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ε-constraint procedures for pareto front optimization of
large size discrete time/cost trade-off problem. <em>EJOR</em>,
<em>322</em>(3), 753–769. (<a
href="https://doi.org/10.1016/j.ejor.2024.11.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The discrete time/cost trade-off problem (DTCTP) optimizes the project duration and/or cost while considering the trade-off between activity durations and their direct costs. The complete and non-dominated time-cost profile over the set of feasible project durations is achieved within the framework of Pareto front problem. Despite the importance of Pareto front optimization in project and portfolio management, exact procedures have achieved very limited success in solving the problem for large size instances. This study develops exact procedures based on combinations of mixed-integer linear programming (MILP), ε -constraint method, network and problem reduction techniques, and present new bounding strategies to solve the Pareto problem for large size instances. This study also provides new large size benchmark problem instances aiming to represent the size of real-life projects for the DTCTP. The new instances, therefore, are generated to include up to 990 activities and nine execution modes. Computational experiments reveal that the procedures presented herein can remarkably outperform the state-of-the-art exact methods. The new exact procedures enabled obtaining the optimal Pareto front for instances with serial networks that include more than 200 activities for the first time.},
  archive      = {J_EJOR},
  author       = {Saman Aminbakhsh and Rifat Sönmez and Tankut Atan},
  doi          = {10.1016/j.ejor.2024.11.032},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {753-769},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {ε-constraint procedures for pareto front optimization of large size discrete time/cost trade-off problem},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Overcoming poor data quality: Optimizing validation of
precedence relation data. <em>EJOR</em>, <em>322</em>(3), 740–752. (<a
href="https://doi.org/10.1016/j.ejor.2024.11.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Insufficient data quality prevents data usage by decision support systems (DSS) in many areas of business. This is the case for data on precedence relations between tasks, which is relevant, for instance, in project scheduling and assembly line balancing. Inaccurate data on unnecessary precedence relations cannot be used, otherwise the recommendations of DSS may turn infeasible. So, unnecessary relations must be satisfied, diminishing the baseline problem’s solution space and the business result. Experts can validate the data, but their time is limited. We apply an optimization lens and formulate the data validation problem (DVP). Restricted by the available time budget, an expert dynamically receives queries about specific data entries and corrects or validates them. The DVP searches for an interview policy that states queries to the expert, each using up some of the time budget, in a way that maximizes the (weighted) number of removed precedence relations. We model the DVP as a dynamic program, derive optimal policies for several important special cases and design a heuristic interview policy LSTD. In a case study of an automobile manufacturer, this policy substantially reduces the stations’ idle time after selectively addressing about 8% of the data entries. We prove theoretically and numerically that data validation by experts can lead to significant savings. The number of queries required to validate the data exhaustively is much less than naive estimates. Additionally, the probability to remove an unnecessary precedence relation per query in a series of queries is high, even for simple interview policies.},
  archive      = {J_EJOR},
  author       = {Benedikt Finnah and Jochen Gönsch and Alena Otto},
  doi          = {10.1016/j.ejor.2024.11.009},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {740-752},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Overcoming poor data quality: Optimizing validation of precedence relation data},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fifty years of maintenance optimization: Reflections and
perspectives. <em>EJOR</em>, <em>322</em>(3), 725–739. (<a
href="https://doi.org/10.1016/j.ejor.2024.07.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {On the occasion of the 50th anniversary of the Association of European Operational Research Societies (EURO), we share our perspectives and reflections on maintenance research. We review the main methods and techniques for optimizing when and what to maintain, providing concrete examples as illustrations. We also discuss the optimization of the logistics support system surrounding the act of maintenance. In doing so, we highlight the multidisciplinary nature of maintenance research and its interface with other domains, such as spare parts inventory management, production scheduling, and transportation planning. We support our reflections with basic text-mining analyses of the archive of the European Journal of Operational Research , the journal published in collaboration with EURO. With this paper, we introduce interested researchers to maintenance optimization and share opportunities to close the gaps between the current state of research and real-world needs.},
  archive      = {J_EJOR},
  author       = {Joachim Arts and Robert N. Boute and Stijn Loeys and Heletjé E. van Staden},
  doi          = {10.1016/j.ejor.2024.07.002},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {725-739},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Fifty years of maintenance optimization: Reflections and perspectives},
  volume       = {322},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="iandc---16">IANDC - 16</h2>
<ul>
<li><details>
<summary>
(2025). On the computational power of energy-constrained mobile
robots. <em>IANDC</em>, <em>303</em>, 105280. (<a
href="https://doi.org/10.1016/j.ic.2025.105280">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider distributed systems of autonomous robots operating in the plane under synchronous Look - Compute - Move ( LCM ) cycles. Prior research on four distinct models assumes robots have unlimited energy. We remove this assumption and investigate systems where robots have limited but renewable energy, requiring inactivity for energy restoration. We analyze the computational impact of this constraint, fully characterizing the relationship between energy-restricted and unrestricted robots. Surprisingly, we show that energy constraints can enhance computational power. Additionally, we study how memory persistence and communication capabilities influence computation under energy constraints. By comparing the four models in this setting, we establish a complete characterization of their computational relationships. A key insight is that energy-limited robots can be modeled as unlimited-energy robots controlled by an adversarial activation scheduler. This provides a novel equivalence framework for analyzing energy-constrained distributed systems.},
  archive      = {J_IANDC},
  author       = {Kevin Buchin and Paola Flocchini and Irina Kostitsyna and Tom Peters and Nicola Santoro and Koichi Wada},
  doi          = {10.1016/j.ic.2025.105280},
  journal      = {Information and Computation},
  month        = {3},
  pages        = {105280},
  shortjournal = {Inf. Comput.},
  title        = {On the computational power of energy-constrained mobile robots},
  volume       = {303},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Consistent query answering in multi-relation databases.
<em>IANDC</em>, <em>303</em>, 105279. (<a
href="https://doi.org/10.1016/j.ic.2025.105279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditionally, to verify the consistency of a multi-relation database with respect to a set of functional dependencies, one applies the well-known Chase algorithm, which derives new tuples as long as no conflict with some dependency arises. Therefore, the Chase algorithm uses dependencies both as inference rules and as tools to check consistency. If no conflicts occur, the database is declared consistent else inconsistent. If the database is consistent then query answering proceeds as usual, otherwise extracting consistent information from the inconsistent database is an issue, known as consistent query answering. To address this issue, we consider the set T of all tuples built from constants occurring in the database, and we use set theoretic semantics to characterize tuples in T in two orthogonal ways: true/false and conflicting/non-conflicting. Calling ‘consistent’ a tuple which is true and non-conflicting, a ‘repair’ is defined to be a maximal subset of true tuples that satisfies the dependencies and in which as many consitent tuples as possible are true. A query Q is of the form select X where C o n d i t i o n , and a tuple x of T is in the consistent answer of Q if x is in the answer of Q in every repair. Our main contributions are: (a) a novel approach to consistent query answering in multi-relation databases; (b) a modified Chase algorithm to compute true/false and conflicting/non-conflicting tuples; (c) for acyclic functional dependencies, a polynomial-time algorithm computing the exact or approximate consistent answers; (d) a detailed discussion comparing our approach with other related approaches.},
  archive      = {J_IANDC},
  author       = {Dominique Laurent and Nicolas Spyratos},
  doi          = {10.1016/j.ic.2025.105279},
  journal      = {Information and Computation},
  month        = {3},
  pages        = {105279},
  shortjournal = {Inf. Comput.},
  title        = {Consistent query answering in multi-relation databases},
  volume       = {303},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On regular trees defined from unfoldings and coverings.
<em>IANDC</em>, <em>303</em>, 105278. (<a
href="https://doi.org/10.1016/j.ic.2025.105278">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the infinite trees that arise, first as complete unfoldings of finite weighted directed graphs, and second, as universal coverings of finite weighted undirected graphs. They are respectively the regular rooted trees and the strongly regular trees, a new notion. A rooted tree is regular if it has finitely many subtrees up to isomorphism. A tree (without root) is strongly regular if it has finitely many rooted trees, up to isomorphism, obtained by taking each of its nodes as a root. We prove the first-order definability of each regular or strongly regular tree with respect to the class of trees (that is not itself first-order definable). We characterize the strongly regular trees among the regular ones and we establish several decidability results.},
  archive      = {J_IANDC},
  author       = {Bruno Courcelle},
  doi          = {10.1016/j.ic.2025.105278},
  journal      = {Information and Computation},
  month        = {3},
  pages        = {105278},
  shortjournal = {Inf. Comput.},
  title        = {On regular trees defined from unfoldings and coverings},
  volume       = {303},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The computational properties of p systems with mutative
membrane structures. <em>IANDC</em>, <em>303</em>, 105277. (<a
href="https://doi.org/10.1016/j.ic.2025.105277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Membrane computing is a subfield of nature-inspired computing studying computational models named P systems , where several rules (division rules, dissolving rules, merging rules, creation rules, separation rules, etc) for evolving the membrane structure were considered in many variants of P systems, and most of these variants employ at most two of these types of rules. In this article, we combine budding rules, fusion rules, dissolving rules, division rules (both for non-elementary membrane and elementary membranes), therefore a mutative type of P systems, termed cell-like P systems with mutative membrane structures (CMMS P systems) are defined. We discuss the computational properties of CMMS P systems. More specifically, CMMS P systems are shown to be Turing universal by integrating some types of rules. Moreover, we prove that CMMS P systems can also effectively solve the SAT problem.},
  archive      = {J_IANDC},
  author       = {Bosheng Song and Chuanlong Hu and David Orellana-Martín and Antonio Ramírez-de-Arellano and Mario J. Pérez-Jiménez and Xiangxiang Zeng},
  doi          = {10.1016/j.ic.2025.105277},
  journal      = {Information and Computation},
  month        = {3},
  pages        = {105277},
  shortjournal = {Inf. Comput.},
  title        = {The computational properties of p systems with mutative membrane structures},
  volume       = {303},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Metric quantifiers and counting in timed logics and
automata. <em>IANDC</em>, <em>303</em>, 105268. (<a
href="https://doi.org/10.1016/j.ic.2025.105268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the expressiveness of the pointwise interpretations (i.e. over timed words) of some predicate and temporal logics with metric and counting features. We show that counting in the unit interval ( 0 , 1 ) is strictly weaker than counting in ( 0 , b ) with arbitrary b ≥ 0 ; moreover, allowing the latter to be included in temporal logics leads to expressive completeness for the metric predicate logic Q2MLO , recovering the corresponding result for the continuous interpretations (i.e. over signals). Exploiting this connection, we show that in contrast to the continuous case, adding ‘punctual’ predicates into Q2MLO is still insufficient for the full expressive power of the Monadic First-Order Logic of Order and Metric ( FO[ &lt; , + 1 ] ); as a remedy, we propose a generalisation of the recently proposed Pnueli automata modalities and show that the resulting metric temporal logic is expressively complete for FO[ &lt; , + 1 ] . On the practical side, we propose a compositional construction from metric interval temporal logic with counting or similar extensions to timed automata, which is more amenable to implementation based on existing tools that support on-the-fly model checking.},
  archive      = {J_IANDC},
  author       = {Hsi-Ming Ho and Khushraj Madnani},
  doi          = {10.1016/j.ic.2025.105268},
  journal      = {Information and Computation},
  month        = {3},
  pages        = {105268},
  shortjournal = {Inf. Comput.},
  title        = {Metric quantifiers and counting in timed logics and automata},
  volume       = {303},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalising the maximum independent set algorithm via
boolean networks. <em>IANDC</em>, <em>303</em>, 105266. (<a
href="https://doi.org/10.1016/j.ic.2025.105266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A simple greedy algorithm to find a maximal independent set (MIS) in a graph starts with the empty set and visits every vertex, adding it to the set if and only if none of its neighbours are already in the set. In this paper, we consider (the complexity of decision problems related to) the generalisation of this MIS algorithm wherein any starting set is allowed. Two main approaches are leveraged. Firstly, we view the MIS algorithm as a sequential update of a Boolean network according to a permutation of the vertex set. Secondly, we introduce the concept of a constituency of a graph: a set of vertices that is dominated by an independent set. Recognizing a constituency is NP -complete, a fact we leverage repeatedly in our investigation. Our contributions are multiple: we establish that deciding whether all maximal independent sets can be reached from some configuration is coNP -complete; that fixing words (which reach a MIS from any starting configuration) and fixing permutations (briefly, permises) are coNP -complete to recognize; and that permissible graphs (graphs with a permis) are coNP -hard to recognize. We also exhibit large classes of permissible and non-permissible graphs, notably near-comparability graphs which may be of independent interest. Lastly, we extend our study to digraphs, where we search for kernels. Since the natural generalisation of our approach may not necessarily find a kernel, we introduce two further Boolean networks for digraphs: one always finds an independent set, and the other always finds a dominating set.},
  archive      = {J_IANDC},
  author       = {Maximilien Gadouleau and David C. Kutner},
  doi          = {10.1016/j.ic.2025.105266},
  journal      = {Information and Computation},
  month        = {3},
  pages        = {105266},
  shortjournal = {Inf. Comput.},
  title        = {Generalising the maximum independent set algorithm via boolean networks},
  volume       = {303},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient assignment of identities in anonymous populations.
<em>IANDC</em>, <em>303</em>, 105265. (<a
href="https://doi.org/10.1016/j.ic.2025.105265">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the fundamental problem of assigning distinct labels to agents in the probabilistic model of population protocols. Our protocols operate under the assumption that the size n of the population is embedded in the transition function. W.h.p. (with high probability), they are silent, i.e., eventually each agent reaches its final state and remains in it forever, and they are safe, i.e., never change a label that has already been assigned to an agent. We provide efficient protocols for this problem complemented with tight lower bounds. Our fast labeling protocol uses only O ( ( n log ⁡ n ) / ε ) interactions w.h.p., ( 2 + ε ) n + O ( n a ) states, and the label range [ 1 , ( 1 + ε ) n ] , where 1 ≥ ε &gt; 0 and 0 &lt; a &lt; 1 , while our nearly state-optimal protocol uses only n + 5 n + O ( log ⁡ log ⁡ n ) states, the label range [ 1 , n ] , and w.h.p., O ( n 3 ) interactions.},
  archive      = {J_IANDC},
  author       = {Leszek Gąsieniec and Jesper Jansson and Christos Levcopoulos and Andrzej Lingas},
  doi          = {10.1016/j.ic.2025.105265},
  journal      = {Information and Computation},
  month        = {3},
  pages        = {105265},
  shortjournal = {Inf. Comput.},
  title        = {Efficient assignment of identities in anonymous populations},
  volume       = {303},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximate envy-freeness in indivisible resource allocation
with budget constraints. <em>IANDC</em>, <em>303</em>, 105264. (<a
href="https://doi.org/10.1016/j.ic.2024.105264">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the fair allocation of indivisible resources under knapsack constraints, where a set of items with varied costs and values are to be allocated among a group of agents. Each agent has a budget constraint on the total cost of items she can receive. The goal is to compute a budget-feasible allocation that is envy-free (EF), in which the agents do not envy each other for the items they receive, nor do they envy a charity, which is endowed with all the unallocated items. Since EF allocations barely exist (even without the budget constraints), we are interested in the relaxed notion of envy-freeness up to one item (EF1). Our results are twofold. Firstly, for the general setting where agents have heterogeneous valuations and budgets, we show that a budget-feasible allocation that maximizes the Nash social welfare (NSW) achieves a 1/4-approximation of EF1. This approximation ratio carries to the general case of arbitrary monotone subadditive valuations. The approximation ratio improves gracefully when the items have small cost compared with the agents&#39; budgets; it converges to 1/2 when the budget-cost ratio approaches infinity, and to 1 if the agents further have identical valuations. Secondly, when agents have identical valuations, we design a polynomial-time algorithm that computes a 1/2-approximate EF1 allocation for an arbitrary number of agents. For the case of identical agents and the case of two agents, we propose polynomial-time algorithms for computing EF1 allocations.},
  archive      = {J_IANDC},
  author       = {Xiaowei Wu and Bo Li and Jiarui Gan},
  doi          = {10.1016/j.ic.2024.105264},
  journal      = {Information and Computation},
  month        = {3},
  pages        = {105264},
  shortjournal = {Inf. Comput.},
  title        = {Approximate envy-freeness in indivisible resource allocation with budget constraints},
  volume       = {303},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nondeterminism and the clique problem. <em>IANDC</em>,
<em>303</em>, 105260. (<a
href="https://doi.org/10.1016/j.ic.2024.105260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Clique problem is known to be NP-Complete and the question whether P=NP is unresolved. This paper examines the relative power of nondeterminism versus determinism in a restricted setting. Specifically, we consider solving the clique problem using non-deterministic and deterministic Turing machines. We impose a (reasonable) format in which a problem instance is encoded. We also impose constraints on the computation of both deterministic and non-deterministic Turing machines: both have two tapes, the input tape is read-only and one-way, and once a certain stop point in the input tape is reached, no additional writing on the work tape is allowed. We consider two cases for the position of the stop point: immediately after the number of graph nodes and the size of the clique are specified, or controlled by a parameter q that indicates what portion of the graph nodes&#39; edge specifications have been scanned. The parameter q may be arbitrarily close to 1, e.g., q = 0.99999 . We show, for both cases in our setting, that a non-deterministic Turing machine can solve the problem in O ( n 3 ) time whereas no deterministic Turing machine can solve the problem in polynomial time. However, we exhibit an exponential time deterministic single work tape, two-heads Turing machine that solves the clique problem in our setting.},
  archive      = {J_IANDC},
  author       = {Oded Shmueli},
  doi          = {10.1016/j.ic.2024.105260},
  journal      = {Information and Computation},
  month        = {3},
  pages        = {105260},
  shortjournal = {Inf. Comput.},
  title        = {Nondeterminism and the clique problem},
  volume       = {303},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An algebraic attack on the key exchange protocol based upon
a modified tropical structure. <em>IANDC</em>, <em>303</em>, 105259. (<a
href="https://doi.org/10.1016/j.ic.2024.105259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we analyze the key exchange protocol based on an algebraic structure derived from a tropical semiring. The security of this key exchange scheme depends on an attacker&#39;s inability to solve a system of non-linear equations to obtain the private parameters. However, we propose an algebraic attack on this key exchange scheme using only the public parameters. We thoroughly evaluate the protocol&#39;s security against algebraic attacks through comprehensive cryptanalysis. We study the behavior of matrix sequences produced during key exchange, looking for any almost linear periodicity property that could affect the cryptanalysis. We provide the algorithm and an example to illustrate our attack, demonstrating that this key exchange protocol is not secure. Additionally, we examine how different parameter selections and matrix sizes impact the protocol&#39;s security. Ultimately, this cryptanalysis enhances tropical cryptography by expanding our understanding of the security implications of modified tropical semiring-based key exchange protocols.},
  archive      = {J_IANDC},
  author       = {J. Jackson and R. Perumal},
  doi          = {10.1016/j.ic.2024.105259},
  journal      = {Information and Computation},
  month        = {3},
  pages        = {105259},
  shortjournal = {Inf. Comput.},
  title        = {An algebraic attack on the key exchange protocol based upon a modified tropical structure},
  volume       = {303},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extending CL-reducibility on array noncomputable degrees.
<em>IANDC</em>, <em>303</em>, 105258. (<a
href="https://doi.org/10.1016/j.ic.2024.105258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a function f , f -bounded-Turing ( f -bT-) reducibility is the Turing reducibility with use function bounded by f . In the special case where f = id + c (with id being the identity function and c a constant), this is referred to as cl-reducibility. In a work by Barmpalias, Fang, and Lewis-Pye, it was proven that there exist two left-c.e. reals such that no left-c.e. real ( id + g ) -bT-computes both of them whenever g is computable, nondecreasing, and satisfies ∑ n 2 − g ( n ) = ∞ . Moreover, such maximal pairs exist precisely within every array noncomputable degree. This result generalizes a prior result on cl-reducibility, which states that there exist two left-c.e. reals such that no left-c.e. real cl-computes both of them. An open question remained as to whether a similar extension could apply to another result on cl-reducibility, which asserts that there exists a left-c.e. real not cl-reducible to any random left-c.e. real. We answer this question affirmatively, providing a simpler proof compared to previous works. Additionally, we streamline the proof of the initial extension.},
  archive      = {J_IANDC},
  author       = {Nan Fang and Wolfgang Merkle},
  doi          = {10.1016/j.ic.2024.105258},
  journal      = {Information and Computation},
  month        = {3},
  pages        = {105258},
  shortjournal = {Inf. Comput.},
  title        = {Extending CL-reducibility on array noncomputable degrees},
  volume       = {303},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reasoning about group responsibility for exceeding risk
threshold in one-shot games. <em>IANDC</em>, <em>303</em>, 105257. (<a
href="https://doi.org/10.1016/j.ic.2024.105257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tracing and analysing the responsibility for unsafe outcomes of actors&#39; decisions in multi-agent settings have been studied in recent years. These studies often focus on deterministic scenarios and assume that the unsafe outcomes for which actors can be held responsible are actually realized. This paper considers a broader notion of responsibility where unsafe outcomes are not necessarily realized, but their probabilities are unacceptably high. We present a logic combining strategic, probabilistic and temporal primitives designed to express concepts such as the risk of an undesirable outcome and being responsible for exceeding a risk threshold in one-shot games. We demonstrate that the proposed logic is (weakly) complete, decidable and has an efficient model-checking procedure. Finally, we define a probabilistic notion of responsibility and study its formal properties in the proposed logic setting.},
  archive      = {J_IANDC},
  author       = {Maksim Gladyshev and Natasha Alechina and Mehdi Dastani and Dragan Doder},
  doi          = {10.1016/j.ic.2024.105257},
  journal      = {Information and Computation},
  month        = {3},
  pages        = {105257},
  shortjournal = {Inf. Comput.},
  title        = {Reasoning about group responsibility for exceeding risk threshold in one-shot games},
  volume       = {303},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic judgment aggregation with conditional
independence constraints. <em>IANDC</em>, <em>303</em>, 105256. (<a
href="https://doi.org/10.1016/j.ic.2024.105256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic judgment aggregation is concerned with aggregating judgments about probabilities of logically related issues. It takes as input imprecise probabilistic judgments over the issues given by a group of agents and defines rules of aggregating the individual judgments into a collective opinion representative for the group. The process of aggregation can be subject to constraints, i.e., aggregation rules can be required to satisfy certain properties. We explore how probabilistic independence constraints can be represented and incorporated into the aggregation process.},
  archive      = {J_IANDC},
  author       = {Magdalena Ivanovska and Marija Slavkovik},
  doi          = {10.1016/j.ic.2024.105256},
  journal      = {Information and Computation},
  month        = {3},
  pages        = {105256},
  shortjournal = {Inf. Comput.},
  title        = {Probabilistic judgment aggregation with conditional independence constraints},
  volume       = {303},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ltlf synthesis under environment specifications for
reachability and safety properties. <em>IANDC</em>, <em>303</em>,
105255. (<a href="https://doi.org/10.1016/j.ic.2024.105255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study ltl f synthesis under environment specifications for arbitrary reachability and safety properties. We consider both kinds of properties for both agent tasks and environment specifications, providing a complete landscape of synthesis algorithms. For each case, we devise a specific algorithm (optimal wrt complexity of the problem) and prove its correctness. The algorithms combine common building blocks in different ways. While some cases are already studied in literature others are studied here for the first time.},
  archive      = {J_IANDC},
  author       = {Benjamin Aminof and Giuseppe De Giacomo and Antonio Di Stasio and Hugo Francon and Sasha Rubin and Shufang Zhu},
  doi          = {10.1016/j.ic.2024.105255},
  journal      = {Information and Computation},
  month        = {3},
  pages        = {105255},
  shortjournal = {Inf. Comput.},
  title        = {Ltlf synthesis under environment specifications for reachability and safety properties},
  volume       = {303},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed fractional local ratio and independent set
approximation. <em>IANDC</em>, <em>303</em>, 105238. (<a
href="https://doi.org/10.1016/j.ic.2024.105238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the Maximum Weight Independent Set problem, with a focus on obtaining good approximations for graphs of small maximum degree Δ. We give deterministic local algorithms running in time poly ( Δ , log ⁡ n ) that come close to matching the best centralized results known and improve the previous distributed approximations by a factor of about 2. More precisely, we obtain approximations below Δ + 1 / 2 2 , and a further improvement to 8 / 5 + ε when Δ = 3 . Technically, this is achieved by leveraging the fractional local ratio technique, for a first application in a distributed setting.},
  archive      = {J_IANDC},
  author       = {Magnús M. Halldórsson and Dror Rawitz},
  doi          = {10.1016/j.ic.2024.105238},
  journal      = {Information and Computation},
  month        = {3},
  pages        = {105238},
  shortjournal = {Inf. Comput.},
  title        = {Distributed fractional local ratio and independent set approximation},
  volume       = {303},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A parallel algorithm for counting parse trees.
<em>IANDC</em>, <em>303</em>, 105237. (<a
href="https://doi.org/10.1016/j.ic.2024.105237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A parallel algorithm for computing the number of parse trees of a given string according to a fixed context-free grammar is defined. More generally, the algorithm applies to computing the weight of a string in a weighted grammar over any semiring. The algorithm is first implemented on an arithmetic circuit of depth at most 6 ( log 2 ⁡ n ) 2 + O ( log ⁡ n ) and with O ( n 6 ) elements, where the constant factors in the big-O notation depend on the grammar. Then, the circuit is improved using fast matrix multiplication to use only O ( n 5.38 ) elements, while preserving depth O ( ( log ⁡ n ) 2 ) .},
  archive      = {J_IANDC},
  author       = {Margarita Mikhelson and Alexander Okhotin},
  doi          = {10.1016/j.ic.2024.105237},
  journal      = {Information and Computation},
  month        = {3},
  pages        = {105237},
  shortjournal = {Inf. Comput.},
  title        = {A parallel algorithm for counting parse trees},
  volume       = {303},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="icv---19">ICV - 19</h2>
<ul>
<li><details>
<summary>
(2025). MUNet: A lightweight mamba-based under-display camera
restoration network. <em>ICV</em>, <em>156</em>, 105486. (<a
href="https://doi.org/10.1016/j.imavis.2025.105486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under-Display Camera (UDC) restoration aims to recover the underlying clean images from the degraded images captured by UDC. Although promising results have been achieved, most existing UDC restoration methods still suffer from two vital obstacles in practice: (i) existing UDC restoration models are parameter-intensive, and (ii) most of them struggle to capture long-range dependencies within high-resolution images. To overcome above drawbacks, we study a challenging problem in UDC restoration, namely, how to design a lightweight UDC restoration model that could capture long-range image dependencies. To this end, we propose a novel lightweight Mamba-based UDC restoration network (MUNet) consisting of two modules, named Separate Multi-scale Mamba (SMM) and Separate Convolutional Feature Extractor (SCFE). Specifically, SMM exploits our proposed alternate scanning strategy to efficiently capture long-range dependencies across multi-scale image features. SCFE preserves local dependencies through convolutions with various receptive fields. Thanks to SMM and SCFE, MUNet achieves state-of-the-art lightweight UDC restoration performance with significantly fewer parameters, making it well-suited for deployment on mobile devices. Our codes will be available after acceptance.},
  archive      = {J_ICV},
  author       = {Wenxin Wang and Boyun Li and Wanli Liu and Xi Peng and Yuanbiao Gou},
  doi          = {10.1016/j.imavis.2025.105486},
  journal      = {Image and Vision Computing},
  month        = {4},
  pages        = {105486},
  shortjournal = {Image Vis. Comput.},
  title        = {MUNet: A lightweight mamba-based under-display camera restoration network},
  volume       = {156},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dense small target detection algorithm for UAV aerial
imagery. <em>ICV</em>, <em>156</em>, 105485. (<a
href="https://doi.org/10.1016/j.imavis.2025.105485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicle (UAV) aerial images make dense small target detection challenging due to the complex background, small object size in the wide field of view, low resolution, and dense target distribution. Many aerial target detection networks and attention-based methods have been proposed to enhance the capability of dense small target detection, but there are still problems, such as insufficient effective information extraction, missed detection, and false detection of small targets in dense areas. Therefore, this paper proposes a novel dense small target detection algorithm (DSTDA) for UAV aerial images suitable for various high-altitude complex environments. The core component of the proposed DSTDA consists of the multi-axis attention units, the adaptive feature transformation mechanism, and the target-guided sample allocation strategy. Firstly, by introducing the multi-axis attention units into DSTDA, the limitation of DSTDA on global information perception can be addressed. Thus, the detailed features and spatial relationships of small targets at long distances can be sufficiently extracted by our proposed algorithm. Secondly, an adaptive feature transformation mechanism is designed to flexibly adjust the feature map according to the characteristics of the target distribution, which enables the DSTDA to focus more on densely populated target areas. Lastly, a goal-oriented sample allocation strategy is presented, combining coarse screening based on positional information and fine screening guided by target prediction information. By employing this dynamic sample allocation from coarse to fine, the detection performance of small and dense targets in complex backgrounds is further improved. These above innovative improvements empower the DSTDA with enhanced global perception and target-focusing capabilities, effectively addressing the challenges of detecting dense small targets in complex aerial scenes. Experimental validation was conducted on three publicly available datasets: VisDrone, SIMD, and CARPK. The results showed that the proposed DSTDA outperforms other state-of-the-art algorithms in terms of comprehensive performance. The algorithm significantly improves the issues of false alarms and missed detection in drone-based target detection, showcasing remarkable accuracy and real-time performance. It proves to be proficient in the task of detecting dense small targets in drone scenarios.},
  archive      = {J_ICV},
  author       = {Sheng Lu and Yangming Guo and Jiang Long and Zun Liu and Zhuqing Wang and Ying Li},
  doi          = {10.1016/j.imavis.2025.105485},
  journal      = {Image and Vision Computing},
  month        = {4},
  pages        = {105485},
  shortjournal = {Image Vis. Comput.},
  title        = {Dense small target detection algorithm for UAV aerial imagery},
  volume       = {156},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time localization and navigation method for autonomous
vehicles based on multi-modal data fusion by integrating memory
transformer and DDQN. <em>ICV</em>, <em>156</em>, 105484. (<a
href="https://doi.org/10.1016/j.imavis.2025.105484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of autonomous driving, real-time localization and navigation are the core technologies that ensure vehicle safety and precise operation. With advancements in sensor technology and computing power, multi-modal data fusion has become a key method for enhancing the environmental perception capabilities of autonomous vehicles. This study aims to explore a novel visual-language navigation technology to achieve precise navigation of autonomous cars in complex environments. By integrating information from radar, sonar, 5G networks, Wi-Fi, Bluetooth, and a 360-degree visual information collection device mounted on the vehicle&#39;s roof, the model fully exploits rich multi-source data. The model uses the Memory Transformer for efficient data encoding and a data fusion strategy with a self-attention network, ensuring a balance between feature integrity and algorithm real-time performance. Furthermore, the encoded data is input into a DDQN vehicle navigation algorithm based on an automatically growing environmental target knowledge graph and large-scale scene maps, enabling continuous learning and optimization in real-world environments. Comparative experiments show that the proposed model outperforms existing SOTA models, particularly in terms of macro-spatial reference from large-scale scene maps, background knowledge support from the automatically growing knowledge graph, and the experience-optimized navigation strategies of the DDQN algorithm. In the comparative experiments with the SOTA models, the proposed model achieved scores of 3.99, 0.65, 0.67, 0.65, 0.63, and 0.63 on the six metrics NE, SR, OSR, SPL, CLS, and DTW, respectively. All of these results significantly enhance the intelligent positioning and navigation capabilities of autonomous driving vehicles.},
  archive      = {J_ICV},
  author       = {Li Zha and Chen Gong and Kunfeng Lv},
  doi          = {10.1016/j.imavis.2025.105484},
  journal      = {Image and Vision Computing},
  month        = {4},
  pages        = {105484},
  shortjournal = {Image Vis. Comput.},
  title        = {Real-time localization and navigation method for autonomous vehicles based on multi-modal data fusion by integrating memory transformer and DDQN},
  volume       = {156},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A spatial-frequency domain multi-branch decoder method for
real-time semantic segmentation. <em>ICV</em>, <em>156</em>, 105483. (<a
href="https://doi.org/10.1016/j.imavis.2025.105483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation is crucial for the functionality of autonomous driving systems. However, most of the existing real-time semantic segmentation models focus on encoder design and underutilize spatial and frequency domain information in the decoder, limiting the segmentation accuracy of the model. To solve this problem, this paper proposes a multi-branch decoder network combining spatial domain and frequency domain to meet the real-time and accuracy requirements of the semantic segmentation task of road scenes for autonomous driving systems. Firstly, the network introduces a novel multi-scale dilated fusion block that gradually enlarges the receptive field through three consecutive dilated convolutions, and integrates features from different levels using skip connections. At the same time, a strategy of gradually reducing the number of channels is adopted to effectively remove redundant features. Secondly, we design three branches for the decoder. The global branch utilizes a lightweight Transformer architecture to extract global features and employs horizontal and vertical convolutions to achieve interaction among global features. The multi-scale branch combines dilated convolution and adaptive pooling to perform multi-scale feature extraction through fusion and post-processing. The wavelet transform feature converter maps spatial domain features into low-frequency and high-frequency components, which are then fused with global and multi-scale features to enhance the model representation. Finally, we conduct experiments on multiple datasets. The experimental results show that the proposed method best balances segmentation accuracy and inference speed.},
  archive      = {J_ICV},
  author       = {Liwei Deng and Boda Wu and Songyu Chen and Dongxue Li and Yanze Fang},
  doi          = {10.1016/j.imavis.2025.105483},
  journal      = {Image and Vision Computing},
  month        = {4},
  pages        = {105483},
  shortjournal = {Image Vis. Comput.},
  title        = {A spatial-frequency domain multi-branch decoder method for real-time semantic segmentation},
  volume       = {156},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CMS-net: Edge-aware multimodal MRI feature fusion for brain
tumor segmentation. <em>ICV</em>, <em>156</em>, 105481. (<a
href="https://doi.org/10.1016/j.imavis.2025.105481">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing application of artificial intelligence in medical image processing, multimodal MRI brain tumor segmentation has become crucial for clinical diagnosis and treatment. Accurate segmentation relies heavily on the effective utilization of multimodal information. However, most existing methods primarily focus on global and local deep semantic features, often overlooking critical aspects such as edge information and cross-channel correlations. To address these limitations while retaining the strengths of existing methods, we propose a novel brain tumor segmentation approach: an edge-aware feature fusion model based on a dual-encoder architecture. CMS-Net is a novel brain tumor segmentation model that integrates edge-aware fusion, cross-channel interaction, and spatial state feature extraction to fully leverage multimodal information for improved segmentation accuracy. The architecture comprises two main components: an encoder and a decoder. The encoder utilizes both convolutional downsampling and Smart Swin Transformer downsampling, with the latter employing Shifted Spatial Multi-Head Self-Attention (SSW-MSA) to capture global features and enhance long-range dependencies. The decoder reconstructs the image via the CMS-Block, which consists of three key modules: the Multi-Scale Deep Convolutional Cross-Channel Attention module (MDTA), the Spatial State Module (SSM), and the Boundary-Aware Feature Fusion module (SWA). CMS-Net&#39;s dual-encoder architecture allows for deep extraction of both local and global features, enhancing segmentation performance. MDTA generates attention maps through cross-channel covariance, while SSM models spatial context to improve the understanding of complex structures. The SWA module, combining SSW-MSA with pooling, subtraction, and convolution, facilitates feature fusion and edge extraction. Dice and Focal loss functions were introduced to optimize cross-channel and spatial feature extraction. Experimental results on the BraTS2018, BraTS2019, and BraTS2020 datasets demonstrate that CMS-Net effectively integrates spatial state, cross-channel, and boundary information, significantly improving multimodal brain tumor segmentation accuracy.},
  archive      = {J_ICV},
  author       = {Chunjie Lv and Biyuan Li and Xiuwei Wang and Pengfei Cai and Bo Yang and Xuefeng Jia and Jun Yan},
  doi          = {10.1016/j.imavis.2025.105481},
  journal      = {Image and Vision Computing},
  month        = {4},
  pages        = {105481},
  shortjournal = {Image Vis. Comput.},
  title        = {CMS-net: Edge-aware multimodal MRI feature fusion for brain tumor segmentation},
  volume       = {156},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial cascaded clustering and weighted memory for
unsupervised person re-identification. <em>ICV</em>, <em>156</em>,
105478. (<a href="https://doi.org/10.1016/j.imavis.2025.105478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in unsupervised person re-identification (re-ID) methods have demonstrated high performance by leveraging fine-grained local context, often referred to as part-based methods. However, many existing part-based methods rely on horizontal division to obtain local contexts, leading to misalignment issues caused by various human poses. Moreover, misalignment of semantic information within part features hampers the effectiveness of metric learning, thereby limiting the potential of part-based methods. These challenges result in under-utilization of part features in existing approaches. To address these issues, we introduce the Spatial Cascaded Clustering and Weighted Memory (SCWM) method. SCWM aims to parse and align more accurate local contexts for different human body parts while allowing the memory module to balance hard example mining and noise suppression. Specifically, we first analyze the issues of foreground omissions and spatial confusions in previous methods. We then propose foreground and space corrections to enhance the completeness and reasonableness of human parsing results. Next, we introduce a weighted memory and utilize two weighting strategies. These strategies address hard sample mining for global features and enhance noise resistance for part features, enabling better utilization of both global and part features. Extensive experiments conducted on Market-1501, DukeMTMC-reID and MSMT17 datasets validate the effectiveness of the proposed method over numerous state-of-the-art methods.},
  archive      = {J_ICV},
  author       = {Jiahao Hong and Jialong Zuo and Chuchu Han and Ruochen Zheng and Ming Tian and Changxin Gao and Nong Sang},
  doi          = {10.1016/j.imavis.2025.105478},
  journal      = {Image and Vision Computing},
  month        = {4},
  pages        = {105478},
  shortjournal = {Image Vis. Comput.},
  title        = {Spatial cascaded clustering and weighted memory for unsupervised person re-identification},
  volume       = {156},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-information guided camouflaged object detection.
<em>ICV</em>, <em>156</em>, 105470. (<a
href="https://doi.org/10.1016/j.imavis.2025.105470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camouflaged Object Detection (COD) aims to identify the objects hidden in the background environment. Though more and more COD methods have been proposed in recent years, existing methods still perform poorly for detecting small objects, obscured objects, boundary-rich objects, and multi-objects, mainly because they fail to effectively utilize context information, texture information, and boundary information simultaneously. Therefore, in this paper, we propose a Multi-information Guided Camouflaged Object Detection Network (MIGNet) to fully utilize multi-information containing context information, texture information, and boundary information to boost the performance of camouflaged object detection. Specifically, firstly, we design the texture and boundary label and the Texture and Boundary Enhanced Module (TBEM) to obtain differentiated texture information and boundary information. Next, the Neighbor Context Information Exploration Module (NCIEM) is designed to obtain rich multi-scale context information. Then, the Parallel Group Bootstrap Module (PGBM) is designed to maximize the effective aggregation of context information, texture information and boundary information. Finally, Information Enhanced Decoder (IED) is designed to effectively enhance the interaction of neighboring layer features and suppress the background noise for good detection results. Extensive quantitative and qualitative experiments are conducted on four widely used datasets. The experimental results indicate that our proposed MIGNet with good performance of camouflaged object detection outperforms the other 22 COD models.},
  archive      = {J_ICV},
  author       = {Caijuan Shi and Lin Zhao and Rui Wang and Kun Zhang and Fanyue Kong and Changyu Duan},
  doi          = {10.1016/j.imavis.2025.105470},
  journal      = {Image and Vision Computing},
  month        = {4},
  pages        = {105470},
  shortjournal = {Image Vis. Comput.},
  title        = {Multi-information guided camouflaged object detection},
  volume       = {156},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SFFEF-YOLO: Small object detection network based on
fine-grained feature extraction and fusion for unmanned aerial images.
<em>ICV</em>, <em>156</em>, 105469. (<a
href="https://doi.org/10.1016/j.imavis.2025.105469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicles (UAVs) images object detection has emerged as a research hotspot, yet remains a significant challenge due to variable target scales and the high proportion of small objects caused by UAVs’ diverse altitudes and angles. To address these issues, we propose a novel Small Object Detection Network Based on Fine-Grained Feature Extraction and Fusion(SFFEF-YOLO). First, we introduce a tiny prediction head to replace the large prediction head, enhancing the detection accuracy for tiny objects while reducing model complexity. Second, we design a Fine-Grained Information Extraction Module (FIEM) to replace standard convolutions. This module improves feature extraction and reduces information loss during downsampling by utilizing multi-branch operations and SPD-Conv. Third, we develop a Multi-Scale Feature Fusion Module (MFFM), which adds an additional skip connection branch based on the bidirectional feature pyramid network (BiFPN) to preserve fine-grained information and improve multi-scale feature fusion. We evaluated SFFEF-YOLO on the VisDrone2019-DET and UAVDT datasets. Compared to YOLOv8, experimental results demonstrate that SFFEF-YOLO achieves a 9.9% mAP0.5 improvement on the VisDrone2019-DET dataset and a 3.6% mAP0.5 improvement on the UAVDT dataset.},
  archive      = {J_ICV},
  author       = {Chenxi Bai and Kexin Zhang and Haozhe Jin and Peng Qian and Rui Zhai and Ke Lu},
  doi          = {10.1016/j.imavis.2025.105469},
  journal      = {Image and Vision Computing},
  month        = {4},
  pages        = {105469},
  shortjournal = {Image Vis. Comput.},
  title        = {SFFEF-YOLO: Small object detection network based on fine-grained feature extraction and fusion for unmanned aerial images},
  volume       = {156},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint transformer and mamba fusion for multispectral object
detection. <em>ICV</em>, <em>156</em>, 105468. (<a
href="https://doi.org/10.1016/j.imavis.2025.105468">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multispectral object detection is generally considered better than single-modality-based object detection, due to the complementary properties of multispectral image pairs. However, how to integrate features from images of different modalities for object detection is still an open problem. In this paper, we propose a new multispectral object detection framework based on the Transformer and Mamba architectures, called the joint Transformer and Mamba detection (JTMDet). Specifically, we divide the feature fusion process into two stages, the intra-scale fusion stage and the inter-scale fusion stage, to comprehensively utilize the multi-modal features at different scales. To this end, we designed the so-called cross-modal fusion (CMF) and cross-level fusion (CLF) modules, both of which contain JTMBlock modules. A JTMBlock module interweaves the Transformer and Mamba layers to robustly capture the useful information in multispectral image pairs while maintaining high inference speed. Extensive experiments on three publicly available datasets conclusively show that the proposed JTMDet framework achieves state-of-the-art multispectral object detection performance, and is competitive with current leading methods. Code and pre-trained models are publicly available at https://github.com/LiC2023/JTMDet .},
  archive      = {J_ICV},
  author       = {Chao Li and Xiaoming Peng},
  doi          = {10.1016/j.imavis.2025.105468},
  journal      = {Image and Vision Computing},
  month        = {4},
  pages        = {105468},
  shortjournal = {Image Vis. Comput.},
  title        = {Joint transformer and mamba fusion for multispectral object detection},
  volume       = {156},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AF2CN: Towards effective demoiréing from multi-resolution
images. <em>ICV</em>, <em>156</em>, 105467. (<a
href="https://doi.org/10.1016/j.imavis.2025.105467">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, CNN-based methods have gained significant attention for addressing the demoiré task due to their powerful feature extraction capabilities. However, these methods are generally trained on datasets with fixed resolutions, limiting their applicability to diverse real-world scenarios. To address this limitation, we introduce a more generalized task: effective demoiréing across multiple resolutions. To facilitate this task, we constructed MTADM, the first multi-resolution moiré dataset, designed to capture diverse real-world scenarios. Leveraging this dataset, we conducted extensive studies and introduced the Adaptive Fractional Calculus and Adjacency Fusion Convolution Network (AF2CN). Specifically, we employ fractional derivatives to develop an adaptive frequency enhancement module, which refines spatial distribution and texture details in moiré patterns. Additionally, we design a spatial attention gate to enhance deep feature interaction. Extensive experiments demonstrate that AF2CN effectively handles multi-resolution moiré patterns. It significantly outperforms previous state-of-the-art methods on fixed-resolution benchmarks while requiring fewer parameters and achieving lower computational costs.},
  archive      = {J_ICV},
  author       = {Shitan Asu and Yujin Dai and Shijie Li and Zheng Li},
  doi          = {10.1016/j.imavis.2025.105467},
  journal      = {Image and Vision Computing},
  month        = {4},
  pages        = {105467},
  shortjournal = {Image Vis. Comput.},
  title        = {AF2CN: Towards effective demoiréing from multi-resolution images},
  volume       = {156},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Innovative underwater image enhancement algorithm: Combined
application of adaptive white balance color compensation and pyramid
image fusion to submarine algal microscopy. <em>ICV</em>, <em>156</em>,
105466. (<a href="https://doi.org/10.1016/j.imavis.2025.105466">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time collected microscopic images of harmful algal blooms (HABs) in coastal areas often suffer from significant color deviations and loss of fine cellular details. To address these issues, this paper proposes an innovative method for enhancing underwater marine algal microscopic images based on Adaptive White Balance Color Compensation (AWBCC) and Image Pyramid Fusion (IPF). Firstly, an effective Algorithm Adaptive Cyclic Channel Compensation (ACCC) is proposed based on the gray world assumption to enhance the color of underwater images. Then, the Maximum Color Channel Attention Guidance (MCCAG) method is employed to reduce color disturbance caused by ignoring light absorption. This paper introduces an Empirical Contrast Enhancement (ECH) module based on multi-scale IPF tailored for underwater microscopic images of algae, which is used for global contrast enhancement, texture detail enhancement, and noise control. Secondly, this paper proposes a network based on a diffusion probability model for edge detection in HABs, which simultaneously considers both high-order and low-order features extracted from images. This approach enriches the semantic information of the feature maps and enhances edge detection accuracy. This edge detection method achieves an ODS of 0.623 and an OIS of 0.683. Experimental evaluations demonstrate that our underwater algae microscopic image enhancement method amplifies local texture features while preserving the original image structure. This significantly improves the accuracy of edge detection and key point matching. Compared to several state-of-the-art underwater image enhancement methods, our approach achieves the highest values in contrast, average gradient, entropy, and Enhancement Measure Estimation (EME), and also delivers competitive results in terms of image noise control. .},
  archive      = {J_ICV},
  author       = {Yi-Ning Fan and Geng-Kun Wu and Jia-Zheng Han and Bei-Ping Zhang and Jie Xu},
  doi          = {10.1016/j.imavis.2025.105466},
  journal      = {Image and Vision Computing},
  month        = {4},
  pages        = {105466},
  shortjournal = {Image Vis. Comput.},
  title        = {Innovative underwater image enhancement algorithm: Combined application of adaptive white balance color compensation and pyramid image fusion to submarine algal microscopy},
  volume       = {156},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature field fusion for few-shot novel view synthesis.
<em>ICV</em>, <em>156</em>, 105465. (<a
href="https://doi.org/10.1016/j.imavis.2025.105465">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconstructing neural radiance fields from limited or sparse views has given very promising potential for this field of research. Previous methods usually constrain the reconstruction process with additional priors, e.g. semantic-based or patch-based regularization. Nevertheless, such regularization is given to the synthesis of unseen views, which may not effectively assist the field of learning, in particular when the training views are sparse. Instead, we propose a feature Field Fusion (FFusion) NeRF in this paper that can learn structure and more details from features extracted from pre-trained neural networks for the sparse training views, and use as extra guide for the training of the RGB field. With such extra feature guides, FFusion predicts more accurate color and density when synthesizing novel views. Experimental results have shown that FFusion can effectively improve the quality of the synthesized novel views with only limited or sparse inputs.},
  archive      = {J_ICV},
  author       = {Junting Li and Yanghong Zhou and Jintu Fan and Dahua Shou and Sa Xu and P.Y. Mok},
  doi          = {10.1016/j.imavis.2025.105465},
  journal      = {Image and Vision Computing},
  month        = {4},
  pages        = {105465},
  shortjournal = {Image Vis. Comput.},
  title        = {Feature field fusion for few-shot novel view synthesis},
  volume       = {156},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gait recognition via view-aware part-wise attention and
multi-scale dilated temporal extractor. <em>ICV</em>, <em>156</em>,
105464. (<a href="https://doi.org/10.1016/j.imavis.2025.105464">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gait recognition based on silhouette sequences has made significant strides in recent years through the extraction of body shape and motion features. However, challenges remain in achieving accurate gait recognition under covariate changes, such as variations in view and clothing. To tackle these issues, this paper introduces a novel methodology incorporating a View-aware Part-wise Attention (VPA) mechanism and a Multi-scale Dilated Temporal Extractor (MDTE) to enhance gait recognition. Distinct from existing techniques, VPA mechanism acknowledges the differential sensitivity of various body parts to view changes, applying targeted attention weights at the feature level to improve the efficacy of view-aware constraints in areas of higher saliency or distinctiveness. Concurrently, MDTE employs dilated convolutions across multiple scales to capture the temporal dynamics of gait at diverse levels, thereby refining the motion representation. Comprehensive experiments on the CASIA-B, OU-MVLP, and Gait3D datasets validate the superior performance of our approach. Remarkably, our method achieves a 91.0% accuracy rate under clothing-change conditions on the CASIA-B dataset using solely silhouette information, surpassing the current state-of-the-art (SOTA) techniques. These results underscore the effectiveness and adaptability of our proposed strategy in overcoming the complexities of gait recognition amidst covariate changes.},
  archive      = {J_ICV},
  author       = {Xu Song and Yang Wang and Yan Huang and Caifeng Shan},
  doi          = {10.1016/j.imavis.2025.105464},
  journal      = {Image and Vision Computing},
  month        = {4},
  pages        = {105464},
  shortjournal = {Image Vis. Comput.},
  title        = {Gait recognition via view-aware part-wise attention and multi-scale dilated temporal extractor},
  volume       = {156},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning for brain tumor segmentation in multimodal MRI
images: A review of methods and advances. <em>ICV</em>, <em>156</em>,
105463. (<a href="https://doi.org/10.1016/j.imavis.2025.105463">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background and Objectives: Image segmentation is crucial in applications like image understanding, feature extraction, and analysis. The rapid development of deep learning techniques in recent years has significantly enhanced the field of medical image processing, with the process of segmenting tumor from MRI images of the brain emerging as a particularly active area of interest within the medical science community. Existing reviews predominantly focus on traditional CNNs and Transformer models but lack systematic analysis and experimental validation on the application of the emerging Mamba architecture in multimodal brain tumor segmentation, the handling of missing modalities, the potential of multimodal fusion strategies, and the heterogeneity of datasets. Methods: This paper provides a comprehensive literature review of recent deep learning-based methods for multimodal brain tumor segmentation using multimodal MRI images, including performance and quantitative analysis of state-of-the-art approaches. It focuses on the handling of multimodal fusion, adaptation techniques, and missing modality, while also delving into the performance, advantages, and disadvantages of deep learning models such as U-Net, Transformer, hybrid deep learning, and Mamba-based methods in segmentation tasks. Results: Through the entire review process, It is found that most researchers preferred to use the Transformer-based U-Net model and mamba-based U-Net, especially the fusion model combination of U-Net and mamba, for image segmentation.},
  archive      = {J_ICV},
  author       = {Bin Jiang and Maoyu Liao and Yun Zhao and Gen Li and Siyu Cheng and Xiangkai Wang and Qingling Xia},
  doi          = {10.1016/j.imavis.2025.105463},
  journal      = {Image and Vision Computing},
  month        = {4},
  pages        = {105463},
  shortjournal = {Image Vis. Comput.},
  title        = {Deep learning for brain tumor segmentation in multimodal MRI images: A review of methods and advances},
  volume       = {156},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multispectral images reconstruction using median filtering
based spectral correlation. <em>ICV</em>, <em>156</em>, 105462. (<a
href="https://doi.org/10.1016/j.imavis.2025.105462">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multispectral images are widely utilized in various computer vision applications because they capture more information than traditional color images. Multispectral imaging systems utilize a multispectral filter array (MFA), an extension of the color filter array found in standard RGB cameras. This approach provides an efficient, cost-effective, and practical method for capturing multispectral images. The primary challenge with multispectral imaging systems using an MFA is the significant undersampling of spectral bands in the mosaicked image. This occurs because a multispectral mosaic image contains a greater number of spectral bands compared to an RGB mosaicked image, leading to reduced sampling density per band. Now, multispectral demosaicing algorithm is required to generate the complete multispectral image from the mosaicked image. The effectiveness of demosaicing algorithms relies heavily on the efficient utilization of spatial and spectral correlations inherent in mosaicked images. In the proposed method, a binary tree-based MFA pattern is employed to capture the mosaicked image. Rather than directly leveraging spectral correlations between bands, median filtering is applied to the spectral differences to mitigate the impact of noise on these correlations. Experimental results demonstrate that the proposed method achieves an improvement of 1.03 dB and 0.92 dB on average from 5-band to 10-band multispectral images from the widely used TokyoTech and CAVE datasets, respectively.},
  archive      = {J_ICV},
  author       = {Vishwas Rathi and Abhilasha Sharma and Amit Kumar Singh},
  doi          = {10.1016/j.imavis.2025.105462},
  journal      = {Image and Vision Computing},
  month        = {4},
  pages        = {105462},
  shortjournal = {Image Vis. Comput.},
  title        = {Multispectral images reconstruction using median filtering based spectral correlation},
  volume       = {156},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NPVForensics: Learning VA correlations in non-critical
phoneme–viseme regions for deepfake detection. <em>ICV</em>,
<em>156</em>, 105461. (<a
href="https://doi.org/10.1016/j.imavis.2025.105461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced deepfake technology enables the manipulation of visual and audio signals within videos, leading to visual–audio (VA) inconsistencies. Current multimodal detectors primarily rely on VA contrastive learning to identify such inconsistencies, particularly in critical phoneme–viseme (PV) regions. However, state-of-the-art deepfake techniques have aligned critical PV pairs, thereby reducing the inconsistency traces on which existing methods rely. Due to technical constraints, forgers cannot fully synchronize VA in non-critical phoneme–viseme (NPV) regions. Consequently, we exploit inconsistencies in NPV regions as a general cue for deepfake detection. We propose NPVForensics, a two-stage VA correlation learning framework specifically designed to detect VA inconsistencies in NPV regions of deepfake videos. Firstly, to better extract VA unimodal features, we utilize the Swin Transformer to capture long-term global dependencies. Additionally, the Local Feature Aggregation (LFA) module aggregates local features from spatial and channel dimensions, thus preserving more comprehensive and subtle information. Secondly, the VA Correlation Learning (VACL) module enhances intra-modal augmentation and inter-modal information interaction, exploring intrinsic correlations between the two modalities. Moreover, Representation Alignment is introduced for real videos to narrow the modal gap and effectively extract VA correlations. Finally, our model is pre-trained on real videos using a self-supervised strategy and fine-tuned for the deepfake detection task. We conducted extensive experiments on six widely used deepfake datasets: FaceForensics++, FakeAVCeleb, Celeb-DF-v2, DFDC, FaceShifter, and DeeperForensics-1.0. Our method achieves state-of-the-art performance in cross-manipulation generalization and robustness. Notably, our approach demonstrates superior performance on VA-coordinated datasets such as A2V, T2V-L, and T2V-S. It indicates that VA inconsistencies in NPV regions serve as a general cue for deepfake detection.},
  archive      = {J_ICV},
  author       = {Yu Chen and Yang Yu and Rongrong Ni and Haoliang Li and Wei Wang and Yao Zhao},
  doi          = {10.1016/j.imavis.2025.105461},
  journal      = {Image and Vision Computing},
  month        = {4},
  pages        = {105461},
  shortjournal = {Image Vis. Comput.},
  title        = {NPVForensics: Learning VA correlations in non-critical phoneme–viseme regions for deepfake detection},
  volume       = {156},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FRoundation: Are foundation models ready for face
recognition? <em>ICV</em>, <em>156</em>, 105453. (<a
href="https://doi.org/10.1016/j.imavis.2025.105453">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Foundation models are predominantly trained in an unsupervised or self-supervised manner on highly diverse and large-scale datasets, making them broadly applicable to various downstream tasks. In this work, we investigate for the first time whether such models are suitable for the specific domain of face recognition (FR). We further propose and demonstrate the adaptation of these models for FR across different levels of data availability, including synthetic data. Extensive experiments are conducted on multiple foundation models and datasets of varying scales for training and fine-tuning, with evaluation on a wide range of benchmarks. Our results indicate that, despite their versatility, pre-trained foundation models tend to underperform in FR in comparison with similar architectures trained specifically for this task. However, fine-tuning foundation models yields promising results, often surpassing models trained from scratch, particularly when training data is limited. For example, after fine-tuning only on 1K identities, DINOv2 ViT-S achieved average verification accuracy on LFW, CALFW, CPLFW, CFP-FP, and AgeDB30 benchmarks of 87.10%, compared to 64.70% achieved by the same model and without fine-tuning. While training the same model architecture, ViT-S, from scratch on 1k identities reached 69.96%. With access to larger-scale FR training datasets, these performances reach 96.03% and 95.59% for the DINOv2 and CLIP ViT-L models, respectively. In comparison to the ViT-based architectures trained from scratch for FR, fine-tuned same architectures of foundation models achieve similar performance while requiring lower training computational costs and not relying on the assumption of extensive data availability. We further demonstrated the use of synthetic face data, showing improved performances over both pre-trained foundation and ViT models. Additionally, we examine demographic biases, noting slightly higher biases in certain settings when using foundation models compared to models trained from scratch. We release our code and pre-trained models’ weights at github.com/TaharChettaoui/FRoundation .},
  archive      = {J_ICV},
  author       = {Tahar Chettaoui and Naser Damer and Fadi Boutros},
  doi          = {10.1016/j.imavis.2025.105453},
  journal      = {Image and Vision Computing},
  month        = {4},
  pages        = {105453},
  shortjournal = {Image Vis. Comput.},
  title        = {FRoundation: Are foundation models ready for face recognition?},
  volume       = {156},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PolarDETR: Polar parametrization for vision-based
surround-view 3D detection. <em>ICV</em>, <em>156</em>, 105438. (<a
href="https://doi.org/10.1016/j.imavis.2025.105438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D detection based on surround-view camera system is a critical and promising technique in autopilot. In this work, we exploit the view symmetry of surround-view camera system as inductive bias to improve optimization and boost performance. We parameterize object’s position by polar coordinate and decompose velocity along radial and tangential direction. And the perception range, label assignment and loss function are correspondingly reformulated in polar coordinate system. This new Polar Parametrization scheme establishes explicit associations between image patterns and prediction targets. Based on it, we propose a surround-view 3D detection method, termed PolarDETR. PolarDETR achieves competitive performance on nuScenes dataset. Thorough ablation studies are provided to validate the effectiveness.},
  archive      = {J_ICV},
  author       = {Shaoyu Chen and Xinggang Wang and Tianheng Cheng and Qian Zhang and Chang Huang and Wenyu Liu},
  doi          = {10.1016/j.imavis.2025.105438},
  journal      = {Image and Vision Computing},
  month        = {4},
  pages        = {105438},
  shortjournal = {Image Vis. Comput.},
  title        = {PolarDETR: Polar parametrization for vision-based surround-view 3D detection},
  volume       = {156},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DAN: Distortion-aware network for fisheye image
rectification using graph reasoning. <em>ICV</em>, <em>156</em>, 105423.
(<a href="https://doi.org/10.1016/j.imavis.2025.105423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the wide-field view of fisheye images, their application is still hindered by the presentation of distortions. Existing learning-based methods still suffer from artifacts and loss of details, especially at the image edges. To address this, we introduce the Distortion-aware Network (DAN), a novel deep network architecture for fisheye image rectification that leverages graph reasoning. Specifically, we employ the superior relational understanding capability of graph technology to associate distortion patterns in different regions, generating an accurate and globally consistent unwarping flow. Meanwhile, during the image reconstruction process, we utilize deformable convolution to construct same-resolution feature blocks and employ skip connections to supplement the detailed information. Additionally, we introduce a weight decay-based multi-scale loss function, enabling the model to focus more on accuracy at high-resolution layers while enhancing the model’s generalization ability. To address the lack of quantitative evaluation standards for real fisheye images, we propose a new metric called the “Line Preservation Metric.” Through qualitative and quantitative experiments on PLACE365, COCO2017 and real fisheye images, the proposed method proves to outperform existing methods in terms of performance and generalization.},
  archive      = {J_ICV},
  author       = {Yongjia Yan and Hongzhe Liu and Cheng Zhang and Cheng Xu and Bingxin Xu and Weiguo Pan and Songyin Dai and Yiqing Song},
  doi          = {10.1016/j.imavis.2025.105423},
  journal      = {Image and Vision Computing},
  month        = {4},
  pages        = {105423},
  shortjournal = {Image Vis. Comput.},
  title        = {DAN: Distortion-aware network for fisheye image rectification using graph reasoning},
  volume       = {156},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ijar---10">IJAR - 10</h2>
<ul>
<li><details>
<summary>
(2025). Improved evidential three-way decisions in incomplete
multi-scale information systems. <em>IJAR</em>, <em>181</em>, 109417.
(<a href="https://doi.org/10.1016/j.ijar.2025.109417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Granular computing, by simulating human thought processes, provides a paradigm for solving complex decision-making problems. The three-way decision is a key component of granular computing. Compared to traditional decision-making methodologies, it introduces “deferred decision-making”, allowing for multi-granularity exploration of alternatives. This process gradually refines the granularity of alternatives, leading to a transition between acceptance and rejection. Moreover, data structures in the real world are typically multi-granular, multi-level, and incomplete. Compared to single-scale information systems, incomplete multi-scale information systems provide richer decision foundations by mapping information to different levels. Additionally, they allow for more precise and flexible decision-making by integrating attribute information from different levels at a specific granularity, depending on requirements. Therefore, this paper seeks to present a three-way multi-scale decision-making methodology under incomplete environments. First, an integration methodology under incomplete multi-scale information systems by using the best-worst method is built, which comprehensively considers the importance of each scale of attributes. Second, the grey relation analysis calculation is integrated into the technique for order preference by similarity to ideal solution methodology to obtain the score of alternatives, serving as the conditional probability of three-way decisions, which compensates for the problem of Euclidean distance failures due to the correlation among indicators. Third, according to the evidence theory and the enhanced belief Jensen-Sharma-Mittal divergence, the thresholds of three-way decisions are fused, improving the classification efficiency of three-way decisions for alternatives. Finally, the effectiveness of the methodology established in this paper is validated using the campus environment evaluation data set collected through the Questionnaire Star from Shanxi University, China.},
  archive      = {J_IJAR},
  author       = {Rui Li and Chao Zhang and Deyu Li and Wentao Li and Jianming Zhan},
  doi          = {10.1016/j.ijar.2025.109417},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109417},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Improved evidential three-way decisions in incomplete multi-scale information systems},
  volume       = {181},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel axiomatic approach to l-valued rough sets within an
l-universe via inner product and outer product of l-subsets.
<em>IJAR</em>, <em>181</em>, 109416. (<a
href="https://doi.org/10.1016/j.ijar.2025.109416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fuzzy rough approximation operator serves as the cornerstone of fuzzy rough set theory and its practical applications. Axiomatization is a crucial approach in the exploration of fuzzy rough sets, aiming to offer a clear and direct characterization of fuzzy rough approximation operators. Among the fundamental tools employed in this process, the inner product and outer product of fuzzy sets stand out as essential components in the axiomatization of fuzzy rough sets. In this paper, we will develop the axiomatization of a comprehensive fuzzy rough set theory, that is, the so-called L -valued rough sets with an L -set serving as the foundational universe (referred to as the L -universe) for defining L -valued rough approximation operators, where L typically denotes a GL-quantale. Firstly, we give the notions of inner product and outer product of two L -subsets within an L -universe and examine their basic properties. It is shown that these notions are extensions of the corresponding notion of fuzzy sets within a classical universe. Secondly, leveraging the inner product and outer product of L -subsets, we respectively characterize L -valued upper and lower rough approximation operators generated by general, reflexive, transitive, symmetric, Euclidean, and median L -value relations on L -universe as well as their compositions. Finally, utilizing the provided axiomatic characterizations, we present the precise examples for the least and largest equivalent L -valued upper and lower rough approximation operators. Notably, many existing axiom characterizations of fuzzy rough sets within classical universe can be viewed as direct consequences of our findings.},
  archive      = {J_IJAR},
  author       = {Lingqiang Li and Qiu Jin},
  doi          = {10.1016/j.ijar.2025.109416},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109416},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A novel axiomatic approach to L-valued rough sets within an L-universe via inner product and outer product of L-subsets},
  volume       = {181},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Matrix-based local multigranulation reduction for covering
decision information systems. <em>IJAR</em>, <em>181</em>, 109415. (<a
href="https://doi.org/10.1016/j.ijar.2025.109415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute reduction has become an essential step in pattern recognition and machine learning tasks. As an extension of the classical rough set, the covering rough set has garnered considerable attention in both theory and application. A matrix-based method for computing local covering optimistic approximation sets and local optimistic multigranulation reductions based on covering rough set in covering decision information systems (CDISs) is proposed in this paper. Firstly, we introduce a matrix representation along with its associated operations to compute the local covering optimistic approximation sets and the local positive regions of the CDISs. Subsequently, local optimistic discernibility matrices and local optimistic discernibility functions are constructed for the CDISs. By performing disjunction and conjunction operations on these local optimistic discernibility matrices, all local optimistic multigranulation reductions of the CDISs can be accurately obtained. In addition, an algorithm is developed using the local optimistic discernibility matrix to compute a suboptimal minimal local optimistic multigranulation reduction. Finally, to verify the effectiveness and feasibility of the proposed method, numerical experiments are conducted on 6 UCI datasets.},
  archive      = {J_IJAR},
  author       = {Tao Jiang and Yan-Lan Zhang},
  doi          = {10.1016/j.ijar.2025.109415},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109415},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Matrix-based local multigranulation reduction for covering decision information systems},
  volume       = {181},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Characterizations for union and intersection on non-normal
membership functions of type-2 fuzzy sets. <em>IJAR</em>, <em>181</em>,
109414. (<a href="https://doi.org/10.1016/j.ijar.2025.109414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we mainly investigate set operations for type-2 fuzzy sets. To be more exact, we present several algorithms under the left continuous t-norms that compute the join and meet operations of the non-normal convex secondary membership functions of type-2 fuzzy sets, and give some properties of operations that would enhance the application of fuzzy logic connectives. We anticipate that these algorithms can be applied to type-2 fuzzy logic systems as well as several fields of soft computing that tackle logical operations in type-2 fuzzy sets.},
  archive      = {J_IJAR},
  author       = {Zhi-qiang Liu and Jingxin Liu},
  doi          = {10.1016/j.ijar.2025.109414},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109414},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Characterizations for union and intersection on non-normal membership functions of type-2 fuzzy sets},
  volume       = {181},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised hierarchical multi-label classifier based on
local information. <em>IJAR</em>, <em>181</em>, 109411. (<a
href="https://doi.org/10.1016/j.ijar.2025.109411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scarcity of labeled data is a common problem in supervised classification, since hand-labeling can be time consuming, expensive or hard to label; on the other hand, large amounts of unlabeled information can be found. The problem of scarcity of labeled data is even more notorious in hierarchical classification, because the data of a node is split among its children, which results in few instances associated to the deepest nodes of the hierarchy. In this work it is proposed the semi-supervised hierarchical multi-label classifier based on local information (SSHMC-BLI) which can be trained with labeled and unlabeled data to perform hierarchical classification tasks. The method can be applied to any type of hierarchical problem, here we focus on the most difficult case: hierarchies of DAG type, where the instances can be associated to multiple paths of labels which can finish in an internal node. SSHMC-BLI builds pseudo-labels for each unlabeled instance from the paths of labels of its labeled neighbors, while it considers whether the unlabeled instance is similar to its neighbors. Experiments on 12 challenging datasets from functional genomics show that making use of unlabeled along with labeled data can help to improve the performance of a supervised hierarchical classifier trained only on labeled data, even with statistical significance.},
  archive      = {J_IJAR},
  author       = {Jonathan Serrano-Pérez and L. Enrique Sucar},
  doi          = {10.1016/j.ijar.2025.109411},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109411},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Semi-supervised hierarchical multi-label classifier based on local information},
  volume       = {181},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hyperspace approach to relation-based neighborhood
operators. <em>IJAR</em>, <em>181</em>, 109404. (<a
href="https://doi.org/10.1016/j.ijar.2025.109404">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, new, subsequent versions of neighborhoods have been defined based on the concept of relation-based neighborhoods introduced by Y.Y. Yao. This article proposes a unified concept for investigations of such neighborhoods. This work presents the notion of hyper-neighborhood, which enables the investigation of the neighborhoods from the universe&#39;s perspective. As a result, we drive multiple equivalent characterizations of the types of neighborhoods that enable us to compare them and indicate the new, missing kinds of neighborhoods. Moreover, many kinds of neighborhoods defined in the literature on the issue proved to be identical. In particular, none of the types of recently defined so-called subset neighborhoods is new.},
  archive      = {J_IJAR},
  author       = {Marian Przemski},
  doi          = {10.1016/j.ijar.2025.109404},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109404},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Hyperspace approach to relation-based neighborhood operators},
  volume       = {181},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evidential time-to-event prediction with calibrated
uncertainty quantification. <em>IJAR</em>, <em>181</em>, 109403. (<a
href="https://doi.org/10.1016/j.ijar.2025.109403">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-to-event analysis provides insights into clinical prognosis and treatment recommendations. However, this task is more challenging than standard regression problems due to the presence of censored observations. Additionally, the lack of confidence assessment, model robustness, and prediction calibration raises concerns about the reliability of predictions. To address these challenges, we propose an evidential regression model specifically designed for time-to-event prediction. Our approach computes a degree of belief for the event time occurring within a time interval, without any strict distribution assumption. Meanwhile, the proposed model quantifies both epistemic and aleatory uncertainties using Gaussian Random Fuzzy Numbers and belief functions, providing clinicians with uncertainty-aware survival time predictions. Experimental evaluations using simulated and real-world survival datasets highlight the potential of our approach for enhancing clinical decision-making in survival analysis.},
  archive      = {J_IJAR},
  author       = {Ling Huang and Yucheng Xing and Swapnil Mishra and Thierry Denœux and Mengling Feng},
  doi          = {10.1016/j.ijar.2025.109403},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109403},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Evidential time-to-event prediction with calibrated uncertainty quantification},
  volume       = {181},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view outlier detection based on multi-granularity
fusion of fuzzy rough granules. <em>IJAR</em>, <em>181</em>, 109402. (<a
href="https://doi.org/10.1016/j.ijar.2025.109402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, multi-view data has seen widespread application across various fields, presenting both opportunities and challenges due to its complex distribution across different views. Detecting outliers in such heterogeneous data has become a significant research problem. Existing multi-view outlier detection methods often rely on clustering assumptions, pairwise constraints between views, and a focus on learning consensus information, which overlook the inherent differences across views. To address the aforementioned issues, this paper proposes an outlier detection method based on the fusion of multi-granularity fuzzy rough information (MGFMOD). The method calculates a multi-granularity similarity matrix using fuzzy similarity relationships, combines similarity matrices from different granularities to form an upper approximation matrix, and constructs fused upper approximation granules to detect attribute anomalies. Neighbor domain probabilistic mapping is then employed to unify neighborhood relationships across views, allowing the analysis of both consistency and distribution differences to capture class outliers. Additionally, this paper employs a novel coarse-to-fine approximation method to construct the upper approximation matrix, further improving the accuracy of attribute outlier detection. Experimental results on multiple public datasets demonstrate that the proposed method generally outperforms existing multi-view outlier detection methods in terms of detection accuracy and robustness.},
  archive      = {J_IJAR},
  author       = {Siyi Qiu and Yuefei Wang and Zixu Wang and Jinyan Cao and Xi Yu},
  doi          = {10.1016/j.ijar.2025.109402},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109402},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Multi-view outlier detection based on multi-granularity fusion of fuzzy rough granules},
  volume       = {181},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiindistinguishability operators. <em>IJAR</em>,
<em>181</em>, 109401. (<a
href="https://doi.org/10.1016/j.ijar.2025.109401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper (binary) equivalence relations and their fuzzification, indistinguishability operators, are generalized to n -equivalence relations and n -multiindistinguishability operators respectively. Some of the properties of these two last objects are stated as well as their relation with binary ones.},
  archive      = {J_IJAR},
  author       = {D. Boixader and J. Recasens},
  doi          = {10.1016/j.ijar.2025.109401},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109401},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Multiindistinguishability operators},
  volume       = {181},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DEEM: A novel approach to semi-supervised and unsupervised
image clustering under uncertainty using belief functions and
convolutional neural networks. <em>IJAR</em>, <em>181</em>, 109400. (<a
href="https://doi.org/10.1016/j.ijar.2025.109400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {DEEM (Deep Evidential Encoding of iMages) is a clustering algorithm that combines belief functions with convolutional neural networks in a Siamese-like framework for unsupervised and semi-supervised image clustering. In DEEM, images are mapped to Dempster–Shafer mass functions to quantify uncertainty in cluster membership. Various forms of prior information, including must-link and cannot-link constraints, supervised dissimilarities, and Distance Metric Learning, are incorporated to guide training and improve generalisation. By processing image pairs through shared network weights, DEEM aligns pairwise dissimilarities with the conflict between mass functions, thereby mitigating errors in noisy or incomplete distance matrices. Experiments on MNIST demonstrate that DEEM generalises effectively to unseen data while managing different types of prior knowledge, making it a promising approach for clustering and semi-supervised learning from image data under uncertainty.},
  archive      = {J_IJAR},
  author       = {Loïc Guiziou and Emmanuel Ramasso and Sébastien Thibaud and Sébastien Denneulin},
  doi          = {10.1016/j.ijar.2025.109400},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109400},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {DEEM: A novel approach to semi-supervised and unsupervised image clustering under uncertainty using belief functions and convolutional neural networks},
  volume       = {181},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ipl---14">IPL - 14</h2>
<ul>
<li><details>
<summary>
(2025). On the tractability landscape of the conditional minisum
approval voting rule. <em>IPL</em>, <em>189</em>, 106561. (<a
href="https://doi.org/10.1016/j.ipl.2025.106561">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work examines the Conditional Approval Framework for elections involving multiple interdependent issues, specifically focusing on the Conditional Minisum Approval Voting Rule. We first conduct a detailed analysis of the computational complexity of this rule, demonstrating that no approach can significantly outperform the brute-force algorithm under common computational complexity assumptions and various natural input restrictions. In response, we propose two practical restrictions (the first in the literature) that make the problem computationally tractable and show that these restrictions are essentially tight. Overall, this work provides a clear picture of the tractability landscape of the problem, contributing to a comprehensive understanding of the complications introduced by conditional ballots and indicating that conditional approval voting can be applied in practice, albeit under specific conditions.},
  archive      = {J_IPL},
  author       = {Georgios Amanatidis and Michael Lampis and Evangelos Markakis and Georgios Papasotiropoulos},
  doi          = {10.1016/j.ipl.2025.106561},
  journal      = {Information Processing Letters},
  month        = {3},
  pages        = {106561},
  shortjournal = {Inf. Process. Lett.},
  title        = {On the tractability landscape of the conditional minisum approval voting rule},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Total variation distance for product distributions is
#p-complete. <em>IPL</em>, <em>189</em>, 106560. (<a
href="https://doi.org/10.1016/j.ipl.2025.106560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that computing the total variation distance between two product distributions is # P -complete. This is in stark contrast with other distance measures such as Kullback–Leibler, Chi-square, and Hellinger, which tensorize over the marginals leading to efficient algorithms.},
  archive      = {J_IPL},
  author       = {Arnab Bhattacharyya and Sutanu Gayen and Kuldeep S. Meel and Dimitrios Myrisiotis and A. Pavan and N.V. Vinodchandran},
  doi          = {10.1016/j.ipl.2025.106560},
  journal      = {Information Processing Letters},
  month        = {3},
  pages        = {106560},
  shortjournal = {Inf. Process. Lett.},
  title        = {Total variation distance for product distributions is #P-complete},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Metric distortion of obnoxious distributed voting.
<em>IPL</em>, <em>189</em>, 106559. (<a
href="https://doi.org/10.1016/j.ipl.2025.106559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a distributed voting problem with a set of agents that are partitioned into disjoint groups and a set of obnoxious alternatives. Agents and alternatives are represented by points in a metric space. The goal is to compute the alternative that maximizes the total distance from all agents using a two-step mechanism which, given some information about the distances between agents and alternatives, first chooses a representative alternative for each group of agents, and then declares one of them as the overall winner. Due to the restricted nature of the mechanism and the potentially limited information it has to make its decision, it might not be always possible to choose the optimal alternative. We show tight bounds on the distortion of different mechanisms depending on the amount of the information they have access to; in particular, we study full-information and ordinal mechanisms.},
  archive      = {J_IPL},
  author       = {Alexandros A. Voudouris},
  doi          = {10.1016/j.ipl.2025.106559},
  journal      = {Information Processing Letters},
  month        = {3},
  pages        = {106559},
  shortjournal = {Inf. Process. Lett.},
  title        = {Metric distortion of obnoxious distributed voting},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lower bound for the quickhull convex hull algorithm that
disproves the quickhull precision conjecture. <em>IPL</em>,
<em>189</em>, 106558. (<a
href="https://doi.org/10.1016/j.ipl.2025.106558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Quickhull algorithm is a simple algorithm for constructing the convex hull of a set of n points. Quickhull is usually described for points in the plane, in which case it is defined as a divide-and-conquer algorithm, where one has a pair of points ( p , r ) such that p and r are on the convex hull, and one then finds the point, q , farthest from the line p r ‾ , which must also be on the convex hull, and then uses the triangle ( p , q , r ) to divide the remaining points and recursively solve the resulting subproblems. It is well-known that Quickhull has a worst-case running time of Θ ( n 2 ) , but it runs much faster than this for some input distributions. In a highly cited paper, Barber, Dobkin, and Huhdanpaa conjecture that the Quickhull algorithm runs in worst-case O ( n log ⁡ h ) time, where h is the size of the convex hull, when the input points have precision O ( log ⁡ n ) . In this paper, we give an explicit lower-bound construction that shows that, in general, the worst-case running time of the Quickhull algorithm is Θ ( n h ) . Our lower bound proof also provides a counter-example to the Quickhull precision conjecture of Barber et al., in that we give an explicit construction of a set, S , of n points with precision O ( log ⁡ n ) such that h is O ( log ⁡ n ) but the worst-case running time of Quickhull on S is Θ ( n h ) , not O ( n log ⁡ h ) .},
  archive      = {J_IPL},
  author       = {Michael T. Goodrich},
  doi          = {10.1016/j.ipl.2025.106558},
  journal      = {Information Processing Letters},
  month        = {3},
  pages        = {106558},
  shortjournal = {Inf. Process. Lett.},
  title        = {A lower bound for the quickhull convex hull algorithm that disproves the quickhull precision conjecture},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). String searching with mismatches using AVX2 and AVX-512
instructions. <em>IPL</em>, <em>189</em>, 106557. (<a
href="https://doi.org/10.1016/j.ipl.2025.106557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present new algorithms for the k mismatches version of approximate string matching. Our algorithms utilize the SIMD (Single Instruction Multiple Data) instruction set extensions, particularly AVX2 and AVX-512 instructions. Our approach is an extension of an earlier algorithm for exact string matching with SSE2 and AVX2. In addition, we modify this exact string matching algorithm to work with AVX-512. We demonstrate the competitiveness of our solutions by practical experiments. Our algorithms outperform earlier algorithms for both exact and approximate string matching on various benchmark data sets.},
  archive      = {J_IPL},
  author       = {Tamanna Chhabra and Sukhpal Singh Ghuman and Jorma Tarhio},
  doi          = {10.1016/j.ipl.2025.106557},
  journal      = {Information Processing Letters},
  month        = {3},
  pages        = {106557},
  shortjournal = {Inf. Process. Lett.},
  title        = {String searching with mismatches using AVX2 and AVX-512 instructions},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On approximate reconfigurability of label cover.
<em>IPL</em>, <em>189</em>, 106556. (<a
href="https://doi.org/10.1016/j.ipl.2024.106556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a two-prover game G and its two satisfying labelings ψ ini and ψ tar , the Label Cover Reconfiguration problem asks whether ψ ini can be transformed into ψ tar by repeatedly changing the label of a single vertex while preserving any intermediate labeling satisfying G . We consider its optimization version by relaxing the feasibility of labelings, referred to as Maxmin Label Cover Reconfiguration : We are allowed to pass through any non-satisfying labelings, but required to maximize the “soundness error,” which is defined as the minimum fraction of satisfied edges during transformation from ψ ini to ψ tar . Since the parallel repetition theorem of Raz (1998) [32] , which implies -hardness of approximating Label Cover within any constant factor, gives strong inapproximability results for many -hard problems, one may think of using Maxmin Label Cover Reconfiguration to derive inapproximability results for reconfiguration problems. We prove the following results on Maxmin Label Cover Reconfiguration , which display different trends from those of Label Cover and the parallel repetition theorem: • Maxmin Label Cover Reconfiguration can be approximated within a factor of 1 4 − o ( 1 ) for some restricted graph classes, including biregular graphs, balanced bipartite graphs with no isolated vertices, and superconstant average degree graphs. • A “naive” parallel repetition of Maxmin Label Cover Reconfiguration does not decrease the soundness error for every two-prover game. • Label Cover Reconfiguration on projection games can be decided in polynomial time. Our results suggest that a reconfiguration analogue of the parallel repetition theorem is unlikely.},
  archive      = {J_IPL},
  author       = {Naoto Ohsaka},
  doi          = {10.1016/j.ipl.2024.106556},
  journal      = {Information Processing Letters},
  month        = {3},
  pages        = {106556},
  shortjournal = {Inf. Process. Lett.},
  title        = {On approximate reconfigurability of label cover},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New bounds for the number of lightest cycles in undirected
graphs. <em>IPL</em>, <em>189</em>, 106555. (<a
href="https://doi.org/10.1016/j.ipl.2024.106555">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider an undirected graph G = ( V , E ) with positive integer edge weights. Subramanian [11] established an upper bound of | V | 4 / 6 on the number of minimum weight cycles. We present a new algorithm to enumerate all minimum weight cycles with a complexity of O ( | V | 3 ( | E | + | V | log ⁡ | V | ) ) . Using this algorithm, we derive the following upper bounds for the number of minimum weight cycles: if the minimum weight is even, the bound is | V | 4 / 4 , and if it is odd, the bound is | V | 3 / 2 . Notably, we improve Subramanian&#39;s bound by an order of magnitude when the minimum weight of a cycle is odd. Additionally, we demonstrate that these bounds are asymptotically tight.},
  archive      = {J_IPL},
  author       = {Hassene Aissi and Mourad Baiou and Francisco Barahona},
  doi          = {10.1016/j.ipl.2024.106555},
  journal      = {Information Processing Letters},
  month        = {3},
  pages        = {106555},
  shortjournal = {Inf. Process. Lett.},
  title        = {New bounds for the number of lightest cycles in undirected graphs},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Connected equitable cake division via sperner’s lemma.
<em>IPL</em>, <em>189</em>, 106554. (<a
href="https://doi.org/10.1016/j.ipl.2024.106554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of fair cake-cutting where each agent receives a connected piece of the cake. A division of the cake is deemed fair if it is equitable , which means that all agents derive the same value from their assigned piece. Prior work has established the existence of a connected equitable division for agents with nonnegative valuations using various techniques. We provide a simple proof of this result using Sperner&#39;s lemma. Our proof extends known existence results for connected equitable divisions to significantly more general classes of valuations, including nonnegative valuations with externalities, as well as several interesting subclasses of general (possibly negative) valuations.},
  archive      = {J_IPL},
  author       = {Umang Bhaskar and A.R. Sricharan and Rohit Vaish},
  doi          = {10.1016/j.ipl.2024.106554},
  journal      = {Information Processing Letters},
  month        = {3},
  pages        = {106554},
  shortjournal = {Inf. Process. Lett.},
  title        = {Connected equitable cake division via sperner&#39;s lemma},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Satisfying the restricted isometry property with the optimal
number of rows and slightly less randomness. <em>IPL</em>, <em>189</em>,
106553. (<a href="https://doi.org/10.1016/j.ipl.2024.106553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A matrix Φ ∈ R Q × N satisfies the restricted isometry property if ‖ Φ x ‖ 2 2 is approximately equal to ‖ x ‖ 2 2 for all k -sparse vectors x . We give a construction of RIP matrices with the optimal Q = O ( k log ⁡ ( N / k ) ) rows using O ( k log ⁡ ( N / k ) log ⁡ ( k ) ) bits of randomness. The main technical ingredient is an extension of the Hanson-Wright inequality to ε -biased distributions.},
  archive      = {J_IPL},
  author       = {Shravas Rao},
  doi          = {10.1016/j.ipl.2024.106553},
  journal      = {Information Processing Letters},
  month        = {3},
  pages        = {106553},
  shortjournal = {Inf. Process. Lett.},
  title        = {Satisfying the restricted isometry property with the optimal number of rows and slightly less randomness},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved hardness of approximation for geometric bin
packing. <em>IPL</em>, <em>189</em>, 106552. (<a
href="https://doi.org/10.1016/j.ipl.2024.106552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Geometric Bin Packing (GBP) problem is a generalization of Bin Packing where the input is a set of d -dimensional rectangles, and the goal is to pack them into d -dimensional unit cubes efficiently. It is NP-hard to obtain a PTAS for the problem, even when d = 2 . For general d , the best-known approximation algorithm has an approximation guarantee that is exponential in d . In contrast, the best hardness of approximation is still a small constant inapproximability from the case when d = 2 . In this paper, we show that the problem cannot be approximated within a d 1 − ϵ factor unless NP = P . Recently, d -dimensional Vector Bin Packing, a problem closely related to the GBP, was shown to be hard to approximate within a Ω ( log ⁡ d ) factor when d is a fixed constant, using a notion of Packing Dimension of set families. In this paper, we introduce a geometric analog of it, the Geometric Packing Dimension of set families. While we fall short of obtaining similar inapproximability results for the Geometric Bin Packing problem when d is fixed, we prove a couple of key properties of the Geometric Packing Dimension which highlight fundamental differences between Geometric Bin Packing and Vector Bin Packing.},
  archive      = {J_IPL},
  author       = {Arka Ray and Sai Sandeep},
  doi          = {10.1016/j.ipl.2024.106552},
  journal      = {Information Processing Letters},
  month        = {3},
  pages        = {106552},
  shortjournal = {Inf. Process. Lett.},
  title        = {Improved hardness of approximation for geometric bin packing},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient algorithm for identifying rainbow ortho-convex
4-sets in k-colored point sets. <em>IPL</em>, <em>189</em>, 106551. (<a
href="https://doi.org/10.1016/j.ipl.2024.106551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let P be a k -colored set of n points in the plane, 4 ≤ k ≤ n . We study the problem of deciding if P contains a subset of four points of different colors such that its Rectilinear Convex Hull has positive area. We show this problem to be equivalent to deciding if there exists a point c in the plane such that each of the open quadrants defined by c contains a point of P , each of them having a different color. We provide an O ( n log ⁡ n ) -time algorithm for this problem, where the hidden constant does not depend on k ; then, we prove that this problem has time complexity Ω ( n log ⁡ n ) in the algebraic computation tree model. No general position assumptions for P are required.},
  archive      = {J_IPL},
  author       = {David Flores-Peñaloza and Mario A. Lopez and Nestaly Marín and David Orden},
  doi          = {10.1016/j.ipl.2024.106551},
  journal      = {Information Processing Letters},
  month        = {3},
  pages        = {106551},
  shortjournal = {Inf. Process. Lett.},
  title        = {An efficient algorithm for identifying rainbow ortho-convex 4-sets in k-colored point sets},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A simple division-free algorithm for computing pfaffians.
<em>IPL</em>, <em>189</em>, 106550. (<a
href="https://doi.org/10.1016/j.ipl.2024.106550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a very simple algorithm for computing Pfaffians which uses no division operations. Essentially, it amounts to iterating matrix multiplication and truncation. Its complexity, for a 2 n × 2 n matrix, is O ( n M ( n ) ) , where M ( n ) is the cost of matrix multiplication. In case of a sparse matrix, M ( n ) is the cost of the dense-sparse matrix multiplication. The algorithm is an adaptation of the Bird algorithm for determinants. We show how to extract, with practically no additional work, the characteristic polynomial and the Pfaffian characteristic polynomial from these algorithms.},
  archive      = {J_IPL},
  author       = {Adam J. Przeździecki},
  doi          = {10.1016/j.ipl.2024.106550},
  journal      = {Information Processing Letters},
  month        = {3},
  pages        = {106550},
  shortjournal = {Inf. Process. Lett.},
  title        = {A simple division-free algorithm for computing pfaffians},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modifying an instance of the super-stable matching problem.
<em>IPL</em>, <em>189</em>, 106549. (<a
href="https://doi.org/10.1016/j.ipl.2024.106549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The topic of this paper is the stable matching problem in a bipartite graph. Super-stability is one of the stability concepts in the stable matching problem with ties. It is known that there may not exist a super-stable matching, and the existence of a super-stable matching can be checked in polynomial time. In this paper, we consider the problem of modifying an instance of the stable matching problem with ties by deleting some bounded number of agents in such a way that there exists a super-stable matching in the modified instance. First, we consider the setting where we are allowed to delete agents on only one side. We prove that, in this setting, our problem can be solved in polynomial time. Interestingly, this result is obtained by carefully observing the existing algorithm for checking the existence of a super-stable matching. Next, we consider the setting where we are given an upper bound on the number of deleted agents for each side, and we are allowed to delete agents on both sides. We prove that, in this setting, our problem is NP-complete.},
  archive      = {J_IPL},
  author       = {Naoyuki Kamiyama},
  doi          = {10.1016/j.ipl.2024.106549},
  journal      = {Information Processing Letters},
  month        = {3},
  pages        = {106549},
  shortjournal = {Inf. Process. Lett.},
  title        = {Modifying an instance of the super-stable matching problem},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Instability results for cosine-dissimilarity-based nearest
neighbor search on high dimensional gaussian data. <em>IPL</em>,
<em>189</em>, 106542. (<a
href="https://doi.org/10.1016/j.ipl.2024.106542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because many dissimilarity functions behave differently in low versus high-dimensional spaces, the behavior of high-dimensional nearest neighbor search has been studied extensively. One line of research involves the characterization of nearest neighbor queries as unstable if their query points have nearly identical dissimilarity with most points in the dataset. This research has shown that, for various data distributions and dissimilarity functions, the probability of query instability approaches one. Previous work in Information Processing Letters by C. Giannella in 2021 explicated this phenomenon for centered Gaussian data and Euclidean distance. This paper addresses the problem of characterizing query instability behavior over centered Gaussian data and a fundamentally different dissimilarity function, cosine dissimilarity. Conditions are provided on the covariance matrices and dataset size function guaranteeing that the probability of query instability goes to one. Furthermore, conditions are provided under which the instability probability is bounded away from one.},
  archive      = {J_IPL},
  author       = {Chris R. Giannella},
  doi          = {10.1016/j.ipl.2024.106542},
  journal      = {Information Processing Letters},
  month        = {3},
  pages        = {106542},
  shortjournal = {Inf. Process. Lett.},
  title        = {Instability results for cosine-dissimilarity-based nearest neighbor search on high dimensional gaussian data},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="isci---49">ISCI - 49</h2>
<ul>
<li><details>
<summary>
(2025). FedRL-hybrid: A federated hybrid reinforcement learning
approach. <em>ISCI</em>, <em>710</em>, 122102. (<a
href="https://doi.org/10.1016/j.ins.2025.122102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated reinforcement learning (FedRL) offers promising avenues for secure collaboration among deep reinforcement learning (DRL) clients. We embark on a pioneering journey into the federated hybrid reinforcement learning (FedRL-Hybrid) domain which remains relatively unexplored in comparison with federated online reinforcement learning (FedRL-Online). Our proposed FedRL-Hybrid framework seamlessly integrates the strengths of both Online-DRL and Offline-DRL Clients. Central to this framework are the FedRL-Offline algorithm and the FedRL-Online-AFT algorithm, with the federated adaptive fine-tuning (FedAFT) mechanism ensuring a fluid transition of the global model from FedRL-Offline to FedRL-Online settings. To bolster the empirical research in this nascent field, we present benchmark datasets along with their generation methods to evaluate the performance of FedRL-Hybrid. Our experimental results highlight the fact that FedRL-Hybrid achieves notable performance across the three paradigms, i.e., FedRL-Online, FedRL-Offline, and FedRL-Hybrid, highlighting its potential as a comprehensive framework for FedRL.},
  archive      = {J_ISCI},
  author       = {Yikang Li and Biao Jin and Xuan Li and Zhiqiang Yao and Jinbo Xiong and Jie Lin and Xing Wang and Mingwei Lin},
  doi          = {10.1016/j.ins.2025.122102},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122102},
  shortjournal = {Inf. Sci.},
  title        = {FedRL-hybrid: A federated hybrid reinforcement learning approach},
  volume       = {710},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated learning with adaptive local aggregation for
privacy-aware recommender systems in internet of vehicles.
<em>ISCI</em>, <em>710</em>, 122100. (<a
href="https://doi.org/10.1016/j.ins.2025.122100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) models have great potential to be used for recommender systems (RS) in the Internet of Vehicles (IoV) due to their excellent data processing and learning abilities. To alleviate the problem of privacy leakage in centralized training of DL models, federated learning (FL) is engaged for its advantage of just uploading gradients or parameters of models without raw data sharing. However, the ubiquitous data heterogeneity in IoV brings a big challenge to the stable global convergence of FL. In addition, existing FL schemes with high convergence latency cannot realize the timely personalized content recommendation in IoV. In this paper, a FL scheme with adaptive local aggregation for privacy-aware RS in IoV, named FLRS, is proposed. At first, we analyze the data distribution on each vehicle locally from two aspects: label distribution and feature distribution. After receiving vehicle data distribution information, the edge server selects aggregation collaborators for each vehicle according to the distribution similarity of labels and features. In the model updating stage, the local model on each vehicle is adaptively aggregated with those from its collaborators and then the local training process begins. At last, the performance of FLRS is evaluated through simulation experiments.},
  archive      = {J_ISCI},
  author       = {Yong Cheng and Yuhao Hu and Wei Liu and Muhammad Bilal},
  doi          = {10.1016/j.ins.2025.122100},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122100},
  shortjournal = {Inf. Sci.},
  title        = {Federated learning with adaptive local aggregation for privacy-aware recommender systems in internet of vehicles},
  volume       = {710},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic event-triggered cooperative critic-only control for
heterogeneous MASs with uniformly positive minimum inter-event times.
<em>ISCI</em>, <em>710</em>, 122099. (<a
href="https://doi.org/10.1016/j.ins.2025.122099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the dynamic event-triggered optimal output consensus problem for heterogeneous linear multi-agent systems (MASs), where uniformly positive minimum inter-event times (UPMIETs) are ensured, using the cooperative critic-only algorithm. An optimal triggering controller and a dynamic triggering mechanism are designed, incorporating a positive, decreasing dynamic parameter that gradually decreases from a positive constant to zero. This approach ensures the existence of UPMIETs. Next, a cooperative weight-updating rule for the critic-only neural network (NN) is developed, which utilizes the weights of neighboring agents. It is then proven that the weight update error of the critic-only NN is ultimately uniformly bounded, and the theoretical value of UPMIETs for the dynamic triggering mechanism can be calculated. The proposed algorithm has three main advantages: 1) It does not require global information; 2) It ensures UPMIETs; 3) It simplifies the network structure. Finally, two simulation examples are used to verify the effectiveness of the proposed algorithm. The simulation results show that the algorithm has fewer trigger times and larger positive minimum inter-event times, which verifies the superiority of the proposed algorithm.},
  archive      = {J_ISCI},
  author       = {Lina Xia and Yue Feng and Qing Li and Ruizhuo Song},
  doi          = {10.1016/j.ins.2025.122099},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122099},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic event-triggered cooperative critic-only control for heterogeneous MASs with uniformly positive minimum inter-event times},
  volume       = {710},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Protocol-based model predictive control for fuzzy systems
with multi-segment DoS attacks. <em>ISCI</em>, <em>710</em>, 122098. (<a
href="https://doi.org/10.1016/j.ins.2025.122098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the model predictive control (MPC) strategy for Takagi-Sugeno (T-S) fuzzy systems in the presence of Denial-of-Service (DoS) attacks. A novel switching event-triggered protocol featuring an adaptive threshold and a switching signal is introduced to enhance network efficiency while preserving system stability. This approach represents a significant improvement over conventional static or dynamic event-triggered protocols. The effects of DoS attacks on both sensor-to-controller and controller-to-actuator communication channels are modeled using independent Markov chains, which are then unified into a single chain for comprehensive analysis. The proposed MPC, combined with the switching event-triggered protocol, ensures robust performance by achieving both disturbance attenuation and input-to-state stability for the fuzzy system. Two practical examples are presented to validate the effectiveness and advantages of the proposed control strategy, underscoring its superiority compared to existing methods.},
  archive      = {J_ISCI},
  author       = {Qingfei Gao and Tong Wang and Hongjie Pang and Jun Cheng and Dan Zhang and Wenhai Qi},
  doi          = {10.1016/j.ins.2025.122098},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122098},
  shortjournal = {Inf. Sci.},
  title        = {Protocol-based model predictive control for fuzzy systems with multi-segment DoS attacks},
  volume       = {710},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Signed graphs in data sciences via communicability geometry.
<em>ISCI</em>, <em>710</em>, 122096. (<a
href="https://doi.org/10.1016/j.ins.2025.122096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Signed graphs are an emergent way of representing data in a variety of contexts where antagonistic interactions exist. These include data from biological, ecological, and social systems. Here we propose the concept of communicability for signed graphs and explore in depth its mathematical properties. We also prove that the communicability induces a hyperspherical geometric embedding of the signed network, and derive communicability-based metrics that satisfy the axioms of a distance even in the presence of negative edges. We then apply these metrics to solve several problems in the data analysis of signed graphs within a unified framework. These include the partitioning of signed graphs, dimensionality reduction, finding hierarchies of alliances in signed networks, and quantifying the degree of polarization between the existing factions in social systems represented by these types of graphs.},
  archive      = {J_ISCI},
  author       = {Fernando Diaz-Diaz and Ernesto Estrada},
  doi          = {10.1016/j.ins.2025.122096},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122096},
  shortjournal = {Inf. Sci.},
  title        = {Signed graphs in data sciences via communicability geometry},
  volume       = {710},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive path planning for wafer second probing via an
attention-based hierarchical reinforcement learning framework with
shared memory. <em>ISCI</em>, <em>710</em>, 122089. (<a
href="https://doi.org/10.1016/j.ins.2025.122089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In semiconductor manufacturing, wafer probing is a quality control process before packaging, usually performed by an automated machine with a fixed path. The unqualified grains in the first detection need to be confirmed again. The fixed path method is inefficient and requires manual intervention for the second wafer probing on randomly scattered grains. To this end, we propose a reinforcement learning-based adaptive path planning method for second wafer probing. To simplify decision-making in a large state space, we propose a novel attention-based hierarchical reinforcement learning method with shared memory (AHRL-SM) and introduce it into wafer probing for the first time. The high-level agent is responsible for focusing on the region with a large number of grains to be detected, while the low-level agent is responsible for planning the moving path of the probe in the specified sub-region. The soft attention mechanism and recurrent neural network are incorporated into the probing architecture to facilitate original image feature extraction and historical information acquisition, respectively. In addition, we propose a unique shared memory mechanism to further improve decision-making efficiency. The Markov decision process of the complete wafer second probing and the performance verification of the proposed method are thoroughly described in this work. Compared with the existing path planning methods for wafer probing, sufficient experimental results confirm that our method has obvious advantages in probing efficiency, grain surface protection, and generalization.},
  archive      = {J_ISCI},
  author       = {Haobin Shi and Ziming He and Kao-Shing Hwang},
  doi          = {10.1016/j.ins.2025.122089},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122089},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive path planning for wafer second probing via an attention-based hierarchical reinforcement learning framework with shared memory},
  volume       = {710},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward automated verification of timed business process
models using timed-automata networks and temporal properties.
<em>ISCI</em>, <em>710</em>, 122088. (<a
href="https://doi.org/10.1016/j.ins.2025.122088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the challenges in verifying the correctness and effectiveness of business process models with time constraints by introducing an automated approach that combines formal model abstraction with Time Computation Tree Logic (TCTL) property expression. The proposed framework transforms BPMN models into UPPAAL timed-automata networks, utilizing structural process block patterns to generate TCTL property expressions for verification. Key innovations include automated transformation and verification processes that significantly reduce time and effort compared to traditional methods. The transformation rules and generated TCTL properties are comprehensively tested, and the correctness and effectiveness of the derived UPPAAL constructs are validated through extensive simulations and real-world case studies in the UPPAAL-TIGA environment. Results demonstrate the practical applicability of this approach, with substantial improvements in verification efficiency and accuracy and a notable reduction in the time needed for model abstraction and TCTL property expression. The framework includes rules for transforming block timed BPMN models into UPPAAL and logic for automatically generating temporal properties, highlighting its potential to enhance business process modeling and verification practices.},
  archive      = {J_ISCI},
  author       = {Chanon Dechsupa and Wiwat Vatanawood and Arthit Thongtak},
  doi          = {10.1016/j.ins.2025.122088},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122088},
  shortjournal = {Inf. Sci.},
  title        = {Toward automated verification of timed business process models using timed-automata networks and temporal properties},
  volume       = {710},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Highly improve the accuracy of clustering algorithms based
on shortest path distance. <em>ISCI</em>, <em>710</em>, 122087. (<a
href="https://doi.org/10.1016/j.ins.2025.122087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dataset-amelioration methods improve clustering accuracy by introducing gravitation between neighboring objects, pulling them closer together. However, in overlapping datasets, the gravitation can also pull adjacent clusters closer, which will degrade data distribution. Highly Improving the Accuracy of Clustering (HIAC) constructs a probability curve to select a global threshold that eliminates inter-cluster gravitation, thereby aggregating objects within the same cluster. Nonetheless, the global threshold may erroneously retain inter-cluster gravitation while removing intra-cluster gravitation, potentially resulting in the formation of new tiny clusters and the deviation of boundary objects. To address this issue, we propose the HIACSP algorithm ( H ighly I mproving the A ccuracy of C lustering Algorithms based on S hortest P ath Distance). HIACSP defines the weight of the shortest path between objects as a novel distance metric, denoted as δ S P . This new metric prompts the K nearest neighbors identified by δ S P to be biased toward the cluster core and belong to the same cluster. Consequently, only intra-cluster gravitation forces are retained without relying on the threshold, thus preventing the formation of tiny clusters and the deviation of boundary objects. Additionally, based on SP-KNN, the boundary score is devised to identify actual boundary objects. By pulling boundary objects toward the cluster core using the gravitation acting on them by SP-KNN, overlapping clusters can be well-separated, and no clusters will be over-divided. Extensive experiments have been conducted to validate HIACSP. The experimental results show that HIACSP achieves an average improvement in clustering accuracy of 19.9% (Adjusted Rand Index, ARI), 14.8% (Normalized Mutual Information, NMI), 12.0% (Fowlkes-Mallows Index, FMI), 11.0% (Purity, PUR), and 14.8% (V-Measure, VM) across five evaluation metrics, outperforming baseline algorithms by at least 5.7% (ARI), 3.9% (NMI), 3.2% (FMI), 3.6% (PUR), and 3.9% (VM). The code and datasets are available at https://github.com/XJaiYH/HIACSP .},
  archive      = {J_ISCI},
  author       = {Xianjun Zeng and Shuliang Wang and Qi Li and Sijie Ruan and Qianyu Yang and Haoxiang Xu},
  doi          = {10.1016/j.ins.2025.122087},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122087},
  shortjournal = {Inf. Sci.},
  title        = {Highly improve the accuracy of clustering algorithms based on shortest path distance},
  volume       = {710},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed i&amp;i adaptive output feedback control of
uncertain second-order systems with output constraint and input
saturation. <em>ISCI</em>, <em>710</em>, 122086. (<a
href="https://doi.org/10.1016/j.ins.2025.122086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a distributed adaptive control strategy is developed for multi-agent systems (MASs) consisted of uncertain second-order systems with output and input constraints. In order to estimate unknown state and parameter, the immersion and invariance (I&amp;I) adaptive observer is constructed to compensate for the unknown information, where a disturbance observer is embedded to estimate the external disturbance generated by a partially known exosystem. To fulfill the time-varying constraint requirement on the consensus error, universal barrier function (UBF) is used to transform the original consensus error into a new one. The observed state and the transformed consensus error are incorporated into the command-filtered backstepping procedure, utilizing auxiliary signals to eliminate the filtered error associated with the virtual controls. To derive the final control law, a smooth function is employed to approximate the input saturation nonlinearity, and an extended state is introduced along with an update law to estimate the bound of the nonlinear time-varying term resulting from the partial derivative of the smooth function. Finally, simulation results are carried out to validate the effectiveness of the designed scheme.},
  archive      = {J_ISCI},
  author       = {Qi Han and Zhitao Liu and Hongye Su and Xiangbin Liu},
  doi          = {10.1016/j.ins.2025.122086},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122086},
  shortjournal = {Inf. Sci.},
  title        = {Distributed I&amp;I adaptive output feedback control of uncertain second-order systems with output constraint and input saturation},
  volume       = {710},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence in medical practice: The
CRITIC-TOPSIS method based on λ(pq)-cubic quasi rung orthopair fuzzy
robust aggregation operators and their applications. <em>ISCI</em>,
<em>710</em>, 122076. (<a
href="https://doi.org/10.1016/j.ins.2025.122076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) tools completely transform the medical field by increasing efficiency, precision, and availability while expanding the field&#39;s understanding of medicine and available treatments. However, to guarantee the responsible and secure application of AI technology in healthcare, it is imperative to address issues like data protection, moral concerns, and compliance with regulations. The concept of a p , q -cubic quasi-rung orthopair fuzzy set provides an effective optimization strategy for managing the uncertainty about the use of AI tools in healthcare issues. By adding an additional parameter, the p , q -cubic quasi-rung orthopair fuzzy set enables a more comprehensive and flexible description of the insufficient information. The key objective of the paper is to represent uncertain evaluation information about the use of AI tools in medical industry processes by introducing p , q -cubic quasi-rung orthopair fuzzy weighted arithmetic/geometric mean aggregation operator and p , q -cubic quasi-rung orthopair fuzzy ordered weighted arithmetic/geometric mean aggregation operator under the environment of a new class of algebraic operational laws. Further, to determine the optimum order of each action, which may reflect the inter-correlations among criteria, an additional structure incorporating p , q -cubic quasi-rung orthopair fuzzy assessment of alternatives and ranking based on the TOPSIS method implementing p , q -cubic quasi-rung orthopair fuzzy-criteria importance through inter-criteria correlation (CRITIC) is offered. Additionally, we go into extensive detail on the newly suggested multi-attribute group decision process that is based on the p , q -cubic quasi-rung orthopair fuzzy weighted arithmetic/geometric mean aggregation operators using new class of algebraic operational laws environment. We use the artificial intelligence tools in medical industry problem to further verify the feasibility of the approach. In terms of decision-making capability, the suggested strategy outperforms a number of different approaches that have been reported in the literature.},
  archive      = {J_ISCI},
  author       = {Peide Liu and Abbas Ali and Noor Rehman and Muqadas Parveen},
  doi          = {10.1016/j.ins.2025.122076},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122076},
  shortjournal = {Inf. Sci.},
  title        = {Artificial intelligence in medical practice: The CRITIC-TOPSIS method based on λ(pq)-cubic quasi rung orthopair fuzzy robust aggregation operators and their applications},
  volume       = {710},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An off-policy deep reinforcement learning-based active
learning for crime scene investigation image classification.
<em>ISCI</em>, <em>710</em>, 122074. (<a
href="https://doi.org/10.1016/j.ins.2025.122074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crime scene investigation (CSI) image classification is crucial in forensic analysis, significantly boosting the efficiency of police investigations. Conventional CSI image classification detection approaches depend heavily on convolutional neural networks (CNNs) and pre-labeled, extensive image data, which are time-consuming and costly to assemble. To address this issue, we present an active learning method that boosts model performance using fewer labeled examples. Unlike traditional active learning methods that employ heuristic selection techniques independently of the training process and compromise their effectiveness, our strategy integrates off-policy deep reinforcement learning (DRL) to make strategic data selections. The off-policy approach allows for learning from a broader range of experiences, improving adaptability and accelerating the learning process compared to on-policy methods. Our model utilizes numerous CNNs to pull features from different layers of images, which are subsequently processed by the softmax layer for image categorization. Starting with a minimal labeled dataset, the classifier employs DRL to identify which unlabeled images should be annotated next. These newly labeled images are then added to the training pool, and the classifier is periodically retrained to enhance its accuracy. Additionally, our framework incorporates a generative adversarial network (GAN) for online data augmentation and introduces a novel regularization technique to stabilize GAN training and prevent mode collapse. Furthermore, our model employs the Random Key method, optimized by the differential evolution (DE) algorithm, to minimize the dependence of the approach on hyperparameters. Our comprehensive testing across diverse datasets, including the center for image and information processing-CSI dataset (CIIP-CSID), the global human image dataset with 10,000 images (GHIM-10 K), and corel 1,000 (Corel-1 K), demonstrates that our model achieves F-measures ranging from 86.758 % to 92.611 %. This underscores the superior performance and versatility of the model in handling varied CSI image classification tasks.},
  archive      = {J_ISCI},
  author       = {Zhang Yixin and Liu Yang and Jiang Guofan and Yang yuchen and Zhang Jian and Jing Yang and Roohallah Alizadehsani and Ryszard Tadeusiewicz and Paweł Pławiak},
  doi          = {10.1016/j.ins.2025.122074},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122074},
  shortjournal = {Inf. Sci.},
  title        = {An off-policy deep reinforcement learning-based active learning for crime scene investigation image classification},
  volume       = {710},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable physics-guided attention network for long-lead
ENSO forecasts. <em>ISCI</em>, <em>709</em>, 122084. (<a
href="https://doi.org/10.1016/j.ins.2025.122084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The El Niño–Southern Oscillation (ENSO) is the primary interannual variations of the climate system, significantly impacts global climate patterns, ecosystems, and economies. Most cutting-edge ENSO prediction methods rely on traditional numerical models and novel data driven technologies. The numerical ways are based on dynamic equations and contribute to the physical representation of ENSO. However, the numerical model is relatively complex, leading to resource consumption, and it fails to address the inherent uncertainty like spring predictability barrier (SPB) and signal-to-noise ratio problem for long-lead forecasts particularly in long-term forecasts exceeding one year. Data-driven methods can effectively alleviate the SPB and improve the effective hindcasting time. However, they lack guidance from physical mechanisms, which results in a lack of physical interpretability in their outcomes. This can even lead to physically inconsistent results. In this study, we introduce an explainable physics-guided intelligent spatio-temporal forecasting model for ENSO (PGtransNet_ENSO). The model incorporates key characteristics and factors of ENSO events, including internal variability, external forcing, Bjerknes positive feedback mechanism, delayed attention mechanism to account for temporal lag effects, and El Niño/La Niña event types and intensities encoding. PGtransNet_ENSO maintains high accuracy even with limited data availability and enhances the model&#39;s convergence speed. Extensive experimental confirm its capability to deliver dependable ENSO predictions up to 12 months in advance. Moreover, the model outputs demonstrate robust physical consistency with established dynamical principles, thereby enhancing the interpretability of its underlying mechanisms.},
  archive      = {J_ISCI},
  author       = {Song Wu and Xiaoyong Li and Wei Dong and Senliang Bao and Senzhang Wang and Junxing Zhu and Xiaoli Ren and Chengcheng Shao},
  doi          = {10.1016/j.ins.2025.122084},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122084},
  shortjournal = {Inf. Sci.},
  title        = {Explainable physics-guided attention network for long-lead ENSO forecasts},
  volume       = {709},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy knowledge inference-based dynamic task allocation
method for multi-agent systems. <em>ISCI</em>, <em>709</em>, 122083. (<a
href="https://doi.org/10.1016/j.ins.2025.122083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a cooperative policy learning method, task allocation has been widely used to enhance the collaboration of multi-agent systems. However, most allocation methods require a fully observable state of the environment during training. In dynamic environments with incomplete and noisy observations, these methods struggle to achieve effective task allocation. To address this issue, this paper proposes a Fuzzy Knowledge Inference-based dynamic Task Allocation method (FKITA) for multi-agent systems, which adopts fuzzy behavioral knowledge to improve task allocation effectiveness. Specifically, FKITA incorporates fuzzy inference into the process of interpreting agent tasks based on local observations, compensating for missing information, and reducing the uncertainty of the incomplete observation environment. Furthermore, the characteristics knowledge of task allocation is expressed in the form of fuzzy rules, which optimize the search space of task allocation, and reduce the environmental interference during task matching. In addition, we introduce a two-layer coordination framework that updates task allocation and policy learning to enhance cooperation capabilities. Experimental evaluations on three cooperative multi-agent tasks demonstrate that FKITA improved the accuracy of task allocation 75% by fuzzy knowledge inference and achieved better success rates on six StarCraft maps, leading to efficient task cooperation.},
  archive      = {J_ISCI},
  author       = {Mengke Wang and Xiaoming Wang and Xinzhi Wang and Xiangfeng Luo and Shaorong Xie},
  doi          = {10.1016/j.ins.2025.122083},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122083},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy knowledge inference-based dynamic task allocation method for multi-agent systems},
  volume       = {709},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Random walk on point clouds for feature detection.
<em>ISCI</em>, <em>709</em>, 122082. (<a
href="https://doi.org/10.1016/j.ins.2025.122082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The points on the point clouds that can entirely outline the shape of the model are of critical importance, as they serve as the foundation for numerous point cloud processing tasks and are widely utilized in computer graphics and computer-aided design. This study introduces a novel method, RWoDSN, for extracting such feature points, incorporating considerations of sharp-to-smooth transitions, large-to-small scales, and textural-to-detailed features. We approach feature extraction as a two-stage context-dependent analysis problem. In the first stage, we propose a novel neighborhood descriptor, termed the Disk Sampling Neighborhood (DSN), which, unlike traditional spatially and geometrically invariant approaches, preserves a matrix structure while maintaining normal neighborhood relationships. In the second stage, a random walk is performed on the DSN (RWoDSN), yielding a graph-based DSN that simultaneously accounts for the spatial distribution, topological properties, and geometric characteristics of the local surface surrounding each point. This enables the effective extraction of feature points. Experimental results demonstrate that the proposed RWoDSN method achieves a recall of 0.769—22% higher than the current state-of-the-art—alongside a precision of 0.784. Furthermore, it significantly outperforms several traditional and deep-learning techniques across eight evaluation metrics.},
  archive      = {J_ISCI},
  author       = {Yuhe Zhang and Zhikun Tu and Zhi Li and Jian Gao and Bao Guo and Shunli Zhang},
  doi          = {10.1016/j.ins.2025.122082},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122082},
  shortjournal = {Inf. Sci.},
  title        = {Random walk on point clouds for feature detection},
  volume       = {709},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Overcoming intermittent instability in reinforcement
learning via gradient norm preservation. <em>ISCI</em>, <em>709</em>,
122081. (<a href="https://doi.org/10.1016/j.ins.2025.122081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instability is a critical challenge in online reinforcement learning (RL), particularly in robotics. While existing RL methods primarily address this intractable instability through algorithmic modifications or training strategies, the role of optimization techniques remains largely underexplored. This paper investigates intermittent instability in RL training, which hinders accurate value learning, and proposes a novel optimization approach: Gradient Norm Preservation (GNP). Our analysis identifies irregular gradient spikes, caused by high-reward data during exploration, as a key source of instability. These spikes are mathematically quantified, and the optimizer&#39;s learning rate is dynamically adjusted to preserve initial gradient norms, mitigating their impact on value learning. Experiments across diverse environments demonstrate that integrating GNP into RL algorithms significantly improves stability, with notable gains in training performance across several environments.},
  archive      = {J_ISCI},
  author       = {Jonghyeok Park and Jongsoo Lee and Jangwon Kim and Soohee Han},
  doi          = {10.1016/j.ins.2025.122081},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122081},
  shortjournal = {Inf. Sci.},
  title        = {Overcoming intermittent instability in reinforcement learning via gradient norm preservation},
  volume       = {709},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approaches to attribute reduction of metric-fuzzy decision
systems based on information theory. <em>ISCI</em>, <em>709</em>,
122080. (<a href="https://doi.org/10.1016/j.ins.2025.122080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy rough sets and information theory are both effective tools for processing large-scale data. This study combines the advantages of both to establish the attribute reduction theory and the method of metric fuzzy information systems based on information theory. First, it defines the concepts of metric fuzzy rough entropy, fuzzy joint rough entropy and fuzzy rough mutual information, explores their properties and relationships and constructs a method for evaluating attribute importance. Secondly, based on this theoretical foundation, two efficient attribute reduction algorithms are designed: the first algorithm doesn&#39;t rely on decision attributes, and its advantage is that it can effectively improve the computational efficiency; the second algorithm combines decision attributes, and its advantage is that it can optimize the reduction effect. Both algorithms use the strategies of forward selection and backward elimination to eliminate redundant attributes. Finally, this paper compares these two reduction algorithms with five commonly used reduction algorithms on 20 datasets and uses the average classification accuracy of 14 classifiers to evaluate the reduction effects of these algorithms. Experimental results show that the two algorithms proposed in this paper perform well in classification tasks, with their average accuracy ranking among the highest compared to other algorithms, thus verifying the efficiency and advantages of the reduction algorithms of metric fuzzy information systems in large-scale data processing.},
  archive      = {J_ISCI},
  author       = {Guirong Peng and Fei Li and Wei Yao},
  doi          = {10.1016/j.ins.2025.122080},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122080},
  shortjournal = {Inf. Sci.},
  title        = {Approaches to attribute reduction of metric-fuzzy decision systems based on information theory},
  volume       = {709},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward rough set based insightful reasoning in intelligent
systems. <em>ISCI</em>, <em>709</em>, 122078. (<a
href="https://doi.org/10.1016/j.ins.2025.122078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores a rough set-based approach for supporting insightful reasoning in Intelligent Systems (ISs). The novelty lies in the introduction of a new concept for approximate reasoning processes based on granular computations. Although many rough set theory extensions developed over time focus on reasoning about (partial) set inclusion, these approximation spaces sometimes fall short when dealing with crucial aspects of approximate reasoning within ISs. Specifically, these systems aim to construct high-quality approximations of compound decision granules that represent solutions. Here, we present the basis for insightful reasoning realized through approximate reasoning processes grounded in granular computations. By doing so, we provide a sufficiently rich basis for designing IS problem solvers. This basis allows ISs to restructure or adapt their reasoning based on the generated granular computations, ultimately leading to high-quality granular solutions.},
  archive      = {J_ISCI},
  author       = {Andrzej Skowron and Jaroslaw Stepaniuk},
  doi          = {10.1016/j.ins.2025.122078},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122078},
  shortjournal = {Inf. Sci.},
  title        = {Toward rough set based insightful reasoning in intelligent systems},
  volume       = {709},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge&amp;social-based collaborative method with
contrastive graph structure learning for explainable recommendation.
<em>ISCI</em>, <em>709</em>, 122077. (<a
href="https://doi.org/10.1016/j.ins.2025.122077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explainable Recommendation has attracted increasing attention due to the growing significance of data privacy and model security in recommendation systems. However, the effectiveness of robust and security-sensitive recommendation methods may be constrained by limited observed data, potentially resulting in suboptimal accuracy and reliability. Although introducing multi-source side information helps mitigate data sparsity issues and improve recommendation performance, it also presents new challenges, including semantic disparities and noise interference. In view of these observations, we propose a K nowledge&amp; S ocial-based collaborative method with C ontrastive G raph S tructure L earning for explainable recommendation, named KSCGSL . It establishes multi-view representations for users and items with explainable learning based on knowledge-enhanced semantic-aware modeling and social network-driven preference learning, both refined via contrastive graph structure optimization. Specifically, KSCGSL introduces a dual graph augmentation mechanism based on knowledge graph and semantic awareness for item embedding learning. For user modeling, it captures user preferences from user-item interaction analysis and augments them through social relations. To solve the inherent semantic inconsistencies across multiple views and mitigate noise interference, contrastive graph structural learning is incorporated to optimize embedding learning and filter structural noise. Experiments conducted on three publicly available datasets demonstrate that KSCGSL achieves significant improvements in recommendation accuracy with explainable manners.},
  archive      = {J_ISCI},
  author       = {Shunmei Meng and Xuyun Zhang and Nan Liu and Longchuan Tu and Qianmu Li},
  doi          = {10.1016/j.ins.2025.122077},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122077},
  shortjournal = {Inf. Sci.},
  title        = {Knowledge&amp;Social-based collaborative method with contrastive graph structure learning for explainable recommendation},
  volume       = {709},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anomaly detection based on fuzzy neighborhood rough sets.
<em>ISCI</em>, <em>709</em>, 122075. (<a
href="https://doi.org/10.1016/j.ins.2025.122075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection is a significant data mining task with great application potential. However, the presence of uncertain information, such as noise and fuzziness, in real data usually poses a great challenge to existing anomaly detection methods. As an important technique of granular computing theory, fuzzy neighborhood rough sets can effectively handle uncertain data. It has been successfully applied to data pre-processing tasks such as attribute reduction or feature selection. In response to the shortcomings of existing anomaly detection methods that cannot effectively handle uncertain information such as noise and fuzziness, this paper proposes an unsupervised anomaly detection algorithm based on a novel fuzzy neighborhood rough sets model. At first, parameterized fuzzy relations are introduced to inscribe fuzzy neighborhood information granules. By establishing the relationship between different granules, the fuzzy neighborhood lower and upper approximations are defined to construct a fuzzy neighborhood rough set model for decision-free information systems. The lower approximation ratio is further proposed and used to construct the anomaly score, which characterizes the anomaly degree of the objects by aggregating the granule intensity of anomalies with corresponding weights. Finally, an unsupervised anomaly detection algorithm is designed for heterogeneous data based on the proposed fuzzy neighborhood rough set model. The results of extensive experiments illustrate that the proposed algorithm outperforms the other ten comparison algorithms and can effectively handle uncertain information. The code is publicly available online at https://github.com/yuyuan97/ADFNR .},
  archive      = {J_ISCI},
  author       = {Yuan Yuan and Sihan Wang and Hongmei Chen and Chuan Luo and Zhong Yuan},
  doi          = {10.1016/j.ins.2025.122075},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122075},
  shortjournal = {Inf. Sci.},
  title        = {Anomaly detection based on fuzzy neighborhood rough sets},
  volume       = {709},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predefined-time collision avoidance adaptive leader–follower
formation control for nonlinear multiagent systems. <em>ISCI</em>,
<em>709</em>, 122073. (<a
href="https://doi.org/10.1016/j.ins.2025.122073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates predefined-time collision avoidance adaptive leader follower formation control for nonlinear multiagent systems (MASs) with unmeasurable states. The practical predefined-time stability (PPTS) criterion is employed to ensure that all system errors, including observer errors and filtering errors, converge within the specified time frame. Prescribed performance functions (PPFs) are implemented to prevent collisions by transforming and constraining errors appropriately, while simultaneously ensuring that the convergence of system errors is achieved within the specified range. System stability is evaluated by integrating the command filter and backstepping technique, preventing the need for repeated differentiation Then, a predefined-time adaptive formation controller with collision avoidance is designed, which also address situations involving unmeasurable states. Finally, simulations using a model of unmanned surface vehicles (USVs) are performed to validate the proposed method.},
  archive      = {J_ISCI},
  author       = {Dongyang Liu and Zhi Liu and Lei Yan and C.L. Philip Chen and Ci Chen},
  doi          = {10.1016/j.ins.2025.122073},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122073},
  shortjournal = {Inf. Sci.},
  title        = {Predefined-time collision avoidance adaptive leader–follower formation control for nonlinear multiagent systems},
  volume       = {709},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed dynamic event-triggered consensus control of
multiagent systems subject to external disturbances. <em>ISCI</em>,
<em>709</em>, 122072. (<a
href="https://doi.org/10.1016/j.ins.2025.122072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present paper focuses on the bounded consensus problem of multi-agent systems (MASs) with external disturbances. A novel hybrid dynamic event-triggered mechanism (DETM) is proposed to simultaneously reduce the triggering frequency of the sensors and controllers. Under this mechanism, a fully distributed event-triggered protocol is designed to reach the bounded consensus. Not only the triggering functions but also the control protocols utilize the relative information between agents and are independent of the global information of the system network. Furthermore, the Zeno phenomenon is excluded for any time. In comparison with existing results, the most significant advantage of this paper is that the designed hybrid DETM reduces both the communication frequency between agents and the controller update frequency. Finally, several examples are introduced to validate the effectiveness and advantages of the proposed methods.},
  archive      = {J_ISCI},
  author       = {Juan Zhang and Bowen Zhou and Dongsheng Yang and Yanhong Luo and Guangdi Li},
  doi          = {10.1016/j.ins.2025.122072},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122072},
  shortjournal = {Inf. Sci.},
  title        = {Distributed dynamic event-triggered consensus control of multiagent systems subject to external disturbances},
  volume       = {709},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning using statistical invariants with privileged
information. <em>ISCI</em>, <em>709</em>, 122069. (<a
href="https://doi.org/10.1016/j.ins.2025.122069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning using privileged information has been widely applied across various fields, with most existing research based on the classical SVM+ model. Inspired by recent advances in learning using statistical invariants, this paper introduces a new paradigm for representing privileged information as statistical invariants, enabling its integration into the model in the mode of weak convergence. This method is denoted as learning using statistical invariants with privileged information (LUSIPI). In LUSIPI, privileged information establishes a connection between the decision functions in the input space and privileged space through statistical invariants, which helps to select a suitable set of admissible functions. Additionally, this method enables the simultaneous utilization of multiple types of privileged information. Experimental results on the UCI, MNIST, and 20 newsgroups datasets demonstrate that the method improves the classification performance and exhibits enhanced stability with variations in privileged information compared to SVM+.},
  archive      = {J_ISCI},
  author       = {Xueqin Yan and Chunna Li and Yuanhai Shao and Yanhui Meng},
  doi          = {10.1016/j.ins.2025.122069},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122069},
  shortjournal = {Inf. Sci.},
  title        = {Learning using statistical invariants with privileged information},
  volume       = {709},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A group recommendation method based on automatically
integrating members’ preferences via taking advantages of LLM.
<em>ISCI</em>, <em>709</em>, 122067. (<a
href="https://doi.org/10.1016/j.ins.2025.122067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared with personalized recommendation, group recommendation is more complex, achieving accurate recommendation that satisfy with all group members&#39; preferences faces more severe challenges, including how to make a trade-off for the difference of preferences among group members, recommendation performance is easily affected by the problems of data sparsity and cold start, it is more difficult for users to understand the reasons for being recommended (i.e., poor interpretability), etc. Inspired by the strong text learning and understanding ability provided by large language models (LLMs), we propose a LLM-based group recommendation method for learning multi-view interaction topics of groups and items contained in various texts. This method can learn a group&#39;s preference by automatically integrating its members preferences without integrating policy, and analyze group/user preferences and understand group/user behaviors by using multi-view text mining. Specifically, in order to integrate rich group to item interaction information into the model, we designed a graph convolution network (GCN) model based on multi-topic learning, and denote the new model as topic-based graph convolution network via LLM (T-GCN-LLM). By applying graph convolutions on the multi-topic association graphs, the model can make a comprehensive representations for groups and users through using embeddings contained in multiple topics, so as to improve the group recommendations. We conducted extensive experiments on multiple real-world datasets to evaluate the T-GCN-LLM, the results demonstrate that our model can better represent the interactions between groups and items than many novel and high quality group recommendation methods. At the same time, the interpretability analysis experiment also proves the importance of incorporating the topics into the model to improve the interpretability of group recommendations.},
  archive      = {J_ISCI},
  author       = {Shanshan Feng and Zeping Lang and Jing He and Huaxiang Zhang and Wenjuan Chen and Jian Cao},
  doi          = {10.1016/j.ins.2025.122067},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122067},
  shortjournal = {Inf. Sci.},
  title        = {A group recommendation method based on automatically integrating members&#39; preferences via taking advantages of LLM},
  volume       = {709},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reliability-driven joint clustering based on hybrid
attribute analysis for supporting social network large-scale
decision-making. <em>ISCI</em>, <em>709</em>, 122062. (<a
href="https://doi.org/10.1016/j.ins.2025.122062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social network large-scale decision-making (SNLSDM) has become an important domain in the field of decision science. A major challenge in solving such problems lies in the effective data dimensionality reduction through clustering techniques. While the reliability of evaluation information significantly influences clustering quality, most clustering algorithms overlook this critical factor. To address this gap, this article proposes novel reliability-driven joint clustering algorithms based on hybrid attribute analysis for SNLSDM problems. First, the probabilistic linguistic evaluation-reliability function (PL-ERF) is defined to handle fuzzy evaluations and social networks, along with its operational rules. We describe the configuration of SNLSDM with PL-ERFs. Subsequently, the hybrid attribute analysis is conducted to process the initial trust social network. A new reliability-based trust propagation method is designed to construct a complete trust social network. By combining trust and similarity information, a compatibility network is established. Accordingly, we develop reliability-driven joint clustering algorithms that consider multiple constraints, including similarity, trust, and compatibility. We also discuss the time complexity analysis and scalability of the algorithms. Finally, a numerical experiment and two real-word cases studies illustrate the feasibility and effectiveness of the algorithms. A comparative analysis highlights the impact and advantages of incorporating reliability into clustering.},
  archive      = {J_ISCI},
  author       = {Sumin Yu and Jia Xiao and Zhijiao Du and Xuanhua Xu},
  doi          = {10.1016/j.ins.2025.122062},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122062},
  shortjournal = {Inf. Sci.},
  title        = {Reliability-driven joint clustering based on hybrid attribute analysis for supporting social network large-scale decision-making},
  volume       = {709},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A general link prediction method based on path node
information and source node information. <em>ISCI</em>, <em>709</em>,
122051. (<a href="https://doi.org/10.1016/j.ins.2025.122051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction in complex networks involves forecasting unknown or future connections. Traditional methods often rely heavily on network topology information. However, in complex networks with significant attribute information (i.e., attributed networks), relying solely on topology information often leads to limited accuracy in predicting node connections. To address this issue, this study explores link prediction methods for weighted/unweighted and attributed/non-attributed networks. A novel node similarity is introduced, which comprehensively considers multiple factors. Based on structural information, attribute information, and weight information, a general link prediction framework is proposed for four different network types. This framework contains three core modules: a structural similarity module, an attribute similarity module, and a weighted similarity module. Using these modules, four global similarity measurements are defined for different network types. Taking weighted and attributed networks as an example, a link prediction algorithm is designed, and three key parameters are analyzed. To validate the effectiveness of the proposed algorithms, experiments are conducted on four types of real-world network datasets. The experimental results demonstrate that the proposed algorithms exhibit significant advantages in terms of prediction accuracy and robustness.},
  archive      = {J_ISCI},
  author       = {Zhi Kong and Shudi Zhai and Lifu Wang and Ge Guo},
  doi          = {10.1016/j.ins.2025.122051},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122051},
  shortjournal = {Inf. Sci.},
  title        = {A general link prediction method based on path node information and source node information},
  volume       = {709},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Granular ball-based partial label feature selection via
fuzzy correlation and redundancy. <em>ISCI</em>, <em>709</em>, 122047.
(<a href="https://doi.org/10.1016/j.ins.2025.122047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial label learning is a weakly supervised framework in which each training sample is associated with a set of candidate labels, but only one among them is the true label. Feature selection is a technique for enhancing the ability of learning models to generalize effectively. However, a challenging problem in feature selection for partial label learning is the impact of ambiguous candidate labels. To address this, this paper proposes a granular ball-based partial label feature selection method via fuzzy correlation and redundancy. Firstly, the paper utilizes granular ball computing to obtain two granular ball sets that respectively reflect the supervision information from candidate and non-candidate labels. The relative density between two granular ball sets is used to obtain labeling confidence which can identify the ground-truth labels. Then, a novel fuzzy entropy is defined by combining consistency in the granular ball with fuzzy information entropy. Additionally, fuzzy mutual information is derived by considering the fuzzy entropy and the fuzzy similarity constrained by granular ball radius. Fuzzy correlation and redundancy is measured by granular ball-based fuzzy mutual information. A heuristic search strategy is used to rank the features according to the principle of maximizing relevance and minimizing redundancy. Finally, experimental results on five real-world datasets and eight controlled UCI datasets show that the proposed method obtains superior performance than other compared methods.},
  archive      = {J_ISCI},
  author       = {Wenbin Qian and Junqi Li and Xinxin Cai and Jintao Huang and Weiping Ding},
  doi          = {10.1016/j.ins.2025.122047},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122047},
  shortjournal = {Inf. Sci.},
  title        = {Granular ball-based partial label feature selection via fuzzy correlation and redundancy},
  volume       = {709},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing urban mobility: A multi-modal travel plan
recommendation framework integrating the influences of temporal
characteristics and candidate sets. <em>ISCI</em>, <em>709</em>, 122042.
(<a href="https://doi.org/10.1016/j.ins.2025.122042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposed a travel plan recommendation system that can provide multi-modal, personalized, and door-to-door travel plans to solve travelers’ difficulty in choosing when facing vast and complex travel information. First, we established a dynamic T ravel C hoice B ehavior G raph (TCBG) model, which considers the travel plan candidate set and the temporal characteristics (time-decay and periodicity) of travelers’ behavioral preferences. Next, to effectively learn from TCBG, we constructed a U nified C andidate S et R epresentation M odule (UCSRM) and a new graph neural network called C ontinuous D ynamic H eterogeneous Graph A ttention N etworks (CDHAN). UCSRM can employ a multi-head self-attention mechanism for a unified representation of travel plan candidate sets with inconsistent lengths. CDHAN can capture the temporal characteristics of travelers’ preferences by combining the improved Hawkes process. Finally, we validated the effectiveness of the model and framework on multi-modal travel datasets and achieved 0.8172, 0.7994, 0.7859, and 0.9345 on the evaluation metrics of Pre, Rec, F1, and NDCG, respectively. These results show that our model/framework outperforms six existing state-of-the-art models/frameworks in these four evaluation metrics. This study provided a new model and learning framework for travel plan recommendation systems, essential for improving the efficiency of urban transportation and travelers’ travel experience.},
  archive      = {J_ISCI},
  author       = {Yiran Yu and Dewei Li and Baoming Han and Qi Zhang and Yue Huang and Ruixia Yang},
  doi          = {10.1016/j.ins.2025.122042},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122042},
  shortjournal = {Inf. Sci.},
  title        = {Enhancing urban mobility: A multi-modal travel plan recommendation framework integrating the influences of temporal characteristics and candidate sets},
  volume       = {709},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Similarity measures for interval type-3 fuzzy sets.
<em>ISCI</em>, <em>709</em>, 121991. (<a
href="https://doi.org/10.1016/j.ins.2025.121991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The similarity measure (SM) is an important parameter for comparing two different sets and is widely used in various applications, such as clustering, biometric identification, data analysis, information retrieval, decision-making, approximate reasoning, pattern recognition and natural language processing. Various SMs have been developed using type-1 and type-2 fuzzy sets (FSs) to perform the comparison of fuzzy sets in different applications. In this paper, a similarity measure for interval type-3 fuzzy sets (IT3FS) is introduced. Using IT3FSs, three set-theoretic and proximity-based SMs are proposed. These SMs are determined using α-levels on type-3 fuzzy sets (T3FSs). The employed IT3FSs are represented using Gaussians with uncertain widths and uncertain centers. The proposed SMs are used to evaluate the similarity of these fuzzy sets. The experiments are conducted, and the degrees of similarities for IT3FSs are determined. A comparison of the proposed SMs reveals that two of them exhibit a high correlation, while the third produces slightly different results. The SMs are tested in differentiating the linguistic values.},
  archive      = {J_ISCI},
  author       = {Rafik Aliev and Rahib Abiyev and Rafig Aliyev and Sanan Abizada},
  doi          = {10.1016/j.ins.2025.121991},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {121991},
  shortjournal = {Inf. Sci.},
  title        = {Similarity measures for interval type-3 fuzzy sets},
  volume       = {709},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A learning-based anomaly detection framework for secure
recommendation. <em>ISCI</em>, <em>708</em>, 122071. (<a
href="https://doi.org/10.1016/j.ins.2025.122071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems are essential tools for suggesting items or information to users based on their preferences and behaviors, which have been widely applied in various online platforms and services to personalize user experiences, increase user engagement, and drive business growth. However, the security and efficacy of recommendation systems can be compromised if the input data is tainted by malicious users. One of the primary threats to recommendation systems is shilling attacks, which pose great challenges in handling various types of huge-volume data with anomaly detection techniques. In this paper, we propose a novel anomaly detection framework named LTHiForest with the use of the learning to hash based isolation forest. Then, we instantiate the generic framework with one concrete hashing mechanism, extended order preserving hashing, to illustrate the stages of our framework and verify its effectiveness in detecting various anomalies. The core idea of this instantiation is to learn from data to construct a better isolation forest structure than the state-of-the-art methods like iForest and LSHiForest, which can achieve robust detection of various anomaly types. Extensive experiments on both synthetic and real-world data sets demonstrate the robustness and effectiveness of our framework for recommendation systems.},
  archive      = {J_ISCI},
  author       = {Haolong Xiang and Wenhao Fei and Ruiyang Ni and Xuyun Zhang},
  doi          = {10.1016/j.ins.2025.122071},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122071},
  shortjournal = {Inf. Sci.},
  title        = {A learning-based anomaly detection framework for secure recommendation},
  volume       = {708},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design of zero-determinant alliances in repeated
multi-player games. <em>ISCI</em>, <em>708</em>, 122070. (<a
href="https://doi.org/10.1016/j.ins.2025.122070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The formation of coalitions or alliances is ubiquitous in nature. This paper extends the zero-determinant (ZD) strategies from single players to subsets of players, to which we refer to as the ZD alliances. First, we model the dynamics of repeated multi-player games with a strategic alliance as an equivalent algebraic form and a simple formula is proposed to design a strategic ZD alliance. Thereafter, the modeling and designing methods for synchronous ZD alliance are considered. Finally, we apply the main results to a four-player prisoner&#39;s dilemma and analyze the influence of parameters on the probability of alliance cooperation. Our results can not only reduce the computation complexity, but also highlight the importance of coordination to succeed in large groups.},
  archive      = {J_ISCI},
  author       = {Ying Wang and Yuanhua Wang and Yonglin Guo and Wenke Zang and Guodong Zhao},
  doi          = {10.1016/j.ins.2025.122070},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122070},
  shortjournal = {Inf. Sci.},
  title        = {Design of zero-determinant alliances in repeated multi-player games},
  volume       = {708},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multiple level competitive swarm optimizer based on dual
evaluation criteria and global optimization for large-scale optimization
problem. <em>ISCI</em>, <em>708</em>, 122068. (<a
href="https://doi.org/10.1016/j.ins.2025.122068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale optimization problems (LSOPs) in science and technology bring great challenges to the performance of algorithms. Although Competitive swarm optimizer (CSO) is an effective method, some shortcomings still exist when handling LSOPs, such as premature convergence. Therefore, a novel multiple level CSO with dual evaluation criteria and global optimization (DEGMCSO) is proposed to seek optimal solutions of LSOPs. In this paper, dual evaluation criteria are inserted into the multiple comparison process of the losers and winners to assist the algorithm retain more high quality particles with the potential. In addition to fitness values, adaptive selection weight fitness-distance is designed as the other criterion for selecting winners and losers according to different optimization problems. Meanwhile, a simple global optimal modification strategy is employed to get high quality global best solution. By CEC2010 and CEC2013 function suits, the results indicate DEGMCSO outperforms some popular algorithms. Finally, DEGMCSO is applied to feather selection problems of high dimension classification in the real world. The simulation results show that compared with the original CSO algorithm, DEGMCSO can find the solution of 16 functions on CEC2010 test function set which is obviously better than the CSO algorithm.},
  archive      = {J_ISCI},
  author       = {Chen Huang and Yingjie Song and Hongjiang Ma and Xiangbing Zhou and Wu Deng},
  doi          = {10.1016/j.ins.2025.122068},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122068},
  shortjournal = {Inf. Sci.},
  title        = {A multiple level competitive swarm optimizer based on dual evaluation criteria and global optimization for large-scale optimization problem},
  volume       = {708},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The optimal mode-classification stabilization of sampled
stochastic jump systems via an improved hill-climbing algorithm based on
q-learning. <em>ISCI</em>, <em>708</em>, 122066. (<a
href="https://doi.org/10.1016/j.ins.2025.122066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the stabilization problem of stochastic jump systems (SJSs) closed by a generally sampled controller. Because of the controller&#39;s switching and state both sampled, it is challenging to study its stabilization. A new stabilizing method deeply depending on the mode classifications is proposed to deal with the above sampling situation, whose controllers&#39; quantity is equal to a Stirling number of the second kind. For the sake of finding the best stabilization effect among all the classifications, a convex optimization problem is developed, whose global solution is proved to be existent and can be computed by an augmented Lagrangian function. More importantly, in order to further reduce the computation complexity but retaining a better performance as much as possible, a novelly improved hill-climbing algorithm is established by applying the Q-learning technique to provide an optimal attenuation coefficient. A numerical example is offered so as to verify the effectiveness and superiority of the methods proposed in this study.},
  archive      = {J_ISCI},
  author       = {Guoliang Wang and Dechao Kong},
  doi          = {10.1016/j.ins.2025.122066},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122066},
  shortjournal = {Inf. Sci.},
  title        = {The optimal mode-classification stabilization of sampled stochastic jump systems via an improved hill-climbing algorithm based on Q-learning},
  volume       = {708},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view ordinal regression with feature augmentation and
privileged information learning. <em>ISCI</em>, <em>708</em>, 122065.
(<a href="https://doi.org/10.1016/j.ins.2025.122065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ordinal regression deals with the classification problems that the classes are ranked in order. The majority of existing ordinal regression approaches are designed for single-view data, and only a little work is done on multi-view ordinal regression. However, these multi-view ordinal regression works mainly concentrate on the consensus information between different views, while the complementary information that is critical in multi-view learning is not adequately considered in learning the ordinal regression classifier. In this paper, we put forward the multi-view ordinal regression model that incorporates feature augmentation and privileged information learning (MORFP). Firstly, distinguished from the existing multi-view ordinal regression approaches that mainly embody the consensus principle, MORFP introduces the concept of privileged information learning and implements both the consensus and complementarity principles. Based on the concept of privileged information learning, we treat one view as the privileged information of another view, so that different views can supply complementary information to enhance each other. Secondly, considering that the distributions of data in distinct views may be are greatly different, we map those views to a common subspace and augment this subspace by incorporating the original features of each view. By combining the original features in the views and projected features in the common subspace, the learned ordinal regression classifier is expected to have better discriminative ability than that learned on only the projected features or the original features. Lastly, we employ a heuristic framework to resolve the learning problem of MORFP, which trains the multi-view ordinal regression classifier and optimizes the projection matrices alternately. Numerical studies on real-life datasets have demonstrated that MORFP performs explicitly better than the existing multi-view ordinal regression approaches.},
  archive      = {J_ISCI},
  author       = {Yanshan Xiao and Linbin Chen and Bo Liu},
  doi          = {10.1016/j.ins.2025.122065},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122065},
  shortjournal = {Inf. Sci.},
  title        = {Multi-view ordinal regression with feature augmentation and privileged information learning},
  volume       = {708},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fixed-time control of multi-motor nonlinear systems via
adaptive neural network dual sliding mode. <em>ISCI</em>, <em>708</em>,
122061. (<a href="https://doi.org/10.1016/j.ins.2025.122061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a fixed-time control method integrating backlash, friction, and unknown time-varying delay compensation to achieve precise load position tracking and speed synchronization in multi-motor systems. First, the novel tracking and synchronization control strategies are developed based on adaptive neural network (NN) dual sliding modes. The sliding mode surfaces are designed based on tracking and synchronization errors, respectively, and adaptive neural networks are employed to approximate unknown nonlinear functions. This approach ensures fixed-time convergence independent of the initial states of the system, with convergence time determined a priori and capable of ensuring satisfactory dynamic performance. Secondly, a new exponential Lyapunov-Krasovskii functional is constructed to compensate for the uncertainties of time-varying delays without requiring prior knowledge of the upper bound of delay nonlinearities. Finally, the effectiveness of the proposed approach is validated through simulation results.},
  archive      = {J_ISCI},
  author       = {Wanjun Jing and Meng Li and Yong Chen and Zhangyong Chen},
  doi          = {10.1016/j.ins.2025.122061},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122061},
  shortjournal = {Inf. Sci.},
  title        = {Fixed-time control of multi-motor nonlinear systems via adaptive neural network dual sliding mode},
  volume       = {708},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). One-class graph autoencoder: A new end-to-end,
low-dimensional, and interpretable approach for node classification.
<em>ISCI</em>, <em>708</em>, 122060. (<a
href="https://doi.org/10.1016/j.ins.2025.122060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One-class learning (OCL) for graph neural networks (GNNs) comprises a set of techniques applied when real-world problems are modeled through graphs and have a single class of interest. These methods may employ a two-step strategy: first representing the graph and then classifying its nodes. End-to-end methods learn the node representations while classifying the nodes in OCL process. We highlight three main gaps in this literature: (i) non-customized representations for OCL; (ii) the lack of constraints on hypersphere learning; and (iii) the lack of interpretability. This paper presents O ne-c L ass G raph A utoencoder (OLGA), a new OCL for GNN approach. OLGA is an end-to-end method that learns low-dimensional representations for nodes while encapsulating interest nodes through a proposed and new hypersphere loss function. Furthermore, OLGA combines this new hypersphere loss with the graph autoencoder reconstruction loss to improve model learning. The reconstruction loss is a constraint to the sole use of the hypersphere loss that can bias the model to encapsulate all nodes. Finally, our low-dimensional representation makes the OLGA interpretable since we can visualize the representation learning at each epoch. OLGA achieved state-of-the-art results and outperformed six other methods with statistical significance while maintaining the learning process interpretability with its low-dimensional representations.},
  archive      = {J_ISCI},
  author       = {Marcos Paulo Silva Gôlo and José Gilberto Barbosa de Medeiros Junior and Diego Furtado Silva and Ricardo Marcondes Marcacini},
  doi          = {10.1016/j.ins.2025.122060},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122060},
  shortjournal = {Inf. Sci.},
  title        = {One-class graph autoencoder: A new end-to-end, low-dimensional, and interpretable approach for node classification},
  volume       = {708},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigation of consensus for nonlinear time-varying
multiagent systems via data-driven techniques. <em>ISCI</em>,
<em>708</em>, 122052. (<a
href="https://doi.org/10.1016/j.ins.2025.122052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper employs data-driven techniques to investigate the robustness control of leader-follower consensus in nonlinear discrete-time time-varying multiagent systems with fixed topology. Initially, pertinent symbolic definitions for sampled data are established, followed by an introduction to graph theory and system models. As data-driven algorithms necessitate linear systems, each nonlinear subsystem is linearized. Subsequently, distributed controllers are designed based on control principles to ensure multi-agent consensus. Additionally, the controller gain matrix is derived via a data-driven method, with its feasibility theoretically verified by solving nonlinear matrix inequalities. Finally, numerical simulations validate the efficacy of this approach for achieving robust leader-follower consensus control.},
  archive      = {J_ISCI},
  author       = {Yuanshan Liu and Yude Xia},
  doi          = {10.1016/j.ins.2025.122052},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122052},
  shortjournal = {Inf. Sci.},
  title        = {Investigation of consensus for nonlinear time-varying multiagent systems via data-driven techniques},
  volume       = {708},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Consensus control for multi-agent systems with unknown faded
neighborhood information via iterative learning scheme. <em>ISCI</em>,
<em>708</em>, 122050. (<a
href="https://doi.org/10.1016/j.ins.2025.122050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the consensus problem of multi-agent systems with unknown faded neighborhood information is addressed using the iterative learning control method. Considering that information exchange in wireless networks may be disturbed by unknown fading effects and unknown additive noise, it is significant to realize accurate consensus tracking of each agent to a given leader under the contaminated information. Unlike the traditional mechanism of correcting unknown faded neighborhood information by estimating the statistical characteristics of random fading variables, we introduce test signals to correct the trajectory signals of each agent. As no estimation mechanism is involved, the storage and computational burden of the whole system are greatly reduced. Based on a classic distributed structure and a novel correction mechanism, two novel distributed learning consensus control schemes are constructed. The consensus results of multi-agent systems under the two learning control schemes are discussed in detail using mathematical analysis tools. Finally, the multi-pendulum network system is simulated to verify the theoretical results.},
  archive      = {J_ISCI},
  author       = {Wanzheng Qiu and JinRong Wang and Dong Shen},
  doi          = {10.1016/j.ins.2025.122050},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122050},
  shortjournal = {Inf. Sci.},
  title        = {Consensus control for multi-agent systems with unknown faded neighborhood information via iterative learning scheme},
  volume       = {708},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable service recommendation for interactive mashup
development counteracting biases. <em>ISCI</em>, <em>708</em>, 122049.
(<a href="https://doi.org/10.1016/j.ins.2025.122049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Web services have been prevalently applied in many software development scenarios such as the development of many applications in the cloud, mobile networks, and Web. But Web services usually suffer from the serious issue of single functionality; thus in recent years, compositions of Web services, i.e., mashups, have become a popular choice, and have brought significant convenience in providing more comprehensive functionalities. But the diversity and number of Web services are expanding dramatically, resulting in an intractable challenge: how to effectively recommend Web services for mashup development. Researchers have proposed several recommendation approaches, but existing solutions are primarily applicable in a one-shot paradigm, which may introduce biases and usually lack explainability. In real-world scenarios, developers usually need to incorporate new Web services to address emerging challenges, implying that the development paradigm could be interactive. Moreover, existing approaches are prone to produce mediocre accuracy. To solve these issues, in this paper, we develop an innovative Multimodal Features-based Unbiased (MMFU) service recommendation framework for interactive mashup development, which takes full advantage of the multimodal features involved in the development procedure. Our MMFU framework encompasses two separate models developed to learn deep features from both text and graph structural information, and contains a feature fusion mechanism. Extensive experiments were performed on two real-world datasets, and the results revealed that the MMFU framework outperforms the compared existing state-of-the-art approaches, and has high explainability and the ability to counteract biases.},
  archive      = {J_ISCI},
  author       = {Yueshen Xu and Shaoyuan Zhang and Honghao Gao and Yuyu Yin and Jingzhao Hu and Rui Li},
  doi          = {10.1016/j.ins.2025.122049},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122049},
  shortjournal = {Inf. Sci.},
  title        = {Explainable service recommendation for interactive mashup development counteracting biases},
  volume       = {708},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical three-way decision fusion for multigranularity
GPU-CPU coscheduling in hybrid computing systems. <em>ISCI</em>,
<em>708</em>, 122048. (<a
href="https://doi.org/10.1016/j.ins.2025.122048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In heterogeneous computing environments, coscheduling of the graphics processing unit (GPU) and central processing unit (CPU) poses substantial challenges because of the diverse hardware architectures and dynamic workload patterns. To address this, we propose a novel hierarchical three-way decision fusion (H3WDF) strategy that integrates multigranularity workload predictions and adaptive scheduling policies. H3WDF employs a three-tier decision-making process, achieving global coordination through selective aggregation of localized decisions while establishing a balance between efficiency and quality of service. Results of experimental evaluation in a heterogeneous environment comprising several GPUs demonstrate the superior performance of H3WDF across multiple metrics. For “large language model” workloads, H3WDF achieves remarkable prediction accuracy both for short- and long-term forecasts. H3WDF&#39;s three-way decision mechanism effectively distributes workloads, balancing between batched executions for training tasks and immediate executions for inference workloads. Resource utilization exhibits significant improvements across all GPU types, with particularly strong performance in the case of high-end GPUs. Compared with the state-of-the-art baselines, H3WDF substantially reduces job completion times, enhances energy efficiency, and consistently maintains high fairness in resource allocation.},
  archive      = {J_ISCI},
  author       = {Chunmao Jiang and Yongpeng Wang},
  doi          = {10.1016/j.ins.2025.122048},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122048},
  shortjournal = {Inf. Sci.},
  title        = {Hierarchical three-way decision fusion for multigranularity GPU-CPU coscheduling in hybrid computing systems},
  volume       = {708},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PCG-CAM: Enhanced class activation map using principal
components of gradients and its applications in brain MRI.
<em>ISCI</em>, <em>708</em>, 122046. (<a
href="https://doi.org/10.1016/j.ins.2025.122046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumors are among the most prevalent and deadly diseases worldwide, making early diagnosis critical. However, existing automated brain tumor diagnostic methods often lack interpretability, and the high cost of labeled data limits their effectiveness. Class activation mapping (CAM) provides visual explanations and object localization for convolutional neural networks (CNNs) by highlighting regions of interest corresponding to specific classes. However, existing approaches tend to focus solely on discriminative regions and often contain excessive noise. In this paper, we propose a simpler and more efficient method called PCG-CAM, which provides visual explanations for brain tumor diagnosis and generates fine-grained pseudo-labels. PCG-CAM extracts the principal components of gradients and uses their absolute values as weights for the feature maps, thereby better reflecting the importance of each feature map while preserving more object features. We evaluated the saliency maps generated by PCG-CAM on weakly-supervised brain tumor segmentation and assessed their generalizability in object localization tasks. Specifically, our method achieves 47.42% mIoU in weakly-supervised brain tumor segmentation, outperforming other methods by nearly 10% on average. The results on brain MRI and natural images demonstrate that our method effectively localizes target positions and provides robust explanations for model decisions.},
  archive      = {J_ISCI},
  author       = {Lan Huang and Yangguang Shao and Wenju Hou and Hui Yang and Yan Wang and Nan Sheng and Yinglu Sun and Yao Wang},
  doi          = {10.1016/j.ins.2025.122046},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122046},
  shortjournal = {Inf. Sci.},
  title        = {PCG-CAM: Enhanced class activation map using principal components of gradients and its applications in brain MRI},
  volume       = {708},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-way decision-based reinforcement learning for
container vertical scaling. <em>ISCI</em>, <em>708</em>, 122045. (<a
href="https://doi.org/10.1016/j.ins.2025.122045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Container-based cloud computing requires efficient and adaptive resource management, particularly when making vertical scaling decisions. Traditional approaches often struggle with workload variability and lack flexibility when faced with uncertainties in workload patterns. This paper introduces a novel three-way decision-based reinforcement learning (TWD-RL) model for container vertical scaling. The TWD-RL model partitions the state space into positive, boundary, and negative regions based on confidence measures derived from historical data and current system states. This partitioning enables more nuanced scaling decisions: immediate scaling in high-confidence states, deferring decisions in uncertain states, and exploring in low-confidence states. We provide a theoretical analysis of the model&#39;s convergence properties and optimality conditions, thus establishing its mathematical foundation. Furthermore, we evaluate our model using real-world workload data from the Google Cloud Platform. The results demonstrate that TWD-RL significantly outperforms traditional Vertical Pod Autoscaler (VPA) approaches with respect to average response time, Service Level Agreement (SLA) violations, and resource utilization efficiency.},
  archive      = {J_ISCI},
  author       = {Chunmao Jiang and Guojun Mao and Bin Xie},
  doi          = {10.1016/j.ins.2025.122045},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122045},
  shortjournal = {Inf. Sci.},
  title        = {Three-way decision-based reinforcement learning for container vertical scaling},
  volume       = {708},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Innovative rough set approaches using novel
initial-neighborhood systems: Applications in medical diagnosis of
covid-19 variants. <em>ISCI</em>, <em>708</em>, 122044. (<a
href="https://doi.org/10.1016/j.ins.2025.122044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The theory of rough sets produces a potent framework for administrating uncertainty and ambiguity in data, which is crucial for effective decision-making. However, the reliance on equivalence relations within this framework has led to the exploration of various generalizations and extensions. In this paper, we introduce eight new types of initial neighborhoods, expanding on the idea of initial neighborhoods, and examine the relationships and properties of twelve distinct types of neighborhoods derived from binary relations. We define initial-minimal and initial-maximal neighborhoods and develop eight types of rough approximations ( I ȷ -approximations) that generalize Pawlak&#39;s theory. These new approximations significantly improve upon previous methods, achieving accuracy rates of up to 100%. Furthermore, we implement Generalized Nano-topological frameworks in conjunction with our novel methodologies to address clinical applications, particularly focusing on advancing diagnostic strategies for Covid-19. By employing a universal binary relation, we clarify the effectiveness for our methodology per enhancing decision-making processes and pinpointing significant risk factors associated with Covid-19. Additionally, we introduce two algorithms for decision-making problems in information systems, emphasizing the broader applicability and significance of our approach across various fields.},
  archive      = {J_ISCI},
  author       = {Mostafa K. El-Bably and Rodyna A. Hosny and Mostafa A. El-Gayar},
  doi          = {10.1016/j.ins.2025.122044},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122044},
  shortjournal = {Inf. Sci.},
  title        = {Innovative rough set approaches using novel initial-neighborhood systems: Applications in medical diagnosis of covid-19 variants},
  volume       = {708},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic futures portfolio strategy: A multi-criteria nested
sequential three-state three-way decision model based on herd behavior.
<em>ISCI</em>, <em>708</em>, 122043. (<a
href="https://doi.org/10.1016/j.ins.2025.122043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The futures portfolio is a key tool for addressing market volatility and complexity in the financial markets. Traditional static strategies struggle to keep up with the rapidly shifting market sentiment and herd behavior, leading to delayed decision-making and risk management failures. To enhance investment efficiency and improve risk control, we propose a dynamic multi-criteria nested sequential three-state three-way decision (TS3WD) model based on herd behavior to identify and implement herd behaviors and optimize the futures portfolio strategy. Firstly, this paper proposes a method for determining optimistic and pessimistic conditional probabilities based on loss functions, deriving new TS3WD and simplified decision rules. Secondly, the herd behavior discrimination method is introduced to divide it into positive, neutral, and negative herd behaviors for holding futures contracts. Thirdly, four minimum adjustment optimization models for positive and negative herd behaviors under optimistic and pessimistic attitudes are constructed based on new decision rules, respectively, and a method based on the self-confidence principle for neutral herd behavior is presented, providing a quantitative model for implementing herd behaviors. Subsequently, a progressive dynamic algorithm based on a multi-criteria nested sequential TS3WD model is proposed to deduce the futures portfolio strategy, which dynamically identifies and adjusts loss functions to obtain the optimal futures investment behavior, forming a complete futures portfolio strategy. Finally, we apply the proposed method to solve the metal futures portfolio strategy in the Shanghai Futures Exchange, providing implications for investors in the futures market through sensitivity and comparative analyses.},
  archive      = {J_ISCI},
  author       = {Han Wang and Yanbing Ju and Yongxing Chang and Enrique Herrera-Viedma},
  doi          = {10.1016/j.ins.2025.122043},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122043},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic futures portfolio strategy: A multi-criteria nested sequential three-state three-way decision model based on herd behavior},
  volume       = {708},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A quality-relevant deep rule-based system with complementary
lifelong learning for adaptive quality prediction in industrial
semi-supervised process data streams. <em>ISCI</em>, <em>708</em>,
122036. (<a href="https://doi.org/10.1016/j.ins.2025.122036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning techniques have been widely applied for industrial quality prediction. However, industrial process data are often generated as data streams, which typically exhibit characteristics such as strong nonlinearity, time-varying behavior, and low sampling rates of quality variables. Conventional offline-trained deep learning models often fail to provide accurate predictions for such semi-supervised data streams. Therefore, a quality-relevant deep rule-based system with complementary lifelong learning (QDRSCLL) is proposed to enable adaptive prediction of critical quality variables in streaming data environments. QDRSCLL comprises a deep backbone network and a shallow predictor. The former utilizes a semi-supervised quality-relevant stacked autoencoder (SQSAE) for feature extraction, while the latter employs a hierarchical fuzzy rule system (HFRS) to perform fuzzy inference on hierarchical hidden features. Furthermore, a novel complementary lifelong learning mechanism is proposed to enable QDRSCLL with online incremental learning capabilities. Additionally, semi-supervised learning is integrated into the online learning process to further enhance its deep feature extraction capabilities and the prediction performance. The feasibility and superiority of the proposed method are demonstrated through two real-world processes and four synthetic datasets. Compared to the traditional evolving fuzzy system (EFS), the RMSE of QDRSCLL is reduced by more than 25% in all application scenarios.},
  archive      = {J_ISCI},
  author       = {Yu Gao and Huaiping Jin and Zhiqiang Wang and Bin Wang and Bin Qian and Biao Yang},
  doi          = {10.1016/j.ins.2025.122036},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122036},
  shortjournal = {Inf. Sci.},
  title        = {A quality-relevant deep rule-based system with complementary lifelong learning for adaptive quality prediction in industrial semi-supervised process data streams},
  volume       = {708},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Temporal knowledge graph link predictions with query-guided
temporal representation learning. <em>ISCI</em>, <em>708</em>, 122035.
(<a href="https://doi.org/10.1016/j.ins.2025.122035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal Knowledge Graph (TKG) records real-life events using timestamped facts and is used for the TKG link prediction task which is to answer an incomplete timestamped fact called the query. Existing works predict by learning entity embeddings where they represent entities with entity-related facts guided by queries to emphasize important ones. Although they generalize well, their learning with queries is limited since they guide learning with the average query which merges all queries without considering that queries in TKG represent diverse meanings. Merging diverse queries generates a vague averaged query which will mislead embedding learning and further confuse predictions. To resolve the limitation, we propose individual-query-guided learning (IndiQ) to learn clearer embeddings which faithfully realizes the nature of TKG that its records are diverse and should be modeled individually rather than averaging. Specifically, IndiQ formulates embedding learning as a weighted sum of entity-related facts and calculates weights using queries individually following the total probability theorem. Then, with the novel formulation, IndiQ guides the learning of entity embeddings using queries individually to identify important facts. Finally, IndiQ predicts future links using learned entity embeddings. Experimental results show that we achieve better performance. Visualizations further demonstrate the effectiveness of our IndiQ.},
  archive      = {J_ISCI},
  author       = {Linhua Dong and Xiaofei Zhou and Bo Wang and Qiannan Zhu and Fan Meng},
  doi          = {10.1016/j.ins.2025.122035},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122035},
  shortjournal = {Inf. Sci.},
  title        = {Temporal knowledge graph link predictions with query-guided temporal representation learning},
  volume       = {708},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrated heterogeneous graph and reinforcement learning
enabled efficient scheduling for surface mount technology workshop.
<em>ISCI</em>, <em>708</em>, 122023. (<a
href="https://doi.org/10.1016/j.ins.2025.122023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Timely scheduling is crucial for manufacturing workshops to adapt swiftly to changing conditions. This paper introduces a novel deep heterogeneous graph and reinforcement learning approach to address real-time challenges in a surface mount technology (SMT) workshop. The scheduling problem in SMT workshop can be modeled as a reconfigurable distributed flowshop group scheduling problem (RDFGSP), involving assignment of family operations to cells for their flows, sequencing of family operations on the cells, and sequencing of job operations in the family operations for their flows. By mapping the problem to a heterogeneous graph with distinct node and edge types, an end-to-end learning model is developed. The model integrates a heterogeneous graph neural network (HGNN) and sequential Q networks to effectively represent the key scheduling elements and the Markov decision-making process. HGNN is employed to extract meaningful features and representations from the heterogeneous graph. These representations are then fed into the sequential Q networks to select two cooperated actions to be taken. A weighted sum approach is proposed to provide more reasonable evaluation of the selected actions. Experimental comparisons with exact and heuristic methods from the literature demonstrate the superior performance and effectiveness of the proposed model.},
  archive      = {J_ISCI},
  author       = {Biao Zhang and Hongyan Sang and Chao Lu and Leilei Meng and Yanan Song and Xuchu Jiang},
  doi          = {10.1016/j.ins.2025.122023},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122023},
  shortjournal = {Inf. Sci.},
  title        = {Integrated heterogeneous graph and reinforcement learning enabled efficient scheduling for surface mount technology workshop},
  volume       = {708},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RIONIDA: A novel algorithm for imbalanced data combining
instance-based learning and rule induction. <em>ISCI</em>, <em>708</em>,
122015. (<a href="https://doi.org/10.1016/j.ins.2025.122015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The article presents the Rule Induction with Optimal Neighbourhood for Imbalanced Data Algorithm (RIONIDA) learning algorithm based on combination of two widely-used empirical approaches: rule induction and instance-based learning for imbalanced data classification. The algorithm is a substantial extension of the well-known the Rule Induction with Optimal Neighbourhood Algorithm (RIONA) learning algorithm developed for balanced data. RIONIDA uses rules more general than in RIONA and realises a few additional concepts in comparison to RIONA, i.e. optimisation of the explicitly given performance measure defined over the confusion matrix, optimisation of weights for two classes, the idea of scaled rules, optimisation of parameters related to two latter ideas. RIONIDA, with decisions explainable for the user, is relatively fast and significantly outperforms the state-of-the-art algorithms analysed in the article.},
  archive      = {J_ISCI},
  author       = {Grzegorz Góra and Andrzej Skowron},
  doi          = {10.1016/j.ins.2025.122015},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122015},
  shortjournal = {Inf. Sci.},
  title        = {RIONIDA: A novel algorithm for imbalanced data combining instance-based learning and rule induction},
  volume       = {708},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A method for determining maximin OWA operator weights.
<em>ISCI</em>, <em>708</em>, 122010. (<a
href="https://doi.org/10.1016/j.ins.2025.122010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a mathematical programming-based approach to determine the ordered weighted averaging (OWA) operator weights by maximizing the smallest difference between adjacent weights, referred to as the maximin OWA operator weights. Behavioral evidence suggests that decision-makers’ implicit weights, which influence their choices, are often quite steep. Thus, they tend to intuitively prefer alternatives that excel in several important criteria. If one alternative’s score is comparable to others, they might consider secondary and tertiary important criteria. The proposed maximin approach aligns more closely with this philosophy compared to previous methods that aim to evenly distribute operator weights. Furthermore, we derive a closed-form solution for the maximin OWA operator weights using results from convex analysis. We also revisit the minimax disparity model, which is similar to our maximin approach, to emphasize the similarities and differences between the two methods.},
  archive      = {J_ISCI},
  author       = {Byeong Seok Ahn},
  doi          = {10.1016/j.ins.2025.122010},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122010},
  shortjournal = {Inf. Sci.},
  title        = {A method for determining maximin OWA operator weights},
  volume       = {708},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel similarity-based taste features-extracted
emotions-aware music recommendation algorithm. <em>ISCI</em>,
<em>708</em>, 122001. (<a
href="https://doi.org/10.1016/j.ins.2025.122001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human music tastes are subjective and difficult to measure, with existing recommendation algorithms often failing to consider music similarity, taste features, and emotions simultaneously. This paper proposes a novel music recommendation algorithm that integrates music similarity, taste features, and emotions, organized into five modules. Motivated by the probabilistic linguistic term set (PLTS), we establish attribute feature vectors of songs by associating attribute values with corresponding probabilities. Module 1 establishes behavior matrix of users to calculate comprehensive behavioral feeling score for obtaining the original music interests of users. Module 2 designs two improved collaborative filtering algorithms to alleviate data sparsity of intuitionistic fuzzy music taste matrix. Module 3 extracts taste features from user listening behavior and the favorite songs of users. Module 4 integrates subjective and objective music emotions to obtain the comprehensive music emotions of user. Considering the dynamic change in users’ music taste features, we incorporate the latest taste features in Module 5 to reorder the song list obtained by the above four modules. The experiment results verify the effectiveness of this recommendation algorithm. It significantly outperforms three popular music recommendation systems in accuracy, excels in ranking quality, new song accuracy, and richness metrics, marginally surpasses them in listening duration.},
  archive      = {J_ISCI},
  author       = {Yu Gao and Shu-Ping Wan and Jiu-Ying Dong},
  doi          = {10.1016/j.ins.2025.122001},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {122001},
  shortjournal = {Inf. Sci.},
  title        = {A novel similarity-based taste features-extracted emotions-aware music recommendation algorithm},
  volume       = {708},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jat---5">JAT - 5</h2>
<ul>
<li><details>
<summary>
(2025). Asymptotics of bergman polynomials for domains with
reflection-invariant corners. <em>JAT</em>, <em>309</em>, 106172. (<a
href="https://doi.org/10.1016/j.jat.2025.106172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the asymptotic behavior of the Bergman orthogonal polynomials ( p n ) n = 0 ∞ for a class of bounded simply connected domains D . The class is defined by the requirement that conformal maps φ of D onto the unit disk extend analytically across the boundary L of D , and that φ ′ has a finite number of zeros z 1 , … , z q on L . The boundary L is then piecewise analytic with corners at the zeros of φ ′ . A result of Stylianopoulos implies that a Carleman-type strong asymptotic formula for p n holds on the exterior domain ℂ ∖ D ¯ . We prove that the same formula remains valid across L ∖ { z 1 , … , z q } and on a maximal open subset of D . As a consequence, the only boundary points that attract zeros of p n are the corners. This is in stark contrast to the case when φ fails to admit an analytic extension past L , since when this happens the zero counting measure of p n is known to approach the equilibrium measure for L along suitable subsequences.},
  archive      = {J_JAT},
  author       = {Erwin Miña-Díaz and Aron Wennman},
  doi          = {10.1016/j.jat.2025.106172},
  journal      = {Journal of Approximation Theory},
  month        = {8},
  pages        = {106172},
  shortjournal = {J. Approx. Theory},
  title        = {Asymptotics of bergman polynomials for domains with reflection-invariant corners},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A note on diffusion limits for stochastic gradient descent.
<em>JAT</em>, <em>309</em>, 106160. (<a
href="https://doi.org/10.1016/j.jat.2025.106160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the machine learning literature stochastic gradient descent has recently been widely discussed for its purported implicit regularization properties. Much of the theory, that attempts to clarify the role of noise in stochastic gradient algorithms, has approximated stochastic gradient descent by a stochastic differential equation with Gaussian noise. We provide a rigorous theoretical justification for this practice that showcases how the Gaussianity of the noise arises naturally.},
  archive      = {J_JAT},
  author       = {Alberto Lanconelli and Christopher S.A. Lauria},
  doi          = {10.1016/j.jat.2025.106160},
  journal      = {Journal of Approximation Theory},
  month        = {8},
  pages        = {106160},
  shortjournal = {J. Approx. Theory},
  title        = {A note on diffusion limits for stochastic gradient descent},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pseudo s-numbers of embeddings of gaussian weighted sobolev
spaces. <em>JAT</em>, <em>309</em>, 106159. (<a
href="https://doi.org/10.1016/j.jat.2025.106159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the approximation problem for functions in the Gaussian-weighted Sobolev space W p α ( R d , γ ) of mixed smoothness α ∈ N with error measured in the Gaussian-weighted space L q ( R d , γ ) . We obtain the exact asymptotic order of some pseudo s -numbers for the cases 1 ≤ q &lt; p &lt; ∞ and p = q = 2 . Additionally, we also obtain an upper bound and a lower bound for some pseudo s -numbers of the embedding of W 2 α ( R d , γ ) into L ∞ g ( R d ) . Our result is an extension of that obtained in Dinh Dũng and Van Kien Nguyen (IMA Journal of Numerical Analysis, 2023) for approximation and Kolmogorov numbers.},
  archive      = {J_JAT},
  author       = {Van Kien Nguyen},
  doi          = {10.1016/j.jat.2025.106159},
  journal      = {Journal of Approximation Theory},
  month        = {8},
  pages        = {106159},
  shortjournal = {J. Approx. Theory},
  title        = {Pseudo s-numbers of embeddings of gaussian weighted sobolev spaces},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Relative asymptotics of multiple orthogonal polynomials for
nikishin systems of two measures. <em>JAT</em>, <em>309</em>, 106158.
(<a href="https://doi.org/10.1016/j.jat.2025.106158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the relative asymptotics of two sequences of multiple orthogonal polynomials corresponding to two Nikishin systems of measures on the real line, the second one of which is obtained from the first one perturbing the generating measures with non-negative integrable functions. Each Nikishin system consists of two measures.},
  archive      = {J_JAT},
  author       = {A. López García and G. López Lagomasino},
  doi          = {10.1016/j.jat.2025.106158},
  journal      = {Journal of Approximation Theory},
  month        = {8},
  pages        = {106158},
  shortjournal = {J. Approx. Theory},
  title        = {Relative asymptotics of multiple orthogonal polynomials for nikishin systems of two measures},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The pearcey integral in the highly oscillatory region II.
<em>JAT</em>, <em>309</em>, 106150. (<a
href="https://doi.org/10.1016/j.jat.2025.106150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the Pearcey integral P ( x , y ) for large values of | x | and bounded values of | y | . The standard saddle point analysis is difficult to apply because the Pearcey integral is highly oscillating in this region. To overcome this problem we use the modified saddle point method introduced in López et al. (2009). A complete asymptotic analysis is possible with this method, and we derive a complete asymptotic expansion of P ( x , y ) for large | x | , accompanied by the exact location of the Stokes lines. There are two Stokes lines that divide the complex x − plane in two different sectors in which P ( x , y ) behaves differently when | x | is large. The asymptotic approximation is the sum of two asymptotic series whose terms are elementary functions of x and y . Both of them are of Poincaré type; one of them is given in terms of inverse powers of x ; the other one in terms of inverse powers of x 1 / 2 , and it is multiplied by an exponential factor that behaves differently in the two mentioned sectors. Some numerical experiments illustrate the accuracy of the approximation.},
  archive      = {J_JAT},
  author       = {Chelo Ferreira and José L. López and Ester Pérez Sinusía},
  doi          = {10.1016/j.jat.2025.106150},
  journal      = {Journal of Approximation Theory},
  month        = {8},
  pages        = {106150},
  shortjournal = {J. Approx. Theory},
  title        = {The pearcey integral in the highly oscillatory region II},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jde---25">JDE - 25</h2>
<ul>
<li><details>
<summary>
(2025). Universal gradient estimates of δu + a(x)up(ln⁡(u+c))q = 0 on
complete riemannian manifolds. <em>JDE</em>, <em>434</em>, 113257. (<a
href="https://doi.org/10.1016/j.jde.2025.113257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the elliptic non-linear equation Δ u + a ( x ) u p ( ln ⁡ ( u + c ) ) q = 0 on a complete Riemannian manifold with Ricci curvature bounded from below. By applying Nash-Moser iteration, we establish universal gradient estimates for positive solutions to the equation, where c ≥ 1 and a ( x ) is allowed to change sign. As an application, we obtain Liouville theorems when the manifold has non-negative Ricci curvature and a ( x ) is constant.},
  archive      = {J_JDE},
  author       = {Chong Song and Jibo Wu},
  doi          = {10.1016/j.jde.2025.113257},
  journal      = {Journal of Differential Equations},
  month        = {7},
  pages        = {113257},
  shortjournal = {J. Diff. Equ.},
  title        = {Universal gradient estimates of Δu + a(x)up(ln⁡(u+c))q = 0 on complete riemannian manifolds},
  volume       = {434},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two classes of benjamin–ono-type equations with the hilbert
operator related to the calogero–moser system and the classical
orthogonal polynomials. <em>JDE</em>, <em>434</em>, 113249. (<a
href="https://doi.org/10.1016/j.jde.2025.113249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates two distinct classes of Benjamin–Ono(BO)-type equations with the Hilbert operator. The first class consists of equations with constant coefficients, derived from linear differential equations, with a specific focus on the Mikhailov–Novikov equation and Satsuma–Mimura equation. The second class involves BO-type equations with variable coefficients linked to orthogonal polynomials, including Hermite, Jacobi, and Laguerre polynomials. A key aspect of transforming these differential equations into BO-type equations is that the zeros of the polynomial or periodic solutions must lie in the upper half-plane. For linear and quadratic polynomials, we directly analyze their zeros to determine the solutions of corresponding BO-type equations. For higher-order polynomials, we use the pole expansion method to derive the governing many-body systems of the zeros. This study deepens our understanding of the relationship between the zeros of polynomials and the solutions of BO-type equations.},
  archive      = {J_JDE},
  author       = {Ling-Juan Yan and Ya-Jie Liu and Xing-Biao Hu and Ying-Nan Zhang},
  doi          = {10.1016/j.jde.2025.113249},
  journal      = {Journal of Differential Equations},
  month        = {7},
  pages        = {113249},
  shortjournal = {J. Diff. Equ.},
  title        = {Two classes of Benjamin–Ono-type equations with the hilbert operator related to the Calogero–Moser system and the classical orthogonal polynomials},
  volume       = {434},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Smoothing effects and maximal hölder regularity for
non-autonomous kolmogorov equations in infinite dimension. <em>JDE</em>,
<em>434</em>, 113245. (<a
href="https://doi.org/10.1016/j.jde.2025.113245">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove smoothing properties and optimal Schauder type estimates for a class of nonautonomous evolution equations driven by time dependent Ornstein-Uhlenbeck operators in a separable Hilbert space. They arise as Kolmogorov equations of linear nonautonomous stochastic differential equations with Gaussian noise.},
  archive      = {J_JDE},
  author       = {Sandra Cerrai and Alessandra Lunardi},
  doi          = {10.1016/j.jde.2025.113245},
  journal      = {Journal of Differential Equations},
  month        = {7},
  pages        = {113245},
  shortjournal = {J. Diff. Equ.},
  title        = {Smoothing effects and maximal hölder regularity for non-autonomous kolmogorov equations in infinite dimension},
  volume       = {434},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global existence of strong solutions to the
landau–lifshitz–slonczewski equation. <em>JDE</em>, <em>434</em>,
113242. (<a href="https://doi.org/10.1016/j.jde.2025.113242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we focus on the existence of strong solutions for the Cauchy problem of the three-dimensional Landau-Lifshitz-Slonczewski equation. We construct a new combination of Bourgain space and Lebesgue space where linear and nonlinear estimates can be closed by applying frequency decomposition and energy methods. Finally, we establish the existence and uniqueness of the global strong solution provided that the initial data belongs to Besov space B ˙ Ω n 2 .},
  archive      = {J_JDE},
  author       = {Chenlu Zhang and Huaqiao Wang},
  doi          = {10.1016/j.jde.2025.113242},
  journal      = {Journal of Differential Equations},
  month        = {7},
  pages        = {113242},
  shortjournal = {J. Diff. Equ.},
  title        = {Global existence of strong solutions to the Landau–Lifshitz–Slonczewski equation},
  volume       = {434},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Universal log-gradient estimates of solutions to δpv + bvq +
cvr = 0 on manifolds and applications. <em>JDE</em>, <em>434</em>,
113233. (<a href="https://doi.org/10.1016/j.jde.2025.113233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we employ Cheng-Yau&#39;s method, the Saloff-Coste&#39;s Sobolev inequalities and Nash-Moser iteration to study local and global properties of positive solutions to the equation Δ p v + b v q + c v r = 0 on complete Riemannian manifolds with Ricci curvature bounded from below, where b , c ∈ R , p &gt; 1 , and q ≤ r are some real constants. Assuming certain conditions on b , c , p , q and r , we derive succinct and universal Cheng-Yau type gradient estimates for positive solutions, which are of sharp form. These gradient estimates allow us to obtain some Liouville-type theorems and Harnack inequalities. Our Liouville-type results are novel even in Euclidean spaces. Based on the global gradient estimates obtained, we also obtain the explicit global gradient estimates for such entire solutions by a lemma of Sung and Wang. As applications, we show the uniqueness of positive solutions to some generalized Allen-Cahn equation and Fisher-KPP equations.},
  archive      = {J_JDE},
  author       = {Jie He and Yuanqing Ma and Youde Wang},
  doi          = {10.1016/j.jde.2025.113233},
  journal      = {Journal of Differential Equations},
  month        = {7},
  pages        = {113233},
  shortjournal = {J. Diff. Equ.},
  title        = {Universal log-gradient estimates of solutions to Δpv + bvq + cvr = 0 on manifolds and applications},
  volume       = {434},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hölder regularity for degenerate parabolic double-phase
equations. <em>JDE</em>, <em>434</em>, 113231. (<a
href="https://doi.org/10.1016/j.jde.2025.113231">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove that bounded weak solutions to degenerate parabolic double-phase equations of p -Laplace type are locally Hölder continuous. The proof is based on phase analysis and methods for the p -Laplace equation. In particular, the phase analysis determines whether the double-phase equation is locally similar to the p -Laplace or the q -Laplace equation.},
  archive      = {J_JDE},
  author       = {Wontae Kim and Kristian Moring and Lauri Särkiö},
  doi          = {10.1016/j.jde.2025.113231},
  journal      = {Journal of Differential Equations},
  month        = {7},
  pages        = {113231},
  shortjournal = {J. Diff. Equ.},
  title        = {Hölder regularity for degenerate parabolic double-phase equations},
  volume       = {434},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quasi-periodic solutions around plane wave of high
dimensional nonlinear schrödinger equation. <em>JDE</em>, <em>434</em>,
113229. (<a href="https://doi.org/10.1016/j.jde.2025.113229">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a degenerate KAM theorem with multiple normal frequencies is established under qualitative non-degenerate conditions. As an application, quasi-periodic solutions around plane wave are obtained for high dimensional nonlinear Schrödinger equation with periodic boundary conditions.},
  archive      = {J_JDE},
  author       = {Meina Gao and Jianjun Liu and Zejing Liu},
  doi          = {10.1016/j.jde.2025.113229},
  journal      = {Journal of Differential Equations},
  month        = {7},
  pages        = {113229},
  shortjournal = {J. Diff. Equ.},
  title        = {Quasi-periodic solutions around plane wave of high dimensional nonlinear schrödinger equation},
  volume       = {434},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exact multiplicity, bifurcation curves, and asymptotic
profiles of endemic equilibria of a cross-diffusive epidemic model.
<em>JDE</em>, <em>434</em>, 113226. (<a
href="https://doi.org/10.1016/j.jde.2025.113226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study examines the global structure of endemic equilibrium (EE) solutions of a cross-diffusive epidemic model which incorporates the repulsive movement of the susceptible population away from the infected population. We show that the basic reproduction number R 0 alone cannot determine the existence of the EEs and the model may have multiple EEs when the repulsive movement rate χ is large. We prove that the set of EEs forms a simple and unbounded curve bifurcating from the curve of disease free equilibria at R 0 = 1 as R 0 varies from zero to infinity, where the bifurcation curve can be forward or backward. We find conditions under which a forward bifurcation curve is of S-shaped and show that a large χ tends to induce backward bifurcation curves. Results on the asymptotic profiles of the EEs are obtained as the repulsive movement rate is large or the random movement rates are small. Finally, we perform numerical simulations to illustrate the results.},
  archive      = {J_JDE},
  author       = {Rachidi B. Salako and Yixiang Wu and Shuwen Xue},
  doi          = {10.1016/j.jde.2025.113226},
  journal      = {Journal of Differential Equations},
  month        = {7},
  pages        = {113226},
  shortjournal = {J. Diff. Equ.},
  title        = {Exact multiplicity, bifurcation curves, and asymptotic profiles of endemic equilibria of a cross-diffusive epidemic model},
  volume       = {434},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global bifurcation results for a delay differential system
representing a chemostat model. <em>JDE</em>, <em>434</em>, 113222. (<a
href="https://doi.org/10.1016/j.jde.2025.113222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies a one-species chemostat model described by a system of differential delay equations, featuring a periodic input of a single nutrient with period ω . The delay represents the interval time between the consumption of the nutrient and its metabolization by the microbial species. We obtain global bifurcation results for the periodic solutions with period ω . Our proof is based on the application of the topological degree theory combined with a Whyburn-type Lemma.},
  archive      = {J_JDE},
  author       = {Pablo Amster and Pierluigi Benevieri},
  doi          = {10.1016/j.jde.2025.113222},
  journal      = {Journal of Differential Equations},
  month        = {7},
  pages        = {113222},
  shortjournal = {J. Diff. Equ.},
  title        = {Global bifurcation results for a delay differential system representing a chemostat model},
  volume       = {434},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effective medium theory for van-der-waals heterostructures.
<em>JDE</em>, <em>433</em>, 113260. (<a
href="https://doi.org/10.1016/j.jde.2025.113260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We derive the electromagnetic medium equivalent to a collection of all-dielectric nano-particles (enjoying high refractive indices) distributed locally non-periodically, precisely the medium is periodic with a unit cell composed of a cluster of multiple nano-particles, in a smooth domain Ω. Such distributions are used to model well-known structures in material sciences as the Van-der-Waals heterostructures. Since the nano-particles are all-dielectric, then the permittivity remains unchanged with respect to the background while the permeability is altered by this effective medium. This permeability is given in terms of three parameters. The first one is the polarization tensors of the used nano-particles. The second one is the averaged Magnetization matrix | Ω 0 | − 1 ∫ Ω 0 ∇ x ∫ Ω 0 ∇ y Φ 0 ( x , y ) ⋅ I 3 d y d x , where Φ 0 ( x , y ) : = 1 4 π | x − y | , I 3 is the identity matrix and Ω 0 is the unit cell. The third one is ∇ ∇ Φ 0 ( z i , z j ) , where z i &#39;s are locations of the local nano-particles distributed in the unit cell. This last tensor models the local strong interaction of the nano-particles. To our best knowledge, such tensors are new in both the mathematical and engineering oriented literature. This equivalent medium describes, in particular, the effective medium of 2 dimensional type Van-der-Waals heterostructures. These structures are 3 dimensional which are built as superposition of identical (2D)-sheets each supporting locally non-periodic distributions of nano-particles. An explicit form of this effective medium is provided for the particular case of honeycomb heterostructures. At the mathematical analysis level, we propose a new approach to derive the effective medium when the subwavelength nano-particles are distributed non-periodically. The first step consists in deriving the point-interaction approximation, also called the Foldy-Lax approximation. The scattered field is given as a superposition of dipoles (or poles for other models) multiplied by the elements of a vector which is itself solution of an algebraic system. This step is done regardless of the way how the particles are distributed. As a second step, which is the new and critical step, we rewrite this algebraic system according to the way how these nano-particles are locally distributed. The new algebraic system will then fix the related continuous Lippmann-Schwinger system which, in its turn, indicates naturally the equivalent medium.},
  archive      = {J_JDE},
  author       = {Xinlin Cao and Ahcene Ghandriche and Mourad Sini},
  doi          = {10.1016/j.jde.2025.113260},
  journal      = {Journal of Differential Equations},
  month        = {7},
  pages        = {113260},
  shortjournal = {J. Diff. Equ.},
  title        = {Effective medium theory for van-der-waals heterostructures},
  volume       = {433},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On logarithmic double phase problems. <em>JDE</em>,
<em>433</em>, 113247. (<a
href="https://doi.org/10.1016/j.jde.2025.113247">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we introduce a new logarithmic double phase type operator of the form G u : = − div ( | ∇ u | p ( x ) − 2 ∇ u + μ ( x ) [ log ⁡ ( e + | ∇ u | ) + | ∇ u | q ( x ) ( e + | ∇ u | ) ] | ∇ u | q ( x ) − 2 ∇ u ) , whose energy functional is given by u ↦ ∫ Ω ( | ∇ u | p ( x ) p ( x ) + μ ( x ) | ∇ u | q ( x ) q ( x ) log ⁡ ( e + | ∇ u | ) ) d x , where Ω ⊆ R N , N ≥ 2 , is a bounded domain with Lipschitz boundary ∂Ω, p , q ∈ C ( Ω ‾ ) with 1 &lt; p ( x ) ≤ q ( x ) for all x ∈ Ω ‾ and 0 ≤ μ ( ⋅ ) ∈ L 1 ( Ω ) . First, we prove that the logarithmic Musielak-Orlicz Sobolev spaces W 1 , H log ( Ω ) and W 0 1 , H log ( Ω ) with H log ( x , t ) = t p ( x ) + μ ( x ) t q ( x ) log ⁡ ( e + t ) for ( x , t ) ∈ Ω ‾ × [ 0 , ∞ ) are separable, reflexive Banach spaces and W 0 1 , H log ( Ω ) can be equipped with the equivalent norm inf ⁡ { λ &gt; 0 : ∫ Ω [ | ∇ u λ | p ( x ) + μ ( x ) | ∇ u λ | q ( x ) log ⁡ ( e + | ∇ u | λ ) ] d x ≤ 1 } . We also prove several embedding results for these spaces and the closedness of W 1 , H log ( Ω ) and W 0 1 , H log ( Ω ) under truncations. In addition we show the density of smooth functions in W 1 , H log ( Ω ) even in the case of an unbounded domain by supposing Nekvinda&#39;s decay condition on p ( ⋅ ) . The second part is devoted to the properties of the operator and it turns out that it is bounded, continuous, strictly monotone, of type (S + ), coercive and a homeomorphism. Also, the related energy functional is of class C 1 . As a result of independent interest we also present a new version of Young&#39;s inequality for the product of a power-law and a logarithm. In the last part of this work we consider equations of the form G u = f ( x , u ) in Ω , u = 0 on ∂ Ω with superlinear right-hand sides. We prove multiplicity results for this type of equation, in particular about sign-changing solutions, by making use of a suitable variation of the corresponding Nehari manifold together with the quantitative deformation lemma and the Poincaré-Miranda existence theorem.},
  archive      = {J_JDE},
  author       = {Rakesh Arora and Ángel Crespo-Blanco and Patrick Winkert},
  doi          = {10.1016/j.jde.2025.113247},
  journal      = {Journal of Differential Equations},
  month        = {7},
  pages        = {113247},
  shortjournal = {J. Diff. Equ.},
  title        = {On logarithmic double phase problems},
  volume       = {433},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Local exact controllability to the trajectories for the
two-dimensional magnetohydrodynamic system with controls acting only on
the velocity field. <em>JDE</em>, <em>433</em>, 113237. (<a
href="https://doi.org/10.1016/j.jde.2025.113237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the local exact controllability to the trajectories for the two-dimensional incompressible magnetohydrodynamic system on a bounded domain with no-slip boundary condition on the velocity field and the perfect insulating condition on the magnetic field. The controls are distributed in an arbitrarily small nonempty open subset and act only on the velocity field. In this situation, the divergence free condition for the magnetic field can be inherited from the initial value. With this condition, we transform the magnetohydrodynamic system into a coupled system between the Navier-Stokes equations and a scalar equation. Our proof relies on a new Carleman inequality for two kinds of boundary conditions.},
  archive      = {J_JDE},
  author       = {Qiang Tao and Zheng-an Yao and Xuan Yin},
  doi          = {10.1016/j.jde.2025.113237},
  journal      = {Journal of Differential Equations},
  month        = {7},
  pages        = {113237},
  shortjournal = {J. Diff. Equ.},
  title        = {Local exact controllability to the trajectories for the two-dimensional magnetohydrodynamic system with controls acting only on the velocity field},
  volume       = {433},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Shifts on trees versus classical shifts in chain recurrence.
<em>JDE</em>, <em>433</em>, 113230. (<a
href="https://doi.org/10.1016/j.jde.2025.113230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We construct continuous (and even invertible) linear operators acting on Banach (even Hilbert) spaces whose restrictions to their respective closed linear subspaces of chain recurrent vectors are not chain recurrent operators. This construction completely solves in the negative a problem posed by Nilson C. Bernardes Jr. and Alfred Peris on chain recurrence in Linear Dynamics. In particular: we show that the non-invertible case can be directly solved via relatively simple weighted backward shifts acting on certain unrooted directed trees; then we modify the non-invertible counterexample to address the invertible case, but falling outside the class of weighted shift operators; and we finally show that this behaviour cannot be achieved via classical (unilateral neither bilateral) weighted backward sifts (acting on N and Z respectively) by noticing that a classical shift is a chain recurrent operator as soon as it admits a non-zero chain recurrent vector.},
  archive      = {J_JDE},
  author       = {Antoni López-Martínez and Dimitris Papathanasiou},
  doi          = {10.1016/j.jde.2025.113230},
  journal      = {Journal of Differential Equations},
  month        = {7},
  pages        = {113230},
  shortjournal = {J. Diff. Equ.},
  title        = {Shifts on trees versus classical shifts in chain recurrence},
  volume       = {433},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Threshold dynamics for a class of time-delayed nonlocal
dispersal equations with a shifting habitat. <em>JDE</em>, <em>433</em>,
113228. (<a href="https://doi.org/10.1016/j.jde.2025.113228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to the study of the threshold dynamics for a class of time-delayed nonlocal dispersal equations with a shifting habitat which is suitable for survival only in bounded regions. We first establish the asymptotic annihilation of solutions under several appropriate assumptions. In order to avoid the tedious asymptotic spectral radius analysis of the solution map without compactness, we then transform the issues corresponding to forced wave for the original system into a fixed point problem of traveling wave map. Notably, such traveling wave map possesses compactness, enabling us to establish the existence and uniqueness of fixed points in terms of asymptotic spectral radius. Finally, these, together with the theory of asymptotic spectral radius again, yield the threshold dynamics of the original system.},
  archive      = {J_JDE},
  author       = {Jing Chen and Leyi Jiang and Taishan Yi},
  doi          = {10.1016/j.jde.2025.113228},
  journal      = {Journal of Differential Equations},
  month        = {7},
  pages        = {113228},
  shortjournal = {J. Diff. Equ.},
  title        = {Threshold dynamics for a class of time-delayed nonlocal dispersal equations with a shifting habitat},
  volume       = {433},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Persistence of a class of degenerate hyperbolic lower
dimensional invariant tori in hamiltonian systems. <em>JDE</em>,
<em>433</em>, 113227. (<a
href="https://doi.org/10.1016/j.jde.2025.113227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proves the persistence of degenerate hyperbolic lower dimensional invariant tori under small perturbations. The result is an extension of that in [41] to multiple dimensional case. The proof is based on the KAM technique with external parameters as counter terms and the theory of Brouwer degree.},
  archive      = {J_JDE},
  author       = {Qi Li and Junxiang Xu},
  doi          = {10.1016/j.jde.2025.113227},
  journal      = {Journal of Differential Equations},
  month        = {7},
  pages        = {113227},
  shortjournal = {J. Diff. Equ.},
  title        = {Persistence of a class of degenerate hyperbolic lower dimensional invariant tori in hamiltonian systems},
  volume       = {433},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global well-posedness and scattering of the two dimensional
cubic focusing nonlinear schrödinger system. <em>JDE</em>, <em>433</em>,
113225. (<a href="https://doi.org/10.1016/j.jde.2025.113225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we prove the global well-posedness (GWP) and scattering of the cubic focusing infinitely coupled nonlinear Schrödinger system (NLSS) on R 2 below the ground state in L x 2 h 1 ( R 2 × Z ) . We first establish the variational characterization of the ground state and derive the threshold for global well-posedness and scattering. We then demonstrate the global well-posedness and scattering below the threshold using the concentration-compactness/rigidity method. The almost periodic solution is excluded by adapting the argument used in the proof of the focusing mass-critical nonlinear Schrödinger equations (NLS) by B. Dodson. As a byproduct of the scattering of the cubic focusing infinitely coupled nonlinear Schrödinger system, we obtain the scattering of the cubic focusing nonlinear Schrödinger equation on the small cylinder. We also show the global well-posedness and scattering of the two dimensional N -coupled focusing cubic nonlinear Schrödinger system in ( L 2 ( R 2 ) ) N .},
  archive      = {J_JDE},
  author       = {Xing Cheng and Zihua Guo and Gyeongha Hwang and Haewon Yoon},
  doi          = {10.1016/j.jde.2025.113225},
  journal      = {Journal of Differential Equations},
  month        = {7},
  pages        = {113225},
  shortjournal = {J. Diff. Equ.},
  title        = {Global well-posedness and scattering of the two dimensional cubic focusing nonlinear schrödinger system},
  volume       = {433},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global well-posedness for the hydrostatic oldroyd-b model.
<em>JDE</em>, <em>433</em>, 113224. (<a
href="https://doi.org/10.1016/j.jde.2025.113224">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Oldroyd-B model plays an important role in the viscoelastic flows. In this paper, we study the Oldroyd-B model in a strip domain R × T . We first derive the hydrostatic approximate system for the Oldroyd-B model and then we prove the global well-posedness of this limit system with small analytic data in horizontal variable. Finally, we justify the limit from the re-scaled Oldroyd-B model to the hydrostatic Oldroyd-B model.},
  archive      = {J_JDE},
  author       = {Marius Paicu and Tianyuan Yu and Ning Zhu},
  doi          = {10.1016/j.jde.2025.113224},
  journal      = {Journal of Differential Equations},
  month        = {7},
  pages        = {113224},
  shortjournal = {J. Diff. Equ.},
  title        = {Global well-posedness for the hydrostatic oldroyd-B model},
  volume       = {433},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Growth of sobolev norms for completely resonant quantum
harmonic oscillators on r2. <em>JDE</em>, <em>433</em>, 113221. (<a
href="https://doi.org/10.1016/j.jde.2025.113221">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider time dependently perturbed quantum harmonic oscillators in R 2 : i ∂ t u = 1 2 ( − ∂ x 1 2 − ∂ x 2 2 + x 1 2 + x 2 2 ) u + V ( t , x , D ) u , x ∈ R 2 , where V ( t , x , D ) is a selfadjoint pseudodifferential operator of degree zero, 2 π periodic in time. We identify sufficient conditions on the principal symbol of the potential V ( t , x , D ) that ensure existence of solutions exhibiting unbounded growth in time of their positive Sobolev norms and we show that the class of symbols satisfying such conditions is generic in the Fréchet space of classical 2 π -time periodic symbols of order zero. To prove our result we apply the abstract Theorem of [46] : the main difficulty is to find a conjugate operator A for the resonant average of V ( t , x , D ) . We construct explicitly the symbol of the conjugate operator A , called escape function, combining techniques from microlocal analysis, dynamical systems and contact topology.},
  archive      = {J_JDE},
  author       = {Beatrice Langella and Alberto Maspero and Maria Teresa Rotolo},
  doi          = {10.1016/j.jde.2025.113221},
  journal      = {Journal of Differential Equations},
  month        = {7},
  pages        = {113221},
  shortjournal = {J. Diff. Equ.},
  title        = {Growth of sobolev norms for completely resonant quantum harmonic oscillators on r2},
  volume       = {433},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transmission problems for simply connected domains in the
complex plane. <em>JDE</em>, <em>433</em>, 113216. (<a
href="https://doi.org/10.1016/j.jde.2025.113216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study existence and uniqueness of a transmission problem in simply connected domains in the plane with data in weighted Lebesgue spaces by first investigating solvability results of a related novel problem associated to a homeomorphism in the real line and domains given by the upper and lower half planes. Our techniques are based on the use of conformal maps and Rellich identities for the Hilbert transform, and are motivated by previous works concerning the Dirichlet, Neumann and Zaremba problems.},
  archive      = {J_JDE},
  author       = {María J. Carro and Virginia Naibo and María Soria-Carro},
  doi          = {10.1016/j.jde.2025.113216},
  journal      = {Journal of Differential Equations},
  month        = {7},
  pages        = {113216},
  shortjournal = {J. Diff. Equ.},
  title        = {Transmission problems for simply connected domains in the complex plane},
  volume       = {433},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global existence and optimal time decay rate to
one-dimensional two-phase flow model. <em>JDE</em>, <em>433</em>,
113210. (<a href="https://doi.org/10.1016/j.jde.2025.02.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the global existence and optimal time decay rate of solution to the one dimensional (1D) two-phase flow described by compressible Euler equations coupled with compressible Navier-Stokes equations through the relaxation drag force on the momentum equations (Euler-Navier-Stokes system). First, we prove the global existence of strong solution and the stability of the constant equilibrium state to 1D Cauchy problem of compressible Euler-Navier-Stokes system by using the standard continuity argument for small H 1 data while their second order derivative can be large. Then we derive the optimal time decay rate to the constant equilibrium state. Compared with multi-dimensional case, it is much harder to get optimal time decay rate by direct spectrum method due to a slower convergence rate of the fundamental solution in 1D case. To overcome this main difficulty, we need to first carry out time-weighted energy estimates (not optimal) for higher order derivatives, and based on these time-weighted estimates, we can close a priori assumptions and get the optimal time decay rate by spectrum analysis method. Moreover, due to non-conserved form and insufficient decay rate of the coupled drag force terms between the two-phase flows, we essentially need to use momentum variables ( m = ρ u , M = n ω ) , rather than velocity variables ( u , ω ) in the spectrum analysis, to fully cancel out those non-conserved and insufficient time decay drag force terms.},
  archive      = {J_JDE},
  author       = {Xushan Huang and Yi Wang},
  doi          = {10.1016/j.jde.2025.02.081},
  journal      = {Journal of Differential Equations},
  month        = {7},
  pages        = {113210},
  shortjournal = {J. Diff. Equ.},
  title        = {Global existence and optimal time decay rate to one-dimensional two-phase flow model},
  volume       = {433},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Similarity between two distributed parameter systems.
<em>JDE</em>, <em>432</em>, 113218. (<a
href="https://doi.org/10.1016/j.jde.2025.113218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The relationship between two distributed parameter systems can be linked by a homeomorphic mapping, and the core is to study the minimizer of the functional to measure the degree of their similarity. We prove the existence and the necessary conditions (a maximum principle) for the minimizer. The similarity degree between two distributed parameter systems is thus defined by the functional, which extends the conjugacy in dynamical systems. As applications, we consider parabolic systems that satisfy different similarities. We prove a Hartman-Grobman theorem for general parabolic systems. We also demonstrate asymptotic similarity for the general quasilinear parabolic systems, indicating the Clausius statement of the second law of thermodynamics.},
  archive      = {J_JDE},
  author       = {Xiaoying Wang and Yong Li and Shuguan Ji},
  doi          = {10.1016/j.jde.2025.113218},
  journal      = {Journal of Differential Equations},
  month        = {7},
  pages        = {113218},
  shortjournal = {J. Diff. Equ.},
  title        = {Similarity between two distributed parameter systems},
  volume       = {432},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Existence, multiplicity and classification results for
solutions to k-hessian equations with general weights. <em>JDE</em>,
<em>432</em>, 113214. (<a
href="https://doi.org/10.1016/j.jde.2025.02.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present paper is concerned with negative classical solutions to a k -Hessian equation involving a nonlinearity with a general weight ( P ) { S k ( D 2 u ) = λ ρ ( | x | ) ( 1 − u ) q in B , u = 0 on ∂ B . Here, B denotes the unit ball in R n , n &gt; 2 k , λ is a positive parameter and q &gt; k with k ∈ N . The function r ρ ′ ( r ) / ρ ( r ) satisfies very general conditions in the radial direction r = | x | . We show the existence, nonexistence, and multiplicity of solutions to Problem ( P ) . The main technique used for the proofs is a phase-plane analysis related to a non-autonomous dynamical system associated to the equation in ( P ) . Further, using the aforementioned non-autonomous system, we give a comprehensive characterization of P 2 -, P 3 + -, P 4 + -solutions to the related problem ( P ˆ ) { S k ( D 2 w ) = ρ ( | x | ) ( − w ) q , w &lt; 0 , given on the entire space R n . In particular, we describe new classes of solutions: fast decay P 3 + -solutions and P 4 + -solutions.}}},
  archive      = {J_JDE},
  author       = {João Marcos do Ó and Justino Sánchez and Evelina Shamarova},
  doi          = {10.1016/j.jde.2025.02.085},
  journal      = {Journal of Differential Equations},
  month        = {7},
  pages        = {113214},
  shortjournal = {J. Diff. Equ.},
  title        = {Existence, multiplicity and classification results for solutions to k-hessian equations with general weights},
  volume       = {432},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Existence and regularity results for the penalized thin
obstacle problem with variable coefficients. <em>JDE</em>, <em>432</em>,
113213. (<a href="https://doi.org/10.1016/j.jde.2025.02.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we give a comprehensive treatment of a two-penalty boundary obstacle problem for a divergence form elliptic operator, motivated by applications to fluid dynamics and thermics. Specifically, we prove existence, uniqueness and optimal regularity of solutions, and establish structural properties of the free boundary. The proofs are based on tailor-made monotonicity formulas of Almgren, Weiss, and Monneau-type, combined with the classical theory of oblique derivative problems.},
  archive      = {J_JDE},
  author       = {Donatella Danielli and Brian Krummel},
  doi          = {10.1016/j.jde.2025.02.084},
  journal      = {Journal of Differential Equations},
  month        = {7},
  pages        = {113213},
  shortjournal = {J. Diff. Equ.},
  title        = {Existence and regularity results for the penalized thin obstacle problem with variable coefficients},
  volume       = {432},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Singularity analysis of a semilinear bernoulli-type free
boundary problem near the stagnation point. <em>JDE</em>, <em>432</em>,
113208. (<a href="https://doi.org/10.1016/j.jde.2025.02.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a thorough singularity analysis of Bernoulli-type free boundary problem for semilinear elliptic equation, with a particular emphasis on the asymptotic behavior near stagnation points where the gradient of solution vanishes. The findings, derived from variational and weak solutions, rely on the monotonicity formula to construct the blow-up limit, thereby identifying that the possible singular profiles near stagnation points are constrained to corner, cusp, or flat singularity. Additionally, the application of frequency formula eliminates the possibility of flat singularity. Through a further symbol limitation at the right hand side of equation, we show that cusp singularity is impossible. The only admissible singular profile is a corner, whose angle depends on the decay rate of the solution near the stagnation point.},
  archive      = {J_JDE},
  author       = {Yang Pu},
  doi          = {10.1016/j.jde.2025.02.079},
  journal      = {Journal of Differential Equations},
  month        = {7},
  pages        = {113208},
  shortjournal = {J. Diff. Equ.},
  title        = {Singularity analysis of a semilinear bernoulli-type free boundary problem near the stagnation point},
  volume       = {432},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Partial regularity for degenerate systems of double phase
type. <em>JDE</em>, <em>432</em>, 113207. (<a
href="https://doi.org/10.1016/j.jde.2025.02.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study partial regularity for degenerate elliptic systems of double-phase type, where the growth function is given by H ( x , t ) = t p + a ( x ) t q with 1 &lt; p ≤ q and a ( x ) a nonnegative C 0 , α -continuous function. Our main result proves that if q p ≤ 1 + α n , the gradient of any weak solution is locally Hölder continuous, except on a set of measure zero.},
  archive      = {J_JDE},
  author       = {Jihoon Ok and Giovanni Scilla and Bianca Stroffolini},
  doi          = {10.1016/j.jde.2025.02.078},
  journal      = {Journal of Differential Equations},
  month        = {7},
  pages        = {113207},
  shortjournal = {J. Diff. Equ.},
  title        = {Partial regularity for degenerate systems of double phase type},
  volume       = {432},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jmaa---44">JMAA - 44</h2>
<ul>
<li><details>
<summary>
(2025). Composition of locally solid convergences. <em>JMAA</em>,
<em>549</em>(2), 129511. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We carry on a more detailed investigation of the composition of locally solid convergences as introduced in [6] , as well as the corresponding notion of idempotency considered in [4] . In particular, we study the interactions between these two concepts and various operations with convergences. We prove associativity of the composition and show that the adherence of an ideal with respect to an idempotent convergence is equal to its closure. Some results from [12] about unbounded modification of locally solid topologies are generalized to the level of locally solid idempotent convergences. A simple application of the composition allows us to answer a question from [6] about minimal Hausdorff locally solid convergences. We also show that the weakest Hausdorff locally solid convergence exists on an Archimedean vector lattice if and only if it is atomic.},
  archive      = {J_JMAA},
  author       = {Eugene Bilokopytov},
  doi          = {10.1016/j.jmaa.2025.129511},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129511},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Composition of locally solid convergences},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-dimensional schrödinger operators with non-local
singular potentials. <em>JMAA</em>, <em>549</em>(2), 129498. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129498">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we introduce and study a family of self-adjoint realizations of the Laplacian in L 2 ( R 2 ) with a new type of transmission conditions along a closed bi-Lipschitz curve Σ. These conditions incorporate jumps in the Dirichlet traces both of the functions in the operator domains and of their Wirtinger derivatives and are non-local. Constructing a convenient generalized boundary triple, they may be parametrized by all compact self-adjoint operators in L 2 ( Σ ; C 2 ) . Whereas for all choices of parameters the essential spectrum is stable and equal to [ 0 , + ∞ ) , the discrete spectrum exhibits diverse behavior. While in many cases it is finite, we will describe also a class of parameters for which the discrete spectrum is infinite and accumulates at −∞. The latter class contains a non-local version of the oblique transmission conditions. Finally, we will connect the current model to its relativistic counterpart studied recently in [33] .},
  archive      = {J_JMAA},
  author       = {Lukáš Heriban and Markus Holzmann and Christian Stelzer-Landauer and Georg Stenzel and Matěj Tušek},
  doi          = {10.1016/j.jmaa.2025.129498},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129498},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Two-dimensional schrödinger operators with non-local singular potentials},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dirac structure for linear dynamical systems on sobolev
spaces. <em>JMAA</em>, <em>549</em>(2), 129493. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The port-Hamiltonian structure of linear dynamical systems is defined by a Dirac structure. In this paper we prove existence and well-posedness of a Dirac structure for linear dynamical systems on Sobolev spaces of differential forms on a bounded, connected and oriented manifold with Lipschitz continuous boundary. This result extends the proof of a Dirac structure for linear dynamical systems originally defined on smooth differential forms to a much larger class of function spaces, which is of theoretical importance and provides a solid basis for the numerical discretization of many linear port-Hamiltonian dynamical systems.},
  archive      = {J_JMAA},
  author       = {N. Kumar and H.J. Zwart and J.J.W. van der Vegt},
  doi          = {10.1016/j.jmaa.2025.129493},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129493},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Dirac structure for linear dynamical systems on sobolev spaces},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An alternate proof for the global mean speed of bistable
transition fronts. <em>JMAA</em>, <em>549</em>(2), 129492. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129492">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present an alternate proof to show the existence and uniqueness of the global mean speed of bistable transition fronts under a general framework.},
  archive      = {J_JMAA},
  author       = {Linlin Li and Hong Xu and Zhi-Cheng Wang},
  doi          = {10.1016/j.jmaa.2025.129492},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129492},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {An alternate proof for the global mean speed of bistable transition fronts},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). (P,q)-sobolev inequality and nash inequality on compact
finsler metric measure manifolds. <em>JMAA</em>, <em>549</em>(2),
129491. (<a href="https://doi.org/10.1016/j.jmaa.2025.129491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we carry out in-depth research centering around the ( p , q ) -Sobolev inequality and Nash inequality on compact Finsler metric measure manifolds under the condition that Ric ∞ ≥ − K for some K ≥ 0 . We first obtain a global p -Poincaré inequality on complete Finsler manifolds. Based on this, we can derive a ( p , q ) -Sobolev inequality. Furthermore, we establish a global optimal ( p , q ) -Sobolev inequality. Finally, as an application of the p -Poincaré inequality, we prove a Nash inequality.},
  archive      = {J_JMAA},
  author       = {Xinyue Cheng and Qihui Ni},
  doi          = {10.1016/j.jmaa.2025.129491},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129491},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {(p,q)-sobolev inequality and nash inequality on compact finsler metric measure manifolds},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Null controllability for cascade systems of coupled backward
stochastic parabolic equations with one distributed control.
<em>JMAA</em>, <em>549</em>(2), 129489. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove the null controllability of a cascade system of n coupled backward stochastic parabolic equations, which involve both reaction and convection terms, as well as general second-order parabolic operators, with n ≥ 2 . To achieve this, we apply a single distributed control to the first equation, while the other equations are controlled through the coupling. To obtain our results, we develop a new global Carleman estimate for the forward stochastic parabolic adjoint system, with some terms in the H − 1 -space. Subsequently, we derive the corresponding observability inequality, and using the classical duality argument, we establish our null controllability result. Additionally, we provide an accurate estimate for the null control cost in terms of the final time T and the potentials of the system.},
  archive      = {J_JMAA},
  author       = {Said Boulite and Abdellatif Elgrou and Lahcen Maniar},
  doi          = {10.1016/j.jmaa.2025.129489},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129489},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Null controllability for cascade systems of coupled backward stochastic parabolic equations with one distributed control},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spherically symmetric strong solution of compressible flow
with large data and density-dependent viscosities. <em>JMAA</em>,
<em>549</em>(2), 129488. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the isentropic compressible Navier-Stokes equations with density-dependent viscosities μ ( ρ ) = ρ α , λ ( ρ ) = ( α − 1 ) ρ α in N -dimensional ( N = 2 , 3 ) bounded domain when the initial data are spherically symmetric. Based on the exploitation of the one-dimensional and non-swirl feature of symmetric solution, together with the BD-entropy estimates, the global well-posedness of strong solution with the symmetry center is proved for non-vacuum and large initial data as N = 2 , 4 5 ≤ α &lt; 1 , 1 &lt; γ or N = 3 , 7 8 ≤ α &lt; 1 , 1 &lt; γ &lt; 9 α − 6 . In particular, it is shown that the solution will not develop the vacuum states in any finite time provided that no vacuum states are present initially.},
  archive      = {J_JMAA},
  author       = {Xueyao Zhang},
  doi          = {10.1016/j.jmaa.2025.129488},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129488},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Spherically symmetric strong solution of compressible flow with large data and density-dependent viscosities},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Upper bounds for the blow-up time of the 2-d
parabolic-elliptic patlak-keller-segel model of chemotaxis.
<em>JMAA</em>, <em>549</em>(2), 129487. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we obtain upper bounds for the critical time T ⁎ of the blow-up for the parabolic-elliptic Patlak-Keller-Segel system on the 2D-Euclidean space. No moment condition or/and entropy condition are required on the initial data; only the usual assumptions of non-negativity and finiteness of the total mass is assumed. The result is expressed not only in terms of supercritical mass M &gt; 8 π , but also in terms of the shape of the initial data.},
  archive      = {J_JMAA},
  author       = {Patrick Maheux},
  doi          = {10.1016/j.jmaa.2025.129487},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129487},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Upper bounds for the blow-up time of the 2-d parabolic-elliptic patlak-keller-segel model of chemotaxis},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Polynomial growth and functional calculus in algebras of
integrable cross-sections. <em>JMAA</em>, <em>549</em>(2), 129486. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let G be a locally compact group with polynomial growth of order d , a polynomial weight ν on G and a Fell bundle C → q G . We study the Banach ⁎ -algebras L 1 ( G | C ) and L 1 , ν ( G | C ) , consisting of integrable cross-sections with respect to d x and ν ( x ) d x , respectively. By exploring new relations between the L p -norms and the norm of the Hilbert C ⁎ -module L e 2 ( G | C ) , we are able to show that the growth of the self-adjoint, compactly supported, continuous cross-sections is polynomial. More precisely, they satisfy ‖ e i t Φ ‖ = O ( | t | n ) , as | t | → ∞ , for values of n that only depend on d and the weight ν . We use this fact to develop a smooth functional calculus for such elements. We also give some sufficient conditions for these algebras to be symmetric. As consequences, we show that these algebras are locally regular, ⁎ -regular and have the Wiener property (when symmetric), among other results. Our results are already new for convolution algebras associated with C ⁎ -dynamical systems.},
  archive      = {J_JMAA},
  author       = {Felipe I. Flores},
  doi          = {10.1016/j.jmaa.2025.129486},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129486},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Polynomial growth and functional calculus in algebras of integrable cross-sections},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the existence of eigenvalues of a one-dimensional dirac
operator. <em>JMAA</em>, <em>549</em>(2), 129485. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is to study the existence of eigenvalues in the gap of the essential spectrum of the one-dimensional Dirac operator in the presence of a bounded potential. We employ a generalized variational principle to prove existence of such eigenvalues, estimate how many eigenvalues there are, and give upper and lower bounds for them.},
  archive      = {J_JMAA},
  author       = {Daniel Sánchez-Mendoza and Monika Winklmeier},
  doi          = {10.1016/j.jmaa.2025.129485},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129485},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {On the existence of eigenvalues of a one-dimensional dirac operator},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On elliptic equations with unbounded or decaying potentials
involving stein-weiss convolution parts and critical exponential growth.
<em>JMAA</em>, <em>549</em>(2), 129483. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a class of nonlinear Schrödinger equations with Stein-Weiss convolution parts − Δ u + V ( x ) u = ( ∫ R 2 F ( u ) | x − y | μ | | y | β d y ) f ( u ) | x | β , x ∈ R 2 , where V is an unbounded or decaying potential, β &gt; 0 , μ &gt; 0 with 0 &lt; 2 β + μ &lt; 2 , and F denotes the primitive of f that fulfills the critical exponential growth in the Trudinger-Moser sense at infinity. Via establishing a new version of the Trudinger-Moser inequality, we shall exploit the general minimax principle to demonstrate the existence of nontrivial solutions using variational method.},
  archive      = {J_JMAA},
  author       = {Claudianor Oliveira Alves and Manassés de Souza and Liejun Shen},
  doi          = {10.1016/j.jmaa.2025.129483},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129483},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {On elliptic equations with unbounded or decaying potentials involving stein-weiss convolution parts and critical exponential growth},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A (μ,ν)-dichotomy spectrum. <em>JMAA</em>, <em>549</em>(2),
129482. (<a href="https://doi.org/10.1016/j.jmaa.2025.129482">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we introduce three notions of dichotomy spectrum based on general growth rates and describe their structure. Our results are applicable to nonautonomous linear systems acting on general Banach spaces having negative μ -index of compactness, a condition which is satisfied, for instance, by any sequence of compact operators. Moreover, for any possible form of the spectra, we present an explicit example exhibiting such spectrum. Furthermore, as an application, we obtain normal forms of certain nonautonomous systems. We emphasize that the classical Sacker-Sell spectrum can be obtained as a very particular case of our setting.},
  archive      = {J_JMAA},
  author       = {Lucas Backes},
  doi          = {10.1016/j.jmaa.2025.129482},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129482},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {A (μ,ν)-dichotomy spectrum},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The fueter mittag-leffler bargmann transform. <em>JMAA</em>,
<em>549</em>(2), 129480. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we continue exploring the Mittag-Leffler Bargmann (MLB) transform, which maps the Hilbert space L 2 ( R ) onto the Mittag-Leffler-Fock (MLF) space. The MLF space is a reproducing kernel Hilbert space that extends the classic Fock space and its reproducing kernel is given by the Mittag-Leffler function. We study the MLB transform and its main properties in the quaternionic setting. In this noncommutative setting there are two function theories that are prominent: the slice hyperholomorphic theory and the Fueter regular theory. The connection between the slice hyperholomorphic functions and the Fueter regular functions is given by the Fueter mapping theorem. The Mittag-Leffler Bargmann transform investigated in this paper maps the quaternionic-valued L 2 ( R , H ) space onto a counterpart of the MLF space in the Fueter regular setting. Finally the creation, annihilation, backward-shift and integration operators are studied in the case of the Fueter-MLF space.},
  archive      = {J_JMAA},
  author       = {Natanael Alpay and Antonino De Martino and Kamal Diki},
  doi          = {10.1016/j.jmaa.2025.129480},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129480},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {The fueter mittag-leffler bargmann transform},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergence at infinity for solutions of nonhomogeneous
degenerate and singular elliptic equations in exterior domains.
<em>JMAA</em>, <em>549</em>(2), 129476. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we investigate the existence of the limit at infinity of weak solutions of the nonhomogeneous equation − div ( | ∇ u | p − 2 A ( | ∇ u | ) ∇ u ) = f in the exterior domain R n ﹨ K , where K ⊂ R n is a compact set. Indeed, for any p ∈ ( 1 , + ∞ ) and n ≥ 2 , we prove that the solutions converge at infinity if A satisfies some growth conditions and f ∈ L ∞ ( R n ) has some decay property. Moreover, for p &gt; n we can show that the solutions converge at some rate and, for p &lt; n , the convergence holds even for some unbounded f . In addition, for p &gt; n , we show that for any continuous function ϕ defined on ∂ K , the problem { − div ( | ∇ u | p − 2 A ( | ∇ u | ) ∇ u ) = f in R n ﹨ K u = ϕ , on ∂ K has a bounded weak solution in C ( R n ﹨ K ‾ ) ∩ C 1 ( R n ﹨ K ) , provided A and f are suitable. Furthermore, if ϕ ∈ C α ( K ) , then this solution is in C α ( R n ) .}},
  archive      = {J_JMAA},
  author       = {Leonardo P. Bonorino and Lucas P. Dutra and Filipe J. dos Santos},
  doi          = {10.1016/j.jmaa.2025.129476},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129476},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Convergence at infinity for solutions of nonhomogeneous degenerate and singular elliptic equations in exterior domains},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Local and global properties of spaces of minimal usco maps.
<em>JMAA</em>, <em>549</em>(2), 129472. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129472">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study an interplay between local and global properties of spaces of minimal usco maps equipped with the topology of uniform convergence on compact sets. In particular, for each locally compact space X and metric space Y , we characterize the space of minimal usco maps from X to Y , satisfying one of the following properties: (i) compact, (ii) locally compact, (iii) σ -compact, (iv) locally σ -compact, (v) metrizable, (vi) ccc, (vii) locally ccc, where in the last two items we additionally assumed that Y is separable and non-discrete. Some of the aforementioned results complement ones of Ľubica Holá and Dušan Holý. Also, we obtain analogous characterizations for spaces of minimal cusco maps.},
  archive      = {J_JMAA},
  author       = {Serhii Bardyla and Branislav Novotný and Jaroslav Šupina},
  doi          = {10.1016/j.jmaa.2025.129472},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129472},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Local and global properties of spaces of minimal usco maps},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Local existence and uniqueness of classical solutions for a
compressible oldroyd-b model with vacuum. <em>JMAA</em>,
<em>549</em>(2), 129450. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider compressible Oldroyd-B equations in a bounded or unbounded domain Ω of R 3 . Assuming that the initial data satisfy a natural compatibility condition, we show the local existence and uniqueness of the classical solutions for Oldroyd-B equations through some high-order estimations with respect to time weighting. To obtain the result, the initial density does not need to differ from zero and may vanish in an open subset (vacuum) of Ω or decay at infinity when Ω is unbounded.},
  archive      = {J_JMAA},
  author       = {Yubi Yin and Xingyang Zhang},
  doi          = {10.1016/j.jmaa.2025.129450},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129450},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Local existence and uniqueness of classical solutions for a compressible oldroyd-B model with vacuum},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Asymptotics for k-crank of k-colored partitions.
<em>JMAA</em>, <em>549</em>(2), 129447. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we obtain asymptotic formulas for the k -crank of k -colored partitions. Let M k ( a , c ; n ) denote the number of k -colored partitions of n with a k -crank congruent to a mod c . For the cases k = 2 , 3 , 4 , Fu and Tang derived several inequality relations for M k ( a , c ; n ) using generating functions. We employ the Hardy-Ramanujan Circle Method to extend the results of Fu and Tang. Furthermore, strict log-subadditivity for M k ( a , c ; n ) is established.},
  archive      = {J_JMAA},
  author       = {Helen W.J. Zhang and Ying Zhong},
  doi          = {10.1016/j.jmaa.2025.129447},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129447},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Asymptotics for k-crank of k-colored partitions},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Admissibility and generalized nonuniform dichotomies for
nonautonomous random dynamical systems. <em>JMAA</em>, <em>549</em>(2),
129441. (<a href="https://doi.org/10.1016/j.jmaa.2025.129441">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce generalized dichotomies for nonautonomous random linear dynamical systems acting on arbitrary Banach spaces, and obtain their complete characterization in terms of an appropriate admissibility property. These generalized dichotomies are associated to growth rates satisfying mild conditions and they include the standard exponential behavior as a very particular case. As a nontrivial application, we establish the robustness property of such dichotomies under small (linear) perturbations.},
  archive      = {J_JMAA},
  author       = {Davor Dragičević and César M. Silva and Helder Vilarinho},
  doi          = {10.1016/j.jmaa.2025.129441},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129441},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Admissibility and generalized nonuniform dichotomies for nonautonomous random dynamical systems},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). About solutions for gradient-type cooperative systems beyond
extremal parameter. <em>JMAA</em>, <em>549</em>(2), 129436. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the existence and non-existence of solutions for cooperative elliptic gradient-type systems, depending on the real parameters λ and μ . Our approach, based on a refined analysis of the Nehari manifold associated with the problem, allows us to establish the existence and multiplicity of solutions by minimizing the associated energy functional over components of the Nehari set for parameters beyond the extremal parameter λ ⁎ ( μ ) .},
  archive      = {J_JMAA},
  author       = {Steffânio Moreno},
  doi          = {10.1016/j.jmaa.2025.129436},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129436},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {About solutions for gradient-type cooperative systems beyond extremal parameter},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Szegö’s inequality revisited. <em>JMAA</em>,
<em>549</em>(1), 129505. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By using an equality due to Feldheim between Hermite and Laguerre polynomials we give a very short proof of Szegö&#39;s inequality. In the process we obtained a better bound for the Laguerre polynomials.},
  archive      = {J_JMAA},
  author       = {Rui A.C. Ferreira},
  doi          = {10.1016/j.jmaa.2025.129505},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {1},
  pages        = {129505},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Szegö&#39;s inequality revisited},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An extension of petek-šemrl preserver theorems for jordan
embeddings of structural matrix algebras. <em>JMAA</em>,
<em>549</em>(1), 129497. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129497">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let M n be the algebra of n × n complex matrices and T n ⊆ M n the corresponding upper-triangular subalgebra. In their influential work, Petek and Šemrl characterize Jordan automorphisms of M n and T n , when n ≥ 3 , as (injective in the case of T n ) continuous commutativity and spectrum preserving maps ϕ : M n → M n and ϕ : T n → T n . Recently, in a joint work with Petek, the authors extended this characterization to the maps ϕ : A → M n , where A is an arbitrary subalgebra of M n that contains T n . In particular, any such map ϕ is a Jordan embedding and hence of the form ϕ ( X ) = T X T − 1 or ϕ ( X ) = T X t T − 1 , for some invertible matrix T ∈ M n . In this paper we further extend the aforementioned results in the context of structural matrix algebras (SMAs), i.e. subalgebras A of M n that contain all diagonal matrices. More precisely, we provide both a necessary and sufficient condition for an SMA A ⊆ M n such that any injective continuous commutativity and spectrum preserving map ϕ : A → M n is necessarily a Jordan embedding. In contrast to the previous cases, such maps ϕ no longer need to be multiplicative/antimultiplicative, nor rank-one preservers.},
  archive      = {J_JMAA},
  author       = {Ilja Gogić and Mateo Tomašević},
  doi          = {10.1016/j.jmaa.2025.129497},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {1},
  pages        = {129497},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {An extension of petek-Šemrl preserver theorems for jordan embeddings of structural matrix algebras},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The elliptic functions of dixon and du val. <em>JMAA</em>,
<em>549</em>(1), 129496. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129496">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We demonstrate and elaborate upon the very intimate relationship between the elliptic functions sm and cm of Dixon and the ternary elliptic functions of Du Val.},
  archive      = {J_JMAA},
  author       = {P.L. Robinson},
  doi          = {10.1016/j.jmaa.2025.129496},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {1},
  pages        = {129496},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {The elliptic functions of dixon and du val},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The cartesian product of shrinking target sets in dyadic
system and triadic system. <em>JMAA</em>, <em>549</em>(1), 129495. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the Cartesian product of shrinking target sets. Let f and g be two positive continuous functions. For any x 0 , y 0 ∈ [ 0 , 1 ] , we define the shrinking target sets as follows: E 2 ( f ) = { x ∈ [ 0 , 1 ] : | T 2 n x − x 0 | &lt; e − S n f ( x ) for infinitely many n ∈ N } , and E 3 ( g ) = { y ∈ [ 0 , 1 ] : | T 3 m y − y 0 | &lt; e − S ¯ m g ( y ) for infinitely many m ∈ N } , where S n f ( x ) = ∑ j = 0 n − 1 f ( T 2 j x ) and S ¯ m g ( y ) = ∑ j = 0 m − 1 g ( T 3 j y ) denote the Birkhoff ergodic sums, and T b x = b x ( mod 1 ) . The Hausdorff dimension of the Cartesian product set E 2 ( f ) × E 3 ( g ) is determined in this work.},
  archive      = {J_JMAA},
  author       = {Wanjin Cheng},
  doi          = {10.1016/j.jmaa.2025.129495},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {1},
  pages        = {129495},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {The cartesian product of shrinking target sets in dyadic system and triadic system},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New type solutions for a biharmonic hénon problem with
slightly subcritical sobolev exponent. <em>JMAA</em>, <em>549</em>(1),
129481. (<a href="https://doi.org/10.1016/j.jmaa.2025.129481">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the following biharmonic Hénon problem { Δ 2 u = K ( x ) | u | p − 1 − ϵ u in Ω , u = Δ u = 0 on ∂ Ω , where Ω is a bounded and smooth domain in R n with 6 ≤ n ≤ 12 , p = n + 4 n − 4 , and p + 1 = 2 n n − 4 denotes the critical Sobolev exponent for the embedding H 2 ( Ω ) ∩ H 0 1 ( Ω ) ↪ L p + 1 ( Ω ) . The parameter ϵ &gt; 0 is a small, and the function K ∈ C 2 ( Ω ¯ ) is positive and satisfies ∇ ( K ( ξ ⁎ ) − 2 p − 1 ) ⋅ η ( ξ ⁎ ) &gt; 0 , where ξ ⁎ ∈ ∂ Ω is a non-degenerate critical point of K which is restricted to the boundary of Ω, and η is the inner normal unit vector on ∂Ω. We establish the existence of a positive solution and a sign-changing solution with two bubbles concentrating at ξ ⁎ for the above problem.}},
  archive      = {J_JMAA},
  author       = {Wenjing Chen and Fang Yu},
  doi          = {10.1016/j.jmaa.2025.129481},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {1},
  pages        = {129481},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {New type solutions for a biharmonic hénon problem with slightly subcritical sobolev exponent},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Restricted slowly growing digits for infinite iterated
function systems. <em>JMAA</em>, <em>549</em>(1), 129478. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For an infinite iterated function system f on [ 0 , 1 ] with an attractor Λ ( f ) and for an infinite subset D ⊆ N , consider the set E ( f , D ) = { x ∈ Λ ( f ) : a n ( x ) ∈ D for all n ∈ N and lim n → ∞ ⁡ a n = ∞ } . For a function φ : N → [ min ⁡ D , ∞ ) such that φ ( n ) → ∞ as n → ∞ , we compute the Hausdorff dimension of the set S ( f , D , φ ) = { x ∈ E ( f , D ) : a n ( x ) ≤ φ ( n ) for all n ∈ N } . We prove that the Hausdorff dimension stays the same no matter how slowly the function φ grows. One of the consequences of our result is the recent work of Takahasi (2023), which only dealt with regular continued fraction expansions. We further extend our result to slowly growing products of (not necessarily consecutive) digits.},
  archive      = {J_JMAA},
  author       = {Gerardo González Robert and Mumtaz Hussain and Nikita Shulga and Hiroki Takahasi},
  doi          = {10.1016/j.jmaa.2025.129478},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {1},
  pages        = {129478},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Restricted slowly growing digits for infinite iterated function systems},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On algebras with locally convex topologies admitting arens
products in their second topological duals. <em>JMAA</em>,
<em>549</em>(1), 129477. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129477">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study algebras with locally convex topologies admitting Arens products in their second topological duals. We identify the exact conditions required for the existence of Arens products. We show that for algebras admitting Arens products in their second duals, the identity W A P ( A ) = A ⁎ is equivalent to Arens regularity (Pym&#39;s criterion). We show that on any infinite dimensional normed algebra ( A , ‖ ⋅ ‖ ) , there exist uncountably many locally convex topologies τ compatible with the duality 〈 A , A ⁎ 〉 , such that ( A , τ ) admits Arens products in its second topological dual. If ( A , ‖ ⋅ ‖ ) is Arens regular, strongly Arens irregular or extremely non-Arens regular, then there are uncountably many locally convex topologies τ on A for which ( A , τ ) has the same property.},
  archive      = {J_JMAA},
  author       = {M. Filali and M. Sangani Monfared},
  doi          = {10.1016/j.jmaa.2025.129477},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {1},
  pages        = {129477},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {On algebras with locally convex topologies admitting arens products in their second topological duals},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Normalized solutions for the mass supercritical kirchhoff
problem. <em>JMAA</em>, <em>549</em>(1), 129475. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present paper, we are concerned with the existence of normalized solutions for the Kirchhoff problem, where the nonlinear term exhibits some new weak mass supercritical conditions. By employing analytical techniques and critical point theorems, we establish several new existence results. Our main results improve and complement the works of He et al. [10] , Wang and Qian (2023) [22] and some other related literature.},
  archive      = {J_JMAA},
  author       = {Liu Gao and Zhong Tan},
  doi          = {10.1016/j.jmaa.2025.129475},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {1},
  pages        = {129475},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Normalized solutions for the mass supercritical kirchhoff problem},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semiclassical limit of a non-polynomial q-askey scheme.
<em>JMAA</em>, <em>549</em>(1), 129474. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129474">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove a semiclassical asymptotic formula for the two elements M and Q lying at the bottom of the recently constructed non-polynomial hyperbolic q -Askey scheme. We also prove that the corresponding exponent is a generating function of the canonical transformation between pairs of Darboux coordinates on the monodromy manifold of the Painlevé I and III 3 equations, respectively. Such pairs of coordinates characterize the asymptotics of the tau function of the corresponding Painlevé equation. We conjecture that the other members of the non-polynomial hyperbolic q -Askey scheme yield generating functions associated to the other Painlevé equations in the semiclassical limit.},
  archive      = {J_JMAA},
  author       = {Jonatan Lenells and Julien Roussillon},
  doi          = {10.1016/j.jmaa.2025.129474},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {1},
  pages        = {129474},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Semiclassical limit of a non-polynomial q-askey scheme},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boundedness and global existence in a higher-dimensional
parabolic-elliptic-ODE chemotaxis-haptotaxis model with remodeling of
non-diffusible attractant. <em>JMAA</em>, <em>549</em>(1), 129473. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the issue of boundedness for solutions to the following quasilinear chemotaxis-haptotaxis model of parabolic-elliptic-ODE type: { u t = Δ u − χ ∇ ⋅ ( u ∇ v ) − ξ ∇ ⋅ ( u ∇ w ) + u ( r − μ u γ − 1 − w ) , x ∈ Ω , t &gt; 0 , 0 = Δ v + u − v , x ∈ Ω , t &gt; 0 , w t = − v w + η w ( 1 − u − w ) , x ∈ Ω , t &gt; 0 , subject to zero-flux boundary conditions within a smooth, bounded domain Ω ⊂ R N (with N ≥ 3 ). The parameters involved are χ &gt; 0 , μ &gt; 0 , r ≥ 0 , and η &gt; 0 . It is demonstrated that, provided γ &gt; 3 − 2 N , for sufficiently smooth initial data, the corresponding initial-boundary problem admits a unique global-in-time classical solution, which remains uniformly bounded. To the best of our knowledge, these are the first results concerning the boundedness of solutions for this parabolic-elliptic-ODE system in higher dimensions.}},
  archive      = {J_JMAA},
  author       = {Ling Liu},
  doi          = {10.1016/j.jmaa.2025.129473},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {1},
  pages        = {129473},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Boundedness and global existence in a higher-dimensional parabolic-elliptic-ODE chemotaxis-haptotaxis model with remodeling of non-diffusible attractant},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large time behavior of a quasilinear two-species
attraction-repulsion chemotaxis system with two chemicals.
<em>JMAA</em>, <em>549</em>(1), 129471. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129471">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the quasilinear two-species attraction-repulsion chemotaxis system with two chemicals: u t = ∇ ⋅ ( D 1 ( u ) ∇ u ) − ∇ ⋅ ( Φ 1 ( u ) ∇ v ) + r 1 u − μ 1 u k 1 , 0 = Δ v − v + w , w t = ∇ ⋅ ( D 2 ( w ) ∇ w ) + ∇ ⋅ ( Φ 2 ( w ) ∇ z ) + r 2 w − μ 2 w k 2 , 0 = Δ z − z + u , subject to the homogeneous Neumann boundary conditions in a bounded domain Ω ⊂ R N ( N ≥ 2 ) with smooth boundary, where the parameters r i , μ i &gt; 0 , k i &gt; 1 and D i ( s ) = ( s + 1 ) p i , Φ i ( s ) = χ i s ( s + 1 ) q i − 1 with χ i &gt; 0 , p i , q i ∈ R , i = 1 , 2 . The interactions among the diffusion, attraction, repulsion, and logistic sources in the system determine the behavior of solutions. It is showed that when N &lt; 4 , as long as the diffusion mechanism of population w dominates with q 2 − p 2 &lt; 4 N , global boundedness of solutions can be guaranteed; if max ⁡ { q 1 , q 2 } ≤ min ⁡ { p 1 + 2 N , p 2 + 2 N } or max ⁡ { q 1 , q 2 } ≤ min ⁡ { k 1 − 1 , k 2 − 1 } , i.e. the diffusion mechanisms or the logistic source terms of populations u and w are both dominant, the solutions are globally bounded; when the diffusion mechanism of u (or w ) and the logistic source term of w (or u ) dominate with max ⁡ { q 1 , q 2 } ≤ min ⁡ { k 2 − 1 , p 1 + 2 N } (or max ⁡ { q 1 , q 2 } ≤ min ⁡ { k 1 − 1 , p 2 + 2 N } ), the solutions are globally bounded. Also, we have proved that when the logistic source term of either u or w dominates, the global boundedness of the solutions can be obtained. Moreover, we give the large time behavior of the globally bounded solutions.},
  archive      = {J_JMAA},
  author       = {Miaoqing Tian and Fuxin Yu and Xinchun Gao and Jiahui Hu},
  doi          = {10.1016/j.jmaa.2025.129471},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {1},
  pages        = {129471},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Large time behavior of a quasilinear two-species attraction-repulsion chemotaxis system with two chemicals},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Asymptotic expansions for the generalised trigonometric
integral and its zeros. <em>JMAA</em>, <em>549</em>(1), 129463. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129463">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the asymptotic properties of the generalised trigonometric integral ti ( a , z , α ) and its associated modulus and phase functions for large complex values of z . We derive asymptotic expansions for these functions, accompanied by explicit and computable error bounds. For real values of a , the function ti ( a , z , α ) possesses infinitely many positive real zeros. Assuming a &lt; 1 , we establish asymptotic expansions for the large zeros, accompanied by precise error estimates. The error bounds for the asymptotics of the phase function and its zeros will be derived by studying the analytic properties of both the phase function and its inverse. Additionally, we demonstrate that for real variables, the derived asymptotic expansions are enveloping, meaning that successive partial sums provide upper and lower bounds for the corresponding functions.},
  archive      = {J_JMAA},
  author       = {Gergő Nemes},
  doi          = {10.1016/j.jmaa.2025.129463},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {1},
  pages        = {129463},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Asymptotic expansions for the generalised trigonometric integral and its zeros},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Normalized solutions of a (2,p)-laplacian equation.
<em>JMAA</em>, <em>549</em>(1), 129462. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129462">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we are concerned with normalized solutions of a ( 2 , p ) -Laplacian equation with an L p constraint in R 3 , where 2 &lt; p &lt; 3 . Different from literature previous, we focus on the L p not L 2 constraint for p &gt; 2 . Moreover, an interesting finding is that the non-homogeneity driven by the operators Δ and Δ p has an important impact on L p constraint ( 2 , p ) -Laplacian equations, as reflected in the definition of the L p critical exponent, and the existence of normalized solutions in both L p subcritical and supercritical cases. All these new phenomena, which are different from those exhibited by a single p -Laplacian equation, reveal the essential characteristics of ( 2 , p ) -Laplacian equations.},
  archive      = {J_JMAA},
  author       = {Xiaoli Zhu and Yunli Zhao and Zhanping Liang},
  doi          = {10.1016/j.jmaa.2025.129462},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {1},
  pages        = {129462},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Normalized solutions of a (2,p)-laplacian equation},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Free boundary problem governed by a non-linear
diffusion-convection equation with neumann condition. <em>JMAA</em>,
<em>549</em>(1), 129461. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a one-dimensional free boundary problem governed by a nonlinear diffusion - convection equation with a Neumann condition at fixed face x = 0 , which is variable in time and a like Stefan convective condition on the free boundary. Through successive transformations, an integral representation of the problem is obtained that involves a system of coupled nonlinear integral equations. Existence of the solution is obtained for all times by using fixed point theorems.},
  archive      = {J_JMAA},
  author       = {Adriana C. Briozzo},
  doi          = {10.1016/j.jmaa.2025.129461},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {1},
  pages        = {129461},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Free boundary problem governed by a non-linear diffusion-convection equation with neumann condition},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamics and optimal control of an SIVR
immuno-epidemiological model with standard incidence. <em>JMAA</em>,
<em>549</em>(1), 129449. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129449">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on the immuno-epidemiological model concept, we propose a susceptible–infected–vaccinated–recovered epidemic model with between-host transmission and within-host infection, where disease transmission between hosts is described by a standard incidence rate and the within-host infection process is governed by a bilinear incidence rate. The basic reproduction number R 0 ( ψ ) in the between-host model strongly depends on the within-host infection process. If R 0 ( ψ ) &lt; 1 , the disease-free steady state E 0 of the between-host epidemic model is locally stable, and if R 0 ( ψ ) &gt; 1 , the endemic steady state E ⁎ of the between-host epidemic model is locally stable. If R 0 ( 0 ) &lt; 1 , the disease-free steady state E 0 of the between-host epidemic model is globally stable. Furthermore, to better understand the roles of within-host treatment and between-host control in disease transmission, we formulated and studied an optimal control problem for the immuno-epidemiological model involving treatment and vaccination. Numerical simulations were conducted to demonstrate the effectiveness of the control strategies in various infection processes. The results showed that the duration of within-host treatment must be longer than the duration of vaccination to better control the spread of the disease.},
  archive      = {J_JMAA},
  author       = {Xi-Chao Duan and Chenyu Zhu and Xue-Zhi Li and Eric Numfor and Maia Martcheva},
  doi          = {10.1016/j.jmaa.2025.129449},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {1},
  pages        = {129449},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Dynamics and optimal control of an SIVR immuno-epidemiological model with standard incidence},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysis of SIS infectious disease dynamics with linear
external sources and free boundaries: A computational and theoretical
perspective. <em>JMAA</em>, <em>549</em>(1), 129448. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spatio-temporal distribution of individuals within the SIS (Susceptible-Infected-Susceptible) model is pivotal for the effective prevention and control of infectious diseases. This study leverages the reaction-diffusion epidemic model to improve the accuracy of identifying infected areas and predicting potential outbreaks. Compression mapping and the standard theory of parabolic equations are applied to analyze the dynamics of susceptible individuals influenced by linear external sources, simulating their birth and death rates. Key findings reveal a dichotomous relationship between the spread and extinction of infectious diseases, dictated by the time-dependent basic reproduction number. Furthermore, the study investigates the impact of the diffusion coefficient, the propagation potential of infected individuals, and the initial infection range on disease dissemination or attenuation. Numerical simulations support the theoretical findings, indicating that a high expanding capacity of infected individuals poses challenges to effective disease prevention and control. This work provides novel insights into the spatio-temporal dynamics of the SIS model and lays a foundation for future research endeavours in this domain.},
  archive      = {J_JMAA},
  author       = {Yarong Zhang and Meng Hu and Jie Zheng and Xinyu Shi},
  doi          = {10.1016/j.jmaa.2025.129448},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {1},
  pages        = {129448},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Analysis of SIS infectious disease dynamics with linear external sources and free boundaries: A computational and theoretical perspective},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A remark on the weak harnack inequality. <em>JMAA</em>,
<em>549</em>(1), 129446. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A short proof of the weak Harnack inequality based on the critical-density and double-ball properties is presented. The proof relies on basic properties of Muckenhoupt weights in general spaces of homogenous type.},
  archive      = {J_JMAA},
  author       = {Diego Maldonado},
  doi          = {10.1016/j.jmaa.2025.129446},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {1},
  pages        = {129446},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {A remark on the weak harnack inequality},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Properties for transposition solutions to operator-valued
BSEEs, and applications to robust second order necessary conditions for
controlled SEEs. <em>JMAA</em>, <em>549</em>(1), 129445. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129445">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article is concerned with the second order necessary conditions for the stochastic optimal control problem of stochastic evolution equation with model uncertainty when the traditional Pontryagin-type maximum principle holds trivially and does not provide any information depicting the optimal control. The diffusion terms of the state equations are allowed to be control dependent with convex control constraints. Transposition method is adopted to deal with the adjoint operator-valued backward stochastic evolution equations, especially the correction terms. Besides, weak convergence arguments are used to obtain the optimal uncertainty reference measure, in which the regularities of the state processes, variational processes, and adjoint processes in the transposition sense are characterized. Malliavin calculus is applied to pave the way for differentiation theorem of Lebesgue type to deduce the pointwise robust optimality conditions.},
  archive      = {J_JMAA},
  author       = {Guangdong Jing},
  doi          = {10.1016/j.jmaa.2025.129445},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {1},
  pages        = {129445},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Properties for transposition solutions to operator-valued BSEEs, and applications to robust second order necessary conditions for controlled SEEs},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The finite spectrum problems for dirac operators.
<em>JMAA</em>, <em>549</em>(1), 129444. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present paper, the finite spectrum problem of Dirac operators is studied. For each nonnegative integer m , we construct a class of regular Dirac operator which has at most n = 2 m + 1 eigenvalues. The method presented is based on choosing the coefficients of the Dirac equation such that they are alternatively zero on consecutive subintervals and iterative construction of the characteristic function.},
  archive      = {J_JMAA},
  author       = {Fangyuan Zhang and Kun Li and Jinming Cai},
  doi          = {10.1016/j.jmaa.2025.129444},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {1},
  pages        = {129444},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {The finite spectrum problems for dirac operators},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The algebra d(w) via strong darboux transformations.
<em>JMAA</em>, <em>549</em>(1), 129443. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Matrix Bochner Problem aims to classify weight matrices W such that the algebra D ( W ) , of all differential operators that have a sequence of matrix-valued orthogonal polynomials for W as eigenfunctions, contains a second-order differential operator. In [5] it is proven that, under certain assumptions, the solutions to the Matrix Bochner Problem can be obtained through a noncommutative bispectral Darboux transformation of some classical scalar weights. The main aim of this paper is to introduce the concept of strong Darboux transformation among weight matrices and explore the relationship between the algebras D ( W ) and D ( W ˜ ) when W ˜ is a strong Darboux transformation of W . Starting from a direct sum of classical scalar weights W ˜ , and leveraging our complete knowledge of the algebra of D ( W ˜ ) , we can easily determine the algebra D ( W ) of a weight W that is a strong Darboux transformation of W ˜ .},
  archive      = {J_JMAA},
  author       = {Ignacio Bono Parisi and Ines Pacharoni},
  doi          = {10.1016/j.jmaa.2025.129443},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {1},
  pages        = {129443},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {The algebra D(W) via strong darboux transformations},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boundedness and compactness for differences of composition
operators between bergman spaces on strongly pseudoconvex domains.
<em>JMAA</em>, <em>549</em>(1), 129440. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article deals with boundedness and compactness of differences of composition operators C u − C v between holomorphic Bergman spaces on strongly Levi-pseudoconvex domains in C n .},
  archive      = {J_JMAA},
  author       = {Ly Kim Ha},
  doi          = {10.1016/j.jmaa.2025.129440},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {1},
  pages        = {129440},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Boundedness and compactness for differences of composition operators between bergman spaces on strongly pseudoconvex domains},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The monotony of the q−bessel functions. <em>JMAA</em>,
<em>549</em>(1), 129439. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129439">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we prove a monotonicity property for the normalized Jackson and Hahn-Exton q -Bessel functions using the method of subordination factor sequences. Additionally, in the special case of q → 1 , we obtain the result of Cotîrlá and Szász (2024) [8] .},
  archive      = {J_JMAA},
  author       = {Yücel Özkan and Semra Korkmaz and Erhan Deniz},
  doi          = {10.1016/j.jmaa.2025.129439},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {1},
  pages        = {129439},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {The monotony of the q−Bessel functions},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysis of a free boundary problem on stratified lie group.
<em>JMAA</em>, <em>549</em>(1), 129438. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a variational framework for studying the existence of solutions of a class of elliptic free boundary problems on stratified Lie groups. Using the important monotonicity result in a Non-Euclidean setup, we prove that our solution is the limit of mountain pass points of a sequence of C 1 -functionals approximating the energy.},
  archive      = {J_JMAA},
  author       = {Sabri Bensid},
  doi          = {10.1016/j.jmaa.2025.129438},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {1},
  pages        = {129438},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Analysis of a free boundary problem on stratified lie group},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On properties of the solutions to the (p,q)-harmonic
functions. <em>JMAA</em>, <em>549</em>(1), 129437. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Suppose p , q ∈ R ﹨ Z − such that p + q &gt; − 1 . The aim of this paper is to establish properties of the ( p , q ) -harmonic functions in the unit disc | z | &lt; 1 in the complex plane C . We obtain the boundedness and the Lipschitz continuity with respect to the hyperbolic metric for ( p , q ) -harmonic functions. In particular, for p = q &gt; − 1 , we get the Heinz type inequality on the unit circle | z | = 1 . As an application, a Landau type theorem of ( p , q ) -harmonic functions is established.},
  archive      = {J_JMAA},
  author       = {Peijin Li and Qinghong Luo and Saminathan Ponnusamy},
  doi          = {10.1016/j.jmaa.2025.129437},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {1},
  pages        = {129437},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {On properties of the solutions to the (p,q)-harmonic functions},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximation of feedback gains for the oseen system.
<em>JMAA</em>, <em>549</em>(1), 129418. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129418">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the Oseen system with a Dirichlet boundary control, and its semidiscrete approximation by a finite element method (FEM). We show that these two systems fit with the abstract setting recently introduced in [5] . We obtain convergence rates for Riccati based feedback laws and their discrete approximation, in terms of the discretization parameter h (the mesh size of the FEM). We also prove convergence rates between the solution of the closed-loop Oseen system and the solution of the semidiscrete closed-loop Oseen system. These results are based on new error estimates, previously known for the Stokes system in polyhedral or polygonal convex domains, that we have recently extended to the Oseen system in polyhedral (or polygonal) convex or non-convex domains. We also prove a uniform bound for the discrete control operator B h , which seems to be totally new in the context of the numerical approximation of feedback laws.},
  archive      = {J_JMAA},
  author       = {Mehdi Badra and Jean-Pierre Raymond},
  doi          = {10.1016/j.jmaa.2025.129418},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {1},
  pages        = {129418},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Approximation of feedback gains for the oseen system},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jocs---4">JOCS - 4</h2>
<ul>
<li><details>
<summary>
(2025). A cluster-based opposition differential evolution algorithm
boosted by a local search for ECG signal classification. <em>JOCS</em>,
<em>86</em>, 102541. (<a
href="https://doi.org/10.1016/j.jocs.2025.102541">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrocardiogram (ECG) signals, which capturethe heart&#39;s electrical activity, are used to diagnose and monitor cardiac problems. The accurate classification of ECG signals, particularly for distinguishing among various types of arrhythmias and myocardial infarctions, is crucial for the early detection and treatment of heart-related diseases. This paper proposes a novel approach based on an improved differential evolution (DE) algorithm for ECG signal classification for enhancing the performance. In the initial stages of our approach, the preprocessing step is followed by the extraction of several significant features from the ECG signals. These extracted features are then provided as inputs to an enhanced multi-layer perceptron (MLP). While MLPs are still widely used for ECG signal classification, using gradient-based training methods, the most widely used algorithm for the training process, has significant disadvantages, such as the possibility of being stuck in local optimums. This paper employs an enhanced differential evolution (DE) algorithm for the training process as one of the most effective population-based algorithms. To this end, we improved DE based on a clustering-based strategy, opposition-based learning, and a local search. Clustering-based strategies can act as crossover operators, while the goal of the opposition operator is to improve the exploration of the DE algorithm. The weights and biases found by the improved DE algorithm are then fed into six gradient-based local search algorithms. In other words, the weights found by the DE are employed as an initialization point. Therefore, we introduced six different algorithms for the training process (in terms of different local search algorithms). In an extensive set of experiments, we showed that our proposed training algorithm could provide better results than the conventional training algorithms.},
  archive      = {J_JOCS},
  author       = {Mehran Pourvahab and Seyed Jalaleddin Mousavirad and Virginie Felizardo and Nuno Pombo and Henriques Zacarias and Hamzeh Mohammadigheymasi and Sebastião Pais and Seyed Nooreddin Jafari and Nuno M. Garcia},
  doi          = {10.1016/j.jocs.2025.102541},
  journal      = {Journal of Computational Science},
  month        = {4},
  pages        = {102541},
  shortjournal = {J. Comput. Sci.},
  title        = {A cluster-based opposition differential evolution algorithm boosted by a local search for ECG signal classification},
  volume       = {86},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Community-based voting approach to enhance the spreading
dynamics by identifying a group of influential spreaders in complex
networks. <em>JOCS</em>, <em>86</em>, 102540. (<a
href="https://doi.org/10.1016/j.jocs.2025.102540">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploring a group of influential spreaders to acquire maximum influence has become an emerging area of research in complex network analysis. The main challenge of this research is to identify the group of important nodes that are scattered broadly, such that the propagation ability of information is maximum to a network. Researchers proposed many centrality-based approaches with certain limitations to identify the influential nodes (spreaders) considering different properties of the networks. To find a group of spreaders, the VoteRank (a voting mechanism) based method produces effective results with low time complexity, where in each iteration, the node votes for its neighbors by its voting capability, and the node obtaining the maximum vote score is identified as an influential spreader. The major loophole of existing VoteRank methods is measuring the voting capability based on the degree, k-shell index, or contribution of neighbors methods, which does not efficiently identify the spreaders from the diverse regions based on their spreading ability. In this paper, we propose a novel Community-based VoteRank method (CVoteRank) to identify a group of influential spreaders from diverse network regions by which the diffusion process is enhanced. Firstly, we measure every node’s spreading ability based on intra- and inter-connectivity structure in a community, which signifies the local and global importance of the node. To identify the seed nodes, we assign the spreading ability to that node’s voting capability and iteratively calculate the voting score of a node based on its neighboring voting capability and its spreading ability. Then, the node acquiring the maximum voting score is identified as the influential spreader in each iteration. Finally, to solve the problem of influence overlapping, CVoteRank reduces the voting capability of the neighboring nodes of the identified spreader. The efficiency of CVoteRank is evaluated and compared with the different state-of-the-art methods on twelve real networks. Utilizing the stochastic susceptible–infected–recovered epidemic method, we calculate the infected scale, final infected scale, and the average shortest path length among the identified spreaders. The experimental results show that CVoteRank identifies the most efficient spreaders with the highest spreading ability within a short period and the maximum reachability, and the identified spreaders are situated at diverse portions of the networks.},
  archive      = {J_JOCS},
  author       = {Suman Nandi and Mariana Curado Malta and Giridhar Maji and Animesh Dutta},
  doi          = {10.1016/j.jocs.2025.102540},
  journal      = {Journal of Computational Science},
  month        = {4},
  pages        = {102540},
  shortjournal = {J. Comput. Sci.},
  title        = {Community-based voting approach to enhance the spreading dynamics by identifying a group of influential spreaders in complex networks},
  volume       = {86},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep dive into generative models through feature interpoint
distances. <em>JOCS</em>, <em>86</em>, 102539. (<a
href="https://doi.org/10.1016/j.jocs.2025.102539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the Interpoint Inception Distance (IID) as a new approach for evaluating deep generative models. It is based on reducing the measurement of discrepancy between multidimensional feature distributions to one-dimensional interpoint comparisons. Our method provides a general tool for deriving a wide range of evaluation measures. The Cramér Interpoint Inception Distance (CIID) is notable for its theoretical properties, including a Gaussian-free structure of feature distribution and a strongly consistent estimator. Our experiments, conducted on both synthetic and large-scale real or generated data, suggest that CIID is a promising competitor to the Fréchet Inception Distance (FID), which is currently the primary metric for evaluating deep generative models. This article is an extended version of the ICCS 2024 conference paper (Jajeśniak et al., 2024) [1] .},
  archive      = {J_JOCS},
  author       = {Dariusz Jajeśniak and Piotr Kościelniak and Arkadiusz Zajdel and Marcin Mazur},
  doi          = {10.1016/j.jocs.2025.102539},
  journal      = {Journal of Computational Science},
  month        = {4},
  pages        = {102539},
  shortjournal = {J. Comput. Sci.},
  title        = {Deep dive into generative models through feature interpoint distances},
  volume       = {86},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised continual learning by cross-level,
instance-group and pseudo-group discrimination with hard attention.
<em>JOCS</em>, <em>86</em>, 102535. (<a
href="https://doi.org/10.1016/j.jocs.2025.102535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extensive work has been done in supervised continual learning (SCL) , wherein models adapt to changing distributions with labeled data while mitigating catastrophic forgetting. However, this approach diverges from real-world scenarios where labeled data is scarce or non-existent. Unsupervised continual learning (UCL) emerges to bridge this disparity. Previous research has explored methods for unsupervised continuous feature learning by incorporating rehearsal to alleviate the problem of catastrophic forgetting. Although these techniques are effective, they may not be feasible for scenarios where storing training data is impractical. Moreover, rehearsal techniques may confront challenges pertaining to representation drifts and overfitting, particularly under limited buffer size conditions. To address these drawbacks, we employ parameter isolation as a strategy to mitigate forgetting. Specifically, we use task-specific hard attention to prevent updates to parameters important for previous tasks. In contrastive learning, loss is prone to be negatively affected by a reduction in the diversity of negative samples. Therefore, we incorporate instance-to-instance similarity into contrastive learning through both direct instance grouping and discrimination at the cross-level with local instance groups, as well as with local pseudo-instance groups. The masked model learns the features using cross-level discrimination, which naturally clusters similar data in the representation space. Extensive experimentation demonstrates that our proposed approach outperforms current state-of-the-art (SOTA) baselines by significant margins, all while exhibiting minimal or nearly zero forgetting, and without the need for any rehearsal buffer. Additionally, the model learns distinct task boundaries. It achieves an overall-average task and class incremental learning (TIL &amp; CIL) accuracy of 76.79% and 62.96% respectively with nearly zero forgetting, across standard datasets for varying task sequences ranging from 5 to 100. This surpasses SOTA baselines, which only reach 74.28% and 60.68% respectively in the UCL setting, where they experience substantial forgetting of almost over 4%. Moreover, our approach achieves performance nearly comparable to the SCL baseline and even surpasses it on some standard datasets, with a notable reduction in forgetting from almost 14.51% to nearly zero.},
  archive      = {J_JOCS},
  author       = {Ankit Malviya and Sayak Dhole and Chandresh Kumar Maurya},
  doi          = {10.1016/j.jocs.2025.102535},
  journal      = {Journal of Computational Science},
  month        = {4},
  pages        = {102535},
  shortjournal = {J. Comput. Sci.},
  title        = {Unsupervised continual learning by cross-level, instance-group and pseudo-group discrimination with hard attention},
  volume       = {86},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="joe---19">JOE - 19</h2>
<ul>
<li><details>
<summary>
(2025). Reprint of: Finite underidentification. <em>JOE</em>,
<em>248</em>, 105947. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105947">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {I adapt the Generalised Method of Moments to deal with nonlinear models in which a finite number of isolated parameter values satisfy the moment conditions. I also study the closely related class of first-order underidentified models, whose expected Jacobian is rank deficient but not necessarily zero. In both cases, my proposed procedures exploit the underidentification structure to yield parameter estimators and underidentification tests within a standard asymptotically normal GMM framework. I study nonlinear models with and without separation of data and parameters. I also illustrate my proposed inference procedures with applications to production function estimation and dynamic panel data models.},
  archive      = {J_JOE},
  author       = {Enrique Sentana},
  doi          = {10.1016/j.jeconom.2025.105947},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105947},
  shortjournal = {J. Econ.},
  title        = {Reprint of: Finite underidentification},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identifying the volatility risk price through the leverage
effect. <em>JOE</em>, <em>248</em>, 105943. (<a
href="https://doi.org/10.1016/j.jeconom.2024.105943">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In asset pricing models with stochastic volatility, uncertainty about volatility affects risk premia through two channels: aversion to decreasing returns and aversion to increasing volatility. We analyze the identification of and robust inference for structural parameters measuring investors’ aversions to these risks: the return risk price and the volatility risk price. In the presence of a leverage effect (instantaneous causality between the asset return and its volatility), we study the identification of both structural parameters with the price data only, without relying on additional option pricing models or option data. We analyze this identification challenge in a nonparametric discrete-time exponentially affine model, complementing the continuous-time approach of Bandi and Renò (2016). We then specialize to a parametric model and derive the implied minimum distance criterion relating the risk prices to the asset return and volatility’s joint distribution. This criterion is almost flat when the leverage effect is small, and we introduce identification-robust confidence sets for both risk prices regardless of the magnitude of the leverage effect.},
  archive      = {J_JOE},
  author       = {Xu Cheng and Eric Renault and Paul Sangrey},
  doi          = {10.1016/j.jeconom.2024.105943},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105943},
  shortjournal = {J. Econ.},
  title        = {Identifying the volatility risk price through the leverage effect},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identification, inference and risk. <em>JOE</em>,
<em>248</em>, 105938. (<a
href="https://doi.org/10.1016/j.jeconom.2024.105938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JOE},
  author       = {Bertille Antoine and Patrick Gagliardini and René Garcia and Enrique Sentana},
  doi          = {10.1016/j.jeconom.2024.105938},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105938},
  shortjournal = {J. Econ.},
  title        = {Identification, inference and risk},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Functional ecological inference. <em>JOE</em>, <em>248</em>,
105918. (<a
href="https://doi.org/10.1016/j.jeconom.2024.105918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the problem of ecological inference when one observes the conditional distributions of Y | W and Z | W from aggregate data and attempts to infer the conditional distribution of Y | Z without observing Y and Z in the same sample. First, we show that this problem can be transformed into a linear equation involving operators for which, under suitable regularity assumptions, least squares solutions are available. We then propose the use of the least squares solution with the minimum Hilbert–Schmidt norm, which, in our context, can be structurally interpreted as the solution with minimum dependence between Y and Z . Interestingly, in the case where the conditioning variable W is discrete and belongs to a finite set, such as the labels of units/groups/cities, the solution of this minimal dependence has a closed form. In the more general case, we use a regularization scheme and show the convergence of our proposed estimator. A numerical evaluation of our procedure is proposed.},
  archive      = {J_JOE},
  author       = {Christian Bontemps and Jean-Pierre Florens and Nour Meddahi},
  doi          = {10.1016/j.jeconom.2024.105918},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105918},
  shortjournal = {J. Econ.},
  title        = {Functional ecological inference},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identification-robust and simultaneous inference in
multifactor asset pricing models. <em>JOE</em>, <em>248</em>, 105915.
(<a href="https://doi.org/10.1016/j.jeconom.2024.105915">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes exact identification-robust confidence sets for the zero-beta rate and ex-post factor prices in asset pricing models. Exploiting the information from the cross-sectional intercept allows us to impose or formally test model-consistent restrictions, including those resulting from traded factors in excess of the zero beta-rate or from return spreads. Analytical projection-based solutions for confidence set outcomes are developed. The proposed procedures are extended to the case of missing factors. Empirical and simulation results with traded and non-traded factors show that model-consistent restrictions and elusive factors can materially affect model fit, identification, inference and temporal constancy of pricing influence.},
  archive      = {J_JOE},
  author       = {Marie-Claude Beaulieu and Jean-Marie Dufour and Lynda Khalaf},
  doi          = {10.1016/j.jeconom.2024.105915},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105915},
  shortjournal = {J. Econ.},
  title        = {Identification-robust and simultaneous inference in multifactor asset pricing models},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long-run risk in stationary vector autoregressive models.
<em>JOE</em>, <em>248</em>, 105905. (<a
href="https://doi.org/10.1016/j.jeconom.2024.105905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a local-to-unity/small sigma model for stationary processes with long-range persistence and non-negligible long-run prediction and estimation risks. The model represents a process containing unobserved short and long-run components measured on different time scales. The short-run component is defined in calendar time, while the long-run component evolves in rescaled time with ultra-long units. We develop estimation and long-run prediction methods for time series with multivariate Vector Autoregressive (VAR) short-run components and reveal the impossibility of estimating consistently some of the long-run parameters, which causes significant estimation and prediction risks in the long run. A simulation study and an application to macroeconomic data illustrate the approach.},
  archive      = {J_JOE},
  author       = {Christian Gourieroux and Joann Jasiak},
  doi          = {10.1016/j.jeconom.2024.105905},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105905},
  shortjournal = {J. Econ.},
  title        = {Long-run risk in stationary vector autoregressive models},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncovering asset market participation from household
consumption and income. <em>JOE</em>, <em>248</em>, 105867. (<a
href="https://doi.org/10.1016/j.jeconom.2024.105867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an asset pricing model featuring time-varying limited participation in both bond and stock markets and household heterogeneity. Households participate in financial markets with a certain probability that depends on their individual income and on asset market conditions. We use indirect inference to uncover individual asset market participation from individual consumption data and asset prices. Our model very accurately reproduces the proportions of stockholders in the Survey of Consumer Finances over three-year intervals, provides a reasonable estimate of stock market participation costs, and is able to price characteristic-based stock portfolios with the top decile of households identified as stockholders.},
  archive      = {J_JOE},
  author       = {Veronika Czellar and René Garcia and François Le Grand},
  doi          = {10.1016/j.jeconom.2024.105867},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105867},
  shortjournal = {J. Econ.},
  title        = {Uncovering asset market participation from household consumption and income},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weak identification in discrete choice models. <em>JOE</em>,
<em>248</em>, 105866. (<a
href="https://doi.org/10.1016/j.jeconom.2024.105866">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the impact of weak identification in discrete choice models, and provide insights into the determinants of identification strength in these models. Using these insights, we propose a novel test that can consistently detect weak identification in commonly applied discrete choice models, such as probit, logit, and many of their extensions. Furthermore, we demonstrate that when the null hypothesis of weak identification is rejected, Wald-based inference can be carried out using standard formulas and critical values. A Monte Carlo study compares our proposed testing approach against commonly applied weak identification tests. The results simultaneously demonstrate the good performance of our approach and the fundamental failure of using conventional weak identification tests for linear models in the discrete choice model context. Lastly, we apply our approach in two empirical examples: married women labor force participation, and US food aid and civil conflicts.},
  archive      = {J_JOE},
  author       = {David T. Frazier and Eric Renault and Lina Zhang and Xueyan Zhao},
  doi          = {10.1016/j.jeconom.2024.105866},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105866},
  shortjournal = {J. Econ.},
  title        = {Weak identification in discrete choice models},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conditional spectral methods. <em>JOE</em>, <em>248</em>,
105863. (<a
href="https://doi.org/10.1016/j.jeconom.2024.105863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We model predictive scale-specific cycles. By employing suitable matrix representations, we express the forecast errors of covariance-stationary multivariate time series in terms of conditionally orthonormal scale-specific bases. The representations yield conditionally orthogonal decompositions of these forecast errors. They also provide decompositions of their variances and betas in terms of scale-specific variances and betas capturing predictive variability and co-variability over cycles of alternative lengths without spillovers across cycles. Making use of the proposed representations within the classical family of time-varying conditional volatility models, we document the role of time-varying volatility forecasts in generating orthogonal predictive scale-specific cycles in returns. We conclude by providing suggestive evidence that the conditional variances of the predictive return cycles ( i ) may be priced over short-to-medium horizons and ( i i ) may offer economically-relevant trading signals over these same horizons.},
  archive      = {J_JOE},
  author       = {Federico M. Bandi and Yinan Su},
  doi          = {10.1016/j.jeconom.2024.105863},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105863},
  shortjournal = {J. Econ.},
  title        = {Conditional spectral methods},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exogeneity tests and weak identification in IV regressions:
Asymptotic theory and point estimation. <em>JOE</em>, <em>248</em>,
105821. (<a
href="https://doi.org/10.1016/j.jeconom.2024.105821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides new insights on exogeneity tests in linear IV models and their use for estimation, when identification fails or may not be strong. We make two main contributions. First , we show that Durbin–Wu–Hausman (DWH) and Revankar–Hartley (RH) exogeneity tests have correct level asymptotically, even when the first-stage coefficient matrix (which controls identification) is rank-deficient. We provide necessary and sufficient conditions under which these tests are consistent. In particular, we show that test consistency can hold even when identification fails, provided at least one component of the structural parameter vector is identifiable. Second , we study point estimation after estimator (or model) selection, when the outcome of a DWH/RH test determines whether OLS or an IV method is employed in the second-stage. For this purpose, we use ( non-local ) concepts of asymptotic bias , asymptotic mean squared error (AMSE), and asymptotic relative efficiency (ARE), which remain applicable even when the estimators considered do not have moments (as can happen for 2SLS) or may be inconsistent. We study the asymptotic properties of OLS, 2SLS, and pretest estimators which select OLS or 2SLS based on the outcome of a DWH/RH test. We show that: (i) OLS typically dominates 2SLS estimator asymptotically for MSE across a broad spectrum of cases, including weak identification and moderate endogeneity; (ii) exogeneity-pretest estimators exhibit consistently good performance and asymptotically dominate both OLS and 2SLS. The proposed theoretical findings are documented by Monte Carlo simulations.},
  archive      = {J_JOE},
  author       = {Firmin Doko Tchatoka and Jean-Marie Dufour},
  doi          = {10.1016/j.jeconom.2024.105821},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105821},
  shortjournal = {J. Econ.},
  title        = {Exogeneity tests and weak identification in IV regressions: Asymptotic theory and point estimation},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simulation-based estimation with many auxiliary statistics
applied to long-run dynamic analysis. <em>JOE</em>, <em>248</em>,
105814. (<a
href="https://doi.org/10.1016/j.jeconom.2024.105814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing asymptotic theory for estimators obtained by simulated minimum distance does not cover situations in which the number of components of the auxiliary statistics (or number of matched “moments”) is large — typically larger than the sample size. We establish the consistency of the simulated minimum distance estimator in this situation and derive its asymptotic distribution. Our estimator is easy to implement and allows us to exploit all the informational content of a large number of auxiliary statistics without having to, (i) know these functions explicitly, or (ii) choose a priori which functions are the most informative. As a result, we are able to exploit, among other things, long-run information. We illustrate the implementation of the proposed method through Monte-Carlo simulation experiments based on small- and medium-scale New Keynesian models. These examples highlight how to conveniently exploit valuable information from matching a large number of impulse responses including at long-run horizons.},
  archive      = {J_JOE},
  author       = {Bertille Antoine and Wenqian Sun},
  doi          = {10.1016/j.jeconom.2024.105814},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105814},
  shortjournal = {J. Econ.},
  title        = {Simulation-based estimation with many auxiliary statistics applied to long-run dynamic analysis},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The chained difference-in-differences. <em>JOE</em>,
<em>248</em>, 105783. (<a
href="https://doi.org/10.1016/j.jeconom.2024.105783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the identification, estimation, and inference of long-term (binary) treatment effect parameters when balanced panel data is not available, or consists of only a subset of the available data. We develop a new estimator: the chained difference-in-differences, which leverages the overlapping structure of many unbalanced panel data sets. This approach consists in aggregating a collection of short-term treatment effects estimated on multiple incomplete panels. Our estimator accommodates (1) multiple time periods, (2) variation in treatment timing, (3) treatment effect heterogeneity, (4) general missing data patterns, and (5) sample selection on observables. We establish the asymptotic properties of the proposed estimator and discuss identification and efficiency gains in comparison to existing methods. Finally, we illustrate its relevance through (i) numerical simulations, and (ii) an application about the effects of an innovation policy in France.},
  archive      = {J_JOE},
  author       = {Christophe Bellégo and David Benatia and Vincent Dortet-Bernadet},
  doi          = {10.1016/j.jeconom.2024.105783},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105783},
  shortjournal = {J. Econ.},
  title        = {The chained difference-in-differences},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Regularizing stock return covariance matrices via multiple
testing of correlations. <em>JOE</em>, <em>248</em>, 105753. (<a
href="https://doi.org/10.1016/j.jeconom.2024.105753">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a large-scale inference approach for the regularization of stock return covariance matrices. The framework allows for the presence of heavy tails and multivariate GARCH-type effects of unknown form among the stock returns. The approach involves simultaneous testing of all pairwise correlations, followed by setting non-statistically significant elements to zero. This adaptive thresholding is achieved through sign-based Monte Carlo resampling within multiple testing procedures, controlling either the traditional familywise error rate, a generalized familywise error rate, or the false discovery proportion. Subsequent shrinkage ensures that the final covariance matrix estimate is positive definite and well-conditioned while preserving the achieved sparsity. Compared to alternative estimators, this new regularization method demonstrates strong performance in simulation experiments and real portfolio optimization.},
  archive      = {J_JOE},
  author       = {Richard Luger},
  doi          = {10.1016/j.jeconom.2024.105753},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105753},
  shortjournal = {J. Econ.},
  title        = {Regularizing stock return covariance matrices via multiple testing of correlations},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spanning latent and observable factors. <em>JOE</em>,
<em>248</em>, 105743. (<a
href="https://doi.org/10.1016/j.jeconom.2024.105743">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Factor analysis is a widely used tool to summarize high dimensional panel data via a small dimensional set of latent factors. Many applications in finance and macroeconomics, are often focused on observable factors with an economic interpretation. The objective of this paper is to provide a test to answer a question which naturally comes up in discussions regarding latent versus observable factors: do latent and observable factors span the same space? We derive asymptotic properties of a formal test and propose a bootstrap version with improved small sample properties. We find empirical evidence for a small number of factors common between a small number of traditional Fama–French risk factors – or returns on a few stocks (i.e. “magnificent” 5 or 7) – and large panels of US, North American and international portfolio returns.},
  archive      = {J_JOE},
  author       = {E. Andreou and P. Gagliardini and E. Ghysels and M. Rubin},
  doi          = {10.1016/j.jeconom.2024.105743},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105743},
  shortjournal = {J. Econ.},
  title        = {Spanning latent and observable factors},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identification robust inference for the risk premium in term
structure models. <em>JOE</em>, <em>248</em>, 105728. (<a
href="https://doi.org/10.1016/j.jeconom.2024.105728">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose identification robust statistics for testing hypotheses on the risk premia in dynamic affine term structure models. We do so using the moment equation specification proposed in Adrian et al. (2013) . Statistical inference based on their three-stage estimator requires knowledge of the risk factors’ quality and can be misleading when the β ’s are weak, which results when sampling errors are of comparable order of magnitude as the risk factor loadings. We extend the subset (factor) Anderson–Rubin test from Guggenberger et al. (2012) to models with multiple dynamic factors and time-varying risk prices. It provides a computationally tractable manner to conduct identification robust tests on a few risk premia when a larger number is present. We use it to analyze potential identification issues arising in the data from Adrian et al. (2013) for which we show that some factors, though potentially weak, may drive the time variation of risk prices, and weak identification issues are more prominent in multi-factor models.},
  archive      = {J_JOE},
  author       = {Frank Kleibergen and Lingwei Kong},
  doi          = {10.1016/j.jeconom.2024.105728},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105728},
  shortjournal = {J. Econ.},
  title        = {Identification robust inference for the risk premium in term structure models},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficiency bounds for moment condition models with mixed
identification strength. <em>JOE</em>, <em>248</em>, 105723. (<a
href="https://doi.org/10.1016/j.jeconom.2024.105723">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Moment condition models with mixed identification strength are models that are point identified but with estimating moment functions that are allowed to drift to 0 uniformly over the parameter space. Even though identification fails in the limit, depending on how slow the moment functions vanish, consistent estimation is possible. Existing estimators such as the generalized method of moment (GMM) estimator exhibit a pattern of nonstandard or even heterogeneous rate of convergence that materializes by some parameter directions being estimated at a slower rate than others. This paper derives asymptotic semiparametric efficiency bounds for regular estimators of parameters of these models. We show that GMM estimators are regular and that the so-called two-step GMM estimator – using the inverse of estimating function’s variance as weighting matrix – is semiparametrically efficient as it reaches the minimum variance attainable by regular estimators. This estimator is also asymptotically minimax efficient with respect to a large family of loss functions. Monte Carlo simulations are provided that confirm these results.},
  archive      = {J_JOE},
  author       = {Prosper Dovonon and Yves F. Atchadé and Firmin Doko Tchatoka},
  doi          = {10.1016/j.jeconom.2024.105723},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105723},
  shortjournal = {J. Econ.},
  title        = {Efficiency bounds for moment condition models with mixed identification strength},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Score-type tests for normal mixtures. <em>JOE</em>,
<em>248</em>, 105717. (<a
href="https://doi.org/10.1016/j.jeconom.2024.105717">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Testing normality against discrete normal mixtures is complex because some parameters turn increasingly underidentified along alternative ways of approaching the null, others are inequality constrained, and several higher-order derivatives become identically 0. These problems make the maximum of the alternative model log-likelihood function numerically unreliable. We propose score-type tests asymptotically equivalent to the likelihood ratio as the largest of two simple intuitive statistics that only require estimation under the null. One novelty of our approach is that we treat symmetrically both ways of writing the null hypothesis without excluding any region of the parameter space. We derive the asymptotic distribution of our tests under the null and sequences of local alternatives. We also show that their asymptotic distribution is the same whether applied to observations or standardized residuals from heteroskedastic regression models. Finally, we study their power in simulations and apply them to the residuals of Mincer earnings functions.},
  archive      = {J_JOE},
  author       = {Dante Amengual and Xinyue Bei and Marine Carrasco and Enrique Sentana},
  doi          = {10.1016/j.jeconom.2024.105717},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105717},
  shortjournal = {J. Econ.},
  title        = {Score-type tests for normal mixtures},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). When uncertainty and volatility are disconnected:
Implications for asset pricing and portfolio performance. <em>JOE</em>,
<em>248</em>, 105654. (<a
href="https://doi.org/10.1016/j.jeconom.2023.105654">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze an environment where the uncertainty in the equity market return and its volatility are both stochastic and may be potentially disconnected. We solve a representative investor’s optimal asset allocation and derive the resulting conditional equity premium and risk-free rate in equilibrium. Our empirical analysis shows that the equity premium appears to be earned for facing uncertainty, especially high uncertainty that is disconnected from lower volatility, rather than for facing volatility as traditionally assumed. Incorporating the possibility of a disconnect between volatility and uncertainty significantly improves portfolio performance, over and above the performance obtained by conditioning on volatility only.},
  archive      = {J_JOE},
  author       = {Yacine Aït-Sahalia and Felix Matthys and Emilio Osambela and Ronnie Sircar},
  doi          = {10.1016/j.jeconom.2023.105654},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105654},
  shortjournal = {J. Econ.},
  title        = {When uncertainty and volatility are disconnected: Implications for asset pricing and portfolio performance},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The term structure of macroeconomic risks at the effective
lower bound. <em>JOE</em>, <em>248</em>, 105383. (<a
href="https://doi.org/10.1016/j.jeconom.2023.01.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new macro-finance model that solves the tension between tractability, flexibility in macroeconomic dynamics, and consistency of the term structures of treasury yields with the effective lower bound (ELB). I use the term structures of U.S. nominal and real treasury yields from 1990 to explore the interdependence between inflation expectations, volatility, and monetary policy at the ELB. The estimation reveals that real yields stay elevated during the ELB due to large premia and deflation fears, produced by a persistent shift in inflation dynamics, with low average inflation and heightened inflation volatility.},
  archive      = {J_JOE},
  author       = {Guillaume Roussellet},
  doi          = {10.1016/j.jeconom.2023.01.005},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105383},
  shortjournal = {J. Econ.},
  title        = {The term structure of macroeconomic risks at the effective lower bound},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="joma---15">JOMA - 15</h2>
<ul>
<li><details>
<summary>
(2025). Graph-constrained analysis for multivariate functional data.
<em>JOMA</em>, <em>207</em>, 105428. (<a
href="https://doi.org/10.1016/j.jmva.2025.105428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The manuscript considers multivariate functional data analysis with a known graphical model among the functional variables representing their conditional relationships (e.g., brain region-level fMRI data with a prespecified connectivity graph among brain regions). Functional Gaussian graphical models (GGM) used for analyzing multivariate functional data customarily estimate an unknown graphical model, and cannot preserve knowledge of a given graph. We propose a method for multivariate functional analysis that exactly conforms to a given inter-variable graph. We first show the equivalence between partially separable functional GGM and graphical Gaussian processes (GP), proposed recently for constructing optimal multivariate covariance functions that retain a given graphical model. The theoretical connection helps to design a new algorithm that leverages Dempster’s covariance selection for obtaining the maximum likelihood estimate of the covariance function for multivariate functional data under graphical constraints. We also show that the finite term truncation of functional GGM basis expansion used in practice is equivalent to a low-rank graphical GP, which is known to oversmooth marginal distributions. To remedy this, we extend our algorithm to better preserve marginal distributions while respecting the graph and retaining computational scalability. The benefits of the proposed algorithms are illustrated using empirical experiments and a neuroimaging application.},
  archive      = {J_JOMA},
  author       = {Debangan Dey and Sudipto Banerjee and Martin A. Lindquist and Abhirup Datta},
  doi          = {10.1016/j.jmva.2025.105428},
  journal      = {Journal of Multivariate Analysis},
  month        = {5},
  pages        = {105428},
  shortjournal = {J. Multi. Anal.},
  title        = {Graph-constrained analysis for multivariate functional data},
  volume       = {207},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A review of multivariate permutation tests: Findings and
trends. <em>JOMA</em>, <em>207</em>, 105421. (<a
href="https://doi.org/10.1016/j.jmva.2025.105421">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The permutation test is a widely recognized and frequently used nonparametric hypothesis test, notable for its minimal reliance on assumptions compared to parametric tests. It has found applications in many fields, particularly in multivariate analysis. Since its introduction in the 1930s, permutation tests have been extensively examined both theoretically and empirically. This article provides the results of a comprehensive and systematic review of the literature, focusing on different aspects of multivariate permutation tests. Key articles published in international journals from 2010 onwards have been analyzed, classifying them into four main research strands: data, model, test and issues. These strands were further subdivided into more specific categories. The state of the art and significant developments in this field are summarized, followed by a discussion on future research challenges and trends, offering guidance for the design and development on new approaches.},
  archive      = {J_JOMA},
  author       = {Rosa Arboretti and Elena Barzizza and Nicoló Biasetton and Marta Disegna},
  doi          = {10.1016/j.jmva.2025.105421},
  journal      = {Journal of Multivariate Analysis},
  month        = {5},
  pages        = {105421},
  shortjournal = {J. Multi. Anal.},
  title        = {A review of multivariate permutation tests: Findings and trends},
  volume       = {207},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Consistency of empirical distributions of sequences of graph
statistics in networks with dependent edges. <em>JOMA</em>,
<em>207</em>, 105420. (<a
href="https://doi.org/10.1016/j.jmva.2025.105420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the first steps in applications of statistical network analysis is frequently to produce summary charts of important features of the network. Many of these features take the form of sequences of graph statistics counting the number of realized events in the network, examples of which are degree distributions, edgewise shared partner distributions, and more. We provide conditions under which the empirical distributions of sequences of graph statistics are consistent in the ℓ ∞ -norm in settings where edges in the network are dependent. We accomplish this task by deriving concentration inequalities that bound probabilities of deviations of graph statistics from the expected value under weak dependence conditions. We apply our concentration inequalities to empirical distributions of sequences of graph statistics and derive non-asymptotic bounds on the ℓ ∞ -error which hold with high probability. Our non-asymptotic results are then extended to demonstrate uniform convergence almost surely in selected examples. We illustrate theoretical results through examples, simulation studies, and an application.},
  archive      = {J_JOMA},
  author       = {Jonathan R. Stewart},
  doi          = {10.1016/j.jmva.2025.105420},
  journal      = {Journal of Multivariate Analysis},
  month        = {5},
  pages        = {105420},
  shortjournal = {J. Multi. Anal.},
  title        = {Consistency of empirical distributions of sequences of graph statistics in networks with dependent edges},
  volume       = {207},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semiparametric density estimation with localized bregman
divergence. <em>JOMA</em>, <em>207</em>, 105419. (<a
href="https://doi.org/10.1016/j.jmva.2025.105419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines semiparametric density estimation by combining a parametric crude guess and its nonparametric adjustment. The nonparametric adjustment is implemented via minimization of the localized Bregman divergence, which yields a broad class of semiparametric density estimators. Asymptotic theories of the density estimators in this general class are developed. Specific concrete forms of density estimators under a certain divergence and parametric guess are calculated. Simulations for several target densities and application to a real data set reveal that the proposed density estimators offer competitive or, in some cases, better performance compared to fully nonparametric kernel density estimator.},
  archive      = {J_JOMA},
  author       = {Daisuke Matsuno and Kanta Naito},
  doi          = {10.1016/j.jmva.2025.105419},
  journal      = {Journal of Multivariate Analysis},
  month        = {5},
  pages        = {105419},
  shortjournal = {J. Multi. Anal.},
  title        = {Semiparametric density estimation with localized bregman divergence},
  volume       = {207},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tree-structured markov random fields with poisson marginal
distributions. <em>JOMA</em>, <em>207</em>, 105418. (<a
href="https://doi.org/10.1016/j.jmva.2025.105418">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new family of tree-structured Markov random fields for a vector of discrete counting random variables is introduced. According to the characteristics of the family, the marginal distributions of the Markov random fields are all Poisson with the same mean, and are untied from the strength or structure of their built-in dependence. This key feature is uncommon for Markov random fields and most convenient for applications purposes. The specific properties of this new family confer a straightforward sampling procedure and analytic expressions for the joint probability mass function and the joint probability generating function of the vector of counting random variables, thus granting computational methods that scale well to vectors of high dimension. We study the distribution of the sum of random variables constituting a Markov random field from the proposed family, analyze a random variable’s individual contribution to that sum through expected allocations, and establish stochastic orderings to assess a wide understanding of their behavior.},
  archive      = {J_JOMA},
  author       = {Benjamin Côté and Hélène Cossette and Etienne Marceau},
  doi          = {10.1016/j.jmva.2025.105418},
  journal      = {Journal of Multivariate Analysis},
  month        = {5},
  pages        = {105418},
  shortjournal = {J. Multi. Anal.},
  title        = {Tree-structured markov random fields with poisson marginal distributions},
  volume       = {207},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Classification using global and local mahalanobis distances.
<em>JOMA</em>, <em>207</em>, 105417. (<a
href="https://doi.org/10.1016/j.jmva.2025.105417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel semiparametric classifier based on Mahalanobis distances of an observation from the competing classes. Our tool is a generalized additive model with the logistic link function that uses these distances as features to estimate the posterior probabilities of different classes. While popular parametric classifiers like linear and quadratic discriminant analyses are mainly motivated by the normality of the underlying distributions, the proposed classifier is more flexible and free from such parametric modeling assumptions. Since the densities of elliptic distributions are functions of Mahalanobis distances, this classifier works well when the competing classes are (nearly) elliptic. In such cases, it often outperforms popular nonparametric classifiers, especially when the sample size is small compared to the dimension of the data. To cope with non-elliptic and possibly multimodal distributions, we propose a local version of the Mahalanobis distance. Subsequently, we propose another classifier based on a generalized additive model that uses the local Mahalanobis distances as features. This nonparametric classifier usually performs like the Mahalanobis distance based semiparametric classifier when the underlying distributions are elliptic, but outperforms it for several non-elliptic and multimodal distributions. We also investigate the behavior of these two classifiers in high dimension, low sample size situations. A thorough numerical study involving several simulated and real datasets demonstrate the usefulness of the proposed classifiers in comparison to many state-of-the-art methods.},
  archive      = {J_JOMA},
  author       = {Annesha Ghosh and Anil K. Ghosh and Rita SahaRay and Soham Sarkar},
  doi          = {10.1016/j.jmva.2025.105417},
  journal      = {Journal of Multivariate Analysis},
  month        = {5},
  pages        = {105417},
  shortjournal = {J. Multi. Anal.},
  title        = {Classification using global and local mahalanobis distances},
  volume       = {207},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model averaging for global fréchet regression.
<em>JOMA</em>, <em>207</em>, 105416. (<a
href="https://doi.org/10.1016/j.jmva.2025.105416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-Euclidean complex data analysis becomes increasingly popular in various fields of data science. In a seminal paper, Petersen and Müller (2019) generalized the notion of regression analysis to non-Euclidean response objects. Meanwhile, in the conventional regression analysis, model averaging has a long history and is widely applied in statistics literature. This paper studies the problem of optimal prediction for non-Euclidean objects by extending the method of model averaging. In particular, we generalize the notion of model averaging for global Fréchet regressions and establish an optimal property of the cross-validation to select the averaging weights in terms of the final prediction error. A simulation study illustrates excellent out-of-sample predictions of the proposed method.},
  archive      = {J_JOMA},
  author       = {Daisuke Kurisu and Taisuke Otsu},
  doi          = {10.1016/j.jmva.2025.105416},
  journal      = {Journal of Multivariate Analysis},
  month        = {5},
  pages        = {105416},
  shortjournal = {J. Multi. Anal.},
  title        = {Model averaging for global fréchet regression},
  volume       = {207},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An exponential inequality for hilbert-valued u-statistics of
i.i.d. data. <em>JOMA</em>, <em>207</em>, 105406. (<a
href="https://doi.org/10.1016/j.jmva.2025.105406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we establish an exponential inequality for U -statistics of i.i.d. data, varying kernel and taking values in a separable Hilbert space. The bound is expressed as a sum of an exponential term plus an other one involving the tail of a sum of squared norms. We start by the degenerate case. Then we provide applications to U -statistics of not necessarily degenerate fixed kernel, incomplete U -statistics and weighted U -statistics.},
  archive      = {J_JOMA},
  author       = {Davide Giraudo},
  doi          = {10.1016/j.jmva.2025.105406},
  journal      = {Journal of Multivariate Analysis},
  month        = {5},
  pages        = {105406},
  shortjournal = {J. Multi. Anal.},
  title        = {An exponential inequality for hilbert-valued U-statistics of i.i.d. data},
  volume       = {207},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SFQRA: Scaled factor-augmented quantile regression with
aggregation in conditional mean forecasting. <em>JOMA</em>,
<em>207</em>, 105405. (<a
href="https://doi.org/10.1016/j.jmva.2024.105405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving robust forecasts for a single time series with many covariates and possible nonlinear effects is a problem worth investigating. In this paper, a scaled factor-augmented quantile regression with aggregation (SFQRA) method is proposed for an effective prediction. It first estimates different conditional quantiles by introducing scaled covariates to the factor-augmented quantile regression, which not only combats the curse of dimensionality but also includes the target information in the estimation. Then the different conditional quantiles are aggregated appropriately to a robust forecast. Moreover, combining SFQRA with feature screening via an aggregated quantile correlation allows it to be extended to handle cases when only a portion of covariates is informative. The effectiveness of the proposed methods is justified theoretically, under the framework of large cross-sections and large time dimensions while no restriction is imposed on the relation between them. Various simulation studies and real data analyses demonstrate the superiority of the newly proposed method in forecasting.},
  archive      = {J_JOMA},
  author       = {Lei Shu and Yifan Hao and Yu Chen and Qing Yang},
  doi          = {10.1016/j.jmva.2024.105405},
  journal      = {Journal of Multivariate Analysis},
  month        = {5},
  pages        = {105405},
  shortjournal = {J. Multi. Anal.},
  title        = {SFQRA: Scaled factor-augmented quantile regression with aggregation in conditional mean forecasting},
  volume       = {207},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fisher’s legacy of directional statistics, and beyond to
statistics on manifolds. <em>JOMA</em>, <em>207</em>, 105404. (<a
href="https://doi.org/10.1016/j.jmva.2024.105404">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is not an exaggeration to say that R.A. Fisher is the Albert Einstein of Statistics. He pioneered almost all the main branches of statistics, but it is not as well known that he opened the area of Directional Statistics with his 1953 paper introducing a distribution on the sphere which is now known as the Fisher distribution. He stressed that for spherical data one should take into account that the data is on a manifold. We will describe this Fisher distribution and reanalyze his geological data. We also comment on the two goals he set himself in that paper, and on how he reinvented the von Mises distribution on the circle. Since then, many extensions of this distribution have appeared bearing Fisher’s name such as the von Mises–Fisher distribution and the matrix Fisher distribution. In fact, the subject of Directional Statistics has grown tremendously in the last two decades with new applications emerging in life sciences, image analysis, machine learning and so on. We give a recent new method of constructing the Fisher type distributions on manifolds which has been motivated by some problems in machine learning. The number of directional distributions has increased since then, including the bivariate von Mises distribution and we describe its connection to work resulting in the 2024 Nobel-winning AlphaFold (in Chemistry). Further, the subject has evolved as Statistics on Manifolds which also includes the new field of Shape Analysis, and finally, we end with a historical note pointing out some correspondence between D’Arcy Thompson and R.A. Fisher related to Shape Analysis.},
  archive      = {J_JOMA},
  author       = {Kanti V. Mardia},
  doi          = {10.1016/j.jmva.2024.105404},
  journal      = {Journal of Multivariate Analysis},
  month        = {5},
  pages        = {105404},
  shortjournal = {J. Multi. Anal.},
  title        = {Fisher’s legacy of directional statistics, and beyond to statistics on manifolds},
  volume       = {207},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sequential estimation of high-dimensional signal plus noise
models under general elliptical frameworks. <em>JOMA</em>, <em>207</em>,
105403. (<a href="https://doi.org/10.1016/j.jmva.2024.105403">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High dimensional data analysis has attracted considerable interest and is facing new challenges, one of which is the increasingly available data with noise corrupted and in a streaming manner, such as signals and stocks. In this paper, we develop a sequential method to dynamically update the estimates of signal and noise strength in signal plus noise models. The proposed sequential method is easy to compute based on the stored statistics and the current data point. The consistency and, more importantly, the asymptotic normality of the estimators of signal strength and noise level are demonstrated for high dimensional settings under mild conditions. Simulations and real data examples are further provided to illustrate the practical utility of our proposal.},
  archive      = {J_JOMA},
  author       = {Li Yanpeng and Xie Jiahui and Zhou Guoliang and Zhou Wang},
  doi          = {10.1016/j.jmva.2024.105403},
  journal      = {Journal of Multivariate Analysis},
  month        = {5},
  pages        = {105403},
  shortjournal = {J. Multi. Anal.},
  title        = {Sequential estimation of high-dimensional signal plus noise models under general elliptical frameworks},
  volume       = {207},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-functional varying coefficient mode-based regression.
<em>JOMA</em>, <em>207</em>, 105402. (<a
href="https://doi.org/10.1016/j.jmva.2024.105402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose estimating semi-functional varying coefficient regression based on the mode value through a kernel objective function, where the bandwidth included is treated as a tuning parameter to achieve efficiency and robustness. For estimation, functional principal component basis functions are utilized to approximate the slope function and functional predictor variable, while B-spline functions are employed to approximate the varying coefficient component. Under mild regularity conditions, the convergence rates of the resulting estimators for the unknown slope function and varying coefficient are established under various cases. To numerically estimate the proposed model, we recommend employing a computationally efficient mode expectation–maximization algorithm with the aid of a Gaussian kernel. The tuning parameters are selected using the mode-based Bayesian information criterion and cross-validation procedures. Built upon the generalized likelihood technique, we further develop a goodness-of-fit test to assess the constancy of varying coefficient functions and put forward a wild bootstrap procedure for estimating the corresponding critical values. The finite sample performance of the developed estimators is illustrated through Monte Carlo simulations and real data analysis related to the Tecator data. The results produced by the propounded method are compared favorably with those obtained from alternative estimation techniques.},
  archive      = {J_JOMA},
  author       = {Tao Wang},
  doi          = {10.1016/j.jmva.2024.105402},
  journal      = {Journal of Multivariate Analysis},
  month        = {5},
  pages        = {105402},
  shortjournal = {J. Multi. Anal.},
  title        = {Semi-functional varying coefficient mode-based regression},
  volume       = {207},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-dimensional projection-based ANOVA test. <em>JOMA</em>,
<em>207</em>, 105401. (<a
href="https://doi.org/10.1016/j.jmva.2024.105401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In bioinformation and medicine, an enormous amount of high-dimensional multi-population data is collected. For the inference of several-samples mean problem, traditional tests do not perform well and many new theories mainly focus on normal distribution and low correlation assumptions. Motivated by the weighted sign test, we propose two projection-based tests which are robust against the choice of correlation matrix. One test utilizes Scheffe’s transformation to generate a group of new samples and derives the optimal projection direction. The other test is adaptive to projection direction and is generalized to the assumption of the whole elliptical distribution and independent component model. Further the theoretical properties are deduced and numerical experiments are carried out to examine the finite sample performance. They show that our tests outperform others under certain circumstances.},
  archive      = {J_JOMA},
  author       = {Weihao Yu and Qi Zhang and Weiyu Li},
  doi          = {10.1016/j.jmva.2024.105401},
  journal      = {Journal of Multivariate Analysis},
  month        = {5},
  pages        = {105401},
  shortjournal = {J. Multi. Anal.},
  title        = {High-dimensional projection-based ANOVA test},
  volume       = {207},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quadratic inference with dense functional responses.
<em>JOMA</em>, <em>207</em>, 105400. (<a
href="https://doi.org/10.1016/j.jmva.2024.105400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the challenge of estimation in the context of constant linear effect models with dense functional responses. In this framework, the conditional expectation of the response curve is represented by a linear combination of functional covariates with constant regression parameters. In this paper, we present an alternative solution by employing the quadratic inference approach, a well-established method for analyzing correlated data, to estimate the regression coefficients. Our approach leverages non-parametrically estimated basis functions, eliminating the need for choosing working correlation structures. Furthermore, we demonstrate that our method achieves a parametric n -convergence rate, contingent on an appropriate choice of bandwidth. This convergence is observed when the number of repeated measurements per trajectory exceeds a certain threshold, specifically, when it surpasses n a 0 , with n representing the number of trajectories. Additionally, we establish the asymptotic normality of the resulting estimator. The performance of the proposed method is compared with that of existing methods through extensive simulation studies, where our proposed method outperforms. Real data analysis is also conducted to demonstrate the proposed method.},
  archive      = {J_JOMA},
  author       = {Pratim Guha Niyogi and Ping-Shou Zhong},
  doi          = {10.1016/j.jmva.2024.105400},
  journal      = {Journal of Multivariate Analysis},
  month        = {5},
  pages        = {105400},
  shortjournal = {J. Multi. Anal.},
  title        = {Quadratic inference with dense functional responses},
  volume       = {207},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the consistency of the jackknife estimator of the
asymptotic variance of spatial median. <em>JOMA</em>, <em>207</em>,
105399. (<a href="https://doi.org/10.1016/j.jmva.2024.105399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is shown that the usual delete-1 jackknife variance estimator of the asymptotic variance of spatial median is consistent. This is proved under the assumptions that the dimension of the data d ≥ 3 , the sampled distribution possesses a density with respect to the Lebesgue measure and this density is bounded on every bounded subset of R d .},
  archive      = {J_JOMA},
  author       = {František Rublík},
  doi          = {10.1016/j.jmva.2024.105399},
  journal      = {Journal of Multivariate Analysis},
  month        = {5},
  pages        = {105399},
  shortjournal = {J. Multi. Anal.},
  title        = {On the consistency of the jackknife estimator of the asymptotic variance of spatial median},
  volume       = {207},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jomp---7">JOMP - 7</h2>
<ul>
<li><details>
<summary>
(2025). Conjugate bayesian analysis of the wald model: On an exact
drift-rate posterior. <em>JOMP</em>, <em>124</em>, 102904. (<a
href="https://doi.org/10.1016/j.jmp.2025.102904">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In cognitive psychology, simple response times are often modeled as the time required by a one-dimensional Wiener process with drift to first reach a given threshold. This stochastic process’s first-passage time follows a Wald distribution, which is a specific parameterization of the inverse-Gaussian distribution. It can be shown that the Gaussian-Gamma distribution is a conjugate prior with respect to an inverse-Gaussian likelihood, albeit under a parameterization different from that of the Wald distribution. This leads to a posterior distribution that does not directly correspond to the core parameters of the Wiener process; that is, the drift-rate and the threshold parameter. While the marginal threshold posterior under a Gaussian-Gamma prior is relatively easy to derive and turns out to be a known distribution, this is not the case for the marginal drift-rate posterior. The present work addresses this issue by providing the exact marginal posterior distributions of the drift-rate parameter under a Gaussian-Gamma prior—something that has not yet been done in the literature. Unfortunately, the probability density function of this distribution cannot be expressed in terms of elementary functions. Thus, different methods of approximation are discussed as an expedient for time-critical applications.},
  archive      = {J_JOMP},
  author       = {Constantin G. Meyer-Grant},
  doi          = {10.1016/j.jmp.2025.102904},
  journal      = {Journal of Mathematical Psychology},
  month        = {3},
  pages        = {102904},
  shortjournal = {J. Math. Psychol.},
  title        = {Conjugate bayesian analysis of the wald model: On an exact drift-rate posterior},
  volume       = {124},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic models of delay discounting: “Fixed-endpoint”
psychometric curves improve plausibility and performance. <em>JOMP</em>,
<em>124</em>, 102902. (<a
href="https://doi.org/10.1016/j.jmp.2025.102902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic models of delay discounting allow the estimation of discount functions without prescribing unrealistically sharp boundaries in decision making. However, existing probabilistic models have two implausible implications: first, that no reward is sometimes preferred over some reward (e.g., $0 now over $100 in 1 year), and second, that the same reward is sometimes preferred later rather than sooner (e.g., $100 in a year over $100 now). We introduce a class of “fixed-endpoint” models that assign these edge cases a probability of 0. We find that these outperform conventional models across a range of discount functions using nonlinear regression. We also introduce a series of generalized linear models that implicitly parameterize various discount functions, and demonstrate the same result for these.},
  archive      = {J_JOMP},
  author       = {Isaac Kinley and Joseph Oluwasola and Suzanna Becker},
  doi          = {10.1016/j.jmp.2025.102902},
  journal      = {Journal of Mathematical Psychology},
  month        = {3},
  pages        = {102902},
  shortjournal = {J. Math. Psychol.},
  title        = {Probabilistic models of delay discounting: “Fixed-endpoint” psychometric curves improve plausibility and performance},
  volume       = {124},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Choosing is losing: How opportunity cost influences
valuations and choice. <em>JOMP</em>, <em>124</em>, 102901. (<a
href="https://doi.org/10.1016/j.jmp.2025.102901">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a model of choice that accounts for opportunity costs actually suffered, as a result of renouncing the alternative not chosen. The valuation of each option is relative: The decision maker subtracts from the standard utility of any given option the psychological cost of giving up the alternative. In the presence of a default option, the final inclination of a person is the net effect of a ‘conservative’ disposition to keep the default and an ‘adventurous’ disposition toward choosing an alternative. This trait-like inclination is captured by the difference in sensitivity to giving up the default option or its alternative(s). When the options have elements in common, the conservative and adventurous dispositions operate only on their distinguishing elements. Unlike previous conceptualizations of anticipated regret, our decision maker suffers most when the foregone option is of comparable value to the chosen one. Our model can explain the empirical regularity that faced with the same choice, some people tend to favor the default option (a form of endowment effect), while others tend to favor its alternative (a form of fear of missing out). In the presence of several alternatives, the decision maker compares the default option with the best option among the alternatives.},
  archive      = {J_JOMP},
  author       = {Tomás Lejarraga and József Sákovics},
  doi          = {10.1016/j.jmp.2025.102901},
  journal      = {Journal of Mathematical Psychology},
  month        = {3},
  pages        = {102901},
  shortjournal = {J. Math. Psychol.},
  title        = {Choosing is losing: How opportunity cost influences valuations and choice},
  volume       = {124},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A class of random utility models yielding the exploded
logit. <em>JOMP</em>, <em>124</em>, 102900. (<a
href="https://doi.org/10.1016/j.jmp.2025.102900">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We reexamine a family of distributions introduced within the framework of random utility models by David Strauss. This family generates ranking probabilities of the exploded logit model and, de facto, the choice probabilities of the multinomial logit model. We explore the necessary and sufficient conditions for its validity within the copula theory. By specifying the minimal assumptions required for the support of the marginal utility distributions, we clarify and reinforce the fundamental structure of the model, proving that it relies on strict archimedean copulas. Additionally, we provide a new mathematical proof by induction on the number of alternatives confirming that these utility distributions indeed generate the exploded logit model.},
  archive      = {J_JOMP},
  author       = {Karim Kilani},
  doi          = {10.1016/j.jmp.2025.102900},
  journal      = {Journal of Mathematical Psychology},
  month        = {3},
  pages        = {102900},
  shortjournal = {J. Math. Psychol.},
  title        = {A class of random utility models yielding the exploded logit},
  volume       = {124},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysing the bias introduced by adaptive designs to
estimates of psychometric functions. <em>JOMP</em>, <em>124</em>,
102899. (<a href="https://doi.org/10.1016/j.jmp.2025.102899">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An adaptive design adjusts dynamically as information is accrued. In psychometrics and psychophysics, a class of studies investigates a subject’s ability to perform tasks as a function of the stimulus intensity, ie the amount or clarity of information supplied for the task. The relationship between performance and intensity is represented by a psychometric function. Such experiments routinely apply adaptive designs using both previous intensities and performance to assign stimulus intensities, the strategy being to sample intensities where information about the psychometric function is maximised. We investigate the influence of adaptation on statistical inference about the psychometric function focusing on estimation, considering parametric and non-parametric estimation under both fixed and adaptive designs and under within-subject independence as well as dependence. We study the scenarios analytically and numerically through a simulation study. We show that while asymptotic properties of estimators are preserved under adaptation, the adaptive nature of the design introduces small-sample bias, in particular in the slope parameter of the psychometric function. We supply an explanation of this phenomenon that formalises and supplements the one found in the literature. We argue that this poses a dilemma for studies applying an adaptive design in the form of a trade-off between more efficient sampling and the need to increase the number of samples to ameliorate small-sample bias.},
  archive      = {J_JOMP},
  author       = {Simon Bang Kristensen and Katrine Bødkergaard and Bo Martin Bibby},
  doi          = {10.1016/j.jmp.2025.102899},
  journal      = {Journal of Mathematical Psychology},
  month        = {3},
  pages        = {102899},
  shortjournal = {J. Math. Psychol.},
  title        = {Analysing the bias introduced by adaptive designs to estimates of psychometric functions},
  volume       = {124},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dimensions of knowledge structures. <em>JOMP</em>,
<em>124</em>, 102898. (<a
href="https://doi.org/10.1016/j.jmp.2024.102898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A knowledge structure is inherently one-dimensional when its collection of states forms a chain. But how to define the dimension of a knowledge structure in general? We investigate four options: (i) the ordinal dimension , which is the dimension of the poset consisting of all states ordered by inclusion; (ii) for a knowledge space, the spatial dimension which is the least number of one-dimensional knowledge spaces which generate the space (a notion extending from learning spaces to knowledge spaces the dual of the convex dimension of an antimatroid); (iii) the bidimension , which is the bidimension of the membership relation from items to states, in either the intersection or the union version of the bidimension. Our results establish or disprove inequalities among the four dimension parameters for knowledge structures, for knowledge spaces, for terse knowledge structures, for terse knowledge spaces, and finally for learning spaces. We finally list some problems for future research.},
  archive      = {J_JOMP},
  author       = {Jean-Paul Doignon and Luca Stefanutti},
  doi          = {10.1016/j.jmp.2024.102898},
  journal      = {Journal of Mathematical Psychology},
  month        = {3},
  pages        = {102898},
  shortjournal = {J. Math. Psychol.},
  title        = {Dimensions of knowledge structures},
  volume       = {124},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Characterizing master fringes in competence-based knowledge
space theory for personalized learning applications. <em>JOMP</em>,
<em>124</em>, 102897. (<a
href="https://doi.org/10.1016/j.jmp.2024.102897">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a general method to directly compute the outer (inner) master fringe of the knowledge state based on the top or bottom of the equivalence class of competence state, and a general method for personalized learning guidance (reinforcement learning recommendation) based on competences and the master fringe. Two characterization theorems are mainly given: one characterizes the top (bottom) of competence states using skill functions; the other characterizes the outer (inner) master fringe of knowledge states using problem functions. As applications of two characterization theorems, the first is to provide a new method to directly obtain the corresponding competence state’s top or bottom from the knowledge state. The second application is to integrate skills into the competence-based master fringe, which takes into account the influence of students’ latent competences, resulting in more precise values.},
  archive      = {J_JOMP},
  author       = {Gongxun Wang and Jinjin Li and Bo Wang and Chenyi Tao},
  doi          = {10.1016/j.jmp.2024.102897},
  journal      = {Journal of Mathematical Psychology},
  month        = {3},
  pages        = {102897},
  shortjournal = {J. Math. Psychol.},
  title        = {Characterizing master fringes in competence-based knowledge space theory for personalized learning applications},
  volume       = {124},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jpdc---9">JPDC - 9</h2>
<ul>
<li><details>
<summary>
(2025). Front matter 1 - full title page (regular issues)/special
issue title page (special issues). <em>JPDC</em>, <em>199</em>, 105060.
(<a href="https://doi.org/10.1016/S0743-7315(25)00027-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JPDC},
  doi          = {10.1016/S0743-7315(25)00027-9},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {5},
  pages        = {105060},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {Front matter 1 - full title page (regular issues)/Special issue title page (special issues)},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DePoL: Assuring training integrity in collaborative learning
via decentralized verification. <em>JPDC</em>, <em>199</em>, 105056. (<a
href="https://doi.org/10.1016/j.jpdc.2025.105056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative learning enables multiple participants to jointly train complex models but is vulnerable to attacks like model poisoning or backdoor attacks. Ensuring training integrity can prevent these threats by blocking any tampered contributions from affecting the model. However, traditional approaches often suffer from single points of bottleneck or failure in decentralized environments. To address these issues, we propose DePoL , a secure, scalable, and efficient decentralized verification framework based on duplicated execution. DePoL leverages blockchain to distribute the verification tasks across multiple participant-formed groups, eliminating single-point bottlenecks. Within each group, redundant verification and a majority-based arbitration prevent single points of failure. To further enhance security, DePoL introduces a two-stage plagiarism-free commitment scheme to prevent untrusted verifiers from exploiting public on-chain data. Additionally, a hybrid verification method employs fuzzy matching to handle unpredictable reproduction errors, while a “slow path” ensures zero false positives for honest trainers. Our theoretical analysis demonstrates DePoL &#39;s security and termination properties. Extensive evaluations show that DePoL has overhead similar to common distributed machine learning algorithms, while outperforming centralized verification schemes in scalability, reducing training latency by up to 46%. Additionally, DePoL effectively handles reproduction errors with 0 false positives.},
  archive      = {J_JPDC},
  author       = {Zhicheng Xu and Xiaoli Zhang and Xuanyu Yin and Hongbing Cheng},
  doi          = {10.1016/j.jpdc.2025.105056},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {5},
  pages        = {105056},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {DePoL: Assuring training integrity in collaborative learning via decentralized verification},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Massive parallel simulation of gas turbine combustion using
a fully implicit unstructured solver on the heterogeneous sunway
taihulight supercomputer. <em>JPDC</em>, <em>199</em>, 105055. (<a
href="https://doi.org/10.1016/j.jpdc.2025.105055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Massive parallel simulations of a full annular aeroengine combustor chamber have been achieved on the on-chip heterogeneous Sunway Taihulight supercomputer. A billion-size unstructured mesh is generated through grid replication and rotation, accompanied by the development of an efficient geometric matching algorithm to address the conformal interface issue. We developed graph-based and tree-based loop fusion approaches for implicit solving procedure of the momentum equation, it is found that the strategic utilization of data reuse and separation of vector computation significantly enhances the performance on many-core processor. For linear system, a finer-grained parallelization based on sparse matrix-vector multiplication and vector computation is validated. Massive parallel tests utilizing 16 K processes with 1 M cores are successfully conducted to simulate the turbulent non-premixed combustion in an aeroengine combustor with nearly one billion cells. Compared to the pre-optimization version, this fully accelerated code achieves an impressive 5.48 times speedup in overall performance, with a parallel efficiency of up to 59 %.},
  archive      = {J_JPDC},
  author       = {Fei Gao and Hu Ren and Zhuyin Ren and Ming Liu and Chengpeng Zhao and Guangwen Yang},
  doi          = {10.1016/j.jpdc.2025.105055},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {5},
  pages        = {105055},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {Massive parallel simulation of gas turbine combustion using a fully implicit unstructured solver on the heterogeneous sunway taihulight supercomputer},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient GPU-accelerated parallel cross-correlation.
<em>JPDC</em>, <em>199</em>, 105054. (<a
href="https://doi.org/10.1016/j.jpdc.2025.105054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-correlation is a data analysis method widely employed in various signal processing and similarity-search applications. Our objective is to design a highly optimized GPU-accelerated implementation that will speed up the applications and also improve energy efficiency since GPUs are more efficient than CPUs in data-parallel tasks. There are two rudimentary ways to compute cross-correlation — a definition-based algorithm that tries all possible overlaps and an algorithm based on the Fourier transform, which is much more complex but has better asymptotical time complexity. We have focused mainly on the definition-based approach which is better suited for smaller input data and we have implemented multiple CUDA-enabled algorithms with multiple optimization options. The algorithms were evaluated on various scenarios, including the most typical types of multi-signal correlations, and we provide empirically verified optimal solutions for each of the studied scenarios.},
  archive      = {J_JPDC},
  author       = {Karel Maděra and Adam Šmelko and Martin Kruliš},
  doi          = {10.1016/j.jpdc.2025.105054},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {5},
  pages        = {105054},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {Efficient GPU-accelerated parallel cross-correlation},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GPU memory usage optimization for backward propagation in
deep network training. <em>JPDC</em>, <em>199</em>, 105053. (<a
href="https://doi.org/10.1016/j.jpdc.2025.105053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern Deep Learning, it has been a trend to design larger Deep Neural Networks (DNNs) for the execution of more complex tasks and better accuracy. On the other hand, Convolutional Neural Networks (CNNs) have become the standard method for most of computer vision tasks. However, the memory allocation for the intermediate data in convolution layers can cause severe memory pressure during model training. Many solutions have been proposed to resolve the problem. Besides hardware-dependent solutions, a general methodology rematerialization can reduce GPU memory usage by trading computation for memory efficiently. The idea is to select a set of intermediate results during the forward phase as checkpoints , and only save them in memory to reduce memory usage. The backward phase recomputes the intermediate data from the closest checkpoints in memory as needed. This recomputation increases execution time but saves memory by not storing all intermediate results in memory during the forward phase. In this paper, we will focus on efficiently finding the optimal checkpoint subset to achieve the least peak memory usage during the model training. We first describe the theoretical background of the training of a neural network using mathematical equations. We use these equations to identify all essential data required during both forward and backward phases to compute the gradient of weights of the model. We first identify the checkpoint selection problem and propose a dynamic programming algorithm with time complexity O ( n 3 ) to solve the problem of finding the optimal checkpoint subset. With extensive experiments, we formulate a more accurate description of the problem using our theoretical analysis and revise the objective function based on the tracing, and propose an O ( n ) -time algorithm for finding the optimal checkpoint subset.},
  archive      = {J_JPDC},
  author       = {Ding-Yong Hong and Tzu-Hsien Tsai and Ning Wang and Pangfeng Liu and Jan-Jan Wu},
  doi          = {10.1016/j.jpdc.2025.105053},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {5},
  pages        = {105053},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {GPU memory usage optimization for backward propagation in deep network training},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An introductory-level undergraduate CS course that
introduces parallel computing. <em>JPDC</em>, <em>199</em>, 105044. (<a
href="https://doi.org/10.1016/j.jpdc.2025.105044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present the curricular design, pedagogy, and goals of an introductory-level course on computer systems that introduces parallel and distributed computing (PDC) to students who have only a CS1 background. With the ubiquity of multicore processors, cloud computing, and hardware accelerators, PDC topics have become fundamental knowledge areas in the undergraduate CS curriculum. As a result, it is increasingly important for students to learn a common core of introductory parallel and distributed computing topics and to develop parallel thinking skills early in their CS studies. Our introductory-level course focuses on three main curricular goals: 1) understanding how a computer runs a program, 2) evaluating system costs associated with running a program, and 3) taking advantage of the power of parallel computing. We elaborate on the goals and details of our course&#39;s key modules, and we discuss our pedagogical approach that includes active-learning techniques. We also include an evaluation of our course and a discussion of our experiences teaching it since Fall 2012. We find that the PDC foundation gained through early exposure in our course helps students gain confidence in their ability to expand and apply their understanding of PDC concepts throughout their CS education.},
  archive      = {J_JPDC},
  author       = {Tia Newhall and Kevin C. Webb and Vasanta Chaganti and Andrew Danner},
  doi          = {10.1016/j.jpdc.2025.105044},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {5},
  pages        = {105044},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {An introductory-level undergraduate CS course that introduces parallel computing},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DRViT: A dynamic redundancy-aware vision transformer
accelerator via algorithm and architecture co-design on FPGA.
<em>JPDC</em>, <em>199</em>, 105042. (<a
href="https://doi.org/10.1016/j.jpdc.2025.105042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-modal artificial intelligence (MAI) has attracted significant interest due to its capability to process and integrate data from multiple modalities, including images, text, and audio. Addressing MAI tasks in distributed systems necessitate robust and efficient architectures. The Transformer architecture has emerged as a primary network in this context. The integration of Vision Transformers (ViTs) within multimodal frameworks is crucial for enhancing the processing and comprehension of image data across diverse modalities. However, the complex architecture of ViTs and the extensive resources required for processing large-scale image data pose high computational and storage demands. These demands are particularly challenging for deploying ViTs on edge devices within distributed frameworks. To address this issue, we propose a novel dynamic redundancy-aware ViT accelerator based on parallel computing, termed DRViT. DRViT is supported by an algorithm and architecture co-design. We first propose a hardware-friendly lightweight algorithm featuring token merging, token pruning, and an INT8 quantization scheme. Then, we design a specialized architecture to support this algorithm, transforming the lightweight algorithm into significant latency and energy-efficiency improvements. Our design is implemented on the Xilinx Alveo U250, achieving an overall inference latency of 0.86 ms and 1.17 ms per image for ViT-tiny at 140 MHz and 100 MHz, respectively. The throughput can reach 1,380 GOP/s at peak, demonstrating superior performance compared to state-of-the-art accelerators, even at lower frequencies.},
  archive      = {J_JPDC},
  author       = {Xiangfeng Sun and Yuanting Zhang and Qinyu Wang and Xiaofeng Zou and Yujia Liu and Ziqian Zeng and Huiping Zhuang},
  doi          = {10.1016/j.jpdc.2025.105042},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {5},
  pages        = {105042},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {DRViT: A dynamic redundancy-aware vision transformer accelerator via algorithm and architecture co-design on FPGA},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Latency-aware placement of stream processing operators in
modern-day stream processing frameworks. <em>JPDC</em>, <em>199</em>,
105041. (<a href="https://doi.org/10.1016/j.jpdc.2025.105041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise of the Internet of Things has substantially increased the number of interconnected devices at the edge of the network. As a result, a large number of computations are now distributed in the compute continuum, spanning from the edge to the cloud, generating vast amounts of data. Stream processing is typically employed to process this data in near real-time due to its efficiency in handling continuous streams of information in a scalable manner. However, many stream processing approaches do not consider the underlying network devices of the compute continuum as candidate resources for processing data. Moreover, many existing works do not consider the incurred network latency of performing computations on multiple devices in a distributed way. To avoid this, we formulate an optimization problem for utilizing the complete compute continuum resources and design heuristics to solve this problem efficiently. Furthermore, we integrate our heuristics into Apache Storm and perform experiments that show latency- and throughput-related benefits compared to alternatives.},
  archive      = {J_JPDC},
  author       = {Raphael Ecker and Vasileios Karagiannis and Michael Sober and Stefan Schulte},
  doi          = {10.1016/j.jpdc.2025.105041},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {5},
  pages        = {105041},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {Latency-aware placement of stream processing operators in modern-day stream processing frameworks},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Skyward secure: Advancing drone data-sharing in 6G with
decentralized dataspace and supported technologies. <em>JPDC</em>,
<em>199</em>, 105040. (<a
href="https://doi.org/10.1016/j.jpdc.2025.105040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The capacity of Dataspace enables the distribution of heterogeneous data from several sources and domains and has attracted attention for resolving data integration challenges. Drone data sharing faces challenges such as protecting privacy and security, building trust and dependability, controlling latency and scalability, facilitating real-time data processing, and preserving the caliber of shared models. Therefore, sixth-generation (6G) networks provide high throughput and low latency to improve drone operations; security issues are exacerbated by the sensitive nature of shared data and the lack of centralized monitoring. To address the challenges, this paper presents a conceptual framework for a Dataspace in the Sky to enable secure and efficient drone data-sharing within 6G networks in the transition from Industry 4.0 to Industry 5.0. The Dataspace in the Sky integrates Federated Learning (FL), a decentralized Machine Learning (ML) approach that enhances security and privacy by sharing models instead of raw data, facilitating effective drone collaboration. However, the quality of shared local models often suffers due to inconsistent data contributions and unreliable recording mechanisms, which can undermine the performance of FL. To tackle the challenges, the framework employs blockchain (BC) to decentralize and secure the Dataspace, ensuring the integrity of contribution records and improving the reliability of shared models. Dataspace in the Sky empowered decentralized data sharing which addresses latency issues by decentralizing decision-making and enhances trust and reliability by leveraging immutable and transparent BC mechanisms. The robustness of Dataspace in the Sky solution is not only secures drone-sharing operations in 6G environments but enables the development of citizen-friendly mobility services, expanding opportunities across smart environments.},
  archive      = {J_JPDC},
  author       = {Saeed Hamood Alsamhi and Sumit Srivastava and Mamoon Rashid and Amnnah Alhabeeb and Santosh Kumar and Navin Singh Rajput and Ammar Hawbani and Liang Zhao and Mohammed A.A. Al-qaness and Edward Curry},
  doi          = {10.1016/j.jpdc.2025.105040},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {5},
  pages        = {105040},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {Skyward secure: Advancing drone data-sharing in 6G with decentralized dataspace and supported technologies},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jtb---7">JTB - 7</h2>
<ul>
<li><details>
<summary>
(2025). Spatio-temporal model of combining ADT and chemotherapy with
senolytic treatment in metastatic prostate cancer. <em>JTB</em>,
<em>602-603</em>, 112069. (<a
href="https://doi.org/10.1016/j.jtbi.2025.112069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prostate cancer cells depend on androgen for their survival. A standard treatment of metastatic prostate cancer (mPC) is androgen deprivation treatment (ADT). However, after a period of remission, some cancer cells changed into androgen-independent cells, and then treatment proceeds with a combination of ADT and chemotherapy. Senescent cells are cells that stop dividing but sustain viability. Senescence cancer cells are common in cancer, and they affect cancer treatment negatively by secreting inflammatory cytokines and pro-cancer VEGF. In this paper, we include the effect of senescence in a model of mPC. We consider combinations of ADT, chemotherapy, and senolytic drug, which eliminate senescent cells, in a spatio-temporal partial differential equations model, and demonstrate that simulations of the model are in agreement with experimental results. We evaluate the synergy between different doses of chemotherapy and senolytic drugs, at different fixed doses of ADT. We also consider optimal scheduling of the drugs, and the hypothesis that, in optimal schedule, a senolytic drug is to be administered immediately following the chemotherapy drug.},
  archive      = {J_JTB},
  author       = {Teddy Lazebnik and Avner Friedman},
  doi          = {10.1016/j.jtbi.2025.112069},
  journal      = {Journal of Theoretical Biology},
  month        = {4},
  pages        = {112069},
  shortjournal = {J. Theor. Biol},
  title        = {Spatio-temporal model of combining ADT and chemotherapy with senolytic treatment in metastatic prostate cancer},
  volume       = {602-603},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The effect of heterogeneity of relative vaccine costs on the
mean population vaccination rate with mpox as an example. <em>JTB</em>,
<em>602-603</em>, 112062. (<a
href="https://doi.org/10.1016/j.jtbi.2025.112062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mpox (formerly known as monkeypox) is a neglected tropical disease that became notorious during its 2022–2023 worldwide outbreak. The vaccination was available, but there were inequities in vaccine access. In this paper, we extend existing game-theoretic models to study a population that is heterogeneous in the relative vaccination costs. We consider a population with two groups. We determine the Nash equilibria (NE), i.e., optimal vaccination rates, for each of the groups. We show that the NE always exists and that, for a narrow range of parameter values, there can be multiple NEs. We focus on comparing the mean optimal vaccination rate in the heterogeneous population with the optimal vaccination rate in the corresponding homogeneous population. We show that there is a critical size for the group with lower relative costs and the mean optimal vaccination in the heterogeneous population is more than in the homogeneous population if and only if the group is larger than the critical size.},
  archive      = {J_JTB},
  author       = {Spalding Garakani and Luis Flores and Guillermo Alvarez-Pardo and Jan Rychtář and Dewey Taylor},
  doi          = {10.1016/j.jtbi.2025.112062},
  journal      = {Journal of Theoretical Biology},
  month        = {4},
  pages        = {112062},
  shortjournal = {J. Theor. Biol},
  title        = {The effect of heterogeneity of relative vaccine costs on the mean population vaccination rate with mpox as an example},
  volume       = {602-603},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient coupling of within-and between-host infectious
disease dynamics. <em>JTB</em>, <em>602-603</em>, 112061. (<a
href="https://doi.org/10.1016/j.jtbi.2025.112061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mathematical models of infectious disease transmission typically neglect within-host dynamics. Yet within-host dynamics – including pathogen replication, host immune responses, and interactions with microbiota – are crucial not only for determining the progression of disease at the individual level, but also for driving within-host evolution and onwards transmission, and therefore shape dynamics at the population level. Various approaches have been proposed to model both within- and between-host dynamics, but these typically require considerable simplifying assumptions to couple processes at contrasting scales (e.g., the within-host dynamics quickly reach a steady state) or are computationally intensive. Here we propose a novel, readily adaptable and broadly applicable method for modelling both within- and between-host processes which can fully couple dynamics across scales and is both realistic and computationally efficient. By individually tracking the deterministic within-host dynamics of infected individuals, and stochastically coupling these to continuous host state variables at the population-level, we take advantage of fast numerical methods at both scales while still capturing individual transient within-host dynamics and stochasticity in transmission between hosts. Our approach closely agrees with full stochastic individual-based simulations and is especially useful when the within-host dynamics do not rapidly reach a steady state or over longer timescales to track pathogen evolution. By applying our method to different pathogen growth scenarios we show how common simplifying assumptions fundamentally change epidemiological and evolutionary dynamics.},
  archive      = {J_JTB},
  author       = {Cameron A. Smith and Ben Ashby},
  doi          = {10.1016/j.jtbi.2025.112061},
  journal      = {Journal of Theoretical Biology},
  month        = {4},
  pages        = {112061},
  shortjournal = {J. Theor. Biol},
  title        = {Efficient coupling of within-and between-host infectious disease dynamics},
  volume       = {602-603},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Age-dependence of food allergy due to decreased supply of
naïve t cells. <em>JTB</em>, <em>602-603</em>, 112060. (<a
href="https://doi.org/10.1016/j.jtbi.2025.112060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Food allergies to eggs and cow’s milk are common during infancy but often undergo desensitization during childhood. To investigate the age dependence of food allergies, we develop a simple mathematical model focusing on T helper 2 cells (Th2) causing allergies and induced regulatory T cells (iTreg) suppressing them. We assume as follows: Both types of cells differentiate from naïve T cells reactive to specific food allergens, with the rate of supply from the thymus decreasing with age. Naïve T cells are activated by allergens in peripheral tissues, differentiating into both Th2 and iTreg cells. The activation rate of Th2 cells is reduced by iTreg cells. Th2 cells promote allergies while iTreg cells help mitigate them. Analyses show that food allergies may develop at one age and resolve at a later age. Negative selection in the thymus reduces the number of naïve T cells that react to proteins resembling components of the body. As a result, allergies to these substances tend to start and resolve earlier in life than those to dissimilar materials. Food allergy starting at an older age tends to have a longer duration if the rate of naïve T cell supply decreases according to a hyperbolic (instead of exponential) function of age.},
  archive      = {J_JTB},
  author       = {Yuna Kotsubo and Akane Hara and Rena Hayashi and Yoh Iwasa},
  doi          = {10.1016/j.jtbi.2025.112060},
  journal      = {Journal of Theoretical Biology},
  month        = {4},
  pages        = {112060},
  shortjournal = {J. Theor. Biol},
  title        = {Age-dependence of food allergy due to decreased supply of naïve t cells},
  volume       = {602-603},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Possible regulatory mechanisms of typical and atypical
absence seizures through an equivalent projection from the subthalamic
nucleus to the cortex: Evidence in a computational model. <em>JTB</em>,
<em>602-603</em>, 112059. (<a
href="https://doi.org/10.1016/j.jtbi.2025.112059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The subthalamic nucleus (STN) is an important structure that regulates basal ganglia output and has been involved in the pathophysiology of epilepsy disease. In this paper, we propose an equivalent inhibitory pathway directly projecting from the STN to the cortex and systematically study its regulatory effect on absence seizures. Interestingly, we find that this equivalent inhibitory projection is a key factor for assisting in the development of atypical absence seizures. Through computational simulation and model analysis, we find that the enhancement of coupling strength on this equivalent STN-cortex projection can effectively suppress typical and atypical spike and wave discharges (TSWDs and ASWDs) during absence seizures. Furthermore, altering the activation level of STN through external stimuli can also control seizures, and the presence of equivalent STN-cortex projection makes the control effect more easier to achieve. Several direct and indirect pathways related to the STN can achieve inhibition of SWDs by regulating the activation level of STN, and relevant control strategies have high biological plausibility. Therefore, the STN may be an effective target for the deep brain stimulation (DBS) to control absence seizures. Importantly, we observe that the control effect of DBS-STN on SWDs is significantly superior to other basal ganglia targets in this model. Moreover, we find that the parameter range and value with high biological plausibility for the coupling weight in this equivalent STN-cortex projection can be effectively estimated in this model. Our results imply that the inhibitory effect from the STN to the cortex plays a crucial role in regulating both typical and atypical SWDs, and the STN might be a potential and reasonable DBS target for the treatment of absence epilepsy.},
  archive      = {J_JTB},
  author       = {Bing Hu and Yaqi Guo and JinDong Zhao and Xunfu Ma},
  doi          = {10.1016/j.jtbi.2025.112059},
  journal      = {Journal of Theoretical Biology},
  month        = {4},
  pages        = {112059},
  shortjournal = {J. Theor. Biol},
  title        = {Possible regulatory mechanisms of typical and atypical absence seizures through an equivalent projection from the subthalamic nucleus to the cortex: Evidence in a computational model},
  volume       = {602-603},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A mathematical model of microglia glucose metabolism and
lactylation with positive feedback. <em>JTB</em>, <em>602-603</em>,
112049. (<a href="https://doi.org/10.1016/j.jtbi.2025.112049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present and analyze a model for metabolism and lactylation in a single microglia. The model includes positive feedback from lactylation in the glycolytic pathway, and links metabolism and inflammation. Specific pathways include the transition of glucose to pyruvate to lactate in a microglia, as well as the gradient transport of glucose and lactate into and out of the cell. Additionally, the upregulation of certain pathways by either epigenetic modification or the inflammatory response are included. Bifurcation and sensitivity analyses demonstrate the importance of key parameters and pathways in the model, specifically the role of lactylation. Our model is validated by qualitatively reproducing recent in vitro experiments in which exogenous glucose and lactate are modified.},
  archive      = {J_JTB},
  author       = {Kamila Larripa and Anca Rǎdulescu},
  doi          = {10.1016/j.jtbi.2025.112049},
  journal      = {Journal of Theoretical Biology},
  month        = {4},
  pages        = {112049},
  shortjournal = {J. Theor. Biol},
  title        = {A mathematical model of microglia glucose metabolism and lactylation with positive feedback},
  volume       = {602-603},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simulations probe the role of space in the interplay between
drug-sensitive and drug-resistant cancer cells. <em>JTB</em>,
<em>602-603</em>, 112048. (<a
href="https://doi.org/10.1016/j.jtbi.2025.112048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interplay between drug-sensitive and drug-resistant cancer cells has been observed to impact cell-to-cell interactions in experimental settings. However, the role that space plays in these interactions remains unclear. In this study, we develop mathematical models to investigate how spatial factors affect cell-to-cell competition between drug-sensitive and drug-resistant cancer cells in silico. We develop two baseline models to study cells from the epithelial FaDu cell line subjected to two drugs, specifically the ATR inhibitor ceralasertib and the PARP inhibitor olaparib, that target DNA damage response pathways. Our baseline models are: (1) a temporally resolved ordinary differential equation (ODE) model, and (2) a spatio-temporally resolved agent-based model (ABM). The models simulate cells in well-mixed and spatially structured cell systems, respectively. The ODE model is calibrated against in vitro data and is thereafter mapped onto the baseline ABM which, in turn, is extended to enable a simulation-based investigation on how spatial factors impact cell-to-cell competition. Simulation results from the extended ABMs demonstrate that the in silico treatment responses are simultaneously affected by: (i) the initial spatial cell configurations, (ii) the initial fraction of drug-resistant cells, (iii) the drugs to which cells express resistance, (iv) drug combinations, (v) drug doses, and (vi) the doubling time of drug-resistant cells compared to the doubling time of drug-sensitive cells. These results reveal that spatial structures of the simulated cancer cells affect both cell-to-cell interactions, and the impact that these interactions have on the ensuing population dynamics. This leads us to suggest that the role that space plays in cell-to-cell interactions should be further investigated and quantified in experimental settings.},
  archive      = {J_JTB},
  author       = {Kira Pugh and Rhys D.O. Jones and Gibin Powathil and Sara Hamis},
  doi          = {10.1016/j.jtbi.2025.112048},
  journal      = {Journal of Theoretical Biology},
  month        = {4},
  pages        = {112048},
  shortjournal = {J. Theor. Biol},
  title        = {Simulations probe the role of space in the interplay between drug-sensitive and drug-resistant cancer cells},
  volume       = {602-603},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="matdes---100">MATDES - 100</h2>
<ul>
<li><details>
<summary>
(2025). Cover_252. <em>MATDES</em>, <em>252</em>, 113847. (<a
href="https://doi.org/10.1016/S0264-1275(25)00267-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MATDES},
  doi          = {10.1016/S0264-1275(25)00267-9},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113847},
  shortjournal = {Mater. Des.},
  title        = {Cover_252},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Direct evidence and kinetics of cu precipitation in the
austenite phase of a maraging stainless steel. <em>MATDES</em>,
<em>252</em>, 113835. (<a
href="https://doi.org/10.1016/j.matdes.2025.113835">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we investigate the precipitation kinetics of Cu in 15–5 PH maraging stainless steel during high-temperature thermal treatments in the fully austenitic state. This provides direct evidence that Cu precipitation can occur in the austenite phase of martensitic or ferritic steels. The kinetics of Cu precipitation in austenite are examined at 700 and 800 °C using in situ synchrotron small-angle and wide-angle X-ray scattering, complemented by atom probe tomography investigations to analyze the precipitates, particularly their chemistry, following heat treatment. The resulting experimental data, which include the evolution of size, volume fraction, number density and chemical composition, are used to inform precipitation kinetics modelling using the Langer-Schwartz-Kampmann-Wagner (LSKW) approach coupled with CALPHAD thermodynamic and kinetic databases. The simulations accurately capture the experimental data by adjusting the interfacial energy in an inverse modelling approach. The insight that Cu precipitation occurs in austenite and subsequently in martensite paves the way for design of hierarchical structures with a bi-modal particle size distribution of Cu precipitates with varying crystal structures and compositions. Additionally, the validated LSKW modelling approach establishes a foundation for designing Cu-alloyed high-performance steels, taking into account various manufacturing routes.},
  archive      = {J_MATDES},
  author       = {Tao Zhou and Gabriel Spartacus and Xiaoqing Li and Sonia Guehairia and Tim Fischer and Malte Blankenburg and Peter Hedström},
  doi          = {10.1016/j.matdes.2025.113835},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113835},
  shortjournal = {Mater. Des.},
  title        = {Direct evidence and kinetics of cu precipitation in the austenite phase of a maraging stainless steel},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Molecular dynamics and machine learning study of tensile
behavior in single-crystal tungsten containing he bubbles.
<em>MATDES</em>, <em>252</em>, 113831. (<a
href="https://doi.org/10.1016/j.matdes.2025.113831">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tungsten is commonly used in nuclear fusion plants, where irradiation defects (e.g., He bubbles) are frequently generated. This study investigates the impact of He bubbles on the tensile behavior of single-crystal tungsten through molecular dynamics (MD) simulations. The analysis considers varying He bubble sizes, He/V ratios (the number of helium atoms with respect to the number of vacancies in helium bubble), temperatures, and strain rates. The findings indicate that He bubbles significantly affect the material’s mechanical properties, with larger bubble sizes reducing tensile strength. Dislocation emission initiates from the void surface during tensile deformation. While the He/V ratio slightly influences peak stress values, it does not alter the overall stress–strain curve. Elevated temperatures lower peak stress, whereas higher strain rates increase it. Additionally, machine learning models predict the combined effects of bubble size, He/V ratio, strain rate, and temperature on the peak stress of tungsten, utilizing MD simulation data. This work offers important insights into tungsten’s behavior under irradiation conditions.},
  archive      = {J_MATDES},
  author       = {Pan-dong Lin and Yan Lin and Hong-guang Li and Shu-gang Cui and Jun-feng Nie and Bai-wen Zhong and Yu-peng Lu},
  doi          = {10.1016/j.matdes.2025.113831},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113831},
  shortjournal = {Mater. Des.},
  title        = {Molecular dynamics and machine learning study of tensile behavior in single-crystal tungsten containing he bubbles},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Microstructure and composition evolution of SPPs in the
oxide film of zr-1.0Sn-0.25Nb-0.2Fe-0.1Cr during corrosion.
<em>MATDES</em>, <em>252</em>, 113830. (<a
href="https://doi.org/10.1016/j.matdes.2025.113830">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The microstructure and composition evolution of SPPs in the oxide film of Zr-1.0Sn-0.25Nb-0.2Fe-0.1Cr alloy during aqueous corrosion at 360 °C is investigated by HRTEM. The results show that SPPs with their distances to the O-M interface less than 500 nm remain metallic and exhibit similar structure and composition as those in Zr matrix. However, the SPPs with their distances to the O-M interface more than 1 μm exhibit obvious oxidation, characterized by the high O content and the appearance of the oxides of Fe, Cr and Zr inside the SPPs. The cracks connected to the SPPs could provide a good O supply and enhance the oxidation of the SPPs. Such cracks also promote the outwards diffusion of Fe and Cr from the SPPs during oxidation. In the oxidized Zr(FeCrNb) 2 particles, Fe has a faster outwards diffusion rate than Cr, while Nb seems to be almost immobile. Under certain conditions, small oxidized SPPs will leave porous regions within the oxide film locally. Tetragonal ZrO 2 is observed occasionally nearby the oxidized SPPs, which is thought to be caused by the doping effect of Fe depleted from the dissolved SPPs.},
  archive      = {J_MATDES},
  author       = {Tianguo Wei and Xun Dai and Yi Zhao and Dong Wang and Yufeng Du and JiYun Zheng and Chongsheng Long and Chao Sun},
  doi          = {10.1016/j.matdes.2025.113830},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113830},
  shortjournal = {Mater. Des.},
  title        = {Microstructure and composition evolution of SPPs in the oxide film of zr-1.0Sn-0.25Nb-0.2Fe-0.1Cr during corrosion},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Geometric design and mechanical performance of isotropic
bone scaffolds. <em>MATDES</em>, <em>252</em>, 113829. (<a
href="https://doi.org/10.1016/j.matdes.2025.113829">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bone tissue engineering scaffolds with reduced elastic anisotropy, enhanced mechanical performance, and high ratio of surface to volume are continuous pursuits. In this work, a mechanical metamaterial design strategy for isotropic bone scaffolds is proposed. The design of isotropic bone scaffolds is realized by interactive clipping of the lattice structure without nesting and complex adjustments. Employing homogenization, elastic stiffness tensors were estimated to evaluate the anisotropic measure, according to Zener ratio and elastic modulus. The designed scaffolds have a Zener ratio of nearly 1.0 and an increase of 20 % in stiffness over the pristine lattice. Quasi-static compression experiments were performed to investigate the Ti4Al6V scaffolds fabricated by selective laser melting, and the results showed that the isotropic scaffolds had compressive strengths of 100.59–198.53 MPa and stiffnesses of 1.86–4.88 GPa, which met the requirements for bone implants. Finite element simulations further revealed the structure’s mechanical response mechanism. Computational fluid dynamics results demonstrated that the structure’s permeability of 8.56 × 10 −9 -1.29 × 10 −8 m 2 , matches well with the requirements of human trabecular bone. Its large surface area facilitates osteogenic differentiation and enhances osseointegration. This study has important contribution in overcoming the constraints in the clinical applications of bone tissue engineering scaffolds.},
  archive      = {J_MATDES},
  author       = {Rongwei Xu and Zhou Zhang and Zhen Peng and Fuyuan Deng and Zhong Li and Xu Liu and Liang He},
  doi          = {10.1016/j.matdes.2025.113829},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113829},
  shortjournal = {Mater. Des.},
  title        = {Geometric design and mechanical performance of isotropic bone scaffolds},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mechanisms of in-situ polymerization for enhancing washout
resistance of cement paste. <em>MATDES</em>, <em>252</em>, 113825. (<a
href="https://doi.org/10.1016/j.matdes.2025.113825">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional concrete is generally unsuitable for underwater construction, typically requiring the addition of anti-washout admixtures (AWAs) to improve its washout resistance. Herein, we demonstrate the enhancement of cement paste washout resistance through the in-situ polymerization of acrylamide (AM) and sodium acrylate (SA) and elucidate the underlying mechanisms. Macroscopic experiments reveal a significant improvement, with washout loss reduced to 12 % and 2 % of that observed in REF at 60 min for cement pastes modified by the in-situ polymerization of AM and SA, respectively. This enhancement is attributed to the formation of a more flocculated microstructure, where smaller flocs agglomerate into larger ones due to increased floc strength induced by the bridging effect of the resultant polymers. Consequently, flocs in cement pastes with in-situ polymerized SA exhibit higher strength and a denser structure, with a fractal dimension ( D f ) exceeding 2.00, shifting the floc break mode from surface erosion to large-scale fragmentation and thereby improving washout resistance. Nevertheless, the in-situ polymerization of both AM and SA retards cement hydration, albeit through distinct mechanisms: the non-adsorbing PAM molecules primarily hinder the nucleation and formation of hydration products, whereas the adsorbed PAAS molecules predominantly inhibit the dissolution of aqueous species.},
  archive      = {J_MATDES},
  author       = {Zhaoyang Sun and Ming Sun and Dongshuai Hou and Binmeng Chen},
  doi          = {10.1016/j.matdes.2025.113825},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113825},
  shortjournal = {Mater. Des.},
  title        = {Mechanisms of in-situ polymerization for enhancing washout resistance of cement paste},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). In-situ alloying of nonequiatomic TiNbMoTaW refractory
bio-high entropy alloy via laser powder bed fusion: Achieving suppressed
microsegregation and texture formation. <em>MATDES</em>, <em>252</em>,
113824. (<a href="https://doi.org/10.1016/j.matdes.2025.113824">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-entropy alloys (HEAs) have attracted considerable attention owing to their excellent properties. However, the severe segregation of the constituent elements remains a common challenge in refractory HEAs. Recently, an approach to suppress segregation was proposed using laser powder bed fusion (LPBF) owing to the ultra-high cooling rates during solidification. Despite the advantages of LPBF, the persistent microsegregation between the dendritic and interdendritic regions of refractory HEAs and costly gas atomization process hinder the further development. To address these challenges, a novel nonequiatomic TiNbMoTaW refractory HEA was designed to minimize the difference between the liquidus and solidus temperatures to prevent segregation and phase separation for a better biological performance. In-situ alloying was implemented instead of costly and time-consuming gas atomization process. The segregation of constituent elements was suppressed by remelting, resulted in epitaxial growth and development of crystallographic texture, consequently reducing residual stress. The mechanical properties were improved due to the increase of solid solution strengthening and densification. It showed superior mechanical strength and equivalent biocompatibility compared to conventional biomaterials, indicating its superiority as a biomaterial. This study represents the first successful control of crystallographic texture through in-situ alloying of BioHEAs for next-generation biomaterials.},
  archive      = {J_MATDES},
  author       = {Yong Seong Kim and Ozkan Gokcekaya and Kazuhisa Sato and Ryosuke Ozasa and Aira Matsugaki and Takayoshi Nakano},
  doi          = {10.1016/j.matdes.2025.113824},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113824},
  shortjournal = {Mater. Des.},
  title        = {In-situ alloying of nonequiatomic TiNbMoTaW refractory bio-high entropy alloy via laser powder bed fusion: Achieving suppressed microsegregation and texture formation},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel concept for self-healing metallic structural
materials: Internal soldering of damage using low melting eutectics.
<em>MATDES</em>, <em>252</em>, 113821. (<a
href="https://doi.org/10.1016/j.matdes.2025.113821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel self-healing concept for metallic structural materials based on internal soldering using low-melting constituents is presented. The proof-of-principle study is based on a binary Al–4.28 wt%-Sn alloy, where a Sn-rich eutectic with a liquidus temperature of 228 °C acts as a self-assembling healing agent, and validated by a two-pronged approach: (i) A bulk sample with artificial damage is exploited to evaluate the healing effect on large cracks open to the sample surface and to gauge its mechanical effectiveness, whereas (ii) a 3.5 µm-thick Al 2 O 3 -Al-Sn-Al thin film multilayer architecture was used as a model system to study the healing mechanisms of small-scale internal damage induced by bending of the brittle Al 2 O 3 layer. A crack length of ∼1.6 mm could be successfully re-filled by the low-melting eutectic with a simple annealing treatment at 400 °C for 30 min, which increased the bulk tensile ductility to more than 120 % compared to a similarly damaged pure Al sample. Furthermore, it is shown that the dispersion of the Sn-rich eutectic can be effectively controlled by utilising the polymorphy of Sn during material production. Alloy design perspectives for translating these findings towards industrial materials and applications are outlined and discussed.},
  archive      = {J_MATDES},
  author       = {L. Tanure and L. Patterer and S. Balakumar and M. Fekete and S. Mráz and S. Karimi Aghda and M. Hans and J.M. Schneider and H. Springer},
  doi          = {10.1016/j.matdes.2025.113821},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113821},
  shortjournal = {Mater. Des.},
  title        = {A novel concept for self-healing metallic structural materials: Internal soldering of damage using low melting eutectics},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing the efficiency of luminescent solar concentrators
via soft colloidal lithography negative templating. <em>MATDES</em>,
<em>252</em>, 113817. (<a
href="https://doi.org/10.1016/j.matdes.2025.113817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building-integrated photovoltaics (BIPV) offers a sustainable pathway by seamlessly incorporating PV cells into architectural elements like façades and windows. In this study, we investigate the potential of luminescent down-shifting solar concentrators in combination with a nanophotonic light-trapping scheme to improve the optical-guiding capabilities and thereby enhance the energy conversion efficiency. We propose a novel cost-effective method to fabricate the photonic structures via soft colloidal lithography negative templating of thin films of TiO 2 nanoparticles, successfully scaling the production to 11x11 cm 2 glass windows. Through simulations and optical-electrical characterization, we demonstrate substantial improvements in energy harvesting for different angles of solar irradiation. We found increases in power output ranging from 57% for angles of incidence below 45° to above 100% for 60° thanks to the nanostructured TiO 2 nanoparticles coatings added to a bottom down-shifting layer. This shows that such integrated approach can enhance both the efficiency and aesthetic appeal of solar solutions in urban environments, advancing the design of energy-efficient, sustainable buildings. Our methodology ensures consistent solar energy capture all year-round, for the relevant range of sunlight incidence angles, while preserving the transparency and multifunctionality of building elements.},
  archive      = {J_MATDES},
  author       = {J.G. Guerrero-Felix and S.F.H. Correia and M. Alexandre and C.D. Gonzalez-Gomez and V. Sencadas and L. Fu and E. Ruiz-Reina and P.S. André and C.L. Moraila-Martinez and M.J. Mendes and R.A.S. Ferreira and M.A. Fernandez-Rodriguez},
  doi          = {10.1016/j.matdes.2025.113817},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113817},
  shortjournal = {Mater. Des.},
  title        = {Enhancing the efficiency of luminescent solar concentrators via soft colloidal lithography negative templating},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synergistic strengthening and toughening in β titanium alloy
via enhanced micron-sized primary α with the fiber-like β grains.
<em>MATDES</em>, <em>252</em>, 113816. (<a
href="https://doi.org/10.1016/j.matdes.2025.113816">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The trade-offs between strength and toughness and strength and ductility restrict the broader use of high-strength titanium alloys. To optimize the coordination of strength, ductility and toughness, a fiber-like structure in a metastable β titanium alloy was architected through a simple thermomechanical process and aging treatment. During the thermomechanical process, the microscale primary α phase (α p ) hindered the migration of β grain boundaries and coordinated the deformation, forming fiber-like β grains. The fiber-like β grains effectively hinder and deflect crack propagation in Charpy impact tests, significantly enhancing the impact toughness. Meanwhile, plenty of kink bands activated in the α p after the thermomechanical process, refining the α grains and resulting in high yield strength and ductility. The impact toughness of the fiber-structured titanium alloy rises from 28.3 ± 2.5 J/cm 2 to 47.3 ± 2.8 J/cm 2 when compared to the sample with a bimodal structure, while the yield strength and elongation remain at the same level. The design of Fiber-structured titanium alloys synergistically enhances the strength, ductility and toughness of the Ti-Al-Mo-V-Cr-Nb titanium alloy, providing a novel way to coordinate the strength, ductility and toughness of high-strength titanium alloy.},
  archive      = {J_MATDES},
  author       = {Leliang Liu and Qiaoyan Sun and Jixiong Liu and Xiaoxiang Wang and Jun Sun},
  doi          = {10.1016/j.matdes.2025.113816},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113816},
  shortjournal = {Mater. Des.},
  title        = {Synergistic strengthening and toughening in β titanium alloy via enhanced micron-sized primary α with the fiber-like β grains},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large-scale as-sb-s chalcogenide glasses with ultrahigh
gradient refractive index. <em>MATDES</em>, <em>252</em>, 113815. (<a
href="https://doi.org/10.1016/j.matdes.2025.113815">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gradient refractive index (GRIN) infrared lens provided additional degrees of freedom for correcting chromatic and spherical aberrations in optical design by combining an internally customized refractive index distribution with the surface curvature of optical elements. However, high-performance GRIN infrared lenses are still faced with multiple bottlenecks including complex processing processes, limited fabrication size, unsatisfying refractive index difference and inferior interface quality, which restrict their wide applications. In this study, a group of novel infrared lens with high plasticity and large refractive index difference were developed based on the As 40- x Sb x S 60 system. Planar and spherical infrared GRIN lenses were successfully fabricated using precision molding technology, with a maximum refractive index difference (Δ n ) of 0.33 at a wavelength of 2 μm. In addition, a maximum diffusion depth of 6000 μm between two pieces of glass was achieved using a high-temperature melt diffusion process. The successful preparation of large-scale Δ n GRIN optical lens with controllable size and shape provides a new solution for realizing high performance and lightweight infrared optical systems.},
  archive      = {J_MATDES},
  author       = {Peikuan Fan and Chengwei Gao and Gangjie Zhou and Linling Tan and Shiliang Kang and Jinjin Chen and Shixun Dai and Changgui Lin},
  doi          = {10.1016/j.matdes.2025.113815},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113815},
  shortjournal = {Mater. Des.},
  title        = {Large-scale as-sb-S chalcogenide glasses with ultrahigh gradient refractive index},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Injectable PRP-enriched photosensitive hydrogel: Enhanced
prevention and infection control in anastomotic leaks. <em>MATDES</em>,
<em>252</em>, 113813. (<a
href="https://doi.org/10.1016/j.matdes.2025.113813">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The occurrence of anastomotic leakage (AL) could lead to leakage of digestive fluid, which erodes surrounding organs, subsequently causing severe intra-abdominal infections, hemorrhaging, and even death. Preventing AL was crucial for significantly enhancing patient quality of life. Thus, we developed an injectable photosensitive hydrogel enriched with platelet-rich plasma (PRP) aimed at preventing AL. This study utilized the Schiff-base crosslinking reaction between photosensitive methacryloyl-substituted gelatin (GM) and oxidized dextran (OD), incorporating PRP to create a multifunctional, tri-crosslinked hydrogel (GM/OD@PRP) that effectively promotes AL healing. This GM/OD@PRP exhibited excellent mechanical properties, biocompatibility, and self-healing capabilities. The hydrogel was loaded with PRP, which was rich in various growth factors that stimulate fibroblast proliferation and angiogenesis, thereby increasing cell proliferation, vascular regeneration, and formation and ultimately promoting healing at the anastomotic site. Furthermore, the superior antimicrobial properties of GM/OD@PRP provide a relatively sterile environment at the healing site, reducing the possibility of abdominal infections. In a rat model of AL, the GM/OD@PRP notably enhanced anastomotic healing prevented the occurrence of fistulae, and demonstrated significant advantages in reducing abdominal adhesions. This GM/OD@PRP holds substantial potential for use in preventing AL and represents a promising new composite material for improving patient quality of life.},
  archive      = {J_MATDES},
  author       = {Huijie Wang and Dongjie Zhang and Yiheng Ju and Yihui Cheng and Lei Liu and Houxi Li and Lianghong Lv and Jing Zhang and Yun Lu},
  doi          = {10.1016/j.matdes.2025.113813},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113813},
  shortjournal = {Mater. Des.},
  title        = {Injectable PRP-enriched photosensitive hydrogel: Enhanced prevention and infection control in anastomotic leaks},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Corrigendum to “shear strength parameters for porous asphalt
mixtures: From macro to meso” [mater. Design 238 (2024) 112670].
<em>MATDES</em>, <em>252</em>, 113812. (<a
href="https://doi.org/10.1016/j.matdes.2025.113812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MATDES},
  author       = {Shu Liu and Rui Huang and Juan Wang and Jing Bie and Alvaro Garcia Hernandez},
  doi          = {10.1016/j.matdes.2025.113812},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113812},
  shortjournal = {Mater. Des.},
  title        = {Corrigendum to “Shear strength parameters for porous asphalt mixtures: From macro to meso” [Mater. design 238 (2024) 112670]},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Liquid metal-graphene composite conductive nanofiber
flexible pressure sensor for dynamic health monitoring. <em>MATDES</em>,
<em>252</em>, 113811. (<a
href="https://doi.org/10.1016/j.matdes.2025.113811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flexible pressure sensors nanofibers-based have garnered significant attention due to their applications in smart wearable devices, healthcare monitoring, human–computer interaction, and artificial intelligence. However, developing flexible pressure sensors with excellent conductivity and stability for stable monitoring of small pressures remains a considerable challenge. This study presents a highly sensitive and rapid-response flexible pressure sensor using liquid metal-graphene composite conductive nanofibers. The sensor employs electrospinning and electrostatic spraying techniques to prepare a liquid metal-polyimide matrix material, with polyvinyl alcohol modification significantly enhancing its adhesion. Notably, an ultrasonic impregnation method was utilized to uniformly disperse conductive fillers onto the surfaces of the nanofibers and within the three-dimensional skeletal structure, creating a dual-conductive network that enhances the sensor’s conductivity. The sensor exhibits high sensitivity (3.02 kPa −1 ), rapid response/recovery times (80 ms/200 ms), and a broad detection range (0–90 kPa), along with excellent mechanical stability and durability (5000 loading–unloading cycles). These advantages enable the flexible pressure sensor to detect various signals from minor body movements to larger motions, such as throat swallowing and finger bending. This research provides an effective method for continuous health monitoring and the identification of subtle physiological changes, showcasing its tremendous potential in the fields of smart robotics and prosthetics.},
  archive      = {J_MATDES},
  author       = {Manfeng Gong and Chenglong Tu and Xitong Lin and Fang Wang and Haishan Lian and Zaifu Cui and Xiaojun Chen},
  doi          = {10.1016/j.matdes.2025.113811},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113811},
  shortjournal = {Mater. Des.},
  title        = {Liquid metal-graphene composite conductive nanofiber flexible pressure sensor for dynamic health monitoring},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Insights on enhancing the adhesion of inkjet-printed
europium-doped yttrium oxide by tailoring interfacial bonding
environments. <em>MATDES</em>, <em>252</em>, 113810. (<a
href="https://doi.org/10.1016/j.matdes.2025.113810">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inkjet printing of metal nitrate precursors and subsequent annealing offers a facile and scalable route toward tailoring metal oxides in well-defined patterns. In the following work, an ink formulation comprised of yttrium nitrate hexahydrate, europium nitrate hexahydrate, and urea was printed onto borosilicate glass and stainless steel 304 substrates to study the surface reaction and interface evolution after annealing in an air or N 2 environment. A QR code was fabricated with luminescent europium-doped yttrium oxide droplets to demonstrate the user-defined patterning capability of the inkjet printing technique, in which an invisible pattern to the naked eye was achieved for the oxide deposited on stainless steel. X-ray photoelectron spectroscopy reveals the reaction evolution from the yttrium nitrate precursor to yttrium oxide and yields insight into the potential role of cation diffusion and thermal expansion mismatch in governing the adhesion properties of the oxide layer.},
  archive      = {J_MATDES},
  author       = {Yujuan He and Jeffrey A. Dhas and Kijoon Lee and Milad Ghayoor and V. Vinay K. Doddapaneni and Anton T. Escher and Somayeh Pasebani and Brian K. Paul and Chih-hung Chang},
  doi          = {10.1016/j.matdes.2025.113810},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113810},
  shortjournal = {Mater. Des.},
  title        = {Insights on enhancing the adhesion of inkjet-printed europium-doped yttrium oxide by tailoring interfacial bonding environments},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 3D multi-site hydrogen evolution reaction catalysts on
nanoimprinted surfaces, structured via multi-photon lithography derived
masks. <em>MATDES</em>, <em>252</em>, 113809. (<a
href="https://doi.org/10.1016/j.matdes.2025.113809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient water splitting is a major challenge in green hydrogen production and energy transition. Thus, considerable scientific efforts are devoted to optimize surface geometries for enhancing the performance of water-splitting catalysts. The current study aims to develop a reliable and facile 3-step (re-)production technique for manufacturing structured surfaces by combining multi-photon lithography (MPL) and nanoimprint lithography (NIL). MPL enables structuring of high-definition micrometer-scale surface geometries. A variation of these topologies was used as masks for replication by NIL. Thus, molds were derived to emboss the original nanostructured topologies repeatedly into a UV-curable resin. Subsequently, a Ni thin film metallization was deposited by physical vapor deposition onto the final imprinted polymeric structures, thereby realizing topologically structured conductive electrodes. To demonstrate the applicability of this elaborated technique, the catalytic activities towards the hydrogen evolution reaction were assessed for different surface geometries. An increase in catalytic performance was achieved through surface enlargement by structuring, whereby a direct contribution of the specific structure geometry was not evident. This elegant method is highly versatile and scalable for producing a wide range of structured functional surfaces on a lab scale, as demonstrated for the water splitting reaction, with results transferable to an industrial scale.},
  archive      = {J_MATDES},
  author       = {Alexander Jelinek and Daniela Neumüller and Christoph Gammer and Jürgen Eckert and Daniel Kiener},
  doi          = {10.1016/j.matdes.2025.113809},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113809},
  shortjournal = {Mater. Des.},
  title        = {3D multi-site hydrogen evolution reaction catalysts on nanoimprinted surfaces, structured via multi-photon lithography derived masks},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Corrigendum to “machine learning in additive
manufacturing——NiTi alloy’s transformation behavior” [mater. Des. 247
(2024) 113443]. <em>MATDES</em>, <em>252</em>, 113808. (<a
href="https://doi.org/10.1016/j.matdes.2025.113808">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MATDES},
  author       = {Lidong Gu and Kongyuan Yang and Hongchang Ding and Zezhou Xu and Chunling Mao and Panpan Li and Zhenglei Yu and Yunting Guo and Luquan Ren},
  doi          = {10.1016/j.matdes.2025.113808},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113808},
  shortjournal = {Mater. Des.},
  title        = {Corrigendum to “Machine learning in additive manufacturing——NiTi alloy’s transformation behavior” [Mater. des. 247 (2024) 113443]},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new journey of fluorescent carbon dots: A shining star in
the realm of nucleic acid dyes. <em>MATDES</em>, <em>252</em>, 113806.
(<a href="https://doi.org/10.1016/j.matdes.2025.113806">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nucleic acid dyes play important roles in the quantification and detection of nucleic acids by binding to nucleic acids. However, traditional nucleic acid dyes pose great environmental and economic challenges due to their high price, high toxicity, long dyeing time, low sensitivity and insufficient stability. To overcome these problems, we developed a new nucleic acid dye based on carbon dots, which were generated through hydrothermal synthesis with liquorice components as precursors and a system containing ethylenediamine. This new type of carbon dot can effectively replace traditional dyes and can be used to efficiently visualize DNA, RNA and plasmids via agarose gel electrophoresis. Then, we studied the interaction mechanism between carbon dots and nucleic acids by UV–visible spectroscopy, Fourier transform infrared spectroscopy and circular dichroism spectroscopy. The interaction between the carbon dots and nucleic acids mainly occurred through groove binding and was accompanied by a slight electrostatic interaction. Carbon dots-based nucleic acid dyes, with their low cost, simple synthesis process and high stability, have opened a new path for the field of nucleic acid detection. Its research and development not only promote the frontier progress of biological science and medicine but also introduces innovative strategies and tools for scientific research and clinical practice.},
  archive      = {J_MATDES},
  author       = {Yu Ma and Bin Zhao and Guozhen Yan and Ting Zhou and Zhihua Xu and Zhihan Niu and Zhenghong Xu and Tongtong Zhang and Feng Shi},
  doi          = {10.1016/j.matdes.2025.113806},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113806},
  shortjournal = {Mater. Des.},
  title        = {A new journey of fluorescent carbon dots: A shining star in the realm of nucleic acid dyes},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Negative to zero poisson’s ratio adjustable UV-PDMS flexible
metamaterials fabricated by using 3D photolithography. <em>MATDES</em>,
<em>252</em>, 113805. (<a
href="https://doi.org/10.1016/j.matdes.2025.113805">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mechanical metamaterials (MMs) exhibit mechanical characteristics that are challenging to achieve using existing isotropic materials. Due to their unique characteristics, MMs hold significant potential for applications in diverse fields such as space, architecture, and robotics. This study proposes a method for processing and tuning the mechanical characteristics of MMs composed of UV-curable silicone rubber (UV-PDMS) submillimeter-sized thorough holes, specifically for integration into flexible microdevices. We focused on the microfabrication of polymeric materials with elastic limits and MMs regions, which have traditionally been difficult to achieve. Using 3D photolithography, UV-PDMS was successfully processed to incorporate submillimeter-sized through-holes. Furthermore, MMs with different linewidths were fabricated using from an identical mask pattern by only adjusting the UV incidence angle and exposure dose using 3D photolithography. The resulting flexible MMs exhibited tunable Poisson’s ratios within the range of −0.16 to −0.06.},
  archive      = {J_MATDES},
  author       = {Riku Ito and Yuji Takata and Yuya Tanaka and Hiroshi Toshiyoshi and Takaaki Suzuki},
  doi          = {10.1016/j.matdes.2025.113805},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113805},
  shortjournal = {Mater. Des.},
  title        = {Negative to zero poisson’s ratio adjustable UV-PDMS flexible metamaterials fabricated by using 3D photolithography},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Infrared spectroscopic characterization by atomic force
microscopy of two model nano-samples of low-density polyethylene
designed by laser ablation and ultraviolet/ultrasound. <em>MATDES</em>,
<em>252</em>, 113804. (<a
href="https://doi.org/10.1016/j.matdes.2025.113804">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model plastic samples mimicking the behavior of environmental nanoparticles (NPs) are necessary for understanding their biological effects. This is because the particle size and surface chemistry of plastic particles can be parameters for biotoxicity testing. Therefore, different types of particles need to be produced or designed. In this study, the chemical and physical properties of two model nano-samples of Low-Density Polyethylene (LDPE) were investigated; one designed by nanosecond laser ablation (LASER-LDPE.NPs), and the other designed by a combination of Ultraviolet (UV) irradiation and Ultrasound (US) exposure (UV/US-LDPE.NPs). AFM-IR, for detecting and imaging the response of a sample by scanning an AFM cantilever while irradiating an IR laser, was used to analyze the local chemical properties of these particles. New peaks specific to oxidation and degradation reactions were observed. In addition, the LASER-LDPE.NPs tend to have greater oxidation behavior with increasing methyl groups and a greater degradation with increasing carbonyl index than UV/US-LDPE.NPs. It was found that each NP production process produces NPs with unique chemical and physical properties. These designed model plastic particles mimic NPs in the environment and a study of their respective oxidation and degradation properties is expected to provide new insights into the assessment of biological effects. (200 words)},
  archive      = {J_MATDES},
  author       = {Ikuna Kanehara and Naoto Washihira and Tatsuhiro Nagasaka and Hirofumi Seki and Sho Fujii and Tsuyoshi Kimura and Masaya Yamamoto and Tadao Tanabe},
  doi          = {10.1016/j.matdes.2025.113804},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113804},
  shortjournal = {Mater. Des.},
  title        = {Infrared spectroscopic characterization by atomic force microscopy of two model nano-samples of low-density polyethylene designed by laser ablation and Ultraviolet/Ultrasound},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structure, chemistry, and mechanical properties of
non-reactively sputtered ti-al-n. <em>MATDES</em>, <em>252</em>, 113803.
(<a href="https://doi.org/10.1016/j.matdes.2025.113803">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents the influence of substrate temperature, sputtering conditions (DC and pulsed DC), and Al content on chemical composition, structure, growth morphology, mechanical properties and thermal stability of non-reactively sputtered Ti-Al-N coatings. The substrate temperature and the pulse frequency have a minor impact on the coating properties, which are more strongly influenced by the chemical composition of the target (Ti 0.5 Al 0.5 N, Ti 0.33 Al 0.67 N, or Ti 0.2 Al 0.8 N) and the duty cycle during pulsed DC sputtering. The highest deposition rate of 109 ± 2 nm/min was obtained from a single-phase cubic rock-salt-structured coating and the highest hardness of 38.2 ± 2.5 GPa from a two-phase-structure coating (cubic rock salt and minor hexagonal wurtzite structure), both prepared from the Ti 0.5 Al 0.5 N target. The maximum Al content (Ti 1-x Al x N) for single-phase cubic rock-salt-structured coatings is x = 0.64, and the minimum Al content for single-phase hexagonal wurtzite-structured coatings is x = 0.81. The findings demonstrate that non-reactive sputtering is a viable method for preparing Ti-Al-N coatings. Furthermore, even without additional substrate heating, this approach achieves a high hardness of 33.6 ± 1.5 GPa and an impressive deposition rate of 102 ± 1 nm/min, offering a pathway to further enhance the sustainable production of these hard protective coatings.},
  archive      = {J_MATDES},
  author       = {Sarah Christine Bermanschläger and Balint Istvan Hajas and Tomasz Wojcik and Eleni Ntemou and Daniel Primetzhofer and Szilard Kolozsvari and Friedrich Bleicher and Paul Heinz Mayrhofer},
  doi          = {10.1016/j.matdes.2025.113803},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113803},
  shortjournal = {Mater. Des.},
  title        = {Structure, chemistry, and mechanical properties of non-reactively sputtered ti-al-N},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High power impulse magnetron sputtering plasma nitriding of
biomedical grade CoCrMo alloy. <em>MATDES</em>, <em>252</em>, 113802.
(<a href="https://doi.org/10.1016/j.matdes.2025.113802">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical implants are requested to meet stringent requirements to ensure their safety and efficacy over extended periods within the human body. The use of surface modification techniques, such as nitriding, is essential in advancing the performance and lifetime of implant materials. The innovative use of High Power Impulse Magnetron Sputtering (HiPIMS) discharge for nitriding represents a significant advancement in surface treatment technologies for medical implants. In this work, a CoCrMo alloy underwent a low-pressure plasma nitriding process by using four different target materials to sustain the plasma: Ti, Cr, Mo and Ta. Among them, the molybdenum target leads to the best overall performance, since it achieves the formation of the desired γ N phase without secondary phases or surface particles and provides enhanced mechanical properties and chemical stability. The hardness achieved after the nitriding process is significantly higher than that of untreated CoCrMo, reaching up to 18 GPa. All nitrided samples exhibit a positive shift in corrosion potential values in Ringer’s solution, indicating improved corrosion resistance and demonstrate reduced wear rates and smoother wear scars compared to pristine samples, especially the Mo-treated one offers improved tribocorrosion behaviour, balancing wear and corrosion resistance effectively.},
  archive      = {J_MATDES},
  author       = {Valentina Zin and Francesco Montagner and Silvia Maria Deambrosis and Enrico Miorin and Nicola Comisso and Marzio Rancan and Enrico Paradisi and Cecilia Mortalò},
  doi          = {10.1016/j.matdes.2025.113802},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113802},
  shortjournal = {Mater. Des.},
  title        = {High power impulse magnetron sputtering plasma nitriding of biomedical grade CoCrMo alloy},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spring-based mechanical metamaterials with
deep-learning-accelerated design. <em>MATDES</em>, <em>252</em>, 113800.
(<a href="https://doi.org/10.1016/j.matdes.2025.113800">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mechanical metamaterials exhibit unique properties that depend on their microstructure and surpass those of their constituent materials. Flexible mechanical metamaterials, in particular, hold significant potential for applications requiring substantial deformations, such as soft robotics and energy absorption. In this study, we proposed a collection of flexible mechanical metamaterials discretely assembled using structural spring elements. These spring elements enhance both flexibility and reversibility, allowing the materials to withstand large deformations. The geometric regularity of the metamaterials enables zero-shot learning, allowing deep learning frameworks to address property prediction and inverse design problems beyond the training dataset. Using a property-prediction model, the effective mechanical properties of these metamaterials can be accurately predicted based on specified design parameters. Furthermore, an inverse-design model enables the direct generation of mechanical metamaterials with desired target properties, even outside the training dataspace, in the range of Young&#39;s modulus E ∈ (0, 350) kPa and Poisson&#39;s ratio ν ∈ (-0.12, 0.12). The properties of these inversely designed metamaterials are analyzed through finite element method simulations and mechanical testing. The deep learning-accelerated design approach not only streamlines the development process but also provides a framework for advancing metamaterial design, encompassing property prediction and inverse design.},
  archive      = {J_MATDES},
  author       = {Xiaofeng Guo and Xiaoyang Zheng and Jiaxin Zhou and Takayuki Yamada and Yong Yi and Ikumu Watanabe},
  doi          = {10.1016/j.matdes.2025.113800},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113800},
  shortjournal = {Mater. Des.},
  title        = {Spring-based mechanical metamaterials with deep-learning-accelerated design},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Designing laves-phase RFe2-type alloy with excellent
magnetostrictive performance by physics-informed interpretable machine
learning. <em>MATDES</em>, <em>252</em>, 113799. (<a
href="https://doi.org/10.1016/j.matdes.2025.113799">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Laves-phase RFe 2 -type (R = rare earth) magnetostrictive materials have tremendous application potential in smart devices. However, efficiently unearthing novel RFe 2 -type compounds with huge magnetostriction in experiments remains challenge due to the vast compositional space. Herein, we employ a physics-informed interpretable machine learning-based strategy to facilitate the design of targeted alloys. A home-built dataset is obtained through constructing composition-physical parameters-magnetostriction relationship. By comparing different models, the XGBoost (XGB) regression model is selected to predict magnetostriction of quaternary Tb x Dy 1- x Fe y V 2- y alloys. The results demonstrate that the optimal performance occurs in the composition range of 0.23–0.38 for Tb content and 0.01–0.08 for V content. The predicted properties are then verified by the measured results of a series of synthesized samples. Additionally, a model interpretability based on SHapley Additive exPlanations (SHAP) values manifests that volume magnetic susceptibility and bulk modulus exert the greatest impact on magnetostriction. This work offers a recipe to swiftly designing RFe 2 -type materials with giant magnetostriction.},
  archive      = {J_MATDES},
  author       = {Pengqiang Hu and Chao Zhou and Ruisheng Zhang and Sidan Ding and Yuanjun Guo and Bo Wang and Dezhen Xue and Yizhe Ma and Zhiyong Dai and Yin Zhang and Fanghua Tian and Sen Yang},
  doi          = {10.1016/j.matdes.2025.113799},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113799},
  shortjournal = {Mater. Des.},
  title        = {Designing laves-phase RFe2-type alloy with excellent magnetostrictive performance by physics-informed interpretable machine learning},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design of auxetic metamaterial for enhanced low cycle
fatigue life and negative poisson’s ratio through multi-objective
bayesian optimization. <em>MATDES</em>, <em>252</em>, 113798. (<a
href="https://doi.org/10.1016/j.matdes.2025.113798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Auxetic metamaterials (AM) with negative Poisson’s ratio (NPR) offer promising mechanical properties but often suffer from significant stress concentrations, compromising durability and fatigue life. Conventional design approaches, including topology optimization and empirical geometry-based methods, struggle with exploring complex design spaces, while data-driven techniques demand extensive datasets, making fatigue life prediction computationally expensive. To address these challenges, we propose a novel framework that integrates Bézier curve-based geometric parameterization, multi-objective Bayesian optimization (MBO), and fatigue life prediction via elastoplastic homogenization and critical distance theory. This approach systematically explores the design space, simultaneously enhancing NPR and optimizing fatigue resistance while alleviating localized stress concentrations. MBO efficiently balances exploration and exploitation with limited data, making it particularly suitable for computationally intensive fatigue analysis. Optimized AM structures exhibited an 85.11% increase in NPR and a 12.07% improvement in low-cycle fatigue (LCF) life compared to initial designs. Experimental validation confirmed up to 30 times the LCF life and a 2.5-fold NPR increase over conventional AM structures. These findings establish a scalable methodology for AM design, advancing the development of durable, high-performance metamaterials for biomedical, aerospace, and energy-harvesting applications.},
  archive      = {J_MATDES},
  author       = {Sukheon Kang and Hyeonbin Moon and Seonho Shin and Mahmoud Mousavi and Hyokyung Sung and Seunghwa Ryu},
  doi          = {10.1016/j.matdes.2025.113798},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113798},
  shortjournal = {Mater. Des.},
  title        = {Design of auxetic metamaterial for enhanced low cycle fatigue life and negative poisson’s ratio through multi-objective bayesian optimization},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Friction and wear study for the new method of laser-induced
cavitation micro-texturing on 7050 aluminum alloy. <em>MATDES</em>,
<em>252</em>, 113796. (<a
href="https://doi.org/10.1016/j.matdes.2025.113796">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new surface-texturing technique—laser-induced cavitation micro-texturing (LICMT) was proposed to improve the friction and lubrication properties of 7050 aluminum alloy. Reciprocating friction tests were used to analyze the tribological properties at different micro-texturing densities and depths under starved lubrication conditions. SEM was used to observe the morphology of the wear surface. The average friction coefficient and wear rate were lowest for a micro-texturing density of 19.63 %. The average friction coefficient decreased with increasing micro-texturing depth. Compared with LST, no craters formed on the surface. Because of the lower abrasive and adhesive wear, the LICMT samples exhibited good friction reduction and lubrication performance. Finally, the mechanism of LICMT explained friction reduction and lubrication under starved lubrication conditions.},
  archive      = {J_MATDES},
  author       = {Rui Zhou and Weidong Shi and Yupeng Cao and Yongfei Yang and Kangwen Li},
  doi          = {10.1016/j.matdes.2025.113796},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113796},
  shortjournal = {Mater. Des.},
  title        = {Friction and wear study for the new method of laser-induced cavitation micro-texturing on 7050 aluminum alloy},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparison of various UHMWPE formulations from contemporary
total knee replacements before and after accelerated aging.
<em>MATDES</em>, <em>252</em>, 113795. (<a
href="https://doi.org/10.1016/j.matdes.2025.113795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We have collected 21 different formulations of ultrahigh molecular weight polyethylene (UHMWPE), which have been employed as liners in contemporary total knee replacements (TKR). The UHMWPE liners were bought from the most important manufacturers on the orthopedic market in the Czech Republic as of 2020. The collected liners represented a broad range of both traditional and modern UHMWPE formulations, which differed by the level of crosslinking, type of thermal treatment, sterilization and/or stabilization. All obtained UHMWPE’s were characterized by multiple methods immediately after purchase and after the accelerated aging in H 2 O 2 . The experimental results (oxidative degradation, structure changes, and micromechanical properties) were correlated with manufacturer’s data (crosslinking, thermal treatment, sterilization, and stabilization). The investigated UHMWPE liners exhibited significant differences in their properties, namely in their resistance to long term oxidative degradation. The stiffness-related mechanical properties showed a strong correlation with the overall crystallinity. The crystallinity depended mostly on the oxidative degradation of the UHMWPE liners, while the thermal treatment played a minor role. The highest resistance to oxidation and wear, which promises the best in vivo performance, was found for the crosslinked UHMWPE formulations with biocompatible stabilizers (such as α-tocopherol, which is the key component of vitamin E).},
  archive      = {J_MATDES},
  author       = {Petr Fulin and Veronika Gajdosova and Ivana Sloufova and Jiri Hodan and David Pokorny and Miroslav Slouf},
  doi          = {10.1016/j.matdes.2025.113795},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113795},
  shortjournal = {Mater. Des.},
  title        = {Comparison of various UHMWPE formulations from contemporary total knee replacements before and after accelerated aging},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Melting mode-driven processing diagram for
nanoparticle-enhanced high-strength aluminum alloy processed by laser
powder bed fusion. <em>MATDES</em>, <em>252</em>, 113794. (<a
href="https://doi.org/10.1016/j.matdes.2025.113794">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AA7075 + ZrH 2 (7A76) is a nanoparticle-enhanced high-strength Al alloy, designed to substantially prevent solidification cracking during laser powder bed fusion (LPBF). Significant knowledge gaps persist in understanding the effects of melting modes, the functionality of nanoparticles, and compositional variations in this material system. This study systematically investigates the melting modes in LPBF of 7A76 to achieve defect-free samples. Processing diagrams were generated using dimensionless heat input ( E* ) and velocity ( v* ) terms, alongside a physics-based temperature prediction model used to predict melting mode thresholds. A wide operation window was discovered within the transition melting mode region, resulting in defect-free 7A76, reaching a relative density of 99.98 %, reported for the first time. Furthermore, the transition melting mode was effective in lowering the Mg and Zn evaporation. Microstructural characterizations revealed that although melting and solidification during the LPBF process resulted in the dissolution of Zr into the printed alloy, some Zr-rich particles remained unmelted. This work represents the first observation of grain nucleation on the partially melted Zr-rich particles in this modified alloy. Additionally, this work sheds light on the successful printing of nanoparticle-enhanced, crack-prone aluminum alloys using processing diagrams, while elucidating the role of nanoparticles in this process.},
  archive      = {J_MATDES},
  author       = {Ali Rezaei and Mohsen K. Keshavarz and John Barnes and Mihaela Vlasea},
  doi          = {10.1016/j.matdes.2025.113794},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113794},
  shortjournal = {Mater. Des.},
  title        = {Melting mode-driven processing diagram for nanoparticle-enhanced high-strength aluminum alloy processed by laser powder bed fusion},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced two-dimensional superelasticity in a laser
micromachined auxetic NiTiNOL geometry. <em>MATDES</em>, <em>252</em>,
113793. (<a href="https://doi.org/10.1016/j.matdes.2025.113793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The superelastic effect in nitinol allows it to accommodate and recover large amounts of deformation. Despite possessing this incredible ability, their use in applications remains limited due to the difficulty in machining into novel geometries. Laser-micromachining is an attractive solution to this problem, with the ability to micromachine geometries not conventionally possible. Such geometries, like auxetics, could be used to enhance the simultaneous two-dimensional accommodation and recovery of superelastic strain. We showcase an example of this enhancement in a laser-micromachined auxetic geometry that has minimal material removal. The recoverable strain in the auxetic geometry represents an enhancement of 86% increase over the bulk failure strain in the loading direction, and an absolute increase of 70% over the bulk failure strain in the transverse direction. Such geometries with enhanced two-dimensional functionality could serve as functional backbones on elastomeric composite testbeds with potential applications in soft robotics, stretch-triggered drug delivery, stretchable electronics, adaptive filters and controlled adhesion.},
  archive      = {J_MATDES},
  author       = {Asheesh Lanba and Tymur Sabirov and Adrien Melanson and Kevin Voter and Benjamin Hall},
  doi          = {10.1016/j.matdes.2025.113793},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113793},
  shortjournal = {Mater. Des.},
  title        = {Enhanced two-dimensional superelasticity in a laser micromachined auxetic NiTiNOL geometry},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Electrospinning-based bone tissue scaffold construction:
Progress and trends. <em>MATDES</em>, <em>252</em>, 113792. (<a
href="https://doi.org/10.1016/j.matdes.2025.113792">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrospinning is a key technique for producing nanofibers used in bone tissue engineering. Electrospinning methods, materials, and parameters affect bone scaffold properties and efficacy. However, there is currently a lack of systematic reviews, and the influence of electrospinning forms, scaffold types, and their parameters on scaffold performance remains unclear, making it difficult for researchers to obtain effective references. Therefore, this paper reviews the applications of electrospun scaffolds in bone tissue engineering. Firstly, it summarizes various electrospun scaffold fabrication methods and their principles, including conventional, blend, melt, coaxial, emulsion, solution, free surface, and improved techniques. Based on differences in scaffold structure, this paper further classifies scaffolds into multilayer, grid, and tubular types, analyzing the advantages and limitations of electrospinning processes and scaffold types, and discussing related scaffolds. Future research should focus on material, structural, and solvent optimization to improve scaffold performance. Secondly, this paper discusses the material characterization and applications of electrospun scaffolds in bone tissue engineering, emphasizing the need for performance optimization for improving bone repair. Finally, it proposes future research directions to address current challenges. This paper aims to provide systematic guidance and technical support for the application of electrospinning technology in bone tissue engineering.},
  archive      = {J_MATDES},
  author       = {Yunqi Ma and Ruiyu Zhou and Min Yang and Jun Zhang and Wei Song and Xiao Ma and Mingzheng Liu and Xin Cui and Benkai Li and Yanbin Zhang and Yunze Long and Zhigang Zhou and Changhe Li},
  doi          = {10.1016/j.matdes.2025.113792},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113792},
  shortjournal = {Mater. Des.},
  title        = {Electrospinning-based bone tissue scaffold construction: Progress and trends},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Developing a multi-scale framework to predict and evaluate
cohesion and adhesion of rejuvenated bitumen: Insights from molecular
dynamics simulations and experiments. <em>MATDES</em>, <em>252</em>,
113791. (<a href="https://doi.org/10.1016/j.matdes.2025.113791">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rejuvenators are crucial for efficient asphalt pavement recycling, but their effectiveness varies widely based on factors like bitumen source, aging degree, and rejuvenator composition. This study aims to develop a multiscale evaluation methodology to assess the cohesive and adhesive performance of rejuvenated bitumen, integrating molecular dynamics (MD) simulations and experimental testing. Molecular models of rejuvenated bitumen are established to predict nanoscale cohesion energy and the linear amplitude sweep (LAS) tests for fatigue evaluation. Bitumen-aggregate interface models undergo MD simulations for adhesion assessment, validated by pull-off tension tests, while microstructural observations clarify debonding mechanisms. Results show that bio-oil is the most effective rejuvenator for restoring aged bitumen’s cohesion, followed by engine-oil, naphthenic-oil, and aromatic-oil. LAS tests confirm these rankings for both bitumen and mastic, with Filler Wigro outperforming Wigro60K in reducing cohesive cracking risk. While aging decreases adhesion property, rejuvenators restore both cohesive and adhesive performance, with bio-oil achieving 44.4 % restoration of adhesion when adding 10 % by weight of bitumen. Additionally, MD simulations reveal that the work of adhesion (W aa ) negatively correlates with fatigue parameter (G*sinδ) and positively with fatigue life (N f ), and both Waa and the work of bonding adhesion (W BA ) decrease linearly with the pull-off tension strength (POTS) index. Bitumen TB is the most effective for improving cohesion crack resistance, whereas binder FB results in lower fatigue life. Overall, bio-oil proves most effective in restoring cohesion and adhesion across bitumen types and fillers, improving rejuvenated asphalt performance.},
  archive      = {J_MATDES},
  author       = {Shisong Ren and Marco Poot and Xueyan Liu and Sandra Erkens},
  doi          = {10.1016/j.matdes.2025.113791},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113791},
  shortjournal = {Mater. Des.},
  title        = {Developing a multi-scale framework to predict and evaluate cohesion and adhesion of rejuvenated bitumen: Insights from molecular dynamics simulations and experiments},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Electrical resistivity and self-sensing properties of
low-cement limestone calcined clay cement (LC3) mortar. <em>MATDES</em>,
<em>252</em>, 113790. (<a
href="https://doi.org/10.1016/j.matdes.2025.113790">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigated the mechanical, electrical, and piezoresistive performances of mortars made with Ordinary Portland cement (OPC) and limestone calcined clay cement (LC 3 ), especially when reinforced with 0.1 wt% recycled carbon fibre (rCF) by weight of the binder. The results found that 0.1 wt% rCF failed to considerably enhance the electrical conductivity of OPC and LC 3 mortars during the curing period, but the enhancement became apparent when these composites were 1 day-dried. With the increasing cement replacement ratio and the introduction of rCF, the mechanical properties deteriorated because of the dilutive effects together with the fragility of rCF. The OPC and LC 3 mortars exhibited a certain degree of piezoresistivity under compression, which was amplified with added 0.1 wt% rCF. Additionally, the piezoresistive performance of the LC 3 mortar was better than that of the OPC mortar, regardless of the presence of rCFs. The sensing capacity of composites is greatly weakened in terms of flexural stress. In terms of the two-probe method, because of the contact resistance, the resistivity usually decreases under compression, which results in larger fractional changes in resistivity values. This study aims to develop a low conductivity self-sensing cement-based composite (SSCC) filled with a small dosage of rCF.},
  archive      = {J_MATDES},
  author       = {Wenkui Dong and Ameer Hamza Ahmed and Marco Liebscher and Huanyu Li and Yipu Guo and Bo Pang and Mostafa Adresi and Wengui Li and Viktor Mechtcherine},
  doi          = {10.1016/j.matdes.2025.113790},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113790},
  shortjournal = {Mater. Des.},
  title        = {Electrical resistivity and self-sensing properties of low-cement limestone calcined clay cement (LC3) mortar},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced intragranular precipitation strengthening in
sc-microalloyed ultrafine-grained SiCp/al-cu-mg composites via
retrogression and re-ageing heat treatment. <em>MATDES</em>,
<em>252</em>, 113789. (<a
href="https://doi.org/10.1016/j.matdes.2025.113789">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultrafine-grained Al matrix composites suffer from the insufficient dislocation accumulation capability and intragranular precipitation strengthening due to their length-scale dependent precipitation behaviors. In this work, a combination of Sc-microalloying and a retrogression and re-ageing (RRA) route was applied on the SiC p /Al-Cu-Mg composites to achieve well-balanced strength and ductility. Compared to the T6 treatment, RRA heat treatment exhibit a significant strengthening effect in Sc-microalloyed composites with only a slight loss in ductility. The yield strength and ultimate strength of the Sc-RRA samples reach up to 686.4 MPa and 734.5 MPa, respectively. The plastic deformation mechanism was analyzed by thermal activation analysis and TEM observation of deformed microstructure. The plastic deformation of UFG composites, both with and without Sc, is primarily governed by a dislocation-grain boundary interaction mechanism. As confirmed by the observed stacking faults, the Sc-microalloyed composite subjected to T6 treatment suffers from poor dislocation storge capacity and insufficient intragranular precipitation strengthening. In contrast, the RRA treatment promotes the formation of intragranular Al 3 Sc precipitates and GP zones, which improve the dislocation accumulation capability and precipitation strengthening of ultrafine-grained composites by pinning dislocations. This work provides an accessible pathway to exploit aluminum matrix composites with advanced strength-ductility balance.},
  archive      = {J_MATDES},
  author       = {Yunpeng Cai and Kan Liu and Yiwei Dong and Andong Hua and Yishi Su and Qiubao Ouyang and Di Zhang},
  doi          = {10.1016/j.matdes.2025.113789},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113789},
  shortjournal = {Mater. Des.},
  title        = {Enhanced intragranular precipitation strengthening in sc-microalloyed ultrafine-grained SiCp/Al-cu-mg composites via retrogression and re-ageing heat treatment},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Driving martensitic transformation through pre-cold
deformation: Unveiling the mechanism of microstructural evolution in
martensite bearing steel. <em>MATDES</em>, <em>252</em>, 113788. (<a
href="https://doi.org/10.1016/j.matdes.2025.113788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bearing steel is used to produce bearing components through preforming processes, such as cold heading and cold rolling, prior to heat treatment. Cold rolling is a key developmental direction for manufacturing high-performance bearing. This research comprehensively examines how pre-cold deformation affects the microstructural evolution and mechanical characteristics of martensitic bearing steel. The findings suggest that pre-cold deformation reduces the original austenite grain size decreases by half, and the cementite particles become more uniformly distributed. Simultaneously, pre-cold deformation treatment considerably increases the bearing steel hardness from 715HV to 768HV whilst maintaining its toughness. The homogenisation of cementite size and the increase in hardness enhance the wear resistance of the samples by 34%. Furthermore, we explores the microstructural evolution mechanisms during subsequent phase transformations: the bearing steel in the process of martensitic transformation, the pre-cold deformation treatment leads to a strong variant selection, which increases the intrinsic nucleation rate and reduces the autocatalytic nucleation rate of martensite. The change of nucleation positions causes the great differences in the crystallography of the samples. The martensite twins transforming into twinned variants that adhere to the Kurdjumov-Sachs orientation relationship. In this study, we have established a relationship linking crystallography, phase transitions, and mechanical properties.},
  archive      = {J_MATDES},
  author       = {Decheng Jia and Chunsheng Zhang and Runzhou Dong and Haida Zhang and Xinliang Gao and Xiaoyong Feng and Zhinan Yang and Fucheng Zhang},
  doi          = {10.1016/j.matdes.2025.113788},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113788},
  shortjournal = {Mater. Des.},
  title        = {Driving martensitic transformation through pre-cold deformation: Unveiling the mechanism of microstructural evolution in martensite bearing steel},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inhomogeneous α-al/Mg2Si two-phase microstructures with
chemical fluctuation produced by laser-beam powder bed fusion.
<em>MATDES</em>, <em>252</em>, 113787. (<a
href="https://doi.org/10.1016/j.matdes.2025.113787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigated the additive manufacturing of high-strength Al–Mg–Si ternary alloy with refined α-Al/Mg 2 Si two-phase microstructures by laser-beam powder bed fusion (PBF-LB). Although PBF-LB processing produced crack-free samples with high relative densities (&gt;99.5 %), the scanning laser irradiation caused significant Mg vaporization, reducing the Mg content of the sample from 11.3 to 7.6 %. Laser-induced vaporization caused micron-scale chemical fluctuations in the melt-pool structure, resulting in the development of inhomogeneous microstructures. Refined cellular microstructures with many columnar α-Al phases surrounded by numerous Mg 2 Si nano-particles were observed in most parts of the melt-pool structure, corresponding to hypo-eutectic compositions in the Al–Mg–Si ternary system. However, primary solidified Mg 2 Si phases were observed in some parts of the melt-pool boundaries with local Mg-rich compositions (hyper-eutectic compositions). The PBF-LB manufactured alloy specimens with a total composition of Al–7.6Mg–5.4Si (wt%) exhibited a high tensile strength, which reduced significantly with increasing testing temperature, and low ductility (529 MPa and &lt; 2 %, respectively) at room temperature. Moreover, the specimens underwent mechanical deterioration at elevated temperatures, owing to a significant coarsening of metastable microstructural factors (nanoscale Mg 2 Si precipitates or their related metastable phases and atomistic clusters) that contribute towards the high room-temperature strength.},
  archive      = {J_MATDES},
  author       = {Yuki Otani and Naoki Takata and Asuka Suzuki and Makoto Kobashi and Junji Umeda},
  doi          = {10.1016/j.matdes.2025.113787},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113787},
  shortjournal = {Mater. Des.},
  title        = {Inhomogeneous α-Al/Mg2Si two-phase microstructures with chemical fluctuation produced by laser-beam powder bed fusion},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evading strength-ductility trade-off in a metastability
engineered layered metallic composite. <em>MATDES</em>, <em>252</em>,
113786. (<a href="https://doi.org/10.1016/j.matdes.2025.113786">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This investigation demonstrates a unique layered metallic composite (LMC) design strategy which exploits the metastability tunability of the transformative complex concentrate alloys (CCAs). Metastability engineered LMC (ME-LMC) was prepared by sandwiching a relatively less metastable Fe 38.5 Mn 20 Co 20 Cr 15 Si 5 Cu 1.5 CCA (SFE = 12 mJ/m 2 ) between the two layers of the highly metastable Fe 40 Mn 20 Co 20 Cr 15 Si 5 CCA (SFE = 6 mJ/m 2 ). In ME-LMC, plastic instability of highly metastable alloy got delayed resulting in slight increase in the ultimate tensile strength (UTS) while maintaining comparable ductility compared to the monolithic CCAs. Superior properties of the ME-LMC are attributed to the enhanced activation of transformation and twin systems in the HCP phase due to the generation of biaxial state of stresses originating from the CCA interface affected zones. Enhanced transformation and twinning led to the greater dynamic refinement of the microstructure providing higher strain hardening enabling greater ductility while benefitting from the dynamic Hall-Petch strengthening. A dislocation density evolution based modelling framework is developed to elucidate the enhancement in mechanical properties.},
  archive      = {J_MATDES},
  author       = {Roopam Jain and Ravi Sankar Haridas and Prithvi Awasthi and Abhijeet Dhal and Rajiv S. Mishra},
  doi          = {10.1016/j.matdes.2025.113786},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113786},
  shortjournal = {Mater. Des.},
  title        = {Evading strength-ductility trade-off in a metastability engineered layered metallic composite},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling plastic deformation of TWIP steel using cohesive
zone and crystal plasticity finite element. <em>MATDES</em>,
<em>252</em>, 113785. (<a
href="https://doi.org/10.1016/j.matdes.2025.113785">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research, the cohesive zone model-crystal plasticity finite element (CZM-CPFE) method was applied to reveal the influence mechanism of grain boundaries (GBs) and grains on the mechanical properties of fine/ultrafine grained TWIP steels. The reliability and efficiency of this method were verified via corroborating with in-situ SEM tensile tests and EBSD/TEM characterisation. When the average grain size was refined from 8.49 to 0.70 μm, the yield stress increased from 181 to 317 MPa and the ultimate tensile strength from 868 to 1004 MPa with little loss of UE, which was successfully predicted by the CZM-CPFE method. Also, the neighbouring grain model revealed that stress concentrations are pronounced near GBs with high misorientation angle due to the dislocation motion and twin growth hindered by GBs. Furthermore, the simulation and experimental results indicated that the critical resolved shear stress (CRSS) for twinning increased to 202 MPa for average grain size reduction to 0.70 μm, which was much higher than the 138.5 MPa for slip, making twin activation more difficult. The application of this work in steels with moderate grain sizes can facilitate understanding of the evolution of the slip and twins and the strain hardening.},
  archive      = {J_MATDES},
  author       = {Wang Cai and Chaoyang Sun and Hongjia Zhang and Lingyun Qian and Linghui Meng and M.W. Fu},
  doi          = {10.1016/j.matdes.2025.113785},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113785},
  shortjournal = {Mater. Des.},
  title        = {Modeling plastic deformation of TWIP steel using cohesive zone and crystal plasticity finite element},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Free volume and nonlinear viscoelasticity in
supercrystalline nanocomposites: A nanoindentation driven modelling
analysis. <em>MATDES</em>, <em>252</em>, 113784. (<a
href="https://doi.org/10.1016/j.matdes.2025.113784">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supercrystalline nanocomposites (SCNCs) are a new class of hybrid materials consisting of organically functionalized nanoparticles that are arranged into periodic architectures, featuring multi-functional properties. While their mechanical behavior is starting to be assessed, the time-dependent aspects thereof, and especially creep, remain unexplored. This lack of understanding is an obstacle towards future implementation of SCNCs into devices. It is therefore imperative not only to capture experimentally the creep behavior of SCNCs, but also to develop models that accurately predict its evolution. Here, a model is proposed to capture the nanoindentation creep behavior of SCNCs, using both rheological models and free volume theory. The creep compliance derived from the rheological model shows a stress-dependent trend, indicating nonlinear viscoelasticity. The presence of free volume is experimentally detected in SCNCs via positron annihilation lifetime spectroscopy. It decreases in size with increasing degrees of crosslinking of the organic phase, a phenomenon attributed to the shrinkage of superlattices. The creep compliance is predicted by introducing a shift factor to account for the evolution of the relaxation time caused by the change in free volume. A free volume-based creep model is proposed to predict the creep behavior of SCNCs, and its applicability is validated through new nanoindentation creep tests at varying loads.},
  archive      = {J_MATDES},
  author       = {Cong Yan and Eric Hirschmann and Marc G.D. Geers and Diletta Giuntini},
  doi          = {10.1016/j.matdes.2025.113784},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113784},
  shortjournal = {Mater. Des.},
  title        = {Free volume and nonlinear viscoelasticity in supercrystalline nanocomposites: A nanoindentation driven modelling analysis},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Additive manufacturing of multi-material parts – effect of
heat treatment on thermal, electrical, and mechanical part properties of
316L/CuCrZr. <em>MATDES</em>, <em>252</em>, 113783. (<a
href="https://doi.org/10.1016/j.matdes.2025.113783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in multi-material powder bed fusion of metals using a laser beam (PBF-LB/M) facilitate manufacturing 3D parts with an arbitrary voxel-wise material distribution, using 316L and CuCrZr alloy in a single-step process. This combination leverages each material&#39;s distinct advantages for applications requiring high strength, corrosion resistance, and superior thermal and electrical conductivity. However, inherent anisotropy at the interface between these materials poses significant challenges, impacting the integrity of material interfaces and affecting the materials&#39; properties. This research investigates the influence of three different build orientations (CuCrZr on 316L, 316L on CuCrZr, and CuCrZr next to 316L) on interface quality and part performance. Techniques like microscopy imaging, laser flash analysis, and eddy current measurements, alongside Vickers hardness tests, were employed. Aging at 500 °C for 1.5 hours increased CuCrZr&#39;s conductivity by 250% and doubled its hardness. Samples with 316L built on CuCrZr showed reduced thermal contact resistance, suggesting this configuration is preferable for efficient heat transfer. Moreover, 316L contamination reduced the microhardness of CuCrZr, impacting its precipitation hardening potential. These findings underscore the importance of strategic material selection and arrangement within the PBF-LB/M process and highlight the benefits and challenges of heat treatment and contamination.},
  archive      = {J_MATDES},
  author       = {Ina Meyer and Cameron Owen Messmann and Tobias Ehlers and Roland Lachmayer},
  doi          = {10.1016/j.matdes.2025.113783},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113783},
  shortjournal = {Mater. Des.},
  title        = {Additive manufacturing of multi-material parts – effect of heat treatment on thermal, electrical, and mechanical part properties of 316L/CuCrZr},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Achieving superior mechanical properties by regulating
nano-phases in cast al-li alloys: Experimental and simulation.
<em>MATDES</em>, <em>252</em>, 113782. (<a
href="https://doi.org/10.1016/j.matdes.2025.113782">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the outstanding advantages such as low density, high modulus, and high damage tolerance, cast Al-Li alloys are highly promising metallic materials for load-bearing applications in the coming decades. However, compared to their wrought counterparts, the mechanical properties of these alloys, particularly the ductility, are still unsatisfactory, which severely limits their further applications. Here, we report that the mechanical properties of cast Al-Li alloys can be significantly improved by regulating various nano-phases during aging. Results show that the introduction of 0.2 wt% Zr in the Al-2Li-2Cu-0.5 Mg alloy contributes to grain refinement by providing a large number of primary Al 3 Zr particles acting as ideal heterogeneous nucleation sites for the α-Al matrix. During subsequent aging, Al 3 Li tends to nucleate and grow on the Al 3 Zr surface to reduce the interfacial energy and form a nano-complex with a core–shell structure in 0.2Zr alloy. Then, the Al 3 Li shell can serve as an effective nucleation site for the T 1 and θʹ phases. Density functional theory (DFT) calculations indicate that nucleation of T 1 and θʹ on the Al 3 Li shell reduces the interfacial energy, which promotes their uniform precipitation. In this case, unique Al 3 (Zr, Li) particles and higher density of finer T 1 and θʹ phases provide a substantial Orowan strengthening effect, alleviating the stress concentration. In addition, grain refinement improves the coordination of plastic deformation in 0.2Zr alloys. As a result, the ductility of 0.2Zr alloy increases from 3.6 % to 7.1 % compared to the Base alloy, accompanied by a 66 MPa increase in ultimate tensile strength. This work is expected to offer a new engineering approach to designing high-performance cast Al-Li alloy components with broad application prospects.},
  archive      = {J_MATDES},
  author       = {Wengang Bu and Pengfei He and Jiamao Hao and Rong Wang and Zhenfeng Hu and Jinyong Mo and Xiubing Liang},
  doi          = {10.1016/j.matdes.2025.113782},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113782},
  shortjournal = {Mater. Des.},
  title        = {Achieving superior mechanical properties by regulating nano-phases in cast al-li alloys: Experimental and simulation},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Longitudinal wave propagation behavior and dimension effect
of origami-inspired metamaterials prepared by laser powder bed fusion.
<em>MATDES</em>, <em>252</em>, 113781. (<a
href="https://doi.org/10.1016/j.matdes.2025.113781">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Origami principles have garnered significant attention in science and engineering due to their unique deformation behaviors and resultant mechanical properties. This study introduces an innovative elastic metamaterial inspired by Miura-origami tubes, fabricated using laser powder bed fusion (LPBF), a prevalent additive manufacturing technique. The metamaterial’s unit cell consists of a diamond-shaped frame and a pair of orthogonal springs, displaying quasi-zero stiffness through the interaction of lateral and longitudinal springs, which balances internal pressure and tension. The transmission and dispersion of longitudinal waves in these metamaterials, with varying structural parameters, were systematically investigated. The findings demonstrate that the Miura-origami inspired metamaterial can generate ultra-wide band gaps for low-frequency longitudinal waves (500 Hz to 2500 Hz). It effectively converts longitudinal waves into other energy forms via internal vibration mode transformations. Structural parameters critically impact the metamaterial’s mechanical performance and manufacturing quality. Optimal parameters for LPBF fabrication were identified through rigorous experiments and simulations. These origami-inspired elastic metamaterials show substantial promise for vibration mitigation in civil, medical, mechanical, and aerospace engineering applications.},
  archive      = {J_MATDES},
  author       = {Ke Chen and Haoran Wan and Hongyu Chen and Xiang Fang and Tiwen Lu and Yonggang Wang and Yang Liu and Konrad Kosiba},
  doi          = {10.1016/j.matdes.2025.113781},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113781},
  shortjournal = {Mater. Des.},
  title        = {Longitudinal wave propagation behavior and dimension effect of origami-inspired metamaterials prepared by laser powder bed fusion},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Current-assisted low-temperature silver sinter bonding to
silicon carbide by utilizing ion migration. <em>MATDES</em>,
<em>252</em>, 113780. (<a
href="https://doi.org/10.1016/j.matdes.2025.113780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sinter bonding using fine metal particles has attracted significant attention as a promising technology for next-generation power devices. However, achieving high-strength joints between semiconductor materials and metal substrates remains challenging due to the low interfacial bonding ratios, leading to interfacial fractures that weaken the joint. Herein, we demonstrate a current-assisted low-temperature Ag sinter bonding process for SiC, utilizing ion migration within the bonding layer. The process significantly improved the joint strength by enhancing the interfacial bonding properties via Ag precipitation on the SiC surface. The precipitation, facilitated by the current-driven migration of Ag ions derived from the decomposition of compounds, effectively increased the density and interfacial bonding ratio of the sintered Ag layer, thereby mitigating interfacial fracture. Based on these findings, we successfully achieved current-assisted sinter bonding, notably at room temperature. Furthermore, the current-driven migration of the generated Ag ions was sufficiently induced even with a minimal amount of Ag compounds. Accordingly, the joint properties were further enhanced by suppressing localized vulnerability in the sintered Ag layer through the optimization of the Ag 2 O mixture ratio in the bonding paste. This current-assisted process plays a crucial role in achieving reliable low-temperature sinter bonding, essential for advanced electronics packaging.},
  archive      = {J_MATDES},
  author       = {Tetsuhiro Matsuda and Tomoki Matsuda and Makoto Kambara and Akio Hirose},
  doi          = {10.1016/j.matdes.2025.113780},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113780},
  shortjournal = {Mater. Des.},
  title        = {Current-assisted low-temperature silver sinter bonding to silicon carbide by utilizing ion migration},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Programmable helix-tubular composites with bio-inspired
architecture. <em>MATDES</em>, <em>252</em>, 113779. (<a
href="https://doi.org/10.1016/j.matdes.2025.113779">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The programmable materials have attracted attention for its groundbreaking functionalities across diverse applications, especially the curl-fiber reinforced composites inspired from collagen fibers. In this work, a novel helix-tubular composite (HTC) is developed through an integrated braiding-knitting fabrication approach. Experimental analyses demonstrate that the mechanical properties of HTC can be directionally optimized through parameterization of secondary conformational architecture and coupling states. Remarkably, HTC manifests triphasic nonlinear mechanical behavior analogous to native ligamentous tissues. This biomimetic response originates from synergistic interactions between the stiff helix conformation (the stiff conformation) and highly stretchable tubular conformation (the stretchable conformation). Furthermore, cyclic tensile evaluations reveal exceptional fatigue resistance exceeding thousands of cycles. This durability substantiates the composite’s potential for replicating the multifunctional mechanical behavior of biological tendons and ligaments. These findings establish a methodological framework for engineering advanced materials with spatially programmable mechanical properties through conformational coupling.},
  archive      = {J_MATDES},
  author       = {Tong Yang and Zhijia Dong and Chaoyu Chen and Jun Song and Pibo Ma},
  doi          = {10.1016/j.matdes.2025.113779},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113779},
  shortjournal = {Mater. Des.},
  title        = {Programmable helix-tubular composites with bio-inspired architecture},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scalable phononic metamaterials: Tunable bandgap design and
multi-scale experimental validation. <em>MATDES</em>, <em>252</em>,
113778. (<a href="https://doi.org/10.1016/j.matdes.2025.113778">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Phononic metamaterials offer unprecedented control over wave propagation, making them essential for applications such as vibration isolation, waveguiding, and acoustic filtering. However, achieving scalable and precisely tunable bandgap properties across different length scales remains challenging. This study presents a user-friendly design framework for phononic metamaterials, enabling ultra-wide bandgap tunability ( B/ ω c ratios up to 172 %) across multiple frequency ranges and scales. Using finite element simulations of a Yablonovite-inspired unit cell, we establish a comprehensive parametric design space that illustrates how geometric parameters, such as sphere size and beam diameter, controls bandgap width and frequency. The scalability and robustness of the framework are validated through experimental testing on additively manufactured structures at both macro (10 mm) and micro (80 µm) scales, fabricated using Stereolithography and Two-Photon Polymerization. Transmission loss measurements, conducted with piezoelectric transducers and laser vibrometry, closely match simulations in the kHz and MHz frequency ranges, confirming the reliability and consistency of the bandgap behavior across scales. This work bridges theory and experiments at multiple scales, offering a practical methodology for the rapid design of phononic metamaterials and expanding their potential for diverse applications across a broad range of frequencies.},
  archive      = {J_MATDES},
  author       = {Timon Meier and Vasileios Korakis and Brian W. Blankenship and Haotian Lu and Eudokia Kyriakou and Savvas Papamakarios and Zacharias Vangelatos and M. Erden Yildizdag and Gordon Zyla and Xiaoxing Xia and Xiaoyu Zheng and Yoonsoo Rho and Maria Farsari and Costas P. Grigoropoulos},
  doi          = {10.1016/j.matdes.2025.113778},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113778},
  shortjournal = {Mater. Des.},
  title        = {Scalable phononic metamaterials: Tunable bandgap design and multi-scale experimental validation},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mechanical properties of CoCrFeMnNi high entropy alloy
lattice structures formed by selective laser melting. <em>MATDES</em>,
<em>252</em>, 113777. (<a
href="https://doi.org/10.1016/j.matdes.2025.113777">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The special structure of the lattice structure makes it have many excellent properties. CoCrFeMnNi high-entropy alloys (HEAs) is widely used due to its good plasticity, low temperature strength and other advantages. To enhance the mechanical properties of the lattice structure, a unique decahedral internal diamond (DID) unit cell type was designed to construct the periodic lattice structure. The DID lattice structure was prepared by SLM using CoCrFeMnNi HEAs spherical powder as the material, and its surface morphology was observed under SEM. In comparison to conventional lattice structures, various lattice structures’ mechanical properties and deformation behaviors were analyzed using quasi-static compression tests and finite element analysis. Additionally, the effects of different rod diameter on the compressive performance and energy absorption characteristics of the DID lattice structure were also studied. The results show that the lattice structure prepared by SLM has good forming quality. In the tested samples, the DID structure has better bearing capacity and energy absorption performance, and the yield strength of the DID lattice structure with an overall size of 15 mm × 15 mm × 15 mm and a relative density of 25 % is 66 MPa, and the Young’s modulus is 3798 MPa. In addition, increasing the rod diameter can reduce the forming defects of the crossbar and further improve the compressive performance and energy absorption characteristics of the DID structure. This study provides a theoretical reference for the design and fabrication of load-absorber integrated structures, and confirms that the CoCrFeMnNi HEAs DID lattice structure can be used for lightweight support manufacturing applications.},
  archive      = {J_MATDES},
  author       = {Yangwei Du and Ketai He and Rong Guo and Zhipeng Zhou and Guoxuan Ming and Qi Liu and Hao Dong},
  doi          = {10.1016/j.matdes.2025.113777},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113777},
  shortjournal = {Mater. Des.},
  title        = {Mechanical properties of CoCrFeMnNi high entropy alloy lattice structures formed by selective laser melting},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards understanding the machining effect on the additively
manufactured stainless steel for various scanning directions: Texture
evolution and mechanical properties. <em>MATDES</em>, <em>252</em>,
113776. (<a href="https://doi.org/10.1016/j.matdes.2025.113776">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Additive manufacturing (AM) technology hybridized with subtractive manufacturing has been extensively applied as a solution for the fabrication of functional parts. However, the complicated morphologies and anisotropic properties of the resultant grain features lead to challenges in the metallurgical and mechanical analysis of the cutting process of AM-materials, affecting the understanding on mechanical strength alteration of the final surface. In this study, a crystallographic-texture-based analysis method is proposed to elucidate the cutting-induced microstructural alteration from the grain to the texture level, enabling a comprehensive understanding of the collective effect of the hybrid cutting process on the resultant surface. Orthogonal cutting on additively manufactured 17–4 PH stainless steel applying three scanning directions was conducted to produce cut surfaces. In-depth electron backscatter diffraction inspection was applied for quantitative texture analysis based on the calculation of the orientation distribution function and volume fractions of significant texture components. As a result, the textures of the machined surfaces showed an increased intensity of normal direction fiber component to that of building direction with respect to 0° and 90° owing to cutting-induced deformation. This work advances the understanding on the roles of textural evolution for achieving a better surface quality regulation via function-oriented hybrid manufacturing process.},
  archive      = {J_MATDES},
  author       = {Chao Wang and Zhenglong Fang and Toru Kizaki and Naohiko Sugita},
  doi          = {10.1016/j.matdes.2025.113776},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113776},
  shortjournal = {Mater. Des.},
  title        = {Towards understanding the machining effect on the additively manufactured stainless steel for various scanning directions: Texture evolution and mechanical properties},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tuning anionic components to control the phase stability and
mechanical properties of high-entropy carbonitrides. <em>MATDES</em>,
<em>252</em>, 113775. (<a
href="https://doi.org/10.1016/j.matdes.2025.113775">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influence of nitrogen on the synthesis and mechanical properties of high-entropy carbonitride are evaluated in (Ti, Zr, Nb, Mo, Ta)C x N 1-x solid solution (denoted as HECN) through experimental method, thermodynamic calculations and ab-intio modeling. HECN powders with varying nitrogen content are fabricated using an open dynamic carbothermal reduction nitriding method. Both the calculation and experiment results indicate that the higher nitrogen content alters the bonding behavior and charge distribution difference of HECN due to the highly distorted crystal lattice. Leading the increase of formation energy between the HECN and sub-system configurations, resulting in decreased phase stability. Due to the correlation between electronic structure and mechanical properties calculated by Density functional theory and integrated density of states, HEC 0.9 N 0.1 exhibits the highest mechanical properties, with a hardness of 20.1 ± 0.1 GPa at 49N and an indentation fracture resistance ( K IC ) of 5.54 ± 0.16 MPa∙m 1/2 . The weak bonding characteristic between Mo and N atoms contributes to the reduced phase stability and the random atomic occupation. This work reveals the nitridation characteristics critical for the design and preparation of high entropy systems and elucidates the correlation between nitrogen content and intrinsic properties, providing a feasible strategy for guiding the design and synthesis of HECN ceramics.},
  archive      = {J_MATDES},
  author       = {Yifan Li and Zhiyao Ouyang and Yongye Ding and Ying Liu and Na Jin and Jinwen Ye},
  doi          = {10.1016/j.matdes.2025.113775},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113775},
  shortjournal = {Mater. Des.},
  title        = {Tuning anionic components to control the phase stability and mechanical properties of high-entropy carbonitrides},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High efficient near-infrared sintering for
electrohydrodynamic printed frequency selective surface.
<em>MATDES</em>, <em>252</em>, 113774. (<a
href="https://doi.org/10.1016/j.matdes.2025.113774">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The efficient and compatible nano-silver paste sintering technology is significant for printed electronics. However, the current sintering technology still has limitations in terms of sintering time, post-sintering resistivity, and applicable types of substrates. Here we propose a highly efficient near-infrared sintering method for electrohydrodynamic (EHD) printed nano-silver paste. This method is suitable for sintering of nano-silver ink for large curved circuits manufacturing, achieving excellent film conductivity along with enhancing its interfacial strength. This article focuses on exploring the effects of process parameters such as near-infrared sintering power, time and lap-substrate distance on efficiency and resistivity, and ultimately achieving a rapid sintering of nano-silver paste with a resistivity of 12.8 × 10 − 8 Ω ⋅ m . This method adopted near-infrared sintering to sinter nano-silver ink circuits created by EHD printing, followed by plasma treatment to enhance the interfacial strength up to 5B level. Finally, we have successfully fabricated both planar and curved frequency selective surface (FSS) by the above-mentioned methods. The planar FSS sample presented a shielding capability of 2̃5 dB at resonant frequencies of 6 GHz and 10 GHz, which is quite accordance to the simulation results. This method shows great potential for application in large-scale, high-efficiency printed electronics fabrication.},
  archive      = {J_MATDES},
  author       = {Long Bai and Ziru Wang and Dong Ye and Hanghang Wei and Zihan Peng and Jiaying Ge and Siwei Tan and Tianxiang Li and Hao Wu},
  doi          = {10.1016/j.matdes.2025.113774},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113774},
  shortjournal = {Mater. Des.},
  title        = {High efficient near-infrared sintering for electrohydrodynamic printed frequency selective surface},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Size-controlled synthesis of ultrafine silver powders for
electronic paste using a one-pot aqueous method. <em>MATDES</em>,
<em>252</em>, 113773. (<a
href="https://doi.org/10.1016/j.matdes.2025.113773">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Silver nanoparticles possess unique electrical, thermal, and catalytic properties, making them valuable in various fields such as flexible electronics printing, electronic device interconnections, and solar energy applications. Controlling the size of silver nanoparticles is critical to its properties and determining the application. This study investigates the influence of reaction rates on the size of silver nanoparticles synthesized in aqueous solutions. The precursor of silver ammonia concentrations from 5 to 160 mM was explored, revealing a positive correlation between reactant concentration and particle size that challenges traditional theories. It results from aggregation growth facilitated by high concentrations, leading to significant increases of particle size, with a trigger of 10 mM. Furthermore, when fix the precursor concentration, the instantaneous and homogeneous concentrations of the reducing agent have completely opposite effects. Specifically, decreasing the instantaneous concentration while increasing the homogeneous concentration compress the reaction zone and refined particle size distributions. It successfully shrank the particle size from 510 to 140 nm for the condition of 20 mM precursor concentration. Additionally, lower temperatures bring a anisotropic self-assemble, while higher temperatures result in a random growth. At last, the size of silver particles exhibits distinct effects on the printing performance and conductivity of silver paste.},
  archive      = {J_MATDES},
  author       = {Zhe Huang and Jin Yang and Baishan Chen and Minggang Li and Siwei Tang and Yunzhu Ma and Wensheng Liu},
  doi          = {10.1016/j.matdes.2025.113773},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113773},
  shortjournal = {Mater. Des.},
  title        = {Size-controlled synthesis of ultrafine silver powders for electronic paste using a one-pot aqueous method},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Active learning-based alloy design strategy for improving
the strength-ductility balance of al-mg-zn alloys. <em>MATDES</em>,
<em>252</em>, 113772. (<a
href="https://doi.org/10.1016/j.matdes.2025.113772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Al-Mg-Zn alloys, designed to combine the formability of 5xxx alloys with the high strength of 7xxx alloys, still face challenges in achieving an optimal strength-ductility balance. This study presents an active learning-based alloy design strategy to guide experiments aimed at enhancing the strength-ductility balance in Al-Mg-Zn alloys. Firstly, a sub-dataset comprising ultimate tensile strength (UTS) and elongation (EL) data with optimal generalization ability was identified from the small and disordered Al-Mg-Zn dataset using the bagging method. Subsequently, the bagging model of this sub-dataset was employed to construct a Pareto front based on the Upper Confidence Bound for UTS and EL, providing guidance for alloy composition design. Through experimental validation and iterative optimization, the strength-ductility balance of Al-Mg-Zn alloys was significantly improved, with the designed Al-5.27Mg-2.8Zn-0.44Cu-0.19Ag-0.15Sc-0.05Mn-0.01Zr alloy (wt.%) exhibiting superior mechanical properties with the measured UTS of 602 MPa and EL of 15.1 %. Microstructural analysis using SEM, EBSD and TEM revealed that the improved strength-ductility balance of the alloy is attributed to its optimized composition, which results in the minimal micron phases, numerous fine Al 3 Sc particles, low-recrystallization grains, and a high density of precipitates. This active learning-based design strategy offering a novel approach for material development in systems with limited data.},
  archive      = {J_MATDES},
  author       = {Wuwei Mo and Yao Xiao and Yushen Huang and Peng Sun and Ya Li and Xiaoyu Zheng and Qiang Lu and Bo Li and Yuling Liu and Yong Du},
  doi          = {10.1016/j.matdes.2025.113772},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113772},
  shortjournal = {Mater. Des.},
  title        = {Active learning-based alloy design strategy for improving the strength-ductility balance of al-mg-zn alloys},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design strategy for al-containing metallic glasses by
entropy engineering and covalent attribute. <em>MATDES</em>,
<em>252</em>, 113771. (<a
href="https://doi.org/10.1016/j.matdes.2025.113771">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional approaches to the composition design of metallic glasses often disregard the distinct nature of metallic and covalent interactions, leading to challenges in accurately incorporating specific elements that are more covalent and understanding their interactions. This limitation complicates the quantitative design process and hinders the development of a comprehensive theoretical framework. To address this, we propose a novel design strategy based on entropy engineering to tune metallic bonds using melting entropy, while the covalent interactions is guided by mixing enthalpy. Applying this method, we successfully designed the metallic glasses La 60.6 Ni 22.9 Al 17.5 and La 62.2 Ni 11.8 Cu 12.7 Al 13.2 whose GFA is highly consistent with the reported components.},
  archive      = {J_MATDES},
  author       = {Bing-Tao Wang and Zi-Jing Li and Shi-Dong Feng and Li-Min Wang},
  doi          = {10.1016/j.matdes.2025.113771},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113771},
  shortjournal = {Mater. Des.},
  title        = {Design strategy for al-containing metallic glasses by entropy engineering and covalent attribute},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). First-principles study on the faulted interface of
dislocation-sheared t1 precipitates. <em>MATDES</em>, <em>252</em>,
113770. (<a href="https://doi.org/10.1016/j.matdes.2025.113770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The T 1 phase is a crucial shearable precipitate that enhances the strength of Al-Cu-Li alloys. Its strengthening effect is associated with the energy of the faulted interfaces generated upon dislocation-shearing of the precipitates. Due to the extremely small size of the T 1 phase, this energy cannot be directly measured, and the atomic arrangement around the faulted interface has never been characterized, leading to a knowledge gap regarding these interfaces. This work constructed large-scale supercells that encompassed both precipitate and matrix atoms for a first-principles examination of the faulted interfaces. Two opposite dislocation-shearing actions were incorporated to reserve the overall periodicity of the supercells, which is essential for compatibility with density functional theory calculations. Rigorous statistical analysis of the faulted interface energy was facilitated by modeling a variety of possible atomic arrangements of the faulted interfaces and investigating scenarios with T 1 phases of 1, 2, and 3 unit-cells in thickness. Following density functional theory relaxation of the supercells, the results demonstrated satisfactory convergence. The faulted interface energy was calculated as approximately 4 to 5 times the unstable stacking-fault energy of the matrix. The diverse thickening mechanisms of T 1 precipitates were found to significantly alter the overall FIE of the thickened precipitate.},
  archive      = {J_MATDES},
  author       = {Ruohan Shen and Xianchang Li and Panwang Zhou},
  doi          = {10.1016/j.matdes.2025.113770},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113770},
  shortjournal = {Mater. Des.},
  title        = {First-principles study on the faulted interface of dislocation-sheared t1 precipitates},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Corrosion behavior of steel parts repaired using additive
manufacturing: Overview and research perspective. <em>MATDES</em>,
<em>252</em>, 113769. (<a
href="https://doi.org/10.1016/j.matdes.2025.113769">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metal Additive Manufacturing (MAM) for the repair of steel components has attracted considerable interest due to its advantages over traditional repair methods. This paper presents a comprehensive overview of the corrosion aspects of steel parts repaired using MAM, emphasizing both the benefits and challenges associated with this innovative technology. A detailed comparison is made between various MAM repair techniques and conventional methods, focusing on their effects on corrosion resistance. Key factors related to MAM such as chemical composition, microstructure, galvanic couplings, defects, and post-processing techniques are examined concerning their influence on the corrosion performance of steel-repaired components. This review identifies critical knowledge gaps, particularly concerning the need for further comparative studies and the long-term performance of MAM-repaired steel components in diverse environmental conditions. The findings underscore the experimental validation and the use of theoretical simulations to fully understand the capabilities and limitations of MAM in steel repair applications.},
  archive      = {J_MATDES},
  author       = {Marina Furbino and Rubén Del Olmo and Reynier I. Revilla and Iris De Graeve},
  doi          = {10.1016/j.matdes.2025.113769},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113769},
  shortjournal = {Mater. Des.},
  title        = {Corrosion behavior of steel parts repaired using additive manufacturing: Overview and research perspective},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Near α titanium alloy ti60 with equiaxed β grain fabricated
by laser direct energy deposition assisted with ultrasound.
<em>MATDES</em>, <em>252</em>, 113768. (<a
href="https://doi.org/10.1016/j.matdes.2025.113768">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Laser direct energy deposition (LDED) offers unique advantages in the integrated forming of 3D complex-shape parts. However, the columnar grains that grow epitaxially along the building direction are prone to reduce the performance of the as-built parts. Herein, external ultrasonic field are introduced during the LDED of near-α titanium alloy Ti60 (Ti-5.7Al-4.0Sn-3.5Zr-0.4Mo-0.4Si-0.4Nb-1.0Ta-0.05C), resulting in equiaxed β grains with an average grain size of 62.82 μm. The single track morphology, molten pool, microstructure, and mechanical properties under different ultrasonic powers are characterized and investigated. The results indicate that the ultrasound can induce columnar to equiaxed transition (CET) of the prior-β grains and promote the precipitation of silicides, but the width of the α laths increases due to heating effect caused by ultrasound. Consequently, the sample prepared with the 6 μm ultrasonic vibration exhibits a increases of 67.18 % in elongation, and the mechanical properties reach the forge standard. Finally, the effects of prior-β grain and α lath on the final mechanical properties of the samples are discussed. This work provides a deep insight into the LDED process of near-α titanium alloy Ti60 assisted with ultrasound.},
  archive      = {J_MATDES},
  author       = {Yuxiang Ai and Jiasen Han and Yuanxi Huang and Kuitong Yang and Yang Zhou and Hui Chen and Xin Lin and Wentao Yan},
  doi          = {10.1016/j.matdes.2025.113768},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113768},
  shortjournal = {Mater. Des.},
  title        = {Near α titanium alloy ti60 with equiaxed β grain fabricated by laser direct energy deposition assisted with ultrasound},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physical twin of an industrial quad-laser powder bed fusion
machine for high-speed multi-modal sensing measurements.
<em>MATDES</em>, <em>252</em>, 113767. (<a
href="https://doi.org/10.1016/j.matdes.2025.113767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To faithfully capture the laser-material interaction and subsequent process dynamics during the industrial laser powder bed fusion process, we developed a Quad-laser in situ and operando process replicator (or the Quad-ISOPR) – a physical twin that mimics the Renishaw plc.’s RenAM 500Q multi-laser additive manufacturing system that can be used in laboratories and synchrotron radiation facilities. The Quad-ISOPR allows users to take synchrotron X-ray measurements while collecting correlative high-speed optical and photodiode imaging within a 10 ns delay, mounted in-line with the scanning lasers. We have selected case studies to demonstrate: (i) multi-modal data acquisition; (ii) signal processing using continuous wavelet transform; (iii) the study of laser drilling with ultra high-speed X-ray imaging; (iv) process mapping of melting and defect modes in Ti-6Al-4V; and lastly, (v) we showcase the interaction between multi-lasers on a Ti-6Al-4V alloy. Our experimental approach allows end-users to explore the process-structure–property relationship in multi-laser material processing and to use such the physical twin to design new materials and processes.},
  archive      = {J_MATDES},
  author       = {Samy Hocine and Sebastian Marussi and Andrew Farndell and Elena Ruckh and Rubén Lambert-Garcia and Anna C.M. Getley and Kwan Kim and Nick Jones and Maureen Fitzpatrick and Marta Majkut and Alexander Rack and Peter D. Lee and Chu Lun Alex Leung},
  doi          = {10.1016/j.matdes.2025.113767},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113767},
  shortjournal = {Mater. Des.},
  title        = {Physical twin of an industrial quad-laser powder bed fusion machine for high-speed multi-modal sensing measurements},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). In-situ immobilization technique for radioactive cesium
using laser technology for fukushima daiichi decommissioning.
<em>MATDES</em>, <em>252</em>, 113766. (<a
href="https://doi.org/10.1016/j.matdes.2025.113766">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The decommissioning of the Fukushima Daiichi (1F) nuclear power plant remains a significant environmental concern. A crucial aspect of this process involves the effective immobilization of 137 Cs to reduce the volume of radioactive waste. This technique traps radioactive materials that adhere to the concrete surface by embedding in the glass, allowing only the glass to be removed during decommissioning. In this study, we first irradiated concrete mixed with 133 Cs, which had the same composition as the nuclear reactor building at 1F, using a high-brightness laser beam to immobilize Cs. We then investigated the characteristics of in-situ immobilization of Cs from the aspects of distribution, migration, and elution. X-ray diffraction (XRD) results indicate that the concrete underwent vitrification. Measurements from an electron probe microanalyzer (EPMA) show that Cs exhibits aggregate-dependent heterogeneity within the fused, glass-like concrete. The experimental migration rate of 99 % is more reliable compared to the 57 % achieved through conventional thermal plasma melting of simulated low-level radioactive waste. As far as elution is concerned, the normalized mass loss of the elements is 0.06 to 0.08 g/m 2 , which is below the 2 g/m 2 limit set by the American Society for Testing and Materials (ASTM) International. Consequently, laser-assisted in-situ immobilization of Cs has superior potential for supporting the decommissioning of 1F by effectively utilizing the hazardous materials on site.},
  archive      = {J_MATDES},
  author       = {Hitoshi Ozaki and Yosuke Kawahito and Michiko Mori and Masahito Shibata and Tsuyoshi Nakamura and Tatsuya Mase and Hiroyuki Yoshida and Hiroshi Kawakami and Muneo Hori},
  doi          = {10.1016/j.matdes.2025.113766},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113766},
  shortjournal = {Mater. Des.},
  title        = {In-situ immobilization technique for radioactive cesium using laser technology for fukushima daiichi decommissioning},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A skeletonization based image segmentation algorithm to
isolate slender regions in 3D microstructures. <em>MATDES</em>,
<em>252</em>, 113765. (<a
href="https://doi.org/10.1016/j.matdes.2025.113765">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The work proposes an image segmentation algorithm that isolates slender regions in three-dimensional microstructures. Characterizing slender regions in material microstructures is an extremely important aspect in material science because these regions govern the macroscopic behavior of materials for many applications like energy absorption, activation of metamaterials, stability of high temperature filters, etc. This work utilizes skeletonization method to calculate centerline of the microstructure geometry followed by a novel pruning strategy based on cross-sectional area to identify slender regions in the microstructure. 3D images of such microstructures obtained from micro-CT often suffer from low image resolution resulting in high surface noise. The skeleton of such an image has many spurious skeletal branches that do not represent the actual microstructure geometry. The proposed pruning method of cross-sectional area is insensitive to surface noise and hence is a reliable method of identifying skeletal branches that represent the slender regions in the microstructure. The proposed algorithm is implemented on a test case to showcase its effectiveness. Further it is implemented on a 3D microstructure of ceramic foam to identify the slender regions present in it. It is shown that the method can be used to segment slender regions of varying dimensions and to study their geometric properties.},
  archive      = {J_MATDES},
  author       = {Vinit Vijay Deshpande and Romana Piat},
  doi          = {10.1016/j.matdes.2025.113765},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113765},
  shortjournal = {Mater. Des.},
  title        = {A skeletonization based image segmentation algorithm to isolate slender regions in 3D microstructures},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Specific activation of cGAS-STING pathway by manganese-doped
bioactive glasses for boosting systemic tumor immunotherapy.
<em>MATDES</em>, <em>252</em>, 113764. (<a
href="https://doi.org/10.1016/j.matdes.2025.113764">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recurrence and metastasis of renal cell carcinoma present significant challenges in clinical settings, necessitating the urgent development of strategies to enhance the efficacy of kidney cancer treatments. In this study, we designed and developed a manganese-doped bioactive glass-based (Mn-MBG) core, creating a Mn-rich nanotherapeutic platform named MMPI. This platform was further modified by encapsulation with polydopamine (PDA) and successfully loaded with the photosensitizer indocyanine green (ICG) through π-π stacking interactions, enabling photothermal therapy (PTT) and photodynamic therapy (PDT). In vitro experiments demonstrated that under near-infrared (NIR) irradiation, MMPI could generate a moderate photothermal effect, causing damage to tumor cells. At the same time, the photothermal effect enhanced Mn 2+ and ICG release and increased reactive oxygen species (ROS) production, intensifying damage to heat-sensitive tumor cells and aiding tumor elimination. In vivo experiments showed that MMPI can counteract the tumor’s immunosuppressive environment by activating the cGAS-STING pathway, boosting local innate immune cell recruitment, dendritic cell maturation, and T cell-mediated adaptive antitumor responses. In conclusion, this study elucidates the concept of a manganese-based non-invasive tumor immunotherapy model, establishing a paradigm for immunotherapeutic approaches in renal cell carcinoma.},
  archive      = {J_MATDES},
  author       = {Zhaolin Yang and Jiale Zhou and Xinrui Wu and Sian Zhou and Wei Xue and Jiahua Pan and Yonghui Chen and Xiaorong Wu},
  doi          = {10.1016/j.matdes.2025.113764},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113764},
  shortjournal = {Mater. Des.},
  title        = {Specific activation of cGAS-STING pathway by manganese-doped bioactive glasses for boosting systemic tumor immunotherapy},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spiral kinematics: A biomimetic approach to enhancing
demolding efficiency in 3D-printed polymeric formworks for customized
hollow concrete structures. <em>MATDES</em>, <em>252</em>, 113763. (<a
href="https://doi.org/10.1016/j.matdes.2025.113763">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The customization of hollow concrete components has gained significant attention for enhancing multi-functional performance, including structural efficiency, thermal and acoustic properties; however, it also poses challenges in fabricating complex geometries. Conventional concrete formwork often faces demolding difficulties, which can damage both the formwork and the concrete and lead to increased costs and environmental impact. This study introduces a novel approach where polymeric formworks with biomimetic spiral designs are fabricated by 3D-priniting. Such customized 3D-printed formwork designs introduce a kinematic mechanism to enhance demolding efficiency while maintaining structural integrity. Polylactic acid (PLA) and thermoplastic polyurethane (TPU) were used to fabricate 3D-printed polymer bars with varying spiral gap lengths (0.2 mm and 0.6 mm), which were tested under monotonic pull-out conditions, mimicking formwork extraction from hollow concrete components. The spiral designs significantly reduce pull-out resistance, demolding difficulty, and associated damage. The kinematic benefits from spirals can be further amplified by adopting wider spiral gaps or by selecting TPU as the 3D printing filament, due to its greater toughness and flexibility, which resemble those of elastomeric materials. This work advances concrete demolding through innovative design optimization and offers practical solutions for greater customization and fabrication efficiency for intricate concrete structures.},
  archive      = {J_MATDES},
  author       = {Zhuyin Lu and Shawn Owyong and Xin Tian and Pei Xuan Tan and Yi Xuan Liau and Siti Nur Ain Abdul Aziz and Hanmo Wang and Alexander Lin},
  doi          = {10.1016/j.matdes.2025.113763},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113763},
  shortjournal = {Mater. Des.},
  title        = {Spiral kinematics: A biomimetic approach to enhancing demolding efficiency in 3D-printed polymeric formworks for customized hollow concrete structures},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 3D printing of curved continuous fibre filaments using fused
deposition modelling. <em>MATDES</em>, <em>252</em>, 113762. (<a
href="https://doi.org/10.1016/j.matdes.2025.113762">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fused deposition modelling (FDM) is a 3D printing technique capable of fabricating intricately shaped composites through the deposition of continuous fibre filaments. This study investigates the limitations of 3D printing curved filaments using FDM. Polyamide matrix filaments containing continuous carbon, glass, or aramid fibres were 3D printed into curved profiles with different radii as low as 1 mm. A detailed microstructural and mechanical analysis was conducted to assess the damage incurred during curved printing. The deposition mechanism of the FDM process was found to lack high dimensional accuracy when 3D printing continuous fibre filaments in tight curvatures. Issues including filament peeling and twisting resulted in printing error of up to 60 % in the curvature radius, depending on the fibre types. The filaments experienced fibre damage, matrix tearing, and shape distortion during the curved printing process, which subsequently reduced the tensile properties of the printed composites. The average filament strengths were found to be only 30 %, 41 % and 64 % compared to that of the straight printed filament for carbon, glass, and aramid fibre filaments, respectively, when the radius was below 5 mm. These findings provide foundations for identifying optimal FDM printing conditions to produce defect-free composite with complex structures.},
  archive      = {J_MATDES},
  author       = {Yiwei Hu and Adrian P. Mouritz and Raj B. Ladani and Yazhi Li and Shaoyu Zhao and Huanxin Zhang},
  doi          = {10.1016/j.matdes.2025.113762},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113762},
  shortjournal = {Mater. Des.},
  title        = {3D printing of curved continuous fibre filaments using fused deposition modelling},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A static and high-cycle fatigue characterization framework
of metallic lattice structures additive manufactured via fused
deposition modeling based method. <em>MATDES</em>, <em>252</em>, 113761.
(<a href="https://doi.org/10.1016/j.matdes.2025.113761">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared to conventional metal additive manufacturing techniques, metal fused deposition modeling (Metal FDM) reduces cost at the expense of deterioration in materials’ mechanical performance. To realize the full design potential that Metal FDM components can offer, effectively predicting the performance becomes imperative, especially for lattice structures that are widely used in aerospace under complex and cyclic loading. This work developed a framework for characterizing and predicting static and high-cycle fatigue behaviors of FDM-printed metal lattices. Constitutive model constants of FDM-printed 17-4PH steels were identified via experiments on dog bone samples at the same length scale of lattice microstructures. The material exhibits quasi-brittle behavior at microstructural size, with a tensile stiffness of 24 GPa. It is only 13 % of the expected stiffness for macroscopic level materials, showing a severe effect by length scale. Residual porosity leads to microcracks, which act as the primary failure mechanism under high-cycle fatigue, reducing the fatigue limit to 31 % of rolled steel. Assigning developed constitutive models, the asymptotic homogenization method was employed to obtain equivalent static properties of stretch- and bend-dominated lattices, which were in accord with testing results. Through the Brown-Miller-Morrow method, the framework numerically predicted lattice high-cycle fatigue life, which was validated against experiments.},
  archive      = {J_MATDES},
  author       = {Wei Zhang and Rujun Li and Yan Peng and Hang Xu},
  doi          = {10.1016/j.matdes.2025.113761},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113761},
  shortjournal = {Mater. Des.},
  title        = {A static and high-cycle fatigue characterization framework of metallic lattice structures additive manufactured via fused deposition modeling based method},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Biology as inspiration for creative design of roadside
safety hardware: A perspective on the state of the art. <em>MATDES</em>,
<em>252</em>, 113760. (<a
href="https://doi.org/10.1016/j.matdes.2025.113760">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Roadside safety hardware, such as longitudinal barriers and crash cushions, is part of the highway infrastructure used to protect an errant vehicle from crashing into fixed roadside objects in a well-controlled manner. Despite constantly improved design and standardized full-scale impact testing of the roadside safety hardware, more than 3% of U.S. traffic fatalities are caused by the inefficiency of the roadside safety hardware. This perspective article highlights the need for innovative designs to enhance protection and mitigate impact severity. In nature, many plants and animals are optimized to adapt to various overload conditions and have demonstrated superior impact-resistant and energy-absorbing capabilities. Careful study of these biological structures may inspire the development of a new generation of soft, flexible, curvilinear roadside safety hardware.},
  archive      = {J_MATDES},
  author       = {Arman Moussavi and Cody Stolle and Congrui Jin},
  doi          = {10.1016/j.matdes.2025.113760},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113760},
  shortjournal = {Mater. Des.},
  title        = {Biology as inspiration for creative design of roadside safety hardware: A perspective on the state of the art},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Er microalloying significantly refines precipitates to
simultaneously promote the strength and ductility of mg-gd-y-zn-zr
alloy. <em>MATDES</em>, <em>252</em>, 113759. (<a
href="https://doi.org/10.1016/j.matdes.2025.113759">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The contradiction between the strength and ductility of magnesium (Mg) alloys has become a theoretical obstacle and technical bottleneck in their research. The preparation technology of ultrafine grains/nanocrystals relying on severe plastic deformation deviates from actual industrial production, therefore alloying is currently a more practical choice. This work simultaneously promoted the strength and ductility of Mg-Gd-Y-Zn-Zr alloy by adding a trace amount of Er element (0.5 wt%). Er microalloying has little effect on grain size, texture, morphology and content of long-period stacking ordered (LPSO) structure, but significantly promotes aging precipitation, thereby substantially increasing the number density of β’ and reducing its size. The significantly refined β’ makes calculations based on the Orowan bypass mechanism less accurate, and more consideration should be given to linking the synchronous improvement of strength and ductility with the dislocation-shearing mechanism.},
  archive      = {J_MATDES},
  author       = {Qian Zhang and Fulin Wang and Jian Zeng and Fenghua Wang and Shuai Dong and Li Jin and Jie Dong},
  doi          = {10.1016/j.matdes.2025.113759},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113759},
  shortjournal = {Mater. Des.},
  title        = {Er microalloying significantly refines precipitates to simultaneously promote the strength and ductility of mg-gd-Y-zn-zr alloy},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing mechanical properties of CoCrNi via in-situ
alloying with Al2O3 through laser powder bed fusion. <em>MATDES</em>,
<em>252</em>, 113758. (<a
href="https://doi.org/10.1016/j.matdes.2025.113758">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For advantages in integrating the intrinsic properties of the metal matrix and reinforcing phases, properly designed metal matrix composites (MMCs) are promising candidates for overcoming the trade-offs of properties such as corrosion, ductility, strength, and lightweight. However, MMCs often face challenges such as agglomeration and inhomogeneous distribution of the reinforcing phase, leading to significant degradation of mechanical properties. In this study, we propose a method to overcome these obstacles by in-situ alloying via laser powder bed fusion (LPBF), achieving a uniform distribution of the reinforcing nano-sized phase (α-Al 2 O 3 ) within a medium-entropy alloy matrix (CoCrNi). During the LPBF process, Al 2 O 3 is refined from the micrometer scale to the nanometer scale, simultaneously affecting the crystal orientation and leading to grain refinement of the CoCrNi matrix. The mechanical properties of CoCrNi were significantly enhanced by adding Al 2 O 3 , with an ultimate compressive strength of ∼1143 MPa, a fracture strain of ∼25%, and a hardness of ∼300 HV. The achieved strength and hardness levels are among the highest reported in the literature. The results from this study provide new design strategies for the in-situ formation of MMCs, offering a promising approach to developing MMCs with high strength and ductility.},
  archive      = {J_MATDES},
  author       = {Zairan Luo and Qian Liu and Dingding Zhu and Jiang Yi and Zhiqian Rao and Shuai Wang},
  doi          = {10.1016/j.matdes.2025.113758},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113758},
  shortjournal = {Mater. Des.},
  title        = {Enhancing mechanical properties of CoCrNi via in-situ alloying with Al2O3 through laser powder bed fusion},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Powder bed fusion on single lines of cu-doped hydroxyapatite
powder bed. <em>MATDES</em>, <em>252</em>, 113757. (<a
href="https://doi.org/10.1016/j.matdes.2025.113757">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to design ceramic scaffolds for precise bone reconstruction using Powder Bed Laser Sintering (PBLS) to create cohesive Cu-doped HAp ribbons from a single lasered line on a thin powder bed atop a silicate lime substrate. Depending on laser parameters, two ribbon types—delaminated (CDR) or anchored (CAR)—are produced, both exhibiting surface density gradients from the center to the edges. Microscale analysis reveals surface density gradients in both ribbon types, extending from center to edge. CDRs also show depth-wise density variations, resulting in mechanical stresses that cause detachment and curling. In CARs, intense local heating and thermal conductivity cause a temperature rise beyond the irradiated area. The substrate acts as a thermal barrier, concentrating heat at the film-substrate interface and ensuring ribbon adhesion. Cracks propagate perpendicular to isothermal lines, enabling controlled crack patterning.},
  archive      = {J_MATDES},
  author       = {François Rouzé l’Alzit and Benoit Glorieux and Thierry Cardinal and Manuel Gaudon},
  doi          = {10.1016/j.matdes.2025.113757},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113757},
  shortjournal = {Mater. Des.},
  title        = {Powder bed fusion on single lines of cu-doped hydroxyapatite powder bed},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025b). Corrigendum to “ballistic impact performance of
kevlar®/UHMWPE hybrid composite panels with a liquid thermoplastic
resin, elium®” [mater. Des. 252 (2025) 113706]. <em>MATDES</em>,
<em>252</em>, 113756. (<a
href="https://doi.org/10.1016/j.matdes.2025.113756">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MATDES},
  author       = {Aswani Kumar Bandaru and Dinesh Kumar Kothandan and Hemant Chouhan and Hong Ma and Ronan M. O’Higgins},
  doi          = {10.1016/j.matdes.2025.113756},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113756},
  shortjournal = {Mater. Des.},
  title        = {Corrigendum to “Ballistic impact performance of Kevlar®/UHMWPE hybrid composite panels with a liquid thermoplastic resin, elium®” [Mater. des. 252 (2025) 113706]},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tailor-made 3D printing TPU/PLA composites for damping and
energy absorption. <em>MATDES</em>, <em>252</em>, 113752. (<a
href="https://doi.org/10.1016/j.matdes.2025.113752">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Commercially available thermoplastic polyurethane (TPU) materials for 3D printing often exhibit inadequate damping properties, limiting their application in damping scenarios. However, 3D printing TPU filaments specifically engineered for enhanced damping performance frequently lack sufficient stiffness, causing printing continuity issues. To address these challenges, this study investigates the rational design of TPU composites by regulating TPU molecular structure and incorporating polylactic acid (PLA) to enhance both damping performance and stiffness. The results reveal that a prepolymer curing coefficient of 2.0, combined with a chain extender ratio of Dimethyl thio-toluene diamine (DMTDA) to 1,4-Butanediol (BDO) at 5:5, optimizes the damping and mechanical properties of the TPU material. Furthermore, by incorporating 30 wt% PLA particles into the TPU matrix, the obtained TPU7/PLA3 composite filament has excellent printability and admirable damping properties with a peak damping value of 0.60 around room temperature and an effective damping temperature range exceeding 100 °C. A lattice structure resembling Kelvin foam was successfully fabricated using the TPU/PLA filaments, demonstrating superior damping performance compared to commercial TPU filaments and underscoring its potential for energy absorption applications.},
  archive      = {J_MATDES},
  author       = {Ruichao Zu and Wenzheng Chen and Yicang Huang and Yujie Chen and Chengzhen Du and Qunfu Fan and Hua Li and Hezhou Liu},
  doi          = {10.1016/j.matdes.2025.113752},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113752},
  shortjournal = {Mater. Des.},
  title        = {Tailor-made 3D printing TPU/PLA composites for damping and energy absorption},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High temperature he bubble evolution and thermal stability
of the WTaCrV refractory concentrated solid solution alloy.
<em>MATDES</em>, <em>252</em>, 113751. (<a
href="https://doi.org/10.1016/j.matdes.2025.113751">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we investigate the thermal stability and high-temperature evolution of He bubbles within the structure of the WTaCrV refractory concentrated solid solution alloy (RCSA), which is dedicated to nuclear fusion applications. The material was first irradiated with He + ions to form nanometric He bubbles within its structure. Subsequently, their high-temperature evolution was studied using an in-situ heating method in a transmission electron microscope over a temperature range of 700 °C to 1000 °C. We found that the bubbles are stable in size up to a temperature of 700 °C and show no agglomeration up to 800 °C. At higher temperatures, the coarsening of the bubbles occurs through the migration and coalescence mechanism; however, even at 1000 °C, the size of the bubbles only slightly exceeds 1 nm. For a more in-depth understanding of the phenomena occurring during high-temperature annealing, molecular dynamics simulations were applied. We demonstrate that the low diffusivity of V m He n clusters in the investigated WTaCrV alloy is responsible for the low tendency for high-temperature coarsening of the bubbles. The results of this study highlight the potential of the WTaCrV RCSA as a refractory, irradiation-resistant material for crucial components in future fusion reactors.},
  archive      = {J_MATDES},
  author       = {Damian Kalita and Amin Esfandiarpour and Iwona Jóźwik and Yanwen Zhang and Jesper Byggmästar and Mikko J. Alava and Łukasz Kurpaska and William J. Weber and Philip D. Rack and Jacek Jagielski},
  doi          = {10.1016/j.matdes.2025.113751},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113751},
  shortjournal = {Mater. Des.},
  title        = {High temperature he bubble evolution and thermal stability of the WTaCrV refractory concentrated solid solution alloy},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Laser-based additive manufacturing of bulk metallic glasses:
A review on principle, microstructure and performance. <em>MATDES</em>,
<em>252</em>, 113750. (<a
href="https://doi.org/10.1016/j.matdes.2025.113750">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bulk metallic glasses (BMGs) have gained significant attention in the engineering field due to their unique microstructure and excellent properties. However, the fabrication of large-sized and complex-shaped BMGs components remains a major challenge. Laser-based additive manufacturing (LAM) techniques offer a promising solution to conquer the limitations of traditional methods in manufacturing BMGs. Theoretically, LAM techniques can achieve extremely high cooling rates of over 10 4 K/s, resulting in the formation of metallic glass structures within the tiny molten pools. More significantly, the bottom-up concept of LAM enables the layer-by-layer construction of large-sized BMGs parts. Herein, this review extensively explores cutting-edge research on various aspects of utilizing LAM techniques in BMGs fabrication. It provides a comprehensive discussion of the forming mechanism of BMGs during LAM, focusing on factors such as heterogeneous microstructure, crystallization behavior and defect elimination. Additionally, the influence of composition and process parameters on the performance of LAM-produced BMGs, including mechanical properties, corrosion behavior, and biocompatibility, is systematically reviewed. An outlook on the LAM techniques for BMGs production is presented, aiming to provide some guiding principles for future research directions in this pioneering field.},
  archive      = {J_MATDES},
  author       = {Jiapeng Ren and Dongsheng Wang and Xuehua Wu and Youwen Yang},
  doi          = {10.1016/j.matdes.2025.113750},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113750},
  shortjournal = {Mater. Des.},
  title        = {Laser-based additive manufacturing of bulk metallic glasses: A review on principle, microstructure and performance},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Topological interface modes in 3D-printed triply periodic
minimal surface phononic crystals. <em>MATDES</em>, <em>252</em>,
113749. (<a href="https://doi.org/10.1016/j.matdes.2025.113749">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Triply periodic minimal surface (TPMS)-based continuous structures have recently attracted increased attention due to their remarkable mechanical properties, such as high strength-to-weight ratio, impact resistance, and energy absorption capabilities. In this study, we investigate topological interface modes in I-WP (Wrapped Package) TPMS geometry. Inspired by a one-dimensional (1D) Su–Schrieffer–Heeger (SSH) model, we design 1D elastic Phononic Crystals (PCs) made of sheet-based I-WP minimal surface geometry. By manipulating the geometry of the I-WP minimal surface, we open the degeneracies formed at the edges of the Brillouin zone to create band-folding-induced bandgaps. We then design a 1D dimerized chain of two topologically distinct unit cells of I-WP minimal surface to create an interface and introduce topological interface modes. Numerical simulations are performed to study the band structure and topological transition properties of the proposed 1D PC. In addition, we show that hybridizing alternative I-WP unit cells of different relative densities can also break the inversion symmetry of the periodic structure in contrast to manipulating the geometry. The 1D PC made of hybridized I-WP geometry is then used to realize topological interface modes. The proposed 1D PCs are additively manufactured to experimentally validate the existence of topological interface modes. Our work provides an efficient method for TPMS structures to produce multifunctional devices that can support superior load-bearing capabilities as well as robust topological phase properties.},
  archive      = {J_MATDES},
  author       = {Prabhakaran Manogharan and Alper Erturk},
  doi          = {10.1016/j.matdes.2025.113749},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113749},
  shortjournal = {Mater. Des.},
  title        = {Topological interface modes in 3D-printed triply periodic minimal surface phononic crystals},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Natural pigments as multifunctional additives in contact
lenses. <em>MATDES</em>, <em>252</em>, 113748. (<a
href="https://doi.org/10.1016/j.matdes.2025.113748">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous exposure to blue light emitting devices as part of modern life leads to melatonin suppression that results in poor sleep quality and overall health. Contact lenses capable of blue light filtering could be used to mitigate this issue. This can be facilitated by using natural dyes to filter certain wavelengths from contact lenses. In this research, Curcuma Aromatica and Rubia Cordifolia were used to stain commercial contact lenses. This improved the blue light filtering capability and antibacterial resistance against Staphylococcus aureus and Pseudomonas aeruginosa bacteria. The UV Vis transmission spectra showed great blue light reduction for both natural pigments, C. aromatica being the better choice. The lenses showed a reduction of around 95 % in the blue light region while maintaining high transparency. Use of PVA improved the shelf life for C. aromatica, by providing better stability in both deionized water and contact lens storage solution. The lenses showed comparable contact angle and water retention properties, indicating that the additives retained the commercial contact lens’ properties. The MTT assay and Trypan blue assay indicated very good cell viability implying good biocompatibility of the lenses. Additionally, the anti-inflammatory effect of C. aromatica and C. aromatica + PVA dipped lenses strengthens the possibility of implementing them in further applications. The R. cordifolia dipped lenses seem to have improved inflammatory responses upon the addition of PVA. These lenses show great promise for protection against blue light from displays and other sources, offering a remedy to prolonged exposure to blue light.},
  archive      = {J_MATDES},
  author       = {C. Muhammed Shebeeb and Sanjana Chandran and Liya Jacob and Abdulrahim Sajini and Haider Butt},
  doi          = {10.1016/j.matdes.2025.113748},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113748},
  shortjournal = {Mater. Des.},
  title        = {Natural pigments as multifunctional additives in contact lenses},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparison of hydrogen resilience of three different
corrosion-resistant martensitic steels. <em>MATDES</em>, <em>252</em>,
113747. (<a href="https://doi.org/10.1016/j.matdes.2025.113747">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hydrogen gas is a critical resource for future sustainable energy production, with stainless steels playing a substantial role in applications where components are exposed to hydrogen gas environments. In this work, the resistance to hydrogen embrittlement of three ultra-high strength martensitic stainless steels was investigated. The materials comprised of one high carbon, one nitrogen-alloyed and one dual precipitation hardened steel. The experiments involved a combined deuterium charge, followed by atom probe tomography, and hydrogen gas charge, followed by slow strain rate testing. This approach enabled the study of each steel’s resilience to hydrogen gas and allowed correlations between mechanical behaviors after hydrogen charging and their hydrogen trapping capabilities, as well as the presence of undissolved primary carbides or carbonitrides. Results showed that while the nitrogen-alloyed stainless steel demonstrated the highest hydrogen trapping capability, the presence of undissolved primary carbides or carbonitrides within it served as crack initiation sites during slow strain rate tests, reducing its hydrogen resistance. The dual precipitation-hardened steel, which lacked undissolved carbides, exhibited the least hydrogen embrittlement.},
  archive      = {J_MATDES},
  author       = {Severin Jakob and Mattias Thuvander and Steve W. Ooi},
  doi          = {10.1016/j.matdes.2025.113747},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113747},
  shortjournal = {Mater. Des.},
  title        = {Comparison of hydrogen resilience of three different corrosion-resistant martensitic steels},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effect of SiC on the antioxidant properties of al-containing
composites Ti3SiC2/SiC and its oxidation mechanism analysis.
<em>MATDES</em>, <em>252</em>, 113746. (<a
href="https://doi.org/10.1016/j.matdes.2025.113746">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims at improving the oxidation resistance of ceramics intended for high-temperature applications by examining the quantitative SiC-reinforced aluminum-containing composites Ti 3 SiC 2 /SiC that were synthesized through a powder metallurgy method. The high-temperature antioxidant properties of these composites were evaluated at temperatures between 900 °C and 1300 °C. The findings reveal that an increase in SiC content elevates the activation energy associated with oxidation, mitigates oxidation behavior, and decreases the weight gain attributable to oxidation of the material. Additionally, the formation of the oxide layer and atomic diffusion were investigated through the analysis of surface micro-morphology and the distribution of the oxide layer at the interface. It was found that the addition of SiC modifies the oxide layer structure of the material, which primarily consists of an outer mixed oxide layer of TiO 2 and Al 2 O 3 , an intermediate oxide layer of TiO 2 with a small amount of SiO 2 , and an inner homogeneous mixed oxide layer of TiO 2 and SiO 2 . Finally, the high-temperature oxidation mechanism of Ti 3 SiC 2 /SiC composites is systematically illustrated through experimental results.},
  archive      = {J_MATDES},
  author       = {Chengzhi Du and Bo Lei and Yajie Qi and Rui Zhang},
  doi          = {10.1016/j.matdes.2025.113746},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113746},
  shortjournal = {Mater. Des.},
  title        = {Effect of SiC on the antioxidant properties of al-containing composites Ti3SiC2/SiC and its oxidation mechanism analysis},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Femtosecond-laser-surface-nanostructured glass for
building-integrated photovoltaics. <em>MATDES</em>, <em>252</em>,
113745. (<a href="https://doi.org/10.1016/j.matdes.2025.113745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emerging luminescent solar concentrators (LSC) for building-integrated photovoltaics (BIPV) face challenges such as narrow conversion spectrum, material degradation, high costs, and safety concerns, while their reliance on complex fabrication processes further hinders their practical application in large-area systems. In this paper, we present a novel application of femtosecond-laser-nanostructured borosilicate glass for BIPV, offering a promising alternative to traditional LSC windows. Utilizing a scalable, one-step femtosecond laser direct writing process, we fabricate nanostructured borosilicate glass specifically designed to effectively scatter incident light toward solar cells positioned at the edges of the glass. To optimize the laser processing, we perform comprehensive characterizations using scanning electron microscopy, X-ray diffraction, Raman spectroscopy, photoluminescence spectroscopy, and spectrophotometry. The proof-of-concept system demonstrates that the glass processed at an optimized scan speed exhibits a 55-fold increase in photocurrent generation compared to unprocessed glass, highlighting its enhanced optical efficiency. Additionally, a hydrophobic coating is applied on the nanostructured glass to confer self-cleaning properties, achieving superhydrophobicity with advancing and receding contact angles of approximately 170°. This novel approach to utilizing nanostructured glass for solar concentration shows considerable promise for improving both the efficiency and practicality of building-integrated photovoltaics.},
  archive      = {J_MATDES},
  author       = {Lingju Meng and Mohammad Awashra and Sara Hamed and Dmytro Gnatyuk and Ville Vähänissi and Ville Jokinen and Hele Savin and Xiaolong Liu},
  doi          = {10.1016/j.matdes.2025.113745},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113745},
  shortjournal = {Mater. Des.},
  title        = {Femtosecond-laser-surface-nanostructured glass for building-integrated photovoltaics},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Light and pH-activated nanoplatform based on oxidative
stress-amplified for photodynamic and ferroptosis synergistic therapy of
breast cancer. <em>MATDES</em>, <em>252</em>, 113744. (<a
href="https://doi.org/10.1016/j.matdes.2025.113744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared to traditional tumor chemotherapy, photodynamic therapy (PDT) can effectively reduce toxic side effects and prevent tumor resistance. However, the reactive oxygen species (ROS) generated by photosensitizers are limited, and the destructive effects on tumor cells are inadequate. In this study, nanomedicines loaded with the photosensitizers chlorin e6 (Ce6) and dihydroartemisinin (DHA) were constructed using human serum albumin (HSA) and transferrin (Tf), self-assembly for the programmed activation, and expansion of ROS in tumor cells. These nanomedicines, Ce6/DHA@HSA-SS-Tf nanoparticles (NPs), can target Tf receptors overexpressed on cancer cells to produce ROS through PDT with laser irradiation. Subsequently, the ROS-responsive vector is cleaved, and iron ions catalyze the released DHA to produce sufficient ROS and induce ferroptosis in tumor cells. The nanomedicine amplifies the ROS content in tumor cells through a dual response and programmed activation, which can effectively solve the problem of insufficient ROS production in tumor PDT. Consequently, the Ce6/DHA@HSA-SS-Tf NPs demonstrate excellent anti-tumor effects through the synergistic effects of PDT and ferroptosis. This treatment strategy provides a reliable basis for tumor-specific and efficient treatments.},
  archive      = {J_MATDES},
  author       = {Song Li and Zhenxin Guan and Yurong Liu and Xiaokang Zhang and Yunheng Liu and Shaojing Jiang and Wenjing Liu and Aoya Wang and Xiaolin Li and Xukai Che and Liyuan Shao and Li Zhang and Jinghui Hu and Jing Chen},
  doi          = {10.1016/j.matdes.2025.113744},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113744},
  shortjournal = {Mater. Des.},
  title        = {Light and pH-activated nanoplatform based on oxidative stress-amplified for photodynamic and ferroptosis synergistic therapy of breast cancer},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Corrigendum to “superior hemostatic and wound-healing
properties of tetrastigma polysaccharide” [mater. Des. 241 (2024)
112967]. <em>MATDES</em>, <em>252</em>, 113743. (<a
href="https://doi.org/10.1016/j.matdes.2025.113743">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MATDES},
  author       = {Shengyu Li and Wenjun Xu and Weihan Zhu and Jinwei Wang and Jintao Shi and Jingyi Tang and Xia Liu and Wei Zhang and Huiying Fu and Qiyang Shou},
  doi          = {10.1016/j.matdes.2025.113743},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113743},
  shortjournal = {Mater. Des.},
  title        = {Corrigendum to “Superior hemostatic and wound-healing properties of tetrastigma polysaccharide” [Mater. des. 241 (2024) 112967]},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The interaction between local melting and helium bubble in
radiated aluminium under dynamic tension at high temperature and strain
rates. <em>MATDES</em>, <em>252</em>, 113741. (<a
href="https://doi.org/10.1016/j.matdes.2025.113741">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Materials exposed to extreme radiation environments (e.g., nuclear devices) accumulate substantial defects, such as helium (He) bubbles. These defects can alter material properties, including melting behavior, which has not been intensively explored. Here, the melting process and the He bubble evolution in aluminium under dynamic tension at high temperature and strain rates were investigated via molecular dynamic simulations. We found that the melting process contains slow premelting and sequential fast local melting at relatively lower strain rates (10 6 ∼ 10 8 /s). The rapid growth of the bubble promotes local melting, which in turn facilitates the migration and shrinkage of the bubble. The underlying microscopic mechanisms for the interplay between the bubble and local melting have also been uncovered. Such interaction becomes weak at high strain rates (10 9 ∼ 10 10 /s). Homogeneous melting occurs directly and spontaneously throughout the sample, and local melting around the bubble becomes inconspicuous. The evolution process of the bubble gets simple, characterized by continuous growth without shrinkage or migration. Furthermore, damage development is dominated by the growth of the He bubble, which occurs after the sample is nearly completely melted at lower strain rates while it happens concurrently with melting at high strain rates.},
  archive      = {J_MATDES},
  author       = {Tingting Zhou and Fuqi Zhao and Anmin He and Pei Wang},
  doi          = {10.1016/j.matdes.2025.113741},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113741},
  shortjournal = {Mater. Des.},
  title        = {The interaction between local melting and helium bubble in radiated aluminium under dynamic tension at high temperature and strain rates},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigation on fabricating ni/Ni3Al/NiAl thin-walled
cup-shaped component by combining superplastic forming of ni/Ni2Al3
composite sheet with subsequent in-situ reaction. <em>MATDES</em>,
<em>252</em>, 113740. (<a
href="https://doi.org/10.1016/j.matdes.2025.113740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present study, a novel approach is proposed to fabricating Ni/Ni 3 Al/NiAl thin-walled cup-shape component based on superplastic forming of Ni/Ni 2 Al 3 composite sheet with heterogeneous bimodal grains. Firstly, Ni/Ni 2 Al 3 composite sheet with heterogeneous bimodal grains is prepared by means of hot pressing reaction synthesis from Ni and Al for 2 h at 630 ℃ under the pressure of 20 MPa and it is characterized by superplasticity at 750℃ at the strain rate of 1 × 10 - 3 to 1 × 10 - 2 s −1 . Subsequently, Ni/Ni 2 Al 3 composite sheet can be readily used to be made into the thin-walled cup-shaped components by gas forming. The Ni/Ni 2 Al 3 thin-walled cup-shape component is subjected to second-order in-situ reaction for 4 h at 1000℃ under the pressure of 20 MPa, and consequently the involved Ni/Ni 3 Al/NiAl thin-walled cup-shaped component is fabricated, where Ni 3 Al and NiAl phases are dominant. In particular, Ni 3 Al phase contributes to enhancing high-temperature strength and NiAl phase is responsible for bolstering high-temperature plasticity. The present work provides a novel approach for fabricating Ni/Ni 3 Al/NiAl thin-walled cup-shaped component.},
  archive      = {J_MATDES},
  author       = {Peng Lin and Pengle Kong and Bingyao Yan and Hongliang Yin and Dong Sun and Hao Feng and Qihan Zhang and Shuyong Jiang},
  doi          = {10.1016/j.matdes.2025.113740},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113740},
  shortjournal = {Mater. Des.},
  title        = {Investigation on fabricating Ni/Ni3Al/NiAl thin-walled cup-shaped component by combining superplastic forming of Ni/Ni2Al3 composite sheet with subsequent in-situ reaction},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mechanical properties of polymer-infiltrated ZrO2 ceramic
network improved by incorporation of SiO2 component. <em>MATDES</em>,
<em>252</em>, 113739. (<a
href="https://doi.org/10.1016/j.matdes.2025.113739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Polymer-infiltrated ZrO 2 ceramic networks, due to their similar elastic moduli and hardness with natural enamel, have become a promising material for dental restoration. However, since the couple between ZrO 2 and resin is difficult, the poor interface bonding of ZrO 2 /resin degrades the mechanical characteristics of polymer-infiltrated ZrO 2 ceramic networks. This study introduced SiO 2 into ZrO 2 as a scaffold to improve the coupling via the reaction of SiO 2 and silane coupling agents. The impacts of the SiO 2 concentration on the microstructures, the fracture characteristics, and mechanical properties of the porous ceramics and composites were investigated. The microstructures showed that ceramics and resins were bonded more tightly in PICNs with ZrO 2 /SiO 2 scaffold than PICNs with pure ZrO 2 scaffold. The flexural strengths of the composites were significantly improved by the addition of SiO 2 , which was attributed to the increased coupling degree. The composites with 20 mol.% SiO 2 as the porous ceramic exhibited the optimal mechanical properties, with flexural strength, elastic modulus, hardness, and fracture toughness values of 249.8 ± 24.3 MPa, 28.8 ± 4.0 GPa, 2.0 ± 0.2 GPa, and 2.6 ± 0.5 MPa·m 1/2 , respectively. This study provides valuable information for the preparation of polymer-infiltrated ZrO 2 ceramic networks with excellent performance for dental restorations.},
  archive      = {J_MATDES},
  author       = {Xinkai Cui and Xiaoyu Zhang and Lin Hu and Zhe Zhao and Kai Tang and Zhenyu Yang and Fu Wang and Jihua Chen and Lina Niu},
  doi          = {10.1016/j.matdes.2025.113739},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113739},
  shortjournal = {Mater. Des.},
  title        = {Mechanical properties of polymer-infiltrated ZrO2 ceramic network improved by incorporation of SiO2 component},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Phase transformation and recrystallization of cold-rolled
AISI 304L austenitic stainless steel during annealing. <em>MATDES</em>,
<em>252</em>, 113738. (<a
href="https://doi.org/10.1016/j.matdes.2025.113738">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Refining the heat-affected zone (HAZ) microstructure of thermomechanically welded cold-worked AISI 304L austenitic stainless steels (ASSs) improves the weld quality. This study explored the annealing behavior of cold-rolled AISI 304L ASSs through heat treatments over temperatures ranging from 600 °C to 1200 °C and holding times ranging from 2 min to 480 min. The microstructure was analyzed using optical microscopy and EBSD, and the deformation-induced martensite (DIM) content was evaluated using the ferrite scope. Vickers hardness values were correlated with the microstructure evolution following the Hall-Patch relationship. The grain size distribution and the kinetics of grain coarsening were analyzed. Results show that during annealing, the reverse transformation of DIM occurred, followed by static recrystallization of the γ-austenite phase. After recrystallization, grains coarsen with an activation energy of 133.8 kJ/mol, and grain size distribution fits a log-normal function. Nanoscale grains (&lt; 180 nm) were achieved in cold-rolled samples (67 % thickness reduction) annealed at 700 °C for 4 h. The δ-ferrite, primarily located at γ-grain boundaries, retarding their movement during recrystallization and coarsening. Finally, the δ-ferrite partially transformed into austenite and globularized during annealing. These findings show that the processes of phase transformation and recrystallization in cold-worked dual-phase steels are coupled.},
  archive      = {J_MATDES},
  author       = {Peng Wang and Muhammad Farrukh Siddiqui and Maria Cecilia Poletti and Norbert Enzinger},
  doi          = {10.1016/j.matdes.2025.113738},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113738},
  shortjournal = {Mater. Des.},
  title        = {Phase transformation and recrystallization of cold-rolled AISI 304L austenitic stainless steel during annealing},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neuro-symbolic artificial intelligence in accelerated design
for 4D printing: Status, challenges, and perspectives. <em>MATDES</em>,
<em>252</em>, 113737. (<a
href="https://doi.org/10.1016/j.matdes.2025.113737">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {4D printing enables the creation of adaptive and reconfigurable devices by combining additive manufacturing with smart materials. This integration introduces challenges in designing printable, responsive materials and structures. Current research focuses on improving the responsiveness and mechanical performance of smart materials, but incremental advances often lack sufficient feedback for achieving specific properties, shapes, and performance targets. Inverse design has emerged as a strategy for determining material compositions and structural configurations to meet desired outputs, but its application remains limited to simple structures. Accelerating material and structural discovery is crucial for advancing 4D printing. Artificial intelligence (AI), especially machine learning (ML), offers promising solutions to address the complexity of 4D printing design. However, conventional AI approaches often lack logical reasoning, explainability, and interpretability. This review paper highlights recent achievements and challenges in 4D printing design and introduces neuro-symbolic AI as a promising approach. By combining ML&#39;s learning capabilities with the logical reasoning and semantic understanding of symbolic AI, this approach can enhance the exploration of advanced active materials and structures. The insights provided aim to guide future research toward optimizing 4D printing for broader applications and enhanced performance.},
  archive      = {J_MATDES},
  author       = {Oualid Bougzime and Christophe Cruz and Jean-Claude André and Kun Zhou and H. Jerry Qi and Frédéric Demoly},
  doi          = {10.1016/j.matdes.2025.113737},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113737},
  shortjournal = {Mater. Des.},
  title        = {Neuro-symbolic artificial intelligence in accelerated design for 4D printing: Status, challenges, and perspectives},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning inverse design of high-strength
mid-temperature ag-based solders. <em>MATDES</em>, <em>252</em>, 113736.
(<a href="https://doi.org/10.1016/j.matdes.2025.113736">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional trial-and-error experimentation and computational methods are often inefficient for designing solders with specific properties, revealing the need for more effective design strategies. This work presents a novel inverse design framework for accelerating the discovery of mid-temperature (400–600 °C) Ag-based solders. A Wasserstein Autoencoder (WAE) generates candidate compositions, targeting melting temperatures within the 400–600 °C range through a Gaussian Mixture Model and neural network classifier. Yield strength is predicted using a stacking ensemble learning model, combining Multilayer Perceptron and Gradient Boosted Decision Trees with a Decision Tree meta -learner, achieving high accuracy, which was confirmed by experimental validation of four selected alloys. This data-driven approach demonstrates significant potential for the efficient design of high-performance solder materials.},
  archive      = {J_MATDES},
  author       = {Chengchen Jin and Kai Xiong and Yingwu Wang and Shunmeng Zhang and Yunyang Ye and Hui Fang and Aimin Zhang and Hua Dai and Yong Mao},
  doi          = {10.1016/j.matdes.2025.113736},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113736},
  shortjournal = {Mater. Des.},
  title        = {Machine learning inverse design of high-strength mid-temperature ag-based solders},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An overview of methods to qualitatively and quantitatively
characterize the structure of polymer-coated cardboards: Advantages and
limitations. <em>MATDES</em>, <em>252</em>, 113735. (<a
href="https://doi.org/10.1016/j.matdes.2025.113735">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Polymer-coated cardboards are increasingly replacing conventional plastics for packaging applications. Understanding and quantifying the complex structure of these multilayered materials is essential for assessing the coating quality and predicting the performance; however, it remains challenging. This review aims to gather the existing knowledge and advances in experimental techniques and methods developed to characterize the structure of polymer-coated cardboards by systematically highlighting their advantages and limitations. The first part presents the evaluation of the surface coating quality (i.e., its homogeneity and the presence or absence of defects), starting from the detection of surface defects in the coating layer to their visualization and quantification with techniques such as SEM and X-ray tomography. The second part focuses on the evaluation of the thickness of each layer making up the material, which is necessary for predictive modeling and the production of just-necessary food packaging, ranging from visualization approaches to methods that rely on physical measurements. The third part reviews methods for characterizing the cardboard porosity, which is a key property for further modeling approaches as the impregnation of the polymer depends on it.},
  archive      = {J_MATDES},
  author       = {Allison Vercasson and Sébastien Gaucel and Valérie Guillard and Hélène Angellier-Coussy},
  doi          = {10.1016/j.matdes.2025.113735},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113735},
  shortjournal = {Mater. Des.},
  title        = {An overview of methods to qualitatively and quantitatively characterize the structure of polymer-coated cardboards: Advantages and limitations},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding effects of deformation parameters on dynamic
recrystallization-dependent superplasticity in an al-cu-li alloy.
<em>MATDES</em>, <em>252</em>, 113734. (<a
href="https://doi.org/10.1016/j.matdes.2025.113734">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aluminum alloys with initial unrecrystallized structures generally exhibit better superplasticity and are produced more efficiently and cost-effectively than fully recrystallized ones. However, the underlying recrystallization and deformation mechanisms of dynamic recrystallization (DRX)-dependent superplastic aluminium alloys under varying deformation parameters are not yet fully understood. This study investigates the effects of deformation parameters, Al 3 Zr dispersoids, and coarse secondary particles on DRX and superplasticity in an Al-Cu-Li alloy. The alloy achieves a maximum elongation of 780 % at 430 °C and 0.002 s −1 , primarily due to continuous dynamic recrystallization (CDRX) and grain boundary sliding (GBS). Under optimal conditions, deformed grains transform into equiaxed recrystallized grains through sub-grain rotation and coalescence, with GBS dominating subsequent deformation. Lower Zener-Hollomon parameter (lnZ) conditions promote dynamic recovery (DRV) and sub-grain growth, hindering grain refinement and superplastic deformation. Conversely, higher lnZ values inhibit recrystallization due to insufficient thermal driving force and lower DRV, resulting in retained banded grains and reduced elongation. Cu-rich secondary phases enhance CDRX but lose efficacy with their dissolution and coarsening at low lnZ conditions. This work provides insights into DRX-dependent superplastic mechanisms and offers guidance for optimizing deformation parameters to enhance the performance of aluminum alloys.},
  archive      = {J_MATDES},
  author       = {Guotong Zou and Ruiqiang Zhang and Wei Wang and Jun Li and Lingying Ye},
  doi          = {10.1016/j.matdes.2025.113734},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113734},
  shortjournal = {Mater. Des.},
  title        = {Understanding effects of deformation parameters on dynamic recrystallization-dependent superplasticity in an al-cu-li alloy},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joining inconel 718 and GRCop42: A framework for developing
transition compositions to avoid cracking and brittle phase formation.
<em>MATDES</em>, <em>252</em>, 113733. (<a
href="https://doi.org/10.1016/j.matdes.2025.113733">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distinct regions of high temperature strength and high thermal conductivity are required for components such as combustion chambers. Inconel 718 and GRCop42 are commonly used for such components. However, the bimetallic joining of these alloys has been shown to result in a liquid miscibility gap at the interface, which at select compositions can lead to brittle phase formation and cracking. In this work, CALPHAD modeling is used to predict regions of brittle phase formation in the Inconel 718–Ni–GRCop42 and Ni–Cu GRCop42 multi-component ternary systems, with experimental validation of the modeling provided by arc melting. Through characterization of arc melted sample microstructure combined with CALPHAD modeling, the solidification paths throughout the system are elucidated and a brittle phase and crack free compositional region is identified. Based on these results, a compositionally graded path consisting of two transition compositions is identified. Powder Laser Directed Energy Deposition is used to fabricate the Inconel 718–GRCop42 joint with the identified transition compositions, and the joint is subject to characterization in terms of composition profile, defects, grain morphology, present phases and microhardness. Results confirm the transition compositions circumvent brittle phase formation found in bimetallic Inconel 718–GRCop42 joints, thus overcoming the thermodynamic barrier of bimetallic joining.},
  archive      = {J_MATDES},
  author       = {Jakub Preis and Stephanie B. Lawson and Nick Wannenmacher and Somayeh Pasebani},
  doi          = {10.1016/j.matdes.2025.113733},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113733},
  shortjournal = {Mater. Des.},
  title        = {Joining inconel 718 and GRCop42: A framework for developing transition compositions to avoid cracking and brittle phase formation},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploration of MAB phase formation in the fe-y-al-b system
using thin film materials libraries. <em>MATDES</em>, <em>252</em>,
113731. (<a href="https://doi.org/10.1016/j.matdes.2025.113731">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the recent theoretical and experimental advancements in MAB phase materials design we investigate the Fe-Y-Al-B system in search for the theoretically predicted (Fe 2/3 Y 1/3 ) 2 AlB 2 in-plane ordered MAB phase. We use combinatorial co-sputtering of thin film materials libraries from elemental targets on 100 mm diameter sapphire substrates at 700 °C followed by high-throughput X-ray diffraction and energy dispersive X-ray spectroscopy measurements. Selected samples from the materials libraries are further characterized by transmission electron microscopy and atom probe tomography. The MAB phase Fe 2 AlB 2 is realized in thin film form as large, elongated grains imbedded in an Fe-Y-Al-B matrix. However, in contrast to the theoretical thermodynamic stability calculations, no incorporation of Y into Fe 2 AlB 2 was detected.},
  archive      = {J_MATDES},
  author       = {Aurelija Mockute and Aleksander Kostka and Lamya Abdellaoui and Yujiao Li and Alireza B. Parsa and Florian Lourens and Christina Scheu and Alfred Ludwig},
  doi          = {10.1016/j.matdes.2025.113731},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113731},
  shortjournal = {Mater. Des.},
  title        = {Exploration of MAB phase formation in the fe-Y-al-B system using thin film materials libraries},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mitigating core energy losses in fe-si alloys fabricated by
direct energy deposition through oxide inclusions and abnormal goss
grain growth. <em>MATDES</em>, <em>252</em>, 113730. (<a
href="https://doi.org/10.1016/j.matdes.2025.113730">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In traditional electrical steel production oxide inclusions are conventionally perceived as deleterious elements for the functional and structural properties. The present work describes the fabrication of a high silicon content electrical steel alloy (Fe-6.5wt%Si) using directed energy deposition (DED), coupled with oxide inclusions to mitigate core energy losses. Abnormal Grain Growth (ABG) was observed after thermal post-processing at 1000 °C for 24 h (1000–24), together with the creation of oxide inclusions mainly around the grain boundaries. Magnetic properties were assessed through dynamic and quasi-static measurements for both as-printed (AP) and 1000–24 samples. The quasi-static analysis revealed hysteresis losses of 206.9 J/m 3 for the AP and 19.02 J/m 3 for the 1000–24, with maximum flux densities of 1.295 T and 1.031 T, at the magnetic field of 3000 A/m. Dynamic magnetic analysis demonstrated an improvement of 39.2% in the total core losses of the 1000–24 sample (2088.8 J/m 3 ), compared to the AP sample (3436.9 J/m 3 ). The microstructure of the 1000–24 sample revealed the formation of Goss texture via ABG, ultimately decreasing the static hysteresis loss. Furthermore, an improved electrical resistivity compare to conventional electrical steel alloys was demonstrated at 119 μΩcm for the 1000-24 sample, and 105 μΩcm for the AP sample. This work introduces a promising avenue to minimize core energy losses by incorporating oxide inclusions and ABG Goss texture in additively manufactured soft magneitc components after thermal post-processing.},
  archive      = {J_MATDES},
  author       = {Xiaojun Shen and Konstantinos A. Liogas and Verner Soh Qun Liang and Yung Zhen Lek and Fanbo Meng and Yiming Shen and John E. Huber and Roger C. Reed and Pei Wang and Alexander M. Korsunsky and Christopher H.T. Lee},
  doi          = {10.1016/j.matdes.2025.113730},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113730},
  shortjournal = {Mater. Des.},
  title        = {Mitigating core energy losses in fe-si alloys fabricated by direct energy deposition through oxide inclusions and abnormal goss grain growth},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Biomimetic kagome-gyroid interpenetrating metamaterial for
tailoring lightweight and mechanical performance. <em>MATDES</em>,
<em>252</em>, 113729. (<a
href="https://doi.org/10.1016/j.matdes.2025.113729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel interpenetrating Kagome-Gyroid (K-G) structure designed to optimize lightweight, high-strength materials. Inspired by natural biomimetic structures, such as the microstructure of butterfly wings and cancellous bone, which are known for their lightweight and strength properties, the K-G structure combines the shear resistance of the Kagome lattice with the high specific strength and stiffness of the Gyroid lattice. The optimized K-G structure demonstrates a 49.5 % increase in specific energy absorption and a 35.6 % improvement in energy absorption efficiency compared to conventional materials, highlighting its superior potential for high-impact applications. Experimental and simulation results reveal that geometric parameters significantly influence the failure and fracture behavior of the structure, particularly affecting its energy absorption characteristics. The study also investigates the distribution patterns of surface roughness and internal defects during the laser powder bed fusion (L-PBF) manufacturing process, highlighting their potential impact on the mechanical performance of the final structure. This novel design provides a promising foundation for the development of advanced materials with superior energy absorption capabilities, making it ideal for high-impact applications in aerospace, rail transportation, and automotive industries, where lightweight and enhanced mechanical performance are critical.},
  archive      = {J_MATDES},
  author       = {Chang Wang and Xin Lu and Xiaoyi Yang and Hanning Zuo and Mengnie Victor Li and Xin Zhao and Tao Peng and Xing Lu},
  doi          = {10.1016/j.matdes.2025.113729},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113729},
  shortjournal = {Mater. Des.},
  title        = {Biomimetic kagome-gyroid interpenetrating metamaterial for tailoring lightweight and mechanical performance},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combined x-ray microdiffraction and micromechanical testing
for direct measurement of thin film elastic constants. <em>MATDES</em>,
<em>252</em>, 113720. (<a
href="https://doi.org/10.1016/j.matdes.2025.113720">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Direct measurement of elastic constants for thin films is still far from routine and poses significant technical and analytical challenges compared to bulk materials. Ab initio Density Functional Theory calculations offer theoretical input, however, discrepancies between model systems and real-world properties persist, primarily due to a lack of available experimental data for newly emerging material systems. Moreover, computationally affordable models are typically limited to defect-free single crystals, omitting microstructural effects that strongly influence the material’s behavior. This study addresses this gap by proposing a novel experimental approach to measure direction-dependent elastic constants, combining synchrotron microdiffraction and micropillar compression, testing a polycrystalline face-centered cubic TiN 0.8 B 0.2 thin film, where linear elastic failure prevails. We have established an advanced in-situ testing environment to continuously record the load–displacement of the indenter while simultaneously collecting the material’s deformation response to uniform uniaxial compression. This dynamic approach allows the evaluation of the orientation-dependent elastic strain components and the macroscopic uniaxial compressive stresses, each over time, enabling a differential analysis to assess the elastic and X-ray elastic constants. The excellent agreement between experimental and ab initio data solidifies the here-proposed robust method for direct elastic constant measurements, which is crucial for advancements in thin film material testing.},
  archive      = {J_MATDES},
  author       = {Rebecca Janknecht and Rainer Hahn and Nikola Koutná and Juraj Todt and Michael Meindlhumer and Anton Davydok and Helmut Riedl and Jozef Keckes and Paul H. Mayrhofer},
  doi          = {10.1016/j.matdes.2025.113720},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113720},
  shortjournal = {Mater. Des.},
  title        = {Combined X-ray microdiffraction and micromechanical testing for direct measurement of thin film elastic constants},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design and additive manufacture of patient-specific head
phantom for radiotherapy. <em>MATDES</em>, <em>252</em>, 113719. (<a
href="https://doi.org/10.1016/j.matdes.2025.113719">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D printing has extensive potential in medical fields in creating prototypes for treatment planning and in this study, the materials and design of a modular head phantom for dosimetry quality assurance in radiotherapy of cancer treatment were described. Till now, the challenge in medical phantoms lies in their ability to accurately represent the anatomical and radiodensity heterogeneity of actual human tissues using representative synthetic materials and topology. Here, polylactic acid was employed for soft tissue representation, while a new custom material mix of Acrylonitrile Butadiene Styrene and bismuth was developed to replicate the higher Hounsfield Unit values characteristic of bone. Appropriate 3D printing infill densities derived from their respective linear regressions were implemented to achieve specific target radiodensities. To facilitate the efficient assembly, structural and anatomical fidelity, the head phantom was printed in 39 consecutive sections, post-processed and scanned using computed tomography (CT). Validation confirmed the success of the fabrication process, achieving both anatomical accuracy and radiodensity consistency, even in regions with complex geometries and high heterogeneity. This study marks a significant step in advancing the use of 3D printing and modularity design that can be patient-specific in developing cancer treatment processes and contributes to safer and more effective radiotherapy.},
  archive      = {J_MATDES},
  author       = {Brandon Zhan Hong Lin and Ee Teng Zhang and Huiyan Ng and Mervin Yen Leong Tan and Zheng Han Soh and Yun Ming Wong and Clifford Ghee Ann Chua and Kah Seng Lew and Eric Pei Ping Pang and Hong Qi Tan and Sung Yong Park and Bing Feng Ng and Wei Yang Calvin Koh},
  doi          = {10.1016/j.matdes.2025.113719},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113719},
  shortjournal = {Mater. Des.},
  title        = {Design and additive manufacture of patient-specific head phantom for radiotherapy},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New insights into structural and spectroscopic
characteristics of cu2+ doped β-Ca3(PO4)2: Correlation between cu2+
concentration and material properties. <em>MATDES</em>, <em>252</em>,
113718. (<a href="https://doi.org/10.1016/j.matdes.2025.113718">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Doping β-tricalcium phosphate (β-TCP) with copper (Cu 2+ ) has great potential in various applications due to its rich chemistry. However, the doping characteristics are rarely studied in detail and are yet to be fully understood, creating a gap in the existing knowledge of these multifunctional materials. In this work, a series of Cu 2+ doped β-TCP (Cu x -TCPs) were prepared and comprehensively characterized to investigate the correlation between Cu 2+ doping and the material properties. Also, the synthesis of Cu x -TCPs was modeled using thermodynamic equilibrium calculations to investigate their formation pathways. The calculations predicted a possible inclusion of Cu 2+ in intermediate phosphate phases during the material synthesis, depending on the temperature. The structural analyses revealed lattice shrinkage due to the Cu 2+ doping and that Cu 2+ occupied Ca4 and Ca5 sites in the β-TCP crystal. The vibrational spectroscopy of the Cu x -TCPs showed noticeable deformation of ν 1 band of P O 4 3 - ligand. The ultraviolet–visible absorption analysis revealed a reduction in the band gap energy induced by Cu 2+ doping. Photoluminescence spectroscopy demonstrated an enhanced emission tunability of Cu x -TCPs in the blue and orange–red regions depending on Cu 2+ concentration. These findings are a step toward a deeper understanding of the structure–property relationships of Cu 2+ doped β-TCPs and can play a significant role in their multidisciplinary applications.},
  archive      = {J_MATDES},
  author       = {Sana Elbashir and Roushdey Salh and Britt M. Andersson},
  doi          = {10.1016/j.matdes.2025.113718},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113718},
  shortjournal = {Mater. Des.},
  title        = {New insights into structural and spectroscopic characteristics of cu2+ doped β-Ca3(PO4)2: Correlation between cu2+ concentration and material properties},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Material removal and deformation mechanism in multiple
nanoscratches of single crystal MgAl2O4. <em>MATDES</em>, <em>252</em>,
113717. (<a href="https://doi.org/10.1016/j.matdes.2025.113717">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single crystal MgAl 2 O 4 requires ultra-precision machining to achieve dimensional accuracy and surface quality due to its high hardness and brittleness. To investigate the effect of multi-abrasive scratch sequences on the material removal and deformation mechanism of single crystal MgAl 2 O 4 in ultra-precision machining. Multiple nanoscratches experiments with different sequences were conducted to demonstrate the randomness of the scratch sequence occurrence at the abrasive tip in ultra-precision machining. The interactions between multiple nanoscratches with different sequences were analyzed for their effects on the material deformation characteristics and surface morphologies of single crystal MgAl 2 O 4 . Additionally, theoretical models for the penetration depth of multiple nanoscratches with different sequences were established. The results show that multiple nanoscratches with different sequences affect the material removal and deformation mechanism of single crystal MgAl 2 O 4 , and the predictions of the penetration depth theoretical model align closely with the experimental results. TEM analysis results show that the subsurface deformation mechanism in the ductile removal region during multiple nanoscratches is primarily characterized by the transformation of single crystals into poly-crystalline of nanocrystalline.},
  archive      = {J_MATDES},
  author       = {Jun Zhao and Yeshen Lan and Marian Wiercigroch and Wuqian Li and Shiwei Chen and Oltmann Riemer and Bernhard Karpuschewski},
  doi          = {10.1016/j.matdes.2025.113717},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113717},
  shortjournal = {Mater. Des.},
  title        = {Material removal and deformation mechanism in multiple nanoscratches of single crystal MgAl2O4},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Polyetheretherketone biomaterials and their current
progress, modification-based biomedical applications and future
challenges. <em>MATDES</em>, <em>252</em>, 113716. (<a
href="https://doi.org/10.1016/j.matdes.2025.113716">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Polyetheretherketone (PEEK), a high-performance polymer biomaterial, has demonstrated significant potential for biomedical applications due to its excellent resistance to high temperature, friction, and corrosion. However, the scope of its biomedical applications is limited by its inherent biological inertness. To address this limitation and further enhance both the biocompatibility and mechanical properties of PEEK, various technical approaches-such as surface modification and the development of composite materials-have been extensively explored. These advancements aim to broaden the future applications of PEEK as a biomaterial. PEEK is expected to play a pivotal role in diverse fields, including cardiovascular disease treatment, ophthalmic implants, biosensing devices, and 3D printing. Besides, its use in orthopedic and dental clinics is expected to expand significantly. Despite these promising developments, there is currently a lack of comprehensive review articles that summarize the potential future biomedical applications of modified PEEK implants. To address this gap, we conducted this review to systematically examine the latest research findings on modified PEEK implants in the medical field over the past decade and their future prospects in biomedical applications.},
  archive      = {J_MATDES},
  author       = {Zuge Yang and Weiwei Guo and Wenhao Yang and Jianye Song and Wenhui Hu and Kun Wang},
  doi          = {10.1016/j.matdes.2025.113716},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113716},
  shortjournal = {Mater. Des.},
  title        = {Polyetheretherketone biomaterials and their current progress, modification-based biomedical applications and future challenges},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Microstructural analysis and design of electroplated-cu
micropillar under different process variables and pattern structures.
<em>MATDES</em>, <em>252</em>, 113715. (<a
href="https://doi.org/10.1016/j.matdes.2025.113715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cu micropillars, designed to meet the fine pitch demands of high-performance high-density semiconductor devices, offer superior thermal dissipation and electromigration resistance compared to conventional solder bumps. In microelectronic packaging, the Cu micropillar bump pitch and diameter are adjusted as needed; however, achieving a uniform height across all micropillars for reliable signal transmission remains a major challenge. In this study, the morphology of Cu micropillars electrodeposited in pores was patterned for various structures under different deposition conditions. The micropillar morphological characteristics were measured via scanning electron microscopy, revealing tendencies in micropillar height with respect to the deposition conditions and micropore structure. COMSOL-Multiphysics, a finite-element-analysis-based simulation software, was used to verify the ion concentrations and electrolyte distributions in the structure according to the deposition conditions and micropore structure. The methodology and findings of this study could be used to predict, control, and design the microstructural thickness deviations in processes requiring precise micro-plating structures.},
  archive      = {J_MATDES},
  author       = {Sangyeun Park and Byungkwon Chun and Sunbum Kim and Hak-Sung Kim and Hongyun So},
  doi          = {10.1016/j.matdes.2025.113715},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113715},
  shortjournal = {Mater. Des.},
  title        = {Microstructural analysis and design of electroplated-cu micropillar under different process variables and pattern structures},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Programmable control of soft magnetic helical microrobot
from microfluidics. <em>MATDES</em>, <em>252</em>, 113707. (<a
href="https://doi.org/10.1016/j.matdes.2025.113707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft magnetic helical microrobots (SMHMs) have received increasing attention due to their body compliance, high controllability, and rotation-based motion. Their accurate and programmable control is expected for complex environments facing practical applications. We fabricate the SMHM easily through microfluidics, and build a Helmholtz coil system with a user-friendly graphical user interface (GUI) to programmatically control them. By controlling the currents of three-dimensional Helmholtz coil, the rotation speed and direction of the uniform rotating magnetic field generated by the coil can be customized. Besides, SMHMs can rotate in the direction perpendicular to the rotation axis of the magnetic field, and their speeds increase with the magnetic rotation frequency. Thus, the accurate manipulation of the SMHMs’ speed and direction will be achieved just by regulating the coil current. Further, a GUI combined with path planning algorithm is developed to control SMHMs by programming the currents, planning the optimal path for SMHMs, and monitoring their real-time motions. Even non-specialists could easily manipulate SMHMS to move along the desired path and realize the controllable obstacle avoidance movement, which is programmable, user-friendly, and potential for complex scenarios. These characteristics may enable more accurate, effective, and safe work of SMHMs in various fields.},
  archive      = {J_MATDES},
  author       = {Yikai Wu and Can Wang and Wenhui Zhang and Jiahui Yang and Hainiu Zhu and Linlin Xia and Jie Wang},
  doi          = {10.1016/j.matdes.2025.113707},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113707},
  shortjournal = {Mater. Des.},
  title        = {Programmable control of soft magnetic helical microrobot from microfluidics},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025a). Ballistic impact performance of kevlar®/UHMWPE hybrid
composite panels with a liquid thermoplastic resin, elium®.
<em>MATDES</em>, <em>252</em>, 113706. (<a
href="https://doi.org/10.1016/j.matdes.2025.113706">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents the ballistic impact performance of composite panels with novel liquid Methyl methacrylate (MMA) (Elium®) thermoplastic resin. The panels, which include Kevlar ® (Kevlar) and ultra-high molecular weight polyethylene (UHMWPE), and hybrids with their combination (Kevlar/UHMWPE and UHMWPE/Kevlar), were manufactured with different numbers of layers (16 and 24) using vacuum-assisted resin transfer. These panels were tested against 0.38 lead round nose (300 ± 15 m/s) and 0.357 semi-jacketed soft point flat (550 ± 15 m/s) projectiles. The study assesses the ballistic impact performance of single fibre reinforced and the influence of hybridisation through various parameters such as, damage patterns, back face deformation, energy absorption, and residual velocity. The results reveal that 16 and 24 layer panels effectively defeated 0.38 projectile with relatively lower back face deformation while showing perforations for 0.357 projectile with varying residual velocities for different panel configurations. The hybrid combination of Kevlar/UHMWPE with Kevlar on the front demonstrated higher energy absorption with low residual velocity, leveraging the superior energy absorption capability of Kevlar and better stretching from UHMWPE. This study not only underscores the potential of Elium® resin-based composite panels for ballistic protection but also emphasises the crucial role of reinforcement hybridisation in enhancing the ballistic performance.},
  archive      = {J_MATDES},
  author       = {Aswani Kumar Bandaru and Dinesh Kumar Kothandan and Hemant Chouhan and Hong Ma and Ronan M. O’Higgins},
  doi          = {10.1016/j.matdes.2025.113706},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113706},
  shortjournal = {Mater. Des.},
  title        = {Ballistic impact performance of Kevlar®/UHMWPE hybrid composite panels with a liquid thermoplastic resin, elium®},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unveiling processing–property relationships in laser powder
bed fusion: The synergy of machine learning and high-throughput
experiments. <em>MATDES</em>, <em>252</em>, 113705. (<a
href="https://doi.org/10.1016/j.matdes.2025.113705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving desired mechanical properties in additive manufacturing requires many experiments and a well-defined design framework becomes crucial in reducing trials and conserving resources. Here, we propose a methodology embracing the synergy between high-throughput (HT) experimentation and hierarchical machine learning (ML) to unveil the complex relationships between a large set of process parameters in Laser Powder Bed Fusion (LPBF) and selected mechanical properties (tensile strength and ductility). The HT method envisions the fabrication of small samples for rapid automated hardness and porosity characterization, and a smaller set of tensile specimens for more labor-intensive direct measurement of yield strength and ductility. The ML approach is based on a sequential application of Gaussian processes (GPs) where the correlations between process parameters and hardness/porosity are first learnt and subsequently adopted by the GPs that relate strength and ductility to process parameters. Finally, an optimization scheme is devised that leverages these GPs to identify the process parameters that maximize combinations of strength and ductility. By founding the learning on larger “easy-to-collect” and smaller “labor-intensive” data, we reduce the reliance on expensive characterization and enable exploration of a large processing space. Our approach is material-agnostic and herein we demonstrate its application on 17-4PH stainless steel.},
  archive      = {J_MATDES},
  author       = {Mahsa Amiri and Zahra Zanjani Foumani and Penghui Cao and Lorenzo Valdevit and Ramin Bostanabad},
  doi          = {10.1016/j.matdes.2025.113705},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113705},
  shortjournal = {Mater. Des.},
  title        = {Unveiling processing–property relationships in laser powder bed fusion: The synergy of machine learning and high-throughput experiments},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Udimet 720Li as a potential alternative for optimised
aeroengine turbines: Thermophysical and thermomechanical
characterisation under wide-ranging testing conditions. <em>MATDES</em>,
<em>252</em>, 113700. (<a
href="https://doi.org/10.1016/j.matdes.2025.113700">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The need to reduce fuel consumption and emissions is driving advances in aeroengine performance. Efficiency gains are limited by the capacity of the turbine material to withstand the high thermomechanical loads of the combustion process. Nickel-based alloy Udimet 720Li has emerged as a promising alternative to the most widely used Inconel 718 for critical aeroengine components. Nonetheless, its material properties under industry-relevant conditions remain understudied, hindering industrial implementation. Furthermore, discrepancies in the methodology for applying adiabatic heating correction in thermomechanical tests on nickel-based alloys prevent comparability of studies and alloys. This paper presents the thermophysical and thermomechanical properties of forged and heat-treated Udimet 720Li to enable advanced aeroengine design and manufacture. A novel adiabatic heating correction procedure is also proposed for thermomechanical tests. Thermophysical properties (specific heat, density, diffusivity, thermal expansion, and conductivity) were characterised for temperatures 20–1200 °C. Thermomechanical properties were obtained for temperatures 20–1100 °C and strain rates 0.01–100 s −1 with cylinder compression tests. The results show that Udimet 720Li exhibits higher thermomechanical properties than Inconel 718 at elevated temperatures and can withstand greater in-service temperatures (8–23 %) due to the higher γ ’ strengthening phase content which remains stable up to 760 °C.},
  archive      = {J_MATDES},
  author       = {Gorka Ortiz-de-Zarate and Idriss Tiba and Aitor Madariaga and Arantza Linaza and Ainhara Garay and Guénaël Germain and Pedro J. Arrazola},
  doi          = {10.1016/j.matdes.2025.113700},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113700},
  shortjournal = {Mater. Des.},
  title        = {Udimet 720Li as a potential alternative for optimised aeroengine turbines: Thermophysical and thermomechanical characterisation under wide-ranging testing conditions},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interfacial adhesion between dissimilar thermoplastics
fabricated via material extrusion-based multi-material additive
manufacturing. <em>MATDES</em>, <em>252</em>, 113688. (<a
href="https://doi.org/10.1016/j.matdes.2025.113688">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-material additive manufacturing (MMAM) enables the design of materials with tunable mechanical performance by fabricating multiple dissimilar materials in a single print. MMAM has been utilized to fabricate components with unique mechanical properties for applications such as damage detection, medical devices, sensors, and soft robotics. However, the bonding strength between dissimilar polymeric materials strongly depends on the material combination and is typically lower than the material strength of the constituents. This study investigates the interfacial adhesion between two thermoplastics fabricated via material extrusion (ME)-based MMAM by quantifying the interface bonding strength using mechanical tests and polymer adhesion theory-based correlation analysis. Experimental results showed that the polylactic acid (PLA)-polyethylene terephthalate glycol (PETG), PETG-polycarbonate (PC) and PLA-PC material combinations exhibit bonding strengths that are close to or exceed their constituent’s material strength. Material combinations that include polypropylene (PP) and polyethylene (PE) exhibited bonding strengths of nearly two magnitudes lower than those of PLA-PETG, PETG-PC, and PLA-PC. The microstructural images of the samples showed that the most compatible combinations exhibited a smooth, gradient interface indicating the importance of nano-scale adhesion mechanisms. Based on Hansen solubility parameters and the coefficient of thermal expansion (CTE), we observed the correlation between wettability and physical adsorption, intermolecular diffusion, thermal stress, and the interface bonding strength. The wettability and physical adsorption feature extracted from the solubility parameters showed the highest correlation with the interface bonding strength. Furthermore, we observed that the smaller the difference in solubility parameters and CTE between two thermoplastics fabricated via ME, the more compatible the two thermoplastics are.},
  archive      = {J_MATDES},
  author       = {Felix Richter and Dazhong Wu},
  doi          = {10.1016/j.matdes.2025.113688},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113688},
  shortjournal = {Mater. Des.},
  title        = {Interfacial adhesion between dissimilar thermoplastics fabricated via material extrusion-based multi-material additive manufacturing},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Additive manufacturing of metal matrix composites.
<em>MATDES</em>, <em>252</em>, 113609. (<a
href="https://doi.org/10.1016/j.matdes.2025.113609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although Metal matrix composites (MMCs) are superior to most sought-after metallic alloys, their challenging fabricability has limited their widespread use in bulk-form applications. Among the many advanced fabrication techniques, Additive Manufacturing (AM), owing to its unique capabilities to produce near-net shapes, has drawn significant traction in the past two decades, especially for materials that are difficult to process using traditional methods. However, unlike pure metal/alloy systems, MMCs are highly sensitive to the processing conditions prevailing in AM techniques due to factors such as the high melting point of reinforcement particles and the potential for in-situ reactions. Therefore, it may be a while before metal matrix composites are commercially produced via AM. This review will discuss the current state-of-the-art design, fabricability, and performance of various additively manufactured Metal matrix composites (AMMCs). A particular focus will be on microstructural evolution and microstructure-property relationships. The most employed AM techniques, such as directed energy deposition, powder bed fusion, binder jetting, sheet lamination, and solid-state friction stir processing, are fundamentally different in terms of thermo-kinetics, forming the perspective for this review. A detailed comparison of microstructural evolution and process parameter optimization, including feedstock preparation methods and the role of machine learning and modeling among the different AM processes, is also presented. Finally, a critical evaluation of emerging AM technologies for MMCs is also provided, highlighting their potential advantages and challenges.},
  archive      = {J_MATDES},
  author       = {Mohan Sai Kiran Kumar Yadav Nartu and Priyanshi Agrawal},
  doi          = {10.1016/j.matdes.2025.113609},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113609},
  shortjournal = {Mater. Des.},
  title        = {Additive manufacturing of metal matrix composites},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="mla---22">MLA - 22</h2>
<ul>
<li><details>
<summary>
(2025). Predicting classification errors using NLP-based machine
learning algorithms and expert opinions. <em>MLA</em>, <em>19</em>,
100630. (<a href="https://doi.org/10.1016/j.mlwa.2025.100630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various intentional and unintentional biases of humans manifest in classification tasks, such as those related to risk management. In this paper we demonstrate the role of ML algorithms when accomplishing these tasks and highlight the role of expert know-how when training the staff as well as, and very importantly, when training and fine-tuning ML algorithms. In the process of doing so and when facing well-known inefficiencies of the traditional F1 score, especially when working with unbalanced datasets, we suggest a modification of the score by incorporating human-experience-trained algorithms, which include both expert-trained algorithms (i.e., with the involvement of expert experiences in classification tasks) and staff-trained algorithms (i.e., with the involvement of experiences of those staff who have been trained by experts). Our findings reveal that the modified F1 score diverges from the traditional staff F1 score when the staff labels exhibit weak correlation with expert labels, which indicates insufficient staff training. Furthermore, the Long Short-Term Memory (LSTM) model outperforms other classifiers in terms of the modified F1 score when applied to the classification of textual narratives in consumer complaints.},
  archive      = {J_MLA},
  author       = {Peiheng Gao and Chen Yang and Ning Sun and Ričardas Zitikis},
  doi          = {10.1016/j.mlwa.2025.100630},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100630},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Predicting classification errors using NLP-based machine learning algorithms and expert opinions},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep learning framework for accurate COVID-19
classification in CT-scan images. <em>MLA</em>, <em>19</em>, 100628. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background In response to the global COVID-19 pandemic, we have introduced a binary classification model that employs convolutional layers to differentiate between normal cases and COVID-19-infected cases. Our primary aim was to address the urgent need for a highly efficient and accurate diagnostic tool to combat the widespread outbreak of COVID-19. Methods To achieve the background, we proposed a convolutional structure that comprises 10 layers in the encoder and 3 dense layers in the decoder. We conducted comprehensive experiments and evaluations using four distinct datasets. Results The outcomes of our study consistently demonstrated remarkable performance, with our proposed model achieving an accuracy of 89.00 %, a sensitivity of 0.95, a specificity of 0.88, and an impressive AUC of 0.92. Notably, Dataset 4 yielded the most promising results among all datasets, underscoring the effectiveness of our approach. Conclusion Our research substantiates the superiority of our model over previous methodologies and pre-trained models. Furthermore, it significantly contributes to global efforts in combating COVID-19 by providing an advanced diagnostic tool. This work also paves the way for future breakthroughs in the field of medical image analysis.},
  archive      = {J_MLA},
  author       = {Shirin Kordnoori and Maliheh Sabeti and Hamidreza Mostafaei and Saeed Seyed Agha Banihashemi},
  doi          = {10.1016/j.mlwa.2025.100628},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100628},
  shortjournal = {Mach. Learn. Appl.},
  title        = {A deep learning framework for accurate COVID-19 classification in CT-scan images},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Corrigendum to “machine learning for sports betting: Should
model selection be based on accuracy or calibration?” [Machine learning
with applications volume 16, june 2024, 100539]. <em>MLA</em>,
<em>19</em>, 100627. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MLA},
  author       = {Conor Walsh and Alok Joshi},
  doi          = {10.1016/j.mlwa.2025.100627},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100627},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Corrigendum to “Machine learning for sports betting: Should model selection be based on accuracy or calibration?” [Machine learning with applications volume 16, june 2024, 100539]},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Noninvasive estimation of blood glucose and HbA1c using
quantum machine learning technique. <em>MLA</em>, <em>19</em>, 100626.
(<a href="https://doi.org/10.1016/j.mlwa.2025.100626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we developed models with quantum and classical machine learning algorithms to detect blood glucose and HbA1c noninvasively from ten-second fingertip video by deploying a smartphone and near-infrared spectroscopy. Using our developed framework, we collected 136 participants’ ten-second fingertip videos with their baseline blood glucose and HbA1c levels after getting approval from the Institutional Review Board (IRB). We extracted 45 PPG (photoplethysmography) features from the ten-second fingertip video by using the Beer–Lambert law and applied feature engineering to select the most important features. We applied two Quantum Machine Learning (QML) based algorithms and seven Classical Machine Learning (CML) based algorithms for estimating blood glucose and HbA1c levels. The application of QML for the noninvasive estimation of blood glucose and HbA1c is a new and unexplored research area. Among all developed models, the Quantum Support Vector Machine performs best for predicting both blood glucose and HbA1c. The Quantum Support Vector Machine provides an accuracy of 89.30% and an average k-fold cross-validation score of 92.50% for blood glucose prediction and an accuracy of 96.30% and an average k-fold cross-validation score of 92.50% for HbA1c prediction. Our study signifies the potential of QML algorithms in noninvasive health monitoring, especially in the less-explored area of blood glucose and HbA1c estimation. The high performance of the developed models paves the way for advancing noninvasive techniques for measuring blood constituents. These findings offer promising applications in personalized healthcare, including continuous monitoring, early disease diagnosis, and more convenient management of chronic conditions.},
  archive      = {J_MLA},
  author       = {Parama Sridevi and Masud Rabbani and Md Hasanul Aziz and Paramita Basak Upama and Sayed Mashroor Mamun and Rumi Ahmed Khan and Sheikh Iqbal Ahamed},
  doi          = {10.1016/j.mlwa.2025.100626},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100626},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Noninvasive estimation of blood glucose and HbA1c using quantum machine learning technique},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multiobjective continuation method to compute the
regularization path of deep neural networks. <em>MLA</em>, <em>19</em>,
100625. (<a href="https://doi.org/10.1016/j.mlwa.2025.100625">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparsity is a highly desired feature in deep neural networks (DNNs) since it ensures numerical efficiency, improves the interpretability (due to the smaller number of relevant features), and robustness. For linear models, it is well known that there exists a regularization path connecting the sparsest solution in terms of the ℓ 1 norm, i.e., zero weights and the non-regularized solution. Recently, there was a first attempt to extend the concept of regularization paths to DNNs by means of treating the empirical loss and sparsity ( ℓ 1 norm) as two conflicting criteria and solving the resulting multiobjective optimization problem. However, due to the non-smoothness of the ℓ 1 norm and the large number of parameters, this approach is not very efficient from a computational perspective. To overcome this limitation, we present an algorithm that allows for the approximation of the entire Pareto front for the above-mentioned objectives in a very efficient manner for high-dimensional DNNs with millions of parameters. We present numerical examples using both deterministic and stochastic gradients. We furthermore demonstrate that knowledge of the regularization path allows for a well-generalizing network parametrization.},
  archive      = {J_MLA},
  author       = {Augustina Chidinma Amakor and Konstantin Sonntag and Sebastian Peitz},
  doi          = {10.1016/j.mlwa.2025.100625},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100625},
  shortjournal = {Mach. Learn. Appl.},
  title        = {A multiobjective continuation method to compute the regularization path of deep neural networks},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Apply a deep learning hybrid model optimized by an improved
chimp optimization algorithm in PM2.5 prediction. <em>MLA</em>,
<em>19</em>, 100624. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {PM 2.5 pollution in the atmosphere not only contaminates the environment but also seriously affects human health. Therefore, studying how to accurately predict future PM 2.5 concentrations holds significant importance and practical value. This paper innovatively P M 2 . 5 proposes a high-accuracy prediction model: RF-ICHOA-CNN-LSTM-Attention. First, the Random Forest (RF) model is utilized to evaluate the importance of air pollution and meteorological features and select more suitable input features. Subsequently, a one-dimensional convolutional neural network (1DCNN) with efficient feature extraction capability is used to extract dynamic features from sequences. The extracted feature vector sequences are then fed into a Long Short-Term Memory Network (LSTM). After the LSTM, an Attention Mechanism is incorporated to assign different weights to the input features, emphasizing the role of the important features. Additionally, the Improved Chimp Optimization Algorithm (IChOA) is employed to optimize the number of neurons in the two hidden layers of LSTM, the learning rate, and the number of training epochs. The experimental results on 12 test functions demonstrate that the optimization performance of IChOA is better than that of ChOA and the representative swarm optimization algorithms used for comparison. In the case of PM 2.5 predictions in Yining and Beijing, experimental results show that the proposed model achieved the best performance in terms of RMSE, MAE, and R 2 This indicates its excellent prediction accuracy and generalization capability, Thus proving its effectiveness in predicting PM 2.5 concentration in the real world.},
  archive      = {J_MLA},
  author       = {Ming Wei and Xiaopeng Du},
  doi          = {10.1016/j.mlwa.2025.100624},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100624},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Apply a deep learning hybrid model optimized by an improved chimp optimization algorithm in PM2.5 prediction},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning techniques and multi-objective programming
to select the best suppliers and determine the orders. <em>MLA</em>,
<em>19</em>, 100623. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selection of appropriate suppliers and allocation the orders among them have become the two key strategic decisions regarding purchasing. In this study, a two-phase integrated approach is proposed for solving supplier selection and order allocation problems. Phase 1 contains four techniques from statistics and Machine Learning (ML), including Auto-Regressive Integrated Moving Average, Random Forest, Gradient Boosting Regression, and Long Short-term Memory for forecasting the demands, using large amounts of real historical data. In Phase 2, suppliers’ qualitative weights are determined by a fuzzy logic model. Then, a new multi-objective programming model is designed, considering multiple periods and products. In this phase, the results of Phase 1 and the results of the fuzzy model are utilized as inputs for the multi-objective model. The weighted-sum method is applied for solving the multi-objective model. The results show Random Forest model leads to more accurate predictions than the other examined models in this study. In addition, based on the results, the selection of the forecasting techniques and different weights of suppliers affect both supplier selection and the related orders.},
  archive      = {J_MLA},
  author       = {Asma ul Husna and Saman Hassanzadeh Amin and Ahmad Ghasempoor},
  doi          = {10.1016/j.mlwa.2025.100623},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100623},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Machine learning techniques and multi-objective programming to select the best suppliers and determine the orders},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Safety analysis in the era of large language models: A case
study of STPA using ChatGPT. <em>MLA</em>, <em>19</em>, 100622. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Can safety analysis leverage Large Language Models (LLMs)? This study examines the application of Systems Theoretic Process Analysis (STPA) to Automatic Emergency Brake (AEB) and Electricity Demand Side Management (DSM) systems, utilising Chat Generative Pre-Trained Transformer (ChatGPT). We investigate the impact of collaboration schemes, input semantic complexity, and prompt engineering on STPA results. Comparative results indicate that using ChatGPT without human intervention may be inadequate due to reliability issues. However, with careful design, it has the potential to outperform human experts. No statistically significant differences were observed when varying the input semantic complexity or using domain-agnostic prompt guidelines. While STPA-specific prompt engineering produced statistically significant and more pertinent results, ChatGPT generally yielded more conservative and less comprehensive outcomes. We also identify future challenges, such as concerns regarding the trustworthiness of LLMs and the need for standardisation and regulation in this field. All experimental data are publicly accessible.},
  archive      = {J_MLA},
  author       = {Yi Qi and Xingyu Zhao and Siddartha Khastgir and Xiaowei Huang},
  doi          = {10.1016/j.mlwa.2025.100622},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100622},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Safety analysis in the era of large language models: A case study of STPA using ChatGPT},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ensembles of deep one-class classifiers for multi-class
image classification. <em>MLA</em>, <em>19</em>, 100621. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional methods for multi-class classification (MCC) involve using a monolithic feature extractor and classifier trained on data from all the classes simultaneously. These methods are dependent on the number and types of classes and are therefore rigid against changes to the class structure. For instance, if the number of classes needs to be modified or new training data becomes available, retraining would be required for optimum classification performance. Moreover, these classifiers can become biased toward classes with a large data imbalance. An alternative, more attractive framework is to consider an ensemble of one-class classifiers (EOCC) where each one-class classifier (OCC) is trained with data from a single class only, without using any information from the other classes. Although this framework has not yet systematically matched or surpassed the performance of traditional MCC approaches, it deserves further investigation for several reasons. First, it provides a more flexible framework for handling changes in class structure compared to the traditional MCC approach. Second, it is less biased toward classes with large data imbalances compared to the multi-class classification approach. Finally, each OCC can be separately optimized depending on the characteristics of the class it represents. In this paper, we have performed extensive experiments to evaluate EOCC for MCC using traditional OCCs based on Principal Component Analysis (PCA) and Auto-encoders (AE) as well as newly proposed OCCs based on Generative Adversarial Networks (GANs). Moreover, we have compared the performance of EOCC with traditional multi-class DL classifiers including VGG-19, Resnet and EfficientNet. Two different datasets were used in our experiments: (i) a subset from the Plant Village dataset plant disease dataset with high variance in the number of classes and amount of data in each class, and (ii) an Alzheimer’s disease dataset with low amounts of data and a large imbalance in data between classes. Our results show that the GAN-based EOCC outperform previous EOCC approaches and improve the performance gap with traditional MCC approaches.},
  archive      = {J_MLA},
  author       = {Alexander Novotny and George Bebis and Alireza Tavakkoli and Mircea Nicolescu},
  doi          = {10.1016/j.mlwa.2025.100621},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100621},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Ensembles of deep one-class classifiers for multi-class image classification},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-agent deep reinforcement learning with online and fair
optimal dispatch of EV aggregators. <em>MLA</em>, <em>19</em>, 100620.
(<a href="https://doi.org/10.1016/j.mlwa.2025.100620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing popularity of electric vehicles (EVs) and the unpredictable behavior of EV owners have attracted attention to real-time coordination of EVs charging management. This paper presents a hierarchical structure for charging management of EVs by integrating fairness and efficiency concepts within the operations of the distribution system operator (DSO) while utilizing a multi-agent deep reinforcement learning (MADRL) framework to tackle the complexities of energy purchasing and distribution among EV aggregators (EVAs). At the upper level, DSO calculates the maximum allowable power for each EVA based on power flow constraints to ensure grid safety. Then, it finds the optimal efficiency-Jain tradeoff (EJT) point, where it sells the highest energy amount while ensuring equitable energy distribution. At the lower level, initially, each EVA acts as an agent employing a double deep Q-network (DDQN) with adaptive learning rates and prioritized experience replay to determine optimal energy purchases from the DSO. Then, the real-time smart dispatch (RSD) controller prioritizes EVs for energy dispatch based on relevant EVs information. Findings indicate the proposed enhanced DDQN outperforms deep deterministic policy gradient (DDPG) and proximal policy optimization (PPO) in cumulative rewards and convergence speed. Finally, the framework’s performance is evaluated against uncontrolled charging and the first come first serve (FCFS) scenario using the 118-bus distribution system, demonstrating superior performance in maintaining safe operation of the grid while reducing charging costs for EVAs. Additionally, the framework’s integration with renewable energy sources (RESs), such as photovoltaic (PV), demonstrates its potential to enhance grid reliability.},
  archive      = {J_MLA},
  author       = {Arian Shah Kamrani and Anoosh Dini and Hanane Dagdougui and Keyhan Sheshyekani},
  doi          = {10.1016/j.mlwa.2025.100620},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100620},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Multi-agent deep reinforcement learning with online and fair optimal dispatch of EV aggregators},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving mango ripeness grading accuracy: A comprehensive
analysis of deep learning, traditional machine learning, and transfer
learning techniques. <em>MLA</em>, <em>19</em>, 100619. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bangladesh ranks among the top 10 countries globally in mango output. Mangoes can be classified based on their ripeness, with skin color being the most significant aspect. The current classification procedure is done manually, leading to mistakes and vulnerability to human error. Most research often focuses on using a single method to assess the ripeness of fruits. The study comprises a set of comprehensive tests showcasing different tactics for determining the most efficient methods through various models. One unique dataset was used for all five models: Gaussian Naive Bayes (GNB), Support Vector Machine (SVM), Gradient Boosting (GB), Random Forest (RF), and K-Nearest Neighbors (KNN). Utilizing convolutional neural networks (CNNs) and VGG16, a pre-trained CNN model, to extract features and train the dataset. Used these training datasets as input to calculate the average accuracy of the five models during testing. In addition to these experiments, these five models using standard techniques also evaluated. The study also included a comparative analysis that emphasized the best performance of each model in various scenarios. This analysis shows that the CNN model consistently performs better than the transfer learning model (VGG16) and classical machine learning methods. Except for the KNN and Naive Bayes scenarios, the VGG16 model achieved much higher accuracy compared to typical machine learning methods. In three other models, classical machine learning outperforms the VGG16 model. The Gradient Boosting model in deep learning (CNN) demonstrated the highest accuracy of 96.28 % compared to other models and techniques.},
  archive      = {J_MLA},
  author       = {Md․ Saon Sikder and Mohammad Shamsul Islam and Momenatul Islam and Md․ Suman Reza},
  doi          = {10.1016/j.mlwa.2025.100619},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100619},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Improving mango ripeness grading accuracy: A comprehensive analysis of deep learning, traditional machine learning, and transfer learning techniques},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting customer subscription in bank telemarketing
campaigns using ensemble learning models. <em>MLA</em>, <em>19</em>,
100618. (<a href="https://doi.org/10.1016/j.mlwa.2025.100618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the use of ensemble learning models bagging, boosting, and stacking to enhance the accuracy and reliability of predicting customer subscriptions in bank telemarketing campaigns. Recognizing the challenges posed by class imbalance and complex customer behaviors, we employ multiple ensemble techniques to build a robust predictive framework. Our analysis demonstrates that stacking models achieve the best overall performance, with an accuracy of 91.88% and an Receiver Operating Characteristic Area Under the Curve (ROC-AUC) score of 0.9491, indicating a strong capability to differentiate between subscribers and non-subscribers. Additionally, feature importance analysis reveals that contact duration, economic indicators like the Euro interbank offered (Euribor) rate, and customer age are the most influential factors in predicting subscription likelihood. These findings suggest that by focusing on customer engagement and economic trends, banks can improve telemarketing campaign effectiveness. We recommend the integration of advanced balancing techniques and real-time prediction systems to further enhance model performance and adaptability. Future work could explore deep learning models and interpretability techniques to gain deeper insights into customer behavior patterns. Overall, this study highlights the potential of ensemble models in predictive modeling for telemarketing, providing a data-driven foundation for more targeted and efficient customer acquisition strategies.},
  archive      = {J_MLA},
  author       = {Michael Peter and Hawa Mofi and Said Likoko and Julius Sabas and Ramadhani Mbura and Neema Mduma},
  doi          = {10.1016/j.mlwa.2025.100618},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100618},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Predicting customer subscription in bank telemarketing campaigns using ensemble learning models},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). S&amp;p-500 vs. Nasdaq-100 price movement prediction with
LSTM for different daily periods. <em>MLA</em>, <em>19</em>, 100617. (<a
href="https://doi.org/10.1016/j.mlwa.2024.100617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the efficiency of LSTM neural networks in predicting price movements for the two major U.S. stock indices: the S&amp;P-500 and the Nasdaq-100 index. We consider three distinct daily periods: “overnight” (Close-to-Open), “daytime” (Open-to-Close) and “24-hour” (Close-to-Close) trading sessions. Using historical pricing data for these indices since 2000, this study shows how well the standard LSTM model captures price movement patterns to improve short-term trading strategies. The findings reveal that, for the S&amp;P-500, a one-year training with 24-hour periods delivers a 14.5% more return over the Buy-and-Hold strategy. Moreover, combining “overnight” and “daytime” strategies delivers more than 40% return compared to passive index investing. By contrast, for the Nasdaq-100, a shorter training period of three months for “24-hour” periods delivers 90% more return than passive index investing. These results suggest that LSTM effectively learns the unique market dynamics associated with each index and different time periods, offering further insights into how deep learning can enhance financial forecasting and trading opportunities.},
  archive      = {J_MLA},
  author       = {Xiang Zhang and Eugene Pinsky},
  doi          = {10.1016/j.mlwa.2024.100617},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100617},
  shortjournal = {Mach. Learn. Appl.},
  title        = {S&amp;P-500 vs. nasdaq-100 price movement prediction with LSTM for different daily periods},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unified wound diagnostic framework for wound segmentation
and classification. <em>MLA</em>, <em>19</em>, 100616. (<a
href="https://doi.org/10.1016/j.mlwa.2024.100616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chronic wounds affect millions worldwide, posing significant challenges for healthcare systems and a heavy economic burden globally. The segmentation and classification (S&amp;C) of chronic wounds are critical for wound care management and diagnosis, aiding clinicians in selecting appropriate treatments. Existing approaches have utilized either traditional machine learning or deep learning methods for S&amp;C. However, most focus on binary classification, with few addressing multi-class classification, often showing degraded performance for pressure and diabetic wounds. Wound segmentation has been largely limited to foot ulcer images, and there is no unified diagnostic tool for both S&amp;C tasks. To address these gaps, we developed a unified approach that performs S&amp;C simultaneously. For segmentation, we proposed Attention-Dense-UNet (Att- d -UNet), and for classification, we introduced a feature concatenation-based method. Our framework segments wound images using Att- d -UNet, followed by classification into one of the wound types using our proposed method. We evaluated our models on publicly available wound classification datasets (AZH and Medetec) and segmentation datasets (FUSeg and AZH). To test our unified approach, we extended wound classification datasets by generating segmentation masks for Medetec and AZH images. The proposed unified approach achieved 90% accuracy and an 86.55% dice score on the Medetec dataset and 81% accuracy and an 86.53% dice score on the AZH dataset These results demonstrate the effectiveness of our separate models and unified approach for wound S&amp;C.},
  archive      = {J_MLA},
  author       = {Mustafa Alhababi and Gregory Auner and Hafiz Malik and Muteb Aljasem and Zaid Aldoulah},
  doi          = {10.1016/j.mlwa.2024.100616},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100616},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Unified wound diagnostic framework for wound segmentation and classification},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combinations of distributional regression algorithms with
application in uncertainty estimation of corrected satellite
precipitation products. <em>MLA</em>, <em>19</em>, 100615. (<a
href="https://doi.org/10.1016/j.mlwa.2024.100615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To facilitate effective decision-making, precipitation datasets should include uncertainty estimates. Quantile regression with machine learning has been proposed for issuing such estimates. Distributional regression offers distinct advantages over quantile regression, including the ability to model intermittency as well as a stronger ability to extrapolate beyond the training data, which is critical for predicting extreme precipitation. Therefore, here, we introduce the concept of distributional regression in precipitation dataset creation, specifically for the spatial prediction task of correcting satellite precipitation products. Building upon this concept, we formulated new ensemble learning methods that can be valuable not only for spatial prediction but also for other prediction problems. These methods exploit conditional zero-adjusted probability distributions estimated with generalized additive models for location, scale and shape (GAMLSS), spline-based GAMLSS and distributional regression forests as well as their ensembles (stacking based on quantile regression and equal-weight averaging). To identify the most effective methods for our specific problem, we compared them to benchmarks using a large, multi-source precipitation dataset. Stacking was shown to be superior to individual methods at most quantile levels when evaluated with the quantile loss function. Moreover, while the relative ranking of the methods varied across different quantile levels, stacking methods, and to a lesser extent mean combiners, exhibited lower variance in their performance across different quantiles compared to individual methods that occasionally ranked extremely low. Overall, a task-specific combination of multiple distributional regression algorithms could yield significant benefits in terms of stability.},
  archive      = {J_MLA},
  author       = {Georgia Papacharalampous and Hristos Tyralis and Nikolaos Doulamis and Anastasios Doulamis},
  doi          = {10.1016/j.mlwa.2024.100615},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100615},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Combinations of distributional regression algorithms with application in uncertainty estimation of corrected satellite precipitation products},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The association between mindfulness, psychological
flexibility, and rumination in predicting mental health and well-being
among university students using machine learning and structural equation
modeling. <em>MLA</em>, <em>19</em>, 100614. (<a
href="https://doi.org/10.1016/j.mlwa.2024.100614">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objectives This study explores the intricate relationships between mindfulness, psychological flexibility, rumination, and their combined impact on mental health and well-being. Methods Random forest regression on survey data from 524 undergraduate students was used to identify significant predictors from a comprehensive set of psychological variables. Neural networks were then trained on various combinations of these predictors to evaluate their performance in predicting mental health and well-being outcomes. Finally, structural equation modeling (SEM) was employed to validate a model based on the identified key predictors, focusing on pathways from mindfulness through psychological flexibility to rumination and well-being. Results The random forest analysis revealed that the mindfulness variables exerted their influence partially indirectly through psychological flexibility and rumination. The deep neural network analysis supported these findings and additionally showed that the mindfulness manifold model (consisting of self-awareness, self-regulation, and self-transcendence) was superior to the Five Facet Mindfulness Questionnaire variables in predicting mental health outcomes. The SEM analysis confirmed that psychological flexibility, particularly its avoidance and acceptance components, mediated the relationship between mindfulness and mental health. The hypothesized serial mediation pathway—mindfulness affecting psychological flexibility, which then influences rumination and subsequently mental health and well-being—was supported by the data. Self-transcendence was a particularly powerful predictor of mental health outcomes. Conclusions The findings underscore the critical role of psychological flexibility and rumination in mediating the effects of mindfulness on mental health and well-being, suggesting that enhancing mindfulness and psychological flexibility might significantly reduce rumination, thereby improving overall mental health and well-being.},
  archive      = {J_MLA},
  author       = {Ruohan Feng and Vaibhav Mishra and Xin Hao and Paul Verhaeghen},
  doi          = {10.1016/j.mlwa.2024.100614},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100614},
  shortjournal = {Mach. Learn. Appl.},
  title        = {The association between mindfulness, psychological flexibility, and rumination in predicting mental health and well-being among university students using machine learning and structural equation modeling},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stairway to heaven: An emotional journey in divina commedia
with threshold-based naïve bayes classifier. <em>MLA</em>, <em>19</em>,
100613. (<a href="https://doi.org/10.1016/j.mlwa.2024.100613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational literary uses data science and computer science techniques to study literature. In this framework, we investigate how an expert system can acquire knowledge from the specific content of a narrative text without any pre-existing information about it. We utilize the Threshold-based Naïve Bayes (Tb-NB) classifier to analyze the content of Dante Alighieri’s Divina Commedia poem. Tb-NB is a probabilistic data-driven model that predicts the polarity of a binary response based on the probability of an event occurring given certain features, and assigns a log-likelihood score to each word in a text. Our first task is understanding if and how the links between lexical forms and meanings characterize the three parts of the poem (Inferno, Purgatorio and Paradiso) in order to predict if a Canto belongs to Inferno or Paradiso based on its specific content, and to determine if a Canto of Purgatorio is more similar to those of Inferno or to those of Paradiso. We show Tb-NB outperform other similar approaches and achieves the same performance of Random Forest (F1-score = 0.985) but providing much more information to interpret the specific content and the lexical forms used by Dante Alighieri in its poem. The Tb-NB’s scores are the base of knowledge for the implementation of an expert system, like a search engine, that can help users to identify the most informative verses of a Canto or by better comprehend or discover the content of the poem from a word related to a particular feeling or emotion.},
  archive      = {J_MLA},
  author       = {Maurizio Romano and Claudio Conversano},
  doi          = {10.1016/j.mlwa.2024.100613},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100613},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Stairway to heaven: An emotional journey in divina commedia with threshold-based naïve bayes classifier},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive gate residual connection and multi-scale RCNN for
fake news detection. <em>MLA</em>, <em>19</em>, 100612. (<a
href="https://doi.org/10.1016/j.mlwa.2024.100612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detection of false news based on text classification technology has significant research significance and practical value in the current information age. However, existing methods overlook the problem of uneven sample distribution in the false news dataset and fail to consider the mutual influence between news articles. In light of this, this paper proposes a new method for false news detection. Firstly, news texts are embedded using Electra (Efficiently Learning an Encoder that Classifies Token Replacements Accurately) to obtain word embedding representations. Secondly, Multi-Scale Recurrent Convolutional Neural Network (RCNN) is employed to further extract contextual information from news texts. Self-attention is introduced to calculate attention scores between news articles, allowing for mutual influence between news features. The establishment of connections between modules is achieved through adaptive gated residual connections. Finally, the focal loss function is used to balance the relationship between few-sample and multi-sample data in the dataset. Experimental results on publicly available false news detection datasets demonstrate that the proposed method achieves higher prediction accuracy than the comparative methods. This method provides a new perspective for the field of false news detection, playing a positive role in promoting information authenticity and protecting public interests.},
  archive      = {J_MLA},
  author       = {QunHui Zhou and Tijian Cai},
  doi          = {10.1016/j.mlwa.2024.100612},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100612},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Adaptive gate residual connection and multi-scale RCNN for fake news detection},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Practical classification accuracy of sequential data using
neural networks. <em>MLA</em>, <em>19</em>, 100611. (<a
href="https://doi.org/10.1016/j.mlwa.2024.100611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many existing studies on neural network accuracy utilize datasets that may not always reflect real-world conditions. While it has been demonstrated that accuracy tends to decrease as the number of benign samples increases, this effect has not been quantitatively assessed within neural networks. Moreover, its relevance to security tasks beyond malware classification remains unexplored. In this research, we refined the metric to evaluate the degradation of accuracy with an increased number of benign samples in test data. Utilizing both standard and specific neural network models, we conducted experiments to adapt this metric to neural networks and various feature extraction techniques. Using the FFRI dataset, comprising 150,000 malware and 400,000 benign samples, along with the URL dataset, containing 3143 malicious and 106,545,781 benign samples, we increased benign samples in the test set while keeping the training set’s malicious and benign samples constant. Our findings indicate that neural networks can indeed overestimate their accuracy with a smaller count of benign samples. Importantly, our refined metric is not only applicable to neural networks but is also effective for other feature extraction methods and security tasks beyond malware detection.},
  archive      = {J_MLA},
  author       = {Mamoru Mimura},
  doi          = {10.1016/j.mlwa.2024.100611},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100611},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Practical classification accuracy of sequential data using neural networks},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Demographic bias mitigation at test-time using uncertainty
estimation and human–machine partnership. <em>MLA</em>, <em>19</em>,
100610. (<a href="https://doi.org/10.1016/j.mlwa.2024.100610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial attribute classification algorithms frequently manifest demographic biases by obtaining differential performance across gender and racial groups. Existing bias mitigation techniques are mostly in-processing techniques, i.e., implemented during the classifier’s training stage, that often lack generalizability, require demographically annotated training sets, and exhibit a trade-off between fairness and classification accuracy. In this paper, we propose a technique to mitigate bias at the test time i.e., during the deployment stage, by harnessing prediction uncertainty and human–machine partnership. To this front, we propose to utilize those lowest percentages of test data samples identified as outliers with high prediction uncertainty. These identified uncertain samples at test-time are labeled by human analysts for decision rendering and for subsequently re-training the deep neural network in a continual learning framework. With minimal human involvement and through iterative refinement of the network with human guidance at test-time, we seek to enhance the accuracy as well as the fairness of the already deployed facial attribute classification algorithms. Extensive experiments are conducted on gender and smile attribute classification tasks using four publicly available datasets and with gender and race as the protected attributes. The obtained outcomes consistently demonstrate improved accuracy by up to 2% and 5% for the gender and smile attribute classification tasks, respectively, using our proposed approaches. Further, the demographic bias was significantly reduced, outperforming the State-of-the-Art (SOTA) bias mitigation and baseline techniques by up to 55% for both classification tasks. The demo shall be released on https://github.com/hashtaglensman/HumanintheLoop .},
  archive      = {J_MLA},
  author       = {Anoop Krishnan Upendran Nair and Ajita Rattani},
  doi          = {10.1016/j.mlwa.2024.100610},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100610},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Demographic bias mitigation at test-time using uncertainty estimation and human–machine partnership},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Application of convolutional neural networks and ensemble
methods in the fiber volume content analysis of natural fiber
composites. <em>MLA</em>, <em>19</em>, 100609. (<a
href="https://doi.org/10.1016/j.mlwa.2024.100609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The incorporation of natural fibers into fiber-reinforced polymer composites (FRPC) has the potential to bolster their sustainability. A critical attribute of FRPC is the fiber volume content ( FVC ), a parameter that profoundly influences their thermo-mechanical characteristics. However, the determination of FVC in natural fiber composites (NFC) through manual analysis of light microscopy images is a labor-intensive process. In this work, it is demonstrated that the pixels from light microscopy images of NFC can be utilized to predict FVC using machine learning (ML) models. In this proof-of-concept investigation, it is shown that convolutional neural network-based models predict FVC with an accuracy required in polymer engineering applications, with a mean average error of 2.72 % and an R 2 coefficient of 0.85. Finally, it is shown that much simpler ML models, non-specialized in image recognition, besides being much easier and more efficient to optimize and train, can also deliver good accuracies required for FVC characterization, which not only contributes to the sustainability, but also facilitates the access of such models by researchers in regions with little computational resources. This study marks a substantial advancement in the area of automated characterization of NFC, and democratization of knowledge, offering a promising avenue for the enhancement of sustainable materials.},
  archive      = {J_MLA},
  author       = {Florian Rothenhäusler and Rodrigo Queiroz Albuquerque and Marcel Sticher and Christopher Kuenneth and Holger Ruckdaeschel},
  doi          = {10.1016/j.mlwa.2024.100609},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100609},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Application of convolutional neural networks and ensemble methods in the fiber volume content analysis of natural fiber composites},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detection of fraud in IoT based credit card collected
dataset using machine learning. <em>MLA</em>, <em>19</em>, 100603. (<a
href="https://doi.org/10.1016/j.mlwa.2024.100603">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due in large part to the proliferation of electronic financial transactions, credit card fraud is a serious problem for customers, merchants, and banks. For this reason, a novel approach is offered to fraud detection that makes use of cutting-edge ML methods in an IoT setting. The method in this paper employs a carefully selected set of cutting-edge ML algorithms specifically designed to handle the complexities of fraud detection, in contrast to older approaches that have difficulty adapting to shifting fraud patterns. In order to address the many facets of the problem, the methodology employs a large collection of ML models. These models include deep neural networks, decision trees, support vector machines, random forests, and clustering methods. This paper provides a solution that is able to detect fraudulent activity in real time by efficiently analyzing massive amounts of transactional data thanks to the power of big data processing and cloud computing. The model is able to distinguish between valid and fraudulent transactions thanks to careful feature engineering and anomaly detection methods. Extensive experiments on a large and diverse collection of real and simulated credit card transactions, both legitimate and fraudulent, prove the success of this technique. The findings demonstrate state-of-the-art performance in fraud detection, with increased precision and recall rates compared to traditional methods. And because the presented ML models are easy to understand, they improve fraud risk management and prevention techniques. The findings of this study provide banking institutions, government agencies, and policymakers with vital information for combating the negative effects of credit card fraud on consumers, companies, and the economy as a whole. This study provides a solution to the problem of fraud in the Internet of Things (IoT) ecosystem and paves the way for future developments in this crucial area by proposing a unique ML-driven approach to the problem.},
  archive      = {J_MLA},
  author       = {Mohammed Naif Alatawi},
  doi          = {10.1016/j.mlwa.2024.100603},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100603},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Detection of fraud in IoT based credit card collected dataset using machine learning},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="neucom---158">NEUCOM - 158</h2>
<ul>
<li><details>
<summary>
(2025). A reformulation neurodynamic algorithm for distributed
nonconvex optimization. <em>NEUCOM</em>, <em>635</em>, 130023. (<a
href="https://doi.org/10.1016/j.neucom.2025.130023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a reformulation neurodynamic algorithm for solving distributed nonconvex optimization problems. A class of general Lagrangian functions is introduced to eliminate the dual gap in nonconvex problems. This algorithm extends the application of neurodynamic algorithms based on the p -power reformulation transformation of Lagrangian functions. Under mild conditions, the initial point of the decision vector can be arbitrarily chosen. It is proven that the output trajectories will eventually converge to a strict local minimum point of the distributed nonconvex optimization problem. Finally, numerical experiments demonstrate the effectiveness of the proposed algorithm, which is also applied to solve the oblique throwing problem and the distributed source localization problem.},
  archive      = {J_NEUCOM},
  author       = {Xin Yu and Qingzhou Huang and Rixin Lin},
  doi          = {10.1016/j.neucom.2025.130023},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {130023},
  shortjournal = {Neurocomputing},
  title        = {A reformulation neurodynamic algorithm for distributed nonconvex optimization},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ASTR: Transformer-based alert-to-stage translator for
multi-stage attack detection. <em>NEUCOM</em>, <em>635</em>, 130016. (<a
href="https://doi.org/10.1016/j.neucom.2025.130016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-stage attacks have complex patterns and intricate inter-stage dependencies, making them difficult to detect using conventional methods. Traditional detection techniques struggle to capture long-term dependencies in alert sequences and often fail to map individual alerts to their specific attack stages. Aiming to develop an advanced detection method enhancing the accuracy and granularity of multi-stage attack detection, this paper proposes ASTR (Alert Stage TRanslator for MSA), a Transformer-based detection architecture. ASTR utilizes a Doc2Vec-based frontend to embed IDS alerts into numerical vectors and applies positional encoding to preserve sequential information. The core Transformer backbone, with its attention mechanism, is employed to extract deep contextual features and long-term dependencies from alert sequences. Finally, a refined backend maps these features to specific attack stages. ASTR is evaluated against state-of-the-art methods using three public datasets: DARPA2000, ISCXIDS2012, and CIC-IDS2017. Experimental results demonstrate that ASTR achieves detection accuracy of over 97% across all datasets. Compared to existing methods, ASTR not only improves precision, recall, and F1-scores but also provides detailed, one-to-one mappings from alerts to attack stages, thereby offering a more fine-grained detection capability.},
  archive      = {J_NEUCOM},
  author       = {Wei Ma and Yunyun Hou and Aina Sui and Pengpeng Jian},
  doi          = {10.1016/j.neucom.2025.130016},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {130016},
  shortjournal = {Neurocomputing},
  title        = {ASTR: Transformer-based alert-to-stage translator for multi-stage attack detection},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PRG-net: Point relationship-guided network for 3D human
action recognition. <em>NEUCOM</em>, <em>635</em>, 130015. (<a
href="https://doi.org/10.1016/j.neucom.2025.130015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point clouds contain rich spatial information, providing important supplementary clues for human action recognition. Recent methods for action recognition based on point cloud sequences primarily rely on complex spatiotemporal local encoding. However, these methods often utilize max-pooling operations to select features when extracting local features, restricting feature updates to local neighborhoods and failing to fully exploit the relationships between regions. Moreover, cross-frame encoding can also lead to the loss of spatiotemporal information. In this study, we propose PRG-Net, a Point Relation Guided Network, to further improve the learning of spatiotemporal features in point clouds. First, we designed two core modules: the Spatial Feature Aggregation (SFA) and the Spatial Feature Descriptor (SFD) modules. The SFA module expands the spatial structure between regions using dynamic aggregation techniques, while the SFD module guides the region aggregation process by Attention-Weighted Descriptors. They enhance the modeling of human spatial structure by expanding the relationships between regions. Second, we introduce inter-frame motion encoding techniques that can obtain the final spatiotemporal representation of the human body through the aggregation of cross-frame vectors, without relying on complex spatiotemporal local encoding. We evaluate PRG-Net on publicly available human action recognition datasets, including NTU RGB+D 60, NTU RGB+D 120, UTD-MHAD, and MSR Action 3D. Experimental results demonstrate that our method outperforms state-of-the-art point-based 3D action recognition methods significantly. Furthermore, we conduct extended experiments on the SHREC 2017 dataset for gesture recognition, and the results show that our method maintains competitive performance on that dataset as well.},
  archive      = {J_NEUCOM},
  author       = {Yao Du and Zhenjie Hou and En Lin and Xing Li and Jiuzhen Liang and Xinwen Zhou},
  doi          = {10.1016/j.neucom.2025.130015},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {130015},
  shortjournal = {Neurocomputing},
  title        = {PRG-net: Point relationship-guided network for 3D human action recognition},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep consistent penalizing hashing with noise-robust
representation for large-scale image retrieval. <em>NEUCOM</em>,
<em>635</em>, 130014. (<a
href="https://doi.org/10.1016/j.neucom.2025.130014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benefiting from the powerful representational capacity of deep learning and the attractive computational efficiency of binary codes, deep hashing frameworks have made large progress for large-scale image retrieval applications. By calculating the priori labels, most existing deep supervised hashing usually introduces the effective margin-based objective loss to generate label-level penalizing boundaries for training samples during the model optimization. However, the decision boundaries from label-level penalizing may be inconsistent with semantic relations hidden in raw samples, compromising the performance. Besides, for classes with low intra-class variances or inter-class correlations, the force field of the margin-based methods might be too weak to learn the discriminant embedding space. In this paper, we solve this dilemma with a novel unified deep hashing framework, termed Deep Consistent Penalizing Hashing with noise-robust representation (DCPH), to generate compact yet discriminative binary codes for efficient and accurate image retrieval. Specifically, by learning the unbalanced correlations of training samples, the semantic consistency penalizing loss, consisting of pulling penalizing elements and pushing penalizing elements, is proposed to generate the semantic decision boundaries across classes. For parameter optimization, the dice-like optimization strategy is introduced to balance the pulling and pushing field, facilitating the generation of highly separable Hamming space. Besides, to mitigate the negative influence caused by objective-unrelated information or noise, by introducing patch-wise attention strategy and depth-wise convolution operation, the noise-robust representation module is developed to capture the robust feature descriptor with abundant fine-grained information. Comprehensive evaluations are performed on several benchmark datasets, and the experimental results consistently validate the effectiveness of our proposed DCPH framework, which significantly outperforms the state-of-the-art deep hashing methods.},
  archive      = {J_NEUCOM},
  author       = {Qibing Qin and Hong Wang and Wenfeng Zhang and Lei Huang and Jie Nie},
  doi          = {10.1016/j.neucom.2025.130014},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {130014},
  shortjournal = {Neurocomputing},
  title        = {Deep consistent penalizing hashing with noise-robust representation for large-scale image retrieval},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain-wise knowledge decoupling for personalized federated
learning via radon transform. <em>NEUCOM</em>, <em>635</em>, 130013. (<a
href="https://doi.org/10.1016/j.neucom.2025.130013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized federated learning (pFL) customizes local models to address heterogeneous data across clients. One prominent research direction in pFL is model decoupling, where the knowledge of a global model is selectively utilized to assist local model personalization. Prior studies primarily use decoupled global-model parameters to convey this selected knowledge. However, due to the task-related knowledge-mixing nature of deep learning models, using these parameters may introduce irrelevant knowledge to specific clients, impeding personalization. To address this, we propose a domain-wise knowledge decoupling approach (pFedDKD), which decouples global-model knowledge into diverse projection segments in the representation space, meeting the specific needs of clients on heterogeneous local domains. A Radon transform-based method is provided to facilitate this decoupling, enabling clients to extract relevant knowledge segments for personalization. Besides, we provide a distillation-based back-projection learning method to fuse local-model knowledge into the global model, ensuring the updated global-model knowledge remains decouplable by projection. A theoretical analysis confirms that our approach improves generalization. Extensive experiments on four datasets demonstrate that pFedDKD consistently outperforms eleven state-of-the-art baselines, achieving an average improvement of 1.21% in test accuracy over the best-performing baseline.},
  archive      = {J_NEUCOM},
  author       = {Zihao Lu and Junli Wang and Changjun Jiang},
  doi          = {10.1016/j.neucom.2025.130013},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {130013},
  shortjournal = {Neurocomputing},
  title        = {Domain-wise knowledge decoupling for personalized federated learning via radon transform},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiobjective backbone network architecture search based on
transfer learning in steel defect detection. <em>NEUCOM</em>,
<em>635</em>, 130012. (<a
href="https://doi.org/10.1016/j.neucom.2025.130012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, steel defect detection methods based on deep learning have been widely used. However, due to the shape specificity of steel defects and data scarcity, using existing convolutional neural network architectures for training requires significant expertise and time to fine-tune the hyperparameters. Transfer learning effectively tackles the challenges of data scarcity or limited computing resources by transferring domain knowledge from source tasks to related target tasks, reducing the resource consumption of model training from scratch. In this paper, we propose a transfer learning-based multiobjective backbone network architecture search method (TMBNAS). First, TMBNAS formulates defect detection network search as a multiobjective problem while optimizing its detection accuracy and model complexity. Second, an effective variable-length encoding strategy is designed to represent different building blocks and unpredictable optimal depths in convolutional neural networks, and targeted improvements are made to the crossover and mutation operators. For the specificity of the steel defect detection task, a transfer learning strategy based on similar knowledge is used to transfer the architecture and weight parameters obtained from the search in the source task to the target task, and adjust and optimize them. Finally, a dynamic adjustment mechanism based on actual constraints is designed during the search process to gradually approximate the optimal non-dominated solution set with higher detection accuracy without losing its population diversity. The proposed method is tested on the continuous casting slab and workpiece defect datasets. The experimental results show that the model searched by the proposed method can achieve better detection performance compared with manually designed deep learning algorithms and classical network architecture search methods.},
  archive      = {J_NEUCOM},
  author       = {Tianchen Zhao and Xianpeng Wang and Xiangman Song},
  doi          = {10.1016/j.neucom.2025.130012},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {130012},
  shortjournal = {Neurocomputing},
  title        = {Multiobjective backbone network architecture search based on transfer learning in steel defect detection},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pool-mamba: Pooling state space model for low-light image
enhancement. <em>NEUCOM</em>, <em>635</em>, 130005. (<a
href="https://doi.org/10.1016/j.neucom.2025.130005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mamba, with its advantages in long-distance modeling and computational efficiency, has been promptly applied in low-light image enhancement (LLIE). Nevertheless, Mamba faces two key issues when processing low-light images: (1) overexposure in scenes with uneven illumination due to the lack of multi-scale modeling; (2) insufficient local detail recovery, as its sequential operation weakens the perception of local lighting changes. To alleviate these problems, we propose a Pooling State Space Model (Pool-Mamba) by integrating the state space model with pooling techniques. First, we devise the Pyramid-pooling Mamba (PMamba) module, which leverages pyramid pooling to capture multi-scale information, effectively mitigating uneven exposure under varying lighting conditions. Next, the Axis-pooling Mamba (AMamba) module is proposed to model local correlations along specific spatial dimensions (height and width), generating more refined local representations and enhancing the model’s ability to adapt to local lighting variations and intricate details. Finally, we incorporate a Dual Gated Enhancement Module (DGEM) to strengthen the channel correlations between PMamba and AMamba, facilitating the integration of multi-scale and local features. Benchmark assessments demonstrate that Pool-Mamba surpasses current state-of-the-art (SOTA) methods, achieving superior quantitative evaluations and less distorted visual results.},
  archive      = {J_NEUCOM},
  author       = {Qiao Zhang and Mingwen Shao and Xinyuan Chen},
  doi          = {10.1016/j.neucom.2025.130005},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {130005},
  shortjournal = {Neurocomputing},
  title        = {Pool-mamba: Pooling state space model for low-light image enhancement},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MKGF: A multi-modal knowledge graph based RAG framework to
enhance LVLMs for medical visual question answering. <em>NEUCOM</em>,
<em>635</em>, 129999. (<a
href="https://doi.org/10.1016/j.neucom.2025.129999">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical visual question answering (MedVQA) is a challenging task that requires models to understand medical images and return accurate responses for the given questions. Most recent methods focus on transferring general-domain large vision–language models (LVLMs) to the medical domain by constructing medical instruction datasets and in-context learning. However, the performance of these methods are limited due to the hallucination issue of LVLMs. In addition, fine-tuning the abundant parameters of LVLMs on medical instruction datasets is high time and economic cost. Hence, we propose a MKGF framework that leverages a multi-modal medical knowledge graph (MMKG) to relieve the hallucination issue without fine-tuning the abundant parameters of LVLMs. Firstly, we employ a pre-trained text retriever to build question–knowledge relations on training set. Secondly, we train a multi-modal retriever with these relations. Finally, we use it to retrieve question-relevant knowledge and enhance the performance of LVLMs on the test set. To evaluate the effectiveness of MKGF, we conduct extensive experiments on two public datasets Slake and VQA-RAD. Our method improves the pre-trained SOTA LVLMs by 10.15% and 9.32%, respectively. The source codes are available at https://github.com/ehnal/MKGF .},
  archive      = {J_NEUCOM},
  author       = {Yinan Wu and Yuming Lu and Yan Zhou and Yifan Ding and Jingping Liu and Tong Ruan},
  doi          = {10.1016/j.neucom.2025.129999},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129999},
  shortjournal = {Neurocomputing},
  title        = {MKGF: A multi-modal knowledge graph based RAG framework to enhance LVLMs for medical visual question answering},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Label self-correction intelligent diagnosis method and
embedded system for axle box bearings of high-speed trains with noisy
labels. <em>NEUCOM</em>, <em>635</em>, 129998. (<a
href="https://doi.org/10.1016/j.neucom.2025.129998">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to annotation errors, delayed labeling, and noise interference, data label noise is a common issue in high-speed train datasets, leading to overfitting of existing intelligent diagnostic methods on noisy-label samples and a decline in the accuracy of fault diagnosis, which affects the correct assessment of high-speed train bearing health. To tackle this issue, this article presents an adaptive label self-correction intelligent diagnostic method. The method consists of three main parts: First, it employs dynamic thresholds and multi-network interactive training to separate clean from noisy labels. Second, it corrects noisy labels using classifiers trained on clean data, with two designed correction methods for high-accuracy label correction. Third, it retrains the model by reweighting loss to ensure that it fully captures information from noisy label data. Additionally, based on the proposed method, an AI microprocessor diagnosis system is developed for real-world health monitoring of axle box bearings. Both the method and the system have been validated through diagnostic cases of axle box bearings. Validation through diagnostic cases demonstrates that the method can train high-accuracy diagnostic models under label noise conditions and the system can rapidly diagnose data in real-time.},
  archive      = {J_NEUCOM},
  author       = {Yaning Li and Yang Gao and Bin Yang and Yaguo Lei and Xiang Li and Yue Shu and Ke Feng},
  doi          = {10.1016/j.neucom.2025.129998},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129998},
  shortjournal = {Neurocomputing},
  title        = {Label self-correction intelligent diagnosis method and embedded system for axle box bearings of high-speed trains with noisy labels},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SR-CIBN: Semantic relationship-based consistency and
inconsistency balancing network for multimodal fake news detection.
<em>NEUCOM</em>, <em>635</em>, 129997. (<a
href="https://doi.org/10.1016/j.neucom.2025.129997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fast dissemination of online information has facilitated the evolution of multimodal fake news, thereby rendering the trustworthiness of its content difficult to identify. Some existing studies, although capturing the consistency and inconsistency features between different modalities, neglect to dynamically balance these two types of features based on their contributions during the features fusion. Thus, we propose a S emantic R elationship-based C onsistency and I nconsistency B alancing N etwork for multimodal fake news detection (SR-CIBN). Specifically, the global features are thoroughly investigated by hierarchically penetrating and interacting between multimodal features that are aligned by contrastive learning at both the intra- and inter-modal views. Then, the global consistency and inconsistency features are obtained through the interaction between the selected key image patches features and the global features. Additionally, the fusion intensity of the global consistency and inconsistency features is adjusted based on the image–text matching degree, resulting in the final optimized features. Under the joint learning framework we proposed, confusion between semantically similar real and fake news is effectively avoided by training with triplet loss based on the image–text semantic relationship. Our model surpasses comparable approaches, as shown by comprehensive experiments on the Twitter and Weibo datasets.},
  archive      = {J_NEUCOM},
  author       = {Hongzhu Yu and Hongchen Wu and Xiaochang Fang and Meng Li and Huaxiang Zhang},
  doi          = {10.1016/j.neucom.2025.129997},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129997},
  shortjournal = {Neurocomputing},
  title        = {SR-CIBN: Semantic relationship-based consistency and inconsistency balancing network for multimodal fake news detection},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Memory-augmented prototypical meta-learning method for
bearing fault identification under few-sample conditions.
<em>NEUCOM</em>, <em>635</em>, 129996. (<a
href="https://doi.org/10.1016/j.neucom.2025.129996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent developments in deep learning have enhanced the performance of rolling bearing fault diagnosis. However, two challenges persist: 1) These models typically require large amounts of labeled data, which limits their effectiveness when such data is scarce; 2) The decision-making process of these models is often opaque, making it difficult to understand the key factors they focus on. In this paper, the memory-augmented prototypical meta-learning (MAPML) is proposed for few-shot fault identification. In MAPML, the dynamic prototype adjustment module is proposed to dynamically and adaptively refine class prototypes through the memory-augmented mechanism, enhancing the model’s ability to accurately differentiate between classes. Additionally, the multi-scale convolutional architecture is employed to extract hidden features from signals at multiple scales in parallel, providing comprehensive feature representation across different scales. This proposed method is verified through two datasets of bearings, demonstrating robust generalization capabilities across different working conditions. By introducing Gaussian white noise to simulate real industrial environments, the robustness and practicality of MAPML in handling noisy data are further substantiated. The interpretability analysis indicates that MAPML effectively captures impact characteristics in the time domain, as well as resonance bands and fault characteristic frequencies in the frequency domain.},
  archive      = {J_NEUCOM},
  author       = {Xianze Li and Zhitai Xing and Ling Xiang and Yang Chen and Aijun Hu},
  doi          = {10.1016/j.neucom.2025.129996},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129996},
  shortjournal = {Neurocomputing},
  title        = {Memory-augmented prototypical meta-learning method for bearing fault identification under few-sample conditions},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Few-shot SAR image classification via multiple prototypes
ensemble. <em>NEUCOM</em>, <em>635</em>, 129989. (<a
href="https://doi.org/10.1016/j.neucom.2025.129989">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synthetic aperture radar (SAR) image classification has benefited significantly from deep learning techniques, which excel at automatically learning semantic features from data. However, compared with optical remote sensing images, SAR images face a more pronounced sample limitation problem due to sparsely distributed training samples and complex backgrounds. As a result, the performance of data-driven SAR image classification significantly degrades due to overfitting, especially when deep learning algorithms operate under data scarcity. To address these challenges, we present a novel few-shot SAR classification approach using a multiple-prototype ensemble network within the meta-learning paradigm. Specifically, to better capture the scattering feature distribution and enhance intra-category aggregation in SAR images, multiple prototypes are learned to fully leverage the semantic information embedded in the limited support samples. Furthermore, we introduce a subspace discriminative loss to improve the representational power of the learned prototypes by ensuring consistency in SAR feature representation while maintaining inter-class divergence. Extensive experiments conducted on three real-world datasets demonstrate the superiority of the proposed method compared to several state-of-the-art approaches.},
  archive      = {J_NEUCOM},
  author       = {Zhiqiang Zhao and Yuhui Tong and Meng Jia and Yuan Qiu and Xiaofan Wang and Xinhong Hei},
  doi          = {10.1016/j.neucom.2025.129989},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129989},
  shortjournal = {Neurocomputing},
  title        = {Few-shot SAR image classification via multiple prototypes ensemble},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LSKN-MFIF: Large selective kernel network for multi-focus
image fusion. <em>NEUCOM</em>, <em>635</em>, 129984. (<a
href="https://doi.org/10.1016/j.neucom.2025.129984">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-focus image fusion (MFIF) is an image enhancement technique that compensates for the limited depth of field of optical lenses. It has broad application prospects across multiple disciplines such as digital photography, biomedical imaging, and machine vision, similar to other advanced visual tasks. This study proposes a large selective kernel network, referred to as LSKN-MFIF, which is designed to improve multi-focus image fusion. This network has the capability to dynamically adjust its extensive spatial receptive field, effectively expanding the receptive field and capturing multi-scale global information, fully extracting and integrating multi-scale context to better identify various focused regions in the image. More specifically, LSKN-MFIF extracts multi-scale global features through a large selective kernel module (LKSB) that decomposes large kernel convolutions, utilizes spatial feature selection for feature aggregation, and then enhances representation capability by extracting local information through a gated differential convolution block (GDCB), thereby generating accurate decision maps. Experimental results show that the proposed methodology surpasses current multi-focus image fusion techniques in terms of both subjective visual quality and objective performance metrics.},
  archive      = {J_NEUCOM},
  author       = {Hao Zhai and Guochao Zhang and Zhi Zeng and Zhendong Xu and Aiqing Fang},
  doi          = {10.1016/j.neucom.2025.129984},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129984},
  shortjournal = {Neurocomputing},
  title        = {LSKN-MFIF: Large selective kernel network for multi-focus image fusion},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Double-activation neural network for solving parabolic
equations with time delay. <em>NEUCOM</em>, <em>635</em>, 129978. (<a
href="https://doi.org/10.1016/j.neucom.2025.129978">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While physics-informed neural network (PINN) has shown promise in solving partial differential equations (PDEs), their performance is limited by the expressive capacity of standard neural network architectures, particularly when dealing with complex, nonlinear problems. To improve the nonlinear expressive capacity of the network and broaden the applications of PINN, we propose a double-activation neural network (DANN) for solving parabolic equations with time delay, where each neuron is equipped with two activation functions and a new parameter is introduced in one of the functions to form quadratic terms. To address the issue of low fitting accuracy caused by the discontinuity of solution’s derivative, a piecewise fitting approach is proposed by dividing the global solving domain into several subdomains according to the discontinuous points. The convergence of the loss function is proved. We conduct a series of numerical experiments to show the efficiency of the proposed DANN technique, including solving delay partial differential equations (DPDEs) with constant delay, time-dependent delay, and delay differential equations (DDEs) with state-dependent delay. The robustness of DANN is assessed by varying the number of training points, hidden layers, neurons per layer, and random seeds. We also evaluate the extended application of DANN by simulating a second-order rogue wave in the derivative nonlinear Schrödinger (DNLS) equation, to show its applicability beyond DPDEs.},
  archive      = {J_NEUCOM},
  author       = {Qiumei Huang and Qiao Zhu},
  doi          = {10.1016/j.neucom.2025.129978},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129978},
  shortjournal = {Neurocomputing},
  title        = {Double-activation neural network for solving parabolic equations with time delay},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy and synchronization of multifunctional loop neural
networks. <em>NEUCOM</em>, <em>635</em>, 129973. (<a
href="https://doi.org/10.1016/j.neucom.2025.129973">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multifunctional thermo-photoelectric neurons are newly proposed intelligent artificial neurons with expanded functionalities. They are capable of detecting and encoding multimodal thermo-photoelectric signals. This study constructs three loop neural networks by bridging photosensitive, thermosensitive, and thermo-photoelectric neurons with linear resistors, inductive coils, and memristors, respectively. These networks are designated as Voltage, Magnetic, and Memory Coupling Functional Networks (VCFN, MACFN, and MECFN). In the adaptive VCFN model, the system&#39;s diverse energy cannot be effectively balanced by voltage coupling, resulting in an inability to achieve a stable synchronization state. MACFN and MECFN models perform energy pumping and extraction among neurons, resulting in a self-organizing behavior. This behavior spontaneously adjusts the membrane sequences of neurons within the model, ultimately achieving a stable equilibrium of the system&#39;s intrinsic field energy. The acceleration of this process can be facilitated by an increase in the coupling gain ratio. The MECFN model quickly achieves phase synchronization, and due to its adaptive mechanism, the phase synchronization state is further stabilized. This indicates memristors can serve as bridges for communication and encoding between heterogeneous functional neural networks. The effects of chaotic currents on isolated neurons and models were also considered. High-intensity chaotic currents will cause resonance phenomena in neurons under single-peaking oscillation mode, exhibiting chaotic geometric characteristics but without changing their periodic characteristics. In neurons with multi-spiking oscillation modes, chaotic currents may induce extremely narrow chaotic windows. VCFN, MACFN, and MECFN models demonstrate good robustness in spike periodic modes but are more susceptible to external chaotic current interference in chaotic modes. Appropriate intensities of chaotic current stimulation can promote synchronization in models, while excessive intensities may suppress it. This research provides insights into the synchronization processes of multifunctional neural networks and the design of multimodal and high-robustness intelligent sensor systems, providing a theoretical foundation for advancements in artificial intelligence.},
  archive      = {J_NEUCOM},
  author       = {Zebang Cheng and Shu Zhou and Jiajun Jiang and Shunwei Yao and Lin Peng and Tingting Shi and Xiaolin Liu and Jia Lin},
  doi          = {10.1016/j.neucom.2025.129973},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129973},
  shortjournal = {Neurocomputing},
  title        = {Energy and synchronization of multifunctional loop neural networks},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Student behavior detection model based on multilevel
residual networks and hybrid attention mechanisms. <em>NEUCOM</em>,
<em>635</em>, 129965. (<a
href="https://doi.org/10.1016/j.neucom.2025.129965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately analyzing student behaviors allows for better evaluation of student engagement, which in turn can improve teaching quality. To address challenges such as multi-scale scenes, occluded targets, and subtle fine features in classroom environments, while also considering model implementability, we propose an efficient student behavior detection model, RSAY. This model leverages multi-scale information extraction and a hybrid attention mechanism to support teaching. Both the backbone and feature fusion networks of the model integrate our designed Rep_SC_Atten module, which incorporates our novel multi-level residual network architecture and a lightweight hybrid attention mechanism. This hybrid architecture enhances the model’s sensitivity and ability to extract multi-scale information, while ensuring effective extraction of fine-grained features via the attention mechanism. Additionally, the DDetect strategy is introduced in the detection head to reduce model size without sacrificing accuracy. We evaluated our model using the SCB-Dataset and a custom student behavior dataset, demonstrating a 6.3% improvement in accuracy over the baseline model.},
  archive      = {J_NEUCOM},
  author       = {Wenbin Lu and Songyan Liu and Boyang Ding and Peng Chen and Fangpeng Lu},
  doi          = {10.1016/j.neucom.2025.129965},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129965},
  shortjournal = {Neurocomputing},
  title        = {Student behavior detection model based on multilevel residual networks and hybrid attention mechanisms},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reliable ℓ2−ℓ∞ state estimation for delayed neural networks
under weighted try-one-discard protocol. <em>NEUCOM</em>, <em>635</em>,
129923. (<a href="https://doi.org/10.1016/j.neucom.2025.129923">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the problem of reliable ℓ 2 - ℓ ∞ state estimation is addressed for discrete-time artificial neural networks with switched time-delays under weighted try-once-discard (WTOD) protocol. To mitigate data congestion and transmission burdens, the WTOD protocol is implemented in the transmission channels to optimize data communication, where the transmission priority is dynamically determined based on mission importance. A Bernoulli-distributed stochastic variable with known statistical properties is introduced to model the switching behavior between the presence and absence of time-delays and a failure matrix is constructed to characterize potential failures affecting the received measurement data. The primary objective of this paper is to develop a state estimator that effectively performs the desired estimation task by thoroughly accounting for the combined effects of switched time-delays and the WTOD protocol. Specifically, by utilizing Lyapunov theory and matrix inequality techniques, the estimator parameters are meticulously derived to ensure exponentially mean-square stability and ℓ 2 - ℓ ∞ performance. Finally, the efficacy and validity of the proposed algorithm are demonstrated through an illustrative example.},
  archive      = {J_NEUCOM},
  author       = {Yuqiang Luo and Siyu Guo and Di Zhao and Hong Lin},
  doi          = {10.1016/j.neucom.2025.129923},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129923},
  shortjournal = {Neurocomputing},
  title        = {Reliable ℓ2−ℓ∞ state estimation for delayed neural networks under weighted try-one-discard protocol},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-paced learning for anchor-based multi-view clustering:
A progressive approach. <em>NEUCOM</em>, <em>635</em>, 129921. (<a
href="https://doi.org/10.1016/j.neucom.2025.129921">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of multi-view clustering (MVC), the surge in data has led to a significant increase in both the number of samples and the complexity of feature spaces, posing considerable challenges to the domain. Traditional anchor-based clustering methods effectively reduce the time and space complexity of algorithms by selecting representative samples to reconstruct similarity matrices. However, these methods are susceptible to the influence of low-quality anchors. To address this issue, we propose a novel self-paced learning for anchor-based MVC method, termed MSPA. This approach begins by constructing an anchor alternative pool, a novel strategy for selecting anchors that captures both intra-view and inter-view structural information. Subsequently, the concept of self-paced learning (SPL) is employed to progressively integrate anchors of varying quality into the model learning process, thereby constructing an anchor graph. Finally, the K-Means algorithm is applied to the resulting feature matrix to infer the final clustering results. Comprehensive comparative analyses conducted on eight benchmark datasets demonstrate that our proposed method outperforms existing state-of-the-art MVC algorithms in terms of efficiency.},
  archive      = {J_NEUCOM},
  author       = {Xia Ji and Xinran Cheng and Peng Zhou},
  doi          = {10.1016/j.neucom.2025.129921},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129921},
  shortjournal = {Neurocomputing},
  title        = {Self-paced learning for anchor-based multi-view clustering: A progressive approach},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LGKGR: A knowledge graph reasoning model using LLMs
augmented GNNs. <em>NEUCOM</em>, <em>635</em>, 129919. (<a
href="https://doi.org/10.1016/j.neucom.2025.129919">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph reasoning (KGR) aims to infer new factual knowledge based on existing structured factual data, and plays a vital role in various applications. Graph neural networks (GNNs)-based methods have garnered attention due to their exceptional capabilities in learning graph structures. However, they cannot effectively leverage rich text semantics within KG for reasoning. Given the remarkable semantic understanding capabilities of large language models (LLMs), this paper proposes a novel KGR model using LLMs augmented GNNs (LGKGR), which aims to utilize LLMs to enhance the graph structure learning of GNNs. Each round of reasoning includes three stages: path search, path pruning, and path decision. The first stage adopts an incremental path search strategy to identify adjacent entities of current query entity and extract features. The second stage adopts GNNs as a pruning tool to filter out semantically irrelevant reasoning paths. The third stage exploits LLMs for semantic analysis of candidate reasoning paths, and then selects the most possible reasoning paths. In the end, LLMs are further exploited to analyze the semantic information of reasoning paths and generate final reasoning results. Experimental results on public datasets demonstrate that the proposed method achieves an average improvement of 2.1% in the MRR metric and 2.68% in the Hits@1 metric compared to existing SOTA methods. Explainable reasoning justifications are also generated during the reasoning process.},
  archive      = {J_NEUCOM},
  author       = {Yuanming Zhang and Wenbo Zheng and Jiacheng Huang and Gang Xiao},
  doi          = {10.1016/j.neucom.2025.129919},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129919},
  shortjournal = {Neurocomputing},
  title        = {LGKGR: A knowledge graph reasoning model using LLMs augmented GNNs},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SARFormer: Segmenting anything guided transformer for
semantic segmentation. <em>NEUCOM</em>, <em>635</em>, 129915. (<a
href="https://doi.org/10.1016/j.neucom.2025.129915">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation plays a crucial role in robotic systems. Despite advances, we find that current state-of-the-art methods are hard to apply in practice due to their weak generalization ability. Especially, diffusion-based segmentation methods struggle with over-reliance on noisy Ground Truth (GT) annotations, which are corrupted with noise and directly fed into the model’s forward propagation process during training, limiting the model’s ability to generalize. While the Segment Anything Model (SAM) excels at instance segmentation, it faces challenges in controlling granularity and lacks semantic information. To address these issues, we propose SARFormer, a semantic segmentation algorithm guided by SAM. Unlike conventional methods, SARFormer uses GT solely for supervision and replaces noisy GT with SAM guidance, enabling better generalization. The key innovations include a region-based SAM optimizer to refine granularity and a feature aggregation method for enhanced deep feature extraction. Experimental results show SARFormer achieves competitive accuracy, demonstrating the effectiveness of SAM in improving segmentation performance},
  archive      = {J_NEUCOM},
  author       = {Lixin Zhang and Wenteng Huang and Bin Fan},
  doi          = {10.1016/j.neucom.2025.129915},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129915},
  shortjournal = {Neurocomputing},
  title        = {SARFormer: Segmenting anything guided transformer for semantic segmentation},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DACFusion: Dual asymmetric cross-attention guided feature
fusion for multispectral object detection. <em>NEUCOM</em>,
<em>635</em>, 129913. (<a
href="https://doi.org/10.1016/j.neucom.2025.129913">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective fusion of unique features from different spectra plays a crucial role in multispectral object detection. Recent research has focused on transplanting advanced methods from other multimodal fusion fields to multispectral object detection tasks. These fusion methods focus on the fusion of features and ignore the spatial correspondence between multispectral images. This lack of correspondence in turn limits the full utilization of the complementarities between the different modalities, which affects the accuracy of object detection. To address this problem, we creatively propose a dual asymmetric cross-attention multispectral fusion (DACFusion) method, which is able to process features interactively based on the positional correspondence between two spectra, and then asymmetrically fuses the multispectral data according to the characteristics of each spectrum to take advantage of their complementary strengths. Meanwhile, we introduce a large selective kernel network to expand the receptive field for object detection, which further improves the detection accuracy. Experimental results on the VEDAI and LLVIP datasets validate the significant performance advantages of our proposed method and show its applicability to a variety of practical application scenarios. Code will be available at https://github.com/wood-fish/DACFusion .},
  archive      = {J_NEUCOM},
  author       = {Jingchen Qian and Baiyou Qiao and Yuekai Zhang and Tongyan Liu and Shuo Wang and Gang Wu and Donghong Han},
  doi          = {10.1016/j.neucom.2025.129913},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129913},
  shortjournal = {Neurocomputing},
  title        = {DACFusion: Dual asymmetric cross-attention guided feature fusion for multispectral object detection},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From separation to fusion: Screening-assisted bilevel
collaborative evolutionary optimization for railway freight allocation.
<em>NEUCOM</em>, <em>635</em>, 129910. (<a
href="https://doi.org/10.1016/j.neucom.2025.129910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient freight space allocation and stowage planning are critical for optimizing transportation efficiency and minimizing operational costs in railway transportation systems of large-scale enterprises. Traditional methods typically handle freight space allocation and stowage decisions in isolation or by simply layering these processes, leading to suboptimal results in terms of transportation efficiency and operational costs. To address this issue, this paper proposes a novel screening-assisted bilevel collaborative evolutionary optimization (Sa-BCEO) algorithm to explore and fusion the interdependencies between freight space allocation and stowage problems, thereby improving transportation efficiency. First, a screening-assisted mechanism (SAM) is designed to alleviate the complexity of the nested structure of bilevel optimization. This mechanism narrows the search space by retaining individuals with higher potential in the upper-level optimization, thereby enhancing efficiency in solving the lower-level optimization problem. Then, a bilevel framework is constructed to optimize the freight allocation and stowage. The effectiveness of the Sa-BCEO algorithm is validated through extensive experiments on a real-world enterprise dataset and two random datasets. Extensive results demonstrate significant improvements in transportation efficiency and cost reduction compared to traditional optimization methods.},
  archive      = {J_NEUCOM},
  author       = {Yiyin Tang and Yalin Wang and Chenliang Liu and Yong Wang and Weihua Gui},
  doi          = {10.1016/j.neucom.2025.129910},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129910},
  shortjournal = {Neurocomputing},
  title        = {From separation to fusion: Screening-assisted bilevel collaborative evolutionary optimization for railway freight allocation},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RA2SP: Transform readability assessment to sequence
prediction with a loss function incorporating penalty mechanism.
<em>NEUCOM</em>, <em>635</em>, 129909. (<a
href="https://doi.org/10.1016/j.neucom.2025.129909">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of text readability assessment, traditional methods often rely on complex linguistic feature engineering, which increases the complexity of feature extraction and analysis while not necessarily improving model performance. To address these challenges, this work proposes a novel sequence prediction framework named RA2SP, which transforms the text readability classification task into a sequence prediction task. By introducing a penalty mechanism in the loss function, RA2SP reduces the reliance on burdensome linguistic feature engineering. The framework solely depends on deep features extracted from large pre-trained language models as input. Experimental results across various public datasets demonstrate that RA2SP achieves state-of-the-art or competitive performance across various evaluation metrics compared to existing baseline models. Additionally, this work provides a theoretical analysis of the role of the proposed penalty mechanism during model training, offering theoretical support and validating its effectiveness through experimental results. Finally, the potential applicability and superiority of the RA2SP framework are showcased in other text classification tasks, highlighting its adaptability and scalability.},
  archive      = {J_NEUCOM},
  author       = {Yijun Chen and Yurui Zheng and Jianhui Xu and Shaohong Zhang},
  doi          = {10.1016/j.neucom.2025.129909},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129909},
  shortjournal = {Neurocomputing},
  title        = {RA2SP: Transform readability assessment to sequence prediction with a loss function incorporating penalty mechanism},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Handling language prior and compositional reasoning issues
in visual question answering system. <em>NEUCOM</em>, <em>635</em>,
129906. (<a href="https://doi.org/10.1016/j.neucom.2025.129906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual Question Answering (VQA) models often suffer from language bias, favoring common but incorrect answers, and struggle with compositional reasoning in complex queries. This paper proposes a unified approach using a multimodal large language model enhanced with adaptive prompts designed for specific tasks. Our method directly addresses these issues by reducing language bias and improving compositional reasoning. Extensive evaluations on benchmark datasets, including VQA v2.0, VQACP, TDIUC, GQA, Visual7 W, TextVQA, and STVQA show that our approach outperforms state-of-the-art models, achieving accuracy improvements of 8% to 9%. These results demonstrate the effectiveness of our method in enhancing VQA accuracy, making it a significant advancement for more reliable and robust applications in real-world scenarios.},
  archive      = {J_NEUCOM},
  author       = {Souvik Chowdhury and Badal Soni},
  doi          = {10.1016/j.neucom.2025.129906},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129906},
  shortjournal = {Neurocomputing},
  title        = {Handling language prior and compositional reasoning issues in visual question answering system},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event-based optical flow: Method categorisation and review
of techniques that leverage deep learning. <em>NEUCOM</em>,
<em>635</em>, 129899. (<a
href="https://doi.org/10.1016/j.neucom.2025.129899">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing new convolutional neural network architectures and event-based camera representations could play a crucial role in autonomous navigation, pose estimation, and visual odometry applications. This study explores the potential of event cameras in optical flow estimation using convolutional neural networks. We provide a detailed description of the principles of operation and the software available for extracting and processing information from event cameras, along with the various event representation methods offered by this technology. Likewise, we identify four method categories to estimate optical flow using event cameras: gradient-based, frequency-based, correlation-based and neural network models. We report on these categories, including their latest developments, current status and challenges. We provide information on existing datasets and identify the appropriate dataset to evaluate deep learning-based optical flow estimation methods. We evaluate the accuracy of the implemented methods using the average endpoint error metric; meanwhile, the efficiency of the algorithms is evaluated as a function of execution time. Finally, we discuss research directions that promise future advances in this field.},
  archive      = {J_NEUCOM},
  author       = {Robert Guamán-Rivera and Jose Delpiano and Rodrigo Verschae},
  doi          = {10.1016/j.neucom.2025.129899},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129899},
  shortjournal = {Neurocomputing},
  title        = {Event-based optical flow: Method categorisation and review of techniques that leverage deep learning},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-level sparse network lasso: Locally sparse learning
with flexible sample clusters. <em>NEUCOM</em>, <em>635</em>, 129898.
(<a href="https://doi.org/10.1016/j.neucom.2025.129898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional learning usually assumes that all samples share the same global model, which fails to preserve critical local information for heterogeneous data. It can be tackled by detecting sample clusters and learning sample-specific models but is limited to sample-level clustering and sample-specific feature selection. In this paper, we propose multi-level sparse network lasso (MSN Lasso) for flexible local learning. It multiplicatively decomposes model parameters into two components: One component is for coarse-grained group-level, and another is for fine-grained entry-level. At the clustering stage, MSN Lasso simultaneously groups samples (group-level) and clusters specific features across samples (entry-level). At the feature selection stage, it enables both across-sample (group-level) and sample-specific (entry-level) feature selection. Theoretical analysis reveals a potential equivalence to a jointly regularized local model, which informs the development of an efficient algorithm. A divide-and-conquer optimization strategy is further introduced to enhance the algorithm’s efficiency. Extensive experiments across diverse datasets demonstrate that MSN Lasso outperforms existing methods and exhibits greater flexibility.},
  archive      = {J_NEUCOM},
  author       = {Luhuan Fei and Xinyi Wang and Jiankun Wang and Lu Sun and Yuyao Zhang},
  doi          = {10.1016/j.neucom.2025.129898},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129898},
  shortjournal = {Neurocomputing},
  title        = {Multi-level sparse network lasso: Locally sparse learning with flexible sample clusters},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancements in few-shot nested named entity recognition:
The efficacy of meta-learning convolutional approaches. <em>NEUCOM</em>,
<em>635</em>, 129893. (<a
href="https://doi.org/10.1016/j.neucom.2025.129893">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot Named Entity Recognition (NER) involves the identification of new entities using a limited amount of labeled data, which may contain nested entities. Currently, mainstream few-shot NER methods are not designed to handle nested entities. This study introduces a novel span-based meta-learning framework that uses meta-learning convolution to address the challenges of few-shot nested NER. Our proposed method, called M eta-Learning C onvolution for F ew- S hot N ested NER ( MCFSN ), is the first to integrate meta-learning with convolutional neural networks, effectively handling nested entities with limited training examples. This study presents a two-stage processing approach: extracting span features using CNN combined with the Biaffine attention mechanism, followed by entity span classification utilizing ProtoNet and the Biaffine classifier. Our experiments demonstrate consistently superior performance across three diverse language datasets, outperforming several competing baseline models in terms of F1 scores. Specifically, our approach achieves 6.9% F1 score improvement on the Genia, 5.2% F1 value improvement on the GermEval, and 4.5% F1 value enhancement on the NEREL, thus validating the effectiveness of our proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Shuaichen Zhu and Yang Yuan and Lin Shi and Shoukun Xu},
  doi          = {10.1016/j.neucom.2025.129893},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129893},
  shortjournal = {Neurocomputing},
  title        = {Advancements in few-shot nested named entity recognition: The efficacy of meta-learning convolutional approaches},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DCMVC: Dual contrastive multi-view clustering.
<em>NEUCOM</em>, <em>635</em>, 129889. (<a
href="https://doi.org/10.1016/j.neucom.2025.129889">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering, which aims to divide data into different categories that are unsupervised in respect to information from different views, plays an important role in the field of computer vision. Contrastive learning is widely used in deep multi-view clustering methods to learn more discriminative representations. However, most existing multi-view clustering methods based on contrastive learning use only a single positive sample and do not fully utilize the category information in the learning process. To address the above issues, we propose a novel dual contrastive multi-view clustering (DCMVC) method, which uses pseudo-labels to refine the embedded features to make them more suitable for clustering tasks. Specifically, an inter-view correlation contrastive module is designed to learn more compact clustering assignments through a shared clustering prediction layer. Then, on the basis of the clustering predictions, we propose an intra-view consistency contrastive module, which dynamically selects the samples with the same pseudo label as positive samples and sets the other samples as negative samples to construct contrastive learning. The proposed model can alleviate the constraints of a single positive sample on contrastive learning by fully considering the latent category information to regularize the representation structure. Extensive experiments conducted on nine real datasets demonstrate the superiority of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Pengyuan Li and Dongxia Chang and Zisen Kong and Yiming Wang and Yao Zhao},
  doi          = {10.1016/j.neucom.2025.129889},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129889},
  shortjournal = {Neurocomputing},
  title        = {DCMVC: Dual contrastive multi-view clustering},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MAD-DGTD: Multivariate time series anomaly detection based
on dynamic graph structure learning with time delay. <em>NEUCOM</em>,
<em>635</em>, 129887. (<a
href="https://doi.org/10.1016/j.neucom.2025.129887">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection of multivariate time series data is extremely important in the industrial operation maintenance of Internet of Things (IoT). Researchers have found that the relationship between multiple sensors can be modeled as graph structure, and most researchers expresses this relationship by learning static graph structures which only contains the information of single modal. However, in actual IoT, the relationship between sensors will change with the changes of operating conditions, and this fixed graph structure cannot capture the relationship between sensors when working mode changes. To compensate the shortage of static graph, we propose a Multivariate time series Anomaly Detection framework based on Dynamic Graph learning with Time Delay (MAD-DGTD). Firstly, time-delay dynamic graph learning module (TDDG) is proposed to learn the changed mutual relationship between sensors over time and model it as a dynamic graph structure. In TDDG, a delay impact learning mechanism was designed to reconfigure the similarity calculation of node embeddings, which is designed to handle the temporal asynchrony of interactions between sensors in IoT. Secondly, we designed a stacked time dimension information extraction module (TDIE) and graph convolution information propagation module (GCIP) to capture information of different fine-grained sizes through multi-scale feature extraction. Finally, experimental research on three real-world datasets shows that our method outperforms the existing 10 competitive baselines in terms of overall performance.},
  archive      = {J_NEUCOM},
  author       = {Kang Wang and Jun Kong and Meicheng Zhang and Min Jiang and Tianshan Liu},
  doi          = {10.1016/j.neucom.2025.129887},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129887},
  shortjournal = {Neurocomputing},
  title        = {MAD-DGTD: Multivariate time series anomaly detection based on dynamic graph structure learning with time delay},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint subspace learning and subspace clustering based
unsupervised feature selection. <em>NEUCOM</em>, <em>635</em>, 129885.
(<a href="https://doi.org/10.1016/j.neucom.2025.129885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised feature selection (UFS) has become a focal point of extensive research due to its ability to reduce the dimensionality of unlabeled data. Currently, many UFS methods based on subspace learning embed multiple graph regularization terms to preserve the local similarity structure of samples or features and rarely consider exploring global structure simultaneously, such as the self-representation structure between features and the potential clustering structure of samples. We propose a novel UFS model based on subspace learning and subspace orthogonal basis clustering (JSLSC) to address this problem. First, through robust subspace learning, JSLSC explores the self-representation information between the selected features and the original feature space. Features’ local and global structures are learned through feature selection and self-representation structure learning. Secondly, orthogonal basis clustering is introduced to learn the potential clustering structure in the low-dimensional sample space, thus enabling subspace clustering. Thirdly, hard-constrained graph structure learning is introduced to adaptively maintain the local structural consistency between low-dimensional samples and original samples. Finally, an optimization algorithm and convergence proof are proposed, and the superiority of the JSLSC is demonstrated through comparative experiments on nine real datasets.},
  archive      = {J_NEUCOM},
  author       = {Zijian Xiao and Hongmei Chen and Yong Mi and Chuan Luo and Shi-Jinn Horng and Tianrui Li},
  doi          = {10.1016/j.neucom.2025.129885},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129885},
  shortjournal = {Neurocomputing},
  title        = {Joint subspace learning and subspace clustering based unsupervised feature selection},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The consistency analysis of gradient learning under
independent covariate shift. <em>NEUCOM</em>, <em>635</em>, 129883. (<a
href="https://doi.org/10.1016/j.neucom.2025.129883">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many issues have drawn significant attention to gradient learning (GL), which seeks to approximate the gradient of the target function. Despite rapid progress, the existing methods on GL are almost based on the strict assumption that the samples are independent and identically distributed (i.i.d.) drawn. In this paper, we go beyond the classical i.i.d. framework and propose to investigate the GL under the independent covariate shift (i.c.s.) assumption. To be specific, we establish the upper bound of generalization error from the viewpoint of function approximation and show its theoretical consistency under a mild regularity condition on the bounded density-ratio, which generalizes the classical GL results under the i.i.d. framework. In addition, we have discovered a real-world example which meets the i.c.s. assumption. The numerical studies on the synthetic and real-world examples validate the effectiveness of proposed approach on the i.c.s. setting.},
  archive      = {J_NEUCOM},
  author       = {Liyuan Liu and Hong Chen and Chi Xiao and Weifu Li},
  doi          = {10.1016/j.neucom.2025.129883},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129883},
  shortjournal = {Neurocomputing},
  title        = {The consistency analysis of gradient learning under independent covariate shift},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EKCA-cap: Improving dense captioning via external knowledge
and context awareness. <em>NEUCOM</em>, <em>635</em>, 129867. (<a
href="https://doi.org/10.1016/j.neucom.2025.129867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dense captioning is a image-to-text task that aims to locate the key semantic areas of an image and describe them in natural language. Previous researches have made great progresses, but this task remains challenging as it often generates ambiguous sentences due to weak perception of the attributes and semantic relationships of visual objects ( e.g. , holding something green in hands rather than cutting green vegetables). Furthermore, there is a lack of coherence between the sentences generated by each Region of Interest (RoI) and the context in the input image. Due to dense captioning being a multimodal task, the lack of interaction between text and visual modalities in the network can also lead to low accuracy. To tackle these challenges, we propose a dense captioning architecture with External Knowledge and Context Awareness, namely EKCA-Cap. Specifically, we construct a novel Common-Sense Knowledge Graph (CSKG) to provide attribute information of visual objects and semantic relationships with other visual cues. In addition, a Contextual Extractor (CE) is designed to extract contextual features of the target region from both spatial and semantic levels. Finally, a Dual-Stream Interactive Module (DSIM) is introduced to maximize the interaction between visual and text knowledge modalities. Extensive comparison and ablation experiments on Visual Genome (VG) and RefCOCOg datasets demonstrate the effectiveness of our method.},
  archive      = {J_NEUCOM},
  author       = {Zhenwei Zhu and Fengyu Zhou and Saike Huang and Teng Li},
  doi          = {10.1016/j.neucom.2025.129867},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129867},
  shortjournal = {Neurocomputing},
  title        = {EKCA-cap: Improving dense captioning via external knowledge and context awareness},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GSNet: A new small object attention based deep classifier
for presence of gun in complex scenes. <em>NEUCOM</em>, <em>635</em>,
129855. (<a href="https://doi.org/10.1016/j.neucom.2025.129855">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The motivation for focusing on weapon-based scene classification stems from the critical need to enhance public safety by enabling automated systems to quickly and accurately detect firearms in various environments. In contrast to common surveillance scenario classification based on intruders, weapon-based scenario classification often involves small weapons distributed throughout the scene or image. This requires more discriminative features and local semantics for effective classification. However, when deep convolutional neural networks (CNNs) are applied to scene classification, the loss of low- and mid-level features cannot be avoided. Furthermore, most existing networks tend to emphasize the global semantics of images. The low inter-class variability and high intra-class variability present specific challenges in weapon-based scene classification. To address these challenges, we propose a small object attention-based architecture in this work, with DenseNet serving as the backbone of our classification model. We modified the original DenseNet architecture to obtain more structured features. Additionally, we introduce a Small Object Attention (SAN) module after each dense block and an enhancement layer after each transition layer. Furthermore, we propose an enhanced classification layer in place of the traditional softmax layer, which helps retain relevant semantic features during classification. Consequently, the proposed classification model processes small patches of the image, preserving the relevant features of weapons. Experiments on six widely used benchmark datasets for weapon-based scenes demonstrate that our GSNet outperforms state-of-the-art methods by a significant margin while utilizing considerably fewer parameters. On average, the DenseNet model achieved an accuracy of 94.2%, whereas the proposed network attained an average accuracy of 98% across the six datasets.},
  archive      = {J_NEUCOM},
  author       = {Rajib Debnath and Kakali Das and Mrinal Kanti Bhowmik},
  doi          = {10.1016/j.neucom.2025.129855},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129855},
  shortjournal = {Neurocomputing},
  title        = {GSNet: A new small object attention based deep classifier for presence of gun in complex scenes},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on dynamic scene understanding using temporal
knowledge graphs: From scene knowledge representation to extrapolation.
<em>NEUCOM</em>, <em>635</em>, 129854. (<a
href="https://doi.org/10.1016/j.neucom.2025.129854">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic scene understanding is the process of extracting information from video, identifying and inferring entities and relations within the scene, with the aim of thoroughly analyzing complex scenes that evolve over time. This process leverages temporal knowledge graphs to achieve a deep and comprehensive understanding of dynamic environments and is widely applied in areas such as autonomous driving, surveillance, and video analysis. Initially, scene knowledge representation is explored as the foundational step in dynamic scene understanding, achieved through the generation of temporal knowledge graphs. These graphs are categorized based on temporal granularity. Temporal knowledge graphs are divided into multiple-frame dynamic graphs and single-frame dynamic graphs. The generation methods for multiple-frame dynamic graphs are categorized into fragment-based and sliding-window approaches, while single-frame dynamic graphs primarily utilize transformer-based methods. This section provides an overview of the generation models for temporal knowledge graphs. Subsequently, dynamic scenes are further analyzed using extrapolation methods, which are classified into entity-based and relation-based modeling approaches. Entity-based modeling methods mainly include temporal point processes and graph neural network techniques, while relation-based modeling focuses on reinforcement learning and meta-learning techniques. This section summarizes various existing extrapolation techniques within these categories. Finally, the paper discusses the challenges associated with temporal knowledge graphs and explores potential research directions, offering insights into future advancements in dynamic scene understanding.},
  archive      = {J_NEUCOM},
  author       = {Linnan Lu and Guannan Si and Xinyu Liang and Mingshen Li and Fengyu Zhou},
  doi          = {10.1016/j.neucom.2025.129854},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129854},
  shortjournal = {Neurocomputing},
  title        = {A survey on dynamic scene understanding using temporal knowledge graphs: From scene knowledge representation to extrapolation},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MFP-DETR: Marine UAV target detection based on multi-scale
fuzzy perception. <em>NEUCOM</em>, <em>635</em>, 129843. (<a
href="https://doi.org/10.1016/j.neucom.2025.129843">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An end-to-end object detection algorithm based on multi-scale fuzzy perception and feature enhancement, MFP-DETR, is proposed to solve the problem of image blur caused by the fast motion of Unmanned Aerial Vehicle (UAV) and pixel limitation of cameras in Unmanned Surface Vehicle (USV) images. Firstly, a learnable image mapping network — LPNet is designed to improve the representation of the target region and the quality of the input image. Secondly, the features of S3 and S4 and the features of S5 in the backbone Network were extracted, and they were input into the Squeeze and Excitation Network V2 (SENetV2) feature fusion module for feature fusion to enhance the detection ability of small targets. Finally, replace the Attention on the Intermediate Feature Interaction (AIFI) module in the Real-Time DEtection TRansformer (RT-DETR) with a Contextual Transformer(CoT) module. Context information is fully used to guide the learning of dynamic attention matrix and enhance the ability of global visual representation, to improve the accuracy of the model for different targets. The experimental results show that this method can enhance the fuzzy image effectively and detect the UAV accurately under background interference in the natural environment.},
  archive      = {J_NEUCOM},
  author       = {Ting Zou and Quanbo Ge and Yanjun Huang},
  doi          = {10.1016/j.neucom.2025.129843},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129843},
  shortjournal = {Neurocomputing},
  title        = {MFP-DETR: Marine UAV target detection based on multi-scale fuzzy perception},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RagNet3D: Learning distinguishable representation for pooled
grids in 3D object detection. <em>NEUCOM</em>, <em>635</em>, 129841. (<a
href="https://doi.org/10.1016/j.neucom.2025.129841">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D object detection plays a crucial role in autonomous driving. Previous two-stage 3D detectors have developed Grid-based Region-of-Interest (RoI) Pooling techniques, such as RoI-Grid Pooling and Voxel Pooling, both of which quantify RoI into grids. However, the grids are usually ambiguous since parts of them pertain to multiple RoIs that identify a single object. To address this issue, we propose a RoI-Aware Grids Pooling Network (RagNet3D), which introduces RoI-View context to create distinguishable grid representations. Specifically, we present a RoI-View Prediction module that predicts RoI-View context via the guidance of the distance between RoIs and objects. Meanwhile, we propose a Couple-View Fusion module that propagates the probabilistic distribution, calculated from the RoI-View context, into the RoI-irrelevant grid features for further box refinement. Extensive experiments on KITTI and Waymo Open Dataset show that our method achieves remarkable improvements against the baselines.},
  archive      = {J_NEUCOM},
  author       = {Jiaxin Chen and Yuehui Han and Zhiqiang Yan and Jianjun Qian and Jun Li and Jian Yang},
  doi          = {10.1016/j.neucom.2025.129841},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129841},
  shortjournal = {Neurocomputing},
  title        = {RagNet3D: Learning distinguishable representation for pooled grids in 3D object detection},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning for drone detection from images: A review
of techniques and challenges. <em>NEUCOM</em>, <em>635</em>, 129823. (<a
href="https://doi.org/10.1016/j.neucom.2025.129823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicles (UAVs), popularly known as drones, have revolutionized many sectors. In precision agriculture, they are used to effectively sprinkle water, fertilizers, and pesticides. In cinematography, UAVs snap aerial images that were difficult or impossible to obtain in the past. However, just as they can be used for good, they also have the potential for malicious uses. For example, drug smugglers use drones to evade border surveillance and push their goods across countries. Additionally, in the hands of militants, drones can be used to launch ballistics on targets, leading to the loss of lives and properties. Thus, researchers have recently focused on designing automated tools to detect friendly from unfriendly drones. One effective tool for such is Machine Learning (ML). This paper reviews works that use ML to detect drones from images. The images include visible light, infrared, and thermal. After studying the papers, we present the taxonomy and trends in the field. In addition, we also provide open research issues: the development of lightweight models, the use of synthetic data, the adoption of auto-annotation models, and the employment of transformer-based models.},
  archive      = {J_NEUCOM},
  author       = {Abubakar Bala and Ali H. Muqaibel and Naveed Iqbal and Mudassir Masood and Diego Oliva and Mujaheed Abdullahi},
  doi          = {10.1016/j.neucom.2025.129823},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129823},
  shortjournal = {Neurocomputing},
  title        = {Machine learning for drone detection from images: A review of techniques and challenges},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified concept-based system for local, global, and
misclassification explanations. <em>NEUCOM</em>, <em>635</em>, 129761.
(<a href="https://doi.org/10.1016/j.neucom.2025.129761">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explainability of Deep Neural Networks (DNNs) has garnered increasing attention in recent years. Of the various explainability approaches, concept-based techniques stand out for their ability to utilize human-meaningful concepts instead of focusing solely on individual pixels. However, there is a scarcity of methods that consistently provide both local and global explanations. Moreover, most of the methods have no offer to explain misclassification cases. Considering these challenges, we present a unified concept-based system for unsupervised learning of local and global concepts. Our primary objective is to uncover the intrinsic concepts underlying each data category by training a surrogate explainer network to estimate the concepts’ importance. Our experimental results substantiated the efficacy of the discovered concepts through diverse quantitative and qualitative assessments, encompassing faithfulness, completeness, and generality. Furthermore, our approach facilitates the explanation of both accurate and erroneous predictions, rendering it a valuable tool for comprehending the characteristics of the target objects of different classes.},
  archive      = {J_NEUCOM},
  author       = {Fatemeh Aghaeipoor and Dorsa Asgarian and Mohammad Sabokrou},
  doi          = {10.1016/j.neucom.2025.129761},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129761},
  shortjournal = {Neurocomputing},
  title        = {A unified concept-based system for local, global, and misclassification explanations},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural headline generation: A comprehensive survey.
<em>NEUCOM</em>, <em>635</em>, 129633. (<a
href="https://doi.org/10.1016/j.neucom.2025.129633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic headline generation (HG) is an important natural language processing (NLP) task that aims to obtain a highly compressed text snippet from a document, to exhibit the core concept. Traditional headline generation (HG) techniques predominantly employ text summarization methods to generate short texts, by selecting important information from original documents. In recent years, with the rapid development of deep learning techniques, research on HG has leaned toward neural network-based end-to-end modeling approaches. Pretrained schemes and large language models (LLMs) demonstrate superior capability in generating natural language texts, thereby promoting further exploration on HG studies. However, a quality gap remains between machine-generated and human-written texts, making the generation of attractive and faithful headlines worthy of in-depth research. Therefore, this study presents a review of the most recent technologies on HG, including methods, datasets, and evaluation strategies. Future research directions are outlined, which provide a valuable reference point for HG and other summarization tasks. A collection of reference papers and code sources is available at: https://github.com/xiaona-chang/HGSurvey .},
  archive      = {J_NEUCOM},
  author       = {Han Ren and Xiaona Chang and Xia Li},
  doi          = {10.1016/j.neucom.2025.129633},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129633},
  shortjournal = {Neurocomputing},
  title        = {Neural headline generation: A comprehensive survey},
  volume       = {635},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Masked graph autoencoder-based multi-agent dynamic
relational inference model for trajectory prediction. <em>NEUCOM</em>,
<em>634</em>, 129922. (<a
href="https://doi.org/10.1016/j.neucom.2025.129922">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic relational inference models uncover potential complex system interactions, enabling trajectory prediction and improving the interpretability of underlying system dynamics. However, the existing models cannot accurately infer the structural evolution trends and complete dynamic processes of temporal networks. Additionally, when uncertain noisy data are input, more serious graph noise problems, including redundant and noisy edges, occur, undermining the stability of interaction inference and reducing the accuracy of trajectory prediction. Therefore, a masked graph autoencoder-based multi-agent dynamic relational inference (MGAE-MDRI) trajectory prediction model is proposed herein. The mask reconstruction module is integrated into MDRI, where the partial edges of the interaction graph, representing multi-agent dynamic evolution, are masked through sampling. The reconstruction strategy leverages path and degree considerations to mitigate the impact of graph noise on the network topology. Furthermore, a graph attention network-based path sampler with a preference random walk is introduced, effectively combining network topology and node attribute features to construct a topologically weighted degree matrix and assign optimal mask sampling weights to neighboring nodes. Experiments conducted on four standard public datasets demonstrate that MGAE-MDRI outperforms the state-of-the-art models, achieving better trajectory prediction robustness and for complex multi-agent systems.},
  archive      = {J_NEUCOM},
  author       = {Fuyuan Zhao and Xiangang Cao and Jiangbin Zhao and Yong Duan and Xin Yang and Xinyuan Zhang},
  doi          = {10.1016/j.neucom.2025.129922},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129922},
  shortjournal = {Neurocomputing},
  title        = {Masked graph autoencoder-based multi-agent dynamic relational inference model for trajectory prediction},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Brain state model: A novel method to represent the
rhythmicity of object-specific selective attention from
magnetoencephalography data. <em>NEUCOM</em>, <em>634</em>, 129920. (<a
href="https://doi.org/10.1016/j.neucom.2025.129920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object-specific selective attention can be achieved either by simultaneously splitting attention to multiple objects, or by sequentially shifting spatial attention among objects. A growing body of research show that object-specific selective attention can be implemented using the second way and that the sequential movement of attention exhibits specific rhythmicity. However, the neurocomputing mechanisms underlying this phenomenon are still not fully understood. To clarify this issue, we conducted magnetoencephalography experiments on healthy participants and subsequently proposed a computational framework based on time-series decomposition and rhythmic analysis to delve into the neural mechanisms of object-specific selective attention. Our investigation reveals that the four single-object attention states are decodable on the level of magnetoencephalography (MEG) sensor signals. Furthermore, these states manifest dynamically and rhythmically during object-specific selective attention. These findings suggest that the attentional rhythm exhibited by neural activity during object-specific selective attention is fundamentally characterized by a set of basic attentional units. This research provides valuable information for future investigations into the brain model of object-specific selective attention.},
  archive      = {J_NEUCOM},
  author       = {Chunyu Liu and Xin-Yue Yang and Xueyuan Xu},
  doi          = {10.1016/j.neucom.2025.129920},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129920},
  shortjournal = {Neurocomputing},
  title        = {Brain state model: A novel method to represent the rhythmicity of object-specific selective attention from magnetoencephalography data},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GDoT: A gated dual domain transformer for enhanced MRI
off-resonance correction. <em>NEUCOM</em>, <em>634</em>, 129918. (<a
href="https://doi.org/10.1016/j.neucom.2025.129918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based MRI reconstruction methods have gained significant attention recently due to the need for accelerated MRI scans. However, existing deep learning-based methods for off-resonance correction rely on simple CNNs, resulting in suboptimal solutions. In this paper, we propose a gated dual domain transformer with gated spatial projection and gated frequency projection to effectively handle complex-valued MRI, as the first attempt to utilize transformer-based model for off-resonance correction. Additionally, we introduce a selective perceptual loss with a novel test-time translation-merger to reconstruct perceptually high-quality images without checkerboard artifacts. Experiments on both simulated and real off-resonance MRI datasets demonstrate the effectiveness of our approach. Furthermore, we also present ablation studies to determine the optimal design choices.},
  archive      = {J_NEUCOM},
  author       = {Jaesin Ahn and Heechul Jung},
  doi          = {10.1016/j.neucom.2025.129918},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129918},
  shortjournal = {Neurocomputing},
  title        = {GDoT: A gated dual domain transformer for enhanced MRI off-resonance correction},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving spatial-temporal PDEs with arbitrary boundary
conditions using physics-constrained convolutional recurrent neural
networks. <em>NEUCOM</em>, <em>634</em>, 129917. (<a
href="https://doi.org/10.1016/j.neucom.2025.129917">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inception of physics-constrained or physics-informed machine learning represents a paradigm shift, addressing the challenges associated with data scarcity and enhancing model interpretability. This innovative approach incorporates the fundamental laws of physics as constraints, guiding the training process of machine learning models. In this work, the physics-constrained convolutional recurrent neural network is further extended for solving spatial-temporal partial differential equations with arbitrary boundary conditions. Two notable advancements are introduced: the implementation of boundary conditions as soft constraints through finite difference-based differentiation, and the establishment of an adaptive weighting mechanism for the optimal allocation of weights to various losses. These enhancements significantly augment the network&#39;s ability to manage intricate boundary conditions and expedite the training process. The efficacy of the proposed model is validated through its application to two-dimensional phase transition, fluid dynamics, and reaction-diffusion problems, which are pivotal in materials modeling. Compared to traditional physics-constrained neural networks, the physics-constrained convolutional recurrent neural network demonstrates a tenfold increase in prediction accuracy within a similar computational budget. Moreover, the model&#39;s exceptional performance in extrapolating solutions for the Burgers&#39; equation underscores its utility. Therefore, this research establishes the physics-constrained recurrent neural network as a viable surrogate model for sophisticated spatial-temporal PDE systems, particularly beneficial in scenarios plagued by sparse and noisy datasets.},
  archive      = {J_NEUCOM},
  author       = {Guangfa Li and Yanglong Lu and Dehao Liu},
  doi          = {10.1016/j.neucom.2025.129917},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129917},
  shortjournal = {Neurocomputing},
  title        = {Solving spatial-temporal PDEs with arbitrary boundary conditions using physics-constrained convolutional recurrent neural networks},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DSQN: Robust path planning of mobile robot based on deep
spiking q-network. <em>NEUCOM</em>, <em>634</em>, 129916. (<a
href="https://doi.org/10.1016/j.neucom.2025.129916">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement of science and technology, the field of mobile robot applications continues to expand, with path planning emerging as a fundamental yet challenging task. While traditional path planning techniques have developed into a relatively complete theoretical system, their performance in uncertain environments remains a critical area of research. To address this, we propose a novel Deep Spiking Q-Network (DSQN) algorithm that significantly enhances path planning performance by leveraging the unique advantages of spiking neural networks (SNNs). Unlike classic Q-learning and its contemporary variants, the DSQN algorithm integrates global and local information simultaneously, resulting in superior overall performance. As the third generation of neural networks, SNNs offer unparalleled robustness and energy efficiency by mimicking biological neural systems. By introducing spiking neurons into the conventional Deep Q-learning (DQN) framework, the DSQN algorithm overcomes key challenges in deep reinforcement learning (DRL), such as limited robustness and high energy consumption. The DSQN training process incorporates both surrogate gradient learning (SGL) and ANN-to-SNN conversion techniques, with SGL demonstrating remarkable effectiveness in mobile robot path planning tasks. Experimental results validate the practicality and efficiency of DSQN, showcasing improved performance across diverse test scenarios compared to the original DQN algorithm. These findings highlight the potential of DSQN to advance path planning in complex and uncertain environments, establishing it as a robust and energy-efficient solution for mobile robotics.},
  archive      = {J_NEUCOM},
  author       = {Aakash Kumar and Lei Zhang and Hazrat Bilal and Shifeng Wang and Ali Muhammad Shaikh and Lu Bo and Avinash Rohra and Alisha Khalid},
  doi          = {10.1016/j.neucom.2025.129916},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129916},
  shortjournal = {Neurocomputing},
  title        = {DSQN: Robust path planning of mobile robot based on deep spiking Q-network},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Recent progress in digital twin-driven fault diagnosis of
rotating machinery: A comprehensive review. <em>NEUCOM</em>,
<em>634</em>, 129914. (<a
href="https://doi.org/10.1016/j.neucom.2025.129914">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of the Internet of Things (IoT) and industrial automation has propelled diagnostics into the age of intelligence and digitization. Equipment fault diagnosis is predicted to shift from &quot;preventive&quot; to &quot;predictive&quot; through digital twin (DT) technology, which creates a virtual mirror of the physical entity and simulates its operating state in a genuine operating environment. The operation, development history, and current state of application of DT technology are investigated through a literature review, highlighting the technology&#39;s enormous promise in intelligent fault diagnostics. Then, from the four fields of aerospace, transportation, industrial machinery, and energy equipment, the current status of domestic and international research and the latest research developments on the application of DT technology to implement intelligent fault diagnosis (IFD) of equipment are reviewed. On this basis, the limitations of the current application of DT technology in the field of fault diagnosis are analyzed, and the challenges and development trends of the future application of DT technology in the implementation of IFD are discussed and pointed out, providing a clear direction for intelligent fault diagnosis of machinery.},
  archive      = {J_NEUCOM},
  author       = {Pengbo Zhang and Renxiang Chen and Lixia Yang and Ye Zou and Liang Gao},
  doi          = {10.1016/j.neucom.2025.129914},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129914},
  shortjournal = {Neurocomputing},
  title        = {Recent progress in digital twin-driven fault diagnosis of rotating machinery: A comprehensive review},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid safe reinforcement learning: Tackling distribution
shift and outliers with the student-t’s process. <em>NEUCOM</em>,
<em>634</em>, 129912. (<a
href="https://doi.org/10.1016/j.neucom.2025.129912">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Safe reinforcement learning (SRL) aims to optimize control policies that maximize long-term reward, while adhering to safety constraints. SRL has many real-world applications such as, autonomous vehicles, industrial robotics, and healthcare. Recent advances in offline reinforcement learning (RL) — where agents learn policies from static datasets without interacting with the environment — have made it a promising approach to derive safe control policies. However, offline RL faces significant challenges, such as covariate shift and outliers in the data, which can lead to suboptimal policies. Similarly, online SRL, which derives safe policies through real-time environment interaction, struggles with outliers and often relies on unrealistic regularity assumptions, limiting its practicality. This paper addresses these challenges by proposing a hybrid-offline–online approach. First, prior knowledge from offline learning guides online exploration. Then, during online learning, we replace the popular Gaussian Process (GP) with the Student-t’s Process (TP) to enhance robustness to covariate shift and outliers.},
  archive      = {J_NEUCOM},
  author       = {Xavier Hickman and Yang Lu and Daniel Prince},
  doi          = {10.1016/j.neucom.2025.129912},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129912},
  shortjournal = {Neurocomputing},
  title        = {Hybrid safe reinforcement learning: Tackling distribution shift and outliers with the student-t’s process},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient motor imagery electroencephalogram classification
via cross tensor coupling decomposition based on augmented covariance
networks. <em>NEUCOM</em>, <em>634</em>, 129911. (<a
href="https://doi.org/10.1016/j.neucom.2025.129911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A major challenge in fully harnessing the potential of motor imagery-based brain-computer interfaces (MI-BCIs) is the accurate classification of MI electroencephalography (MI-EEG) signals. Traditional methods of analyzing MI-EEG signals, such as spatial pattern analysis, focus solely on the average linear correlation within a specific time frame of the signals. To address these limitations, we introduce an effective classification approach named &quot;Cross Tensor Coupling Decomposition (CTCD) based on Augmented Covariance Networks (ACNs)&quot;. Based on a specific embedding of the original system, we introduce the ACN, which can be conceptualized as a standard covariance network computed within a high-dimensional space. It not only integrates the spatiotemporal characteristics of the signals but also enhances the representation of nonlinear information. By constructing ACN tensors and applying CTCD, we rapidly and accurately extract multidimensional deep features from different categories of MI tasks, significantly enhancing decoding accuracy. Validating on public datasets, we achieved an average accuracy of 91.75 % ± 3.25 % on Dataset 1 and 85.86 % ± 7.93 % on Dataset 2 in subject-independent binary classification experiments, and for cross-subject binary classification experiments, we obtained an average accuracy of 93.91 % ± 8.71 % on Dataset 1 and 84.36 % ± 16.63 % on Dataset 2. These results highlight the robustness and superiority of our approach. Furthermore, our method enables rapid decoding and real-time feedback, enhancing the practical application of MI-BCIs.},
  archive      = {J_NEUCOM},
  author       = {Hechong Su and Jieren Xie and Zengyao Yang and Yuncheng Ge and Jingya Fu and Chengxi Xie and Kai Zhang and Xinyi Hu and Sicong Zhang and Guanghua Xu},
  doi          = {10.1016/j.neucom.2025.129911},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129911},
  shortjournal = {Neurocomputing},
  title        = {Efficient motor imagery electroencephalogram classification via cross tensor coupling decomposition based on augmented covariance networks},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single-shot phase-shifting composition fringe projection
profilometry by multi-attention fringe restoration network.
<em>NEUCOM</em>, <em>634</em>, 129908. (<a
href="https://doi.org/10.1016/j.neucom.2025.129908">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D measurement techniques have permeated sectors like intelligent manufacturing and online inspection, demanding higher real-time performance in industrial applications. Recently, deep-learning-based profilometry (DLP) has gained significant attention due to the powerful feature extraction capabilities of convolutional neural networks, enabling single-shot projection to meet both real-time and robustness requirements in dynamic measurement scenarios. However, while these methods yield promising results, they predominantly emphasize model improvements (e.g., optimizing module functionality or expanding network parameters) often neglecting the parallel integration with traditional physical models and the optimization of input features. To overcome these limitations, a novel DLP that combines parallel phase-shifting theory with a fringe restoration network has been proposed and leverages a high-quality dataset, balancing the trade-offs between projection efficiency and reconstruction accuracy: (1) A learning-based spatial composite phase-shifting profilometry (LSCPP) is proposed, marking the first application of equal thickness interference theory from digital holography to DLP. This mitigates pixel loss caused by frequency-domain filtering in FTP while ensuring high-precision fringe reconstruction without auxiliary templates; (2) A multi-exposure dataset is constructed, accompanied by the introduction of a novel evaluation metric, modulation error rate (MER), for performance assessment; (3) Extensive experiments are conducted across both static and dynamic scenarios, utilizing multi-exposure and public datasets, and are compared with state-of-the-art DLPs. It demonstrates the proposed LSCPP’s real-time capability and generalization performance in dynamic measurement environments.},
  archive      = {J_NEUCOM},
  author       = {Jiayi Qin and Yansong Jiang and Yiping Cao and Haitao Wu},
  doi          = {10.1016/j.neucom.2025.129908},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129908},
  shortjournal = {Neurocomputing},
  title        = {Single-shot phase-shifting composition fringe projection profilometry by multi-attention fringe restoration network},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A parallel neural network based structural anomaly
detection: Leveraging time-frequency domain features. <em>NEUCOM</em>,
<em>634</em>, 129907. (<a
href="https://doi.org/10.1016/j.neucom.2025.129907">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural anomaly detection is essential for ensuring the safety, reliability, and longevity of building engineering. By identifying deviations from normal patterns, it enables early intervention and prevents potential failures. However, most existing methods rely on a single feature extracted from the time domain or the frequency domain. Time-domain features alone are insufficient to capture variations in the frequency components, while frequency-domain features fail to account for transient behaviours in the time domain. This limitation significantly reduces detection performance, particularly when dealing with nonlinear and non-stationary signals. To address the issues, this study proposes a new framework for anomaly detection using parallel time convolutional networks (TCN) and wavelet decomposition based convolutional neural networks (WD-CNN), termed PTWC. In this framework, time-frequency domain features are achieved by utilizing TCN to capture time-domain features and WD-CNN to capture frequency-domain features, distinguishing structural anomaly patterns. The proposed PTWC framework is validated on an actual three-story frame structure. Compared with ten baseline methods, the experimental results demonstrate that PTWC has high accuracy and achieves at least 7 % improvement in area under the curve (AUC) scores, thus confirming its superior performance in structural anomaly detection.},
  archive      = {J_NEUCOM},
  author       = {Yingying He and Bo Yang and Weihong Jin and Likai Zhang and Hongyang Chen},
  doi          = {10.1016/j.neucom.2025.129907},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129907},
  shortjournal = {Neurocomputing},
  title        = {A parallel neural network based structural anomaly detection: Leveraging time-frequency domain features},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing fourier neural operators with CNNs architectures:
Pooling, groupwise convolution and inverted block. <em>NEUCOM</em>,
<em>634</em>, 129905. (<a
href="https://doi.org/10.1016/j.neucom.2025.129905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we hypothesize that effective architectural configurations from Convolutional Neural Networks (CNNs) can significantly enhance the performance of the Fourier Neural Operator (FNO). Pooling layers, such as max-pooling and average-pooling in CNNs, play a key role in improving the learnability of nonlocal features in images. However, despite its resemblance to CNNs, FNO lacks such mechanisms due to two primary challenges: (1) applying traditional pooling layers violates discretization invariance, and (2) the fixed size of pooling windows cannot be pre-defined because of variable data resolutions. To address these issues, we propose a novel “pooling operator” for the FNO architecture that preserves discretization invariance and is differentiable with respect to window size. Additionally, we adapt groupwise convolution and the inverted residual block from CNNs to FNOs. Together, the pooling operator, groupwise convolution, and inverted residual block play a pivotal role in achieving superior performance. Benchmark experiments on the 2D Navier–Stokes and 1D Burger’s equation datasets demonstrate the effectiveness of our proposed architecture.},
  archive      = {J_NEUCOM},
  author       = {Seungtae Park and Heejoon Jeon and Hyung Ju Hwang},
  doi          = {10.1016/j.neucom.2025.129905},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129905},
  shortjournal = {Neurocomputing},
  title        = {Enhancing fourier neural operators with CNNs architectures: Pooling, groupwise convolution and inverted block},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Label-only model inversion attacks: Adaptive boundary
exclusion for limited queries. <em>NEUCOM</em>, <em>634</em>, 129902.
(<a href="https://doi.org/10.1016/j.neucom.2025.129902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies have shown that privacy data in deep learning models is vulnerable to attacks by adversaries who can restore private images even with access only to the labels of DNN models. However, existing similar attacks rely heavily on extensive access to the target model, making them easily detectable by defenders. This paper introduces an Adaptive Boundary Exclusion method, called ABE-MI, that achieves a high success rate with minimal access attempts. The core idea of our algorithm is to estimate the gradient of the target point through Gaussian sampling that progressively expands outward, dynamically adjusting the movement step of the data point to reach the centroid of the decision area quickly. Experiments show that our algorithm can attack both CNN and ViT models, and its performance on ViT models far surpasses that of the state-of-the-art (SOTA) algorithms. Moreover, compared to the best current label-only algorithms, our approach requires significantly fewer queries and even exceeds the performance of white-box attacks on other metrics. Furthermore, our algorithm remains effective on tabular data.},
  archive      = {J_NEUCOM},
  author       = {Jiayuan Wu and Chang Wan and Hao Chen and Zhonglong Zheng and Yaxin Sun},
  doi          = {10.1016/j.neucom.2025.129902},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129902},
  shortjournal = {Neurocomputing},
  title        = {Label-only model inversion attacks: Adaptive boundary exclusion for limited queries},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature representation fidelity preservation during neural
network pruning for enhanced compression efficiency. <em>NEUCOM</em>,
<em>634</em>, 129901. (<a
href="https://doi.org/10.1016/j.neucom.2025.129901">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Channel pruning is a widely used technique for compressing convolutional neural networks (CNNs), primarily by identifying and eliminating redundant filters or channels. However, existing pruning criteria often fail to consider inter-channel interactions, leading to inaccurate importance scores. Furthermore, many criteria focus solely on the immediate influence of channels, neglecting their contributions to higher-level feature representations. These limitations hinder CNNs&#39; ability to retain critical information after pruning. In this paper, we propose a novel criterion to address these issues. Our method highlights how feature information loss occurs due to inter-channel dependencies during forward propagation, which affects the accuracy of feature-based importance scores. To mitigate this, we introduce a per-layer channel contribution analysis that captures channel-layer interactions, ensuring more precise pruning decisions. Extensive experiments on image classification (CIFAR-10, ImageNet), object detection (PASCAL VOC, COCO 2017), and 3D point cloud analysis demonstrate the effectiveness of our approach. For instance, our method achieves a 52.6 % reduction in floating-point operations (FLOPs) in ResNet-56 on CIFAR-10 while improving accuracy by 0.4 %, outperforming existing pruning techniques. On ImageNet, pruning ResNet-50 results in a 55.5 % FLOPs reduction with only a 0.72 % top-1 accuracy drop, surpassing prior methods. Additionally, pruning MobileNet-V2 achieves a 31.5 % FLOPs reduction with a higher top-1 accuracy than alternative approaches. These results confirm that our method enhances compression efficiency while preserving feature representation fidelity, making it a robust solution for CNN model compression.},
  archive      = {J_NEUCOM},
  author       = {Ambuj},
  doi          = {10.1016/j.neucom.2025.129901},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129901},
  shortjournal = {Neurocomputing},
  title        = {Feature representation fidelity preservation during neural network pruning for enhanced compression efficiency},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic neighborhood selection for regularized local linear
embedding with elastic networks. <em>NEUCOM</em>, <em>634</em>, 129900.
(<a href="https://doi.org/10.1016/j.neucom.2025.129900">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The processing of high-dimensional data is of paramount importance in the fields of machine learning and pattern recognition. Local linear embedding (LLE), a popular nonlinear dimensionality reduction method, has gained attention for maintaining the local structure of data in low-dimensional space. However, traditional LLE algorithms have limitations in dealing with datasets that are non-uniformly distributed or noisy. To address this issue, we propose an elastic network regularized LLE algorithm with dynamic neighborhood selection (DNS-ENRLLE). The objective is to enhance the adaptability and robustness of the algorithm through a dynamic neighborhood selection mechanism and a regularization strategy. A series of experiments on synthetic and real datasets demonstrate that our method outperforms existing LLE and other nonlinear dimension reduction methods. In particular, the improved method demonstrates significant performance improvements in the analysis of non-uniformly distributed data, effectively enhancing the accuracy and reliability of data analysis results.},
  archive      = {J_NEUCOM},
  author       = {Jiaqi Cheng and Chaojie Wang},
  doi          = {10.1016/j.neucom.2025.129900},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129900},
  shortjournal = {Neurocomputing},
  title        = {Dynamic neighborhood selection for regularized local linear embedding with elastic networks},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving GBDT performance on imbalanced datasets: An
empirical study of class-balanced loss functions. <em>NEUCOM</em>,
<em>634</em>, 129896. (<a
href="https://doi.org/10.1016/j.neucom.2025.129896">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class imbalance poses a persistent challenge in machine learning, particularly for tabular data classification tasks. While Gradient Boosting Decision Trees (GBDT) models are widely regarded as state-of-the-art for these tasks, their effectiveness diminishes in the presence of imbalanced datasets. This paper is the first to comprehensively explore the integration of class-balanced loss functions into three popular GBDT algorithms, addressing binary, multi-class, and multi-label classification. We present a novel benchmark, derived from extensive experiments across diverse datasets, to evaluate the performance gains from class-balanced losses in GBDT models. Our findings establish the efficacy of these loss functions in enhancing model performance under class imbalance, providing actionable insights for practitioners tackling real-world imbalanced data challenges. To bridge the gap between research and practice, we introduce an open-source Python package that simplifies the application of class-balanced loss functions within GBDT workflows, democratizing access to these advanced methodologies. The code is available at https://github.com/Luojiaqimath/ClassbalancedLoss4GBDT .},
  archive      = {J_NEUCOM},
  author       = {Jiaqi Luo and Yuan Yuan and Shixin Xu},
  doi          = {10.1016/j.neucom.2025.129896},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129896},
  shortjournal = {Neurocomputing},
  title        = {Improving GBDT performance on imbalanced datasets: An empirical study of class-balanced loss functions},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025a). Unsupervised infrared–visible person re-identification by
multi-level dual-stream contrastive learning. <em>NEUCOM</em>,
<em>634</em>, 129895. (<a
href="https://doi.org/10.1016/j.neucom.2025.129895">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised Visible–Infrared Person Re-identification (USL-VI-ReID) aims to learn a label-free cross-modal retrieval model to reduce reliance on expensive manual annotations for cross-modal data. Previous works on USL-VI-ReID tend to generate sample labels from the perspective of inter-modality contrastive learning, while neglecting the information differences between cameras, resulting in low credibility of the generated sample labels. Additionally, traditional inter-modality contrastive learning methods use shared feature encoders, which cannot learn personalized modality features. To address these issues, this paper proposes a Dual-Stream Contrastive Learning Method (DCM) that jointly learns personalized feature encoders from both inter-modality and inter-camera perspectives, generating more reliable sample labels, which we refer to as a Multi-level Dual-Stream Contrastive Learning Method. We first establish a Dual-Stream Contrastive Learning (DCL) pre-training framework, which includes three different feature encoders for learning pedestrian representations within specific modalities, and optimize these encoders through contrastive learning using all training data. Then, based on these three feature encoders, we construct a Multi-level Dual-Stream Contrastive Learning framework (MLA) for cross-camera to cross-modal feature clustering and pseudo-label generation. This enables MLA to focus more on learning hierarchical domain information during subsequent model training, combining multi-level feature information aggregation to obtain more accurate cross-modal pseudo-labels. Finally, to further ensure the semantic consistency of the two modal labels, we insert a Cross-Modality Alignment Module (CMAM) between modalities to further improve the recognition accuracy of USL-VI-ReID. Numerous experiments demonstrate that the proposed method stands out among various USL-VI-ReID approaches, exhibiting promising performance.},
  archive      = {J_NEUCOM},
  author       = {Yifeng Zhang and Canlong Zhang and Haifei Ma and Zhixin Li and Zhiwen Wang and Chunrong Wei},
  doi          = {10.1016/j.neucom.2025.129895},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129895},
  shortjournal = {Neurocomputing},
  title        = {Unsupervised infrared–visible person re-identification by multi-level dual-stream contrastive learning},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSPL: Multi-granularity semantic prototype learning for
occluded person re-identification. <em>NEUCOM</em>, <em>634</em>,
129894. (<a href="https://doi.org/10.1016/j.neucom.2025.129894">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although person re-identification has made remarkable progress in recent years, it remains a challenging problem in occluded scenes. Some existing popular methods attempt to decouple the human local features directly by clustering semantics to counter occlusion. However, due to the lack of good semantic learning strategies, the network will inevitably acquire non-discriminative local features. To effectively separate body parts and eliminate occlusion interference, we propose a Multi-granularity Semantic Prototype Learning (MSPL) network based on a superior semantic learning strategy. MSPL mainly consists of a prototype embedding encoder and a multi-granularity prototype decoder. With the help of our proposed Dual Parallel Attention (DPA) module and easy-to-hard learning strategy, the encoder can gradually aggregate semantics and effectively separate discriminative fine-grained features. We also propose a Pose-guided Feature Enhancement (PFE) module and a Prototype Cyclic Grouping (PCG) module in the decoder to resist background clutter and enhance network robustness for complex occlusion scenes. Finally, we design a Prototype Discriminability (PD) loss to reduce the focused redundancy to increase the discrepancy between the focused areas of prototypes. Extensive experimental results on several challenging benchmark datasets show that our MSPL achieves excellent performance and good generalization ability.},
  archive      = {J_NEUCOM},
  author       = {Zhihao Li and Huaxiang Zhang and Lei Zhu and Jiande Sun and Li Liu},
  doi          = {10.1016/j.neucom.2025.129894},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129894},
  shortjournal = {Neurocomputing},
  title        = {MSPL: Multi-granularity semantic prototype learning for occluded person re-identification},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning with noisy labels for classifying biological echoes
in polarimetric weather radar observations using artificial neural
networks. <em>NEUCOM</em>, <em>634</em>, 129892. (<a
href="https://doi.org/10.1016/j.neucom.2025.129892">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The identification of biological echoes in radar data has revolutionized research into airborne migratory species. Deep learning applied to polarimetric weather radar observations can reveal signature patterns of mass movement by bio-scatterers such as birds, bats, and insects. However, due to the difficulties in labelling bio-scatterers in these data, threshold approaches have been proposed in the literature. In this research, we used the depolarization ratio (DR) based on differential reflectivity (zDR) and the cross-correlation coefficient (pHV), along with citizen scientist-reported data, to label bio-scatterers for deep learning. This method of labelling biological echoes in radar signatures is prone to noise, which impacts the accuracy of any model that relies on it. We introduce a novel semi-supervised co-training approach that uses a bootstrap ensemble with a confidence threshold. Our ensemble consists of the newly proposed STNet and two modified FNet models, which incorporate co-learning through bootstrap sampling for label correction. This innovative method significantly improves classification accuracy across all three multivariate numerical datasets compared to baseline models that lack co-learning with bootstrap-based label correction.},
  archive      = {J_NEUCOM},
  author       = {John Atanbori and Christos A. Frantzidis and Mohammed Al-Khafajiy and Aliyu Aliyu and Behnaz Sohani and Kofi Appiah and Harriet Moore and Catherine Sanders and Alastair I. Ward},
  doi          = {10.1016/j.neucom.2025.129892},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129892},
  shortjournal = {Neurocomputing},
  title        = {Learning with noisy labels for classifying biological echoes in polarimetric weather radar observations using artificial neural networks},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multilingual neural machine translation for low-resource
languages by twinning important nodes. <em>NEUCOM</em>, <em>634</em>,
129890. (<a href="https://doi.org/10.1016/j.neucom.2025.129890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multilingual neural machine translation (MNMT) is a novel machine translation approach that benefits from large multilingual resources. However, its performance drops significantly when training with low-resource languages due to the reliance on parameter sharing and data size. In this paper, a new method is proposed to improve the performance of MNMT for a pair of languages where the target language is low-resource. The main idea of this study is to find important nodes that have parameters connected to them that negatively affect an MNMT model and then split those nodes into two sub nodes. Then, the model selects the important sub node that has an effect on the specific language pair to create a twin sub node. This twin sub node helps to strengthen the translation quality of the specific language pair without having a negative effect on other languages. The proposed method works in four steps as: 1) training an MNMT model with parameter sharing over multiple languages, 2) selecting important nodes which negatively affect the MNMT, 3) splitting important nodes into sub nodes, and 4) Twining important sub nodes. The proposed method has been evaluated using several multilingual datasets, including TED 2013, TED 2020, and BIBLE, by examining English-Persian language as a case study. The obtained results show that the proposed method yields the best results for one-to-many and many-to-many models according to the average BLEU value and semantic similarity . The results also show that the proposed method has given better results than other well-known large language models, such as ChatGPT, BING GPT4, and the Google Neural Machine Translation (GNMT) model, when applied to a low-resource language.},
  archive      = {J_NEUCOM},
  author       = {Abouzar Qorbani and Reza Ramezani and Ahmad Baraani and Arefeh Kazemi},
  doi          = {10.1016/j.neucom.2025.129890},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129890},
  shortjournal = {Neurocomputing},
  title        = {Multilingual neural machine translation for low-resource languages by twinning important nodes},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Causal and local correlations based network for multivariate
time series classification. <em>NEUCOM</em>, <em>634</em>, 129884. (<a
href="https://doi.org/10.1016/j.neucom.2025.129884">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, time series classification has attracted the attention of a large number of researchers, and hundreds of methods have been proposed. However, these methods often ignore the spatial correlations among dimensions and the local correlations among features. To address this issue, the causal and local correlations based network (CaLoNet) is proposed in this study for multivariate time series classification. First, pairwise spatial correlations between dimensions are modeled using causality modeling to obtain the graph structure. Then, a relationship extraction network is used to fuse local correlations to obtain long-term dependency features. Finally, the graph structure and long-term dependency features are integrated into the graph neural network. Experiments on the UEA datasets show that CaLoNet can obtain competitive performance compared with state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Mingsen Du and Yanxuan Wei and Xiangwei Zheng and Cun Ji},
  doi          = {10.1016/j.neucom.2025.129884},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129884},
  shortjournal = {Neurocomputing},
  title        = {Causal and local correlations based network for multivariate time series classification},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSSFN: A multi-scale sequence fusion network for CT-based
diagnosis of pulmonary complications. <em>NEUCOM</em>, <em>634</em>,
129878. (<a href="https://doi.org/10.1016/j.neucom.2025.129878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pulmonary complications exhibit similar symptoms, such as ground-glass opacities and patchy consolidations, posing significant challenges for manual diagnosis. In this paper, a novel Multi-Scale Sequence Fusion Network (MSSFN) designed for a small-scale Computed Tomography (CT) database is proposed for computer-aided identification of pulmonary complications. The MSSFN first applies a transfer learning mechanism that utilizes the convolutional neural network weights pre-trained on a large dataset, enabling optimization of both feature extraction efficiency and model accuracy. Next, the multi-scale feature fusion module uses different types of convolutional layers in parallel to extract and integrate high-level features, enabling the network to capture complex lung lesion characteristics from multiple perspectives and enhance information interaction across different layers. Finally, a sequence feature fusion module establishes three-dimensional connections within the CT data, ensuring comprehensive data fusion by effectively integrating spatial features across the sequence. The comprehensive experimental results demonstrate that, under the same experimental conditions, the MSSFN achieves an accuracy of 82.54% for identifying pulmonary complications in CT images, which exhibits superior performance compared to nine similar network structures as well as other four state-of-the-art deep learning models. Consequently, the proposed MSSFN demonstrates practical significance by providing radiologists with reliable tools for accurately distinguishing various pulmonary complications in CT images. It also holds theoretical value by advancing methods for constructing robust features with enhanced representational capabilities.},
  archive      = {J_NEUCOM},
  author       = {Hongfu Zeng and Xinyu Li and Haipeng Xu and Keyi Yu and Huihua Hu and Peishu Wu and Nianyin Zeng},
  doi          = {10.1016/j.neucom.2025.129878},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129878},
  shortjournal = {Neurocomputing},
  title        = {MSSFN: A multi-scale sequence fusion network for CT-based diagnosis of pulmonary complications},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance-oriented fault detection and fault-tolerant
control for nonlinear uncertain systems: Improved stochastic
configuration network-based methods. <em>NEUCOM</em>, <em>634</em>,
129869. (<a href="https://doi.org/10.1016/j.neucom.2025.129869">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper primarily focuses on performance-oriented fault detection (FD) and fault-tolerant control (FTC) for nonlinear uncertain systems. To achieve this, we initially develop an improved stochastic configuration network-based (ISCN-based) method for modeling nonlinear uncertain systems, leveraging the supervision mechanism and incremental construction techniques. It is followed by a performance indicator to enhance the robustness against the uncertainties and the sensitivity to the faults, which is further implemented for performance-oriented FD purpose. Subsequently, an adaptive FTC method is proposed to recover the nonlinear system performance, and associated with it, the configuration of the fault-tolerant controller parameters is investigated. Finally, a case study on the continuous stirred-tank reactor (CSTR) system is presented to showcase the efficacy and advantage of the proposed methods.},
  archive      = {J_NEUCOM},
  author       = {Jingjing Gao and Feng Gao and Zhengxuan Zhang and Xu Yang and Jian Huang and Kaixiang Peng},
  doi          = {10.1016/j.neucom.2025.129869},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129869},
  shortjournal = {Neurocomputing},
  title        = {Performance-oriented fault detection and fault-tolerant control for nonlinear uncertain systems: Improved stochastic configuration network-based methods},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SPRInT: Scaling programmatic reasoning for INstruction
tuning in mathematics. <em>NEUCOM</em>, <em>634</em>, 129868. (<a
href="https://doi.org/10.1016/j.neucom.2025.129868">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present SPRInT , a novel approach for large-scale, cost-effective synthesis of instruction-tuning datasets, leveraging Program-of-Thoughts (PoT) to enhance mathematical reasoning capabilities. Through the SPRInT framework, we synthesized data from seven high-quality open-source math datasets (including GSM8K, MATH, AQuA), and developed InfinityMATH -a dataset containing over 100,000 samples generated from QA pairs, offering extensive coverage across various mathematical domains. The SPRInT model series, fine-tuned on InfinityMATH using open-source language and code models such as Llama2-7B, Mistral-7B, and CodeLlama-7B, achieved remarkable improvements in mathematical reasoning, with performance gains between 184.7% and 514.3%. In zero-shot settings, our SPRInT -CodeLlama-7B model surpassed MAmmoTH-Coder on widely-used benchmarks, including GSM8K (65.80% vs. 56.86%) and MATH (34.06% vs. 29.88%). To assess logical consistency in numerical transformations, we created the GSM8K+ and MATH＋ test sets by modifying the numerical values in the original datasets. While traditional models struggled with these alterations, the SPRInT models exhibited superior robustness. The InfinityMATH dataset is publicly available at https://huggingface.co/datasets/BAAI/InfinityMATH .},
  archive      = {J_NEUCOM},
  author       = {Yan Yan and Lin Li and Bo-Wen Zhang},
  doi          = {10.1016/j.neucom.2025.129868},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129868},
  shortjournal = {Neurocomputing},
  title        = {SPRInT: Scaling programmatic reasoning for INstruction tuning in mathematics},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SCSA: Exploring the synergistic effects between spatial and
channel attention. <em>NEUCOM</em>, <em>634</em>, 129866. (<a
href="https://doi.org/10.1016/j.neucom.2025.129866">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Channel and spatial attentions have respectively brought significant improvements in extracting feature dependencies and spatial structure relations for various downstream vision tasks. The combined use of both channel and spatial attentions is widely considered beneficial for further performance improvement; however, the synergistic effects between channel and spatial attentions, especially in terms of spatial guidance and mitigating semantic disparities, have not yet been thoroughly studied. This motivates us to propose a novel Spatial and Channel Synergistic Attention module (SCSA), entailing our investigation toward the synergistic relationship between spatial and channel attentions at multiple semantic levels. Our SCSA consists of two parts: the Shareable Multi-Semantic Spatial Attention (SMSA) and the Progressive Channel-wise Self-Attention (PCSA). SMSA integrates multi-semantic information and utilizes a progressive compression strategy to inject discriminative spatial priors into PCSA’s channel self-attention, effectively guiding channel recalibration. Additionally, the robust feature interactions based on the Channel-wise single-head self-attention mechanism in PCSA further mitigate the disparities in multi-semantic information among different sub-features within SMSA. We conduct extensive experiments on seven benchmark datasets, including classification on ImageNet-1K, object detection on MSCOCO, segmentation on ADE20K, and four other complex scene detection datasets. Our results demonstrate that our proposed SCSA not only surpasses the current plug-and-play state-of-the-art attention but also exhibits enhanced generalization capabilities across various task scenarios. The code and models are available at: https://github.com/HZAI-ZJNU/SCSA .},
  archive      = {J_NEUCOM},
  author       = {Yunzhong Si and Huiying Xu and Xinzhong Zhu and Wenhao Zhang and Yao Dong and Yuxing Chen and Hongbo Li},
  doi          = {10.1016/j.neucom.2025.129866},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129866},
  shortjournal = {Neurocomputing},
  title        = {SCSA: Exploring the synergistic effects between spatial and channel attention},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sentiment analysis applications using deep learning
advancements in social networks: A systematic review. <em>NEUCOM</em>,
<em>634</em>, 129862. (<a
href="https://doi.org/10.1016/j.neucom.2025.129862">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis is required to extract insights from social media content affecting decision-making and personalized services. The enormous volume of social network information has to be technically processed to extract relevant knowledge. Sentiment analysis is the most widely used method for this purpose. The current techniques of sentiment analysis have made significant progress in various fields. However, the potential of social networks to better understand human emotions and the recent advancements in deep learning necessitate the review and use of advanced sentiment analysis techniques that still require more attention from researchers in this field. In this regard, this review presents a systematic literature review (SLR) on the advancements of sentiment analysis using deep learning techniques in social networks from 2019 to May 2024. Furthermore, this review emphasizes that sentiment analysis can provide meaningful insights into information extracted from large and diverse datasets such as social media, which is extremely important for decision-making and personalized services. It also highlights mental health concerns as one of the windows into the emotional atmosphere of social networks. In addition, this SLR provides a technical taxonomy and comparison of various deep learning approaches. This SLR not only provides a comprehensive overview of the most advanced techniques and methodologies now used in sentiment analysis but also highlights forthcoming challenges and open issues that need to be addressed in the future. This study helps researchers and practitioners use deep learning to improve sentiment analysis applications and digital social well-being.},
  archive      = {J_NEUCOM},
  author       = {Erfan Bakhtiari Ramezani},
  doi          = {10.1016/j.neucom.2025.129862},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129862},
  shortjournal = {Neurocomputing},
  title        = {Sentiment analysis applications using deep learning advancements in social networks: A systematic review},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised visual similarity-based medical image retrieval
via dual-encoder and metric learning. <em>NEUCOM</em>, <em>634</em>,
129861. (<a href="https://doi.org/10.1016/j.neucom.2025.129861">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin cancer stands as one of the most lethal cancers, with its prognosis heavily reliant upon timely diagnosis. Medical image retrieval (MIR) techniques aim to retrieve images similar to the query one from a dataset, assisting doctors in disease diagnosis and clinical treatment programming. However, a significant challenge in dermatoscopic image interpretation stems from the heterogeneity of lesion visual appearance, which hinders existing methods from effectively balancing visual similarity with disease category. To address this issue, we propose an unsupervised approach for medical image retrieval to enhance the visual congruity of retrieval while ensuring disease accuracy.Dual-Encoder is trained to extract image features via a self-distilling dual network, and followed by subsequent refinement of the feature representation utilizing unsupervised metric learning methodologies. Our method is tested on the skin cancer dataset ISIC2019, evaluated using dual-dimensional metrics of visual and disease similarity. To assess visual similarity performance, we constructed a test visual dataset and categorize into 27 visual types we fine-tuned the pre-trained model on multiple datasets encompassing ultrasound, MRI and CT images to evaluate its applicability, which outperforms other advanced generalized retrieval methods. The experiments demostrated the effectiveness and generalization of our proposed method.},
  archive      = {J_NEUCOM},
  author       = {Xiya Weng and Yan Zhuang and Rui Wang and Ke Chen and Lin Han and Zhan Hua and Jiangli Lin},
  doi          = {10.1016/j.neucom.2025.129861},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129861},
  shortjournal = {Neurocomputing},
  title        = {Unsupervised visual similarity-based medical image retrieval via dual-encoder and metric learning},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph-based interactive knowledge distillation for social
relation continual learning. <em>NEUCOM</em>, <em>634</em>, 129860. (<a
href="https://doi.org/10.1016/j.neucom.2025.129860">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As multimedia advances, there is a growing need for machines to adeptly understand diverse social relations. Traditional methods for recognizing these relations, which are limited to a fixed number of classes, are ill-equipped for continual learning as new social interactions emerge. To address this prob-lem, we propose a pioneering Graph-based Interactive Knowledge Distillation (GI-KD) method for social relation continual learning. GI-KD, embedded in a class incremental learning structure, creates a balanced system where previously learned social relations and new knowledge are positioned at either end of the scale. The old and new knowledge is learned dynamically by adjusting the tilt of the balance. To achieve this balance, we propose a novel Libra loss function, which evaluate the relative contribution of old and new information and thus guides the adaptive fine-tuning of the model. We evaluate the GI-KD on three public social relation recognition (SRR) datasets, under different data distribution strategies. Our method shows a remarkable average 3.6% increase in incremental accuracy over current CIL techniques, effectively reducing catastrophic forgetting. Furthermore, GI-KD improves mAP and Acc by 4.6%, 5.4%, and 4.5%, respectively, compared to current CIL techniques, highlighting its strength in both continual learning and SRR.},
  archive      = {J_NEUCOM},
  author       = {Wang Tang and Linbo Qing and Pingyu Wang and Lindong Li and Yonghong Peng},
  doi          = {10.1016/j.neucom.2025.129860},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129860},
  shortjournal = {Neurocomputing},
  title        = {Graph-based interactive knowledge distillation for social relation continual learning},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sample-pair learning network for extremely imbalanced
classification. <em>NEUCOM</em>, <em>634</em>, 129859. (<a
href="https://doi.org/10.1016/j.neucom.2025.129859">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In data classification, class-balanced data is ideal, but real datasets are often imbalanced, necessitating rebalancing through methods like resampling. In recent years, some new generative model-based resampling methods have been proposed. However, when facing extreme class imbalance, where the minority class is strongly underrepresented and on its own does not contain enough information to conduct the generative process. Some deep learning methods have been proposed to solve extremely imbalanced classification problems, but some of them are only used for specific datasets. Therefore, we proposed a novel deep learning method that combines a generative strategy with multi-task joint learning, termed sample-pair learning network (SPLN), for extremely imbalanced classification. The network consists of data preprocessing and multi-task joint learning modules. During data preprocessing, the training set is expanded by constructing positive and negative sample-pairs, then rebalanced using a strategy combining attention and resampling, termed undersampling based on attention power values (APVUS). The multi-task joint learning module employs a Siamese convolutional subnetwork to measure the similarity between sample-pairs and a multi-layer perceptron to recognize the category of single samples. The module can reduce the risk of overfitting caused by excessive noise in the training set. Finally, we designed a voting model based on the Siamese convolutional subnetwork to infer the categories of test samples. Experimental results demonstrate that our approach outperforms state-of-the-art generative model-based methods and is effective and general for extremely imbalanced classification.},
  archive      = {J_NEUCOM},
  author       = {Linjun Chen and Xiao-Yuan Jing and Runhang Chen and Fei Wu and Yongchang Ding and Changhui Hu and Ziyun Cai},
  doi          = {10.1016/j.neucom.2025.129859},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129859},
  shortjournal = {Neurocomputing},
  title        = {Sample-pair learning network for extremely imbalanced classification},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distantly supervised relation extraction with multi-level
contextual information integration. <em>NEUCOM</em>, <em>634</em>,
129858. (<a href="https://doi.org/10.1016/j.neucom.2025.129858">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The core objective of distantly Supervised relation extraction (DSRE) is to automatically and at scale extract relational information between two entities from unstructured text. However, the generation of noisy data in the automated labeling process is inevitable. To address the limitations of DSRE in terms of contextual information, current mainstream methods primarily focus on enriching entity representations through external knowledge bases. Nevertheless, there remains a wealth of untapped and rich information within the text itself, which plays a crucial role in helping the model to better understand the relationships between entities. In response to this, we propose a novel strategy that does not require the introduction of additional external knowledge. Instead, it cleverly leverages the principle of semantic similarity to construct contextually rich information that is highly semantically aligned with individual sentences. Furthermore, we incorporate information from Knowledge Graphs (KG) to achieve a deep integration of both textual and KG information. Specifically, we share contextual information at any level of the text with the KG information, merging them as the final bag-level representation for relation extraction. Experimental results demonstrate that updating the KG encoder using only the text encoder yields better performance. Furthermore, experiments conducted on two different domain-specific relation extraction datasets confirmed that our model achieved superior performance.},
  archive      = {J_NEUCOM},
  author       = {Danjie Han and Heyan Huang and Shumin Shi and Changsen Yuan and Cunhan Guo},
  doi          = {10.1016/j.neucom.2025.129858},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129858},
  shortjournal = {Neurocomputing},
  title        = {Distantly supervised relation extraction with multi-level contextual information integration},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modal information fusion for multi-task end-to-end
behavior prediction in autonomous driving. <em>NEUCOM</em>,
<em>634</em>, 129857. (<a
href="https://doi.org/10.1016/j.neucom.2025.129857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Behavior prediction in autonomous driving is increasingly achieved through end-to-end frameworks that predict vehicle states from multi-modal information, streamlining decision-making and enhancing robustness in time-varying road conditions. This study proposes a novel multi-modal information fusion-based, multi-task end-to-end model that integrates RGB images, depth maps, and semantic segmentation data, enhancing situational awareness and predictive precision. Utilizing a Vision Transformer (ViT) for comprehensive spatial feature extraction and a Residual-CNN-BiGRU structure for capturing temporal dependencies, the model fuses spatiotemporal features to predict vehicle speed and steering angle with high precision. Through comparative, ablation, and generalization tests on the Udacity and self-collected datasets, the proposed model achieves steering angle prediction errors of MSE 0.012 rad, RMSE 0.109 rad, and MAE 0.074 rad, and speed prediction errors of MSE 0.321 km/h, RMSE 0.567 km/h, and MAE 0.373 km/h, outperforming existing driving behavior prediction models. Key contributions of this study include the development of a channel difference attention mechanism and advanced spatiotemporal feature fusion techniques, which improve predictive accuracy and robustness. These methods effectively balance computational efficiency and predictive performance, contributing to practical advancements in driving behavior prediction.},
  archive      = {J_NEUCOM},
  author       = {Guo Baicang and Liu Hao and Yang Xiao and Cao Yuan and Jin Lisheng and Wang Yinlin},
  doi          = {10.1016/j.neucom.2025.129857},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129857},
  shortjournal = {Neurocomputing},
  title        = {Multi-modal information fusion for multi-task end-to-end behavior prediction in autonomous driving},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model-free extended q-learning method for h∞ output tracking
control of networked control systems with network delays and packet
loss. <em>NEUCOM</em>, <em>634</em>, 129846. (<a
href="https://doi.org/10.1016/j.neucom.2025.129846">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the extended Q-learning method is used to study the H ∞ output tracking control (HOTC) problem of networked control systems with state delay and data loss. Compared with the existing results, the network control system in this paper contains both network delays and packet loss, as well as external disturbances. To deal with the disturbances, the H ∞ control problem is transformed into the maximum and minimum value problem, which is solved by the method of zero-sum game. The packet loss and delay of the state make it difficult to obtain accurate current state information. Therefore, it is necessary to design a new smith predictor that contains delay and packet loss to predict the current state. Using the predicted state, the extended Q-learning algorithm is implemented to solve the H ∞ output tracking problem with unknown dynamics of the system. Then, the convergence of the extended Q-learning algorithm is proved. Moreover, the stability and optimality of the proposed method are analyzed in the theorems. Finally, numerical simulation is performed to verify the effectiveness of the proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Longyan Hao and Chaoli Wang and Dong Liang and Shihua Li},
  doi          = {10.1016/j.neucom.2025.129846},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129846},
  shortjournal = {Neurocomputing},
  title        = {Model-free extended Q-learning method for h∞ output tracking control of networked control systems with network delays and packet loss},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). H∞ human-assistance fuzzy control of discrete-time nonlinear
human-in-the-loop systems. <em>NEUCOM</em>, <em>634</em>, 129845. (<a
href="https://doi.org/10.1016/j.neucom.2025.129845">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reflecting the change of human behavior on control performance of the human–machine collaboration is a difficult task. In this paper, an H ∞ human-assistance fuzzy control is developed for discrete-time nonlinear Markov jump human-in-the-loop (HiTL) systems. More specifically, to improve the human internal state, giving control input to human is considered in a controlled hidden Markov model utilized to describe human behavior. Then, a Takagi–Sugeno fuzzy model is employed to represent the nonlinear HiTL system. Based on this model and by using a stochastic Lyapunov functional, sufficient conditions for the existence of an H ∞ human-assistance fuzzy controller are provided in terms of linear matrix inequalities guaranteeing closed-loop stochastic stability of HiTL fuzzy system with an H ∞ control performance. Finally, simulation results on a single-degree-of-freedom vehicle with HiTL demonstrate that both adding the control input to the driver via the warning system and applying the suggested human-assistance fuzzy control to vehicle via automation are effective.},
  archive      = {J_NEUCOM},
  author       = {Xiu-Mei Zhang and Huai-Ning Wu},
  doi          = {10.1016/j.neucom.2025.129845},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129845},
  shortjournal = {Neurocomputing},
  title        = {H∞ human-assistance fuzzy control of discrete-time nonlinear human-in-the-loop systems},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved YOLOv7 for small object detection in airports:
Task-oriented feature learning with gaussian wasserstein loss and
attention mechanisms. <em>NEUCOM</em>, <em>634</em>, 129844. (<a
href="https://doi.org/10.1016/j.neucom.2025.129844">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small objects in the airport scene, such as Persons and Vehicles, can lead to low accuracy and robustness of the object detection task. To address the above problems, an improved YOLOv7 model is proposed to detect certain objects on the airport scene. Considering the perspective distortion of the monitoring camera on the airport surface, the deformable convolutional feature extractor (DCFE) is first designed to adaptively extract features from input images for irregular occlusion objects. To learn task-oriented features from different channels, the attention mechanism is incorporated into the backbone to focus on informative concepts in a data-driven manner, formulating an attention feature extractor (AttFE). During the model training, the Normalized Gaussian Wasserstein distance (NWD) is considered as the loss function to measure the prediction errors after converting the bounding boxes into Gaussian distribution, thereby enhancing the ability to fit the small objects. A real-world airport surface dataset (ASD) is constructed to validate the proposed model. Extensive experimental results demonstrate that the proposed model outperforms selective baselines, achieving a 1.2% absolute improvement in mAP over the original YOLOv7 network. Experiments conducted on multiple common datasets and the results demonstrate that the proposed model exhibits superior performance in terms of mAP. All proposed technical modules contribute to expected performance improvement. Most importantly, the proposed model achieves higher performance for small objects and has the desired robustness over occluded objects.},
  archive      = {J_NEUCOM},
  author       = {Ruijie Peng and Chuanlin Liao and Weijun Pan and Xiaolin Gou and Jianwei Zhang and Yi Lin},
  doi          = {10.1016/j.neucom.2025.129844},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129844},
  shortjournal = {Neurocomputing},
  title        = {Improved YOLOv7 for small object detection in airports: Task-oriented feature learning with gaussian wasserstein loss and attention mechanisms},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conv-enhanced transformer and robust optimization network
for robust multimodal sentiment analysis. <em>NEUCOM</em>, <em>634</em>,
129842. (<a href="https://doi.org/10.1016/j.neucom.2025.129842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sentiment analysis seeks to utilize data from multiple modalities to enhance the overall performance of sentiment analysis. However, in real-world applications, missing modality data is an inevitable phenomenon. The semantic sparsity associated with missing data hinders existing methods from effectively capturing local dependencies among modalities, resulting in inefficiencies during cross-modal interactions. Furthermore, simplistic feature reconstruction strategies lead to suboptimal representation learning, rendering models susceptible to noise interference. To address these issues, we propose a novel Conv-Enhanced Transformer and Robust Optimization Network (CTRN) for robust multimodal sentiment analysis. Firstly, this method effectively models local dependencies by incorporating convolutional layers within the cross-modal Transformer, while exploring the intrinsic correlations between global multimodal context and local unimodal feature, thereby facilitating cross-modal fusion. Additionally, to enable effective representation learning and reduce the impact of noisy data, we implements Auxiliary Robust Optimization (ARO), integrating feature reconstruction and adversarial training to encourage the model to learn supplementary semantic information from the differences between complete and missing data. Finally, the introduction of momentum distillation further mitigates the influence of noisy data on model performance. Experimental results on three benchmark datasets demonstrate that our approach significantly enhances the performance of robust multimodal sentiment analysis.},
  archive      = {J_NEUCOM},
  author       = {Bin Sun and Li Jia and Yiming Cui and Na Wang and Tao Jiang},
  doi          = {10.1016/j.neucom.2025.129842},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129842},
  shortjournal = {Neurocomputing},
  title        = {Conv-enhanced transformer and robust optimization network for robust multimodal sentiment analysis},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Memo-UNet: Leveraging historical information for enhanced
wave height prediction. <em>NEUCOM</em>, <em>634</em>, 129840. (<a
href="https://doi.org/10.1016/j.neucom.2025.129840">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wave height prediction is a challenging spatiotemporal modeling task. It requires accurately capturing the dynamic evolution patterns of historical data. However, current methods show significant limitations in storing, retrieving, and utilizing historical information. These limitations hinder the learning ability of neural networks in critical temporal dynamics utilization of wave height prediction. Therefore, we propose a novel neural network Meme-Unet for wave height prediction. Specifically, to address the challenges in storing and retrieving historical information, we design a Memo module that adaptively stores historical data and retrieves key historical information through a minimum distance constraint. Additionally, to enhance the utilization effectiveness of historical information, we designed a TimeEncoding module with attention mechanisms to guide the model in better capturing temporal relationships. We conducted wave height prediction experiments in two different ocean regions, achieving the best MSE of 0.041 and a 6.8% improvement compared to state-of-the-art methods. This shows the advantage of the Memo-UNet’s design in capturing the dynamics of spatiotemporal modeling.},
  archive      = {J_NEUCOM},
  author       = {Teng Fang and Xiaojie Li and Canghong Shi and Xian Zhang and Wei Xiao and Yi Kou and Imran Mumtaz and Zhan ao Huang},
  doi          = {10.1016/j.neucom.2025.129840},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129840},
  shortjournal = {Neurocomputing},
  title        = {Memo-UNet: Leveraging historical information for enhanced wave height prediction},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hard-label adversarial attack with dual-granularity
optimization on texts. <em>NEUCOM</em>, <em>634</em>, 129839. (<a
href="https://doi.org/10.1016/j.neucom.2025.129839">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement of artificial intelligence security research has led to the emergence of adversarial attack technology as a critical approach for identifying potential security vulnerabilities in artificial intelligence models. When targeting natural language processing models, conducting adversarial attacks in the hard-label setting presents a more practical and challenging black-box scenario due to the difficulty in computing gradients directly from discrete word sequences. Current textual adversarial attack methods are inefficient due to the lack of consideration for the limited number of queries available during the adversarial text generation process, creating a disparity between these approaches and real-world adversarial attack scenarios. To this end, this work proposes a dual-granularity optimization strategy that consists of a single-word semantic optimization and a multi-word joint semantic optimization procedure, and presents a query-efficient hard-label attack method called DualAttack by incorporating the proposed dual-granularity optimization strategy into the mutation and crossover process of the Genetic Algorithm framework. Extensive experimental results demonstrate that DualAttack can effectively produce high-quality adversarial texts with superior semantic similarity and minimal perturbation rates within fewer queries compared to existing methods in the hard-label setting.},
  archive      = {J_NEUCOM},
  author       = {Shilin Qiu and Qihe Liu and Shijie Zhou and Min Gou and Zhun Zhang and Zhewei Wu},
  doi          = {10.1016/j.neucom.2025.129839},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129839},
  shortjournal = {Neurocomputing},
  title        = {Hard-label adversarial attack with dual-granularity optimization on texts},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Momentum gradient-based untargeted poisoning attack on
hypergraph neural networks. <em>NEUCOM</em>, <em>634</em>, 129835. (<a
href="https://doi.org/10.1016/j.neucom.2025.129835">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypergraph Neural Networks (HGNNs) have been successfully applied in various hypergraph-related tasks due to their excellent higher-order representation capabilities. Unfortunately, recent works have shown deep learning models vulnerable to diverse attacks. Most studies of attacks on graphs have focused on Graph Neural Networks (GNNs), and the study of attacks on HGNNs remains largely unexplored. In this paper, we try to bridge this gap. We design a new untargeted poisoning attack for HGNNs, MGHGA, which focuses on modifying node features. We consider the process of HGNNs training and use a surrogate model to implement the attack before hypergraph modeling. Precisely, MGHGA consists of two parts: feature selection and feature modification. We use a momentum gradient mechanism to choose the attack node features in the feature selection module. In the feature modification module, we use two feature generation approaches (direct modification and sign gradient) to enable MGHGA to be employed on discrete and continuous datasets. We conduct extensive experiments on seven benchmark datasets to validate the attack performance of MGHGA in the node and the visual object classification tasks. The results show that MGHGA improves performance by an average of 2% compared to the baselines.},
  archive      = {J_NEUCOM},
  author       = {Yang Chen and Stjepan Picek and Zhonglin Ye and Zhaoyang Wang and Haixing Zhao},
  doi          = {10.1016/j.neucom.2025.129835},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129835},
  shortjournal = {Neurocomputing},
  title        = {Momentum gradient-based untargeted poisoning attack on hypergraph neural networks},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiple-level enhanced graph convolutional network for
aspect sentiment triplet extraction. <em>NEUCOM</em>, <em>634</em>,
129834. (<a href="https://doi.org/10.1016/j.neucom.2025.129834">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect Sentiment Triplet Extraction (ASTE) is a method for extracting aspect terms, opinion terms, and their corresponding sentiment polarities from a given sentence. Most of the existing studies use joint extraction methods to extract the triplets directly in a unified framework. However, most joint extraction methods only consider the semantic and syntactic dependency information of the sentence. Due to a lack of sentiment information and positional information, they are unable to accurately and completely express the aspect and opinion in the sentence. In order to solve the above problems, we introduce a Multiple-level Enhanced Graph Convolutional Network (MEGCN) for ASTE, which utilizes sentiment scores and sentiment polarity nodes alongside syntactic dependency information. This approach not only enriches contextual understanding by integrating sentiment data but also improves positional analysis of aspect and opinion terms through polarity nodes. Moreover, our dual-aware fusion module, combining semantic with sentiment-enhanced syntactic features through a biaffine attention mechanism and matrix construction, enables a deeper representation of aspect sentiment triplets. Our model demonstrates superior performance over existing methods on two widely recognized ASTE datasets.},
  archive      = {J_NEUCOM},
  author       = {Haowen Xu and Mingwei Tang and Tao Cai and Jie Hu and Zhongyuan Jiang and Deng Bian and Shixuan Lv},
  doi          = {10.1016/j.neucom.2025.129834},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129834},
  shortjournal = {Neurocomputing},
  title        = {Multiple-level enhanced graph convolutional network for aspect sentiment triplet extraction},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dense attention networks for texture classification.
<em>NEUCOM</em>, <em>634</em>, 129833. (<a
href="https://doi.org/10.1016/j.neucom.2025.129833">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Texture plays a fundamental role in visual perception and is a key feature for classifying materials and surfaces in images. However, due to the limited number of training samples for each texture class, current deep learning-based methods struggle to capture diverse texture patterns effectively. To address this challenge, we propose a Dense Attention Networks (DANets), a novel architecture for texture classification that leverages both attention mechanisms and dense connectivity. DANet aims to enhance the ability to capture various texture patterns by constructing a mixed-scale, densely connected squeeze-and-excitation attention network. Additionally, we introduce a new Texture Loss function that incorporates dynamic regularization to improve robustness and generalization. To further boost performance, we propose Trident Feature Fusion (TFF), a simple yet effective method for fusing feature vectors from shallow, middle, and deep layers, enabling more comprehensive texture representation. Experimental results on six benchmark texture datasets demonstrate that DANets outperform 26 representative methods, showing their effectiveness in improving texture classification accuracy.},
  archive      = {J_NEUCOM},
  author       = {Yongsheng Dong and Naixin Lu and Xuelong Li},
  doi          = {10.1016/j.neucom.2025.129833},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129833},
  shortjournal = {Neurocomputing},
  title        = {Dense attention networks for texture classification},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Practical incremental learning: Striving for better
performance-efficiency trade-off. <em>NEUCOM</em>, <em>634</em>, 129831.
(<a href="https://doi.org/10.1016/j.neucom.2025.129831">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We revisit the storage of historical data and buffer management in replay-based Incremental Learning (IL), where the buffer is usually a complete copy of the storage. Storage or buffer size constraints present significant challenges in laboratory settings but may not be practical in real-world applications. Since storing historical data is generally feasible and affordable in most realistic scenarios, we propose a generalization to IL by decoupling the concepts of storage and buffer, dubbed Practical Incremental Learning (PIL). We argue that, in practice, storage size should be determined by cost considerations, while buffer size should be limited for efficiency. Under PIL, we establish a strong baseline by resampling the buffer for each training iteration, ensuring better historical data coverage. We then evaluate popular strategies within the IL community, revealing their ineffectiveness against this baseline. We identify key limitations through in-depth analysis and derive insightful design principles for PIL methods. Based on these principles, Cross-Task Distance Calibration with Distribution Annealing (DCDA) is proposed. It achieves significant improvements over state-of-the-art methods across multiple benchmarks and settings, with performance gains of up to 15%, demonstrating its industrial-level performance and usability.},
  archive      = {J_NEUCOM},
  author       = {Shixiong Xu and Bolin Ni and Xing Nie and Fei Zhu and Yin Li and Jianlong Chang and Gaofeng Meng},
  doi          = {10.1016/j.neucom.2025.129831},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129831},
  shortjournal = {Neurocomputing},
  title        = {Practical incremental learning: Striving for better performance-efficiency trade-off},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing generalization in camera trap image recognition:
Fine-tuning visual language models. <em>NEUCOM</em>, <em>634</em>,
129826. (<a href="https://doi.org/10.1016/j.neucom.2025.129826">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a novel fine-tuning approach for enhancing the generalization capabilities of visual language models in the context of wildlife monitoring, particularly for camera trap image recognition. In this paper, we introduce Ecological Visual Language Models (Eco-VLMs), a model fine-tuned using an ecological subset of the ImageNet1K dataset (ImageNet1K-E), aimed at reducing the reliance on spurious correlations that affect the performance of models like CLIP when applied to specialized domains. By employing text augmentation techniques and expanding species names with rich descriptors, Eco-VLM is optimized to extract more distinctive features from images, thereby improving its discriminative capabilities for wildlife features. Meanwhile, random contrastive loss is proposed to improve the diversity of training data and the generalization of Eco-VLMs. The proposed Eco-CLIP and Eco-SigLIP model are rigorously evaluated against various camera trap datasets and demonstrates superior performance, with average F1 scores improved by 4.44 % and 3.79 % compared to the standard CLIP and SigLIP model. Intrinsic evaluations further confirm that Eco-VLMs have acquired a broader ecological knowledge base, highlighting its enhanced generalization abilities. This research contributes to the field by addressing the limitations of current visual language models in specialized ecological applications and underscores the potential of Eco-VLMs for improving wildlife monitoring efforts.},
  archive      = {J_NEUCOM},
  author       = {Zihe Yang and Ye Tian and Lifeng Wang and Junguo Zhang},
  doi          = {10.1016/j.neucom.2025.129826},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129826},
  shortjournal = {Neurocomputing},
  title        = {Enhancing generalization in camera trap image recognition: Fine-tuning visual language models},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Training multi-bit spiking neural network with virtual
neurons. <em>NEUCOM</em>, <em>634</em>, 129825. (<a
href="https://doi.org/10.1016/j.neucom.2025.129825">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Back-Propagation Through Time (BPTT) with surrogate gradient has been widely applied for directly training the Spiking Neural Network (SNN), a biologically realistic type of Artificial Neural Network. The Multi-Level Firing model (MLF) improves SNN performance by introducing more sub-neurons in a unit and extending the output of spiking neurons from single-bit binary impulse to multiple-bit integers. However, it also worsens the excessive computational resources demanded by the BPTT process. This paper presents a novel neuron model called Virtual Neurons(VN) and its training method. VN can output multi-bit spikes as MLF does but avoid its usually heavy training cost. The VN has been proven numerically equivalent to a special case of several single-bit sub-neurons combined in the MLF way, making it theoretically compatible with 1-bit neuromorphic chips. Experimental results on various vision tasks demonstrate that VN-based SNNs not only have much lower computation costs compared to the MLF model during off-chip training but also achieve advanced performance in fewer time steps.},
  archive      = {J_NEUCOM},
  author       = {Haoran Xu and Zonghua Gu and Ruimin Sun and De Ma},
  doi          = {10.1016/j.neucom.2025.129825},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129825},
  shortjournal = {Neurocomputing},
  title        = {Training multi-bit spiking neural network with virtual neurons},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing sentiment analysis with distributional emotion
embeddings. <em>NEUCOM</em>, <em>634</em>, 129822. (<a
href="https://doi.org/10.1016/j.neucom.2025.129822">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment classification tasks, such as emotion detection and sentiment analysis, are essential in modern natural language processing (NLP). Moreover, vector representation frameworks modeling semantic content underlie each state-of-the-art NLP algorithmic scheme. In sentiment classification, traditional methods often rely on such embedding vectors for semantic representation, yet they typically overlook the dynamic and sequential nature of emotions within textual data. In this work, we present a novel methodology that leverages the distributional patterns of emotions. An embedding framework that captures the inherent serial structure of emotional occurrences in text is introduced, modeling the interdependencies between emotion states as they unfold within a document. Our approach treats each sentence as an observation in a multivariate series of emotions, transforming the emotional flow of a text into a sequence of emotion strings. By applying distributional logic, emotion-based embeddings that represent both emotional and semantic information are derived. Through a comprehensive experimental framework, we demonstrate the effectiveness of these embeddings across various sentiment-related tasks, including emotion detection, irony identification, and hate speech classification, evaluated on multiple datasets. The results show that our distributional emotion embeddings significantly enhance the performance of sentiment classification models, offering improved generalization across diverse domains such as financial news and climate change discourse. Hence, this work highlights the potential of using distributional emotion embeddings to advance sentiment analysis, offering a more nuanced understanding of emotional language and its structured, context-dependent manifestations.},
  archive      = {J_NEUCOM},
  author       = {Charalampos M. Liapis and Aikaterini Karanikola and Sotiris Kotsiantis},
  doi          = {10.1016/j.neucom.2025.129822},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129822},
  shortjournal = {Neurocomputing},
  title        = {Enhancing sentiment analysis with distributional emotion embeddings},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel multi-scale salient object detection framework
utilizing nonlinear spiking neural p systems. <em>NEUCOM</em>,
<em>634</em>, 129821. (<a
href="https://doi.org/10.1016/j.neucom.2025.129821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Salient object detection (SOD) is fundamental to computer vision applications ranging from autonomous driving and surveillance to medical imaging. Despite significant progress, existing methods struggle to effectively model multi-scale features and their complex interdependencies, particularly in challenging real-world scenarios with complex backgrounds and varying scales. To address these limitations, this paper proposes a novel detection framework that leverages the hierarchical processing capabilities of nonlinear spiking neural P (NSNP) systems. The proposed framework introduces three key innovations: a bio-inspired convolution mechanism that captures fine-grained local features with neural dynamics; a semantic learning module enhanced by Contextual Transformer Attention for comprehensive global context understanding; and an adaptive mixed attention-based fusion strategy that optimizes cross-scale feature integration. The experimental results on four challenging benchmark datasets demonstrate that the proposed method outperforms fourteen other state-of-the-art methods, achieving average improvements of 1.02%, 1.3%, 2.3%, and 0.1% on the four evaluation metrics ( S m , E ξ m , F β w , and M A E ), respectively. These advances validate the potential of spiking neural P systems in salient object detection, while opening new possibilities for bio-inspired approaches in visual computing.},
  archive      = {J_NEUCOM},
  author       = {Nan Zhou and Minglong He and Hong Peng and Zhicai Liu},
  doi          = {10.1016/j.neucom.2025.129821},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129821},
  shortjournal = {Neurocomputing},
  title        = {A novel multi-scale salient object detection framework utilizing nonlinear spiking neural p systems},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Local and global spatial–temporal transformer for
skeleton-based action recognition. <em>NEUCOM</em>, <em>634</em>,
129820. (<a href="https://doi.org/10.1016/j.neucom.2025.129820">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skeleton-based action recognition represents a dynamic and expanding research domain in computer vision. Currently, GCN-based methods primarily rely on the graph topology to capture dependencies between joints, however, they are limited in the ability to capture long-distance dependencies. On the other hand, transformer-based methods have also been applied to skeleton-based action recognition, as transformers prove effective in capturing long-distance dependencies. Nevertheless, most transformer-based methods directly calculate pairwise global self-attention of all nodes in both spatial and temporal dimensions, making it challenging to distinguish the correlation between short-distance joints and underestimate the impact of short-term temporal dynamics. Additionally, some existing methods often utilize multi-stream fusion to combine features from different modalities, neglecting the fusion of low-level information from these modalities. In this work, we propose a novel L ocal and G lobal S patial– T emporal Trans former network (LG-STFormer) containing two key components: (1) LGA-module: local and global attention module. The LGA-module enables the model to capture richer temporal and spatial information. It consists of two parts: skeleton topology constraint spatial transformer (STC-SFormer) and attention-enhanced multiscale TCN (AM-TCN). The STC-SFormer focuses on the correlation between local joints and distant joints in the spatial dimension, while the AM-TCN integrates the global self-attention mechanism into multi-scale temporal convolution to capture local and global temporal motion patterns of joints effectively. (2) JBC-Fusion-module: The module consists of joint-bone cross fusion transformer (JBC-Former) and AM-TCN. Utilizing dynamic generation method for complementary features, the JBC-Former facilitates the fusion of low-level information between complementary features. Finally, we make extensive experiments on the NTU-RGB+D, NTU-RGB+D 120, and NW-UCLA datasets to show the competitive performance of the proposed LG-STFormer in the field of skeleton-based action recognition.},
  archive      = {J_NEUCOM},
  author       = {Ruyi Liu and Yu Chen and Feiyu Gai and Yi Liu and Qiguang Miao and Shuai Wu},
  doi          = {10.1016/j.neucom.2025.129820},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129820},
  shortjournal = {Neurocomputing},
  title        = {Local and global Spatial–Temporal transformer for skeleton-based action recognition},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GKA: Graph-guided knowledge association for fine-grained
visual categorization. <em>NEUCOM</em>, <em>634</em>, 129819. (<a
href="https://doi.org/10.1016/j.neucom.2025.129819">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained visual categorization aims to distinguish highly similar subclasses by exploiting subtle differences. However, existing methods predominantly emphasize the extraction of visual cues from individual images, overlooking the exploration of semantic relationships within and across classes. To this end, we introduce a novel approach termed Graph-based Knowledge Association (GKA). Specifically, we employ a positional embedding to model the relationship between instances in the feature space, and adaptively mine the connections between features of different instances via a graph neural network. The framework effectively aggregates features from neighboring nodes to enhance the understanding of discriminative features by exploiting complementary information between instances. Furthermore, a plain knowledge-guided module embeds this relational knowledge into the training of the backbone network for discriminative feature extraction, thus improving fine-grained classification performance. Empirical evaluations on four benchmark datasets for Fine-grained Visual Categorization (FGVC) demonstrate that our method achieves state-of-the-art (SOTA) performance.},
  archive      = {J_NEUCOM},
  author       = {Yuetian Wang and Shuo Ye and Wenjin Hou and Duanquan Xu and Xinge You},
  doi          = {10.1016/j.neucom.2025.129819},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129819},
  shortjournal = {Neurocomputing},
  title        = {GKA: Graph-guided knowledge association for fine-grained visual categorization},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STAD-AI: Spatio-temporal anomaly detection in videos with
attentive dual-stage integration. <em>NEUCOM</em>, <em>634</em>, 129817.
(<a href="https://doi.org/10.1016/j.neucom.2025.129817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel and comprehensive framework for video anomaly detection, distinguished by its specialized spatio-temporal feature extraction and precise anomaly prediction capabilities. The proposed system employs an advanced spatio-temporal attention-based framework designed for effective video frame reconstruction. By isolating and amplifying critical feature regions within the frames, it enables the extraction of fine-grained spatial and temporal representations, which are crucial for detecting subtle anomalies. Complementing this, an attentive U-Net architecture is employed to predict anomalies with high precision, incorporating motion features to enhance temporal coherence and anomaly localization. The attention mechanism in both components is strategically designed to focus on critical areas within each frame and sequence, where abnormal activities are likely to occur, improving detection accuracy and reducing false positives. The two components are seamlessly integrated using a fusion strategy, combining their complementary strengths to enhance the system’s overall robustness and effectiveness. Extensive evaluations on benchmark datasets, including UCSD Peds1, UCSD Peds2, CUHK Avenue, and ShanghaiTech, demonstrate that STAD-AI achieves superior performance with AUC scores of 86.6%, 99.1%, 91.4%, and 77.7%, respectively. These results highlight the framework’s ability to effectively leverage spatial and temporal features for detecting anomalies with high precision, advancing the state-of-the-art in video anomaly detection.},
  archive      = {J_NEUCOM},
  author       = {Rangachary Kommanduri and Mrinmoy Ghorai},
  doi          = {10.1016/j.neucom.2025.129817},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129817},
  shortjournal = {Neurocomputing},
  title        = {STAD-AI: Spatio-temporal anomaly detection in videos with attentive dual-stage integration},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fractional gannet humming optimization enabled deep
convolutional neural network for detection and segmentation of skin
cancer. <em>NEUCOM</em>, <em>634</em>, 129816. (<a
href="https://doi.org/10.1016/j.neucom.2025.129816">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin cancer is a dangerous disorder that is caused by an unchecked proliferation of aberrant skin cells that produce genetic mutations on the skin. When ultraviolet (UV) radiation from sunshine or tanning beds damages the skin cells in a way that leads to their rapid multiplication and formation of malignant tumours. Certain forms of skin cancer metastasize along nerves. This results in tingling, pain, itching, numbness, or a sensation like ants crawling under the skin. Skin cancer spreads to deeper tissues, including cartilage, muscle, and bone. The earlier prediction of skin lesions increases the possibility of survival rate. However, during diagnosis, an anomalous finding is made, and the condition is diagnosed as cancer. To overcome these challenges, a novel deep learning (DL) technique is developed in this research article for categorizing skin cancer by employing the proposed Fractional Gannet Humming Optimization_Deep Convolutional Neural Network (FGHO_DeepCNN). Initially, the input skin cancer image is subjected to the image pre-processing phase. The image pre-processing is done by the bilateral filter. Afterwards, skin lesion segmentation is carried out using an encoder-decoder with Dense-Residual block (DRB), which is trained by the Fractional Gannet optimization algorithm (FGOA). Here, the FGOA is formed by the integration of the Fractional Calculus (FC) concept with the Gannet Optimization Algorithm (GOA). Thereafter, image augmentation is done to enlarge the segmented image using geometric and colour space transformation. After that, a feature extraction process is conducted to obtain the significant features, like Completed Local Binary Pattern (CLBP), Gray Level Co-occurrence Matrix (GLCM), Local Vector Pattern (LVP), Significant Local Binary Pattern (SLBP) and CNN features. Finally, skin cancer detection is done using DeepCNN, which is tuned by the proposed FGHO. Here, the proposed FGHO is formed by the combination of FGOA with the artificial hummingbird algorithm (AHA). The experimental outcomes of the proposed FGHO_DeepCNN approach attained a better Positive Predictive Value (PPV), Negative Predictive Value (NPV), True Positive Rate (TPR), and True Negative Rate (TNR), and accuracy with values of 89.80 %, 89.40 %, 94.50 %, 94.00 % and 93.40 % respectively. The employed FGHO_DeepCNN has acquired excellent performance, thus achieving a PPV of 91.68 %, NPV of 88.46 %, TPR of 91.68 %, TNR of 91.23 % and accuracy of 90.67 % for dataset 2. In dataset 3, the FGHO_DeepCNN obtained superior performance than other techniques with a PPV of 90.56 %, NPV of 90.36 %, TPR of 90.95 %, TNR of 90.87 %, and accuracy of 90.15 %. The practical significance of the proposed FGHO_DeepCNN approach is that it is widely used in dermatology clinics and hospitals to detect skin cancer.},
  archive      = {J_NEUCOM},
  author       = {Aravapalli Rama Satish and Balajee Maram and Varaprasada Rao Perumalla and Mallikharjuna Rao K},
  doi          = {10.1016/j.neucom.2025.129816},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129816},
  shortjournal = {Neurocomputing},
  title        = {Fractional gannet humming optimization enabled deep convolutional neural network for detection and segmentation of skin cancer},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fairness in constrained spectral clustering.
<em>NEUCOM</em>, <em>634</em>, 129815. (<a
href="https://doi.org/10.1016/j.neucom.2025.129815">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised clustering methods have gained significant attention in both theoretical research and real-world applications, including economics, finance, marketing, and healthcare. Among these methods, constrained spectral clustering enhances clustering quality by incorporating pairwise constraints, namely, must-link and cannot-link constraints, which guide the clustering process by specifying whether certain data points should or should not belong to the same cluster. However, traditional constrained spectral clustering methods may inadvertently propagate biases present in the data or constraints, leading to unequal representation of sensitive groups, such as different genders or racial groups, across clusters. This imbalance raises concerns about fairness, an issue that remains largely unexplored in constrained spectral clustering. To address this gap, this paper proposes a novel method named fair-constrained Spectral Clustering (fair-cSC). The proposed method integrates fairness into the must-link and cannot-link constraints by defining a fair constraint matrix, ensuring that pairwise relationships do not introduce bias against any particular group. Additionally, a balance constraint is incorporated to enforce fairness across input data points, promoting equal representation of sensitive groups within clusters. Comprehensive experiments on six benchmarked datasets, including ablation studies, demonstrate that the proposed fair-cSC method effectively enhances fairness while preserving clustering quality. Furthermore, the ablation study provides insights into the method’s performance under different settings, reinforcing its robustness and applicability in real-world scenarios.},
  archive      = {J_NEUCOM},
  author       = {Laxita Agrawal and V. Vijaya Saradhi and Teena Sharma},
  doi          = {10.1016/j.neucom.2025.129815},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129815},
  shortjournal = {Neurocomputing},
  title        = {Fairness in constrained spectral clustering},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Text-driven human image generation with texture and pose
control. <em>NEUCOM</em>, <em>634</em>, 129813. (<a
href="https://doi.org/10.1016/j.neucom.2025.129813">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating high-quality and diverse human images solely based on textual prompts is a challenging task in computer vision and computer graphics. Existing models do not have stable generation capabilities, and their control over image generation is insufficient, requiring an additional densepose map to provide pose information. In this work, we present a text-driven human image generation model, which enables control over texture and pose through textual input. The framework consists of three stages: (1) generating a pose map from the pose description which achieves control over the pose information of the generated human image. (2) converting the pose map to a parsing map based on the shape description, and (3) generating the final image by using textual descriptions of clothes texture along with a quality enhancement network. For the texture learning stage, we construct a texture-aware codebook using FSQ, learning vector representations for different clothes fabrics and patterns. Furthermore, we fine-tune the diffusion model to equip it with the capability of image denoising and image refining, thus improving the quality of the generated images. Extensive experimental results demonstrate our model’s ability of generating realistic human body images that align with the semantics of the input text.},
  archive      = {J_NEUCOM},
  author       = {Zhedong Jin and Guiyu Xia and Paike Yang and Mengxiang Wang and Yubao Sun and Qingshan Liu},
  doi          = {10.1016/j.neucom.2025.129813},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129813},
  shortjournal = {Neurocomputing},
  title        = {Text-driven human image generation with texture and pose control},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancing DoA assessment through federated learning: A
one-shot pseudo data approach. <em>NEUCOM</em>, <em>634</em>, 129812.
(<a href="https://doi.org/10.1016/j.neucom.2025.129812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately measuring the Depth of Anaesthesia (DoA) during surgical procedures is crucial for patient safety. A significant challenge in developing effective machine learning models for DoA assessment is the lack of data from single organisations and preserving data privacy between institutions. Federated learning offers a solution by enabling multiple parties to collaboratively train models without exchanging data. However, traditional federated learning algorithms perform poorly in data heterogeneous, non-identically distributed data distribution scenarios. To address these challenges, we propose a one-shot federated learning framework, DoAFedP-NN, which facilitates federated learning with heterogeneous model development. The framework is tested in a range of model and data heterogeneity environments. This method enables the training of a global DoA prediction model across different medical facilities without sharing local data. The DoAFedP-NN model, utilising neural network design with entropy and spectral feature extraction, is compared to benchmark federated learning architectures, demonstrating its advantage in handling heterogeneous medical data. Experimental results show that DoAFedP-NN achieves robust DoA estimation when compared to the Bispectral (BIS) index, with high correlation coefficients of 0.8472 and 0.8542 across independent databases. The proposed model outperforms locally developed models, showing significant improvements when validated against external datasets from different medical facilities. This paper makes the key contributions: (1) introduces a one-shot pseudo-data method for federated learning; (2) demonstrates the effectiveness of this approach for EEG-based DoA using real-world databases; (3) showcases the model’s ability to achieve high correlation with the BIS index while preserving patient privacy in a range of client distribution scenarios and under cross-validation.},
  archive      = {J_NEUCOM},
  author       = {Thomas Schmierer and Tianning Li and Di Wu and Yan Li},
  doi          = {10.1016/j.neucom.2025.129812},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129812},
  shortjournal = {Neurocomputing},
  title        = {Advancing DoA assessment through federated learning: A one-shot pseudo data approach},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HCKGL: Hyperbolic collaborative knowledge graph learning for
recommendation. <em>NEUCOM</em>, <em>634</em>, 129808. (<a
href="https://doi.org/10.1016/j.neucom.2025.129808">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the integration of knowledge graph and recommendation system has become a hot topic. Its popular solution is firstly combining the knowledge graph and user–item interaction graph to generate a unified Collaborative Knowledge Graph (CKG), and then learn the representations of users and items by applying graph convolutional networks to aggregate high-order neighbor information between entities in CKG. However, existing related methods mainly focus on learning representations in the Euclidean space, posing challenges in capturing the hierarchical structure and intricate relational logic between users and items. In view of this, we propose a novel hyperbolic CKG learning model HCKGL for recommendation, which leverages relation-specific curvature and attention-based geometric transformations to preserve the inherent features of CKG. Additionally, we address two significant challenges that existing methods have often overlooked. Firstly, in order to capture the relationship dependencies between neighbors and accurately calculate the contribution of neighbor information, we propose a hyperbolic graph attention network (HGAT), which combines the curvature of the relationship to assign weights. Secondly, we present a new graph contrastive learning technique (HMCL) that utilizes the hyperbolic embedding propagation and multi-level contrastive learning to improve the representations of users and items. Comprehensive experimental results on two widely used datasets demonstrate that HCKGL outperforms state-of-the-art baselines. The source code for our model is publicly available at: https://github.com/GDM-SCNU/HCKGL .},
  archive      = {J_NEUCOM},
  author       = {Huijuan Hu and Chaobo He and Xinran Chen and Quanlong Guan},
  doi          = {10.1016/j.neucom.2025.129808},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129808},
  shortjournal = {Neurocomputing},
  title        = {HCKGL: Hyperbolic collaborative knowledge graph learning for recommendation},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature expansion and enhanced compression for class
incremental learning. <em>NEUCOM</em>, <em>634</em>, 129807. (<a
href="https://doi.org/10.1016/j.neucom.2025.129807">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class incremental learning consists in training discriminative models to classify an increasing number of classes over time. However, doing so using only the newly added class data leads to the known problem of catastrophic forgetting of the previous classes. Recently, dynamic deep learning architectures have been shown to exhibit a better stability-plasticity trade-off by dynamically adding new feature extractors to the model in order to learn new classes followed by a compression step to scale the model back to its original size, thus avoiding a growing number of parameters. In this context, we propose a new algorithm that enhances the compression of previous class knowledge by cutting and mixing patches of previous class samples with the new images during compression using our Rehearsal-CutMix method. We show that this new data augmentation reduces catastrophic forgetting by specifically targeting past class information and improving its compression. Extensive experiments performed on the CIFAR and ImageNet datasets under diverse incremental learning evaluation protocols demonstrate that our approach consistently outperforms the state-of-the-art . The code will be made available upon publication of our work 1 .},
  archive      = {J_NEUCOM},
  author       = {Quentin Ferdinand and Benoit Clement and Panagiotis Papadakis and Quentin Oliveau and Gilles Le Chenadec},
  doi          = {10.1016/j.neucom.2025.129807},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129807},
  shortjournal = {Neurocomputing},
  title        = {Feature expansion and enhanced compression for class incremental learning},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bioinspired model of decision making guided by reward
dimensions and a motivational state. <em>NEUCOM</em>, <em>634</em>,
129806. (<a href="https://doi.org/10.1016/j.neucom.2025.129806">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The decision-making process is a critical component of computational systems, whose processing involves the evaluation of various alternatives presented as possible solutions to a given problem, depending on the current context. This paper seeks to show how a neuroscience-based decision-making mechanism (DMM) integrating decision criteria, knowledge of reward stimuli, and motivational information helps to contribute to producing human-like adaptive behavior. To fulfill this objective, a computational model on DMM is proposed. The alternatives in this proposed model are constructed based on preferences, and the selection of the best alternative is guided by a goal-directed control scheme influenced by a motivational state (MS). The formation of preferences considers some dimensions of the reward, e.g., magnitude, probability of receiving the reward, incentive salience, and affective value. To validate the model exhibits a behavior considering parameters human being uses to compute its behavior, a case study was proposed. The case study’s objective is to gain the maximum reward (food) from the choice of a 4-choice card (a variation of Iowa Gambling Test), each card has a reward and a contingency probability associated with it. The analysis of the results of the case study shows that the model presents a short exploitation stage to find the contingency rule and choose the best option frequently according to some studies, also observed that the utility value of the card influenced the MS of hunger and other factors play a critical role in the DMM.},
  archive      = {J_NEUCOM},
  author       = {Diana G. Gómez-Martínez and Alison Muñoz-Capote and Oscar Hernández and Francisco Robles and Félix Ramos},
  doi          = {10.1016/j.neucom.2025.129806},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129806},
  shortjournal = {Neurocomputing},
  title        = {A bioinspired model of decision making guided by reward dimensions and a motivational state},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SSDM: Generated image interaction method based on spatial
sparsity for diffusion models. <em>NEUCOM</em>, <em>634</em>, 129805.
(<a href="https://doi.org/10.1016/j.neucom.2025.129805">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image interaction methods based on diffusion models are significantly superior to traditional methods. However, due to its slow sampling speed and high computational complexity, it could be more conducive to image editing applications. To address these issues, we propose a generated image interaction method based on spatial sparsity diffusion models (SSDM), which utilizes the spatial sparsity of the differences between the edited and original images to reduce computational complexity and accelerate image generation. It takes sparse block data as a constraint, uses difference masks, converts it into an index, and learns the spatial sparse features of differences to describe the image, thereby reducing the network parameters and computational complexity during the training process. In addition, the “overlap-add” and “overlap-save” mechanisms are used to ensure coherence and consistency between different boundaries. It also compensates and trains the sampled feature maps by reusing low-frequency information and introduces L p -norm to replace Euclidean distance to calculate the loss function, thereby enhancing the reconstruction effect of high-frequency image features. Compared to the original methods, experiments on the LSUN and CelebA-HQ datasets show that the proposed method has achieved better performance of PSNR by improving 1.2 dB, reduced computational complexity by 4.1 × , and increased processing speed by 3.6 × .},
  archive      = {J_NEUCOM},
  author       = {Zhuochao Yang and Jingjing Liu and Haozhe Zhu and Jianhua Zhang and Wanquan Liu},
  doi          = {10.1016/j.neucom.2025.129805},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129805},
  shortjournal = {Neurocomputing},
  title        = {SSDM: Generated image interaction method based on spatial sparsity for diffusion models},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Backpropagation-based learning with local derivative
approximation and memory replay in biologically plausible neural
systems. <em>NEUCOM</em>, <em>634</em>, 129804. (<a
href="https://doi.org/10.1016/j.neucom.2025.129804">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When learning, the brain modifies individual synaptic connections to reach a desired behavior. Animal and human brains have been shown to be incredibly capable of learning complex and varied functions across a wide variety of tasks. In recent years, artificial neural networks, inspired by human and animal brains, have shown great capabilities in learning a wide variety of difficult tasks. However, artificial neural networks primarily teach themselves through the use of backpropagation, a learning method which has no clear analogue within the brain. Additionally, Artificial Neural Networks primarily use continuous activation functions, which differ significantly from the spiking neuronal behavior present in the brain. In this paper, we discuss and demonstrate a biologically plausible learning method that approximates backpropagation through two techniques on Spiking Neural Networks. First, we show that the local temporal derivatives that are necessary for backpropagation can be approximately recovered through reconstruction using spike timings. Second, we show that through learning during a sleep phase, inspired by neuroscience research into memory replay, the localized parallel feedback path can learn to approximate the derivative through the forward path weight matrix, thus solving the weight transport problem. Finally, we demonstrate that the combination of these two methods can approach or exceed the accuracy of backpropagation-based methods for a variety of neuromorphic vision tasks while maintaining biological plausibility.},
  archive      = {J_NEUCOM},
  author       = {Richard Boone and Peng Li},
  doi          = {10.1016/j.neucom.2025.129804},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129804},
  shortjournal = {Neurocomputing},
  title        = {Backpropagation-based learning with local derivative approximation and memory replay in biologically plausible neural systems},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven stabilization for linear sampled-data systems
with unknown parameters: A pure data analytics perspective.
<em>NEUCOM</em>, <em>634</em>, 129798. (<a
href="https://doi.org/10.1016/j.neucom.2025.129798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the sampled-data stabilization problem for a class of linear systems with unknown parameters, incorporating a data analytics perspective. Traditional sampled-data controller design methods are rendered ineffective due to the lack of knowledge about the system parameters. To address this challenge, a data-driven approach is proposed for designing a sampled-data stabilization controller using an offline-collected data set, eliminating the need for prior knowledge of the plant parameters. Specifically, a novel sampled-data control strategy with a matrix exponential gain is introduced to stabilize the system. The controller gain is designed based on data insights derived from offline information, without requiring access to the system matrices. Leveraging data-driven techniques and Lyapunov stability theory, sufficient conditions are established to guarantee the exponential stability of the system. The proposed sampled-data controller with matrix exponential gain significantly extends the maximum allowable sampling intervals compared to conventional methods. To optimize performance, a convex optimization approach is utilized to maximize the bounds of these sampling intervals. The efficacy of the proposed approach is validated through a practical example involving an operational amplifier circuit, demonstrating the power of integrating data analytics into control design for unknown-parameter systems.},
  archive      = {J_NEUCOM},
  author       = {Luyang Yu and Jiayi Ding and Ying Cui and Yurong Liu and Yamin Wang},
  doi          = {10.1016/j.neucom.2025.129798},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129798},
  shortjournal = {Neurocomputing},
  title        = {Data-driven stabilization for linear sampled-data systems with unknown parameters: A pure data analytics perspective},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new minimalist time series reduction technique.
<em>NEUCOM</em>, <em>634</em>, 129772. (<a
href="https://doi.org/10.1016/j.neucom.2025.129772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose in this paper a minimalist time series reduction technique that comes with a new distance. The proposed technique relies on the extraction of a minimal number of salient features of a time series, which are leveraged by the new distance to perform time series classification. We prove in this paper that the new proposed distance lower bounds the Euclidean distance and has a tighter lower bound than Piecewise Aggregation Approximation. Furthermore, we conduct experiments using standard UCR univariate time series datasets and include a comparative study of the new proposed technique with related SAX and deep learning based time series reduction and classification techniques. The experiments show that the new distance based time series classification enjoys better accuracy results than classifications based on well-known distances and is competitive to deep learning based time series classification techniques.},
  archive      = {J_NEUCOM},
  author       = {Hamdi Yahyaoui and Hosam AboElFotoh and Yanjun Shu and Tianrun Gao},
  doi          = {10.1016/j.neucom.2025.129772},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129772},
  shortjournal = {Neurocomputing},
  title        = {A new minimalist time series reduction technique},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deformable symmetry attention for nuclear medicine image
segmentation. <em>NEUCOM</em>, <em>634</em>, 129757. (<a
href="https://doi.org/10.1016/j.neucom.2025.129757">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prior knowledge of the medical domain has consistently enriched medical image analysis, yet its full potential remains to be explored. Our Deformable Symmetry Attention (DSA) aims to leverage anatomical symmetry prior, commonly used by clinicians, to enhance the automated analysis of medical images, especially in inherently grainy nuclear medicine images. DSA processes an explicit feature alignment attention. It starts with a prior alignment by reflecting the input image to leverage symmetry, followed by a fine-grained alignment using deformable image registration. Our novel Rotational Spatial Transformation Function (RSTF) enhances the registration by estimating local displacement with rotation in relative coordinates, enforcing local smoothness under anatomical variations. Additionally, the Attention Redistribution (AR) module addresses pixel-level mismatch in grainy nuclear medicine images by a set of learnable Gaussian kernels. By translating the anatomical symmetry prior into a locality prior, DSA seamlessly integrates with and enhances sophisticated convolutional neural networks (CNNs) and transformer-based segmentation models. In our study, the DSA framework, when combined with robust baseline models, demonstrated significant performance enhancements across multiple challenging medical imaging tasks. Specifically, it achieved a 3.8% to 8.48% improvement in segmenting lesions in adolescent Whole-Body Bone Scans (WBS) and a 2.88% improvement in the extended 3D MRI brain tumor segmentation experiment. Additionally, the method was validated in asymmetric scenarios, showing an improvement of 0.63% to 10.57% in chest X-ray anatomical segmentation. These results underscore DSA’s effectiveness and versatility across diverse experimental settings. It presents a novel and promising perspective for explicitly leveraging prior knowledge in medical image analysis.},
  archive      = {J_NEUCOM},
  author       = {Zeao Zhang and Pei Yang and Ruomeng Liu and Huawei Cai and Zhen Zhao and Quan Guo and Zhang Yi},
  doi          = {10.1016/j.neucom.2025.129757},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129757},
  shortjournal = {Neurocomputing},
  title        = {Deformable symmetry attention for nuclear medicine image segmentation},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Audio–visual self-supervised representation learning: A
survey. <em>NEUCOM</em>, <em>634</em>, 129750. (<a
href="https://doi.org/10.1016/j.neucom.2025.129750">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence developers leverage the inherent relationships among video, text, and audio to create enhanced representations of the world, mirroring the way humans use multiple senses to understand their environment. As such, multimodal learning, which integrates various data input modalities to augment the learning of intrinsic features, has been gaining traction. While applications in multimodal understanding have made strides with deep learning, they often rely heavily on supervised learning and extensive human annotation. This paper provides a comprehensive review of audio–visual self-supervised learning, a promising alternative that uses vast amounts of unlabeled data. It holds the potential to reshape areas like computer vision, and speech recognition. We begin by explaining the concept of audio–visual modalities in machine learning and then move into their role within self-supervised learning by discussing terminology, general pipelines, and underlying motivations. This is followed by an exploration of common pretext tasks in audio–visual self-supervised learning, along with the evaluation methods, datasets, and downstream tasks associated with it. We then highlight prevailing challenges in both audio–visual and self-supervised learning realms. The paper concludes by presenting open challenges, suggesting avenues for future research in this dynamic domain.},
  archive      = {J_NEUCOM},
  author       = {Manal AlSuwat and Sarah Al-Shareef and Manal AlGhamdi},
  doi          = {10.1016/j.neucom.2025.129750},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129750},
  shortjournal = {Neurocomputing},
  title        = {Audio–visual self-supervised representation learning: A survey},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on self-adaptive grid point cloud down-sampling
method based on plane fitting and mahalanobis distance gaussian
weighting. <em>NEUCOM</em>, <em>634</em>, 129746. (<a
href="https://doi.org/10.1016/j.neucom.2025.129746">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this manuscript, a self-adaptive grid point cloud down-sampling method based on plane fitting was proposed, which could effectively reduce redundant data while better preserving the geometric features of the original model and maintaining high accuracy. This method first constructs initial voxel grids and divides the grids into large density and small density ones according to the point cloud density. After that, for small density grids, the boundary points are extracted first, and the rest areas are uniformly sampled, while for large density grids, a method based on Mahalanobis distance Gaussian weighting is proposed and adopted to estimate the normal vector of points, and feature points are determined and retained by calculating the information entropy. Then, three models in the public dataset, the Cat model, Bed_0355 model and Fandisk model, were employed as test subjects to compare the proposed method with two commonly used down-sampling methods: uniform sampling and voxel grid sampling methods. The results indicated that this new method was able to better retain the geometric features of the original models, especially high curvature and sharp parts, with smaller errors and fewer holes. Finally, this method was applied to the down-sampling of 3D scanning point clouds of two typical metal machine parts, threaded joint and sheet metal part, and the measured results demonstrated that this method not only effectively preserved the model features, but also guaranteed accuracy of key geometric dimensions after high reduction ratio down-sampling, such as the relative errors of thread tooth angles and hole inner diameters being less than 1 %.},
  archive      = {J_NEUCOM},
  author       = {Hongfei Zu and Jing Zhu and Xinfeng Wang and Xiang Zhang and Ning Chen and Gangxiang Guo and Zhangwei Chen},
  doi          = {10.1016/j.neucom.2025.129746},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129746},
  shortjournal = {Neurocomputing},
  title        = {Research on self-adaptive grid point cloud down-sampling method based on plane fitting and mahalanobis distance gaussian weighting},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LTB-solver: Long-tailed bias solver for image synthesis of
diffusion models. <em>NEUCOM</em>, <em>634</em>, 129651. (<a
href="https://doi.org/10.1016/j.neucom.2025.129651">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Though diffusion models have shown the merits of generating high-quality visual data while preserving better diversity in recent studies, they do not generalize well on long-tailed datasets due to the minority classes lacking of diversity and semantic information. To overcome the aforementioned challenges, we first take a closer look at the collapse of tail category patterns under long-tail distributed data and propose an alternative but easy-to-use and effective solution, a L ong- T ailed B ias Solver in diffusion model image synthesis ( LTB-Solver ), which thereby enhances the overall diversity and quality of synthetic samples building upon the properties of the long-tailed distribution training data. Especially, we extract rich generative distribution knowledge of ‘head’ categories within proxy model and transfer the head-tail consistency distance to ‘tail’ categories, enabling the target diffusion model to learn diverse generation preserving inter-sample variation during the diffusion training process. Moreover, we incorporate the minority guidance loss function that better aligns training objectives with sampling behaviors and adjust the loss values for different classes by multiplying them with different weights. Extensive experiments are conducted on various datasets and several state-of-the-art diffusion model frameworks to verify the effectiveness of the proposed method. The results show that our method significantly improves the performance of diffusion models on long-tailed datasets by a large margin.},
  archive      = {J_NEUCOM},
  author       = {Siming Fu and Xiaoxuan He and Haoji Hu},
  doi          = {10.1016/j.neucom.2025.129651},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129651},
  shortjournal = {Neurocomputing},
  title        = {LTB-solver: Long-tailed bias solver for image synthesis of diffusion models},
  volume       = {634},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accurate binary neural network based on rich information
flow. <em>NEUCOM</em>, <em>633</em>, 129837. (<a
href="https://doi.org/10.1016/j.neucom.2025.129837">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The binary neural network (BNN) compresses network parameters significantly, greatly reducing storage consumption and resource usage. This also means extremely low inference power consumption, making it a primary method for deploying machine learning on edge devices. However, due to this, there is a significant decrease in accuracy compared to full-precision networks, which restricts its potential for further advancement. To address this challenge, this study introduces the following novel contributions: (1) Introducing an innovative BNN structure named Rich Information Flow Network (RIF-Net) for amplitude correction, which effectively alleviates the information bottleneck in BNN and thus enhances its accuracy. (2) Incorporating additional shortcut connections and Batch Normalization (BN) layers into the architecture to further mitigate the impact of binary convolution on the output feature map&#39;s numerical distribution. (3) To demonstrate RIF-Net&#39;s performance on edge devices, the study implements the RIF-Net architecture on an FPGA development board. The experimental results show that RIF-Net can achieve the most advanced performance. For example, we achieved a Top-1 accuracy of 63.3 % on ImageNet using the ResNet-18 framework and a 1.0 % absolute accuracy improvement on the CIFAR-10 dataset using the ResNet-20 framework compared to other state-of-the-art methods. The RIF-Net accelerator implemented on the FPGA showcases precise real-time image classification capabilities.},
  archive      = {J_NEUCOM},
  author       = {Shilong Zhang and Xiaobo Zhou and Siyuan Chen},
  doi          = {10.1016/j.neucom.2025.129837},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129837},
  shortjournal = {Neurocomputing},
  title        = {Accurate binary neural network based on rich information flow},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dynamic-static feature fusion learning network for speech
emotion recognition. <em>NEUCOM</em>, <em>633</em>, 129836. (<a
href="https://doi.org/10.1016/j.neucom.2025.129836">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech is a paramount mode of human communication, and enhancing the quality and fluency of Human-Computer Interaction (HCI) greatly benefits from the significant contribution of Speech Emotion Recognition (SER). Feature representation poses a persistent challenge in SER. A single feature is difficult to adequately represent speech emotion, while directly concatenating multiple features may overlook the complementary nature and introduce interference due to redundant information. Towards these difficulties, this paper proposes a Multi-feature Learning network based on Dynamic-Static feature Fusion (ML-DSF) to obtain an effective hybrid feature representation for SER. Firstly, a Time-Frequency domain Self-Calibration Module (TFSC) is proposed to help the traditional convolutional neural networks in extracting static image features from the Log-Mel spectrograms. Then, a Lightweight Temporal Convolutional Network (L-TCNet) is used to acquire multi-scale dynamic temporal causal knowledge from the Mel Frequency Cepstrum Coefficients (MFCC). At last, both extracted features groups are fed into a connection attention module, optimized by Principal Component Analysis (PCA), facilitating emotion classification by reducing redundant information and enhancing the complementary information between features. For ensuring the independence of feature extraction, this paper adopts the training separation strategy. Evaluating the proposed model on two public datasets yielded a Weighted Accuracy (WA) of 93.33 % and an Unweighted Accuracy (UA) of 93.12 % on the RAVDESS dataset, and 94.95 % WA and 94.56 % UA on the EmoDB dataset. The obtained results outperformed the State-Of-The-Art (SOTA) findings. Meanwhile, the effectiveness of each module is validated by ablation experiments, and the generalization analysis is carried out on the cross-corpus SER tasks.},
  archive      = {J_NEUCOM},
  author       = {Peiyun Xue and Xiang Gao and Jing Bai and Zhenan Dong and Zhiyu Wang and Jiangshuai Xu},
  doi          = {10.1016/j.neucom.2025.129836},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129836},
  shortjournal = {Neurocomputing},
  title        = {A dynamic-static feature fusion learning network for speech emotion recognition},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bilinear-experts network with self-adaptive sampler for
long-tailed visual recognition. <em>NEUCOM</em>, <em>633</em>, 129832.
(<a href="https://doi.org/10.1016/j.neucom.2025.129832">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-tail distributed data hinders the practical application of state-of-the-art deep models in computer vision. Consequently, exclusive methodologies for handling the long-tailed problem are proposed, focusing on different hierarchies. For embedding hierarchy, existing works manually augment the diversity of tail-class features for specific datasets. However, prior knowledge about datasets is not always available for practical use, which brings unsatisfactory generalization ability in human fine-turned augmentation under such circumstances. To figure out this problem, we introduce a novel model named Bilinear-Experts Network (BENet) with Self-Adaptive Sampler (SAS). This model leverages model-driven perturbations to tail-class embeddings while preserving generalization capability on head classes through a designed bilinear experts system. The designed perturbations adaptively augment tail-class space and shift the class boundary away from the tail-class centers. Moreover, we find that SAS automatically assigns more significant perturbations to specific tail classes with relatively fewer training samples, which indicates SAS is capable of filtering tail classes with lower quality and enhancing them. Also, experiments conducted across various long-tailed benchmarks validate the comparable performance of the proposed BENet.},
  archive      = {J_NEUCOM},
  author       = {Qin Wang and Sam Kwong and Xizhao Wang},
  doi          = {10.1016/j.neucom.2025.129832},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129832},
  shortjournal = {Neurocomputing},
  title        = {Bilinear-experts network with self-adaptive sampler for long-tailed visual recognition},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A review of SCADA-based condition monitoring for wind
turbines via artificial neural networks. <em>NEUCOM</em>, <em>633</em>,
129830. (<a href="https://doi.org/10.1016/j.neucom.2025.129830">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the supervisory control and data acquisition (SCADA) data has gained increasing research attention in the field of wind turbine condition monitoring. Artificial intelligence (AI) techniques have been widely applied to address condition monitoring challenges, and artificial neural networks (ANNs), recognized as a foundational component of modern AI, have proven to be particularly effective tools. Wind turbine condition monitoring focuses on analyzing the operational parameters of turbines to realize early fault detection, precise diagnostics, and accurate prognostics, thereby mitigating the risk of catastrophic faults, enhancing system reliability, and improving wind farm operational efficiency. Due to inherent issues in raw SCADA data, including missing values and abnormal data, preprocessing steps such as data cleaning are critical before feeding the data into ANN models. Additionally, the choice of ANN architecture typically depends on the specific requirements of condition monitoring tasks (e.g., fault detection, diagnosis, or prediction/prognosis) and the characteristics of SCADA datasets such as imbalance problem of fault samples. Hence, current research with respect to wind turbine condition monitoring generally follows two approaches: (1) utilizing classification models to identify fault types at specific time points, and (2) employing regression models to construct normal behavior models (NBMs) or track and predict continuous key performance indicators. This survey systematically reviews SCADA-based wind turbine condition monitoring methods within five years, emphasizing neural networks as key approaches, and structures the discussion around three core aspects: data preprocessing, classification models, and regression models. Moreover, the comparative strengths, capabilities, and limitations of various ANNs in each link are discussed. By providing an in-depth analysis, this paper aims to offer theoretical and practical insights to support the further development of condition monitoring technologies for wind turbines.},
  archive      = {J_NEUCOM},
  author       = {Li Sheng and Chunyu Li and Ming Gao and Xiaopeng Xi and Donghua Zhou},
  doi          = {10.1016/j.neucom.2025.129830},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129830},
  shortjournal = {Neurocomputing},
  title        = {A review of SCADA-based condition monitoring for wind turbines via artificial neural networks},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zero-shot low-dose CT denoising across variable schemes via
strip-scanning diffusion models. <em>NEUCOM</em>, <em>633</em>, 129828.
(<a href="https://doi.org/10.1016/j.neucom.2025.129828">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artifacts and noise in low-dose CT (LDCT) may degrade image quality, potentially impacting subsequent diagnoses. In recent years, supervised image post-processing methods have been extensively studied for their effectiveness in noise reduction. However, clinical conditions often make it difficult to obtain paired normal-dose and low-dose CT images. Additionally, scanning protocols in clinical settings are diverse, necessitating different thickness or dose settings, which further complicates and increases the cost of low-dose data collection. These challenges limit the practical application and widespread adoption of supervised methods. This study introduces a novel end-to-end zero-shot strip-scanning diffusion model (SSDiff) that requires only a single model trained on normal-dose CT (NDCT) images to achieve LDCT image denoising across various scanning protocols with different slice thicknesses, doses, or devices. The sampling process employs a strip scanning strategy that combines overlapping strip information and input LDCT images to solve the maximum a posteriori problem to produce denoising results sequentially. We use only simple convolutional and attentional architectures and perform extensive experiments on three different datasets involving different doses, thicknesses, and devices; the results show that our method outperforms supervised methods in most cases, and visualization and blinded evaluations indicate that our method is very close to NDCT.},
  archive      = {J_NEUCOM},
  author       = {Bo Su and Jiabo Xu and Xiangyun Hu and Yunfei Zha and Jun Wan and Jiancheng Li},
  doi          = {10.1016/j.neucom.2025.129828},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129828},
  shortjournal = {Neurocomputing},
  title        = {Zero-shot low-dose CT denoising across variable schemes via strip-scanning diffusion models},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LN-DETR: An efficient transformer architecture for lung
nodule detection with multi-scale feature fusion. <em>NEUCOM</em>,
<em>633</em>, 129827. (<a
href="https://doi.org/10.1016/j.neucom.2025.129827">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lung cancer remains one of the leading causes of mortality worldwide, and early detection is crucial for improving patient survival rates. Traditional lung nodule detection methods are inefficient and inaccurate, making them inadequate for clinical needs. Although deep learning methods have made progress in medical image analysis, existing approaches still perform poorly in detecting small, morphologically complex lung nodules, leading to missed detections and false positives. Additionally, the high computational complexity of previous models hinders real-time detection. To address these challenges, this study proposes a Transformer-based lung nodule detection model called LN-DETR. The model integrates a Partial Convolution-based Efficient Multi-scale Attention (PC-EMA) module, a Grouped and Shuffled Convolutional Cross-scale Feature Fusion (GS-CCFM) module, and introduces a Channel Transformer (CTrans) module. PC-EMA combines Efficient Multi-Scale Attention with partial convolution to enhance multi-scale feature extraction while optimizing computational efficiency. GS-CCFM uses Grouped and Shuffled Convolution (GSConv) to achieve efficient cross-scale feature fusion. The CTrans module employs a cross-channel attention mechanism to further strengthen feature fusion capabilities. Experimental results on the LUNA16 and Tianchi lung nodule datasets demonstrate that LN-DETR outperforms existing object detection models in detection accuracy, computational efficiency, and model complexity. On the LUNA16 dataset, LN-DETR achieved an F1 score of 91.5% and a mean Average Precision (mAP) of 93.1%; on the Tianchi dataset, the F1 score was 87.4% and the mAP was 86.4%, both significantly higher than baseline models. Furthermore, the reduced parameter count and computational overhead make the model more suitable for broader clinical applications.},
  archive      = {J_NEUCOM},
  author       = {Jiade Tang and Xiao Chen and Linyuan Fan and Zhenliang Zhu and Chen Huang},
  doi          = {10.1016/j.neucom.2025.129827},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129827},
  shortjournal = {Neurocomputing},
  title        = {LN-DETR: An efficient transformer architecture for lung nodule detection with multi-scale feature fusion},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Observer-based adaptive neural network force tracking
control for pneumatic polishing system end-effector with actuator
saturation. <em>NEUCOM</em>, <em>633</em>, 129824. (<a
href="https://doi.org/10.1016/j.neucom.2025.129824">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the issue of addressing an adaptive neural network dynamic contact force tracking control for pneumatic polishing system end-effector with unmeasurable states and unknown environmental model. To tackle this problem, we utilize a neural network to approximate uncertain nonlinear functions in end-effector system model and design a neural network state observer to estimate unmeasurable states. Additionally, we combine the saturation characteristics of the pneumatic actuator and set the end-effector input voltage saturation condition. By employing the adaptive backstepping approach and the finite time convergence theory, we formulate an adaptive neural network force tracking control method. The proposed control scheme ensures the input and state stability of the end-effector of the pneumatic polishing system, and the ability to accurately track the desired contact force signal in a finite time is verified by stability analysis. Finally, the effectiveness and superiority of the proposed control scheme is verified through the tracking control experiments of static contact and dynamic contact in a variety of polishing scenarios, which provides a new idea for the application of pneumatic technology in polishing scenarios.},
  archive      = {J_NEUCOM},
  author       = {Zhiguo Yang and Jiange Kou and Zhanxin Li and Yushan Ma and Wenbo Zhao and Yixuan Wang and Yan Shi},
  doi          = {10.1016/j.neucom.2025.129824},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129824},
  shortjournal = {Neurocomputing},
  title        = {Observer-based adaptive neural network force tracking control for pneumatic polishing system end-effector with actuator saturation},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correlation-based switching mean teacher for semi-supervised
medical image segmentation. <em>NEUCOM</em>, <em>633</em>, 129818. (<a
href="https://doi.org/10.1016/j.neucom.2025.129818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mean teacher framework is one of the mainstream approaches in semi-supervised medical image segmentation. While training together in the traditional mean teacher framework, the teacher model and the student model share the same structure. An Exponential Moving Average (EMA) updating strategy is applied to optimize the teacher model. Although the EMA approach facilitates a smooth training process, it causes the model coupling and error accumulation problems. These issues constrain the model from precisely delineating the regions of pathological structures, especially for the low-contrast regions in medical images. In this paper, we propose a new semi-supervised segmentation model, namely Correlation-based Switching Mean Teacher (CS-MT), which comprises two teacher models and one student model to alleviate these problems. Particularly, two teacher models adopt a switching training strategy at every epoch to avoid the convergence and similarity between the teacher models and the student model. In addition, we introduce a feature correlation module in each model to leverage the similarity information in the feature maps to improve the model’s predictions. Furthermore, the stochastic process of CutMix operation destroys the structures of organs in medical images, generating adverse mixed results. We propose an adaptive CutMix manner to mitigate the negative effects of these mixed results in model training. Extensive experiments validate that CS-MT outperforms the state-of-the-art semi-supervised methods on the LA, Pancreas-NIH, ACDC and BraTS 2019 datasets.},
  archive      = {J_NEUCOM},
  author       = {Guiyuhan Deng and Hao Sun and Wei Xie},
  doi          = {10.1016/j.neucom.2025.129818},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129818},
  shortjournal = {Neurocomputing},
  title        = {Correlation-based switching mean teacher for semi-supervised medical image segmentation},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DiffuseVAE++: Mitigating training-sampling mismatch based on
additional noise for higher fidelity image generation. <em>NEUCOM</em>,
<em>633</em>, 129814. (<a
href="https://doi.org/10.1016/j.neucom.2025.129814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Denoising Diffusion Probabilistic Models (DDPMs) have demonstrated remarkable results in image generation. However, there exist a mismatch between the training and sampling process in current diffusion models, in addition, the U-Net denoising network based on simple residual blocks cannot predict noise information accurately, which affects the generated quality. To address these limitations, we present a novel image generation method that achieves higher fidelity. First, by additionally adding the standard Gaussian noise in the diffusion forward process, which does not disrupt the forward process, our method alleviates the mismatch. Subsequently, an important efficient denoising network based on U-Net is presented, where our proposed Simple Squeeze-Excitation and Simple GLU, combined with Depthwise Separable Convolution, enhance the ability of the model to predict real noise using the Simplified Nonlinear No Activation (SNNA) block. Furthermore, considering the structural characteristics of the baseline model, we introduce an additional cross-attention mechanism to enable DDPM to focus on VAE stage characteristics. Allowing the model to more accurately capture and learn the noise information. Finally, it is shown after extensive experiments the proposed DiffuseVAE++ obtains significant gains in FID scores, improving from 3.84 to 2.41 on CIFAR-10 and from 3.94 to 2.30 on CelebA-64. In particular, the IS scores on CIFAR-10 reaches 10.10, which is comparable to the current state-of-the-art methods competitively ( e.g., U-ViT , StyleGAN2 ).},
  archive      = {J_NEUCOM},
  author       = {Xiaobao Yang and Wei Luo and Hailong Ning and Guorui Zhang and Wei Sun and Sugang Ma},
  doi          = {10.1016/j.neucom.2025.129814},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129814},
  shortjournal = {Neurocomputing},
  title        = {DiffuseVAE++: Mitigating training-sampling mismatch based on additional noise for higher fidelity image generation},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CMGN: Text GNN and RWKV MLP-mixer combined with
cross-feature fusion for fake news detection. <em>NEUCOM</em>,
<em>633</em>, 129811. (<a
href="https://doi.org/10.1016/j.neucom.2025.129811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of social media, the influence and harm of fake news have gradually increased, making accurate detection of fake news particularly important. Current fake news detection methods primarily rely on the main text of the news, neglecting the interrelationships between additional texts. We propose a cross-feature fusion network with additional text graph construction to address this issue and improve fake news detection. Specifically, we utilize a text graph neural network (GNN) to model the graph relationships of additional texts to enhance the model’s perception capabilities. Additionally, we employ the RWKV MLP-mixer to process the news text and design a cross-feature fusion mechanism to achieve mutual fusion of different features, thereby improving fake news detection. Experiments on the LIAR, FA-KES, IFND, and CHEF datasets demonstrate that our proposed model outperforms existing methods in fake news detection.},
  archive      = {J_NEUCOM},
  author       = {ShaoDong Cui and Kaibo Duan and Wen Ma and Hiroyuki Shinnou},
  doi          = {10.1016/j.neucom.2025.129811},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129811},
  shortjournal = {Neurocomputing},
  title        = {CMGN: Text GNN and RWKV MLP-mixer combined with cross-feature fusion for fake news detection},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). H-SGANet: Hybrid sparse graph attention network for
deformable medical image registration. <em>NEUCOM</em>, <em>633</em>,
129810. (<a href="https://doi.org/10.1016/j.neucom.2025.129810">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of Convolutional Neural Networks (ConvNets) and Transformers has become a strong candidate for image registration, combining the strengths of both models and utilizing a large parameter space. However, this hybrid model, which treats brain MRI volumes as grid or sequence structures, struggles to accurately represent anatomical connectivity, diverse brain regions, and critical connections within the brain’s architecture. There are also concerns about the computational expense and GPU memory usage of this model. To address these issues, we propose a lightweight hybrid sparse graph attention network (H-SGANet). The network includes Sparse Graph Attention (SGA), a core mechanism based on Vision Graph Neural Networks (ViG) with predefined anatomical connections. The SGA module expands the model’s receptive field and integrates seamlessly into the network. To further enhance the hybrid network, Separable Self-Attention (SSA) is used as an advanced token mixer, combined with depth-wise convolution to form SSAFormer. This strategic integration is designed to more effectively extract long-range dependencies. As a hybrid ConvNet-ViG-Transformer model, H-SGANet offers three key benefits for volumetric medical image registration. It optimizes fixed and moving images simultaneously through a hybrid feature fusion layer and an end-to-end learning framework. Compared to VoxelMorph, a model with a similar parameter count, H-SGANet demonstrates significant performance enhancements of 3.5% and 1.5% in Dice score on the OASIS dataset and LPBA40 dataset, respectively. The code is publicly available at https://github.com/2250432015/H-SGANet/ .},
  archive      = {J_NEUCOM},
  author       = {Yufeng Zhou and Wenming Cao},
  doi          = {10.1016/j.neucom.2025.129810},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129810},
  shortjournal = {Neurocomputing},
  title        = {H-SGANet: Hybrid sparse graph attention network for deformable medical image registration},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decoupled contrastive learning for multilingual multimodal
medical pre-trained model. <em>NEUCOM</em>, <em>633</em>, 129809. (<a
href="https://doi.org/10.1016/j.neucom.2025.129809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multilingual multimodal pre-training aims to facilitate the integration of conceptual representations across diverse languages and modalities within a shared, high-dimensional semantic space. This endeavor in healthcare faces challenges related to language diversity, suboptimal multimodal interactions, and an absence of coherent multilingual multimodal representations. In response to these challenges, we introduce a novel multilingual multimodal medical pre-training model. Initially, we employ a strategic augmentation of the medical corpus by expanding the MIMIC-CXR report dataset to 20 distinct languages using machine translation techniques. Subsequently, we develop a targeted label disambiguation technique to address the labeling noise within decoupled contrastive learning. In particular, it categorizes and refines uncertain phrases within the clinical reports based on disease type, promoting finer-grained semantic similarity and improving inter-modality interactions. Building on these proposals, we present a refined multilingual multimodal medical pre-trained model, significantly enhancing the understanding of medical multimodal data and adapting the model to multilingual medical contexts. Experiments reveal that our model outperforms other baselines in medical image classification and multilingual medical image–text retrieval by up to 13.78% and 12.6%, respectively.},
  archive      = {J_NEUCOM},
  author       = {Qiyuan Li and Chen Qiu and Haijiang Liu and Jinguang Gu and Dan Luo},
  doi          = {10.1016/j.neucom.2025.129809},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129809},
  shortjournal = {Neurocomputing},
  title        = {Decoupled contrastive learning for multilingual multimodal medical pre-trained model},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EPAM-net: An efficient pose-driven attention-guided
multimodal network for video action recognition. <em>NEUCOM</em>,
<em>633</em>, 129781. (<a
href="https://doi.org/10.1016/j.neucom.2025.129781">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing multimodal-based human action recognition approaches are computationally intensive, limiting their deployment in real-time applications. In this work, we present a novel and efficient pose-driven attention-guided multimodal network (EPAM-Net) for action recognition in videos. Specifically, we propose eXpand temporal Shift (X-ShiftNet) convolutional architectures for RGB and pose streams to capture spatio-temporal features from RGB videos and their skeleton sequences. The X-ShiftNet tackles the high computational cost of the 3D CNNs by integrating the Temporal Shift Module (TSM) into an efficient 2D CNN, enabling efficient spatiotemporal learning. Then skeleton features are utilized to guide the visual network stream, focusing on keyframes and their salient spatial regions using the proposed spatial–temporal attention block. Finally, the predictions of the two streams are fused for final classification. The experimental results show that our method, with a significant reduction in floating-point operations (FLOPs), outperforms and competes with the state-of-the-art methods on NTU RGB-D 60, NTU RGB-D 120, PKU-MMD, and Toyota SmartHome datasets. The proposed EPAM-Net provides up to a 72.8x reduction in FLOPs and up to a 48.6x reduction in the number of network parameters. The code will be available at https://github.com/ahmed-nady/Multimodal-Action-Recognition .},
  archive      = {J_NEUCOM},
  author       = {Ahmed Abdelkawy and Asem Ali and Aly Farag},
  doi          = {10.1016/j.neucom.2025.129781},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129781},
  shortjournal = {Neurocomputing},
  title        = {EPAM-net: An efficient pose-driven attention-guided multimodal network for video action recognition},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-modal feature symbiosis for personalized meta-path
generation in heterogeneous networks. <em>NEUCOM</em>, <em>633</em>,
129780. (<a href="https://doi.org/10.1016/j.neucom.2025.129780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In heterogeneous graph neural networks (HGNNs), the capture of intricate relationships among various types of entities is essential to achieve advanced machine learning applications. Heterogeneous Information Networks (HINs), composed of interconnected multi-type nodes and edges, face significant challenges in managing semantic diversity and inherent heterogeneity. Traditional methods, which rely on manually designed meta-paths, struggle to adapt dynamically to personalized needs and often neglect the integration of structural and attribute features. To address these limitations, this paper introduces the Cross-Modal Symbiotic Meta-Path Generator (CSMPG) framework. CSMPG integrates two key modules: a Cross-Modal State Generation Module that encodes node structure and attribute information into task-aware state vectors and a Personalized Meta-Path Generation Module that dynamically generates and refines meta-paths using reinforcement learning. By leveraging downstream task feedback, CSMPG optimizes path selection to maximize performance. The framework effectively balances cross-modal feature integration and semantic diversity, uncovering impactful meta-paths that are often overlooked by traditional approaches. Experimental results demonstrate that CSMPG consistently enhances recommendation quality and significantly outperforms structure-only and predefined-path-based models.},
  archive      = {J_NEUCOM},
  author       = {Xiaotong Wu and Liqing Qiu and Weidong Zhao},
  doi          = {10.1016/j.neucom.2025.129780},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129780},
  shortjournal = {Neurocomputing},
  title        = {Cross-modal feature symbiosis for personalized meta-path generation in heterogeneous networks},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zero-shot text-to-parameter realtime translation for game
character auto-creation and identity consistency editing.
<em>NEUCOM</em>, <em>633</em>, 129779. (<a
href="https://doi.org/10.1016/j.neucom.2025.129779">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern video games, character customization often requires adjusting numerous complex parameters, which can be inefficient. Consequently, there is growing interest in using text-based methods to generate 3D characters. The text-based method enhances players’ immersion in the game while improving development efficiency by simplifying the creation of diverse characters. This paper introduces a Text-to-Parameter Editable model (T2PE) that enables players to rapidly create high-quality game characters from textual descriptions. T2PE leverages supervision of CLIP to optimize both continuous and discrete facial parameters simultaneously. This differs from existing Text-to-Parameter (T2P) models, which rely on evolutionary search algorithm that interacts with the game engine to optimize discrete parameters. We also propose a game character editing method that allows modifications using new textual descriptions while preserving other features. Our experimental results show that the proposed model generates higher-quality 3D game characters than T2P models while significantly reducing latency. We observe that T2PE achieves 26x faster inference times and 3.3% increase in CLIP score on lower TFLOPS devices. To the best of our knowledge, T2PE is the first algorithm to support both text-based character generation and text-based character editing. Building upon this, we develop Fast-T2PE, an end-to-end translator trained using text–parameter pairs obtained from T2PE, which enables even faster generation of game characters. Experimental results show that Fast-T2PE further reduces response latency by 62.5% compared to T2PE.},
  archive      = {J_NEUCOM},
  author       = {Tao Wu and Xu Lu and Jia Yu and Weijun Cao and Wei Chen and Haidi Fan and Zhiqiang Zhang and Gen Dong and Siwei Zhou},
  doi          = {10.1016/j.neucom.2025.129779},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129779},
  shortjournal = {Neurocomputing},
  title        = {Zero-shot text-to-parameter realtime translation for game character auto-creation and identity consistency editing},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A variable-gain fixed-time convergent neurodynamic network
for time-variant quadratic programming under unknown noises.
<em>NEUCOM</em>, <em>633</em>, 129778. (<a
href="https://doi.org/10.1016/j.neucom.2025.129778">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a variable-gain fixed-time convergent and noise-tolerant error-dynamics based neurodynamic network (VGFxTNT-EDNN) to solve time-varying quadratic programming problems, while being robust to unknown noises. Unlike existing finite-time convergent EDNNs, the newly designed VGFxTNT-EDNN guarantees fixed-time convergence by dynamically adjusting its variable parameters. Moreover, the VGFxTNT-EDNN effectively handles unknown noise, addressing a limitation of existing fixed-time or predefined-time convergent models, which typically assume that the noise is known. Theoretical analysis utilizing Lyapunov theory proves that the VGFxTNT-EDNN possesses fixed-time convergence and robustness properties. Numerical validations demonstrate superior noise tolerance and fixed-time convergence of the VGFxTNT-EDNN, as compared with the existing models. Finally, a path-tracking experiment is conducted by utilizing a Franka Emika Panda robot to verify the practicality of the VGFxTNT-EDNN.},
  archive      = {J_NEUCOM},
  author       = {Biao Song and Tinghe Hong and Weibing Li and Gang Chen and Yongping Pan and Kai Huang},
  doi          = {10.1016/j.neucom.2025.129778},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129778},
  shortjournal = {Neurocomputing},
  title        = {A variable-gain fixed-time convergent neurodynamic network for time-variant quadratic programming under unknown noises},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LAR-pose: Lightweight human pose estimation with adaptive
regression loss. <em>NEUCOM</em>, <em>633</em>, 129777. (<a
href="https://doi.org/10.1016/j.neucom.2025.129777">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, LAR-Pose, a lightweight, high-resolution network for human pose estimation driven by adaptive regression loss is proposed and experimentally demonstrated based on MS COCO and MPII. The architecture of the LAR-Pose comprises two main components. One is a lightweight high-resolution backbone network, which utilizes a parallel high-resolution architecture with conditional channel weighting block to reduce the model size and computational complexity. The other is a dynamic residual refinement network, which calculates residuals from pseudo-heatmaps and scaling factors, improving training concentration for consistent distribution estimation, rather than predicting coordinates or heatmaps directly. Specific coordinates are derived through integral heatmap regression, effectively minimizing quantization errors. Our adaptive regression loss, which uses a flow model to fit the distribution of residuals in real-time, provides more sensitive parameter feedback than conventional heatmap loss, ensuring differentiability and continuity during backpropagation while enhancing performance. With a relatively small parameter scale, LAR-Pose achieves an AP of 73.5 on MS COCO and a PCKh of 90.9 on MPII, while the results outperform most advanced small networks and approach the performance of large networks.},
  archive      = {J_NEUCOM},
  author       = {Xudong Lou and Xin Lin and Henan Zeng and Xiangxian Zhu},
  doi          = {10.1016/j.neucom.2025.129777},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129777},
  shortjournal = {Neurocomputing},
  title        = {LAR-pose: Lightweight human pose estimation with adaptive regression loss},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Passivity for undirected and directed fractional-order
complex networks with adaptive output coupling. <em>NEUCOM</em>,
<em>633</em>, 129774. (<a
href="https://doi.org/10.1016/j.neucom.2025.129774">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the passivity for adaptive output coupled fractional-order complex networks (CNs) under undirected and directed topologies is studied by selecting appropriate coupling weight adjustment strategies, based on which the output synchronization for the presented networks is discussed by leveraging the properties of Mittag-Leffler functions and the Laplace transform technique. Utilizing the developed distributed adaptive schemes, several passivity criteria for the fractional-order CNs with output coupling are derived. Moreover, several output synchronization conditions for the output coupled fractional-order CNs are given by employing the acquired passivity results. Ultimately, simulations from numerical examples are utilized to judge the effectiveness for the adaptive laws and the presented criteria.},
  archive      = {J_NEUCOM},
  author       = {Jin-Liang Wang and Chen-Guang Liu and Shun-Yan Ren and Tingwen Huang},
  doi          = {10.1016/j.neucom.2025.129774},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129774},
  shortjournal = {Neurocomputing},
  title        = {Passivity for undirected and directed fractional-order complex networks with adaptive output coupling},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automatic diagnosis of early pregnancy fetal nasal bone
development based on complex mid-sagittal section ultrasound imaging.
<em>NEUCOM</em>, <em>633</em>, 129773. (<a
href="https://doi.org/10.1016/j.neucom.2025.129773">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early prenatal screening of fetal nasal bone (FNB) development is crucial for detecting chromosomal abnormalities. Existing deep learning approaches primarily focus on detection rather than diagnosis of FNB. This paper introduces an early prenatal FNB development automated diagnostic system (FNB-ADS), which employs a cascaded hierarchical filtering method to reduce noise interference in mid-sagittal plane ultrasound images. Specifically, the system employs YOLOv8 for precise FNB localization, segments the nasal bone, tip, and prenasal skin using a specially designed lightweight segmentation network, and diagnoses developmental abnormalities using Resnet34 classification methods. Furthermore, this paper has collected and publicly released the FNB-UDV dataset, which includes a detection subset and a video subset. The detection subset contains 1,007 two-dimensional ultrasound images, while the video subset comprises 12 ultrasound videos. Upon a comprehensive evaluation, the diagnostic accuracy of FNB-ADS reaches 92.37% with a processing time of 0.14 s per image, and the video diagnostic accuracy is 98.69% with a per-frame inference speed of 0.37 s in the FNB-UDV dataset. Representing the first deep-learning approach tailored specifically for early pregnancy FNB ultrasound video diagnosis, FNB-ADS significantly enhances the standardization of diagnostic procedures and reduces the dependence on subjective clinical assessments. The dataset and code are available at https://github.com/SIGMACX/FNB-AD/tree/FNB-ADS .},
  archive      = {J_NEUCOM},
  author       = {Xi Chen and Xiaoyu Xu and Lyuyang Tong and Huangxuan Zhao and Bo Du},
  doi          = {10.1016/j.neucom.2025.129773},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129773},
  shortjournal = {Neurocomputing},
  title        = {Automatic diagnosis of early pregnancy fetal nasal bone development based on complex mid-sagittal section ultrasound imaging},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MCU-net: A multi-prior collaborative deep unfolding network
with gates-controlled spatial attention for accelerated MRI
reconstruction. <em>NEUCOM</em>, <em>633</em>, 129771. (<a
href="https://doi.org/10.1016/j.neucom.2025.129771">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep unfolding networks (DUNs) have shown promise in accelerating magnetic resonance imaging (MRI); however, they often face challenges such as high computational costs, slow convergence, and difficulty in fully exploiting complementarity in multiple priors. In the present study, we proposed a novel DUN, termed Multi-prior collaborative deep unfolding network (MCU-Net), to address these limitations. Our method features a parallel structure comprising different optimization-inspired subnetworks based on low-rank and sparsity, respectively. We designed a gates-controlled spatial attention module (GSAM), evaluating the relative confidence (RC) and overall confidence (OC) maps for intermediate reconstructions produced by different subnetworks. RC allocates greater weights to the image regions where each subnetwork excels, enabling precise element-wise collaboration. We designed correction modules to enhance the effectiveness in regions where both subnetworks exhibit limited performance, as indicated by low OC values, thereby obviating the need for additional branches. The gate units within GSAMs are designed to filter necessary information across multiple iterations, thus improving the accuracy of the learned confidence maps and enhancing robustness against accumulated errors. Through evaluating four datasets, MCU-Net outperforms state-of-the-art methods, achieving average PSNR improvements of 0.22, 0.24, 0.41 and 0.12 dB, respectively. Furthermore, applying the proposed strategy to various DUNs consistently results in accelerated convergence and improved reconstruction performance without extra FLOPs. Experimental results demonstrated that the proposed collaborative strategy can improve both reconstruction quality and computational efficiency compared to existing MRI reconstruction methods.},
  archive      = {J_NEUCOM},
  author       = {Xiaoyu Qiao and Weisheng Li and Guofen Wang and Yuping Huang},
  doi          = {10.1016/j.neucom.2025.129771},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129771},
  shortjournal = {Neurocomputing},
  title        = {MCU-net: A multi-prior collaborative deep unfolding network with gates-controlled spatial attention for accelerated MRI reconstruction},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MEAI-net: Multiview embedding and attention interaction for
multivariate time series forecasting. <em>NEUCOM</em>, <em>633</em>,
129769. (<a href="https://doi.org/10.1016/j.neucom.2025.129769">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series (MTS) forecasting plays a critical role in diverse societal applications, including stock market analysis and climate change research. While many existing deep learning models have been proven to be effective in MTS forecasting through complex neural network structures and self-attention mechanisms, several challenges remain: (1) insufficient modeling of complex temporal dependencies, (2) limited ability to handle information redundancy and noise, and (3) inadequate capture of periodic characteristics of time series. To address these problems, we propose a Multiview time-dependent feature Embedding and downsampled subsequences Attention Interaction Network (MEAI-Net) for MTS forecasting. First, MEAI-Net adopts a multiview time-dependent feature embedding mechanism to extract various temporal dependency features from the sequences. Second, it reduces redundancy in the temporal sequence features through downsampling. Third, a subsequences cross-attention module is introduced to enhance information exchange between subsequences. Furthermore, we propose the period consistency loss designed to more effectively capture periodic patterns in time series data. Comprehensive experiments conducted on 12 widely used time series datasets demonstrate that MEAI-Net displays promising performance, providing a competitive alternative to current state-of-the-art approaches in MTS forecasting.},
  archive      = {J_NEUCOM},
  author       = {Chunru Dong and Wenqing Xu and Feng Zhang and Qiang Hua and Yong Zhang},
  doi          = {10.1016/j.neucom.2025.129769},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129769},
  shortjournal = {Neurocomputing},
  title        = {MEAI-net: Multiview embedding and attention interaction for multivariate time series forecasting},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view clustering via view-specific consensus kernelized
graph learning. <em>NEUCOM</em>, <em>633</em>, 129766. (<a
href="https://doi.org/10.1016/j.neucom.2025.129766">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering has received extensive and in-depth research attention in recent years owing to its ability to reflect the nature of the real world from multiple perspectives. Kernel-based methods and subspace learning-based methods are two important categories of multi-view clustering. Compared with subspace-based algorithms, kernel-based algorithms can better address nonlinear relationships in feature spaces. However, the current kernel-based algorithms focus mainly on the diversity of different kernels, and obtaining the optimal kernel via linear combinations of multiple kernels, ignoring the cross-view information and space information in the original feature spaces. To address this issue, our paper proposes a novel algorithm named MC-VCKGL. Specifically, we first obtain view-specific consensus kernelized graphs of each view through kernel-based self-representation learning and by using the kernel trick. Moreover, Laplacian constraints are applied to maintain smoothness in the raw feature space of each view. We stack these kernelized graphs together to obtain a tensor, and then rotate this tensor and apply tensor nuclear norm constraints. As a result, the cross-view complementary information can be explored. We apply our algorithm to seven open datasets, including both text and image datasets. Experiments show that our method outperforms most state-of-the-art multi-view clustering algorithms.},
  archive      = {J_NEUCOM},
  author       = {Bing Hu and Tong Wu and Lixin Han and Shu Li and Yi Xu and Gui-fu Lu},
  doi          = {10.1016/j.neucom.2025.129766},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129766},
  shortjournal = {Neurocomputing},
  title        = {Multi-view clustering via view-specific consensus kernelized graph learning},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Brain-like contour detector following retinex theory and
gestalt perception grouping principles. <em>NEUCOM</em>, <em>633</em>,
129765. (<a href="https://doi.org/10.1016/j.neucom.2025.129765">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous contour detection algorithms draw inspiration from biological vision systems. These algorithms imitate the way simple cells extract edges using Gabor filters. They also suppress edges generated by image textures simulating the non-classical receptive fields (NCRFs), thereby popping up the object contours within the image edges. However, these algorithms are not flawless and may yield imperfect results due to noise pollution, unsatisfactory lighting, limitations in image processing algorithms, and likewise. Weak strengths and pixel loss in contour segments are two common issues. In this paper, we provide two strategies to address these challenges. First, we separate the illumination component from the image following Retinex theory, extract the illumination contour using bio-inspired filters, and boost contour strengths by superimposing the illumination contour. Second, we complete object contours by filling small gaps in contours, using a proposed linking likelihood function that is a joint probability of element distance and orientation difference, following Gestalt perceptual grouping principles. Although not performance-oriented, the experimental results show that our endeavors improve the performance of bio-inspired contour detectors. More importantly, we demonstrate the significance of visual computation theories such as the Retinex theory and the Gestalt perception grouping principle for contour detection.},
  archive      = {J_NEUCOM},
  author       = {Rongtai Cai and Helin Que},
  doi          = {10.1016/j.neucom.2025.129765},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129765},
  shortjournal = {Neurocomputing},
  title        = {Brain-like contour detector following retinex theory and gestalt perception grouping principles},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attribute graph anomaly detection utilizing memory networks
enhanced by multi-embedding comparison. <em>NEUCOM</em>, <em>633</em>,
129762. (<a href="https://doi.org/10.1016/j.neucom.2025.129762">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In complex attribute networks, accurately pinpointing anomalous nodes is vital for grasping network behavior and safeguarding network security. Traditional anomaly detection methods often struggle to fully harness the intricate relationships that underpin attributes and structures, thus curbing their practical effectiveness. To transcend this limitation, we introduce a novel graph anomaly detection model that harmoniously integrates node attributes and structural information. Our model employs multi-embedding contrast modules, coupled with memory network enhancements, to pinpoint anomalous nodes. Precisely, we crafted a multi-embedding contrast module to encode the attributes and structures inherent within nodes, generating a multitude of embedding representations. By scrutinizing the discrepancies between these representations, our model adeptly identifies nodes that deviate from attribute and structural consistency, indicating anomalies. Furthermore, we incorporate a memory network to reconstruct node attributes, thereby enhancing the attribute decoding process while preserving the straightforwardness of structural decoding. To validate our method, we conducted extensive experiments on five authoritative public graph datasets, comparing various graph anomaly detection methods using rigorous metrics such as AUC, precision, and recall. The experimental results unequivocally demonstrate that our proposed method surpasses current state-of-the-art techniques in detecting anomalous nodes within graphs, solidly validating its efficacy.},
  archive      = {J_NEUCOM},
  author       = {Lianming Zhang and Baolin Wu and Pingping Dong},
  doi          = {10.1016/j.neucom.2025.129762},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129762},
  shortjournal = {Neurocomputing},
  title        = {Attribute graph anomaly detection utilizing memory networks enhanced by multi-embedding comparison},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Memory-based walk-enhanced dynamic graph neural network for
temporal graph representation learning. <em>NEUCOM</em>, <em>633</em>,
129759. (<a href="https://doi.org/10.1016/j.neucom.2025.129759">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depending on the ability of obtaining low-dimensional representations of nodes that preserve valuable structural information, graph representation learning has a wide range of applications in graph analysis and inference. However, real-world complex systems are naturally heterogeneous and time-varying, which makes it difficult to learn high-quality node representations. We propose a M emory-based W alk-enhanced D ynamic G raph neural N etwork (denoted as MWDGN) to fully exploit the dependencies and structural features in temporal graph. To capture long-term dependencies, we use a memory module to store and evolve dynamic node representations. MWDGN captures network structural information by constructing time-constrained walk sequences for each interaction node. The walk sequence features are creatively integrated into the update process of memory module, so as to capture the useful information of neighborhood structure features for the interaction node while preserving the long-term dependency of the temporal graph. In addition, we focus on the enlightenment of non-negligible temporal information for sensing key historical interaction nodes of the target node, and design a new aggregation method of historical interaction nodes information. It exploits the temporal attenuation effect of event impact to model short-term dependencies. We further exploit causal convolutional network to mine the potential associations of historical interaction node features of the target node. Comparison experiments on six datasets with mainstream baseline models demonstrate that MWDGN is capable of jointly extracting the heterogeneity and evolutionary patterns of nodes in the graph, improving the node representation quality, and enhancing the performance of the temporal link prediction and dynamic node classification tasks. The effectiveness of the proposed model is further proved by time complexity analysis, ablation study and parameter sensitivity analysis.},
  archive      = {J_NEUCOM},
  author       = {Zhigang Jin and Renjun Su and Hao Zhang and Xiaofang Zhao},
  doi          = {10.1016/j.neucom.2025.129759},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129759},
  shortjournal = {Neurocomputing},
  title        = {Memory-based walk-enhanced dynamic graph neural network for temporal graph representation learning},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inverse reinforcement learning by expert imitation for the
stochastic linear–quadratic optimal control problem. <em>NEUCOM</em>,
<em>633</em>, 129758. (<a
href="https://doi.org/10.1016/j.neucom.2025.129758">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies inverse reinforcement learning (IRL) for the linear–quadratic stochastic optimal control problem, where two agents are considered. A learner agent lacks knowledge of the expert agent’s cost function, but it reconstructs an underlying cost function by observing the expert agent’s states and controls, thereby imitating the expert agent’s optimal feedback control. We initially present a model-based IRL method, which consists of a policy correction and a policy update from the policy iteration in reinforcement learning, as well as a cost function weight reconstruction informed by the inverse optimal control. Afterward, under this scheme, we propose a model-free off-policy IRL method, which requires no system identification, only collecting behavior data from the learner agent and expert agent once during the iteration process. Moreover, the proofs of the method’s convergence, stability, and non-unique solutions are given. Finally, a numerical example and an inverse mean–variance portfolio optimization example are provided to validate the effectiveness of the presented method.},
  archive      = {J_NEUCOM},
  author       = {Zhongshi Sun and Guangyan Jia},
  doi          = {10.1016/j.neucom.2025.129758},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129758},
  shortjournal = {Neurocomputing},
  title        = {Inverse reinforcement learning by expert imitation for the stochastic linear–quadratic optimal control problem},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decoding before aligning: Scale-adaptive early-decoding
transformer for visual grounding. <em>NEUCOM</em>, <em>633</em>, 129756.
(<a href="https://doi.org/10.1016/j.neucom.2025.129756">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual grounding, the task of precisely localizing objects within an image as described by natural language expressions, has recently seen significant advancements through the integration of transformer decoders and early-fusion mechanisms. These approaches aim to enhance the decoding of crucial grounding-related semantics and the generation of discriminative representations. However, they display significant limitations, including reduced generalizability due to the need for custom plug-ins, a gap in effectively bridging decoded visual and linguistic features, and difficulties in processing single-scale features within complex, hierarchical scenes. To address these issues, this study introduces the Scale-Adaptive Early-Decoding Transformer (SA-EDTR), a novel approach that combines decoding and early-fusion mechanisms within a single transformer layer. By positioning the decoding stage before the alignment stage, the decoder adaptively generates richer, context-aware representations that guide the aligning module. This design allows SA-EDTR to effectively overcome previous limitations in feature alignment. Additionally, we integrate a Scale-Adaptive Fusion network (SAF) to fuse multi-scale and heterogeneous representations from parallel Early-Decoding Transformer layers, enhancing the capture of spatial, coarse, and fine-grained semantic details. Extensive experiments demonstrate that SA-EDTR outperforms current state-of-the-art methods in both REC and RES tasks across various mainstream visual grounding datasets, including RefCOCO, RefCOCO+, RefCOCOg-umd, and RefCOCOg-google. The results highlight the architecture’s remarkable capability in accurately localizing objects and interpreting intricate scenes.},
  archive      = {J_NEUCOM},
  author       = {Liuwu Li and Yi Cai and Jiexin Wang and Cantao Wu and Qingbao Huang and Qing Li},
  doi          = {10.1016/j.neucom.2025.129756},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129756},
  shortjournal = {Neurocomputing},
  title        = {Decoding before aligning: Scale-adaptive early-decoding transformer for visual grounding},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Second-order consensus of matrix-weighted switched
multiagent systems. <em>NEUCOM</em>, <em>633</em>, 129755. (<a
href="https://doi.org/10.1016/j.neucom.2025.129755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the switching characteristics of many practical multi-agent systems, such as automatic speed control systems and hybrid quadcopters, for multidimensional individuals, combined with practical complexity, matrix-weighted switching dynamics are needed to model them. This paper considers the consensus issues of second-order switched multi-agent systems on matrix-weighted undirected and directed networks. A new matrix-weighted control algorithm suitable for both CT and DT subsystems is proposed. Under the proposed algorithms, based on variable transformation, matrix theory and stability theory, the consensus criteria are established for undirected and directed switched multi-agent networks that rely on the eigenvalues of the network and coupling gains, respectively. This also indicates that the matrix-weights and coupling gains have a significant impact on switched matrix-weighted consensus. Finally, through simulations, the validity of the obtained results of this essay are verified.},
  archive      = {J_NEUCOM},
  author       = {Suoxia Miao and Housheng Su},
  doi          = {10.1016/j.neucom.2025.129755},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129755},
  shortjournal = {Neurocomputing},
  title        = {Second-order consensus of matrix-weighted switched multiagent systems},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-weighted subspace clustering with adaptive neighbors.
<em>NEUCOM</em>, <em>633</em>, 129754. (<a
href="https://doi.org/10.1016/j.neucom.2025.129754">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subspace clustering has attracted increasing attention in recent years owing to its ability to process high-dimensional data effectively. However, existing subspace clustering methods often assume that different features are equally important, and on this basis, a similarity matrix is constructed to generate the clustering structure. However, this practice may significantly affect the clustering performance in cases where the importance of different features significantly differs or where many noisy features exist in the original data. To address these challenges, we propose a novel self-weighted subspace clustering method with adaptive neighbors (SWSCAN). A feature weighting scheme is introduced to assign appropriate weights to different features. Then, we use the self-expressive property and adaptive neighbors approach to capture both the global and local structures within the weighted data space. Moreover, we employ the alternating direction method of multipliers (ADMM) to effectively solve the optimization problem of SWSCAN. Empirical results on both synthetic and practical datasets validate that our proposed method outperforms other comparative clustering techniques and can learn appropriate weights for features.},
  archive      = {J_NEUCOM},
  author       = {Zhengyan Liu and Huiwen Wang and Lihong Wang and Qing Zhao},
  doi          = {10.1016/j.neucom.2025.129754},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129754},
  shortjournal = {Neurocomputing},
  title        = {Self-weighted subspace clustering with adaptive neighbors},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Routeformer: Transformer utilizing routing mechanism for
traffic flow forecasting. <em>NEUCOM</em>, <em>633</em>, 129753. (<a
href="https://doi.org/10.1016/j.neucom.2025.129753">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction is vital for the development of intelligent transportation systems. The challenge lies in accurately capturing the complex and dynamic spatiotemporal dependencies influenced by real road network fluctuations. These dependencies can be simplified into three categories: (i) spatial dependencies among sensors at the same timestamp, (ii) temporal dependencies of the same sensor at different timestamps, and (iii) cross dimensional dependencies between different sensors at different timestamps. The third type of cross dimensional dependency requires considering the relationships between different sensors across multiple time points, which is not only complex but also difficult to capture accurately. Existing methods often describe it indirectly by merging spatiotemporal dependencies, but this approach is frequently insufficiently accurate. We aim to characterize this relationship more precisely by capturing the sequential dependencies among sensors, referred to as inter-series dependencies. Capturing inter-series dependencies does not require directly modeling the relationships between different sensors across multiple time points; rather, it focuses on the dependencies between the temporal patterns of different sensors. Our designed Temporal Routing Transformer captures temporal dependencies along the temporal axis while implicitly modeling the inter-series dependencies between sensors. At the same time, we capture spatial dependencies through the Spatial Routing Transformer and multi-scale temporal dependencies by using the Context-Aware Transformer. A series of evaluations were conducted on seven real world datasets, and Routeformer achieved state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Jun Qi and Hong Fan},
  doi          = {10.1016/j.neucom.2025.129753},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129753},
  shortjournal = {Neurocomputing},
  title        = {Routeformer: Transformer utilizing routing mechanism for traffic flow forecasting},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Few-shot medical relation extraction via prompt tuning
enhanced pre-trained language model. <em>NEUCOM</em>, <em>633</em>,
129752. (<a href="https://doi.org/10.1016/j.neucom.2025.129752">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical relation extraction is crucial for developing structured information to support intelligent healthcare systems. However, acquiring large volumes of labeled medical data is challenging due to the specialized nature of medical knowledge and privacy constraints. To address this, we propose a prompt-enhanced few-shot relation extraction (FSRE) model that leverages few-shot and prompt learning techniques to improve performance with minimal data. Our approach introduces a hard prompt concatenated to the original input, enabling contextually enriched learning. We calculate prototype representations by averaging the intermediate states of each relation class in the support set, and classify relations by finding the shortest distance between the query instance and class prototypes. We evaluate our model against existing deep learning based FSRE models using three biomedical datasets: the 2010 i2b2/VA challenge dataset, the CHEMPROT corpus, and the BioRED dataset, focusing on few-shot scenarios with limited training data. Our model demonstrates exceptional performance, achieving the highest accuracy across all datasets in most training configurations under a 3-way-5-shot condition and significantly surpassing the current state-of-the-art. Particularly, it achieves improvements ranging from 1.25% to 11.25% on the 2010 i2b2/VA challenge dataset, 3.4% to 20.2% on the CHEMPROT dataset, and 2.73% to 10.98% on the BioRED dataset compared to existing models. These substantial gains highlight the model’s robust generalization ability, enabling it to effectively handle previously unseen relations during testing. The demonstrated effectiveness of this approach underscores its potential for diverse medical applications, particularly in scenarios where acquiring extensive labeled data is challenging.},
  archive      = {J_NEUCOM},
  author       = {Guoxiu He and Chen Huang},
  doi          = {10.1016/j.neucom.2025.129752},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129752},
  shortjournal = {Neurocomputing},
  title        = {Few-shot medical relation extraction via prompt tuning enhanced pre-trained language model},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive multi-model fusion learning for sparse-reward
reinforcement learning. <em>NEUCOM</em>, <em>633</em>, 129748. (<a
href="https://doi.org/10.1016/j.neucom.2025.129748">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address intrinsic reward generation for sparse-reward reinforcement learning, where the agent receives limited extrinsic feedback from the environment. Traditional approaches to intrinsic reward generation often rely on prediction errors from a single model, where the intrinsic reward is derived from the discrepancy between the model’s predicted outputs and the actual targets. This approach exploits the observation that less-visited state–action pairs typically yield higher prediction errors. We extend this framework by incorporating multiple prediction models and propose an adaptive fusion technique specifically designed for the multi-model setting. We establish and mathematically justify key axiomatic conditions that any viable fusion method must satisfy. Our adaptive fusion approach dynamically learns the best way to combine prediction errors during training, leading to improved learning performance. Numerical experiments validate the effectiveness of our method, showing significant performance gains across various tasks compared to existing approaches.},
  archive      = {J_NEUCOM},
  author       = {Giseung Park and Whiyoung Jung and Seungyul Han and Sungho Choi and Youngchul Sung},
  doi          = {10.1016/j.neucom.2025.129748},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129748},
  shortjournal = {Neurocomputing},
  title        = {Adaptive multi-model fusion learning for sparse-reward reinforcement learning},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The SIFT based two-stage STC decoupled learning method for
long-tailed SAR target recognition. <em>NEUCOM</em>, <em>633</em>,
129747. (<a href="https://doi.org/10.1016/j.neucom.2025.129747">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In remote sensing (RS) research, Deep Learning (DL) based methods have been widely applied to Synthetic Aperture Radar (SAR) auto target recognition with extraordinary success. However, as the real-world SAR images often exhibit imbalanced data distribution, numerous existing DL approaches fail to deliver optimal performance when the dataset conforms to a long-tailed distribution. The long-tailed characteristics lead in learning bias towards the majority classes, resulting in poor performance on the minority classes. In response to this issue, this paper proposes a Scale Invariant Feature Transform (SIFT) based two-stage decoupled learning method for long-tailed SAR target recognition, named STC decoupled learning. The proposed STC decoupled learning method is consist of two stages: the feature extraction learning stage and the classifier fine-tuning stage. Specifically, a supervised contrastive learning module is incorporated to obtain feature representation on long-tailed SAR samples at the first stage. Then, classed-balanced samples are trained for fine-tuning a linear-layer-based classifier with cross-entropy loss at the second stage. Besides, SIFT feature extraction module is employed on these two stages, which substantially leverages physical scattering attribution of SAR images. Extensive simulations on long-tailed SAR-AIRcraft-1.0, FUSAR and MSTAR datasets validate that the proposed method achieves state-of-the-art classification accuracy on long-tailed SAR target recognition tasks, as well as superior generalization ability towards varying scenarios. Our code is now available on https://github.com/XYLGroup/STC .},
  archive      = {J_NEUCOM},
  author       = {Ye Li and Jingyuan Xia and Huaizhang Liao and Xu Lan and Weidong Jiang},
  doi          = {10.1016/j.neucom.2025.129747},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129747},
  shortjournal = {Neurocomputing},
  title        = {The SIFT based two-stage STC decoupled learning method for long-tailed SAR target recognition},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AA-mDLAM: An accelerated ADMM-based framework for training
deep neural networks. <em>NEUCOM</em>, <em>633</em>, 129744. (<a
href="https://doi.org/10.1016/j.neucom.2025.129744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic gradient descent (SGD) and its many variants are the widespread optimization algorithms for training deep neural networks. However, SGD suffers from inevitable drawbacks, including vanishing gradients, lack of theoretical guarantees, and substantial sensitivity to input. The Alternating Direction Method of Multipliers (ADMM) has been proposed to address these shortcomings as an effective alternative to the gradient-based methods. It has been successfully employed for training deep neural networks. However, ADMM-based optimizers have a slow convergence rate. This paper proposes an accelerated framework for training deep neural networks, termed AA-mDLAM, which integrates Anderson acceleration within an Alternating Minimization approach inspired by ADMM to tackle this drawback. The main intention of the AA-mDLAM algorithm is to employ Anderson acceleration to alternating minimization by considering it as a fixed-point iteration and attaining a nearly quadratic convergence rate. We verify the effectiveness and efficiency of the proposed AA-mDLAM algorithm by conducting extensive experiments on seven benchmark datasets contrary to other state-of-the-art optimizers.},
  archive      = {J_NEUCOM},
  author       = {Zeinab Ebrahimi and Gustavo Batista and Mohammad Deghat},
  doi          = {10.1016/j.neucom.2025.129744},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129744},
  shortjournal = {Neurocomputing},
  title        = {AA-mDLAM: An accelerated ADMM-based framework for training deep neural networks},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge graph embedding based on embedding permutation and
high-frequency feature fusion for link prediction. <em>NEUCOM</em>,
<em>633</em>, 129743. (<a
href="https://doi.org/10.1016/j.neucom.2025.129743">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph embedding has excellent performance in capturing intrinsic relations and semantics in a wealth of information for link prediction. Knowledge graph embedding methods have achieved impressive results in recent years, especially those using convolutional neural networks. However, many previous approaches focus on interactions between relations and entities, ignoring interactions of internal data elements and the crucial role of high-frequency features. In this paper, we propose a novel approach, a knowledge graph Embedding model using 2D convolution operations integrating Embedding permutation strategy and High-frequency features fusion mechanism, named EHE, for link prediction. First, we design the embedding permutation mechanism for the embedding vectors. This mechanism leverages internal element permutation, efficiently broadening the local interactions of internal elements, especially for far-flung data elements in the one-dimensional space. Subsequently, a high-frequency feature fusion module is proposed to capture the high-frequency feature representations by using Sobel and Laplacian operators. Additionally, the projection attention mechanism is utilized to emphasize the unique semantic regions of interest in entities and relations. We assess our approach on several benchmark link prediction datasets. Considering the important metrics, MRR and H@1, our method achieves the overall best performance compared with existing state-of-the-art methods on five public datasets, showcasing its superior capacity for link prediction.},
  archive      = {J_NEUCOM},
  author       = {Qien Yu and Danilo Vasconcellos Vargas},
  doi          = {10.1016/j.neucom.2025.129743},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129743},
  shortjournal = {Neurocomputing},
  title        = {Knowledge graph embedding based on embedding permutation and high-frequency feature fusion for link prediction},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rehearsal-free continual few-shot relation extraction via
contrastive weighted prompts. <em>NEUCOM</em>, <em>633</em>, 129741. (<a
href="https://doi.org/10.1016/j.neucom.2025.129741">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary challenge in continual few-shot relation extraction is mitigating catastrophic forgetting. Prevailing strategies involve saving a set of samples in memory and replaying them. However, these methods pose privacy and data security concerns. To address this, we propose a novel rehearsal-free approach called Contrastive Weighted Prompt (CWP). This approach categorizes learnable prompts into task-generic and task-specific prompts. Task-generic prompts are shared across all tasks and are injected into the higher layers of the BERT encoder to capture general task knowledge. Task-specific prompts are generated by weighting all the prompts in a task-specific prompt pool based on their relevance to individual samples. These task-specific prompts are injected into the lower layers of BERT to extract task-specific knowledge. Task-generic prompts retain knowledge from prior tasks, while task-specific prompts reduce mutual interference among tasks and improve the relevance between prompts and individual samples. To further enhance the discriminability of the prompt embeddings for samples belonging to different relations, we introduced a relation-aware contrastive learning strategy. Experimental results on two standard datasets indicate that the proposed method outperforms baseline methods and demonstrates superiority in mitigating catastrophic forgetting.},
  archive      = {J_NEUCOM},
  author       = {Fengqin Yang and Mengen Ren and Delu Kong and Shuhua Liu and Zhiguo Fu},
  doi          = {10.1016/j.neucom.2025.129741},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129741},
  shortjournal = {Neurocomputing},
  title        = {Rehearsal-free continual few-shot relation extraction via contrastive weighted prompts},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic neural learning for obstacle avoidance of humanoid
robot performing cooperative tasks. <em>NEUCOM</em>, <em>633</em>,
129727. (<a href="https://doi.org/10.1016/j.neucom.2025.129727">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to avoid the collision between a humanoid robot’s two manipulators is an important problem when two arms cooperate to perform the end task. In this paper, a dynamic neural learning for obstacle avoidance (DNLOA) scheme of a humanoid robot performing cooperative tasks is proposed. In this scheme, the trajectory tracking and mutual collision avoidance of the dual robot arms are converted to a quadratic programming (QP) framework, and the end-effector’s trajectory tracking, mutual collision avoidance and joint angle range are described as equality constraints or inequality constraints. Then the QP framework is solved by a simplified recurrent neural network (S-RNN). The framework is applied to the trajectory tracking tasks of drawing double crossed circles and writing Chinese characters with the humanoid robot’s dual manipulators. With the proposed DNLOA scheme, the tasks are done precisely without dual-arm mutual collision. Compared the scheme we proposed with the minimize velocity norm scheme (MVN) existed, experiments show that the proposed DNLOA scheme for humanoid robot is effective, accurate and practical.},
  archive      = {J_NEUCOM},
  author       = {Yamei Luo and Mingyang Zhang and Yu Liu and Junjie Lin and Zhijun Zhang},
  doi          = {10.1016/j.neucom.2025.129727},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129727},
  shortjournal = {Neurocomputing},
  title        = {Dynamic neural learning for obstacle avoidance of humanoid robot performing cooperative tasks},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). State prediction for multiple diffusion targets based on
point pattern physics-informed neural network. <em>NEUCOM</em>,
<em>633</em>, 129714. (<a
href="https://doi.org/10.1016/j.neucom.2025.129714">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {State prediction for multiple diffuse targets focuses on locating diffuse sources and concentration distributions. However, in real scenarios, problems such as multi-target overlap, unknown diffusion parameters, and difficult-to-measure environmental disturbances arise, causing the existing algorithms to have poor prediction accuracy. To address the above problems, this article proposes a multi-diffusion target state prediction algorithm based on point pattern physics-informed neural network (PP-PINN). This article targets the overlapping problem of multiple diffusion targets and uses the point pattern model to realize the accurate clustering of different diffusion targets and estimate their concentration distributions. Then, the physics-informed neural network is trained to estimate the diffusion parameters and modify the initial concentration distribution to reduce the environmental interference. The experimental results show that the proposed algorithm can significantly improve the performance of multi-diffusion target state prediction, and can provide important data support for the assessment of hazardous material leakage accidents.},
  archive      = {J_NEUCOM},
  author       = {Qiankun Sun and Lei Cai and Xiaochen Qin},
  doi          = {10.1016/j.neucom.2025.129714},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129714},
  shortjournal = {Neurocomputing},
  title        = {State prediction for multiple diffusion targets based on point pattern physics-informed neural network},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FMVP: Fine-grained meta visual prompt enabled
domain-specific few-shot classification. <em>NEUCOM</em>, <em>633</em>,
129688. (<a href="https://doi.org/10.1016/j.neucom.2025.129688">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning is a challenging and promising fundamental research. Inspired by recent advances in large language models (LLMs), visual prompt tuning has achieved notable performance gains in few-shot tasks by introducing only limited trainable parameters in the input space. Though effective, prompt tuning in few-shot settings heavily relies on well-initialized soft prompts and often lacks generalizability. Additionally, in certain specific fields, particularly in agriculture, there is a lack of high-precision fine-grained few-shot classification models. To our knowledge, this study is the first to employ prompt tuning for fine-grained few-shot plant disease classification ( specific to disease severity ). Specifically, we propose a novel F ine-grained M eta V isual P rompt tuning (FMVP) framework to systematically explore how visual prompts can enhance the generalizability of fine-grained few-shot domain-specific models. Firstly, a S parsity-aware M eta V isual P rompt tuning (SMVP) sub-module is proposed to learn a universal visual prompt initialization. SMVP utilizes pixel-level optimizable visual prompts for input transformation, jointly with a novel sparsity-aware meta-learning paradigm for parameter updating, boosting generalizability to unseen classes. Secondly, a F ine-grained C ross- A lignment (FCA) module is introduced to explore intra- and inter-image relational patterns, enhancing fine-grained recognition by extracting object-level cross-image semantic discriminative features. Extensive experiments on datasets such as mini -ImageNet, CUB, and FPV have shown that our model outperforms state-of-the-art (SOTA) models. Our work constitutes a valuable addition to domain-specific models for practical applications.},
  archive      = {J_NEUCOM},
  author       = {Minghui Li and Hongxun Yao},
  doi          = {10.1016/j.neucom.2025.129688},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129688},
  shortjournal = {Neurocomputing},
  title        = {FMVP: Fine-grained meta visual prompt enabled domain-specific few-shot classification},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary multi-objective neural architecture search via
depth equalization supernet. <em>NEUCOM</em>, <em>633</em>, 129674. (<a
href="https://doi.org/10.1016/j.neucom.2025.129674">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To provide a diverse selection of models suitable for different application scenarios, neural architecture search (NAS) is constructed as a multi-objective optimization problem aiming to simultaneously optimize multiple metrics such as model size and accuracy. Evolutionary algorithms (EA) have been shown to be an effective multi-objective approach that can balance different metrics. However, EA require many evaluations, and the evaluation of architectures is expensive. Training a supernet to evaluate an architecture is considered a promising method to reduce the cost of EA. But there are still many challenges in applying supernet to multi-objective NAS: (1) Supernet tends to give higher scores to shallower architectures, causing potential deeper architectures to be ignored. (2) The receptive field of the architecture has a large gap between search and evaluation, causing a decrease in performance. (3) Larger models are gradually eliminated during evolution, leading to a diversity disaster. We proposed a framework called DESEvo to solve these problems in this paper. DESEvo trains a depth equalization supernet to improve bias of supernet via a frequency rejection sampling method. In addition, DESEvo adaptively constrainted receptive field of architecture to reduce the gap. Finally, DESEvo developed a diversity-preserving strategy to enhance the diversity. Experimental results validate the efficiency and effectiveness of the algorithm, DESEvo can search a set of architectures that are more competitive compared to other state-of-the-art algorithms within 0.2 days, becoming the most efficient multi-objective NAS method in the supernet-based methods.},
  archive      = {J_NEUCOM},
  author       = {Juan Zou and Yang Liu and Yuan Liu and Yizhang Xia},
  doi          = {10.1016/j.neucom.2025.129674},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129674},
  shortjournal = {Neurocomputing},
  title        = {Evolutionary multi-objective neural architecture search via depth equalization supernet},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolving j-CO-QL+ with fuzzy evaluators for flexible
queryisng of JSON data sets. <em>NEUCOM</em>, <em>633</em>, 129621. (<a
href="https://doi.org/10.1016/j.neucom.2025.129621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to introduce soft querying based on fuzzy sets in the novel J-CO-QL + query language (specifically designed to query collections of JSON documents from NoSQL databases) has been investigated by the authors in their past work. Specifically, capabilities for defining fuzzy operators and fuzzy aggregators were introduced through two distinct concepts on which two different language constructs were based. This paper proposes the unified concept of “fuzzy evaluator”, by means of which it is possible to define complex methods for evaluating the membership degrees of JSON documents to fuzzy sets, so as to capture complex semantics while analyzing data in a soft way. The paper both provides a formal meta-model for fuzzy evaluators, and proposes a novel statement for the J-CO-QL + language, so as to further foster soft-querying capabilities.},
  archive      = {J_NEUCOM},
  author       = {Paolo Fosci and Giuseppe Psaila},
  doi          = {10.1016/j.neucom.2025.129621},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129621},
  shortjournal = {Neurocomputing},
  title        = {Evolving J-CO-QL+ with fuzzy evaluators for flexible queryisng of JSON data sets},
  volume       = {633},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structural investigations of multi-reservoir echo state
networks for EEG-based emotion classification. <em>NEUCOM</em>,
<em>632</em>, 129856. (<a
href="https://doi.org/10.1016/j.neucom.2025.129856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Echo State Networks (ESNs) employ non-gradient-based learning mechanisms that bypass backpropagation and pre-training, significantly reducing computational costs and training times, thus facilitating their widespread use in EEG analysis. To date, existing ESN architectures employed for EEG signal processing predominantly utilize single-layer reservoir structures, with limited research exploring the application of multi-reservoir ESN configurations that possess enhanced feature representation capabilities. This study addresses these gaps by proposing and validating three novel multi-reservoir ESN architectures: Pyramid ESN, Inverse Pyramid ESN, and Hourglass ESN, specifically for EEG-based emotion classification. Furthermore, the study introduces a concatenation mechanism that integrates the original data with the outputs from multiple reservoirs, thereby improving the representation power of multi-reservoir ESNs. The results indicate that the Hourglass ESN, which incorporates this concatenation mechanism, achieves the highest performance, yielding classification accuracies of 94.2 % and 94.3 % for arousal and valence, respectively, in binary classification tasks on the DEAP dataset. In four-class and eight-class tasks, accuracies reached 83.6 % and 78.7 %, respectively. Notably, the model demonstrates a 35.52 % average reduction in parameter complexity compared to single-layer ESNs, while achieving performance levels that meet the current state-of-the-art (SOTA) benchmarks for binary and four-class tasks, and exceed SOTA for the eight-class task. This study also investigates the impact of reservoir size on EEG-based emotion classification performance, revealing a saturation effect that provides valuable insights for the parameter design of multi-reservoir ESN models, enabling an optimal balance between computational efficiency and classification performance.},
  archive      = {J_NEUCOM},
  author       = {Yang Liu and Ruiqi Liang and Shule Xu and Xiang Guo},
  doi          = {10.1016/j.neucom.2025.129856},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129856},
  shortjournal = {Neurocomputing},
  title        = {Structural investigations of multi-reservoir echo state networks for EEG-based emotion classification},
  volume       = {632},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-security image steganography integrating multi-scale
feature fusion with residual attention mechanism. <em>NEUCOM</em>,
<em>632</em>, 129838. (<a
href="https://doi.org/10.1016/j.neucom.2025.129838">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constructing a good cost function is crucial for minimizing embedding distortion in image steganography. Recently, deep learning-based adaptive cost learning in image steganography has achieved significant advancements. For GAN-based image steganography, an encoder-decoder structure is typically employed by the generator. However, the continual encoding process often results in a lack of detailed information. Even if the image resolution is restored through skip connections, the generator will still be limited. To address the issue, this paper proposes a novel GAN structure named UMSA-GAN. Firstly, we design a residual attention mechanism, Res-CBAM, integrated into the generator network, which enables focusing on high-frequency regions in the cover image. Secondly, multi-scale feature information is also fused using skip connections, which enables the generator to learn more shallow features. Finally, unlike most of the previous works that only utilized Xu-Net as the discriminator, dual steganalyzers are also introduced as the discriminator to further enhance performance. Extensive comparative experiments demonstrate that UMSA-GAN effectively learns features from the cover images and generates better embedding probability maps. Compared to traditional and state-of-the-art GAN-based steganographic methods, UMSA-GAN exhibits superior security performance. In addition, the rationality and superiority of UMSA-GAN are further verified by a large number of ablation studies.},
  archive      = {J_NEUCOM},
  author       = {Jiaqi Liang and Wei Xie and Haotian Wu and Junfeng Zhao and Xianhua Song},
  doi          = {10.1016/j.neucom.2025.129838},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129838},
  shortjournal = {Neurocomputing},
  title        = {High-security image steganography integrating multi-scale feature fusion with residual attention mechanism},
  volume       = {632},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised medical image segmentation using spiking
neural p-like convolutional model and pseudo label-guided cross-patch
contrastive learning. <em>NEUCOM</em>, <em>632</em>, 129782. (<a
href="https://doi.org/10.1016/j.neucom.2025.129782">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based methods have achieved significant improvements in medical image segmentation in recent years. Due to the large amount of labeled data required for neural network training and the difficulty of medical image labeling, semi-supervised learning (SSL) has received great attention in medical image segmentation. However, existing SSL methods often fail to make full use of unlabeled data. Therefore, this study proposes a novel semi-supervised medical image segmentation framework that aims to produce more accurate predictions from unlabeled data. First, a simple and efficient segmentation network is designed, called UNet-ReS. It uses ResNet as the encoder to extract features, and uses spiking neural P-like convolutional neuron model inspired by nonlinear spiking neural P systems to build the decoder. UNet-ReS can generate high-quality unlabeled data prediction in a semi-supervised framework while obtaining reliable pseudo-label. Second, a pseudo-label guided cross-patch contrastive learning loss is proposed to improve the feature representation of deep semantic information from different classes in segmentation prediction. The intra-class aggregation and inter-class separability of deep semantic features from different classes are improved by minimizing the intra-class distance and maximizing the inter-class distance. This helps to improve the overall accuracy of segmentation predictions. The proposed method is validated on three different types of public datasets, including ACDC, Kvasir-SEG, and CRAG. The experimental results show that the proposed method outperforms other semi-supervised segmentation methods.},
  archive      = {J_NEUCOM},
  author       = {Chi Zhou and Lulin Ye and Hong Peng and Jun Wang and Zhicai Liu},
  doi          = {10.1016/j.neucom.2025.129782},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129782},
  shortjournal = {Neurocomputing},
  title        = {Semi-supervised medical image segmentation using spiking neural P-like convolutional model and pseudo label-guided cross-patch contrastive learning},
  volume       = {632},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event-based video reconstruction via attention-based
recurrent network. <em>NEUCOM</em>, <em>632</em>, 129776. (<a
href="https://doi.org/10.1016/j.neucom.2025.129776">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event cameras are novel sensors that capture brightness changes in the form of asynchronous events rather than intensity frames, offering unique advantages such as high dynamic range, high temporal resolution, and no motion blur. However, the sparse, asynchronous nature of event data poses significant challenges for visual perception, limiting compatibility with conventional computer vision algorithms that rely on dense, continuous frames. Event-based video reconstruction has emerged as a promising solution, though existing methods still face challenges in capturing fine-grained details and enhancing contrast. This paper presents a novel approach to video reconstruction from asynchronous event streams, leveraging the unique properties of event data to produce high-quality video. Our method integrates channel and pixel attention mechanisms to focus on essential features and incorporates deformable convolutions and adaptive mix-up operations to provide flexible receptive fields and dynamic fusion across down-sampling and up-sampling layers. Experimental results on multiple real-world event datasets demonstrate that our approach outperforms comparable methods trained on the same dataset, achieving superior video quality from pure event data. We also demonstrate the capability of our method for high dynamic range reconstruction and color video reconstruction using an event camera equipped with a Bayer filter.},
  archive      = {J_NEUCOM},
  author       = {Wenwen Ma and Shanxing Ma and Pieter Meiresone and Gianni Allebosch and Wilfried Philips and Jan Aelterman},
  doi          = {10.1016/j.neucom.2025.129776},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129776},
  shortjournal = {Neurocomputing},
  title        = {Event-based video reconstruction via attention-based recurrent network},
  volume       = {632},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bilateral-aware and multi-scale region guided u-net for
precise breast lesion segmentation in ultrasound images.
<em>NEUCOM</em>, <em>632</em>, 129775. (<a
href="https://doi.org/10.1016/j.neucom.2025.129775">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer ranks among the leading health risks for women globally, with the significance of early diagnosis and intervention being paramount. Using computers to segment breast lesions from ultrasound images serves as a crucial auxiliary tool for diagnosing and studying this disease. However, the effectiveness of breast tumor segmentation is deeply impacted by the severe artifacts, the low contrast, and the diverse tumor shapes found in breast ultrasound images. The focus of this study is to devise an effective strategy to further alleviate the aforementioned issues and achieve more precise lesion segmentation. Specifically, we designed a Bilateral-Aware and Multi-Scale Region Guided U-Net (BA-MRGU-Net) with a bilateral perception strategy to segment breast tumors. Initially, we devised a Foreground and Background Aware Module (FBAM), primarily composed of an Adaptive Spatial Selection Unit (ASSU) and a Background Suppression Unit (BSU). The ASSU can help the network capture spatial context information that is more relevant to lesions. Concurrently, the BSU suppresses the feature responses of ultrasound artifacts and other tissues in the background. The FBAM can effectively distinguish between the foreground and background through these two independent branches. Subsequently, we developed a Multi-Scale Region Guided Module (MRGM) to utilize the feature maps across various scales to boost the network’s perception of the lesion region. We executed a range of experiments utilizing two widely used datasets with several state-of-the-art algorithms. The results reveal that our approach achieves improvements of varying degrees on multiple evaluation metrics and has superior segmentation performance.},
  archive      = {J_NEUCOM},
  author       = {Yangyang Li and Xintong Hou and Xuanting Hao and Ronghua Shang and Licheng Jiao},
  doi          = {10.1016/j.neucom.2025.129775},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129775},
  shortjournal = {Neurocomputing},
  title        = {Bilateral-aware and multi-scale region guided U-net for precise breast lesion segmentation in ultrasound images},
  volume       = {632},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An o(1/k) algorithm for multi-agent optimization with
inequality constraints. <em>NEUCOM</em>, <em>632</em>, 129770. (<a
href="https://doi.org/10.1016/j.neucom.2025.129770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a discrete-time solution algorithm for a constrained multi-agent optimization problem with inequality constraints. Its aim is to seek a solution to minimize the sum of all the agents’ objective functions while satisfy each agent’s local set constraint and nonlinear inequality constraints. Assume that agents’ local constraints are heterogeneous and all the objective functions are convex and continuous, but they may not be differentiable. Similar to the distributed alternating direction method of multipliers (ADMM) algorithm, the designed algorithm can solve the multi-agent optimization problem in a distributed manner and has a fast O ( 1 / k ) convergence rate. Moreover, it can deal with the nonlinear constraints, which cannot be handled by distributed ADMM algorithm. Finally, the proposed algorithm is applied to solve a robust linear regression problem, a lasso problem and a decentralized joint flow and power control problem with inequality constraints, respectively and thus the effectiveness of the proposed algorithm is verified.},
  archive      = {J_NEUCOM},
  author       = {Peng Li and Yiyi Zhao and Jiangping Hu and Jiangtao Ji},
  doi          = {10.1016/j.neucom.2025.129770},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129770},
  shortjournal = {Neurocomputing},
  title        = {An o(1/k) algorithm for multi-agent optimization with inequality constraints},
  volume       = {632},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Words shaping worlds: A comprehensive exploration of
text-driven image and video generation with generative adversarial
networks. <em>NEUCOM</em>, <em>632</em>, 129767. (<a
href="https://doi.org/10.1016/j.neucom.2025.129767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A growing interest in education, media, and entertainment has increased Artificial Intelligence-powered content generation, mainly via Generative Adversarial Networks (GANs), which shape images, videos, audio, and text. A generative adversarial network (GAN) is the combination of two deep neural networks: generator ( G ) and discriminator ( D ). These two components are trained competitively by pitting one against the other such that G generates new data while D authenticates the data. By leveraging powerful deep neural networks and competitive training, GANs can synthesize reasonable and realistic images and videos from the text description. This paper extensively reviews the recent state-of-the-art GAN models for text-to-image (T2I) and text-to-video (T2V) synthesis. In this regard, databases like ACM, IEEE Explore, Web of Science, and ScienceDirect were searched to find and analyze the relevant research articles conducted in this area in the last decade, specifically from 2014 to 2024. Secondly, T2I and T2V GAN methods were classified according to structure and functionality. Later, a comprehensive evaluation between T2I and T2V GAN-based methods was conducted, employing various qualitative and quantitative evaluation techniques. Finally, the paper concludes by discussing multiple applications, main challenges, and limitations of T2I and T2V GAN models for future consideration.},
  archive      = {J_NEUCOM},
  author       = {Anwar Ullah and Muhammad Numan and Mohd Nor Akmal Khalid and Abdul Majid},
  doi          = {10.1016/j.neucom.2025.129767},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129767},
  shortjournal = {Neurocomputing},
  title        = {Words shaping worlds: A comprehensive exploration of text-driven image and video generation with generative adversarial networks},
  volume       = {632},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TDCR: Transformer based decision conflict resolution model
for collaborative scheduling. <em>NEUCOM</em>, <em>632</em>, 129760. (<a
href="https://doi.org/10.1016/j.neucom.2025.129760">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the strong adaptability and iterative capabilities of artificial intelligent algorithms, more and more enterprises are adopting human–machine collaboration to replace traditional enterprise management methods. So in recent years, the use of evolutionary algorithms and reinforcement learning methods to solve multi-objective optimization has made many breakthroughs, but in the intelligent manufacturing industry, such as production scheduling and inventory management and other aspects of decision optimization, because of the actual situation is too complicated, it is not conducive to determine the appropriate constraints, and then affect the performance of the model. This paper proposes a multi-decision optimization model for collaborative scheduling, which comprises two key components: a conflict resolution strategy module and a decision making module. This paper uses the attention mechanism to generate decision preference vectors in different manufacturing scenarios, so that the conflict resolution strategy can be dynamically changed and adds the keyword mask method close to downstream tasks during training to further improve the performance of the model. Finally, we evaluate the performance of our model in the conflict resolution task by selecting multiple data sets from multiple public data sets, and show satisfactory performance in this task, showing robustness in different scenarios. This study provides a valuable reference for conflict resolution between decision making.},
  archive      = {J_NEUCOM},
  author       = {Xiancheng Hu and Jian An and Xiaolin Gui and Long Chen and Siyu Tang and Xin He},
  doi          = {10.1016/j.neucom.2025.129760},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129760},
  shortjournal = {Neurocomputing},
  title        = {TDCR: Transformer based decision conflict resolution model for collaborative scheduling},
  volume       = {632},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Person verification and recognition by combining voice
signal and online handwritten signature using hyperbolic function based
transformer neural network. <em>NEUCOM</em>, <em>632</em>, 129751. (<a
href="https://doi.org/10.1016/j.neucom.2025.129751">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing popularity of smart portable electronic gadgets, various voice based online person verification systems have been developed. However, these systems are susceptible to attacks where an illegitimate individual feeds a recorded voice of a legitimate person, resulting in false confirmations. To overcome this limitation of voice based person verification systems, this article proposes a hyperbolic function based encoded representation of transformer neural network (ERTNN) framework for person verification and recognition by combining online handwritten signature of the genuine person with his/her voice signal. The proposed hyperbolic function based ERTNN framework for person verification and recognition consists of one multi-headed attention layer with positional encoding, seven convolution layers with skip connections, two dense layers, and an output layer. The positional encoding scheme in the proposed hyperbolic function based ERTNN framework has been implemented using hyperbolic s i n e and hyperbolic c o s i n e functions. The mel-frequency cepstral coefficients (MFCC), MFCC-delta, and MFCC-delta-delta features of the voice signal have been combined with all the temporal points of online handwritten signature sample of a person to make a combined feature matrix. The combined feature matrix of voice signal and online handwritten signature has been fed as an input to the proposed framework to verify and recognize a person corresponding to the input feature matrix. The novelty of this work lies in proposing the hyperbolic function based positional encoding scheme in the ERTNN framework . The experiments have also been carried out using traditional ERTNN framework employing sinusoidal function based positional encoding scheme, learnable positional encoding based ERTNN framework, relative positional encoding based ERTNN framework as well as by removing the positional encoding scheme from the multi-headed attention layer to have a performance comparison with the proposed framework.},
  archive      = {J_NEUCOM},
  author       = {Rohitesh Kumar and Rajib Ghosh},
  doi          = {10.1016/j.neucom.2025.129751},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129751},
  shortjournal = {Neurocomputing},
  title        = {Person verification and recognition by combining voice signal and online handwritten signature using hyperbolic function based transformer neural network},
  volume       = {632},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transref: Multi-scale reference embedding transformer for
reference-guided image inpainting. <em>NEUCOM</em>, <em>632</em>,
129749. (<a href="https://doi.org/10.1016/j.neucom.2025.129749">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image inpainting for completing complicated semantic environments and diverse hole patterns of corrupted images is challenging even for state-of-the-art learning-based inpainting methods trained on large-scale data. A reference image capturing the same scene of a corrupted image offers informative guidance for completing the corrupted image as it shares similar texture and structure priors to that of the holes of the corrupted image. In this work, we propose a Trans former-based encoder–decoder network for Ref erence-guided image inpainting, named TransRef . Specifically, the guidance is conducted progressively through a reference embedding procedure, in which the referencing features are subsequently aligned and fused with the features of the corrupted image. For precise utilization of the reference features for guidance, a reference-patch alignment (Ref-PA) module is proposed to align the patch features of the reference and corrupted images and harmonize their style differences, while a reference-patch transformer (Ref-PT) module is proposed to refine the embedded reference feature. Moreover, to facilitate the research of reference-guided image restoration tasks, we construct a publicly accessible benchmark dataset containing 50K pairs of input and reference images. Both quantitative and qualitative evaluations demonstrate the efficacy of the reference information and the proposed method over the state-of-the-art methods in completing complex holes. Code and dataset can be accessed at: https://github.com/Cameltr/TransRef .},
  archive      = {J_NEUCOM},
  author       = {Taorong Liu and Liang Liao and Delin Chen and Jing Xiao and Zheng Wang and Chia-Wen Lin and Shin’ichi Satoh},
  doi          = {10.1016/j.neucom.2025.129749},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129749},
  shortjournal = {Neurocomputing},
  title        = {Transref: Multi-scale reference embedding transformer for reference-guided image inpainting},
  volume       = {632},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Segmentation of 3D neuronal morphologies in microscopy
images utilizing flexible open-curve snakes. <em>NEUCOM</em>,
<em>632</em>, 129742. (<a
href="https://doi.org/10.1016/j.neucom.2025.129742">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active contour models, known as snakes, have effectively shown their capability to track and recreate neurites in three dimensions. Nevertheless, their efficacy is constrained when addressing attenuated filament signals tainted by noise. Moreover, tracking outcomes are contingent upon initial seeds, as they depend exclusively on forces generated from image gradients. To address these issues and enhance the traditional OCS tracker through the utilization of advanced algorithms, we present the Flexible Open Curve Snakes (FOCS). This unique framework synthesizes various forces via energy minimization and facilitates mutual reinforcement for localization, directional determination, and concurrent radii estimation to finalize the neurites’ structure. In FOCS, the open-curve tracking process undergoes dynamic deformation via iterative techniques that incorporate new deformation energy, modifications to strain orientations, and alterations in local radii. This method is perpetually enhanced by reducing a controllable energy function that encompasses the fitting forces and the curve’s length. FOCS effectively integrates snake architectures into a tracing framework, capturing the extensive information in volumetric neural data, hence addressing the issues of segmenting, tracing, and fully reconstructing neural structures in their natural environment. We illustrate the remarkable efficacy of FOCS by assessing many datasets, including BigNeuron (human and mouse) and Diadem. In these assessments, FOCS regularly surpassed current neuron tracking and tracing methodologies, achieving superior performance. Our approach significantly enhances performance measures, yielding gains of approximately 1.7% and 17% in the average overlap and distance scores on the BigNeuron dataset, respectively. Furthermore, it demonstrates a significant enhancement of roughly 4.1% in the average overlap score on the DIADEM dataset. The suggested approach is applicable to confocal and two-photon microscopy datasets, as demonstrated by the datasets employed.},
  archive      = {J_NEUCOM},
  author       = {Amir Vatani and Jie Song and Liang Xiao},
  doi          = {10.1016/j.neucom.2025.129742},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129742},
  shortjournal = {Neurocomputing},
  title        = {Segmentation of 3D neuronal morphologies in microscopy images utilizing flexible open-curve snakes},
  volume       = {632},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LSTM and GRU type recurrent neural networks in model
predictive control: A review. <em>NEUCOM</em>, <em>632</em>, 129712. (<a
href="https://doi.org/10.1016/j.neucom.2025.129712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRU) neural networks are known for their capability of modeling numerous dynamical phenomena. Model Predictive Control (MPC) refers to a family of advanced control methods in which a dynamical model predicts online the future behavior of the controlled process, and an optimization procedure finds the best control policy. From the point of view of the control quality and the computational complexity of MPC, two issues are crucial: the model structure and the way the model is used in MPC. Both factors determine the resulting control quality and computational complexity of MPC. This article reviews possible methods of using LSTM and GRU type networks in MPC. First, we characterize several model variants that are utilized in MPC. Next, we review possible approaches to MPC based on LSTMs and GRUs, particularly the MPC methods leading to low computational complexity. Stability and robustness issues are also discussed. For a chemical pH reactor, the efficiency of LSTM and GRU models and a few neural network-based MPC algorithms are compared. Finally, we review numerous applications, including applications to real processes, hardware-in-the-loop solutions and example simulation studies.},
  archive      = {J_NEUCOM},
  author       = {Maciej Ławryńczuk and Krzysztof Zarzycki},
  doi          = {10.1016/j.neucom.2025.129712},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129712},
  shortjournal = {Neurocomputing},
  title        = {LSTM and GRU type recurrent neural networks in model predictive control: A review},
  volume       = {632},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SHoTGCN: Spatial high-order temporal GCN for skeleton-based
action recognition. <em>NEUCOM</em>, <em>632</em>, 129697. (<a
href="https://doi.org/10.1016/j.neucom.2025.129697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Action recognition algorithms that leverage human skeleton motion data are highly attractive due to their robustness and high information density. Currently, the majority of algorithms in this domain employ graph convolutional neural networks (GCNs). However, these algorithms often neglect the extraction of high-order features. To address this limitation, we propose a novel approach called the Spatial High-Order Temporal Graph Convolution Network (SHoTGCN), designed to evaluate the impact of high-order features on human action recognition. Our method begins by deriving high-order features from human skeleton time series data through temporal interactions. Utilizing these high-order features significantly improves the algorithm’s ability to recognize human actions. Moreover, we found that the traditional feature extraction method, which employs Depthwise Convolution (DWConv) with a single 2D convolution, is suboptimal compared to a multibranch structure for feature extraction. To address this, we introduce a structure re-parameterization technique with DWConv, termed Rep-tDWConv, to enhance feature extraction. By integrating the Exponential Moving Average (EMA) model during the model fusion process, our proposed model achieves state-of-the-art (SOTA) performance, with accuracies of 90.4% and 92.0% on the XSub and XSet splits of the NTU RGB+D 120 dataset, respectively.},
  archive      = {J_NEUCOM},
  author       = {Qiyu Liu and Ying Wu and Bicheng Li and Yuxin Ma and Hanling Li and Yong Yu},
  doi          = {10.1016/j.neucom.2025.129697},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129697},
  shortjournal = {Neurocomputing},
  title        = {SHoTGCN: Spatial high-order temporal GCN for skeleton-based action recognition},
  volume       = {632},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MPDRM: A multi-scale personalized depression recognition
model via facial movements. <em>NEUCOM</em>, <em>632</em>, 129669. (<a
href="https://doi.org/10.1016/j.neucom.2025.129669">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic depression recognition based on facial movements in videos has become a research hotspot. However, existing methods tend to confuse individual inherent facial behavioral habits with characteristics specific to depression, which leads to misjudgments. To address this, we propose a Multi-scale Personalized Depression Recognition Model (MPDRM) that mitigates the negative impact of individual differences, enabling the model to focus on general and robust facial depression cues. The proposed model consists of three main components: the Multi-scale Depression Feature Network (MDFN), the Multi-scale Personality Feature Network (MPFN), and the Relational Attention Recognition Module (RARM). The MDFN extracts depression-related information, while the contrastive learning-based MPFN extracts stable personalized information. In both MDFN and MPFN, we insert the Multi-scale Motion Pattern Extraction Module (MMP) to capture rich multi-scale spatiotemporal facial features. Finally, the RARM is designed to enhance the representation of depression and output the results. Cross-validation on a specifically constructed longitudinal dataset demonstrates that our model outperforms other models. Experimental results indicate that suppressing personalized information of facial movements can effectively improve the accuracy of depression recognition.},
  archive      = {J_NEUCOM},
  author       = {Zhenyu Liu and Bailin Chen and Shimao Zhang and Jiaqian Yuan and Yang Wu and Hanshu Cai and Xin Chen and Lin Liu and Yimiao Zhao and Huan Mei and Jiahui Deng and Yanping Bao and Bin Hu},
  doi          = {10.1016/j.neucom.2025.129669},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129669},
  shortjournal = {Neurocomputing},
  title        = {MPDRM: A multi-scale personalized depression recognition model via facial movements},
  volume       = {632},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025b). A comprehensive overview of generative AI (GAI):
Technologies, applications, and challenges. <em>NEUCOM</em>,
<em>632</em>, 129645. (<a
href="https://doi.org/10.1016/j.neucom.2025.129645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Artificial Intelligence (GAI) represents a forefront research domain and demonstrates the ability to generate innovative and creative content spanning text, images, audio, videos, and other technological forms. Recent breakthroughs in GAI, exemplified by remarkable products like ChatGPT and stable diffusion, have garnered significant attention and hold immense potential to shape the trajectory of societal development. This paper undertakes a comprehensive analysis of the current capabilities and limitations of GAI while exploring optimal strategies for its future application. Specifically, we provide an extensive overview of technical approaches employed in GAI, encompassing text, images, videos, audio, and multi-modal generation models. Furthermore, we summarize the commonly utilized training datasets and evaluation benchmarks of various modalities. These benchmarks serve as integral components for assessing the performance of GAI models. Subsequently, we delve into the current applications and future prospects of GAI across various fields. Finally, we discuss the challenges inherent in GAI and outline prospective directions for future advancements in the field, with the intention of offering valuable insights and inspiration to researchers.},
  archive      = {J_NEUCOM},
  author       = {Zhijun Zhang and Jian Zhang and Xiaodong Zhang and Weijian Mai},
  doi          = {10.1016/j.neucom.2025.129645},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129645},
  shortjournal = {Neurocomputing},
  title        = {A comprehensive overview of generative AI (GAI): Technologies, applications, and challenges},
  volume       = {632},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model adaptive parameter fine-tuning based on contribution
measure for image classification. <em>NEUCOM</em>, <em>632</em>, 129634.
(<a href="https://doi.org/10.1016/j.neucom.2025.129634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-tuning is an important transfer learning technique that has achieved significant success in various image classification tasks lacking training data and requires only a small number of training epochs to achieve satisfactory results. However, with the increasing complexity of the model scale and structure, designing appropriate fine-tuning schemes for specific target tasks becomes increasingly difficult. In this paper, a contribution measure criterion is used to quantify the importance of the pre-trained model parameters to the target task, providing a basis for selecting fine-tuning parameters. In addition, we find that the fine-tuning ratio vary depends on the specific target task. Therefore, we propose an adaptive fine-tuning ratio search strategy to search the appropriate fine-tuning ratio for the given target task. Based on the above strategy, we propose an adaptive fine-tuning algorithm based on parameter contribution to customize the fine-tuning scheme for the target task. The experimental results show that the proposed algorithm can effectively quantify the contribution of model parameters, and our algorithm can adaptively adjust the fine-tuning ratio for the target task. Furthermore, our algorithm achieves state-of-the-art performance on seven publicly available image classification datasets widely used in transfer learning.},
  archive      = {J_NEUCOM},
  author       = {Le Feng and Fujian Feng and Yuan Yang and Mian Tan and Lin Wang},
  doi          = {10.1016/j.neucom.2025.129634},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {129634},
  shortjournal = {Neurocomputing},
  title        = {Model adaptive parameter fine-tuning based on contribution measure for image classification},
  volume       = {632},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="nn---93">NN - 93</h2>
<ul>
<li><details>
<summary>
(2025). A novel self-supervised graph clustering method with
reliable semi-supervision. <em>NN</em>, <em>187</em>, 107418. (<a
href="https://doi.org/10.1016/j.neunet.2025.107418">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cluster analysis, as a core technique in unsupervised learning, has widespread applications. With the increasing complexity of data, deep clustering, which integrates the advantages of deep learning and traditional clustering algorithms, demonstrates outstanding performance in processing high-dimensional and complex data. However, when applied to graph data, deep clustering faces two major challenges: noise and sparsity. Noise introduces misleading connections, while sparsity makes it difficult to accurately capture relationships between nodes. These two issues not only increase the difficulty of feature extraction but also significantly affect clustering performance. To address these problems, we propose a novel Self-Supervised Graph Clustering model based on Reliable Semi-Supervision (SSGC-RSS). This model innovates through upstream and downstream components. The upstream component employs a dual-decoder graph autoencoder with joint clustering optimization, preserving latent information of features and graph structure, and alleviates the sparsity problem by generating cluster centers and pseudo-labels. The downstream component utilizes a semi-supervised graph attention encoding network based on highly reliable samples and their pseudo-labels to select reliable samples for training, thereby effectively reducing the interference of noise. Experimental results on multiple graph datasets demonstrate that, compared to existing methods, SSGC-RSS achieves significant performance improvements, with accuracy improvements of 0.9%, 2.0%, and 5.6% on Cora, Citeseer, and Pubmed datasets respectively, proving its effectiveness and superiority in complex graph data clustering tasks.},
  archive      = {J_NN},
  author       = {Weijia Lu and Min Wang and Yun Yu and Liang Ma and Yaxiang Shi and Zhongqiu Huang and Ming Gong},
  doi          = {10.1016/j.neunet.2025.107418},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107418},
  shortjournal = {Neural Netw.},
  title        = {A novel self-supervised graph clustering method with reliable semi-supervision},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LUNETR: Language-infused UNETR for precise pancreatic tumor
segmentation in 3D medical image. <em>NN</em>, <em>187</em>, 107414. (<a
href="https://doi.org/10.1016/j.neunet.2025.107414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The identification of early micro-lesions and adjacent blood vessels in CT scans plays a pivotal role in the clinical diagnosis of pancreatic cancer, considering its aggressive nature and high fatality rate. Despite the widespread application of deep learning methods for this task, several challenges persist: (1) the complex background environment in abdominal CT scans complicates the accurate localization of potential micro-tumors; (2) the subtle contrast between micro-lesions within pancreatic tissue and the surrounding tissues makes it challenging for models to capture these features accurately; and (3) tumors that invade adjacent blood vessels pose significant barriers to surgical procedures. To address these challenges, we propose LUNETR (Language-Infused UNETR), an advanced multimodal encoder model that combines textual and image information for precise medical image segmentation. The integration of an autoencoding language model with cross-attention enabling our model to effectively leverage semantic associations between textual and image data, thereby facilitating precise localization of potential pancreatic micro-tumors. Additionally, we designed a Multi-scale Aggregation Attention (MSAA) module to comprehensively capture both spatial and channel characteristics of global multi-scale image data, enhancing the model&#39;s capacity to extract features from micro-lesions embedded within pancreatic tissue. Furthermore, in order to facilitate precise segmentation of pancreatic tumors and nearby blood vessels and address the scarcity of multimodal medical datasets, we collaborated with Zhuzhou Central Hospital to construct a multimodal dataset comprising CT images and corresponding pathology reports from 135 pancreatic cancer patients. Our experimental results surpass current state-of-the-art models, with the incorporation of the semantic encoder improving the average Dice score for pancreatic tumor segmentation by 2.23 %. For the Medical Segmentation Decathlon (MSD) liver and lung cancer datasets, our model achieved an average Dice score improvement of 4.31 % and 3.67 %, respectively, demonstrating the efficacy of the LUNETR.},
  archive      = {J_NN},
  author       = {Ziyang Shi and Ruopeng Zhang and Xiajun Wei and Cheng Yu and Haojie Xie and Zhen Hu and Xili Chen and Yongzhong Zhang and Bin Xie and Zhengmao Luo and Wanxiang Peng and Xiaochun Xie and Fang Li and Xiaoli Long and Lin Li and Linan Hu},
  doi          = {10.1016/j.neunet.2025.107414},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107414},
  shortjournal = {Neural Netw.},
  title        = {LUNETR: Language-infused UNETR for precise pancreatic tumor segmentation in 3D medical image},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Noise-resistant predefined-time convergent ZNN models for
dynamic least squares and multi-agent systems. <em>NN</em>,
<em>187</em>, 107412. (<a
href="https://doi.org/10.1016/j.neunet.2025.107412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zeroing neural networks (ZNNs) are commonly used for dynamic matrix equations, but their performance under numerically unstable conditions has not been thoroughly explored, especially in situations involving unequal row-column matrices. The challenge is further aggravated by noise, particularly in dynamic least squares (DLS) problems. To address these issues, we propose the QR decomposition-driven noise-resistant ZNN (QRDN-ZNN) model, specifically designed for DLS problems. By integrating QR decomposition into the ZNN framework, QRDN-ZNN enhances numerical stability and guarantees both precise and rapid convergence through a novel activation function (N-Af). As validated by theoretical analysis and experiments, the model can effectively counter disturbances and enhance solution accuracy in dynamic environments. Experimental results show that, in terms of noise resistance, the QRDN-ZNN model outperforms existing mainstream ZNN models, including the original ZNN, integral-enhanced ZNN, double-integral enhanced ZNN, and super-twisting ZNN. Furthermore, the N-Af offers higher accuracy and faster convergence than other state-of-the-art activation functions. To demonstrate the practical utility of the method, We develop a new noise-resistant consensus protocol inspired by QRDN-ZNN, which enables multi-agent systems to reach consensus even in noisy conditions.},
  archive      = {J_NN},
  author       = {Yiwei Li and Jiaxin Liu and Lei Jia and Liangze Yin and Xingpei Li and Yong Zhang},
  doi          = {10.1016/j.neunet.2025.107412},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107412},
  shortjournal = {Neural Netw.},
  title        = {Noise-resistant predefined-time convergent ZNN models for dynamic least squares and multi-agent systems},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Restarted multiple kernel algorithms with self-guiding for
large-scale multi-view clustering. <em>NN</em>, <em>187</em>, 107409.
(<a href="https://doi.org/10.1016/j.neunet.2025.107409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering is a powerful approach for discovering underlying structures hidden behind diverse views of datasets. Most existing multi-view spectral clustering methods use fixed similarity matrices or alternately updated ones. However, the former often fall short in adaptively capturing relationships among different views, while the latter are often time-consuming and even impractical for large-scale datasets. To the best of our knowledge, there are no multi-view spectral clustering methods can both construct multi-view similarity matrices inexpensively and preserve the valuable clustering insights from previous cycles at the same time. To fill in this gap, we present a Sum-Ratio Multi-view Ncut model that share a common representation embedding for multi-view data. Based on this model, we propose a restarted multi-view multiple kernel clustering framework with self-guiding. To release the overhead, we use similarity matrices with strict block diagonal representation, and present an efficient multiple kernel selection technique. Comprehensive experiments on benchmark multi-view datasets demonstrate that, even using randomly generated initial guesses, the restarted algorithms can improve the clustering performances by 5–10 times for some popular multi-view clustering methods. Specifically, our framework offers a potential boosting effect for most of the state-of-the-art multi-view clustering algorithms at very little cost, especially for those with poor performances.},
  archive      = {J_NN},
  author       = {Yongyan Guo and Gang Wu},
  doi          = {10.1016/j.neunet.2025.107409},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107409},
  shortjournal = {Neural Netw.},
  title        = {Restarted multiple kernel algorithms with self-guiding for large-scale multi-view clustering},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Motif and supernode-enhanced gated graph neural networks for
session-based recommendation. <em>NN</em>, <em>187</em>, 107406. (<a
href="https://doi.org/10.1016/j.neunet.2025.107406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-based recommendation systems aim to predict users’ next interactions based on short-lived, anonymous sessions, a challenging yet vital task due to the sparsity and dynamic nature of user behavior. Existing Graph Neural Network (GNN)-based methods primarily focus on the session graphs while overlooking the influence of micro-structures and user behavior patterns. To address these limitations, we propose a Motif and Supernode-Enhanced Session-based Recommender System (MSERS), which constructs a global session graph, identifies and encodes motifs as supernodes, and reintegrates them into the global graph to enrich its topology and better represent item dependencies. By employing supernode-enhanced Gated Graph Neural Networks (GGNN), MSERS captures both long-term and latent item dependencies, significantly improving session representations. Extensive experiments on two real-world datasets demonstrate the superiority of MSERS over baseline methods, providing robust insights into the role of micro-structures in session-based recommendations.},
  archive      = {J_NN},
  author       = {Ronghua Lin and Chang Liu and Hao Zhong and Chengzhe Yuan and Guohua Chen and Yuncheng Jiang and Yong Tang},
  doi          = {10.1016/j.neunet.2025.107406},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107406},
  shortjournal = {Neural Netw.},
  title        = {Motif and supernode-enhanced gated graph neural networks for session-based recommendation},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mathematical expression exploration with graph
representation and generative graph neural network. <em>NN</em>,
<em>187</em>, 107405. (<a
href="https://doi.org/10.1016/j.neunet.2025.107405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Symbolic Regression (SR) methods in tree representations have exhibited commendable outcomes across Genetic Programming (GP) and deep learning search paradigms. Nonetheless, the tree representation of mathematical expressions occasionally embodies redundant substructures. Representing expressions as computation graphs is more succinct and intuitive through graph representation. Despite its adoption in evolutionary strategies within SR, deep learning paradigms remain under-explored. Acknowledging the profound advancements of deep learning in tree-centric SR approaches, we advocate for addressing SR tasks using the Directed Acyclic Graph (DAG) representation of mathematical expressions, complemented by a generative graph neural network. We name the proposed method as Graph -based D eep S ymbolic R egression (GraphDSR) . We vectorize node types and employ an adjacent matrix to delineate connections. The graph neural networks craft the DAG incrementally, sampling node types and graph connections conditioned on previous DAG at every step. During each sample step, the valid check is implemented to avoid meaningless sampling, and four domain-agnostic constraints are adopted to further streamline the search. This process culminates once a coherent expression emerges. Constants undergo optimization by SGD and BFGS algorithms, and rewards refine the graph neural network through reinforcement learning. A comprehensive evaluation across 110 benchmarks underscores the potency of our approach.},
  archive      = {J_NN},
  author       = {Jingyi Liu and Weijun Li and Lina Yu and Min Wu and Wenqiang Li and Yanjie Li and Meilan Hao},
  doi          = {10.1016/j.neunet.2025.107405},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107405},
  shortjournal = {Neural Netw.},
  title        = {Mathematical expression exploration with graph representation and generative graph neural network},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). More signals matter to detection: Integrating language
knowledge and frequency representations for boosting fine-grained
aircraft recognition. <em>NN</em>, <em>187</em>, 107402. (<a
href="https://doi.org/10.1016/j.neunet.2025.107402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As object detection tasks progress rapidly, fine-grained detection flourishes as a promising extension. Fine-grained recognition naturally demands high-quality detail signals; however, existing fine-grained detectors, built upon the mainstream detection paradigm, struggle to simultaneously address the challenges of insufficient original signals and the loss of critical signals, resulting in inferior performance. We argue that language signals with advanced semantic knowledge can provide valuable information for fine-grained objects, as well as the frequency domain exhibits greater flexibility in suppressing and enhancing signals; then, we propose a fine-grained aircraft detector by integrating language knowledge and frequency representations into the one-stage detection paradigm. Concretely, by considering both original signals and deep feature signals, we develop three components, including an adaptive frequency augmentation branch (AFAB), a content-aware global features intensifier (CGFI), and a fine-grained text–image interactive feeder (FTIF), to facilitate perceiving and retaining critical signals throughout pivotal detection stages. The AFAB adaptively processes image patches according to their frequency characteristics in the Fourier domain, thus thoroughly mining critical visual content in the data space; the CGFI employs content-aware frequency filtering to enhance global features, allowing for generating an information-rich feature space; the FTIF introduces text knowledge to describe visual differences among fine-grained categories, conveying robust semantic priors from language signals to visual spaces via multimodal interaction for information supplement. Extensive experiments conducted on optical and SAR images demonstrate the superior performance of the proposed fine-grained detector, especially the FTIF, which can be plugged into most existing one-stage detectors to boost their fine-grained recognition performance significantly.},
  archive      = {J_NN},
  author       = {Xueru Xu and Zhong Chen and Yuxin Hu and Guoyou Wang},
  doi          = {10.1016/j.neunet.2025.107402},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107402},
  shortjournal = {Neural Netw.},
  title        = {More signals matter to detection: Integrating language knowledge and frequency representations for boosting fine-grained aircraft recognition},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel deep transfer learning method based on explainable
feature extraction and domain reconstruction. <em>NN</em>, <em>187</em>,
107401. (<a href="https://doi.org/10.1016/j.neunet.2025.107401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although deep transfer learning has made significant progress, its “black-box” nature and unstable feature adaptation remain key obstacles. This study proposes a multi-stage deep transfer learning method, called XDTL, which combines explainable feature extraction and domain reconstruction to enhance the performance of target models. Specifically, the study first divides features into key and regular features through cross-validation and explainability analysis, then reconstructs the target domain using a seed replacement method based on key target samples, ultimately achieving deep transfer. Experimental results show that, compared to other methods, XDTL achieves an average improvement of 27.43 % in effectiveness, demonstrating superior performance and stronger explainability. This method offers new insights into addressing the explainability challenges in transfer learning and highlights its potential for broader applications across various tasks.},
  archive      = {J_NN},
  author       = {Li Wang and Lucong Zhang and Ling Feng and Tianyu Chen and Hongwu Qin},
  doi          = {10.1016/j.neunet.2025.107401},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107401},
  shortjournal = {Neural Netw.},
  title        = {A novel deep transfer learning method based on explainable feature extraction and domain reconstruction},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight all-MLP time–frequency anomaly detection for
IIoT time series. <em>NN</em>, <em>187</em>, 107400. (<a
href="https://doi.org/10.1016/j.neunet.2025.107400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection in the Industrial Internet of Things (IIoT) aims at identifying abnormal sensor signals to ensure industrial production safety. However, most existing models only focus on high accuracy by building a bulky neural network with deep structures and huge parameters. In this case, these models usually exhibit poor timeliness and high resource consumption, which makes these models unsuitable for resource-limited edge industrial scenarios. To solve this problem, a lightweight All-MLP time–frequency anomaly detection model is proposed for IIoT time series, namely LTFAD. Firstly , unlike traditional deep and bulky solutions, a shallow and lightweight All-MLP architecture is designed to achieve high timeliness and low resource consumption. Secondly , based on the lightweight architecture, a dual-branch network is constructed to improve model accuracy by simultaneously learning “global to local” and “local to global” reconstruction. Finally , time–frequency joint learning is employed in each reconstruction branch to further enhance accuracy. To the best of our knowledge, this is the first work to develop a time–frequency anomaly detection model based only on the shallow All-MLP architecture. Extensive experiments demonstrate that LTFAD can quickly and accurately identify anomalies on resource-limited edge devices, such as the Raspberry Pi 4b and Jetson Xavier NX. The source code for LTFAD is available at https://github.com/infogroup502/LTFAD .},
  archive      = {J_NN},
  author       = {Lei Chen and Xinzhe Cao and Tingqin He and Yepeng Xu and Xuxin Liu and Bowen hu},
  doi          = {10.1016/j.neunet.2025.107400},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107400},
  shortjournal = {Neural Netw.},
  title        = {A lightweight all-MLP time–frequency anomaly detection for IIoT time series},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decomposition-based multi-scale transformer framework for
time series anomaly detection. <em>NN</em>, <em>187</em>, 107399. (<a
href="https://doi.org/10.1016/j.neunet.2025.107399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series anomaly detection is crucial for maintaining stable systems. Existing methods face two main challenges. First, it is difficult to directly model the dependencies of diverse and complex patterns within the sequences. Second, many methods that optimize parameters using mean squared error struggle with noise in the time series, leading to performance deterioration. To address these challenges, we propose a transformer-based framework built on decomposition (TransDe) for multivariate time series anomaly detection. The key idea is to combine the strengths of time series decomposition and transformers to effectively learn the complex patterns in normal time series data. A multi-scale patch-based transformer architecture is proposed to exploit the representative dependencies of each decomposed component of the time series. Furthermore, a contrastive learn paradigm based on patch operation is proposed, which leverages KL divergence to align the positive pairs, namely the pure representations of normal patterns between different patch-level views. A novel asynchronous loss function with a stop-gradient strategy is further introduced to enhance the performance of TransDe effectively. It can avoid time-consuming and labor-intensive computation costs in the optimization process. Extensive experiments on five public datasets are conducted and TransDe shows superiority compared with twelve baselines in terms of F1 score. Our code is available at https://github.com/shaieesss/TransDe .},
  archive      = {J_NN},
  author       = {Wenxin Zhang and Cuicui Luo},
  doi          = {10.1016/j.neunet.2025.107399},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107399},
  shortjournal = {Neural Netw.},
  title        = {Decomposition-based multi-scale transformer framework for time series anomaly detection},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zero-shot 3D anomaly detection via online voter mechanism.
<em>NN</em>, <em>187</em>, 107398. (<a
href="https://doi.org/10.1016/j.neunet.2025.107398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D anomaly detection aims to solve the problem that image anomaly detection is greatly affected by lighting conditions. As commercial confidentiality and personal privacy become increasingly paramount, access to training samples is often restricted. To address these challenges, we propose a zero-shot 3D anomaly detection method. Unlike previous CLIP-based methods, the proposed method does not require any prompt and is capable of detecting anomalies on the depth modality. Furthermore, we also propose a pre-trained structural rerouting strategy, which modifies the transformer without retraining or fine-tuning for the anomaly detection task. Most importantly, this paper proposes an online voter mechanism that registers voters and performs majority voter scoring in a one-stage, zero-start and growth-oriented manner, enabling direct anomaly detection on unlabeled test sets. Finally, we also propose a confirmatory judge credibility assessment mechanism, which provides an efficient adaptation for possible few-shot conditions. Results on datasets such as MVTec3D-AD demonstrate that the proposed method can achieve superior zero-shot 3D anomaly detection performance, indicating its pioneering contributions within the pertinent domain.},
  archive      = {J_NN},
  author       = {Wukun Zheng and Xiao Ke and Wenzhong Guo},
  doi          = {10.1016/j.neunet.2025.107398},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107398},
  shortjournal = {Neural Netw.},
  title        = {Zero-shot 3D anomaly detection via online voter mechanism},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SympGNNs: Symplectic graph neural networks for identifying
high-dimensional hamiltonian systems and node classification.
<em>NN</em>, <em>187</em>, 107397. (<a
href="https://doi.org/10.1016/j.neunet.2025.107397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing neural network models to learn Hamiltonian systems, such as SympNets, although accurate in low-dimensions, struggle to learn the correct dynamics for high-dimensional many-body systems. Herein, we introduce Symplectic Graph Neural Networks (SympGNNs) that can effectively handle system identification in high-dimensional Hamiltonian systems, as well as node classification. SympGNNs combine symplectic maps with permutation equivariance, a property of graph neural networks. Specifically, we propose two variants of SympGNNs: (i) G-SympGNN and (ii) LA-SympGNN, arising from different parameterizations of the kinetic and potential energy. We demonstrate the capabilities of SympGNN on two physical examples: a 40-particle coupled Harmonic oscillator, and a 2000-particle molecular dynamics simulation in a two-dimensional Lennard-Jones potential. Furthermore, we demonstrate the performance of SympGNN in the node classification task, achieving accuracy comparable to the state-of-the-art. We also empirically show that SympGNN can overcome the oversmoothing and heterophily problems, two key challenges in the field of graph neural networks.},
  archive      = {J_NN},
  author       = {Alan John Varghese and Zhen Zhang and George Em Karniadakis},
  doi          = {10.1016/j.neunet.2025.107397},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107397},
  shortjournal = {Neural Netw.},
  title        = {SympGNNs: Symplectic graph neural networks for identifying high-dimensional hamiltonian systems and node classification},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Expert guidance and partially-labeled data collaboration for
multi-organ segmentation. <em>NN</em>, <em>187</em>, 107396. (<a
href="https://doi.org/10.1016/j.neunet.2025.107396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abdominal multi-organ segmentation in computed tomography (CT) scans has exhibited successful applications in numerous real clinical scenarios. Nevertheless, prevailing methods for multi-organ segmentation often necessitate either a substantial volume of datasets derived from a single healthcare institution or the centralized storage of patient data obtained from diverse healthcare institutions. This prevailing approach significantly burdens data labeling and collection, thereby exacerbating the associated challenges. Compared to multi organ annotation labels, single organ annotation labels are extremely easy to obtain and have low costs. Therefor, this work establishes an effective collaborative mechanism between multi organ labels and single organ labels, and proposes an expert guided and partially-labeled data collaboration framework for multi organ segmentation, named EGPD-Seg. Firstly, a reward penalty loss function is proposed under the setting of partial labels to make the model more focused on the targets in single organ labels, while suppressing the influence of unlabeled organs on segmentation results. Then, an expert guided module is proposed to enable the model to learn prior knowledge, thereby enabling the model to obtain the ability to segment unlabeled organs on a single organ labeled dataset. The two modules interact with each other and jointly promote the multi organ segmentation performance of the model under label partial settings. This work has been effectively validated on five publicly available abdominal multi organ segmentation datasets, including internal datasets and invisible external datasets. Code: https://github.com/LiLiXJTU/EGPDC-Seg .},
  archive      = {J_NN},
  author       = {Li Li and Jianyi Liu and Hanguang Xiao and Guanqun Zhou and Qiyuan Liu and Zhicheng Zhang},
  doi          = {10.1016/j.neunet.2025.107396},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107396},
  shortjournal = {Neural Netw.},
  title        = {Expert guidance and partially-labeled data collaboration for multi-organ segmentation},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enabling scale and rotation invariance in convolutional
neural networks with retina like transformation. <em>NN</em>,
<em>187</em>, 107395. (<a
href="https://doi.org/10.1016/j.neunet.2025.107395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional convolutional neural networks (CNNs) struggle with scale and rotation transformations, resulting in reduced performance on transformed images. Previous research focused on designing specific CNN modules to extract transformation-invariant features. However, these methods lack versatility and are not adaptable to a wide range of scenarios. Drawing inspiration from human visual invariance, we propose a novel brain-inspired approach to tackle the invariance problem in CNNs. If we consider a CNN as the visual cortex, we have the potential to design an “eye” that exhibits transformation invariance, allowing CNNs to perceive the world consistently. Therefore, we propose a retina module and then integrate it into CNNs to create transformation-invariant CNNs (TICNN), achieving scale and rotation invariance. The retina module comprises a retina-like transformation and a transformation-aware neural network (TANN). The retina-like transformation supports flexible image transformations, while the TANN regulates these transformations for scaling and rotation. Specifically, we propose a reference-based training method (RBTM) where the retina module learns to align input images with a reference scale and rotation, thereby achieving invariance. Furthermore, we provide mathematical substantiation for the retina module to confirm its feasibility. Experimental results also demonstrate that our method outperforms existing methods in recognizing images with scale and rotation variations. The code will be released at https://github.com/JiaHongZ/TICNN .},
  archive      = {J_NN},
  author       = {Jiahong Zhang and Guoqi Li and Qiaoyi Su and Lihong Cao and Yonghong Tian and Bo Xu},
  doi          = {10.1016/j.neunet.2025.107395},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107395},
  shortjournal = {Neural Netw.},
  title        = {Enabling scale and rotation invariance in convolutional neural networks with retina like transformation},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature-tuning hierarchical transformer via token
communication and sample aggregation constraint for object
re-identification. <em>NN</em>, <em>187</em>, 107394. (<a
href="https://doi.org/10.1016/j.neunet.2025.107394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, transformer-based methods have shown remarkable success in object re-identification. However, most works directly embed off-the-shelf transformer backbones for feature extraction. These methods treat all patch tokens equally, ignoring the difference of distinct patch tokens for feature representation. To solve this issue, this paper designs a feature-tuning mechanism for transformer backbones to emphasize important patches and attenuate unimportant patches. Specifically, a Feature-tuning Hierarchical Transformer (FHTrans) for object re-identification is proposed. First, we propose a plug-and-play Feature-tuning module via Token Communication (TCF) deployed within transformer encoder blocks. This module regards the class token as a pivot to achieve communication between patch tokens. Important patch tokens are emphasized, while unimportant patch tokens are attenuated, focusing more precisely on the discriminative features related to object distinction. Then, we construct a FHTrans based on the designed feature-tuning module. The encoder blocks are divided into three hierarchies considering the correlation between feature representativeness and transformer depth. As the hierarchy deepens, the communication between tokens becomes tighter. This enables the model to capture more crucial feature information. Finally, we propose a Sample Aggregation (SA) loss to impose more effective constraints on statistical characteristics among samples, thereby enhancing intra-class aggregation and guiding FHTrans to learn more discriminative features. Experiments on object re-identification benchmarks demonstrate that our method can achieve state-of-the-art performance.},
  archive      = {J_NN},
  author       = {Zhi Yu and Zhiyong Huang and Mingyang Hou and Jiaming Pei and Yan Yan and Yushi Liu and Daming Sun},
  doi          = {10.1016/j.neunet.2025.107394},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107394},
  shortjournal = {Neural Netw.},
  title        = {Feature-tuning hierarchical transformer via token communication and sample aggregation constraint for object re-identification},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive node-level weighted learning for directed graph
neural network. <em>NN</em>, <em>187</em>, 107393. (<a
href="https://doi.org/10.1016/j.neunet.2025.107393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Directed graph neural networks (DGNNs) have garnered increasing interest, yet few studies have focused on node-level representation in directed graphs. In this paper, we argue that different nodes rely on neighbor information from different directions. Furthermore, the commonly used mean aggregation for in-neighbor sets and out-neighbor sets may lose expressive power for certain nodes. To achieve this, first, we estimate the homophily of each node to neighbors in different directions by extending the Dirichlet energy. This approach allows us to assign larger weights to neighbors in directions exhibiting higher homophilic ratios for any node. Second, we introduce out-degree and in-degree information in the learning of weights to avoid the problem of weak expressive power ability of mean aggregation. Moreover, we theoretically demonstrate that our method enhances the expressive ability of directed graphs. Extensive experiments on seven real-world datasets demonstrate that our method outperforms state-of-the-art approaches in both node classification and link prediction tasks.},
  archive      = {J_NN},
  author       = {Jincheng Huang and Xiaofeng Zhu},
  doi          = {10.1016/j.neunet.2025.107393},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107393},
  shortjournal = {Neural Netw.},
  title        = {Adaptive node-level weighted learning for directed graph neural network},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Central loss guides coordinated transformer for reliable
anatomical landmark detection. <em>NN</em>, <em>187</em>, 107391. (<a
href="https://doi.org/10.1016/j.neunet.2025.107391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heatmap-based anatomical landmark detection is still facing two unresolved challenges: (1) inability to accurately evaluate the distribution of heatmap; (2) inability to effectively exploit global spatial structure information. To address the computational inability challenge, we propose a novel position-aware and sample-aware central loss. Specifically, our central loss can absorb position information, enabling accurate evaluation of the heatmap distribution. More advanced is that our central loss is sample-aware, which can adaptively distinguish easy and hard samples and make the model more focused on hard samples while solving the challenge of extreme imbalance between landmarks and non-landmarks. To address the challenge of ignoring structure information, a Coordinated Transformer, called CoorTransformer, is proposed, which establishes long-range dependencies under the guidance of landmark coordinate information, making the attention more focused on the sparse landmarks while taking advantage of global spatial structure. Furthermore, CoorTransformer can speed up convergence, effectively avoiding the defect that Transformers have difficulty converging in sparse representation learning. Using the advanced CoorTransformer and central loss, we propose a generalized detection model that can handle various scenarios, inherently exploiting the underlying relationship between landmarks and incorporating rich structural knowledge around the target landmarks. We analyzed and evaluated CoorTransformer and central loss on three challenging landmark detection tasks. The experimental results show that our CoorTransformer outperforms state-of-the-art methods, and the central loss significantly improves the model’s performance with p -values &lt; 0 . 05 . The source code of this work is available at the GitHub repository .},
  archive      = {J_NN},
  author       = {Qikui Zhu and Yihui Bi and Jie Chen and Xiangpeng Chu and Danxin Wang and Yanqing Wang},
  doi          = {10.1016/j.neunet.2025.107391},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107391},
  shortjournal = {Neural Netw.},
  title        = {Central loss guides coordinated transformer for reliable anatomical landmark detection},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-level semantic-aware transformer for image captioning.
<em>NN</em>, <em>187</em>, 107390. (<a
href="https://doi.org/10.1016/j.neunet.2025.107390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective visual representation is crucial for image captioning task. Among the existing methods, the grid-based visual encoding methods take fragmented features extracted from the entire image as input, lacking the fine-grained semantic information focused on salient objects. To address this issue, we propose an effective method, namely Multi-Level Semantic-Aware Transformer (MLSAT) for image captioning, to simultaneously focus on contextual details and high-level semantic information centered on salient objects. First, to model the spatial correlations of grids and the semantic interactions of salient objects, we propose the Visual Content Guided Attention (VCGA), which adaptively embeds the relative position relationships of the grids into the visual features based on their visual content and is used as the attention layer of the encoder. Then, in order to enhance the visual representation, we propose the Multi-Level Semantic-Aware (MLSA) module which further models the fine-grained semantic information centered on salient objects. In this module, the primary semantic information is first extracted from the encoder by using the Semantic Information Extractor (SIE), then refined by the Semantic Refiner (SR) and adaptively integrated into the visual representation by the Visual-Semantic Fusion Block (V-SFB). Our MLSAT is extensively evaluated on the MS-COCO dataset and outperforms the state-of-the-art models, with 135.1% CIDEr (c40) on the official online testing server. The source code is available at https://github.com/XvZhao147/MLSAT},
  archive      = {J_NN},
  author       = {Qin Xu and Shan Song and Qihang Wu and Bo Jiang and Bin Luo and Jinhui Tang},
  doi          = {10.1016/j.neunet.2025.107390},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107390},
  shortjournal = {Neural Netw.},
  title        = {Multi-level semantic-aware transformer for image captioning},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A shape composition method for named entity recognition.
<em>NN</em>, <em>187</em>, 107389. (<a
href="https://doi.org/10.1016/j.neunet.2025.107389">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) roughly encode a sentence into a dense representation (a vector), which mixes up the semantic expression of all named entities within a sentence. So the decoding process is easily overwhelmed by sentence-specific information learned during the pre-training process. It results in seriously performance degeneration in recognizing named entities, especially annotated with nested structures. In contrast to LLMs condensing a sentence into a single vector, our model adopts a discriminative language model to map each sentence into a high-order semantic space. In this space, named entities are decomposed into entity body and entity edge. The decomposition is effective to decode complex semantic structures of named entities. In this paper, a shape composition method is proposed for recognizing named entities. This approach leverages a multi-objective learning neural architecture to simultaneously detect entity bodies and classify entity edges. During training, the dual objectives for body and edge learning guide the deep network to encode more task-relevant semantic information. Our method is evaluated on eight widely used public datasets and demonstrated competitive performance. Analytical experiments show that the strategy of let semantic expressions take its course aligns with the entity recognition task. This approach yields finer-grained semantic representations, which enhance not only NER but also other NLP tasks.},
  archive      = {J_NN},
  author       = {Ying Hu and Yanping Chen and Yong Xu},
  doi          = {10.1016/j.neunet.2025.107389},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107389},
  shortjournal = {Neural Netw.},
  title        = {A shape composition method for named entity recognition},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A semantic enhancement-based multimodal network model for
extracting information from evidence lists. <em>NN</em>, <em>187</em>,
107387. (<a href="https://doi.org/10.1016/j.neunet.2025.107387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Courts require the extraction of crucial information about various cases from heterogeneous evidence lists for knowledge-driven decision-making. However, traditional manual screening is complex and inaccurate when confronted with massive evidence lists and cannot meet the demands of legal judgment. Therefore, we propose a semantic enhancement-based multimodal network model (SEBM) to accurately extract critical information from evidence lists. First, we construct the entity semantic graph based on the differences among entity categories in the text content. Subsequently, we extract the features of multiple modalities within the document by employing distinct methods and guide the fusion of features within each modality to enhance the semantic association among them based on the constructed entity semantic graphs. Furthermore, the improved multimodal self-attention mechanism is employed to enhance the interactions between the various modal features, and the loss function combining Taylor polynomials and supervised contrast learning is utilized to reduce the information loss. Finally, SEBM is evaluated using the authentic Chinese evidence list dataset, which includes extensive entity details from diverse case types across multiple law firms. Results from experiments conducted on the authentic evidence list dataset demonstrate that our model performs better than other high-performing models.},
  archive      = {J_NN},
  author       = {Shun Luo and Juan Yu},
  doi          = {10.1016/j.neunet.2025.107387},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107387},
  shortjournal = {Neural Netw.},
  title        = {A semantic enhancement-based multimodal network model for extracting information from evidence lists},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Memristive circuit of emotion with negative feedback based
on three primary color model. <em>NN</em>, <em>187</em>, 107385. (<a
href="https://doi.org/10.1016/j.neunet.2025.107385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many memristive circuits tend to oversimplify the process of emotion generation as a linear event, disregarding crucial factors such as negative feedback and other regulatory mechanisms. In this paper, a memristive circuit of emotion with negative feedback based on three primary color model is proposed to solve the above problems. The designed circuit is composed of perception modules, synapse modules, central nervous system modules and overt behavior module. It realizes emotion generation, emotion evolution and long-term memory functions based on the neural network circuit with behavioral homeostatic negative feedback function. Meanwhile, the three primary color model of basic emotions is discussed and realized. Any two basic emotions can be mixed to produce a higher order emotion. The memristive circuit, based on the three primary color model as a theoretical foundation, offers valuable insights for the further advancement of neural networks.},
  archive      = {J_NN},
  author       = {Juntao Han and Gang Liu and Zhang Zhang},
  doi          = {10.1016/j.neunet.2025.107385},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107385},
  shortjournal = {Neural Netw.},
  title        = {Memristive circuit of emotion with negative feedback based on three primary color model},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Arch-net: Model conversion and quantization for architecture
agnostic model deployment. <em>NN</em>, <em>187</em>, 107384. (<a
href="https://doi.org/10.1016/j.neunet.2025.107384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The significant computational demands of Deep Neural Networks (DNNs) present a major challenge for their practical application. Recently, many Application-Specific Integrated Circuit (ASIC) chips have incorporated dedicated hardware support for neural network acceleration. However, the lengthy development cycle of ASIC chips means they often lag behind the latest advances in neural architecture research. For instance, Layer Normalization is not well-supported on many popular chips, and the efficiency of 7 × 7 convolution is significantly lower than the equivalent three 3 × 3 convolution. Therefore, in this paper, we introduce Arch-Net, a neural network framework comprised exclusively of a select few common operators, namely 3 × 3 Convolution, 2 × 2 Max-pooling, Batch Normalization, Fully Connected layers, and Concatenation, which are efficiently supported across the majority of ASIC architectures. To facilitate the conversion of disparate network architectures into Arch-Net, we propose the Arch-Distillation methodology, which incorporates strategies such as Residual Feature Adaptation and Teacher Attention Mechanism. These mechanisms enable effective conversion between different network structures alongside efficient model quantization. The resultant Arch-Net eliminates unconventional network constructs while maintaining robust performance even under sub-8-bit quantization, thereby enhancing compatibility and deployment efficiency. Empirical results from image classification and machine translation tasks demonstrate that using only a few types of operators in Arch-Net can achieve results comparable to those obtained with complex architectures. This provides a new insight for deploying structure-agnostic neural networks on various ASIC chips.},
  archive      = {J_NN},
  author       = {Shuangkang Fang and Weixin Xu and Zipeng Feng and Song Yuan and Yufeng Wang and Yi Yang and Wenrui Ding and Shuchang Zhou},
  doi          = {10.1016/j.neunet.2025.107384},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107384},
  shortjournal = {Neural Netw.},
  title        = {Arch-net: Model conversion and quantization for architecture agnostic model deployment},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event-based distributed cooperative neural learning control
for nonlinear multiagent systems with time-varying output constraints.
<em>NN</em>, <em>187</em>, 107383. (<a
href="https://doi.org/10.1016/j.neunet.2025.107383">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical engineering, many systems are required to operate under different constraint conditions due to considerations of system security. Violating these constraints conditions during operation may lead to performance degradation. Additionally, communication among agents is highly dependent on the network, which inevitably imposes a network burden on the control systems. To address these issues, this paper investigates the switching event-triggered distributed cooperative learning control issue for nonlinear multiagent systems with time-vary output constraints. An improved output-dependent universal barrier function with adjustable constraint boundaries is proposed, which can uniformly handle symmetric or asymmetric output constraints without changing the controller structure. Meanwhile, an improved switching event-triggered condition is designed based on neural networks (NNs) weight, which can allow the system to adaptively adjust the NNs weight update frequency according to the performance of the system, thereby saving communication resources. Furthermore, the Padé approximation technique is employed to address the input delay issue and simplify the controller design process. Using Lyapunov stability theory, it is proved that the outputs of all followers converge to a neighborhood around the leader output without violating output constraints, and all signals in the closed-loop system remain ultimately bounded. At last, the availability of the presented approach can be verified through some simulation results.},
  archive      = {J_NN},
  author       = {Congyan Lv and Guangliang Liu and Yingnan Pan and Zhijian Hu and Yan Lei},
  doi          = {10.1016/j.neunet.2025.107383},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107383},
  shortjournal = {Neural Netw.},
  title        = {Event-based distributed cooperative neural learning control for nonlinear multiagent systems with time-varying output constraints},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bilinear spatiotemporal fusion network: An efficient
approach for traffic flow prediction. <em>NN</em>, <em>187</em>, 107382.
(<a href="https://doi.org/10.1016/j.neunet.2025.107382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic flow forecasting is critical for intelligent transportation systems, yet increasing model complexity in spatiotemporal graph neural networks does not always yield proportional gains. In this paper, we present a Bilinear Spatiotemporal Fusion Network (BLSTF) tailored for stable, periodic traffic scenarios. First, a temporal enhancement module is introduced to mitigate multi-step error accumulation. Second, predefined graph priors with linear feedback leverage known road topologies for straightforward yet effective spatial modeling. Finally, a bilinear fusion mechanism seamlessly integrates refined temporal and spatial features with minimal computational overhead. Extensive experiments on four real-world datasets show that BLSTF outperforms state-of-the-art methods, achieving MAE and MAPE of 14.05 and 13.90% on PEMS03, 17.93 and 12.12% on PEMS04, 18.87 and 7.86% on PEMS07, and 13.49 and 8.71% on PEMS08, demonstrating BLSTF’s potential to deliver accurate, efficient, and interpretable traffic flow forecasts.},
  archive      = {J_NN},
  author       = {Jing Chen and Shixiang Pan and Weimin Peng and Wenqiang Xu},
  doi          = {10.1016/j.neunet.2025.107382},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107382},
  shortjournal = {Neural Netw.},
  title        = {Bilinear spatiotemporal fusion network: An efficient approach for traffic flow prediction},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving generalization of neural vehicle routing problem
solvers through the lens of model architecture. <em>NN</em>,
<em>187</em>, 107380. (<a
href="https://doi.org/10.1016/j.neunet.2025.107380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural models produce promising results when solving Vehicle Routing Problems (VRPs), but may often fall short in generalization. Recent attempts to enhance model generalization often incur unnecessarily large training cost or cannot be directly applied to other models solving different VRP variants. To address these issues, we take a novel perspective on model architecture in this study. Specifically, we propose a plug-and-play Entropy-based Scaling Factor (ESF) and a Distribution-Specific (DS) decoder to enhance the size and distribution generalization, respectively. ESF adjusts the attention weight pattern of the model towards familiar ones discovered during training when solving VRPs of varying sizes. The DS decoder explicitly models VRPs of multiple training distribution patterns through multiple auxiliary light decoders, expanding the model representation space to encompass a broader range of distributional scenarios. We conduct extensive experiments on both synthetic and widely recognized real-world benchmarking datasets and compare the performance with seven baseline models. The results demonstrate the effectiveness of using ESF and DS decoder to obtain a more generalizable model and showcase their applicability to solve different VRP variants, i.e., traveling salesman problem and capacitated VRP. Notably, our proposed generic components require minimal computational resources, and can be effortlessly integrated into conventional generalization strategies to further elevate model generalization.},
  archive      = {J_NN},
  author       = {Yubin Xiao and Di Wang and Xuan Wu and Yuesong Wu and Boyang Li and Wei Du and Liupu Wang and You Zhou},
  doi          = {10.1016/j.neunet.2025.107380},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107380},
  shortjournal = {Neural Netw.},
  title        = {Improving generalization of neural vehicle routing problem solvers through the lens of model architecture},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Turbulence control in memristive neural network via adaptive
magnetic flux based on DLS-ADMM technique. <em>NN</em>, <em>187</em>,
107379. (<a href="https://doi.org/10.1016/j.neunet.2025.107379">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-voltage defibrillation for eliminating cardiac spiral waves has significant side effects, necessitating the pursuit of low-energy alternatives for a long time. Adaptive optimization techniques and machine learning methods provide promising solutions for adaptive control of cardiac wave propagation. In this paper, the control of spiral waves and turbulence, as well as 2D and 3D heterogeneity in memristive neural network by using adaptive magnetic flux (AMF) is investigated based on dynamic learning of synchronization - alternating direction method of multipliers (DLS-ADMM). The results show that AMF can achieve global electrical synchronization under multiple complex conditions. There is a trade-off between AMF accuracy and computational speed, lowering the resolution of AMF requires a higher flux of magnetic fields to achieve the network synchronization, resulting in an increase in average Hamiltonian energy, which implies greater energy consumption. The AMF method is more energy efficient than existing DC and AC methods, but it relies on adequate resolution. The ADMM constraints can enhance the synchronization robustness and energy efficiency of DLS techniques, albeit at the cost of increased the computational complexity. The adaptive elimination of spiral waves and turbulence using AMF presented in this paper may provide a novel approach for the low-energy defibrillation studies, and its practical application and performance enhancement deserve further research.},
  archive      = {J_NN},
  author       = {Qianming Ding and Yong Wu and Ying Xie and Yipeng Hu and Weifang Huang and Ya Jia},
  doi          = {10.1016/j.neunet.2025.107379},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107379},
  shortjournal = {Neural Netw.},
  title        = {Turbulence control in memristive neural network via adaptive magnetic flux based on DLS-ADMM technique},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deformation-invariant neural network and its applications in
distorted image restoration and analysis. <em>NN</em>, <em>187</em>,
107378. (<a href="https://doi.org/10.1016/j.neunet.2025.107378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images degraded by geometric distortions pose a significant challenge to imaging and computer vision tasks such as object recognition. Deep learning-based imaging models usually fail to give accurate performance for geometrically distorted images. In this paper, we propose the deformation-invariant neural network (DINN), a framework to address the problem of imaging tasks for geometrically distorted images. The DINN outputs consistent latent features for images that are geometrically distorted but represent the same underlying object or scene. The idea of DINN is to incorporate a simple component, called the quasiconformal transformer network (QCTN), into other existing deep networks for imaging tasks. The QCTN is a deep neural network that outputs a quasiconformal map, which can be used to transform a geometrically distorted image into an improved version that is closer to the distribution of natural or good images. It first outputs a Beltrami coefficient, which measures the quasiconformality of the output deformation map. By controlling the Beltrami coefficient, the local geometric distortion under the quasiconformal mapping can be controlled. The QCTN is lightweight and simple, which can be readily integrated into other existing deep neural networks to enhance their performance. Leveraging our framework, we have developed an image classification network that achieves accurate classification of distorted images. Our proposed framework has been applied to restore geometrically distorted images by atmospheric turbulence and water turbulence. DINN outperforms existing GAN-based restoration methods under these scenarios, demonstrating the effectiveness of the proposed framework. Additionally, we apply our proposed framework to the 1-1 verification of human face images under atmospheric turbulence and achieve satisfactory performance, further demonstrating the efficacy of our approach.},
  archive      = {J_NN},
  author       = {Han Zhang and Qiguang Chen and Lok Ming Lui},
  doi          = {10.1016/j.neunet.2025.107378},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107378},
  shortjournal = {Neural Netw.},
  title        = {Deformation-invariant neural network and its applications in distorted image restoration and analysis},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing text-centric fake news detection via external
knowledge distillation from LLMs. <em>NN</em>, <em>187</em>, 107377. (<a
href="https://doi.org/10.1016/j.neunet.2025.107377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fake news poses a significant threat to society, making the automatic and accurate detection of fake news an urgent task. Various detection cues have been explored in extensive research, with news text content shown to be indispensable as it directly reflects the creator’s intent. Existing paradigms for developing text-centric methods, i.e., small language model (SLM)-based, external knowledge-enhanced, and large language model (LLM)-based approaches, have achieved remarkable improvements. However, each of these paradigms still faces the following challenges: (1) the low generalization ability of SLM-based methods, due to their training on limited and specific knowledge; (2) the extensive retrieval operations required by external knowledge-enhanced methods, both during training and at the inference stage, leading to increased computational costs; and (3) LLMs are prone to hallucinations and less suited for factual reasoning. To address these challenges, we propose LEKD, which combines the strengths of SLMs, external knowledge, and LLMs to enhance text-centric fake news detection. Specifically, LEKD leverages the LLM to generate external knowledge as supplementary information for the training set only and introduces a graph-based semantic-aware feature alignment module to resolve knowledge contradictions, as well as an information bottleneck-based knowledge distillation module to ensure the implicit generation of these features during inference. Extensive experiments conducted on two datasets demonstrate the advantages of LEKD over the baselines.},
  archive      = {J_NN},
  author       = {Xueqin Chen and Xiaoyu Huang and Qiang Gao and Li Huang and Guisong Liu},
  doi          = {10.1016/j.neunet.2025.107377},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107377},
  shortjournal = {Neural Netw.},
  title        = {Enhancing text-centric fake news detection via external knowledge distillation from LLMs},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic semantic-geometric guidance and structure transfer
network for cross-scene hyperspectral image classification. <em>NN</em>,
<em>187</em>, 107374. (<a
href="https://doi.org/10.1016/j.neunet.2025.107374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, cross-scene hyperspectral image classification(HSIC) via domain adaptation is drawing increasing attention. However, most existing methods either directly align the source domain and target domain without fully mining of SD information, or perform the domain adaptation from semantic and structure aspects with simply characterization method which is sensitive to noise, resulting in the negative transfer and performance decline. To address these issues, in this paper, we propose a novel Dynamic Semantic-Geometric Guidance and Structure Transfer (DSGG-ST) network for cross-scene hyperspectral image classification task. The main aspects of DSGG-ST are twofold. On the one hand, the dynamic semantic-geometric guidance (DSGG) module is designed which consists of the semantic guidance component and geometric guidance component. The proposed DSGG module can align source and target domains under the dynamical guidance of the domain-invariance learning from the semantic and geometric perspectives. On the other hand, the graph attention learning-matching (GALM) module is developed for effectively transferring the structure information between the source domain and target domain. In this module, the graph attention network is adopted to encode the underlying complex structures, and the SeedGNN is exploited for efficient graph matching and alignment. Extensive experiments on three commonly used cross-scene HSI datasets demonstrate that the proposed DSGG-ST obtains a new SOTA performance on cross-scene HSIC, verifying the effectiveness of the proposed DSGG-ST.},
  archive      = {J_NN},
  author       = {Qin Xu and Shuke Wang and Jie Wei and Bo Jiang and Zhifu Tao and Bin Luo},
  doi          = {10.1016/j.neunet.2025.107374},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107374},
  shortjournal = {Neural Netw.},
  title        = {Dynamic semantic-geometric guidance and structure transfer network for cross-scene hyperspectral image classification},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved artificial protozoa optimizer for CNN
architecture optimization. <em>NN</em>, <em>187</em>, 107368. (<a
href="https://doi.org/10.1016/j.neunet.2025.107368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel neural architecture search (NAS) method called MAPOCNN, which leverages an enhanced version of the Artificial Protozoa Optimizer (APO) to optimize the architecture of Convolutional Neural Networks (CNNs). The APO is known for its rapid convergence, high stability, and minimal parameter involvement. To further improve its performance, we introduce MAPO (Modified Artificial Protozoa Optimizer), which incorporates the phototaxis behavior of protozoa. This addition helps mitigate the risk of premature convergence, allowing the algorithm to explore a broader range of possible CNN architectures and ultimately identify more optimal solutions. Through rigorous experimentation on benchmark datasets, including Rectangle and Mnist-random, we demonstrate that MAPOCNN not only achieves faster convergence times but also performs competitively when compared to other state-of-the-art NAS algorithms. The results highlight the effectiveness of MAPOCNN in efficiently discovering CNN architectures that outperform existing methods in terms of both speed and accuracy. This work presents a promising direction for optimizing deep learning architectures using biologically inspired optimization techniques.},
  archive      = {J_NN},
  author       = {Xiaofeng Xie and Yuelin Gao and Yuming Zhang},
  doi          = {10.1016/j.neunet.2025.107368},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107368},
  shortjournal = {Neural Netw.},
  title        = {An improved artificial protozoa optimizer for CNN architecture optimization},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive graph auto-encoder for graph embedding.
<em>NN</em>, <em>187</em>, 107367. (<a
href="https://doi.org/10.1016/j.neunet.2025.107367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph embedding aims to embed the information of graph data into low-dimensional representation space. Prior methods generally suffer from an imbalance of preserving structural information and node features due to their pre-defined inductive biases, leading to unsatisfactory generalization performance. In order to preserve the maximal information, graph contrastive learning (GCL) has become a prominent technique for learning discriminative embeddings. However, in contrast with graph-level embeddings, existing GCL methods generally learn less discriminative node embeddings in a self-supervised way. In this paper, we ascribe above problem to two challenges: (1) graph data augmentations, which are designed for generating contrastive representations, hurt the original semantic information for nodes. (2) the nodes within the same cluster are selected as negative samples. To alleviate these challenges, we propose C ontrastive G raph A uto- E ncoder (CGAE) and C ontrastive V ariational G raph A uto- E ncoder (CVGAE). Specifically, we first propose two distribution-dependent regularizations to guide the paralleled encoders to generate contrastive representations following similar distribution, followed by theoretical derivations to verify the equivalence of the above regularizations. Then, we utilize truncated triplet loss, which only selects top-k nodes as negative samples, to avoid over-separate nodes affiliated to the same cluster. Furthermore, we give theoretical analysis of the effectiveness of our models. Experiments on several real-world datasets show that our models advanced performance over all baselines in link prediction, node clustering, and graph visualization tasks.},
  archive      = {J_NN},
  author       = {Shuaishuai Zu and Li Li and Jun Shen and Weitao Tang},
  doi          = {10.1016/j.neunet.2025.107367},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107367},
  shortjournal = {Neural Netw.},
  title        = {Contrastive graph auto-encoder for graph embedding},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantic information-based attention mapping network for
few-shot knowledge graph completion. <em>NN</em>, <em>187</em>, 107366.
(<a href="https://doi.org/10.1016/j.neunet.2025.107366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot Knowledge Graph Completion (FKGC), an emerging technology capable of inferring new triples using only a few reference relation triples, has gained significant attention in recent years. However, existing FKGC methods primarily focus on structural information while failing to effectively utilize the textual semantic information inherent in triples. To address this limitation, we propose an innovative Semantic Information-based Attention Mapping Network (SI-AMN). This novel model significantly enhances knowledge graph completion accuracy through a unique dual-information fusion mechanism that effectively integrates both structural and textual semantic information. The core innovation of SI-AMN lies in its two key components: a semantic encoder for extracting high-quality textual features and an attention mapping network that learns semantic interactions between entity and relation types. Experimental results on benchmark datasets demonstrate SI-AMN’s superior performance, achieving a 40% improvement in prediction accuracy compared to state-of-the-art methods. Ablation studies further validate the effectiveness of each component in our proposed model. This research not only provides a novel solution for knowledge graph completion but also reveals the crucial value of semantic information in graph completion tasks, paving the way for future research directions in this field.},
  archive      = {J_NN},
  author       = {Fan Guo and Xiangmao Chang and Yunqi Guo and Guoliang Xing and Yunlong Zhao},
  doi          = {10.1016/j.neunet.2025.107366},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107366},
  shortjournal = {Neural Netw.},
  title        = {Semantic information-based attention mapping network for few-shot knowledge graph completion},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). S2AF: An action framework to self-check the understanding
self-consistency of large language models. <em>NN</em>, <em>187</em>,
107365. (<a href="https://doi.org/10.1016/j.neunet.2025.107365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs), which are trained on massive text data, have demonstrated remarkable advancements in language understanding capabilities. Nevertheless, it remains unclear to what extent LLMs have effectively captured and utilized the implicit relationships inherent in the text. This study introduces ‘Understanding Self-Consistency’ , a new perspective that reflects LLMs’ ability to grasp in-depth knowledge relationships through their consistency performance. Specifically, Understanding Self-Consistency refers to the model’s capacity to maintain logical and contextual consistency between inputs and responses. Inspired by human cognitive behavior, we design a self-check action framework named S 2 A F . Wherein, a self-question and answering mechanism is emphasized and forms a logically closed loop including four classes of actions, allowing our S 2 A F to generate, question, answer, and evaluate autonomously. Experimental results on six LLMs across two datasets show that LLMs exhibit objective ability values of the understanding self-consistency and demonstrate their differentiated grasp of knowledge relationships across different reasoning paradigms. Moreover, our findings reveal that LLMs’ performance can be improved with their own outputs (which we call ‘self-enhanced Feedforward’). Notably, S 2 A F merely relies on factual logical relationships, showcasing its potential to advance the development of embodied artificial intelligence (EAI).},
  archive      = {J_NN},
  author       = {Huihui Shao and Fanyu Wang and Zhenping Xie},
  doi          = {10.1016/j.neunet.2025.107365},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107365},
  shortjournal = {Neural Netw.},
  title        = {S2AF: An action framework to self-check the understanding self-consistency of large language models},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep huber quantile regression networks. <em>NN</em>,
<em>187</em>, 107364. (<a
href="https://doi.org/10.1016/j.neunet.2025.107364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Typical machine learning regression applications aim to report the mean or the median of the predictive probability distribution, via training with a squared or an absolute error scoring function. The importance of issuing predictions of more functionals of the predictive probability distribution (quantiles and expectiles) has been recognized as a means to quantify the uncertainty of the prediction. In deep learning (DL) applications, that is possible through quantile and expectile regression neural networks (QRNN and ERNN respectively). Here we introduce deep Huber quantile regression networks (DHQRN) that nest QRNN and ERNN as edge cases. DHQRN can predict Huber quantiles, which are more general functionals in the sense that they nest quantiles and expectiles as limiting cases. The main idea is to train a DL algorithm with the Huber quantile scoring function, which is consistent for the Huber quantile functional. As a proof of concept, DHQRN are applied to predict house prices in Melbourne, Australia and Boston, United States (US). In this context, predictive performances of three DL architectures are discussed along with evidential interpretation of results from two economic case studies. Additional simulation experiments and applications to real-world case studies using open datasets demonstrate a satisfactory absolute performance of DHQRN.},
  archive      = {J_NN},
  author       = {Hristos Tyralis and Georgia Papacharalampous and Nilay Dogulu and Kwok P. Chun},
  doi          = {10.1016/j.neunet.2025.107364},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107364},
  shortjournal = {Neural Netw.},
  title        = {Deep huber quantile regression networks},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertainty-aware graph contrastive fusion network for
multimodal physiological signal emotion recognition. <em>NN</em>,
<em>187</em>, 107363. (<a
href="https://doi.org/10.1016/j.neunet.2025.107363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have been widely adopted to mine topological patterns contained in physiological signals for emotion recognition. However, since physiological signals are non-stationary and susceptible to various noises, there exists inter-sensor connectivity uncertainty in each modality. Such intra-modal connectivity uncertainty may further lead to inter-modal semantic gap uncertainty, which will cause the unimodal bias problem and greatly affect the fusion effectiveness. While, such issue has never been fully considered in existing multimodal fusion models. To this end, we proposed an Uncertainty-Aware Graph Contrastive Fusion Network (UAGCFNet) to fuse multimodal physiological signals effectively for emotion recognition. Firstly, a probabilistic model-based Uncertainty-Aware Graph Convolutional Network (UAGCN), which can estimate and quantify the inter-sensor connectivity uncertainty, is constructed for each modality to extract its uncertainty-aware graph representation. Secondly, a Transitive Contrastive Fusion (TCF) module, which combines the Criss-Cross Attention (CCA)-based fusion mechanism and Transitive Contrastive Learning (TCL)-based calibration strategy organically, is designed to achieve effective fusion of multimodal graph representations by eliminating the unimodal bias problem resulting from the inter-modal semantic gap uncertainty. Extensive experimental results on DEAP, DREAMER, and MPED datasets under both subject-dependent and subject-independent scenarios demonstrate that (i) the proposed model outperforms State-Of-The-Art (SOTA) multimodal fusion models with fewer parameters and lower computational complexity; (ii) each key module and loss function contributes significantly to the performance enhancement of the proposed model; (iii) the proposed model can eliminate the unimodal bias problem effectively.},
  archive      = {J_NN},
  author       = {Guangqiang Li and Ning Chen and Hongqing Zhu and Jing Li and Zhangyong Xu and Zhiying Zhu},
  doi          = {10.1016/j.neunet.2025.107363},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107363},
  shortjournal = {Neural Netw.},
  title        = {Uncertainty-aware graph contrastive fusion network for multimodal physiological signal emotion recognition},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neural approach to the turing test: The role of emotions.
<em>NN</em>, <em>187</em>, 107362. (<a
href="https://doi.org/10.1016/j.neunet.2025.107362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As is well known, the Turing Test proposes the possibility of distinguishing the behavior of a machine from that of a human being through an experimental session. The Turing Test assesses whether a person asking questions to two different entities, can tell from their answers which of them is the human being and which is the machine. With the progress of Artificial Intelligence, the number of contexts in which the capacities of response of a machine will be indistinguishable from those of a human being is expected to increase rapidly. In order to configure a Turing Test in which it is possible to distinguish human behavior from machine behavior independently from the advances of Artificial Intelligence, at least in the short-medium term, it would be important to base it not on the differences between man and machine in terms of performance and dialogue capacity, but on some specific characteristic of the human mind that cannot be reproduced by the machine even in principle. We studied a new kind of test based on the hypothesis that such characteristic of the human mind exists and can be made experimentally evident. This peculiar characteristic is the emotional content of human cognition and, more specifically, its link with memory enhancement. To validate this hypothesis we recorded the EEG signals of 39 subjects that underwent a specific test and analyzed their signals with a neural network able to label similar signal patterns with similar binary codes. The results showed that, with a statistically significant difference, the test participants more easily recognized images associated in the past with an emotional reaction than those not associated with such a reaction. This distinction in our view is not accessible to a software system, even AI-based, and a Turing Test based on this feature of the mind may make distinguishable human versus machine responses.},
  archive      = {J_NN},
  author       = {Rita Pizzi and Hao Quan and Matteo Matteucci and Simone Mentasti and Roberto Sassi},
  doi          = {10.1016/j.neunet.2025.107362},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107362},
  shortjournal = {Neural Netw.},
  title        = {A neural approach to the turing test: The role of emotions},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial and frequency information fusion transformer for
image super-resolution. <em>NN</em>, <em>187</em>, 107351. (<a
href="https://doi.org/10.1016/j.neunet.2025.107351">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous works have indicated that Transformer-based models bring impressive image reconstruction performance in single image super-resolution (SISR). However, existing Transformer-based approaches utilize self-attention within non-overlapping windows. This restriction hinders the network’s ability to adopt large receptive fields, which are essential for capturing global information and establishing long-distance dependencies, especially in the early layers. To fully leverage global information and activate more pixels during the image reconstruction process, we have developed a Spatial and Frequency Information Fusion Transformer (SFFT) with an expansive receptive field. SFFT concurrently combines spatial and frequency domain information to comprehensively leverage their complementary strengths, capturing both local and global image features while integrating low and high-frequency information. Additionally, we utilize the overlapping cross-attention block (OCAB) to facilitate pixel transmission between adjacent windows, enhancing network performance. During the training stage, we incorporate the Fast Fourier Transform (FFT) loss, thereby fully leveraging the capabilities of our proposed modules and further tapping into the model’s potential. Extensive quantitative and qualitative evaluations on benchmark datasets indicate that the proposed algorithm surpasses state-of-the-art methods in terms of accuracy. Specifically, our method achieves a PSNR score of 32.67 dB on the Manga109 dataset, surpassing SwinIR by 0.64 dB and HAT by 0.19 dB, respectively. The source code and pre-trained models are available at https://github.com/Xufujie/SFFT},
  archive      = {J_NN},
  author       = {Yan Zhang and Fujie Xu and Yemei Sun and Jiao Wang},
  doi          = {10.1016/j.neunet.2025.107351},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107351},
  shortjournal = {Neural Netw.},
  title        = {Spatial and frequency information fusion transformer for image super-resolution},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A spatial–spectral fusion convolutional transformer network
with contextual multi-head self-attention for hyperspectral image
classification. <em>NN</em>, <em>187</em>, 107350. (<a
href="https://doi.org/10.1016/j.neunet.2025.107350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) can effectively extract local features, while Vision Transformer excels at capturing global features. Combining these two networks to enhance the classification performance of hyperspectral images (HSI) has garnered significant attention. However, most existing fusion methods introduce inductive biases for the Transformer by directly connecting convolutional modules and Transformer encoders for feature extraction but rarely enhance the Transformer’s ability to extract local contextual information through convolutional embedding. In this paper, we propose a spatial–spectral fusion convolutional Transformer method (SSFCT) with contextual multi-head self-attention (CMHSA) for HSI classification. Specifically, we first designed a local feature aggregation (LFA) module that utilizes a three-branch convolution architecture and attention layers to extract and enhance local spatial–spectral fusion features. Then, a novel CMHSA is built to extract interaction information of local contextual features through integrating static and dynamic local contextual representations from 3D convolution and attention mechanisms, and the CMHSA is integrated into the devised dual-branch spatial–spectral convolutional transformer (DSSCT) module to simultaneously capture global–local associations in both spatial and spectral domains. Finally, the attention feature fusion (AFF) module is proposed to fully obtain global–local spatial–spectral comprehensive features. Extensive experiments on five HSI datasets — Indian Pines, Salinas Valley, Houston2013, Botswana, and Yellow River Delta — outperform state-of-the-art methods, achieving overall accuracies of 98.03%, 99.68%, 98.65%, 97.97%, and 89.43%, respectively, showcasing its effectiveness for HSI classification.},
  archive      = {J_NN},
  author       = {Wuli Wang and Qi Sun and Li Zhang and Peng Ren and Jianbu Wang and Guangbo Ren and Baodi Liu},
  doi          = {10.1016/j.neunet.2025.107350},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107350},
  shortjournal = {Neural Netw.},
  title        = {A spatial–spectral fusion convolutional transformer network with contextual multi-head self-attention for hyperspectral image classification},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Task-augmented cross-view imputation network for partial
multi-view incomplete multi-label classification. <em>NN</em>,
<em>187</em>, 107349. (<a
href="https://doi.org/10.1016/j.neunet.2025.107349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world scenarios, multi-view multi-label learning often encounters the challenge of incomplete training data due to limitations in data collection and unreliable annotation processes. The absence of multi-view features impairs the comprehensive understanding of samples, omitting crucial details essential for classification. To address this issue, we present a task-augmented cross-view imputation network (TACVI-Net) for the purpose of handling partial multi-view incomplete multi-label classification. Specifically, we employ a two-stage network to derive highly task-relevant features to recover the missing views. In the first stage, we leverage the information bottleneck theory to obtain a discriminative representation of each view by extracting task-relevant information through a view-specific encoder-classifier architecture. In the second stage, an autoencoder based multi-view reconstruction network is utilized to extract high-level semantic representation of the augmented features and recover the missing data, thereby aiding the final classification task. Extensive experiments on five datasets demonstrate that our TACVI-Net outperforms other state-of-the-art methods.},
  archive      = {J_NN},
  author       = {Lian Zhao and Jie Wen and Xiaohuan Lu and Wai Keung Wong and Jiang Long and Wulin Xie},
  doi          = {10.1016/j.neunet.2025.107349},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107349},
  shortjournal = {Neural Netw.},
  title        = {Task-augmented cross-view imputation network for partial multi-view incomplete multi-label classification},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards zero-shot human–object interaction detection via
vision–language integration. <em>NN</em>, <em>187</em>, 107348. (<a
href="https://doi.org/10.1016/j.neunet.2025.107348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human–object interaction (HOI) detection aims to locate human–object pairs and identify their interaction categories in images. Most existing methods primarily focus on supervised learning, which relies on extensive manual HOI annotations. Such heavy reliance on closed-set supervised learning limits their generalization capabilities to unseen object categories. Inspired by the remarkable zero-shot capabilities of VLM, we propose a novel framework, termed Knowledge Integration to HOI (KI2HOI), that effectively integrates the knowledge of the visual–language model to improve zero-shot HOI detection. Specifically, we propose a ho-pair encoder to supplement contextual and interaction-specific semantic representation decoder into our model. Additionally, we propose two fusion strategies to facilitate prior knowledge transfer of VLM. One is visual-level fusion, producing more global context interaction features; another is language-level fusion, further enhancing the capability of VLM for HOI detection. Extensive experiments conducted on the mainstream HICO-DET and V-COCO datasets demonstrate that our model outperforms the previous methods in various zero-shot and full-supervised settings. The source code is available in https://github.com/xwyscut/K2HOI .},
  archive      = {J_NN},
  author       = {Weiying Xue and Qi Liu and Yuxiao Wang and Zhenao Wei and Xiaofen Xing and Xiangmin Xu},
  doi          = {10.1016/j.neunet.2025.107348},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107348},
  shortjournal = {Neural Netw.},
  title        = {Towards zero-shot human–object interaction detection via vision–language integration},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CFI-former: Efficient lane detection by multi-granularity
perceptual query attention transformer. <em>NN</em>, <em>187</em>,
107347. (<a href="https://doi.org/10.1016/j.neunet.2025.107347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benefiting from the booming development of Transformer methods, the performance of lane detection tasks has been rapidly improved. However, due to the influence of inaccurate lane line shape constraints, the query sequences of existing transformer-based lane line detection methods contain a large number of repetitive and invalid information regions, which leads to redundant information in the detection region and makes the processing of information on localized feature details of the lanes biased. In this paper, a multi-granularity perceptual query attention transformer lane detection method, CFI-Former, is proposed to achieve more accurate lane detection. Specifically, a multi-granularity perceptual query attention (GQA) module is designed to extract lane local detail information. By a two-stage query from coarse to fine, redundant key–value pairs with low information relevance are first filtered out, and then fine-grained token-to-token attention is executed on the remaining candidate regions. This module emphasizes the multi-granularity nuances of lane features from global to local, leading to more effective models based on lane line shape constraints. In addition, weighted adaptive LIoU loss ( L φ − L I oU ) is proposed to improve lane detection in more challenging scenarios by adaptively increasing the relative gradient of high IoU lane objects and the weight of the loss. Extensive experiments show that CFI-Former outperforms the baseline on two popular lane detection benchmark datasets.},
  archive      = {J_NN},
  author       = {Rong Gao and Siqi Hu and Lingyu Yan and Lefei Zhang and Jia Wu},
  doi          = {10.1016/j.neunet.2025.107347},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107347},
  shortjournal = {Neural Netw.},
  title        = {CFI-former: Efficient lane detection by multi-granularity perceptual query attention transformer},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive decoupling-fusion in siamese network for image
classification. <em>NN</em>, <em>187</em>, 107346. (<a
href="https://doi.org/10.1016/j.neunet.2025.107346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) are highly regarded for their ability to extract semantic information from visual inputs. However, this capability often leads to the inadvertent loss of important visual details. In this paper, we introduce an Adaptive Decoupling Fusion (ADF) designed to preserve these valuable visual details and integrate seamlessly with existing hierarchical models. Our approach emphasizes retaining and leveraging appearance information from the network’s shallow layers to enhance semantic understanding. We first decouple the appearance information from one branch of a Siamese Network and embed it into the deep feature space of the other branch. This facilitates a synergistic interaction: one branch supplies appearance information that benefits semantic understanding, while the other integrates this information into the semantic space. Traditional Siamese Networks typically use shared weights, which constrains the diversity of features that can be learned. To address this, we propose a differentiated collaborative learning where both branches receive the same input but are trained with cross-entropy loss, allowing them to have distinct weights. This enhances the network’s adaptability to specific tasks. To further optimize the decoupling and fusion, we introduce a Mapper module featuring depthwise separable convolution and a gated fusion mechanism. This module regulates the information flow between branches, balancing appearance and semantic information. Under fully self-supervised conditions, utilizing only minimal data augmentation, we achieve a top-1 accuracy of 81.11% on the ImageNet-1k dataset using ADF-ResNeXt-101.},
  archive      = {J_NN},
  author       = {Xi Yang and Pai Peng and Danyang Li and Yinghao Ye and Xiaohuan Lu},
  doi          = {10.1016/j.neunet.2025.107346},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107346},
  shortjournal = {Neural Netw.},
  title        = {Adaptive decoupling-fusion in siamese network for image classification},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-attention fusion and adaptive continual updating for
multimodal federated learning with heterogeneous data. <em>NN</em>,
<em>187</em>, 107345. (<a
href="https://doi.org/10.1016/j.neunet.2025.107345">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) enables collaborative model training without direct data sharing, facilitating knowledge exchange while ensuring data privacy. Multimodal federated learning (MFL) is particularly advantageous for decentralized multimodal data, effectively managing heterogeneous information across modalities. However, the diversity in environments and data collection methods among participating devices introduces substantial challenges due to non-independent and identically distributed (non-IID) data. Our experiments reveal that, despite the theoretical benefits of multimodal data, MFL under non-IID conditions often exhibits poor performance, even trailing traditional unimodal FL approaches. Additionally, MFL frequently encounter missing modality issues, further complicating the training process. To address these challenges, we propose several improvements: the federated self-attention multimodal (FSM) feature fusion method and the multimodal federated learning adaptive continual update (FedMAC) algorithm. Moreover, we utilize a Stable Diffusion model to mitigate the impact of missing image modality. Extensive experimental results demonstrate that our proposed methods outperform other state-of-the-art FL algorithms, enhancing both accuracy and robustness in MFL.},
  archive      = {J_NN},
  author       = {Kangning Yin and Zhen Ding and Xinhui Ji and Zhiguo Wang},
  doi          = {10.1016/j.neunet.2025.107345},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107345},
  shortjournal = {Neural Netw.},
  title        = {Self-attention fusion and adaptive continual updating for multimodal federated learning with heterogeneous data},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel one-layer neural network for solving quadratic
programming problems. <em>NN</em>, <em>187</em>, 107344. (<a
href="https://doi.org/10.1016/j.neunet.2025.107344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel one-layer neural network to solve quadratic programming problems in real time by using a control parameter and transforming the optimality conditions into a system of projection equations. The proposed network includes two existing dual networks as its special cases, and an existing model can be derived from it. In particular, another new model for linear and quadratic programming problems can be obtained from the proposed network. Meanwhile, a new Lyapunov function is constructed to ensure that the proposed network is Lyapunov stable and can converge to an optimal solution of the concerned problem under mild conditions. In contrast with the existing models for quadratic programming, the proposed network requires the least neurons while maintaining weaker stability conditions. The effectiveness and characteristics of the proposed model are demonstrated by the limited simulation results.},
  archive      = {J_NN},
  author       = {Xingbao Gao and Lili Du},
  doi          = {10.1016/j.neunet.2025.107344},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107344},
  shortjournal = {Neural Netw.},
  title        = {A novel one-layer neural network for solving quadratic programming problems},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inspired by pathogenic mechanisms: A novel gradual
multi-modal fusion framework for mild cognitive impairment diagnosis.
<em>NN</em>, <em>187</em>, 107343. (<a
href="https://doi.org/10.1016/j.neunet.2025.107343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mild cognitive impairment (MCI) is a precursor to Alzheimer’s disease (AD), and its progression involves complex pathogenic mechanisms. Specifically, disturbed by gene variants, the regulation of gene expression ultimately changes brain structure, resulting in the progression of brain diseases. However, the existing works rarely take these mechanisms into account when designing their diagnosis methods. Therefore, we propose a novel gradual multi-modal fusion framework to fuse representative data from each stage of disease progression in hybrid feature space, including single nucleotide polymorphism (SNP), gene expression (GE), and magnetic resonance imaging (MRI). Specifically, to integrate genetic sequence and expression data, we design a SNP-GE fusion module, which performs multi-modal fusion to obtain genetic embedding by considering the relation between SNP and GE. Compared with SNP-GE fusion, representation of genetic embedding and MRI have more obvious heterogeneity, especially correlation with disease. Therefore, we propose to align the manifold of genetic and imaging representations, which can explore the high-order relationship between imaging and genetic data in the presence of modal heterogeneity. Our proposed framework was validated using the Alzheimer’s Disease Neuroimaging Initiative dataset, and achieved diagnosis accuracy of 76.88%, 72.84%, 87.72%, and 95.00% for distinguishing MCI from control normal, lately MCI from early MCI, MCI from AD, and AD from control normal, respectively. Additionally, our proposed framework helps to identify some multi-modal biomarkers related to MCI progression. In summary, our proposed framework is effective not only for MCI diagnosis but also for guiding the further development of genetic and imaging-based brain studies. Our code is published at https://github.com/tianxu8822/workflow_MCI/tree/main/ .},
  archive      = {J_NN},
  author       = {Xu Tian and Hong-Dong Li and Hanhe Lin and Chao Li and Yu-Ping Wang and Harrison X. Bai and Wei Lan and Jin Liu},
  doi          = {10.1016/j.neunet.2025.107343},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107343},
  shortjournal = {Neural Netw.},
  title        = {Inspired by pathogenic mechanisms: A novel gradual multi-modal fusion framework for mild cognitive impairment diagnosis},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rethinking exploration–exploitation trade-off in
reinforcement learning via cognitive consistency. <em>NN</em>,
<em>187</em>, 107342. (<a
href="https://doi.org/10.1016/j.neunet.2025.107342">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exploration–exploitation dilemma is one of the fundamental challenges in deep reinforcement learning (RL). Agents must strike a trade-off between making decisions based on current beliefs or gathering more information. Prior work mostly prefers devising sophisticated exploration methods to ensure accurate target Q-values or learn rewards and actions association, which may not be intelligent enough for sample efficiency. In this paper, we propose to rethink the trade-off between exploration and exploitation from the perspective of cognitive consistency: humans tend to think and behave in line with their existing knowledge structures (maintaining cognitive consistency), yielding satisfactory results within a brief timeframe. We argue that maintaining consistency, specifically through pessimistic exploration, within the context of optimal policy-oriented cognition, can improve efficiency without compromising performance. To this end, we propose a Cognitive Consistency (CoCo) framework. CoCo first leverages a self-imitating distribution correction approach to pursue cognition oriented toward the optimal policy. Then, it conservatively implements pessimistic exploration by extracting novel inconsistency-minimization objectives inspired by label distribution learning. We validate our framework across various standard off-policy RL tasks and show that maintaining cognitive consistency improves sample efficiency and performance. Code is available at https://github.com/DkING-lv6/CoCo .},
  archive      = {J_NN},
  author       = {Da Wang and Wei Wei and Lin Li and Xin Wang and Jiye Liang},
  doi          = {10.1016/j.neunet.2025.107342},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107342},
  shortjournal = {Neural Netw.},
  title        = {Rethinking exploration–exploitation trade-off in reinforcement learning via cognitive consistency},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving transferability of adversarial examples via
statistical attribution-based attacks. <em>NN</em>, <em>187</em>,
107341. (<a href="https://doi.org/10.1016/j.neunet.2025.107341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial attacks are significant in uncovering vulnerabilities and assessing the robustness of deep neural networks (DNNs), offering profound insights into their internal mechanisms. Feature-level attacks, a potent approach, craft adversarial examples by extensively corrupting the intermediate-layer features of the source model during each iteration. However, it often has imprecise metrics to assess the significance of features and may impose constraints on the transferability of adversarial examples. To address these issues, this paper introduces the Statistical Attribution-based Attack (SAA) method, which emphasizes finding feature importance representations and refining optimization objectives, thereby achieving stronger attack performance. To calculate the Comprehensive Gradient for more accurate feature representation, we introduce the Region-wise Feature Disturbance and Gradient Information Aggregation, which can effectively disrupt the model’s attention focus areas. Subsequently, a statistical attribution-based approach is employed, leveraging the average feature information across layers to provide a more advantageous optimization objective. Experiments have validated the superiority of this method. Specifically, SAA improves the attack success rate by 9.3% compared with the second-best method. When combined with input transformation methods, it achieves an average success rate of 79.2% against eight leading defense models.},
  archive      = {J_NN},
  author       = {Hegui Zhu and Yanmeng Jia and Yue Yan and Ze Yang},
  doi          = {10.1016/j.neunet.2025.107341},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107341},
  shortjournal = {Neural Netw.},
  title        = {Improving transferability of adversarial examples via statistical attribution-based attacks},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised non-negative matrix factorization with
structure preserving for image clustering. <em>NN</em>, <em>187</em>,
107340. (<a href="https://doi.org/10.1016/j.neunet.2025.107340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning methods have wide applications thanks to the reasonable utilization for a part of label information of data. In recent years, non-negative matrix factorization (NMF) has received considerable attention because of its interpretability and practicality. Based on the advantages of semi-supervised learning and NMF, many semi-supervised NMF methods have been presented. However, these existing semi-supervised NMF methods construct a label matrix only containing elements 1 and 0 to represent the labeled data and further construct a label regularization, which neglects an intrinsic structure of NMF. To address the deficiency, in this paper, we propose a novel semi-supervised NMF method with structure preserving. Specifically, we first construct a new label matrix with weights and further construct a label constraint regularizer to both utilize the label information and maintain the intrinsic structure of NMF. Then, based on the label constraint regularizer, the basis images of labeled data are extracted for monitoring and modifying the basis images learning of all data by establishing a basis regularizer. Finally, incorporating the label constraint regularizer and the basis regularizer into NMF, we propose a new semi-supervised NMF method. To solve the optimization problem, a multiplicative updating algorithm is developed. The proposed method is applied to image clustering to test its performance. Experimental results on eight data sets demonstrate the effectiveness of the proposed method in contrast with state-of-the-art unsupervised and semi-supervised algorithms.},
  archive      = {J_NN},
  author       = {Wenjing Jing and Linzhang Lu and Weihua Ou},
  doi          = {10.1016/j.neunet.2025.107340},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107340},
  shortjournal = {Neural Netw.},
  title        = {Semi-supervised non-negative matrix factorization with structure preserving for image clustering},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing few-shot image classification through learnable
multi-scale embedding and attention mechanisms. <em>NN</em>,
<em>187</em>, 107339. (<a
href="https://doi.org/10.1016/j.neunet.2025.107339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of few-shot classification, the goal is to train a classifier using a limited number of samples while maintaining satisfactory performance. However, traditional metric-based methods exhibit certain limitations in achieving this objective. These methods typically rely on a single distance value between the query feature and support feature, thereby overlooking the contribution of shallow features. To overcome this challenge, we propose a novel approach in this paper. Our approach involves utilizing a multi-output embedding network that maps samples into distinct feature spaces. The proposed method extracts feature vectors at different stages, enabling the model to capture both global and abstract features. By utilizing these diverse feature spaces, our model enhances its performance. Moreover, employing a self-attention mechanism improves the refinement of features at each stage, leading to even more robust representations and improved overall performance. Furthermore, assigning learnable weights to each stage significantly improved performance and results. We conducted comprehensive evaluations on the MiniImageNet and FC100 datasets, specifically in the 5-way 1-shot and 5-way 5-shot scenarios. Additionally, we performed cross-domain tasks across eight benchmark datasets, achieving high accuracy in the testing domains. These evaluations demonstrate the efficacy of our proposed method in comparison to state-of-the-art approaches. https://github.com/FatemehAskari/MSENet},
  archive      = {J_NN},
  author       = {Fatemeh Askari and Amirreza Fateh and Mohammad Reza Mohammadi},
  doi          = {10.1016/j.neunet.2025.107339},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107339},
  shortjournal = {Neural Netw.},
  title        = {Enhancing few-shot image classification through learnable multi-scale embedding and attention mechanisms},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph neural networks with coarse- and fine-grained division
for mitigating label noise and sparsity. <em>NN</em>, <em>187</em>,
107338. (<a href="https://doi.org/10.1016/j.neunet.2025.107338">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have gained considerable prominence in semi-supervised learning tasks in processing graph-structured data, primarily owing to their message-passing mechanism, which largely relies on the availability of clean labels. However, in real-world scenarios, labels on nodes of graphs are inevitably noisy and sparsely labeled, significantly degrading the performance of GNNs. Exploring robust GNNs for semi-supervised node classification in the presence of noisy and sparse labels remains a critical challenge. Therefore, we propose a novel G raph N eural N etwork with C oarse- and F ine- G rained D ivision for mitigating label sparsity and noise, namely GNN-CFGD. The key idea of GNN-CFGD is reducing the negative impact of noisy labels via coarse- and fine-grained division, along with graph reconstruction. Specifically, we first investigate the effectiveness of linking unlabeled nodes to cleanly labeled nodes, demonstrating that this approach is more effective in combating labeling noise than linking to potentially noisy labeled nodes. Based on this observation, we introduce a Gaussian Mixture Model (GMM) based on the memory effect to perform a coarse-grained division of the given labels into clean and noisy labels. Next, we propose a clean labels oriented link that connects unlabeled nodes to cleanly labeled nodes, aimed at mitigating label sparsity and promoting supervision propagation. Furthermore, to provide refined supervision for noisy labeled nodes and additional supervision for unlabeled nodes, we fine-grain the noisy labeled and unlabeled nodes into two candidate sets based on confidence, respectively. Extensive experiments on various datasets demonstrate the superior effectiveness and robustness of GNN-CFGD.},
  archive      = {J_NN},
  author       = {Shuangjie Li and Baoming Zhang and Jianqing Song and Gaoli Ruan and Chongjun Wang and Junyuan Xie},
  doi          = {10.1016/j.neunet.2025.107338},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107338},
  shortjournal = {Neural Netw.},
  title        = {Graph neural networks with coarse- and fine-grained division for mitigating label noise and sparsity},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-training EEG discrimination model with weakly
supervised sample construction: An age-based perspective on ASD
evaluation. <em>NN</em>, <em>187</em>, 107337. (<a
href="https://doi.org/10.1016/j.neunet.2025.107337">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning for Electroencephalography (EEG) has become dominant in the tasks of discrimination and evaluation of brain disorders. However, despite its significant successes, this approach has long been facing challenges due to the limited availability of labeled samples and the individuality of subjects, particularly in complex scenarios such as Autism Spectrum Disorders (ASD). To facilitate the efficient optimization of EEG discrimination models in the face of these limitations, this study has developed a framework called STEM (Self-Training EEG Model). STEM accomplishes this by self-training the model, which involves initializing it with limited labeled samples and optimizing it with self-constructed samples. (1) Model initialization with multi-task learning: A multi-task model (MAC) comprising an AutoEncoder and a classifier offers guidance for subsequent pseudo-labeling. This guidance includes task-related latent EEG representations and prediction probabilities of unlabeled samples. The AutoEncoder, which consists of depth-separable convolutions and BiGRUs, is responsible for learning comprehensive EEG representations through the EEG reconstruction task. Meanwhile, the classifier, trained using limited labeled samples through supervised learning, directs the model’s attention towards capturing task-related features. (2) Model optimization aided by pseudo-labeled samples construction: Next, trustworthy pseudo-labels are assigned to the unlabeled samples, and this approach (PLASC) combines the sample’s distance relationship in the feature space mapped by the encoder with the sample’s predicted probability, using the initial MAC model as a reference. The constructed pseudo-labeled samples then support the self-training of MAC to learn individual information from new subjects, potentially enhancing the adaptation of the optimized model to samples from new subjects. The STEM framework has undergone an extensive evaluation, comparing it to state-of-the-art counterparts, using resting-state EEG data collected from 175 ASD-suspicious children spanning different age groups. The observed results indicate the following: (1) STEM achieves the best performance, with an accuracy of 88.33% and an F1-score of 87.24%, and (2) STEM’s multi-task learning capability outperforms supervised methods when labeled data is limited. More importantly, the use of PLASC improves the model’s performance in ASD discrimination across different age groups, resulting in an increase in accuracy (3%–8%) and F1-scores (4%–10%). These increments are approximately 6% higher than those achieved by the comparison methods.},
  archive      = {J_NN},
  author       = {Tengfei Gao and Dan Chen and Meiqi Zhou and Yaodong Wang and Yiping Zuo and Weiping Tu and Xiaoli Li and Jingying Chen},
  doi          = {10.1016/j.neunet.2025.107337},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107337},
  shortjournal = {Neural Netw.},
  title        = {Self-training EEG discrimination model with weakly supervised sample construction: An age-based perspective on ASD evaluation},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diverse teacher–students for deep safe semi-supervised
learning under class mismatch. <em>NN</em>, <em>187</em>, 107336. (<a
href="https://doi.org/10.1016/j.neunet.2025.107336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning can significantly boost model performance by leveraging unlabeled data, particularly when labeled data is scarce. However, real-world unlabeled data often contain unseen-class samples, which can hinder the classification of seen classes. To address this issue, mainstream safe SSL methods suggest detecting and discarding unseen-class samples from unlabeled data. Nevertheless, these methods typically employ a single-model strategy to simultaneously tackle both the classification of seen classes and the detection of unseen classes. Our research indicates that such an approach may lead to conflicts during training, resulting in suboptimal model optimization. Inspired by this, we introduce a novel framework named Diverse Teacher–Students ( DTS ), which uniquely utilizes dual teacher–student models to individually and effectively handle these two tasks. DTS employs a novel uncertainty score to softly separate unseen-class and seen-class data from the unlabeled set, and intelligently creates an additional ( K +1)th class supervisory signal for training. By training both teacher–student models with all unlabeled samples, DTS can enhance the classification of seen classes while simultaneously improving the detection of unseen classes. Comprehensive experiments demonstrate that DTS surpasses baseline methods across a variety of datasets and configurations. Our code and models can be publicly accessible on the link https://github.com/Zhanlo/DTS .},
  archive      = {J_NN},
  author       = {Qikai Wang and Rundong He and Yongshun Gong and Chunxiao Ren and Haoliang Sun and Xiaoshui Huang and Yilong Yin},
  doi          = {10.1016/j.neunet.2025.107336},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107336},
  shortjournal = {Neural Netw.},
  title        = {Diverse Teacher–Students for deep safe semi-supervised learning under class mismatch},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comprehensive evaluation of pipelines for classification of
psychiatric disorders using multi-site resting-state fMRI datasets.
<em>NN</em>, <em>187</em>, 107335. (<a
href="https://doi.org/10.1016/j.neunet.2025.107335">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objective classification biomarkers that are developed using resting-state functional magnetic resonance imaging (rs-fMRI) data are expected to contribute to more effective treatment for psychiatric disorders. Unfortunately, no widely accepted biomarkers are available at present, partially because of the large variety of analysis pipelines for their development. In this study, we comprehensively evaluated analysis pipelines using a large-scale, multi-site fMRI dataset for major depressive disorder (MDD). We explored combinations of options in four sub-processes of the analysis pipelines: six types of brain parcellation, four types of functional connectivity (FC) estimations, three types of site-difference harmonization, and five types of machine-learning methods. A total of 360 different MDD classification biomarkers were constructed using the SRPBS dataset acquired with unified protocols (713 participants from four sites) as the discovery dataset, and datasets from other projects acquired with heterogeneous protocols (449 participants from four sites) were used for independent validation. We repeated the procedure after swapping the roles of the two datasets to identify superior pipelines, regardless of the discovery dataset. The classification results of the top 10 biomarkers showed high similarity, and weight similarity was observed between eight of the biomarkers, except for two that used both data-driven parcellation and FC computation. We applied the top 10 pipelines to the datasets of other psychiatric disorders (autism spectrum disorder and schizophrenia), and eight of the biomarkers exhibited sufficient classification performance for both disorders. Our results will be useful for establishing a standardized pipeline for classification biomarkers.},
  archive      = {J_NN},
  author       = {Yuji Takahara and Yuto Kashiwagi and Tomoki Tokuda and Junichiro Yoshimoto and Yuki Sakai and Ayumu Yamashita and Toshinori Yoshioka and Hidehiko Takahashi and Hiroto Mizuta and Kiyoto Kasai and Akira Kunimitsu and Naohiro Okada and Eri Itai and Hotaka Shinzato and Satoshi Yokoyama and Yoshikazu Masuda and Yuki Mitsuyama and Go Okada and Yasumasa Okamoto and Takashi Itahashi and Okito Yamashita},
  doi          = {10.1016/j.neunet.2025.107335},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107335},
  shortjournal = {Neural Netw.},
  title        = {Comprehensive evaluation of pipelines for classification of psychiatric disorders using multi-site resting-state fMRI datasets},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SHFormer: Dynamic spectral filtering convolutional neural
network and high-pass kernel generation transformer for adaptive MRI
reconstruction. <em>NN</em>, <em>187</em>, 107334. (<a
href="https://doi.org/10.1016/j.neunet.2025.107334">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attention Mechanism (AM) selectively focuses on essential information for imaging tasks and captures relationships between regions from distant pixel neighborhoods to compute feature representations. Accelerated magnetic resonance image (MRI) reconstruction can benefit from AM, as the imaging process involves acquiring Fourier domain measurements that influence the image representation in a non-local manner. However, AM-based models are more adept at capturing low-frequency information and have limited capacity in constructing high-frequency representations, restricting the models to smooth reconstruction. Secondly, AM-based models need mode-specific retraining for multimodal MRI data as their knowledge is restricted to local contextual variations within modes that might be inadequate to capture the diverse transferable features across heterogeneous data domains. To address these challenges, we propose a neuromodulation-based discriminative multi-spectral AM for scalable MRI reconstruction, that can (i) propagate the context-aware high-frequency details for high-quality image reconstruction, and (ii) capture features reusable to deviated unseen domains in multimodal MRI, to offer high practical value for the healthcare industry and researchers. The proposed network consists of a spectral filtering convolutional neural network to capture mode-specific transferable features to generalize to deviated MRI data domains and a dynamic high-pass kernel generation transformer that focuses on high-frequency details for improved reconstruction. We have evaluated our model on various aspects, such as comparative studies in supervised and self-supervised learning, diffusion model-based training, closed-set and open-set generalization under heterogeneous MRI data, and interpretation-based analysis. Our results show that the proposed method offers scalable and high-quality reconstruction with best improvement margins of ∼ 1 dB in PSNR and ∼ 0.01 in SSIM under unseen scenarios. Our code is available at https://github.com/sriprabhar/SHFormer .},
  archive      = {J_NN},
  author       = {Sriprabha Ramanarayanan and Rahul G.S. and Mohammad Al Fahim and Keerthi Ram and Ramesh Venkatesan and Mohanasankar Sivaprakasam},
  doi          = {10.1016/j.neunet.2025.107334},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107334},
  shortjournal = {Neural Netw.},
  title        = {SHFormer: Dynamic spectral filtering convolutional neural network and high-pass kernel generation transformer for adaptive MRI reconstruction},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ternary spike-based neuromorphic signal processing system.
<em>NN</em>, <em>187</em>, 107333. (<a
href="https://doi.org/10.1016/j.neunet.2025.107333">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Networks (DNNs) have been successfully implemented across various signal processing fields, resulting in significant enhancements in performance. However, DNNs generally require substantial computational resources, leading to significant economic costs and posing challenges for their deployment on resource-constrained edge devices. In this study, we take advantage of spiking neural networks (SNNs) and quantization technologies to develop an energy-efficient and lightweight neuromorphic signal processing system. Our system is characterized by two principal innovations: a threshold-adaptive encoding (TAE) method and a quantized ternary SNN (QT-SNN). The TAE method can efficiently encode time-varying analog signals into sparse ternary spike trains, thereby reducing energy and memory demands for signal processing. QT-SNN, compatible with ternary spike trains from the TAE method, quantifies both membrane potentials and synaptic weights to reduce memory requirements while maintaining performance. Extensive experiments are conducted on two typical signal-processing tasks: speech and electroencephalogram recognition. The results demonstrate that our neuromorphic signal processing system achieves state-of-the-art (SOTA) performance with a 94% reduced memory requirement. Furthermore, through theoretical energy consumption analysis, our system shows 7 . 5 × energy saving compared to other SNN works. The efficiency and efficacy of the proposed system highlight its potential as a promising avenue for energy-efficient signal processing.},
  archive      = {J_NN},
  author       = {Shuai Wang and Dehao Zhang and Ammar Belatreche and Yichen Xiao and Hongyu Qing and Wenjie Wei and Malu Zhang and Yang Yang},
  doi          = {10.1016/j.neunet.2025.107333},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107333},
  shortjournal = {Neural Netw.},
  title        = {Ternary spike-based neuromorphic signal processing system},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attribute-guided feature fusion network with
knowledge-inspired attention mechanism for multi-source remote sensing
classification. <em>NN</em>, <em>187</em>, 107332. (<a
href="https://doi.org/10.1016/j.neunet.2025.107332">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Land use and land cover (LULC) classification is a popular research area in remote sensing. The information of single-modal data is insufficient for accurate classification, especially in complex scenes, while the complementarity of multi-modal data such as hyperspectral images (HSIs) and light detection and ranging (LiDAR) data could effectively improve classification performance. The attention mechanism has recently been widely used in multi-modal LULC classification methods to achieve better feature representation. However, the knowledge of data is insufficiently considered in these methods, such as spectral mixture in HSIs and inconsistent spatial scales of different categories in LiDAR data. Moreover, multi-modal features contain different physical attributes, HSI features can represent spectral information of several channels while LiDAR features focus on elevation information at the spatial dimension. Ignoring these attributes, feature fusion may introduce redundant information and effect detrimentally on classification. In this paper, we propose an attribute-guided feature fusion network with knowledge-inspired attention mechanisms, named AFNKA. Focusing on the spectral characteristics of HSI and elevation information of LiDAR data, we design the knowledge-inspired attention mechanism to explore enhanced features. Especially, a novel adaptive cosine estimator (ACE) based attention module is presented to learn features with more discriminability, which adequately utilizes the spatial–spectral correlation of HSI mixed pixels. In the fusion stage, two novel attribute-guided fusion modules are developed to selectively aggregate multi-modal features, which sufficiently exploit the correlations between the spatial–spectral property of HSI features and the spatial-elevation property of LiDAR features. Experimental results on several multi-source datasets quantitatively indicate that the proposed AFNKA significantly outperforms the state-of-the-art methods.},
  archive      = {J_NN},
  author       = {Xiao Pan and Changzhe Jiao and Bo Yang and Hao Zhu and Jinjian Wu},
  doi          = {10.1016/j.neunet.2025.107332},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107332},
  shortjournal = {Neural Netw.},
  title        = {Attribute-guided feature fusion network with knowledge-inspired attention mechanism for multi-source remote sensing classification},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exponential stability of infinite-dimensional impulsive
stochastic systems with poisson jumps under aperiodically intermittent
control. <em>NN</em>, <em>187</em>, 107331. (<a
href="https://doi.org/10.1016/j.neunet.2025.107331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the problem of mean square exponential stability (ES) for a class of impulsive stochastic infinite-dimensional systems with Poisson jumps (ISIDSP) using aperiodically intermittent control (AIC). It provides a detailed analysis of impulsive disturbances, and the related inequalities are given for the two cases when the impulse perturbation occurs at the start time points of the control and rest intervals or non-startpoints, respectively. Additionally, in virtue of Yosida approximating systems, combining with the Lyapunov method, graph theory and the above inequalities, criteria for ES of the above impulsive stochastic infinite-dimensional systems are established under AIC for these two perturbation scenarios. These criteria elucidate the effects of the impulsive perturbation strength, the ratio of control period, to rest period, and network topology on ES. Finally, the theoretical results are applied to a class of neural networks with reaction–diffusion processes, and the effectiveness of the findings is validated through numerical simulations.},
  archive      = {J_NN},
  author       = {Yiqun Liu and Lili Chen and Yanfeng Zhao and Zhen Wang},
  doi          = {10.1016/j.neunet.2025.107331},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107331},
  shortjournal = {Neural Netw.},
  title        = {Exponential stability of infinite-dimensional impulsive stochastic systems with poisson jumps under aperiodically intermittent control},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PanoGen++: Domain-adapted text-guided panoramic environment
generation for vision-and-language navigation. <em>NN</em>,
<em>187</em>, 107320. (<a
href="https://doi.org/10.1016/j.neunet.2025.107320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision-and-language navigation (VLN) tasks require agents to navigate three-dimensional environments guided by natural language instructions, offering substantial potential for diverse applications. However, the scarcity of training data impedes progress in this field. This paper introduces PanoGen++, a novel framework that addresses this limitation by generating varied and pertinent panoramic environments for VLN tasks. PanoGen++ incorporates pre-trained diffusion models with domain-specific fine-tuning, employing parameter-efficient techniques such as low-rank adaptation to minimize computational costs. We investigate two settings for environment generation: masked image inpainting and recursive image outpainting. The former maximizes novel environment creation by inpainting masked regions based on textual descriptions, while the latter facilitates agents’ learning of spatial relationships within panoramas. Empirical evaluations on room-to-room (R2R), room-for-room (R4R), and cooperative vision-and-dialog navigation (CVDN) datasets reveal significant performance enhancements: a 2.44% increase in success rate on the R2R test leaderboard, a 0.63% improvement on the R4R validation unseen set, and a 0.75-meter enhancement in goal progress on the CVDN validation unseen set. PanoGen++ augments the diversity and relevance of training environments, resulting in improved generalization and efficacy in VLN tasks.},
  archive      = {J_NN},
  author       = {Sen Wang and Dongliang Zhou and Liang Xie and Chao Xu and Ye Yan and Erwei Yin},
  doi          = {10.1016/j.neunet.2025.107320},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107320},
  shortjournal = {Neural Netw.},
  title        = {PanoGen++: Domain-adapted text-guided panoramic environment generation for vision-and-language navigation},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learn the global prompt in the low-rank tensor space for
heterogeneous federated learning. <em>NN</em>, <em>187</em>, 107319. (<a
href="https://doi.org/10.1016/j.neunet.2025.107319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning collaborates with multiple clients to train a global model, enhancing the model generalization while allowing the local data transmission-free and security. However, federated learning currently faces three intractable challenges: (1) The large number of model parameters result in an excessive communication burden. (2) The non-independently and identically distributed local data induces the degradation of global model. (3) The model heterogeneity renders traditional federated aggregation infeasible. To dissipate the three difficulties, we propose to learn the global prompt in the low-rank tensor space (FedGPT) for heterogeneous federated learning. Specifically, we employ the prompts rather than the model parameters as the carrier of local knowledge to achieve the information interaction between multiple clients. Since the prompts only have a very small number of variables, the communication volume is greatly reduced. To cope with the data heterogeneity, the prompts from different clients are stacked into the third-order tensors, on which the tensor singular value decomposition is performed to extract the global information. Furthermore, the proposed FedGPT possesses the ability to handle the model heterogeneity, the local models of different sizes can transfer the knowledge with the help of the prompts to improve the performance. Extensive experiments on three real-world datasets are conducted. Overall, FedGPT outperforms other state-of-the-art compared methods by up to 13.21%, and achieves less than 3% of communication volume of FedAvg, demonstrating the superiority of the proposed FedGPT.},
  archive      = {J_NN},
  author       = {Lele Fu and Sheng Huang and Yuecheng Li and Chuan Chen and Chuanfu Zhang and Zibin Zheng},
  doi          = {10.1016/j.neunet.2025.107319},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107319},
  shortjournal = {Neural Netw.},
  title        = {Learn the global prompt in the low-rank tensor space for heterogeneous federated learning},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HCPI-HRL: Human causal perception and inference-driven
hierarchical reinforcement learning. <em>NN</em>, <em>187</em>, 107318.
(<a href="https://doi.org/10.1016/j.neunet.2025.107318">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dependency on extensive expert knowledge for defining subgoals in hierarchical reinforcement learning (HRL) restricts the training efficiency and adaptability of HRL agents in complex, dynamic environments. Inspired by human-guided causal discovery skills, we proposed a novel method, Human Causal Perception and Inference-driven Hierarchical Reinforcement Learning (HCPI-HRL), designed to infer diverse, effective subgoal structures as intrinsic rewards and incorporate critical objects from dynamic environmental states using stable causal relationships. The HCPI-HRL method is supposed to guide an agent’s exploration direction and promote the reuse of learned subgoal structures across different tasks. Our designed HCPI-HRL comprises two levels: the top level operates as a meta controller, assigning subgoals discovered based on human-driven causal critical object perception and causal structure inference; the bottom level employs the Proximal Policy Optimisation (PPO) algorithm to accomplish the assigned subgoals. Experiments conducted across discrete and continuous control environments demonstrated that HCPI-HRL outperforms benchmark methods such as hierarchical and adjacency PPO in terms of training efficiency, exploration capability, and transferability. Our research extends the potential of HRL methods incorporating human-guided causal modelling to infer the effective relationships across subgoals, enhancing the agent’s capability to learn efficient policies in dynamic environments with sparse reward signals.},
  archive      = {J_NN},
  author       = {Bin Chen and Zehong Cao and Wolfgang Mayer and Markus Stumptner and Ryszard Kowalczyk},
  doi          = {10.1016/j.neunet.2025.107318},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107318},
  shortjournal = {Neural Netw.},
  title        = {HCPI-HRL: Human causal perception and inference-driven hierarchical reinforcement learning},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Balancing user preferences by social networks: A
condition-guided social recommendation model for mitigating popularity
bias. <em>NN</em>, <em>187</em>, 107317. (<a
href="https://doi.org/10.1016/j.neunet.2025.107317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social recommendation models weave social interactions into their design to provide uniquely personalized recommendation results for users. However, social networks not only amplify the popularity bias in recommendation models, resulting in more frequent recommendation of hot items and fewer long-tail items, but also include a substantial amount of redundant information that is essentially meaningless for the model’s performance. Existing social recommendation models often integrate the entire social network directly, with little effort to filter or adjust social information to mitigate popularity bias introduced by the social network. In this paper, we propose a Condition-Guided Social Recommendation Model (named CGSoRec) to mitigate the model’s popularity bias by denoising the social network and adjusting the weights of user’s social preferences. More specifically, CGSoRec first includes a Condition-Guided Social Denoising Model (CSD) to remove redundant social relations in the social network for capturing users’ social preferences with items more precisely. Then, CGSoRec calculates users’ social preferences based on denoised social network and adjusts the weights in users’ social preferences to make them can counteract the popularity bias present in the recommendation model. At last, CGSoRec includes a Condition-Guided Diffusion Recommendation Model (CGD) to introduce the adjusted social preferences as conditions to control the recommendation results for a debiased direction. Comprehensive experiments on three real-world datasets demonstrate the effectiveness of our proposed method. The anonymous code is in: https://anonymous.4open.science/r/CGSoRec-2B72 .},
  archive      = {J_NN},
  author       = {Xin He and Wenqi Fan and Ruobing Wang and Yili Wang and Ying Wang and Shirui Pan and Xin Wang},
  doi          = {10.1016/j.neunet.2025.107317},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107317},
  shortjournal = {Neural Netw.},
  title        = {Balancing user preferences by social networks: A condition-guided social recommendation model for mitigating popularity bias},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ADAMT: Adaptive distributed multi-task learning for
efficient image recognition in mobile ad-hoc networks. <em>NN</em>,
<em>187</em>, 107316. (<a
href="https://doi.org/10.1016/j.neunet.2025.107316">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed machine learning in mobile adhoc networks faces significant challenges due to the limited computational resources of devices, non-IID data distribution, and dynamic network topology. Existing approaches often rely on centralized coordination and stable network conditions, which may not be feasible in practice. To address these issues, we propose an adaptive distributed multi-task learning framework called ADAMT for efficient image recognition in resource-constrained mobile ad hoc networks. ADAMT introduces three key innovations: (1) a feature expansion mechanism that enhances the expressiveness of local models by leveraging task-specific information; (2) a deep hashing technique that enables efficient on-device retrieval and multi-task fusion; and (3) an adaptive communication strategy that dynamically adjusts the model updating process based on network conditions and node reliability. The proposed framework allows each device to perform personalized model training on its local dataset while collaboratively updating the shared parameters with neighboring nodes. Extensive experiments on the ImageNet dataset demonstrate the superiority of ADAMT over state-of-the-art methods. ADAMT achieves a top-1 accuracy of 0.867, outperforming existing distributed learning approaches. Moreover, ADAMT significantly reduces the communication overhead and accelerates the convergence speed by 2.69 times compared to traditional distributed SGD. The adaptive communication strategy effectively balances the trade-off between model performance and resource consumption, making ADAMT particularly suitable for resource-constrained environments. Our work sheds light on the design of efficient and robust distributed learning algorithms for mobile adhoc networks and paves the way for deploying advanced machine learning applications on edge devices.},
  archive      = {J_NN},
  author       = {Jia Zhao and Wei Zhao and Yunan Zhai and Liyuan Zhang and Yan Ding},
  doi          = {10.1016/j.neunet.2025.107316},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107316},
  shortjournal = {Neural Netw.},
  title        = {ADAMT: Adaptive distributed multi-task learning for efficient image recognition in mobile ad-hoc networks},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FingerPoseNet: A finger-level multitask learning network
with residual feature sharing for 3D hand pose estimation. <em>NN</em>,
<em>187</em>, 107315. (<a
href="https://doi.org/10.1016/j.neunet.2025.107315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hand pose estimation approaches commonly rely on shared hand feature maps to regress the 3D locations of all hand joints. Subsequently, they struggle to enhance finger-level features which are invaluable in capturing joint-to-finger associations and articulations. To address this limitation, we propose a finger-level multitask learning network with residual feature sharing, named FingerPoseNet, for accurate 3D hand pose estimation from a depth image. FingerPoseNet comprises three stages: (a) a shared base feature map extraction backbone based on pre-trained ResNet-50; (b) a finger-level multitask learning stage that extracts and enhances feature maps for each finger and the palm; and (c) a multitask fusion layer for consolidating the estimation results obtained by each subtask. We exploit multitask learning by decoupling the hand pose estimation task into six subtasks dedicated to each finger and palm. Each subtask is responsible for subtask-specific feature extraction, enhancement, and 3D keypoint regression. To enhance subtask-specific features, we propose a residual feature-sharing approach scaled up to mine supplementary information from all subtasks. Experiments performed on five challenging public hand pose datasets, including ICVL, NYU, MSRA, Hands-2019-Task1, and HO3D-v3 demonstrate significant improvements in accuracy compared with state-of-the-art approaches.},
  archive      = {J_NN},
  author       = {Tekie Tsegay Tewolde and Ali Asghar Manjotho and Prodip Kumar Sarker and Zhendong Niu},
  doi          = {10.1016/j.neunet.2025.107315},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107315},
  shortjournal = {Neural Netw.},
  title        = {FingerPoseNet: A finger-level multitask learning network with residual feature sharing for 3D hand pose estimation},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A general debiasing framework with counterfactual reasoning
for multimodal public speaking anxiety detection. <em>NN</em>,
<em>187</em>, 107314. (<a
href="https://doi.org/10.1016/j.neunet.2025.107314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Public Speaking Anxiety Detection (MPSAD), which aims to identify the anxiety states of learners, has attracted widespread attention. Unfortunately, the current MPSAD task inevitably suffers from the impact of latent different types of multimodal hybrid biases, such as context bias, label bias and keyword bias. Models may rely on these biases as shortcuts, preventing them from fully utilizing all three modalities to learn multimodal knowledge. Existing methods primarily focus on addressing specific types of biases, but anticipating bias types when designing these methods is challenging, as we cannot foresee all possible biases. To tackle this issue, we propose a General Multimodal Counterfactual Reasoning debiasing framework (GMCR), which eliminates multimodal hybrid biases from a unified causal perspective. Specifically, this plug-and-play debiasing framework removes multimodal hybrid biases by disentangling causal and biased features and capturing adverse effects via a counterfactual branch. It then subtracts spurious correlations during inference for unbiased predictions. Due to the challenge of collecting speech video data, there are currently limited high-quality datasets available for the MPSAD task. To overcome this scarcity, we create a new large-scale fine-grained Multimodal English Public Speaking Anxiety (ME-PSA) dataset. Extensive experiments on our ME-PSA and two benchmarks demonstrate the superiority of our proposed framework, with improvements of over 2.00% in accuracy and 4.00% in F1 score compared to the vanilla SOTA baselines. 1},
  archive      = {J_NN},
  author       = {Tingting Zhang and Yangfu Zhu and Bin Wu and Chunping Zheng and Jiachen Tan and Zihua Xiong},
  doi          = {10.1016/j.neunet.2025.107314},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107314},
  shortjournal = {Neural Netw.},
  title        = {A general debiasing framework with counterfactual reasoning for multimodal public speaking anxiety detection},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous graph neural network with adaptive relation
reconstruction. <em>NN</em>, <em>187</em>, 107313. (<a
href="https://doi.org/10.1016/j.neunet.2025.107313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topological structures of real-world graphs often exhibit heterogeneity involving diverse nodes and relation types. In recent years, heterogeneous graph learning methods utilizing meta-paths to capture composite relations and guide neighbor selection have garnered considerable attention. However, meta-path based approaches may establish connections between nodes of different categories while overlooking relations between nodes of the same category, decreasing the quality of node embeddings. In light of this, this paper proposes a Heterogeneous Graph Neural Network with Adaptive Relation Reconstruction (HGNN-AR 2 ) that adaptively adjusts the relations to alleviate connection deficiencies and heteromorphic issues. HGNN-AR 2 is grounded on distinct connections derived from multiple meta-paths. By examining the homomorphic correlations of latent features from each meta-path, we reshape the cross-node connections to explore the pertinent latent relations. Through the relation reconstruction, we unveil unique connections reflected by each meta-path and incorporate them into graph convolutional networks for more comprehensive representations. The proposed model is evaluated on various benchmark heterogeneous graph datasets, demonstrating superior performance compared to state-of-the-art competitors.},
  archive      = {J_NN},
  author       = {Weihong Lin and Zhaoliang Chen and Yuhong Chen and Shiping Wang},
  doi          = {10.1016/j.neunet.2025.107313},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107313},
  shortjournal = {Neural Netw.},
  title        = {Heterogeneous graph neural network with adaptive relation reconstruction},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ABVS breast tumour segmentation via integrating CNN with
dilated sampling self-attention and feature interaction transformer.
<em>NN</em>, <em>187</em>, 107312. (<a
href="https://doi.org/10.1016/j.neunet.2025.107312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the rapid increase in breast cancer incidence, the Automated Breast Volume Scanner (ABVS) is developed to screen breast tumours efficiently and accurately. However, reviewing ABVS images is a challenging task owing to the significant variations in sizes and shapes of breast tumours. We propose a novel 3D segmentation network (i.e., DST-C) that combines a convolutional neural network (CNN) with a dilated sampling self-attention Transformer (DST). In our network, the global features extracted from the DST branch are guided by the detailed local information provided by the CNN branch, which adapts to the diversity of tumour size and morphology. For medical images, especially ABVS images, the scarcity of annotation leads to difficulty in model training. Therefore, a self-supervised learning method based on a dual-path approach for mask image modelling is introduced to generate valuable representations of images. In addition, a unique postprocessing method is proposed to reduce the false-positive rate and improve the sensitivity simultaneously. The experimental results demonstrate that our model has achieved promising 3D segmentation and detection performance using our in-house dataset. Our code is available at: https://github.com/magnetliu/dstc-net .},
  archive      = {J_NN},
  author       = {Yiyao Liu and Jinyao Li and Yi Yang and Cheng Zhao and Yongtao Zhang and Peng Yang and Lei Dong and Xiaofei Deng and Ting Zhu and Tianfu Wang and Wei Jiang and Baiying Lei},
  doi          = {10.1016/j.neunet.2025.107312},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107312},
  shortjournal = {Neural Netw.},
  title        = {ABVS breast tumour segmentation via integrating CNN with dilated sampling self-attention and feature interaction transformer},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual selective fusion transformer network for hyperspectral
image classification. <em>NN</em>, <em>187</em>, 107311. (<a
href="https://doi.org/10.1016/j.neunet.2025.107311">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer has achieved satisfactory results in the field of hyperspectral image (HSI) classification. However, existing Transformer models face two key challenges when dealing with HSI scenes characterized by diverse land cover types and rich spectral information: (1) A fixed receptive field overlooks the effective contextual scales required by various HSI objects; (2) invalid self-attention features in context fusion affect model performance. To address these limitations, we propose a novel Dual Selective Fusion Transformer Network (DSFormer) for HSI classification. DSFormer achieves joint spatial and spectral contextual modeling by flexibly selecting and fusing features across different receptive fields, effectively reducing unnecessary information interference by focusing on the most relevant spatial–spectral tokens. Specifically, we design a Kernel Selective Fusion Transformer Block (KSFTB) to learn an optimal receptive field by adaptively fusing spatial and spectral features across different scales, enhancing the model’s ability to accurately identify diverse HSI objects. Additionally, we introduce a Token Selective Fusion Transformer Block (TSFTB), which strategically selects and combines essential tokens during the spatial–spectral self-attention fusion process to capture the most crucial contexts. Extensive experiments conducted on four benchmark HSI datasets demonstrate that the proposed DSFormer significantly improves land cover classification accuracy, outperforming existing state-of-the-art methods. Specifically, DSFormer achieves overall accuracies of 96.59%, 97.66%, 95.17%, and 94.59% in the Pavia University, Houston, Indian Pines, and Whu-HongHu datasets, respectively, reflecting improvements of 3.19%, 1.14%, 0.91%, and 2.80% over the previous model. The code will be available online at https://github.com/YichuXu/DSFormer .},
  archive      = {J_NN},
  author       = {Yichu Xu and Di Wang and Lefei Zhang and Liangpei Zhang},
  doi          = {10.1016/j.neunet.2025.107311},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107311},
  shortjournal = {Neural Netw.},
  title        = {Dual selective fusion transformer network for hyperspectral image classification},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revisiting face forgery detection towards generalization.
<em>NN</em>, <em>187</em>, 107310. (<a
href="https://doi.org/10.1016/j.neunet.2025.107310">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face forgery detection aims to distinguish AI generated fake faces with real faces. With the rapid development of face forgery creation algorithms, a large number of generative models have been proposed, which gradually reduce the local distortion phenomenon or the specific frequency traces in these models. At the same time, in the process of face data compression and transmission, distortion phenomenon and specific frequency cues could be eliminated, which brings severe challenges to the performance and generalization ability of face forgery detection. To promote the progress on face forgery detection research towards generalization, we present the first comprehensive overview and in-depth analysis of the generalizable face forgery detection methods. We categorize the target of generalizable face forgery detection into the robustness on novel and unknown forged images, and robustness on damaged low-quality images. We discuss representative generalization strategies including the aspects of data augmentation, multi-source learning, fingerprints detection, feature enhancement, temporal analysis, vision-language detection. We summarize the widely used datasets and the generalization performance of state-of-the-art methods in terms of robustness to novel unknown forgery as well as damaged quality forgery types. Finally, we discuss under-investigated open issues on face forgery detection towards generalization in six directions, including building a new generation of datasets, extracting strong forgery cues, considering identity features in face forgery detection, security and fairness of forgery detectors, the potential of large models in forgery detection and test-time adaptation. Our revisit of face forgery detection towards generalization will help promote the research and application of face forgery detection on real-world unconstrained conditions in the future.},
  archive      = {J_NN},
  author       = {Chunlei Peng and Tao Chen and Decheng Liu and Huiqing Guo and Nannan Wang and Xinbo Gao},
  doi          = {10.1016/j.neunet.2025.107310},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107310},
  shortjournal = {Neural Netw.},
  title        = {Revisiting face forgery detection towards generalization},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DRTN: Dual relation transformer network with feature erasure
and contrastive learning for multi-label image classification.
<em>NN</em>, <em>187</em>, 107309. (<a
href="https://doi.org/10.1016/j.neunet.2025.107309">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of multi-label image classification (MLIC) task is to simultaneously identify multiple objects present in an image. Several researchers directly flatten 2D feature maps into 1D grid feature sequences, and utilize Transformer encoder to capture the correlations of grid features to learn object relationships. Although obtaining promising results, these Transformer-based methods lose spatial information. In addition, current attention-based models often focus only on salient feature regions, but ignore other potential useful features that contribute to MLIC task. To tackle these problems, we present a novel D ual R elation T ransformer N etwork ( DRTN ) for MLIC task, which can be trained in an end-to-end manner. Concretely, to compensate for the loss of spatial information of grid features resulting from the flattening operation, we adopt a grid aggregation scheme to generate pseudo-region features, which does not need to make additional expensive annotations to train object detector. Then, a new dual relation enhancement (DRE) module is proposed to capture correlations between objects using two different visual features, thereby complementing the advantages provided by both grid and pseudo-region features. After that, we design a new feature enhancement and erasure (FEE) module to learn discriminative features and mine additional potential valuable features. By using attention mechanism to discover the most salient feature regions and removing them with region-level erasure strategy, our FEE module is able to mine other potential useful features from the remaining parts. Further, we devise a novel contrastive learning (CL) module to encourage the foregrounds of salient and potential features to be closer, while pushing their foregrounds further away from background features. This manner compels our model to learn discriminative and valuable features more comprehensively. Extensive experiments demonstrate that DRTN method surpasses current MLIC models on three challenging benchmarks, i.e. , MS-COCO 2014, PASCAL VOC 2007, and NUS-WIDE datasets.},
  archive      = {J_NN},
  author       = {Wei Zhou and Kang Lin and Zhijie Zheng and Dihu Chen and Tao Su and Haifeng Hu},
  doi          = {10.1016/j.neunet.2025.107309},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107309},
  shortjournal = {Neural Netw.},
  title        = {DRTN: Dual relation transformer network with feature erasure and contrastive learning for multi-label image classification},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structural network measures reveal the emergence of
heavy-tailed degree distributions in lottery ticket multilayer
perceptrons. <em>NN</em>, <em>187</em>, 107308. (<a
href="https://doi.org/10.1016/j.neunet.2025.107308">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural networks (ANNs) were originally modeled after their biological counterparts, but have since conceptually diverged in many ways. The resulting network architectures are not well understood, and furthermore, we lack the quantitative tools to characterize their structures. Network science provides an ideal mathematical framework with which to characterize systems of interacting components, and has transformed our understanding across many domains, including the mammalian brain. Yet, little has been done to bring network science to ANNs. In this work, we propose tools that leverage and adapt network science methods to measure both global- and local-level characteristics of ANNs. Specifically, we focus on the structures of efficient multilayer perceptrons as a case study, which are sparse and systematically pruned such that they share many characteristics with real-world networks. We use adapted network science metrics to show that the pruning process leads to the emergence of a spanning subnetwork (lottery ticket multilayer perceptrons) with complex architecture. This complex network exhibits global and local characteristics, including heavy-tailed nodal degree distributions and dominant weighted pathways, that mirror patterns observed in human neuronal connectivity. Furthermore, alterations in network metrics precede catastrophic decay in performance as the network is heavily pruned. This network science-driven approach to the analysis of artificial neural networks serves as a valuable tool to establish and improve biological fidelity, increase the interpretability, and assess the performance of artificial neural networks. Significance Statement Artificial neural network architectures have become increasingly complex, often diverging from their biological counterparts in many ways. To design plausible “brain-like” architectures, whether to advance neuroscience research or to improve explainability, it is essential that these networks optimally resemble their biological counterparts. Network science tools offer valuable information about interconnected systems, including the brain, but have not attracted much attention for analyzing artificial neural networks. Here, we present the significance of our work: •We adapt network science tools to analyze the structural characteristics of artificial neural networks. •We demonstrate that organizational patterns similar to those observed in the mammalian brain emerge through the pruning process alone. The convergence on these complex network features in both artificial neural networks and biological brain networks is compelling evidence for their optimality in information processing capabilities. •Our approach is a significant first step towards a network science-based understanding of artificial neural networks, and has the potential to shed light on the biological fidelity of artificial neural networks.},
  archive      = {J_NN},
  author       = {Chris Kang and Jasmine A. Moore and Samuel Robertson and Matthias Wilms and Emma K. Towlson and Nils D. Forkert},
  doi          = {10.1016/j.neunet.2025.107308},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107308},
  shortjournal = {Neural Netw.},
  title        = {Structural network measures reveal the emergence of heavy-tailed degree distributions in lottery ticket multilayer perceptrons},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PrivCore: Multiplication-activation co-reduction for
efficient private inference. <em>NN</em>, <em>187</em>, 107307. (<a
href="https://doi.org/10.1016/j.neunet.2025.107307">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The marriage of deep neural network (DNN) and secure 2-party computation (2PC) enables private inference (PI) on the encrypted client-side data and server-side models with both privacy and accuracy guarantees, coming at the cost of orders of magnitude communication and latency penalties. Prior works on designing PI-friendly network architectures are confined to mitigating the overheads associated with non-linear (e.g., ReLU) operations, assuming other linear computations are free. Recent works have shown that linear convolutions can no longer be ignored and are responsible for the majority of communication in PI protocols. In this work, we present PrivCore , a framework that jointly optimizes the alternating linear and non-linear DNN operators via a careful co-design of sparse Winograd convolution and fine-grained activation reduction, to improve high-efficiency ciphertext computation without impacting the inference precision. Specifically, being aware of the incompatibility between the spatial pruning and Winograd convolution, we propose a two-tiered Winograd-aware structured pruning method that removes spatial filters and Winograd vectors from coarse to fine-grained for multiplication reduction, both of which are specifically optimized for Winograd convolution in a structured pattern. PrivCore further develops a novel sensitivity-based differentiable activation approximation to automate the selection of ineffectual ReLUs and polynomial options. PrivCore also supports the dynamic determination of coefficient-adaptive polynomial replacement to mitigate the accuracy degradation. Extensive experiments on various models and datasets consistently validate the effectiveness of PrivCore , achieving 2 . 2 × communication reduction with 1.8% higher accuracy compared with SENet (ICLR 2023) on CIFAR-100, and 2 . 0 × total communication reduction with iso-accuracy compared with CoPriv (NeurIPS 2023) on ImageNet.},
  archive      = {J_NN},
  author       = {Zhi Pang and Lina Wang and Fangchao Yu and Kai Zhao and Bo Zeng and Shuwang Xu},
  doi          = {10.1016/j.neunet.2025.107307},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107307},
  shortjournal = {Neural Netw.},
  title        = {PrivCore: Multiplication-activation co-reduction for efficient private inference},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DuPt: Rehearsal-based continual learning with dual prompts.
<em>NN</em>, <em>187</em>, 107306. (<a
href="https://doi.org/10.1016/j.neunet.2025.107306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rehearsal-based continual learning methods usually involve reviewing a small number of representative samples to enable the network to learn new contents while retaining old knowledge. However, existing works overlook two crucial factors: (1) While the network prioritizes learning new data at incremental stages, it exhibits weaker generalization capabilities when trained individually on limited samples from specific categories, in contrast to training on large-scale samples across multiple categories simultaneously. (2) Knowledge distillation of a limited set of old samples can transfer certain existing knowledge, but imposing strong constraints may hinder knowledge transfer and restrict the ability of the network from the current stage to capture fresh knowledge. To alleviate these issues, we propose a rehearsal-based continual learning method with dual prompts, termed DuPt. First, we propose an input-aware prompt, an input-level cue that utilizes an input prior to querying for valid cue information. These hints serve as an additional complement to help the input samples generate more rational and diverse distributions. Second, we introduce a proxy feature prompt, a feature-level hint that bridges the knowledge gap between the teacher and student models to maintain consistency in the feature transfer process, reinforcing feature plasticity and stability. This is because differences in network features between the new and old incremental stages could affect the generalization of their new models if strictly aligned. Our proposed prompt can act as a consistency regularization to avoid feature conflicts caused by the differences between network features. Extensive experiments validate the effectiveness of our method, which can seamlessly integrate with existing methods, leading to performance improvements.},
  archive      = {J_NN},
  author       = {Shengqin Jiang and Daolong Zhang and Fengna Cheng and Xiaobo Lu and Qingshan Liu},
  doi          = {10.1016/j.neunet.2025.107306},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107306},
  shortjournal = {Neural Netw.},
  title        = {DuPt: Rehearsal-based continual learning with dual prompts},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complex quantized minimum error entropy with fiducial
points: Theory and application in model regression. <em>NN</em>,
<em>187</em>, 107305. (<a
href="https://doi.org/10.1016/j.neunet.2025.107305">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minimum error entropy with fiducial points (MEEF) has gained significant attention due to its excellent performance in mitigating the adverse effects of non-Gaussian noise in the fields of machine learning and signal processing. However, the original MEEF algorithm suffers from high computational complexity due to the double summation of error samples. The quantized MEEF (QMEEF), proposed by Zheng et al. alleviates this computational burden through strategic quantization techniques, providing a more efficient solution. In this paper, we extend the application of these techniques to the complex domain, introducing complex QMEEF (CQMEEF). We theoretically introduce and prove the fundamental properties and convergence of CQMEEF. Furthermore, we apply this novel method to the training of a range of Linear-in-parameters (LIP) models, demonstrating its broad applicability. Experimental results show that CQMEEF achieves high precision in regression tasks involving various noise-corrupted datasets, exhibiting effectiveness under unfavorable conditions, and surpassing existing methods across critical performance metrics. Consequently, CQMEEF not only offers an efficient computational alternative but also opens up new avenues for dealing with complex data in regression tasks.},
  archive      = {J_NN},
  author       = {Bingqing Lin and Guobing Qian and Zongli Ruan and Junhui Qian and Shiyuan Wang},
  doi          = {10.1016/j.neunet.2025.107305},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107305},
  shortjournal = {Neural Netw.},
  title        = {Complex quantized minimum error entropy with fiducial points: Theory and application in model regression},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RISE-editing: Rotation-invariant neural point fields with
interactive segmentation for fine-grained and efficient editing.
<em>NN</em>, <em>187</em>, 107304. (<a
href="https://doi.org/10.1016/j.neunet.2025.107304">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Radiance Fields (NeRF) have shown great potential for synthesizing novel views. Currently, despite the existence of some initial controllable and editable NeRF methods, they remain limited in terms of efficient and fine-grained editing capabilities, hinders the creative editing abilities and potential applications for NeRF. In this paper, we present the rotation-invariant neural point fields with interactive segmentation for fine-grained and efficient editing. Editing the implicit field presents a significant challenge, as varying the orientation of the corresponding explicit scaffold—whether point, mesh, volume, or other representations—may lead to a notable decline in rendering quality. By leveraging the complementary strengths of implicit NeRF-based representations and explicit point-based representations, we introduce a novel rotation-invariant neural point field representation. This representation enables the learning of local contents using Cartesian coordinates, leading to significant improvements in scene rendering quality after fine-grained editing. To achieve this rotation-invariant representation, we carefully design a Rotation-Invariant Neural Inverse Distance Weighting Interpolation (RNIDWI) module to aggregate the neural points. To enable more efficient and flexible cross-scene compositing, we disentangle the traditional NeRF representation into two components: a scene-agnostic rendering module and the scene-specific neural point fields. Furthermore, we present a multi-view ensemble learning strategy to lift the 2D inconsistent zero-shot segmentation results to 3D neural points field in real-time without post retraining. With simple click-based prompts on 2D images, user can efficiently segment the 3D neural point field and manipulate the corresponding neural points, enabling fine-grained editing of the implicit fields. Extensive experimental results demonstrate that our method offers enhanced editing capabilities and simplified editing process for users, delivers photorealistic rendering quality for novel views, and surpasses related methods in terms of the space–time efficiency and the types of editing functions they can achieve. The code is available at https://github.com/yuzewang1998/RISE-Editing .},
  archive      = {J_NN},
  author       = {Yuze Wang and Junyi Wang and Chen Wang and Yue Qi},
  doi          = {10.1016/j.neunet.2025.107304},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107304},
  shortjournal = {Neural Netw.},
  title        = {RISE-editing: Rotation-invariant neural point fields with interactive segmentation for fine-grained and efficient editing},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unambiguous granularity distillation for asymmetric image
retrieval. <em>NN</em>, <em>187</em>, 107303. (<a
href="https://doi.org/10.1016/j.neunet.2025.107303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous asymmetric image retrieval methods based on knowledge distillation have primarily focused on aligning the global features of two networks to transfer global semantic information from the gallery network to the query network. However, these methods often fail to effectively transfer local semantic information, limiting the fine-grained alignment of feature representation spaces between the two networks. To overcome this limitation, we propose a novel approach called Layered-Granularity Localized Distillation (GranDist). GranDist constructs layered feature representations that balance the richness of contextual information with the granularity of local features. As we progress through the layers, the contextual information becomes more detailed, but the semantic gap between networks can widen, complicating the transfer process. To address this challenge, GranDist decouples the feature maps at each layer to capture local features at different granularities and establishes distillation pipelines focused on effectively transferring these contextualized local features. In addition, we introduce an Unambiguous Localized Feature Selection (UnamSel) method, which leverages a well-trained fully connected layer to classify these contextual features as either ambiguous or unambiguous. By discarding the ambiguous features, we prevent the transfer of irrelevant or misleading information, such as background elements that are not pertinent to the retrieval task. Extensive experiments on various benchmark datasets demonstrate that our method outperforms state-of-the-art techniques and significantly enhances the performance of previous asymmetric retrieval approaches.},
  archive      = {J_NN},
  author       = {Hongrui Zhang and Yi Xie and Haoquan Zhang and Cheng Xu and Xuandi Luo and Donglei Chen and Xuemiao Xu and Huaidong Zhang and Pheng Ann Heng and Shengfeng He},
  doi          = {10.1016/j.neunet.2025.107303},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107303},
  shortjournal = {Neural Netw.},
  title        = {Unambiguous granularity distillation for asymmetric image retrieval},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hy-DeFake: Hypergraph neural networks for detecting fake
news in online social networks. <em>NN</em>, <em>187</em>, 107302. (<a
href="https://doi.org/10.1016/j.neunet.2025.107302">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays social media is the primary platform for people to obtain news and share information. Combating online fake news has become an urgent task to reduce the damage it causes to society. Existing methods typically improve their fake news detection performances by utilizing textual auxiliary information (such as relevant retweets and comments) or simple structural information ( i.e. , graph construction). However, these methods face two challenges. First, an increasing number of users tend to directly forward the source news without adding comments, resulting in a lack of textual auxiliary information. Second, simple graphs are unable to extract complex relations beyond pairwise association in a social context. Given that real-world social networks are intricate and involve high-order relations, we argue that exploring beyond pairwise relations between news and users is crucial for fake news detection. Therefore, we propose constructing an attributed hypergraph to represent non-textual and high-order relations for user participation in news spreading. We also introduce a hypergraph neural network-based method called Hy-DeFake to tackle the challenges. Our proposed method captures semantic information from news content, credibility information from involved users, and high-order correlations between news and users to learn distinctive embeddings for fake news detection. The superiority of Hy-DeFake is demonstrated through experiments conducted on four widely-used datasets, and it is compared against nine baselines using four evaluation metrics.},
  archive      = {J_NN},
  author       = {Xing Su and Jian Yang and Jia Wu and Zitai Qiu},
  doi          = {10.1016/j.neunet.2025.107302},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107302},
  shortjournal = {Neural Netw.},
  title        = {Hy-DeFake: Hypergraph neural networks for detecting fake news in online social networks},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantum federated learning with pole-angle quantum local
training and trainable measurement. <em>NN</em>, <em>187</em>, 107301.
(<a href="https://doi.org/10.1016/j.neunet.2025.107301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, quantum federated learning (QFL) has received significant attention as an innovative paradigm. QFL has remarkable features by employing quantum neural networks (QNNs) instead of conventional neural networks owing to quantum supremacy. In order to enhance the flexibility and reliability of classical QFL frameworks, this paper proposes a novel slimmable QFL (SlimQFL) incorporating QNN-grounded slimmable neural network (QSNN) architectures. This innovative design considers time-varying wireless communication channels and computing resource constraints. This framework ensures higher efficiency by using fewer parameters with no performance loss. Furthermore, the proposed QNN is novel according to the implementation of trainable measurement within QFL. The fundamental concept of our QSNN is designed based on the key characteristics of separated training and the dynamic exploitation of joint angle and pole parameters. Our performance evaluation results verify that using both parameters, our proposed QSNN-based SlimQFL achieves higher classification accuracy than QFL and ensures transmission stability, particularly in poor channel conditions.},
  archive      = {J_NN},
  author       = {Soohyun Park and Hyunsoo Lee and Seok Bin Son and Soyi Jung and Joongheon Kim},
  doi          = {10.1016/j.neunet.2025.107301},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107301},
  shortjournal = {Neural Netw.},
  title        = {Quantum federated learning with pole-angle quantum local training and trainable measurement},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EBM-WGF: Training energy-based models with wasserstein
gradient flow. <em>NN</em>, <em>187</em>, 107300. (<a
href="https://doi.org/10.1016/j.neunet.2025.107300">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy-based models (EBMs) show their efficiency in density estimation. However, MCMC sampling in traditional EBMs suffers from expensive computation. Although EBMs with minimax game avoid the above drawback, the energy estimation and generator’s optimization are not always stable. We find that the reason for this instability arises from the inaccuracy of minimizing KL divergence between generative and energy distribution along a vanilla gradient flow. In this paper, we leverage the Wasserstein gradient flow (WGF) of the KL divergence to correct the optimization direction of the generator in the minimax game. Different from existing WGF-based models, we pullback the WGF to parameter space and solve it with a variational scheme for bounded solution error. We propose a new EBM with WGF that overcomes the instability of the minimax game and avoids computational MCMC sampling in traditional methods, as we observe that the solution of WGF in our approach is equivalent to Langevin dynamic in EBMs with MCMC sampling. The empirical experiments on toy and natural datasets validate the effectiveness of our approach.},
  archive      = {J_NN},
  author       = {Ben Wan and Cong Geng and Tianyi Zheng and Jia Wang},
  doi          = {10.1016/j.neunet.2025.107300},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107300},
  shortjournal = {Neural Netw.},
  title        = {EBM-WGF: Training energy-based models with wasserstein gradient flow},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic memory auto-encoding network for abnormal
behavior detection in surveillance video. <em>NN</em>, <em>187</em>,
107299. (<a href="https://doi.org/10.1016/j.neunet.2025.107299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abnormal behavior detection in surveillance video, as one of the essential functions in the intelligent surveillance system, plays a vital role in anti-terrorism, maintaining stability, and ensuring social security. Aiming at the problem of extremely imbalance between normal behavior data and abnormal behavior data, the probabilistic memory model-based network is designed to learn from the distribution of normal behaviors and guide the detection of abnormal behavior. An auto-encoding model is employed as the backbone network, and the gap between the predicted future frame and the real frame is used to measure the degree of abnormality. An autoregressive conditional probability estimation model and a normal distribution memory model are employed as auxiliary modules, to achieve the prediction of normal frames. When extracting temporal and spatial features in the backbone network, the causal three-dimensional convolution and time-dimension shared fully connected layers are used to avoid future information leakage and ensure the timing of information. In addition, from the perspective of probability entropy and behavioral modality diversity, autoregressive probability model is proposed to fit the distribution of input normal frame, so the network converges to the low entropy state of the normal behavior distribution. The memory module stores the feature of normal behavior in historical data, and injects the current input data. The memory vector and the encoding vector are concatenated along the time dimension and input to the decoder, realizing normal frame prediction. Using public datasets, ablation and comparison experiments show that the proposed algorithm has significant advantages in anomaly detection.},
  archive      = {J_NN},
  author       = {Jinsheng Xiao and Jingyi Wu and Shurui Wang and Qiuze Yu and Honggang Xie and Yuan-Fang Wang},
  doi          = {10.1016/j.neunet.2025.107299},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107299},
  shortjournal = {Neural Netw.},
  title        = {Probabilistic memory auto-encoding network for abnormal behavior detection in surveillance video},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dataset-free weight-initialization on restricted boltzmann
machine. <em>NN</em>, <em>187</em>, 107297. (<a
href="https://doi.org/10.1016/j.neunet.2025.107297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In feed-forward neural networks, dataset-free weight-initialization methods such as LeCun, Xavier (or Glorot), and He initializations have been developed. These methods randomly determine the initial values of weight parameters based on specific distributions (e.g., Gaussian or uniform distributions) without using training datasets. To the best of the authors’ knowledge, such a dataset-free weight-initialization method is yet to be developed for restricted Boltzmann machines (RBMs), which are probabilistic neural networks consisting of two layers. In this study, we derive a dataset-free weight-initialization method for Bernoulli–Bernoulli RBMs based on statistical mechanical analysis. In the proposed weight-initialization method, the weight parameters are drawn from a Gaussian distribution with zero mean. The standard deviation of the Gaussian distribution is optimized based on our hypothesis that a standard deviation providing a larger layer correlation (LC) between the two layers improves the learning efficiency. The expression of the LC is derived based on a statistical mechanical analysis. The optimal value of the standard deviation corresponds to the maximum point of the LC. The proposed weight-initialization method is identical to Xavier initialization in a specific case (i.e., when the sizes of the two layers are the same, the random variables of the layers are { − 1 , 1 } -binary, and all bias parameters are zero). The validity of the proposed weight-initialization method is demonstrated in numerical experiments using a toy dataset and real-world datasets.},
  archive      = {J_NN},
  author       = {Muneki Yasuda and Ryosuke Maeno and Chako Takahashi},
  doi          = {10.1016/j.neunet.2025.107297},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107297},
  shortjournal = {Neural Netw.},
  title        = {Dataset-free weight-initialization on restricted boltzmann machine},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Continual learning of conjugated visual representations
through higher-order motion flows. <em>NN</em>, <em>187</em>, 107296.
(<a href="https://doi.org/10.1016/j.neunet.2025.107296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning with neural networks from a continuous stream of visual information presents several challenges due to the non-i.i.d. nature of the data. However, it also offers novel opportunities to develop representations that are consistent with the information flow. In this paper we investigate the case of unsupervised continual learning of pixel-wise features subject to multiple motion-induced constraints, therefore named motion-conjugated feature representations . Differently from existing approaches, motion is not a given signal (either ground-truth or estimated by external modules), but is the outcome of a progressive and autonomous learning process, occurring at various levels of the feature hierarchy. Multiple motion flows are estimated with neural networks and characterized by different levels of abstractions, spanning from traditional optical flow to other latent signals originating from higher-level features, hence called higher-order motions. Continuously learning to develop consistent multi-order flows and representations is prone to trivial solutions, which we counteract by introducing a self-supervised contrastive loss, spatially-aware and based on flow-induced similarity. We assess our model on photorealistic synthetic streams and real-world videos, comparing to pre-trained state-of-the art feature extractors (also based on Transformers) and to recent unsupervised learning models, significantly outperforming these alternatives.},
  archive      = {J_NN},
  author       = {Simone Marullo and Matteo Tiezzi and Marco Gori and Stefano Melacci},
  doi          = {10.1016/j.neunet.2025.107296},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107296},
  shortjournal = {Neural Netw.},
  title        = {Continual learning of conjugated visual representations through higher-order motion flows},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Augmenting sparse behavior data for user identity linkage
with self-generated by model and mixup-generated samples. <em>NN</em>,
<em>187</em>, 107295. (<a
href="https://doi.org/10.1016/j.neunet.2025.107295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The user identity linkage task aims to associate user accounts belonging to the same individual by utilizing user data. This task is relevant in domains such as recommendation systems, where user-generated content (i.e., behavioral data) serves as the key information for identifying users. However, user identity linkage tasks relying on behavioral data face two primary challenges due to data sparsity: insufficient user behavior data and the presence of low-frequency behavior items. These issues hinder accurate modeling and exacerbate representation errors. To address these challenges, we propose two data augmentation methods: self-generated samples by the model and mixup-generated samples. Collectively, these methods are referred to as SGAMDA (Self-generated by Model and Mixup-generated Samples-based Data Augmentation). The self-generated samples method uses Variational Autoencoders to generate new training data by decoding samples in the representation space. The mixup-generated samples method creates new training data by mixing the behavior data of different user groups, thereby alleviating data sparsity. SGAMDA categorizes user behavior data based on data volume and the proportion of low-frequency behaviors to guide the two data augmentation strategies. We evaluate SGAMDA on the Movies2Books and CDs2Movies datasets for user identity linkage tasks. The results show that SGAMDA significantly improves prediction accuracy, enhancing behavior representation through the proposed data augmentation methods.},
  archive      = {J_NN},
  author       = {Hongren Huang and Jianxin Li and Feihong Lu and Lihong Wang and Qian Li and Qingyun Sun},
  doi          = {10.1016/j.neunet.2025.107295},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107295},
  shortjournal = {Neural Netw.},
  title        = {Augmenting sparse behavior data for user identity linkage with self-generated by model and mixup-generated samples},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hyperspectral anomaly detection with self-supervised anomaly
prior. <em>NN</em>, <em>187</em>, 107294. (<a
href="https://doi.org/10.1016/j.neunet.2025.107294">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral anomaly detection (HAD) can identify and locate the targets without any known information and is widely applied in Earth observation and military fields. The majority of existing HAD methods use the low-rank representation (LRR) model to separate the background and anomaly through mathematical optimization, in which the anomaly is optimized with a handcrafted sparse prior (e.g., ℓ 2 , 1 -norm). However, this may not be ideal since they overlook the spatial structure present in anomalies and make the detection result largely dependent on manually set sparsity. To tackle these problems, we redefine the optimization criterion for the anomaly in the LRR model with a self-supervised network called self-supervised anomaly prior (SAP). This prior is obtained by the pretext task of self-supervised learning, which is customized to learn the characteristics of hyperspectral anomalies. Specifically, this pretext task is a classification task to distinguish the original hyperspectral image (HSI) and the pseudo-anomaly HSI, where the pseudo-anomaly is generated from the original HSI and designed as a prism with arbitrary polygon bases and arbitrary spectral bands. In addition, a dual-purified strategy is proposed to provide a more refined background representation with an enriched background dictionary, facilitating the separation of anomalies from complex backgrounds. Extensive experiments on various hyperspectral datasets demonstrate that the proposed SAP offers a more accurate and interpretable solution than other advanced HAD methods.},
  archive      = {J_NN},
  author       = {Yidan Liu and Kai Jiang and Weiying Xie and Jiaqing Zhang and Yunsong Li and Leyuan Fang},
  doi          = {10.1016/j.neunet.2025.107294},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107294},
  shortjournal = {Neural Netw.},
  title        = {Hyperspectral anomaly detection with self-supervised anomaly prior},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anxiety disorder identification with biomarker detection
through subspace-enhanced hypergraph neural network. <em>NN</em>,
<em>187</em>, 107293. (<a
href="https://doi.org/10.1016/j.neunet.2025.107293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose a subspace-enhanced hypergraph neural network (seHGNN) for classifying anxiety disorders (AD), which are prevalent mental illnesses that affect a significant portion of the global population. Our seHGNN model utilizes a learnable incidence matrix to strengthen the influence of hyperedges in graphs and enhance the feature extraction performance of hypergraph neural networks (HGNNs). Then, we integrate multimodal data on the brain limbic system into a hypergraph within an existing binary hypothesis testing framework. Experimental results demonstrate that our seHGNN achieves a remarkable accuracy of 84.46% for AD classification. By employing an ensemble learning strategy, we can further improve its performance, achieving a high accuracy of 94.1%. Our method outperforms other deep-learning-based methods, particularly GNN-based methods. Furthermore, our seHGNN successfully identifies discriminative AD biomarkers that align with existing reports, providing strong evidence supporting the effectiveness and interpretability of our proposed method.},
  archive      = {J_NN},
  author       = {Yibin Tang and Jikang Ding and Ying Chen and Yuan Gao and Aimin Jiang and Chun Wang},
  doi          = {10.1016/j.neunet.2025.107293},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107293},
  shortjournal = {Neural Netw.},
  title        = {Anxiety disorder identification with biomarker detection through subspace-enhanced hypergraph neural network},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Memory flow-controlled knowledge tracing with three stages.
<em>NN</em>, <em>187</em>, 107292. (<a
href="https://doi.org/10.1016/j.neunet.2025.107292">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Tracing (KT), as a pivotal technology in intelligent education systems, analyzes students’ learning data to infer their knowledge acquisition and predict their future performance. Recent advancements in KT recognize the importance of memory laws on knowledge acquisition but neglect modeling the inherent structure of memory, which leads to the inconsistency between explicit student learning and implicit memory transformation. Therefore, to enhance the consistency, we propose a novel memory flow-controlled knowledge tracing with three stages (MFCKT). According to information processing theory, we deconstruct learning into: sensory registration, short-term encoding, and long-term memory retrieval stages. Specifically, to extract sensory memory, MFCKT maximizes the similarity between positive augmentation views of learning sequence representations through contrastive pre-training. Then, to transform sensory memory into short-term memory, MFCKT fuses relational and temporal properties of sensory memory through a dual-channel structure composed of attention and recurrent neural networks. Furthermore, for obtaining long-term memory, MFCKT designs a monotonic gating mechanism to compute weights of hidden memory states, and then performs read-write operations on the memory matrix. Finally, MFCKT combines long-term and short-term memory vectors to retrieve latent knowledge states for future performance prediction. Extensive experimental results on five real-world datasets verify the superiority and interpretability of MFCKT.},
  archive      = {J_NN},
  author       = {Tao Huang and Junjie Hu and Huali Yang and Shengze Hu and Jing Geng and Xinjia Ou},
  doi          = {10.1016/j.neunet.2025.107292},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107292},
  shortjournal = {Neural Netw.},
  title        = {Memory flow-controlled knowledge tracing with three stages},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-view graph-of-graph representation learning with graph
transformer for graph-level anomaly detection. <em>NN</em>,
<em>187</em>, 107291. (<a
href="https://doi.org/10.1016/j.neunet.2025.107291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-Level Anomaly Detection (GLAD) endeavors to pinpoint a small subset of anomalous graphs that deviate from the normal data distribution within a given set of graph data. Existing GLAD methods typically rely on Graph Neural Networks (GNNs) to extract graph-level representations, which are then used for the detection task. However, the inherent limited receptive field of GNNs may exclude crucial anomalous information embedded within the graph. Moreover, the inadequate modeling of cross-graph relationships limits the exploration of connections between different graphs, thus restricting the model’s ability to uncover inter-graph anomalous patterns. In this paper, we propose a novel approach called Dual-View Graph-of-Graph Representation Learning Network for unsupervised GLAD, which takes into account both intra-graph and inter-graph perspectives. Firstly, to enhance the capability of mining intra-graph information, we introduce a Graph Transformer that enhances the receptive field of the GNNs by considering both attribute and structural information. This augmentation enables a comprehensive exploration of the information encoded within the graph. Secondly, to explicitly capture the cross-graph dependencies, we devise a Graph-of-Graph-based dual-view representation learning network to explicitly capture cross-graph interdependencies. Attribute and structure-based graph-of-graph representations are induced, facilitating a comprehensive understanding of the relationships between graphs. Finally, we utilize anomaly scores from different perspectives to quantify the extent of anomalies present in each graph. This multi-perspective evaluation provides a more comprehensive assessment of anomalies within the graph data. Extensive experiments conducted on multiple benchmark datasets demonstrate the effectiveness of our proposed method in detecting anomalies within graph data.},
  archive      = {J_NN},
  author       = {Wangyu Jin and Huifang Ma and Yingyue Zhang and Zhixin Li and Liang Chang},
  doi          = {10.1016/j.neunet.2025.107291},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107291},
  shortjournal = {Neural Netw.},
  title        = {Dual-view graph-of-graph representation learning with graph transformer for graph-level anomaly detection},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Episodic memory-double actor–critic twin delayed deep
deterministic policy gradient. <em>NN</em>, <em>187</em>, 107286. (<a
href="https://doi.org/10.1016/j.neunet.2025.107286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing deep reinforcement learning (DRL) algorithms suffer from the problem of low sample efficiency. Episodic memory allows DRL algorithms to remember and use past experiences with high return, thereby improving sample efficiency. However, due to the high dimensionality of the state–action space in continuous action tasks, previous methods in continuous action tasks often only utilize the information stored in episodic memory, rather than directly employing episodic memory for action selection as done in discrete action tasks. We suppose that episodic memory retains the potential to guide action selection in continuous control tasks. Our objective is to enhance sample efficiency by leveraging episodic memory for action selection in such tasks—either reducing the number of training steps required to achieve comparable performance or enabling the agent to obtain higher rewards within the same number of training steps. To this end, we propose an “Episodic Memory-Double Actor–Critic (EMDAC)” framework, which can use episodic memory for action selection in continuous action tasks. The critics and episodic memory evaluate the value of state–action pairs selected by the two actors to determine the final action. Meanwhile, we design an episodic memory based on a Kalman filter optimizer, which updates using the episodic rewards of collected state–action pairs. The Kalman filter optimizer assigns different weights to experiences collected at different time periods during the memory update process. In our episodic memory, state–action pair clusters are used as indices, recording both the occurrence frequency of these clusters and the value estimates for the corresponding state–action pairs. This enables the estimation of the value of state–action pair clusters by querying the episodic memory. After that, we design intrinsic reward based on the novelty of state–action pairs with episodic memory, defined by the occurrence frequency of state–action pair clusters, to enhance the exploration capability of the agent. Ultimately, we propose an “EMDAC-TD3” algorithm by applying this three modules to Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithm within an Actor–Critic framework. Through evaluations in MuJoCo environments within the OpenAI Gym domain, EMDAC-TD3 achieves higher sample efficiency compared to baseline algorithms. EMDAC-TD3 demonstrates superior final performance compared to state-of-the-art episodic control algorithms and advanced Actor–Critic algorithms, by comparing the final rewards, Median, Interquartile Mean, Mean, and Optimality Gap. The final rewards can directly demonstrate the advantages of the algorithms. Based on the final rewards, EMDAC-TD3 achieves an average performance improvement of 11.01% over TD3, surpassing the current state-of-the-art algorithms in the same category.},
  archive      = {J_NN},
  author       = {Man Shu and Shuai Lü and Xiaoyu Gong and Daolong An and Songlin Li},
  doi          = {10.1016/j.neunet.2025.107286},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107286},
  shortjournal = {Neural Netw.},
  title        = {Episodic memory-double Actor–Critic twin delayed deep deterministic policy gradient},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximation by non-symmetric networks for cross-domain
learning. <em>NN</em>, <em>187</em>, 107282. (<a
href="https://doi.org/10.1016/j.neunet.2025.107282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the past 30 years or so, machine learning has stimulated a great deal of research in the study of approximation capabilities (expressive power) of a multitude of processes, such as approximation by shallow or deep neural networks, radial basis function networks, and a variety of kernel based methods. Motivated by applications such as invariant learning, transfer learning, and synthetic aperture radar imaging, we initiate in this paper a general approach to study the approximation capabilities of kernel based networks using non-symmetric kernels. While singular value decomposition is a natural instinct to study such kernels, we consider a more general approach to include the use of a family of kernels, such as generalized translation networks (which include neural networks and translation invariant kernels as special cases) and rotated zonal function kernels. Naturally, unlike traditional kernel based approximation, we cannot require the kernels to be positive definite. In particular, we obtain estimates on the accuracy of uniform approximation of functions in a Sobolev class by ReLU r networks when r is not necessarily an integer. Our general results apply to the approximation of functions with small smoothness compared to the dimension of the input space.},
  archive      = {J_NN},
  author       = {H.N. Mhaskar},
  doi          = {10.1016/j.neunet.2025.107282},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107282},
  shortjournal = {Neural Netw.},
  title        = {Approximation by non-symmetric networks for cross-domain learning},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). StoCFL: A stochastically clustered federated learning
framework for non-IID data with dynamic client participation.
<em>NN</em>, <em>187</em>, 107278. (<a
href="https://doi.org/10.1016/j.neunet.2025.107278">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning is a distributed learning framework that takes full advantage of private data samples kept on edge devices. In real-world federated learning systems, these data samples are often decentralized and Non-Independently Identically Distributed (Non-IID), causing divergence and performance degradation in the federated learning process. As a new solution, clustered federated learning groups federated clients with similar data distributions to impair the Non-IID effects and train a better model for every cluster. However, existing CFL algorithms are ineffective because they lack an information-sharing mechanism across clusters resulting in low data efficiency and model performance. Meanwhile, their performance is highly subjected to ideal client clustering results which are practically unavailable. This paper proposes StoCFL, a novel clustered federated learning framework for generic Non-IID issues. In detail, StoCFL implements a flexible CFL framework that supports an arbitrary proportion of client participation and newly joined clients for a varying FL system, while maintaining a great improvement in model performance. The intensive experiments are conducted by using four basic Non-IID settings and a real-world dataset. The results show that StoCFL could obtain promising cluster results even when the number of clusters is unknown. Based on the client clustering results, models trained with StoCFL outperform baseline approaches in a variety of scenarios.},
  archive      = {J_NN},
  author       = {Dun Zeng and Xiangjing Hu and Shiyu Liu and Yue Yu and Qifan Wang and Zenglin Xu},
  doi          = {10.1016/j.neunet.2025.107278},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107278},
  shortjournal = {Neural Netw.},
  title        = {StoCFL: A stochastically clustered federated learning framework for non-IID data with dynamic client participation},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural networks trained by weight permutation are universal
approximators. <em>NN</em>, <em>187</em>, 107277. (<a
href="https://doi.org/10.1016/j.neunet.2025.107277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The universal approximation property is fundamental to the success of neural networks, and has traditionally been achieved by training networks without any constraints on their parameters. However, recent experimental research proposed a novel permutation-based training method, which exhibited a desired classification performance without modifying the exact weight values. In this paper, we provide a theoretical guarantee of this permutation training method by proving its ability to guide a ReLU network to approximate one-dimensional continuous functions. Our numerical results further validate this method’s efficiency in regression tasks with various initializations. The notable observations during weight permutation suggest that permutation training can provide an innovative tool for describing network learning behavior.},
  archive      = {J_NN},
  author       = {Yongqiang Cai and Gaohang Chen and Zhonghua Qiao},
  doi          = {10.1016/j.neunet.2025.107277},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107277},
  shortjournal = {Neural Netw.},
  title        = {Neural networks trained by weight permutation are universal approximators},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedELR: When federated learning meets learning with noisy
labels. <em>NN</em>, <em>187</em>, 107275. (<a
href="https://doi.org/10.1016/j.neunet.2025.107275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing research on federated learning (FL) usually assumes that training labels are of high quality for each client, which is impractical in many real-world scenarios (e.g., noisy labels by crowd-sourced annotations), leading to dramatic performance degradation. In this work, we investigate noisy FL through the lens of early-time training phenomenon (ETP). Specifically, a key finding of this paper is that the early training phase varies among different local clients due to the different noisy classes in each client. In addition, we show that such an inconsistency also exists between the local and global models. As a result, local clients would always begin to memorize noisy labels before the global model reaches the optimal, which inevitably leads to the degradation of the quality of service in real-world FL applications (e.g. tumor image classification among different hospitals). Our findings provide new insights into the learning dynamics and shed light on the essence cause of this degradation in noisy FL. To address this problem, we reveal a new principle for noisy FL: it is necessary to align the early training phases across local models. To this end, we propose FedELR, a simple yet effective framework that aims to force local models to stick to their early training phase via an early learning regularization (ELR), so that the learning dynamics of local models can be kept at the same pace. Moreover, this also leverages the ETP in local clients, leading each client to take more training steps in learning a more robust local model for optimal global aggregation. Extensive experiments on various real-world datasets also validate the effectiveness of our proposed methods.},
  archive      = {J_NN},
  author       = {Ruizhi Pu and Lixing Yu and Shaojie Zhan and Gezheng Xu and Fan Zhou and Charles X. Ling and Boyu Wang},
  doi          = {10.1016/j.neunet.2025.107275},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107275},
  shortjournal = {Neural Netw.},
  title        = {FedELR: When federated learning meets learning with noisy labels},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image debanding using cross-scale invertible networks with
banded deformable convolutions. <em>NN</em>, <em>187</em>, 107270. (<a
href="https://doi.org/10.1016/j.neunet.2025.107270">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Banding artifacts in images stem from limitations in color bit depth, image compression, or over-editing, significantly degrades image quality, especially in regions with smooth gradients. Image debanding is about eliminating these artifacts while preserving the authenticity of image details. This paper introduces a novel approach to image debanding using a cross-scale invertible neural network (INN). The proposed INN is information-lossless and enhanced by a more effective cross-scale scheme. Additionally, we present a technique called banded deformable convolution, which fully leverages the anisotropic properties of banding artifacts. This technique is more compact, efficient, and exhibits better generalization compared to existing deformable convolution methods. Our proposed INN exhibits superior performance in both quantitative metrics and visual quality, as evidenced by the results of the experiments.},
  archive      = {J_NN},
  author       = {Yuhui Quan and Xuyi He and Ruotao Xu and Yong Xu and Hui Ji},
  doi          = {10.1016/j.neunet.2025.107270},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107270},
  shortjournal = {Neural Netw.},
  title        = {Image debanding using cross-scale invertible networks with banded deformable convolutions},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploiting instance-label dynamics through reciprocal
anchored contrastive learning for few-shot relation extraction.
<em>NN</em>, <em>187</em>, 107259. (<a
href="https://doi.org/10.1016/j.neunet.2025.107259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the domain of Few-shot Relation Extraction (FSRE), the primary objective is to distill relational facts from limited labeled datasets. This task has recently witnessed significant advancements through the integration of Pre-trained Language Models (PLMs) within a supervised contrastive learning schema, which effectively leverages the dynamics between instance and label information. Despite these advancements, the comprehensive utilization of extensive instance-label pairs, aimed at facilitating the extraction of semantically rich representations within this paradigm, has yet to be fully harnessed. To bridge this gap, we introduce a R eciprocal A nchored C ontrastive L earning framework (RACL) for few-shot relation extraction, which is predicated on the premise that instance-label pairs provide distinct yet inherently complementary insights into textual semantics. Specifically, RACL employs a symmetric contrastive objective that incorporates both instance-level and label-level contrastive losses, promoting a more integrated and unified representational space. This approach is engineered to effectively delineate the nuanced relationships between instance attributes and relational facts, while simultaneously optimizing information sharing across different perspectives within the same relations. Extensive experiments on the FSRE benchmark datasets demonstrate the superiority of our approach as compared to the state-of-the-art baselines. Further ablation studies on Zero-shot and None-of-the-above settings confirm its robustness and adaptability in practical applications.},
  archive      = {J_NN},
  author       = {Yanglei Gan and Qiao Liu and Run Lin and Tian Lan and Yuxiang Cai and Xueyi Liu and Changlin Li and Yan Liu},
  doi          = {10.1016/j.neunet.2025.107259},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107259},
  shortjournal = {Neural Netw.},
  title        = {Exploiting instance-label dynamics through reciprocal anchored contrastive learning for few-shot relation extraction},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="orl---15">ORL - 15</h2>
<ul>
<li><details>
<summary>
(2025). Erratum to “cooperative equilibria of strategy-form games
with both nontransferable and transferable utilities” [oper. Res. Lett.
54 (2024) 107109]. <em>ORL</em>, <em>59</em>, 107254. (<a
href="https://doi.org/10.1016/j.orl.2025.107254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We correct an error in the statement of Theorem 3.2. Moreover, we correct some typos.},
  archive      = {J_ORL},
  author       = {Zhe Yang and Xinyu Yang},
  doi          = {10.1016/j.orl.2025.107254},
  journal      = {Operations Research Letters},
  month        = {3},
  pages        = {107254},
  shortjournal = {Oper. Res. Lett.},
  title        = {Erratum to “Cooperative equilibria of strategy-form games with both nontransferable and transferable utilities” [Oper. res. lett. 54 (2024) 107109]},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An option pricing model with double-exponential jumps in
returns and GARCH diffusion in volatilities. <em>ORL</em>, <em>59</em>,
107253. (<a href="https://doi.org/10.1016/j.orl.2025.107253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new stochastic volatility model with double-exponential jumps in returns and GARCH-type volatility diffusion for option pricing. Previously unexplored due to the lack of analytical option pricing formulas, we obtain closed-form expansions for European option prices under various volatility specifications and jump types, making model calibration feasible. Empirical studies show that this model outperforms alternatives.},
  archive      = {J_ORL},
  author       = {Chunhui Qiao and Xiangwei Wan and Nian Yang},
  doi          = {10.1016/j.orl.2025.107253},
  journal      = {Operations Research Letters},
  month        = {3},
  pages        = {107253},
  shortjournal = {Oper. Res. Lett.},
  title        = {An option pricing model with double-exponential jumps in returns and GARCH diffusion in volatilities},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The inverse optimal value problem for linear fractional
programming. <em>ORL</em>, <em>59</em>, 107251. (<a
href="https://doi.org/10.1016/j.orl.2025.107251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the inverse optimal value problem for linear fractional programming, where the goal is to find the coefficients of the fractional objective function such that the resulting optimal objective function value is as close as possible to some given target value. We show that this problem is NP -hard. Then, we provide some structural results, which are exploited to derive several reformulations and two solution algorithms. The proposed approaches are based on the Charnes-Cooper and parametric transformations.},
  archive      = {J_ORL},
  author       = {Sina Nadi and Taewoo Lee and Oleg A. Prokopyev},
  doi          = {10.1016/j.orl.2025.107251},
  journal      = {Operations Research Letters},
  month        = {3},
  pages        = {107251},
  shortjournal = {Oper. Res. Lett.},
  title        = {The inverse optimal value problem for linear fractional programming},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximation algorithms for the k+-star packing problem.
<em>ORL</em>, <em>59</em>, 107249. (<a
href="https://doi.org/10.1016/j.orl.2025.107249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a target graph G and a set G of k + -stars, that is, stars with at least k satellites, a k + -star packing of G is a set of vertex-disjoint subgraphs of G with each isomorphic to some element of G . The k + -star packing problem is to find one such packing that covers as many vertices of G as possible. It is known to be NP-hard for any fixed k ≥ 2 , and has a simple 2-approximation algorithm when k = 2 . In this paper, we present an improved algorithm with a tight approximation ratio of 9/5 for k = 2 , and a k + 2 2 -approximation algorithm for general k ≥ 2 using the local search approach.},
  archive      = {J_ORL},
  author       = {Zhihua Huang and An Zhang and Mingqi Gao and Jiayi Sun and Yong Chen},
  doi          = {10.1016/j.orl.2025.107249},
  journal      = {Operations Research Letters},
  month        = {3},
  pages        = {107249},
  shortjournal = {Oper. Res. Lett.},
  title        = {Approximation algorithms for the k+-star packing problem},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the core of information sharing games. <em>ORL</em>,
<em>59</em>, 107247. (<a
href="https://doi.org/10.1016/j.orl.2025.107247">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information sharing games deal with allocating payoffs created by information sharing among agents in the cooperative-game approach. In this study, we preset several properties of the core of those games, such as a necessary and sufficient condition for the singleton core and simple computation of an agent&#39;s maximum payoff in the core.},
  archive      = {J_ORL},
  author       = {Yasuo Sasaki},
  doi          = {10.1016/j.orl.2025.107247},
  journal      = {Operations Research Letters},
  month        = {3},
  pages        = {107247},
  shortjournal = {Oper. Res. Lett.},
  title        = {On the core of information sharing games},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On linear threshold policies for continuous-time dynamic
yield management. <em>ORL</em>, <em>59</em>, 107245. (<a
href="https://doi.org/10.1016/j.orl.2025.107245">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the finite-horizon continuous-time dynamic yield management problem with stationary arrival rates and two customer types. We consider a class of linear threshold policies proposed by Hodge (2008) [5] , in which each less-profitable customer is accepted if and only if the remaining inventory exceeds a threshold that linearly decreases over the horizon. We use a Markov chain representation to show that such policies achieve uniformly bounded regret. We then generalize this result to analogous policies for arbitrarily many customer types.},
  archive      = {J_ORL},
  author       = {Dipayan Banerjee and Alan L. Erera and Alejandro Toriello},
  doi          = {10.1016/j.orl.2025.107245},
  journal      = {Operations Research Letters},
  month        = {3},
  pages        = {107245},
  shortjournal = {Oper. Res. Lett.},
  title        = {On linear threshold policies for continuous-time dynamic yield management},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Smoothed analysis of the k-swap neighborhood for makespan
scheduling. <em>ORL</em>, <em>59</em>, 107244. (<a
href="https://doi.org/10.1016/j.orl.2025.107244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the problem of scheduling a set of n jobs on m identical parallel machines with the objective of makespan minimization, by considering a local search neighborhood, called k -swap. In our previous study, we provided an exponential lower bound of 2 Ω ( n ) for k ≥ 3 . In this study, we show that the smoothed number of iterations in finding a local optimum with respect to the k -swap neighborhood is O ( m 2 ⋅ n 2 k + 2 ⋅ log ⁡ m ⋅ ϕ ) , where ϕ ≥ 1 is the perturbation parameter.},
  archive      = {J_ORL},
  author       = {Lars Rohwedder and Ashkan Safari and Tjark Vredeveld},
  doi          = {10.1016/j.orl.2025.107244},
  journal      = {Operations Research Letters},
  month        = {3},
  pages        = {107244},
  shortjournal = {Oper. Res. Lett.},
  title        = {Smoothed analysis of the k-swap neighborhood for makespan scheduling},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New facets of the clique partitioning polytope.
<em>ORL</em>, <em>59</em>, 107242. (<a
href="https://doi.org/10.1016/j.orl.2025.107242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The clique partitioning problem is a combinatorial optimisation problem which has many applications. At present, the most promising exact algorithms are those that are based on an understanding of the associated polytope. We present two new families of valid inequalities for that polytope, and show that the inequalities define facets under certain conditions.},
  archive      = {J_ORL},
  author       = {Adam N. Letchford and Michael M. Sørensen},
  doi          = {10.1016/j.orl.2025.107242},
  journal      = {Operations Research Letters},
  month        = {3},
  pages        = {107242},
  shortjournal = {Oper. Res. Lett.},
  title        = {New facets of the clique partitioning polytope},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the capacity inequalities for the heterogeneous vehicle
routing problem. <em>ORL</em>, <em>59</em>, 107239. (<a
href="https://doi.org/10.1016/j.orl.2024.107239">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fractional and Rounded capacity inequalities are two important families of valid inequalities known for the homogeneous Capacitated Vehicle Routing Problem (CVRP). Such inequalities impose the minimum number of vehicles required to service each and every subset of customers, be it a fractional or an integer value. In case of the Heterogeneous version of the routing problem (HCVRP), the minimum number of vehicles required for a subset of customers is not defined uniquely: it depends on the vehicle types and fleet composition that was engaged in serving the customers. This paper revises existing literature on the capacity-based valid inequalities for the HCVRP and presents new routines to separate them exactly using mixed integer linear programming (MILP). In addition, this paper proposes a new family of capacity-based valid inequalities for the HCVRP together with an exact routine to separate them. A computational study demonstrates applicability of considered inequalities in solving HCVRP instances using a standard MILP solver.},
  archive      = {J_ORL},
  author       = {Konstantin Pavlikov},
  doi          = {10.1016/j.orl.2024.107239},
  journal      = {Operations Research Letters},
  month        = {3},
  pages        = {107239},
  shortjournal = {Oper. Res. Lett.},
  title        = {On the capacity inequalities for the heterogeneous vehicle routing problem},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assortment optimization under the multinomial logit choice
model with product-specific capacities. <em>ORL</em>, <em>59</em>,
107238. (<a href="https://doi.org/10.1016/j.orl.2024.107238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider assortment optimization with product-specific capacities under the multinomial logit (MNL) choice model, wherein each product has a finite capacity, i.e., a limited number of units for sale. The number of customers served by each product is the smaller of its demand and capacity. We assume the demand of each product is deterministic as a function of the assortment offered. We show that this assortment optimization problem is NP-hard. We devise a 1/2-approximation algorithm and a fully polynomial-time approximation scheme (FPTAS) by exploiting its connection to a series of knapsack problems.},
  archive      = {J_ORL},
  author       = {Woonghee Tim Huh and Siyue Liu},
  doi          = {10.1016/j.orl.2024.107238},
  journal      = {Operations Research Letters},
  month        = {3},
  pages        = {107238},
  shortjournal = {Oper. Res. Lett.},
  title        = {Assortment optimization under the multinomial logit choice model with product-specific capacities},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal arrangement of servers for a tollbooth tandem queue
with two heterogeneous servers. <em>ORL</em>, <em>59</em>, 107222. (<a
href="https://doi.org/10.1016/j.orl.2024.107222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a tollbooth tandem queue with a Poisson arrival process and two heterogeneous servers of exponential service times. We show that performance measures, such as queue length, system size, waiting time and sojourn time, are stochastically larger when a server with a larger service rate is used as the first server. Our results include a rigorous proof of the observation made by He and Chao (2014) and Do (2015) regarding the performance comparison between two alternative server arrangements.},
  archive      = {J_ORL},
  author       = {Bara Kim and Jeongsim Kim},
  doi          = {10.1016/j.orl.2024.107222},
  journal      = {Operations Research Letters},
  month        = {3},
  pages        = {107222},
  shortjournal = {Oper. Res. Lett.},
  title        = {Optimal arrangement of servers for a tollbooth tandem queue with two heterogeneous servers},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An augmented lagrangian-type stochastic approximation method
for convex stochastic semidefinite programming defined by expectations.
<em>ORL</em>, <em>59</em>, 107221. (<a
href="https://doi.org/10.1016/j.orl.2024.107221">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An augmented Lagrangian-type stochastic approximation method (ALSAssdp) is proposed to solve the convex stochastic semidefinite optimization problem defined by expectations and regrets of this method are analyzed. Under mild conditions, we show that this method exhibits O ( T − 1 / 2 ) regret for both objective reduction and constraint violation. Moreover, we show that, with at least 1 − 1 / T probability, the method has no more than O ( log ⁡ ( T ) / T ) for both objective regret and constraint violation regret.},
  archive      = {J_ORL},
  author       = {Yule Zhang and Jia Wu and Liwei Zhang},
  doi          = {10.1016/j.orl.2024.107221},
  journal      = {Operations Research Letters},
  month        = {3},
  pages        = {107221},
  shortjournal = {Oper. Res. Lett.},
  title        = {An augmented lagrangian-type stochastic approximation method for convex stochastic semidefinite programming defined by expectations},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal control of queues with demand-driven discharge.
<em>ORL</em>, <em>59</em>, 107220. (<a
href="https://doi.org/10.1016/j.orl.2024.107220">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a Markovian queueing system with finite buffer space. Arriving customers belong to different classes and have class dependent service rates. At the time of an arrival, if the system is full, one of the existing customers has to be discharged prematurely, incurring a class dependent cost, whereas class dependent rewards are earned upon successful service completions. Our objective is to determine which customer class to discharge prematurely in order to maximize the long-run average profit.},
  archive      = {J_ORL},
  author       = {Guergana P. Ilieva and Hayriye Ayhan},
  doi          = {10.1016/j.orl.2024.107220},
  journal      = {Operations Research Letters},
  month        = {3},
  pages        = {107220},
  shortjournal = {Oper. Res. Lett.},
  title        = {Optimal control of queues with demand-driven discharge},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new sampling approach for bayesian sample size analysis in
applications of queueing models. <em>ORL</em>, <em>59</em>, 107219. (<a
href="https://doi.org/10.1016/j.orl.2024.107219">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In statistics, sample size determination (SSD) is of fundamental interest. In this paper, we focus on Bayesian sample size analysis, under the well-known ACC and WOC criteria, for queueing systems. Our study is based on a different method from the literature studies that is supported by the fact that observed data (sample or samples) from the population in applications can be significantly different from samples generated from the selected prior distribution.},
  archive      = {J_ORL},
  author       = {Dujuan Zhou},
  doi          = {10.1016/j.orl.2024.107219},
  journal      = {Operations Research Letters},
  month        = {3},
  pages        = {107219},
  shortjournal = {Oper. Res. Lett.},
  title        = {A new sampling approach for bayesian sample size analysis in applications of queueing models},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysis of the two-for-one swap heuristic for approximating
the maximum independent set in a k-polymatroid. <em>ORL</em>,
<em>59</em>, 107217. (<a
href="https://doi.org/10.1016/j.orl.2024.107217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let f : 2 N → Z + be a polymatroid (an integer-valued non-decreasing submodular set function with f ( ∅ ) = 0 ). A k -polymatroid satisfies that f ( e ) ≤ k for all e ∈ N . We call S ⊆ N independent if f ( S ) = ∑ e ∈ S f ( e ) and f ( e ) &gt; 0 for all e ∈ S . Such a set was also called a matching . Finding a maximum-size independent set in a 2-polymatroid has been studied and polynomial-time algorithms are known for linear polymatroids. For k ≥ 3 , the problem is NP-hard, and a ( ( 2 / k ) − ϵ ) -approximation is known and is obtained by swapping as long as possible a subset of up to ( 1 / ϵ ) log k − 1 ⁡ ( 2 k + 1 ) elements from the current solution by a set with one more element. Here we give a simple analysis of the more particular two-for-one repeated swapping heuristic, obtaining a tight (weaker) ( 2 / ( k + 1 ) ) -approximation.},
  archive      = {J_ORL},
  author       = {Adrian Calinescu and Gruia Călinescu},
  doi          = {10.1016/j.orl.2024.107217},
  journal      = {Operations Research Letters},
  month        = {3},
  pages        = {107217},
  shortjournal = {Oper. Res. Lett.},
  title        = {Analysis of the two-for-one swap heuristic for approximating the maximum independent set in a k-polymatroid},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="pr---83">PR - 83</h2>
<ul>
<li><details>
<summary>
(2025). A feature pair-based neural network embedded decision tree
for synergistic drug combination prediction. <em>PR</em>, <em>164</em>,
111608. (<a href="https://doi.org/10.1016/j.patcog.2025.111608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of combination therapy, it&#39;s a vital step to evaluate the synergistic effects of anti-tumor drug pairs. However, most existing machine learning methods only focus on the attributes of individual drugs, overlooking the implicit relationships of drug pairs, which are essential for understanding their synergistic effects. To address this issue, this paper constructs a novel Neural network Embedded Decision Tree model (NEDT) under a novel paradigm of synergistic drug combination prediction, synonymous feature pairing for drug pairs . It matches synonymous features of drug pairs to construct molecular-level correlations, capturing the implicit relationships of drugs. Our work distinguishes itself from previous neural decision trees by introducing a bi-objective optimization strategy into the fine-tuning process. Experimental results validate that NEDT performs well in predicting synergistic drug combinations. Systematically interpretability analyses demonstrate that NEDT can yield valuable insights into drug synergy, confirming its potential in the biomedical field.},
  archive      = {J_PR},
  author       = {Jiayu Zou and Lianlian Wu and Kunhong Liu and Yong Xu and Song He and Xiaochen Bo},
  doi          = {10.1016/j.patcog.2025.111608},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111608},
  shortjournal = {Pattern Recognition},
  title        = {A feature pair-based neural network embedded decision tree for synergistic drug combination prediction},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tensor-based incomplete multiple kernel clustering with
auto-weighted late fusion alignment. <em>PR</em>, <em>164</em>, 111601.
(<a href="https://doi.org/10.1016/j.patcog.2025.111601">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of big data, the rapid increase in data volume is accompanied by substantial missing data issues. Incomplete multiple kernel clustering (IMKC) investigates how to perform clustering when certain rows or columns of the predefined kernel matrix are missing. Among existing IMKC methods, the recent proposed late fusion IMKC (LF-IMKC) algorithm has garnered considerable attention due to its superior clustering accuracy and computational efficiency. However, existing LF-IMKC algorithms still suffer from several limitations. Firstly, we observe that in existing methods, the missing kernel imputation, kernel partition learning and subsequent late fusion processes are treated separately, which may lead to suboptimal solutions and adversely affect the clustering performance. Secondly, existing LF-IMKC algorithms treat each base partition equally, overlooking the differences in their contributions to the consistent clustering process. Thirdly, Existing algorithms typically overlook the higher-order correlations between the base partitions as well as the strong correlations between the base and consensus partitions, let alone leveraging these correlations for clustering. To address these issues, we propose a novel method, i.e., tensor-based incomplete multiple kernel clustering with auto-weighted late fusion alignment (TIKC-ALFA). Specifically, we first integrate the missing kernel imputation, base partition learning and subsequent late fusion processes within a unified framework. Secondly, we construct a third-order tensor using the weighted base partitions, offering an innovative perspective on tensor slices through the lens of weight distribution and then utilize the tensor nuclear norm (TNN) to approximate the true rank of the tensor. Furthermore, we incorporate the consensus partition into the tensor structure originally constructed solely from weighted base partitions to further investigate the strong correlations between the base partitions and the consensus partition. The experimental results on six commonly used datasets demonstrate the effectiveness of our algorithm.},
  archive      = {J_PR},
  author       = {Xiaoxing Guo and Gui-Fu Lu},
  doi          = {10.1016/j.patcog.2025.111601},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111601},
  shortjournal = {Pattern Recognition},
  title        = {Tensor-based incomplete multiple kernel clustering with auto-weighted late fusion alignment},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MPE: Multi-frame prediction error-based video anomaly
detection framework for robust anomaly inference. <em>PR</em>,
<em>164</em>, 111595. (<a
href="https://doi.org/10.1016/j.patcog.2025.111595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As video surveillance has become increasingly widespread, the necessity of video anomaly detection to support surveillance-related tasks has grown significantly. We propose a novel multi-frame prediction error-based framework (MPE) to enhance anomaly detection accuracy and efficiency. MPE mitigates false positives in prediction models by leveraging multi-frame prediction errors and reduces the time required for their generation through a frame prediction error storage method. The core idea of MPE is to reduce the prediction error of a normal frame while increasing the prediction error of an abnormal frame by leveraging the prediction errors of adjacent frames. We evaluated our method on the Ped2, Avenue, and ShanghaiTech datasets. The experimental results demonstrate that MPE improved the frame-level area under the curve (AUC) of prediction models while maintaining low computational overhead across all datasets. These results show that MPE makes prediction models robust and efficient for video anomaly detection in real-world scenarios.},
  archive      = {J_PR},
  author       = {Yujun Kim and Young-Gab Kim},
  doi          = {10.1016/j.patcog.2025.111595},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111595},
  shortjournal = {Pattern Recognition},
  title        = {MPE: Multi-frame prediction error-based video anomaly detection framework for robust anomaly inference},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HaarFuse: A dual-branch infrared and visible light image
fusion network based on haar wavelet transform. <em>PR</em>,
<em>164</em>, 111594. (<a
href="https://doi.org/10.1016/j.patcog.2025.111594">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared-visible image fusion remains challenging due to the inherent conflict between preserving multi-modal complementary features and minimizing reconstruction loss. Existing methods often suffer from inadequate feature representation and information degradation during fusion. To address this, we propose HaarFuse, a wavelet-enhanced auto-encoder network that hierarchically integrates multi-scale features for robust fusion. The network first employs wavelet transform to extend the receptive field of convolutional layers, extracting shared shallow features that encode both low-frequency structural contours and high-frequency texture primitives. Subsequently, the shallow features are decomposed into high-frequency and low-frequency components through Haar wavelet transform, and techniques such as INN, Gabor layer, and Transformer are adopted to further optimize and process these features. Finally, the fused image is reconstructed via the inverse wavelet transform. Experiments on TNO, MSRS, and M3FD benchmarks validate HaarFuse&#39;s superiority: it achieves the highest thermal saliency (SD=45.78, +5.5%↑ on MSRS; EN=6.98, +4.0%↑ on M3FD), optimal edge fidelity (Qabf=0.62, +1.6%↑ on M3FD), and 34.2 × faster inference than SwinFusion with 0.468 MB parameters. Further validation in machine vision and medical imaging confirms its robustness for real-time applications.},
  archive      = {J_PR},
  author       = {Yuequn Wang and Jie Liu and Jianli Wang and Leqiang Yang and Bo Dong and Zhengwei Li},
  doi          = {10.1016/j.patcog.2025.111594},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111594},
  shortjournal = {Pattern Recognition},
  title        = {HaarFuse: A dual-branch infrared and visible light image fusion network based on haar wavelet transform},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SyntaPulse: An unsupervised framework for sentiment
annotation and semantic topic extraction. <em>PR</em>, <em>164</em>,
111593. (<a href="https://doi.org/10.1016/j.patcog.2025.111593">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis is a critical area within natural language processing, with applications in various domains like marketing, social media analytics, and politics. However, current methods encounter challenges in handling contextual ambiguities, accurately detecting sarcasm and irony, and effectively processing domain-specific vocabulary without extensive labeled datasets. Addressing these issues is essential, as the nuanced nature of language can lead to diverse interpretations across contexts, complicating reliable sentiment analysis. Furthermore, sarcasm and irony remain difficult to identify precisely, while reliance on labeled data and limitations in handling domain-specific vocabulary restrict adaptability across different fields. This paper presents SyntaPulse, a novel framework for sentiment classification in social networks, developed to overcome these challenges. The framework combines an innovative dictionary-based approach with Probabilistic Syntactic Latent Semantic Analysis (PSLSA) for semantic topic extraction. This integration enables it to handle homographs effectively, thereby enhancing sarcasm detection, facilitating the interpretation of domain-specific vocabulary, and reducing dependency on labeled data. Evaluated on 12 datasets, our framework demonstrates adaptability across various domains and achieves high Macro-F1 scores, ranging from 72.89 % to 96.22 %. SyntaPulse has also obtained improvements on seven datasets, with the lowest improvement rate being 0.21 % and the highest reaching 2.97 %.},
  archive      = {J_PR},
  author       = {Hadis Bashiri and Hassan Naderi},
  doi          = {10.1016/j.patcog.2025.111593},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111593},
  shortjournal = {Pattern Recognition},
  title        = {SyntaPulse: An unsupervised framework for sentiment annotation and semantic topic extraction},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer-driven feature fusion network and visual feature
coding for multi-label image classification. <em>PR</em>, <em>164</em>,
111584. (<a href="https://doi.org/10.1016/j.patcog.2025.111584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label image classification (MLIC) has attracted extensive research attention in recent years. Nevertheless, most of the existing methods have difficulty in effectively fusing multi-scale features and focusing on critical visual information, which makes it difficult to recognize objects from images. Besides, recent studies have utilized graph convolutional networks and attention mechanisms to model label dependencies in order to improve the model performance. However, these methods often rely on manually predefined label structures, which limits flexibility and model generality. And they also fail to capture intrinsic object correlations within images and spatial contexts. To address these challenges, we propose a novel Feature Fusion network combined with Transformer (FFTran) to fuse different visual features. Firstly, to address the difficulties of current methods in recognizing small objects, we propose a Multi-level Scale Information Integration Mechanism (MSIIM) that fuses different feature maps from the backbone network. Secondly, we develop an Intra-Image Spatial-Channel Semantic Mining (ISCM) module for learning important spaces and channel information. Thirdly, we design a Visual Feature Coding based on Transformer (VFCT) module to enhance the contextual information by pooling different visual features. Compared to the baseline model, FFTran achieves a significant boost in mean Average Precision (mAP) on both the VOC2007 and COCO2014 datasets, with enhancements of 2.9% and 5.1% respectively, highlighting its superior performance in multi-label image classification tasks.},
  archive      = {J_PR},
  author       = {Pingzhu Liu and Wenbin Qian and Jintao Huang and Yanqiang Tu and Yiu-Ming Cheung},
  doi          = {10.1016/j.patcog.2025.111584},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111584},
  shortjournal = {Pattern Recognition},
  title        = {Transformer-driven feature fusion network and visual feature coding for multi-label image classification},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online signature verification based on the lagrange
formulation with 2D and 3D robotic models. <em>PR</em>, <em>164</em>,
111581. (<a href="https://doi.org/10.1016/j.patcog.2025.111581">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online Signature Verification commonly relies on function-based features, such as time-sampled horizontal and vertical coordinates, as well as the pressure exerted by the writer, obtained through a digitizer. Although inferring additional information about the writer’s arm pose, kinematics, and dynamics based on digitizer data can be useful, it constitutes a challenge. In this paper, we tackle this challenge by proposing a new set of features based on the dynamics of online signatures. These new features are inferred through a Lagrangian formulation, obtaining the sequences of generalized coordinates and torques for 2D and 3D robotic arm models. By combining kinematic and dynamic robotic features, our results demonstrate their significant effectiveness for online automatic signature verification and achieving state-of-the-art results when integrated into deep learning models.},
  archive      = {J_PR},
  author       = {Moises Diaz and Miguel A. Ferrer and Juan M. Gil and Rafael Rodriguez and Peirong Zhang and Lianwen Jin},
  doi          = {10.1016/j.patcog.2025.111581},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111581},
  shortjournal = {Pattern Recognition},
  title        = {Online signature verification based on the lagrange formulation with 2D and 3D robotic models},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LMFNet: Lightweight multimodal fusion network for
high-resolution remote sensing image segmentation. <em>PR</em>,
<em>164</em>, 111579. (<a
href="https://doi.org/10.1016/j.patcog.2025.111579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the rapid evolution of semantic segmentation for land cover classification in high-resolution remote sensing imagery, integrating multiple data modalities such as Digital Surface Model (DSM), RGB, and Near-infrared (NIR) remains a challenge. Current methods often process only two types of data, missing out on the rich information that additional modalities can provide. Addressing this gap, we propose a novel L ightweight M ultimodal data F usion Net work (LMFNet) to accomplish the tasks of fusion and semantic segmentation of multimodal remote sensing images. LMFNet uniquely accommodates various data types simultaneously, including RGB, NirRG, and DSM, through a weight-sharing, multi-branch vision transformer that minimizes parameter count while ensuring robust feature extraction. Our proposed multimodal fusion module integrates a Multimodal Feature Fusion Reconstruction Layer and Multimodal Feature Self-Attention Fusion Layer , which can reconstruct and fuse multimodal features. Our method achieves a mean Intersection over Union ( m I o U ) of 85.09% on the US3D dataset, marking a significant improvement over existing methods. We also studied the scalability of our method, directly extending the input modality to the SAR and hyperspectral fields. Our experimental results on the C2Seg dataset show that our method has generalization applicability to data of various modalities.},
  archive      = {J_PR},
  author       = {Tong Wang and Guanzhou Chen and Xiaodong Zhang and Chenxi Liu and Jiaqi Wang and Xiaoliang Tan and Wenlin Zhou and Chanjuan He},
  doi          = {10.1016/j.patcog.2025.111579},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111579},
  shortjournal = {Pattern Recognition},
  title        = {LMFNet: Lightweight multimodal fusion network for high-resolution remote sensing image segmentation},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SAPFormer: Shape-aware propagation transformer for point
clouds. <em>PR</em>, <em>164</em>, 111578. (<a
href="https://doi.org/10.1016/j.patcog.2025.111578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer-based networks have achieved impressive performance on three-dimensional point cloud data. However, most existing methods focus on aggregating local features in the neighborhoods of a point cloud, ignoring the global feature information. Therefore, it is difficult to capture the long-range dependencies of a point cloud. In this paper, we propose the Shape-Aware Propagation Transformer (SAPFormer) , which flexibly captures the semantic information of point clouds in geometric space and effectively extracts the contextual geometric space information. Specifically, we first design local group self-attention (LGA) to capture the local interaction information in each region. To capture the separated local region feature relationships, we propose local group propagation (LGP) to pass the information between different regions via query points. This allows features to propagate among neighbors for more fine-grained feature information. To further enlarge the receptive field, we propose the global shape feature module (GSFM) to learn global context information through key shape points (KSPs). Finally, to solve the positional information cues between global contexts, we introduce spatial-shape relative position encoding (SS-RPE), which obtains positional relationships between points. Extensive experiments demonstrate the effectiveness and superiority of our method on the S3DIS, SensatUrban, ScanNet V2, ShapeNetPart, and ModelNet40 datasets. The code is available at https://github.com/viivan/SAPFormer-main .},
  archive      = {J_PR},
  author       = {Gang Xiao and Sihan Ge and Yangsheng Zhong and Zhongcheng Xiao and Junfeng Song and Jiawei Lu},
  doi          = {10.1016/j.patcog.2025.111578},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111578},
  shortjournal = {Pattern Recognition},
  title        = {SAPFormer: Shape-aware propagation transformer for point clouds},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AFIFC: Adaptive fuzzy neighborhood mutual information-based
feature selection via label correlation. <em>PR</em>, <em>164</em>,
111577. (<a href="https://doi.org/10.1016/j.patcog.2025.111577">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing feature selection schemes do not comprehensively consider correlation between features and labels and between labels, and certain neighborhood radius affects the prediction accuracy of multilabel classification. To solve these deficiencies, this paper develops an adaptive fuzzy neighborhood mutual information-based feature selection scheme via label correlation. Firstly, to study different distribution structures of multilabel data, the standard Euclidean distance as classification interval is employed to construct adaptive fuzzy neighborhood radius. Adaptive fuzzy neighborhood similarity relation and fuzzy neighborhood granule will be presented via difference between samples for features. Uncertainty measures via fuzzy neighborhood entropy can be developed. Secondly, to select features strongly associated with labels, adaptive fuzzy neighborhood mutual information measures this correlation between candidate features and labels, and the correlation between features and labels relative to those selected features is computed by mutual information. Then discriminant function of correlation is provided. Thirdly, to improve efficacy of multilabel classification, adaptive fuzzy neighborhood granules are employed to study the membership degree of labels. To assess the correlation between labels, Jaccard similarity and adaptive fuzzy neighborhood mutual information are combined, and to reflect this internal correlation between label and label set, the correlation ratio is studied. Finally, maximum relevance between the candidate features and labels and minimum redundancy between features are calculated, and then a new multilabel feature selection scheme is provided to acquire this best feature subset. Experiments on 12 datasets show the efficacy of this designed scheme in several evaluation metrics.},
  archive      = {J_PR},
  author       = {Lin Sun and Feng Xu and Weiping Ding and Jiucheng Xu},
  doi          = {10.1016/j.patcog.2025.111577},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111577},
  shortjournal = {Pattern Recognition},
  title        = {AFIFC: Adaptive fuzzy neighborhood mutual information-based feature selection via label correlation},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-agent policy gradients with dynamic weighted value
decomposition. <em>PR</em>, <em>164</em>, 111576. (<a
href="https://doi.org/10.1016/j.patcog.2025.111576">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world multi-agent systems, multiple agents need to coordinate with other agents due to some limitations of observation and communication ability. Multi-agent policy gradient methods recently have witnessed vigorous progress in such challenging settings. However, multi-agent policy gradient methods have scalability and credit assignment issues due to the centralized critic. To solve these issues, a novel D ynamic Weighted QMI X Based M ulti-Agent Policy Gradients (DXM) is proposed in this paper, where the idea of dynamic weighted value decomposition is introduced into the framework of multi-agent actor-critic. Based on this idea, the proposed DXM approach has a more general decomposition on centralized critic than existing value decomposition methods, which address the scalability and credit assignment issue in both continuous and discrete action spaces. Briefly, in the presented DXM, deep deterministic policy gradient is employed to learn policies and a single centralized but factored critic, which can decompose the dynamic weighted nonlinear nonmonotonic summation of individual value functions. Empirical evaluations on the discrete action space environment StarCraft multi-agent challenge benchmark and the continuous action space environment continuous predator-prey benchmark show that the DXM approach successfully addresses the scalability and credit allocation issues. DXM significantly outperforms other baselines, with an average win rate improvement of &gt;15 %.},
  archive      = {J_PR},
  author       = {Shifei Ding and Xiaomin Dong and Jian Zhang and Lili Guo and Wei Du and Chenglong Zhang},
  doi          = {10.1016/j.patcog.2025.111576},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111576},
  shortjournal = {Pattern Recognition},
  title        = {Multi-agent policy gradients with dynamic weighted value decomposition},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TLR-3DRN: Unsupervised single-view reconstruction via
tri-layer renderer. <em>PR</em>, <em>164</em>, 111568. (<a
href="https://doi.org/10.1016/j.patcog.2025.111568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-view three-dimensional (3D) reconstruction is a challenging task in computer vision, focusing on reconstructing 3D objects from a single image. Existing single-view object reconstruction approaches typically rely on viewpoints, silhouettes, multiple views of the same instance, and strategy-specific priors, which are difficult to obtain in the wild. To address this issue, we propose a novel end-to-end single-view reconstruction method based on a tri-layer renderer, named the Tri-Layer Renderer-based 3D Reconstruction Network (TLR-3DRN). TLR-3DRN recovers 3D structures from original image collections without requiring additional supervision, assumptions, or priors. In particular, TLR-3DRN employs a tri-layer renderer that enables the model to extract more 3D details from unprocessed image data. To obtain an optimizable interlayer, we developed a robust interlayer generation network based on a nonparametric memory bank. Notably, we designed a joint optimization strategy for the overall framework. Additionally, a shape and texture consistency loss based on image–text models is proposed to enhance the optimization process. Owing to the aforementioned proposed modules, TLR-3DRN can achieve high-quality, diverse-category reconstruction under completely unsupervised conditions. TLR-3DRN is validated on synthetic datasets and real-world datasets. Experimental results demonstrate that TLR-3DRN outperforms state-of-the-art unsupervised and two-dimensional supervised methods, achieving performance comparable to 3D supervised methods.},
  archive      = {J_PR},
  author       = {HaoYu Guo and Ying Li and Chunyan Deng},
  doi          = {10.1016/j.patcog.2025.111568},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111568},
  shortjournal = {Pattern Recognition},
  title        = {TLR-3DRN: Unsupervised single-view reconstruction via tri-layer renderer},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical multi-granular multi-label contrastive
learning. <em>PR</em>, <em>164</em>, 111567. (<a
href="https://doi.org/10.1016/j.patcog.2025.111567">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label classification is a task wherein predictive models are developed to assign relevant label sets to unseen instances. Label correlation extraction and utilization have been widely implemented in multi-label classification methodologies. However, current multi-label contrastive learning algorithms inadequately incorporate label correlations into the feature space, thus limiting the learning of optimal feature representations for multi-label samples. To address this limitation, a novel hierarchical multi-granularity multi-label contrastive learning approach is proposed in this paper. The proposed method encompasses the construction of multi-label hierarchical correlations, label expansion based on hierarchical relationships, and representation learning through multi-granularity contrastive learning built upon these structures. Experimental results demonstrate the superiority of the proposed method over state-of-the-art techniques across widely used datasets.},
  archive      = {J_PR},
  author       = {Haixiang Li and Min Fang and Xiao Li and Bo Chen and Guizhi Wang},
  doi          = {10.1016/j.patcog.2025.111567},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111567},
  shortjournal = {Pattern Recognition},
  title        = {Hierarchical multi-granular multi-label contrastive learning},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robustifying vision transformer for image forgery
localization with multi-exit architectures. <em>PR</em>, <em>164</em>,
111565. (<a href="https://doi.org/10.1016/j.patcog.2025.111565">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of image manipulation tools has led to an increase in the number of manipulated images being disseminated online, posing risks like the propagation of fake news and telecom fraud. Thus, there is an increasing demand for precise, generic, and robust methods for detecting and locating manipulated images. In this paper, we propose a simple and clean model, named MEAFormer, for image forgery localization that does not heavily rely on pre-trained models. MEAFormer comprises three main components: an encoder network , a neck network , and a decoder network . Specifically, the transformer-based encoder network extracts hierarchical feature representations from the input image, providing rich contextual information in each layer. The neck network , incorporating our proposed cross-layer feature aggregation (CFA), aggregates these hierarchical features. To achieve better spatial feature co-occurrence, instead of using noise or edge artifacts, we introduce a multi-scale graph reasoning (MGR) module within the decoder network via bipartite graphs over the encoder and decoder features in a multi-scale fashion. The cross-level enhancement (CLE) further performs adjacent-level feature fusion to amplify the regions of interest in aggregated manipulation features. Finally, the multi-exit architecture (MEA) guides the model to learn fine-grained features and segment out the manipulated region. Extensive experiments across diverse and challenging datasets conclusively establish the superiority of MEAFormer over existing state-of-the-art methods, excelling in accuracy, generalization, and robustness.},
  archive      = {J_PR},
  author       = {Zenan Shi and Haipeng Chen and Dong Zhang},
  doi          = {10.1016/j.patcog.2025.111565},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111565},
  shortjournal = {Pattern Recognition},
  title        = {Robustifying vision transformer for image forgery localization with multi-exit architectures},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An information bottleneck approach for feature selection.
<em>PR</em>, <em>164</em>, 111564. (<a
href="https://doi.org/10.1016/j.patcog.2025.111564">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection has been studied extensively over the last few decades. As a widely used method, the information-theoretic feature selection methods have attracted considerable attention due to their better interpretation and desirable performance. From an information-theoretic perspective, a golden rule for feature selection is to maximize the mutual information I ( X s , Y ) between the selected feature subset X s and the class labels Y . Despite its simplicity, explicitly optimizing this objective is a non-trivial task. In this work, we propose a novel global neural network-based feature selection framework with the information bottleneck principle and establish its connection to the rule of maximizing I ( X s , Y ) . Using the matrix-based Rényi’s α -order entropy functional, our framework enjoys a simple and tractable objective without any variational approximation or distributional assumption. We further extend the framework to multi-view scenarios and verify it with two large-scale, high-dimensional real-world biomedical applications. Comprehensive experimental results demonstrate the superior performance of our framework not only in terms of classification accuracy but also in terms of good interpretability within and across each view, effectively proving that the proposed framework is trustworthy. Code is available at https://github.com/archy666/IBFS .},
  archive      = {J_PR},
  author       = {Qi Zhang and Mingfei Lu and Shujian Yu and Jingmin Xin and Badong Chen},
  doi          = {10.1016/j.patcog.2025.111564},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111564},
  shortjournal = {Pattern Recognition},
  title        = {An information bottleneck approach for feature selection},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient approach for finger vein verification to
solving the biometric recognition technique. <em>PR</em>, <em>164</em>,
111563. (<a href="https://doi.org/10.1016/j.patcog.2025.111563">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vein authentication is a novel biometric method to authenticate a person&#39;s individuality. The conventional biometric technique employs shape images and exact segments of finger veins for the verification process. The proposed deep belief structure model aims to improve verification accuracy using a novel Anisotropic Filtered Stromberg Feature Transform based on Tucker&#39;s Congruence Deep Belief Structure Learning (AFSFT-TCDBSL) technique. The main aim of the AFSFT-TCDBSL technique is to improve verification accuracy and minimize time consumption. The proposed AFSFT-TCDBSL technique comprises one input layer, three hidden layers, and one output layer. The numbers of images are collected in the input layer, and the input images are pre-processed using anisotropic diffusion filtering in the first hidden layer. Then the pre-processed input images are sent to the next layer, where the feature extraction process is carried out using the Stromberg wavelet transform. Finally, the verification process is performed using Tucker&#39;s congruence correlation coefficient. Based on the correlation, the verification results are obtained at the output layer. In this way, accurate finger vein verification is performed with superior accuracy and with a minimum false rate. We performed experimental assessments with different factors, such as the Peak Signal-to-Noise Ratio (PSNR), Finger Vein Verification Accuracy (FVVA), False Positive Rate (FPR), Processing Time (PT), and Feature Extraction Time (FET). The results of the proposed ADFSFT-TCDBSL technique were conducted on 9% of improved peak signal-to-noise ratio and accuracy with a minimum 59% false positive rate and 16% time as well as 19% feature extraction time than the state-of-the-art FVV methods; therefore, it better facilitates the application of real-time finger vein verification.},
  archive      = {J_PR},
  author       = {Dharmalingam Muthusamy and Rakkimuthu Ponnusamy},
  doi          = {10.1016/j.patcog.2025.111563},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111563},
  shortjournal = {Pattern Recognition},
  title        = {An efficient approach for finger vein verification to solving the biometric recognition technique},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HMSFT: Hierarchical multi-scale spatial-frequency-temporal
collaborative transformer for 3D human pose estimation. <em>PR</em>,
<em>164</em>, 111562. (<a
href="https://doi.org/10.1016/j.patcog.2025.111562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconstructing 3D poses from monocular video sequences faces formidable challenges due to noise-induced jitters and intricate joint dependencies. With this in mind, we propose the hierarchical multi-scale spatial-frequency-temporal collaborative transformer (HMSFT), which obtains robust multi-level joint relations by synergistically combining the complementary strengths of the spatial, frequency, and temporal domains. First, we utilize the spatial kinematics aware block to acquire geometric relationships across joints within the same frame. Subsequently, the adaptive frequency encoding block is presented to optimize the frequency representation of single poses and action sequences in response to distinctive feature attributes, thus alleviating the adverse impact of short-term and long-term jitters. Finally, through comprehensive temporal modeling across multiple scales, we explicitly capture the motion dependencies of the joint-level, part-level and body-level over time. Experimental validations on three benchmarks (Human 3.6M, HumanEva-I and MPI-INF-3DHP) show that the proposed HMSFT obtains significant improvements and excellent robust performance over several state-of-the-art techniques.},
  archive      = {J_PR},
  author       = {Hehao Zhang and Zhengping Hu and Shuai Bi and Jirui Di and Zhe Sun},
  doi          = {10.1016/j.patcog.2025.111562},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111562},
  shortjournal = {Pattern Recognition},
  title        = {HMSFT: Hierarchical multi-scale spatial-frequency-temporal collaborative transformer for 3D human pose estimation},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention-driven acoustic properties learning for underwater
target ranging. <em>PR</em>, <em>164</em>, 111560. (<a
href="https://doi.org/10.1016/j.patcog.2025.111560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater acoustic ranging (UAR) plays a crucial role in estimating object distances for ocean exploration. However, a reliable UAR method remains elusive, with current approaches either being reliant on inadequate hand-crafted features or neglecting the unique underwater acoustic properties. To address this, we propose Multi-attentional Underwater Acoustic Ranging (MUAR), a highly effective and robust UAR framework. MUAR incorporates multiple attention mechanisms tailored to the acoustic properties. Specifically, to better leverage the rich channel information in UAR data, we design a grouped channel attention module that can efficiently capture informative channels of the input data. Then, a feature-balancing strategy based on spatial-attention is introduced to mitigate information redundancy and conflicts, thereby enhancing the multi-level expressive capability of the model. We further theoretically analyze the connection between the self-attention mechanism and the acoustical signal correlations, such that achieving a better interpretation for the extracted features. Through extensive experiments and analysis on three authentic datasets, we show that MUAR outperforms previous approaches by obtaining state-of-the-art performance, i.e , achieving a MSE of 0.44 (vs. 2.72) and a MAPE of 0.97 (vs. 2.42). The source code of the proposed MUAR is released at https://github.com/TiernosChu/MUAR .},
  archive      = {J_PR},
  author       = {Xiaohui Chu and Hantao Zhou and Yan Zhang and Yachao Zhang and Runze Hu and Haoran Duan and Yawen Huang and Yefeng Zheng and Rongrong Ji},
  doi          = {10.1016/j.patcog.2025.111560},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111560},
  shortjournal = {Pattern Recognition},
  title        = {Attention-driven acoustic properties learning for underwater target ranging},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph augmentation guided federated knowledge distillation
for multisite functional MRI analysis. <em>PR</em>, <em>164</em>,
111559. (<a href="https://doi.org/10.1016/j.patcog.2025.111559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resting-state functional MRI (rs-fMRI) is a non-invasive tool increasingly used to detect abnormalities in brain connectivity for disorder analysis. Many learning models have been explored for fMRI analysis but usually require extensive data for reliable training. Multisite studies increase sample sizes by pooling data from multiple sites, but often face data security and privacy challenges. Federated learning (FL) facilitates collaborative model training without pooling fMRI data from different sites/clients. However, many FL methods share model parameters between clients, posing significant security risks during communication and greatly increasing communication costs. Besides, fMRI data for local model training is usually limited at each site, which may hinder local model training. To this end, we propose a graph augmentation guided federated distillation (GAFD) framework for multisite fMRI analysis and brain disorder identification. At each client, we augment each input functional connectivity network/graph derived from fMRI by perturbing node features and edges, followed by a feature encoder for graph representation learning. A contrastive loss is used to maximize the agreement of learned representations from the same subject, further enhancing discriminative power of fMRI representations. On the server side, the server receives model outputs ( i.e. , logit scores) corresponding to augmented graphs from each client and merges them. The merged logit score is then sent back to each client for knowledge distillation. This can promote knowledge sharing among clients, reduce the risk of privacy leakage, and greatly decrease communication costs. Experimental results on two multisite fMRI datasets indicate that our approach outperforms several state-of-the-arts.},
  archive      = {J_PR},
  author       = {Qianqian Wang and Junhao Zhang and Long Li and Lishan Qiao and Pew-Thian Yap and Mingxia Liu},
  doi          = {10.1016/j.patcog.2025.111559},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111559},
  shortjournal = {Pattern Recognition},
  title        = {Graph augmentation guided federated knowledge distillation for multisite functional MRI analysis},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spectral approximation of gaussian random graph laplacians
and applications to pattern recognition. <em>PR</em>, <em>164</em>,
111555. (<a href="https://doi.org/10.1016/j.patcog.2025.111555">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spectral decomposition of Gaussian Random Graph Laplacian (GRGLs) is at the core of the solutions to many graph-based problems. Most prevalent are graph signal processing, graph matching, and graph learning problems. Proposed here is the Eigen Approximation Theorem (EAT), which states that the diagonal entries of a GRGL matrix are reliable empirical approximations of its eigenvalues, given certain general conditions. This theorem provides a more precise bound for eigenvalues in a subspace derived from the Courant–Fischer min–max theorem. Consequently, the k th eigenvalue and eigenvector of a GRGL can be computed efficiently using deflated power iteration. Simulation results demonstrate the accuracy and computational speed of the EAT application. Hence, it can solve problems involving GRGLs like graph signal processing, graph matching, and graph learning. The EAT can also be used directly when approximations to spectral decomposition suffice. The real-time applications are also demonstrated.},
  archive      = {J_PR},
  author       = {Rajeev Airani and Sachin Kamble},
  doi          = {10.1016/j.patcog.2025.111555},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111555},
  shortjournal = {Pattern Recognition},
  title        = {Spectral approximation of gaussian random graph laplacians and applications to pattern recognition},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low-light image enhancement via clustering contrastive
learning for visual recognition. <em>PR</em>, <em>164</em>, 111554. (<a
href="https://doi.org/10.1016/j.patcog.2025.111554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual recognition tasks of low-light images remain a big challenge. We propose an unsupervised low-light image enhancement module that can be integrated into any baseline visual model to enhance the performance. The proposed method is based on Clustering Contrastive Learning and Grad-CAM (Gradient-Class Activation Map) feature alignment, called CCGC. The CCGC method enhances the luminance semantic information of low-light images and remains the semantic feature information focusing. Simulation experimental results on various low-light image datasets demonstrate the significant feature enhancement and generalization capability of CCGC. Evaluation of the established CUB-2011 low-light image dataset shows a substantial increase in classification accuracy across multiple benchmark models. Furthermore, the proposed method significantly improves the classification accuracy on a real low-light traditional Chinese medicine dataset and enhances face detection performance on dark face detection datasets.},
  archive      = {J_PR},
  author       = {Guanglei Sheng and Gang Hu and Xiaofeng Wang and Wei Chen and Jinlin Jiang},
  doi          = {10.1016/j.patcog.2025.111554},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111554},
  shortjournal = {Pattern Recognition},
  title        = {Low-light image enhancement via clustering contrastive learning for visual recognition},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contribution-based imbalanced hybrid resampling ensemble.
<em>PR</em>, <em>164</em>, 111553. (<a
href="https://doi.org/10.1016/j.patcog.2025.111553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resampling is an effective method for addressing data imbalance. Prevailing methods adjust the data distribution by either describing information or noise, and exhibit superiority in many scenarios. However, current studies face challenges in considering both information and noise simultaneously, as noisy samples usually have high information levels, potentially leading to misestimation. In this paper, a Contribution-Based Hybrid Resampling Ensemble (CHRE) is proposed to address the correlation problem between information and noise. CHRE is a semi-supervised algorithm based on a novel Global Unified Data Evaluation (GUDE) framework. Firstly, GUDE describes sample contribution by redefining the information and noise levels. Subsequently, based on sample contribution, CHRE removes negatively contributing majority samples, and oversamples minority samples Concurrently, pseudo-labels related to these minority samples are included in the oversampling. Throughout this process, CHRE resamples based on the sample contribution and optimizes the model. GUDE provides sample contribution based on the model feedback, with both interacting for iterative optimization. Extensive experiments are conducted on 53 benchmark datasets, involving three base classifiers and 13 state-of-the-art imbalance algorithms. The results demonstrate significant advantages of CHRE. Noise studies further indicate the high robustness of CHRE.},
  archive      = {J_PR},
  author       = {Lingyun Zhao and Fei Han and Qinghua Ling and Yubin Ge and Yuze Zhang and Qing Liu and Henry Han},
  doi          = {10.1016/j.patcog.2025.111553},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111553},
  shortjournal = {Pattern Recognition},
  title        = {Contribution-based imbalanced hybrid resampling ensemble},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meta-distribution-based ensemble sampler for imbalanced
semi-supervised learning. <em>PR</em>, <em>164</em>, 111552. (<a
href="https://doi.org/10.1016/j.patcog.2025.111552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning (SSL) on imbalanced data is largely under-explored and suffers from erroneous pseudo-labels, biased model training, or intolerable training costs. To alleviate these issues, we propose a meta-distribution-based ensemble sampler (MDSampler) approach 1 for imbalanced SSL. MDSampler is a unified framework that integrates SSL, imbalanced learning, and ensemble learning via iterative instance under-sampling and cascade classifier aggregation. Specifically, MDSampler considers the confidence-diversity distribution of both labeled and unlabeled samples and obtains the so-called meta-distribution via 2-D histogram discretization. Sampling on the meta-distribution (1) assigns pseudo-labels to unlabeled data for SSL, (2) alleviates class imbalance since the sampling process is unbiased, (3) improves the diversity of the ensemble learning framework, and (4) is highly efficient and flexible. Additionally, an adaptive instance interpolation strategy is presented to improve the quality of pseudo-labeled samples. Extensive experiments show that MDSampler can be organically combined with various classifiers to achieve superior performance in imbalanced SSL.},
  archive      = {J_PR},
  author       = {Zhihan Ning and Chaoxun Guo and David Zhang},
  doi          = {10.1016/j.patcog.2025.111552},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111552},
  shortjournal = {Pattern Recognition},
  title        = {Meta-distribution-based ensemble sampler for imbalanced semi-supervised learning},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anisotropic multiresolution analyses for deepfake detection.
<em>PR</em>, <em>164</em>, 111551. (<a
href="https://doi.org/10.1016/j.patcog.2025.111551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Networks (GANs) can be misused to fabricate elaborate lies. The threat posed by GANs has sparked the need to discern between genuine and fabricated content. We argue that since GANs primarily utilize isotropic convolutions to generate their output, they leave clear traces, their fingerprint, in the coefficient distribution on sub-bands extracted by anisotropic multiresolution transforms. We employ the fully separable wavelet transform and anisotropic multiwavelets to obtain anisotropic features to feed to lightweight convolutional neural network classifiers. The proposed approach is capable of considerably improving the state-of-the-art in detecting fully GAN-generated images. It is particularly resilient to common perturbations, such as compression, noise or blur. We find that anisotropic transforms, when combined with XceptionNet, also significantly enhance the state-of-the-art in detecting partially manipulated images.},
  archive      = {J_PR},
  author       = {Wei Huang and Michelangelo Valsecchi and Michael Multerer},
  doi          = {10.1016/j.patcog.2025.111551},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111551},
  shortjournal = {Pattern Recognition},
  title        = {Anisotropic multiresolution analyses for deepfake detection},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Concept-guided domain generalization for semantic
segmentation. <em>PR</em>, <em>164</em>, 111550. (<a
href="https://doi.org/10.1016/j.patcog.2025.111550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent domain generalization semantic segmentation methods are proposed to use vision foundation models (VFMs) for achieving superior performance in unseen domains. However, unlike human vision, which naturally adapts to recognize objects in different contexts, VFMs still suffer from the distribution shift problem. Based on this, a concept-guided domain generalization (CDG) approach is proposed for semantic segmentation. First, considering that humans can recognize objects in various environments after humans learn the conception of objects, a concept token learning module is proposed to learn the semantic concept token from semantic prototypes, which aims to exploit domain-invariant instance-aware knowledge. Second, when the recognition of objects is uncertain, humans recognize the objects by contextual information. Thus, a concept-contextual calibration strategy is proposed to generate concept-contextual relations by the semantic concepts to calibrate uncertain regions for refining final predictions. Extensive experiments demonstrate that the proposed approach achieves superior performance on multiple benchmarks. The code is released on GitHub: https://github.com/seabearlmx/CDG .},
  archive      = {J_PR},
  author       = {Muxin Liao and Wei Li and Chengle Yin and Yuling Jin and Yingqiong Peng},
  doi          = {10.1016/j.patcog.2025.111550},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111550},
  shortjournal = {Pattern Recognition},
  title        = {Concept-guided domain generalization for semantic segmentation},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive spatial and scale label assignment for anchor-free
object detection. <em>PR</em>, <em>164</em>, 111549. (<a
href="https://doi.org/10.1016/j.patcog.2025.111549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, anchor-free object detection has attracted widespread attention due to its simplicity and efficiency. The mainstream anchor-free object detectors allocate positive/negative candidate samples through prior guidance at a fixed spatial position and assign positive/negative samples according to predefined scale constraints. However, artificially designing assignment strategies according to prior data distribution may hinder further optimization of label assignment. To this end, this paper proposes Adaptive Spatial and Scale Label Assignment (ASS-LA) to improve the performance of anchor-free object detection. Positive/negative samples are distributed from different pyramid levels using spatial and scale constraints. Specifically, an adaptive Intersection-over-Union (IoU) space assignment is designed to select candidate positive sample points. The membership degree is introduced at each pyramid level to adaptively fuzzy the scale assignment range so that the detector selects the final positive sample from the candidate sample points. Furthermore, a reference box is introduced to design the predicted IoU branch of coupled regression. In the inference stage, the predicted IoU and classification scores are combined as the confidence of the regression bounding box to alleviate the inconsistency between classification and regression. Extensive experiments show that our method achieves comparable performance to other existing label assignment schemes. With the introduction of ASS-LA, the anchor-free object detector has significant performance improvements without introducing other overhead.},
  archive      = {J_PR},
  author       = {Min Dang and Gang Liu and Chao Chen and Di Wang and Xike Li and Quan Wang},
  doi          = {10.1016/j.patcog.2025.111549},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111549},
  shortjournal = {Pattern Recognition},
  title        = {Adaptive spatial and scale label assignment for anchor-free object detection},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Balanced seed selection for k-means clustering with
determinantal point process. <em>PR</em>, <em>164</em>, 111548. (<a
href="https://doi.org/10.1016/j.patcog.2025.111548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {K-means is one of the most popular and effective partitional clustering algorithms. However, in K-means, the initial seeds (centroids) play a critical role in determining the quality of the clusters. The existing methods address this problem either by factoring in the distance between the points on n-dimensional space so that the seeds are spaced apart or by choosing points from the dense regions to avoid the selection of outliers. We introduce a novel approach for seed selection that jointly models diversity as well as the quality of the seeds in a unified probabilistic framework based on a fixed-size determinantal point process. The quality indicator measures the reliability of the point to be considered as a potential seed, while the diversity measure factors in the spatial relation between the points on Euclidean space. The results show that the proposed algorithm outperforms the state-of-the-art models on several datasets.},
  archive      = {J_PR},
  author       = {Namita Bajpai and Jiaul H. Paik and Sudeshna Sarkar},
  doi          = {10.1016/j.patcog.2025.111548},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111548},
  shortjournal = {Pattern Recognition},
  title        = {Balanced seed selection for K-means clustering with determinantal point process},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DC-CLIP: Multilingual CLIP compression via vision-language
distillation and vision-language alignment. <em>PR</em>, <em>164</em>,
111547. (<a href="https://doi.org/10.1016/j.patcog.2025.111547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pre-trained vision-language (V-L) models such as CLIP have shown excellent performance in many downstream cross-modal tasks. However, most of them are only applicable to the English context. Subsequent research has focused on this problem and proposed improved models, such as CN-CLIP and AltCLIP, to facilitate their applicability to Chinese and even other languages. Nevertheless, these models suffer from high latency and a large memory footprint in inference, which limits their further deployment on resource-constrained edge devices. In this work, we propose a conceptually simple yet effective multilingual CLIP Compression framework and train a lightweight multilingual vision-language model, called DC-CLIP, for both Chinese and English contexts. In this framework, we collect a high-quality Chinese–English multi-source dataset and design two training stages, including multilingual vision-language feature distillation and alignment. During the first stage, lightweight image/text student models are designed to learn robust visual/multilingual textual feature representation ability from corresponding teacher models, respectively. Subsequently, the multilingual vision-language alignment stage enables effective alignment of visual and multilingual textual features to further improve the model’s multilingual performance. Comprehensive experiments in zero-shot image classification, conducted based on the ELEVATER benchmark, showcase that DC-CLIP achieves superior performance in the English context and competitive performance in the Chinese context, even with less training data, when compared to existing models of similar parameter magnitude. The evaluation demonstrates the effectiveness of our designed training mechanism.},
  archive      = {J_PR},
  author       = {Wenbo Zhang and Yifan Zhang and Jianfeng Lin and Binqiang Huang and Jinlu Zhang and Wenhao Yu},
  doi          = {10.1016/j.patcog.2025.111547},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111547},
  shortjournal = {Pattern Recognition},
  title        = {DC-CLIP: Multilingual CLIP compression via vision-language distillation and vision-language alignment},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural normalized cut: A differential and generalizable
approach for spectral clustering. <em>PR</em>, <em>164</em>, 111545. (<a
href="https://doi.org/10.1016/j.patcog.2025.111545">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectral clustering, as a popular tool for data clustering, requires an eigen-decomposition step on a given affinity to obtain the spectral embedding. Nevertheless, such a step suffers from the lack of generalizability and scalability. Moreover, the obtained spectral embeddings can hardly provide a good approximation to the ground-truth partition and thus a k -means step is adopted to quantize the embedding. In this paper, we propose a simple yet effective scalable and generalizable approach, called Neural Normalized Cut (NeuNcut), to learn the clustering membership for spectral clustering directly. In NeuNcut, we properly reparameterize the unknown cluster membership via a neural network, and train the neural network via stochastic gradient descent with a properly relaxed normalized cut loss. As a result, our NeuNcut enjoys a desired generalization ability to directly infer clustering membership for out-of-sample unseen data and hence brings us an efficient way to handle clustering task with ultra large-scale data. We conduct extensive experiments on both synthetic data and benchmark datasets and experimental results validate the effectiveness and the superiority of our approach.},
  archive      = {J_PR},
  author       = {Wei He and Shangzhi Zhang and Chun-Guang Li and Xianbiao Qi and Rong Xiao and Jun Guo},
  doi          = {10.1016/j.patcog.2025.111545},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111545},
  shortjournal = {Pattern Recognition},
  title        = {Neural normalized cut: A differential and generalizable approach for spectral clustering},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient sampling-based gaussian processes for few-shot
semantic segmentation. <em>PR</em>, <em>164</em>, 111542. (<a
href="https://doi.org/10.1016/j.patcog.2025.111542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot segmentation (FSS) is a longstanding challenge in computer vision. Previous methods adopting Gaussian Processes (GPs) aggregate detailed information and manage complex distributions from small support sets, thereby modeling uncertainty of features and handling wide variations in context. However, the exact GP-based FSS methods struggle with computational burden and information redundancy. To tackle the issues, we propose ESGP, an Efficient Sampling-based Gaussian Process framework for few-shot segmentation. The model decouples the GP into a two-step process: weight space approximation for the prior and function space update for the posterior. Additionally, we adopt Deep Kernel Learning to enhance ESGP’s performance. This combination results in a faster, more accurate FSS model that effectively concentrates support sample information. Moreover, GP’s inherent ability to model uncertainty provides robust predictions and valuable insights into segmentation reliability. Experimental results demonstrate that ESGP outperforms previous GP-based methods and achieves competitive performance with state-of-the-art techniques.},
  archive      = {J_PR},
  author       = {Xin-Yi Zhang and Xian-Kai Lu and Yi-Long Yin and Han-Jia Ye and De-Chuan Zhan},
  doi          = {10.1016/j.patcog.2025.111542},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111542},
  shortjournal = {Pattern Recognition},
  title        = {Efficient sampling-based gaussian processes for few-shot semantic segmentation},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bijective inference network for interpretable
identification of RNA n6-methyladenosine modification sites.
<em>PR</em>, <em>164</em>, 111541. (<a
href="https://doi.org/10.1016/j.patcog.2025.111541">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accurate identification of N 6 -methyladenosine (m 6 A) modification sites is crucial for unraveling various functional mechanisms. While existing methods primarily focus on learning high-quality embeddings of RNA sequences for this task, few of them consider incorporating specific RNA secondary structures, limiting their interpretability for in-depth post-transcriptional analysis. In this work, we introduce a novel bijective inference network, named m 6 A-BIN, which integrates RNA sequences and secondary structures within a unified parameter-shared framework, enhancing the accuracy of m 6 A modification site identification through the auxiliary supervision of RNA secondary structures. To begin with, m 6 A-BIN constructs sequential and structural graphs from RNA sequences and secondary structures, respectively. Bijective mapping functions are then specifically designed to couple the procedures of graph representation learning and interpretable dependency inference, providing informative supervision for learning sequential and structural embeddings of RNA. By fusing these two types of RNA embeddings, m 6 A-BIN efficiently performs the identification task. The attribution phase of m 6 A-BIN further ascribes the prediction results to nucleotide dependencies acquired during the interpretable dependency inference, including RNA sequence and structural patterns, thereby enhancing its interpretability. Extensive experimental results demonstrate the promising performance of m 6 A-BIN, showcasing its efficacy in terms of both accuracy and interpretability for the identification of novel m 6 A modification sites.},
  archive      = {J_PR},
  author       = {Guodong Li and Yue Yang and Dongxu Li and Xiaorui Su and Zhi Zeng and Pengwei Hu and Lun Hu},
  doi          = {10.1016/j.patcog.2025.111541},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111541},
  shortjournal = {Pattern Recognition},
  title        = {A bijective inference network for interpretable identification of RNA n6-methyladenosine modification sites},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic feature regularized loss for weakly supervised
semantic segmentation. <em>PR</em>, <em>164</em>, 111540. (<a
href="https://doi.org/10.1016/j.patcog.2025.111540">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We focus on confronting weakly supervised semantic segmentation with scribble-level annotation. The regularized loss has proven to be an effective solution for this task. However, most existing regularized losses only leverage static shallow features (color, spatial information) to compute the regularized kernel, which limits its final performance since such static shallow features fail to describe pair-wise pixel relationships in complicated cases. In this paper, we propose a new regularized loss that utilizes both shallow and deep features that are dynamically updated to aggregate sufficient information to represent the relationship of different pixels. Moreover, to provide accurate deep features, we design a feature consistency head to train the pair-wise feature relationship. In contrast to most approaches that adopt a multi-stage training strategy with complicated training settings and high time-consuming steps, our approach can be directly trained in an end-to-end manner, in which the feature consistency head and our regularized loss can benefit from each other. We evaluate our approach on different backbones, and extensive experiments show that our approach achieves new state-of-the-art performances on different cases, e.g. , using our approach with a vision transformer outperforms other approaches by a substantial margin (more than 5% mIoU increase). The source code will be released at: https://github.com/zbf1991/DFR .},
  archive      = {J_PR},
  author       = {Bingfeng Zhang and Jimin Xiao and Yao Zhao},
  doi          = {10.1016/j.patcog.2025.111540},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111540},
  shortjournal = {Pattern Recognition},
  title        = {Dynamic feature regularized loss for weakly supervised semantic segmentation},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interpretable 2.5D network by hierarchical attention and
consistency learning for 3D MRI classification. <em>PR</em>,
<em>164</em>, 111539. (<a
href="https://doi.org/10.1016/j.patcog.2025.111539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning methods have been widely applied in diagnostic research on MRI data. Among the existing methods, attention-based multiple-instance learning, which not only provides classification results but also explains significant regions related to the task, has attracted considerable attention from scholars. However, prior methods might be restricted by these issues: (i) the loss of spatial or volume information, (ii) semantic inconsistency of attention weights, (iii) missing information exchange between attention mechanisms within different branches. To overcome these issues, we propose an innovative dual-branch attention-based deep multiple-instance learning framework, namely HA-CSL, which consists of a 2D branch and a 3D branch, a hierarchical attention (HA) module and a consistency learning (CSL) module. Specifically, the 2D and 3D branches employ the 2D and 3D convolutional neural networks to extract 2D and 3D patch-level features, respectively, so as to learn more richer image information. Additionally, the HA module comprises slice-, region- and channel-level attentions to interpret the significance of slices, regions and channels, respectively. Moreover, the CSL module is to enhance the consistency of attention weights obtained by the two branches, so as to reduce the semantic gap of attentions and promote better information exchange of two branches. Experiments on two 3D MRI image datasets demonstrate the superior classification and interpretation performance of the proposed framework over recent state-of-the-art methods. The source codes are available at https://github.com/shuting-pang/HA_CSL .},
  archive      = {J_PR},
  author       = {Shuting Pang and Yidi Chen and Xiaoshuang Shi and Rui Wang and Mingzhe Dai and Xiaofeng Zhu and Bin Song and Kang Li},
  doi          = {10.1016/j.patcog.2025.111539},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111539},
  shortjournal = {Pattern Recognition},
  title        = {Interpretable 2.5D network by hierarchical attention and consistency learning for 3D MRI classification},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-randomized focuses effectively boost metric-based
few-shot classifiers. <em>PR</em>, <em>164</em>, 111538. (<a
href="https://doi.org/10.1016/j.patcog.2025.111538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Towards solving a few-shot image classification task, deep metric learning is the de-facto approach. Usually the idea here is to train a deep metric model on base data, and evaluate it using novel data without any fine-tuning. Enhancing model performance is mostly focused upon improving feature or class representations, or designing or learning new metrics, often ignoring deep exploration of data-augmentation techniques to enhance few-shot learning. Interestingly, we discover that augmentation strategies, such as Cutout, Mixup and CutMix, would in fact greatly enhance performance of few-shot models. We conjecture, this is because such augmentation techniques encourage the model to extend its focus on multiple discriminative regions of an object instead of restricting to just the single-most discriminative point. Following this important discovery, we propose two simple yet effective novel data augmentation methods, viz. CutRot and CutCov, specifically designed to self-randomize focuses within an image itself for metric-based few-shot image classification. While CutRot involves random rotation of any patch within the image, CutCov focuses on random swapping of patches, again within the image. Extensive experiments verify that CutRot or CutCov can significantly boost performances of both classic and recent popular metric-based methods and performs much better than other augmentation methods of Cutout, Mixup, and CutMix on four few-shot image classification datasets. Code is available at https://github.com/liz-lut/CutRot-and-CutCov-main .},
  archive      = {J_PR},
  author       = {Zhen Li and Zhongyuan Liu and Dongliang Chang and Aneeshan Sain and Xiaoxu Li and Zhanyu Ma and Jing-Hao Xue and Yi-Zhe Song},
  doi          = {10.1016/j.patcog.2025.111538},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111538},
  shortjournal = {Pattern Recognition},
  title        = {Self-randomized focuses effectively boost metric-based few-shot classifiers},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bridging domain spaces for unsupervised domain adaptation.
<em>PR</em>, <em>164</em>, 111537. (<a
href="https://doi.org/10.1016/j.patcog.2025.111537">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised Domain Adaptation (UDA) aims to transfer knowledge obtained from a labeled source domain to an unlabeled target domain, facing challenges due to domain shift—significant discrepancies in data distribution that impair model performance when applied to unseen domains. While recent approaches have achieved remarkable progress in mitigating these domain shifts, the focus remains on direct adaptation strategies from source to target domains. However, when the gap between the source and target domains is too substantial, directly aligning their distributions becomes increasingly difficult. Pseudo-labeling, a common strategy in direct adaptation, can further exacerbate this issue when the domain shift is severe. In such cases, incorrect pseudo-labels are likely to propagate through the adaptation process, leading to degraded performance and unstable training. Effective adaptation thus requires methods that can address these challenges by improving the reliability of pseudo-labels or reducing dependency on them. To address this challenge, we propose a novel approach that effectively alleviates domain shift by leveraging intermediate domains as bridges between the source and target domains. Specifically, we introduce a fixed ratio-based mixup to generate distinct intermediate domains between the source and target domains. By training on these augmented domains, we construct source-dominant and target-dominant models that possess distinct strengths and weaknesses, enabling us to implement effective complementary learning strategies. Furthermore, we enhance our fixed ratio-based mixup with uncertainty-aware learning, which addresses not only the image-level space but also the feature space, aiming to reduce the uncertainty at the most critical points within these spaces. Finally, we integrate confidence-based learning strategies, including bidirectional matching with high-confidence predictions and self-penalization with low-confidence predictions. Our extensive experiments on seven public benchmarks, including both single-source and multi-source scenarios, demonstrate the effectiveness of our method in UDA tasks.},
  archive      = {J_PR},
  author       = {Jaemin Na and Heechul Jung and Hyung Jin Chang and Wonjun Hwang},
  doi          = {10.1016/j.patcog.2025.111537},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111537},
  shortjournal = {Pattern Recognition},
  title        = {Bridging domain spaces for unsupervised domain adaptation},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ADGaze: Anisotropic gaussian label distribution learning for
fine-grained gaze estimation. <em>PR</em>, <em>164</em>, 111536. (<a
href="https://doi.org/10.1016/j.patcog.2025.111536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaze estimation technology is crucial for enhancing the effectiveness and safety of applications in human–computer interaction, intelligent driving, virtual reality, and medical diagnosis. With advancements in deep learning, gaze estimation methods using deep neural networks have been extensively researched and applied. However, existing methods have yet to address the anisotropic characteristics of eye features. Based on the discovered anisotropic characteristics, we propose an Anisotropic Gaussian Label Distribution Learning Network for Gaze Estimation (ADGaze). ADGaze is capable of catching neighboring information by taking advantage of coarse-to-fine methodology and the anisotropic soft label construct. The coarse-to-fine framework initially performs classification tasks for gaze estimation, grouping gaze images with small variations into the same category, followed by regression tasks for each category. The construction of anisotropic Gaussian label distributions adopts methods based on data statistics and feature similarity. Extensive experimentation on public datasets has been carried out to substantiate the efficacy of this model. Our code is publicly available at https://github.com/dacilab/ADGaze .},
  archive      = {J_PR},
  author       = {Duantengchuan Li and Shutong Wang and Wanli Zhao and Lingyun Kang and Liangshan Dong and Jiazhang Wang and Xiaoguang Wang},
  doi          = {10.1016/j.patcog.2025.111536},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111536},
  shortjournal = {Pattern Recognition},
  title        = {ADGaze: Anisotropic gaussian label distribution learning for fine-grained gaze estimation},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HIAN: A hybrid interactive attention network for multimodal
sarcasm detection. <em>PR</em>, <em>164</em>, 111535. (<a
href="https://doi.org/10.1016/j.patcog.2025.111535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sarcasm detection aims to use various modalities of data, such as text, images, etc., to identify whether they contain sarcastic meanings. Both images and texts contain rich sarcastic clues, but there are differences in dimension between them, and the quality of the sarcastic information they contain is very different. Therefore, seeking an appropriate feature fusion strategy to align modal features to maximize the utilization of inconsistent relationships between modalities is a significant challenge in this task. To this end, we introduce a novel sarcasm detection fusion model based on multimodal hybrid interactive attention (HIAN). We concatenate class words obtained from images with text and use the proposed bidirectional long short-term memory network with an interactive attention layer to enhance the extraction of text features. The text features obtained in this way can fully capture the contextual information of the text and the supplementary information in the image. To further enhance the feature fusion between modalities, we propose a multimodal interactive attention network and a fusion-enhanced transformer to promote the sharing of high-order complementary information, which represents the complementary non-linear semantic relationship between the three modalities and captures more inconsistencies between modalities. Extensive experiments conducted on publicly available multimodal sarcasm detection benchmark datasets show that our results surpass those of the baseline model and current state-of-the-art methods for the case of using the base BERT model.},
  archive      = {J_PR},
  author       = {Yongtang Bao and Xin Zhao and Peng Zhang and Yue Qi and Haojie Li},
  doi          = {10.1016/j.patcog.2025.111535},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111535},
  shortjournal = {Pattern Recognition},
  title        = {HIAN: A hybrid interactive attention network for multimodal sarcasm detection},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Behavior capture guided engagement recognition. <em>PR</em>,
<em>164</em>, 111534. (<a
href="https://doi.org/10.1016/j.patcog.2025.111534">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Engagement recognition aims to assess an individual’s involvement in various activities, which is essential in fields like education, healthcare, and driving. However, existing methods often suffer from performance degradation due to excessive data and distractions. In this paper, we introduce a novel model, the Behavior Capture-guided Transformer (BCTR). One of its key innovations lies in the proposed architecture for extracting regional features. Specifically, BCTR employs three independent class tokens to capture regional features – ocular, head, and trunk – from image sequences. These features are then used to model the dynamic streams of these regions for video-based engagement recognition. Another unique innovation of BCTR is its ability to mimic the observational techniques used by human teachers. By leveraging both frame-level and video-level class tokens, the model uses dual branches to detect both static and dynamic disengagement behaviors. This approach not only enables BCTR to achieve superior performance – 64.51% accuracy on the DAiSEE dataset and 0.0602 MSE loss on the EmotiW-EP dataset – but also enhances the interpretability of engagement levels by identifying these disengagements.},
  archive      = {J_PR},
  author       = {Yijun Bei and Songyuan Guo and Kewei Gao and Zunlei Feng},
  doi          = {10.1016/j.patcog.2025.111534},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111534},
  shortjournal = {Pattern Recognition},
  title        = {Behavior capture guided engagement recognition},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). REHair: Efficient hairstyle transfer robust to face
misalignment. <em>PR</em>, <em>164</em>, 111533. (<a
href="https://doi.org/10.1016/j.patcog.2025.111533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hairstyle transfer is challenging due to intricate nature of hairstyles. In particular, face misalignment leads to distortion or deformation of the transferred hairstyle. To address this issue, we propose a Robust and Efficient Hairstyle transfer (REHair) framework, which comprises three stages: adaptive angle alignment, adaptive depth alignment, and efficient hairstyle editing. Firstly, we perform head pose estimation and adjust the facial rotation angle based on the latent code, thus ensuring consistent facial orientation between the face image and the hairstyle reference image and preventing hair shape and texture loss from iterative optimization methods. Secondly, we employ monocular depth estimation to predict the face depth of both images and perform adaptive depth alignment, ensuring the preservation of more hairstyle details. Finally, we propose a fast image embedding algorithm and integrate it with the latent code, significantly reducing the image embedding time in StyleGAN2. This adaptation enables REHair to be suitable for real-time applications. Quantitative and qualitative evaluations on the FFHQ and CelebA-HQ dataset demonstrate that REHair achieves state-of-the-art performance by successfully transferring hairstyles between images with different poses. The proposed method significantly reduces image embedding time while preserving image quality, and effectively addresses challenges associated with sub-optimal photography conditions and slow generation speed. Source code avaliable at https://github.com/fdwxfy/REHair .},
  archive      = {J_PR},
  author       = {Yiwen Xu and Liping Ling and Qingxu Lin and Ying Fang and Tiesong Zhao},
  doi          = {10.1016/j.patcog.2025.111533},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111533},
  shortjournal = {Pattern Recognition},
  title        = {REHair: Efficient hairstyle transfer robust to face misalignment},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EACE: Explain anomaly via counterfactual explanations.
<em>PR</em>, <em>164</em>, 111532. (<a
href="https://doi.org/10.1016/j.patcog.2025.111532">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection aims to identify data points that deviate from the prevailing data distribution. Despite numerous anomaly detection models, there is a prevailing oversight in their interpretability, specifically regarding the rationale behind classifying a specific data point as an anomaly. Therefore, Interpretable Machine Learning has become a current research hotspot and is crucial for users to trust models. As one of the representative models, Counterfactual Explanation (CFE) methods generate alternative scenarios different from the observed data to explain model decisions. CFE tries to answer how the model’s output would change if certain factors (features) were altered. However, most existing CFE methods are designed for classification tasks, and it is a challenge for them to transform anomalies into counterfactual explanation samples effectively. To overcome this limitation, we propose a novel method for Explaining Anomaly via Counterfactual Explanation named EACE. Specifically, based on existing CFE methods’ limitations in handling anomalies, we propose a novel optimization objective by incorporating density loss and boundary loss. Meanwhile, we improved the genetic algorithm to solve this optimization problem since the new loss function is not differentiable. To evaluate the quality of the generated counterfactual explanations, we compare comprehensively with state-of-the-art counterfactual explanation methods and feature importance-based explanation methods. Experimental results demonstrate that EACE has a notable ability to convert anomalies into counterfactual explanation samples that are highly aligned with the normal cluster.},
  archive      = {J_PR},
  author       = {Peng Zhou and Qihui Tong and Shiji Chen and Yunyun Zhang and Xindong Wu},
  doi          = {10.1016/j.patcog.2025.111532},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111532},
  shortjournal = {Pattern Recognition},
  title        = {EACE: Explain anomaly via counterfactual explanations},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meta-learning of pseudo force field generation and
estimation for enhancing 3D molecular property prediction. <em>PR</em>,
<em>164</em>, 111531. (<a
href="https://doi.org/10.1016/j.patcog.2025.111531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning Energy-based Model via 3D molecular denoising has been shown to be effective in pretraining the 3D molecular representation. However, existing works carry out denoising in task-agnostic manner, causing inevitable domain gap with the downstream tasks. To overcome this issue, we introduce a task-aware pretraining framework, dubbed Mol-MFFGE, for adapting the energy-based pretraining to downstream tasks in meta-learning approach. In this framework, we design learnable pretraining tasks as generating and estimating pseudo force fields. This is achieved by proposing a learnable noise transformation module to generate the noisy motions of atoms and the model is pretrained to estimate them. These tasks are taken as the auxiliary self-supervised training tasks and learned with the downstream task jointly, formulated as a bi-level meta-learning optimization problem. Based on such an approach, the force field generation and estimation tasks are meta-learned to enhance the downstream tasks for molecular property prediction. Extensive experiments are conducted on three molecular property prediction datasets, and results demonstrate performance improvement over the state-of-the-art 3D molecular pretrained models.},
  archive      = {J_PR},
  author       = {Yufei Luo and Heran Yang and Jian Sun},
  doi          = {10.1016/j.patcog.2025.111531},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111531},
  shortjournal = {Pattern Recognition},
  title        = {Meta-learning of pseudo force field generation and estimation for enhancing 3D molecular property prediction},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive domain adaptation with test-time training for
out-of-context news detection. <em>PR</em>, <em>164</em>, 111530. (<a
href="https://doi.org/10.1016/j.patcog.2025.111530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Out-of-context news is a common type of misinformation on online media platforms. This involves posting a caption, alongside a mismatched news image. Reflecting its importance, researchers have developed models to detect such misinformation. However, a common limitation of these models is that they only consider the scenario where pre-labelled data is available for each news topic or agency, failing to address the out-of-context news detection on unverified news of other topics or agencies. In this work, we therefore focus on domain adaptive out-of-context news detection. We regard news topic or news agency as the domain . In order to effectively adapt the detection model to unlabelled news topics or agencies, we propose Con trastive D omain A daptation with T est- T ime T raining (ConDA-TTT). It first applies contrastive learning to learn a more separable representation space for news inputs, and then uses maximum mean discrepancy (MMD) to remove the domain-specific features so as to keep the domain-invariant features. During test time, it uses the trained model to predict pseudo labels for the target domain test data, and selects those with higher confidence scores to train the classifier of the model, in order to further adapt the model to the target domain data distribution. This approach adapts the model at both training and test phase, making the domain adaptation more robust to distribution shifts. Experimental results demonstrate that our approach outperforms state-of-the-art baselines in all the domain adaptation settings on two benchmark datasets, by as much as 2.6% in F1 and 2.4% in accuracy.},
  archive      = {J_PR},
  author       = {Yimeng Gu and Mengqi Zhang and Ignacio Castro and Shu Wu and Gareth Tyson},
  doi          = {10.1016/j.patcog.2025.111530},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111530},
  shortjournal = {Pattern Recognition},
  title        = {Contrastive domain adaptation with test-time training for out-of-context news detection},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zero-shot sketch-based image retrieval with teacher-guided
and student-centered cross-modal bidirectional knowledge distillation.
<em>PR</em>, <em>164</em>, 111529. (<a
href="https://doi.org/10.1016/j.patcog.2025.111529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of zero-shot learning, the task of using unseen-class sketches as queries to retrieve real images is referred to as Zero-Shot Sketch-Based Image Retrieval (ZS-SBIR). The ZS-SBIR task aims to generalize knowledge learned from known categories to unknown ones. Current research primarily relies on fine-tuning networks via loss functions or by unidirectionally extracting knowledge from fixed-parameter teacher models for training student models. However, unidirectional knowledge extraction from teacher models often lacks mutual learning and knowledge alignment between the teacher and student models, while fine-tuning networks via loss functions struggles to handle both photo and sketch modalities simultaneously. Therefore, we designed a modal perception and distribution alignment scheme based on gradient weighting to explore both photo and sketch features bidirectionally and deeply investigate the relationships between different modalities. Building on this, we propose a teacher-guided and student-centered cross-modal bidirectional knowledge distillation framework. During training, the student and teacher models mutually learn discriminative information based on the relationships between different modalities and synchronize their parameters guided by the teacher model, thus effectively achieving cross-modal alignment. Extensive experiments conducted on the TU-Berlin Ext, Sketchy Ext and QuickDraw Ext datasets demonstrate that our method significantly enhances retrieval performance.},
  archive      = {J_PR},
  author       = {Jiale Du and Yang Liu and Xinbo Gao and Jungong Han and Lei Zhang},
  doi          = {10.1016/j.patcog.2025.111529},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111529},
  shortjournal = {Pattern Recognition},
  title        = {Zero-shot sketch-based image retrieval with teacher-guided and student-centered cross-modal bidirectional knowledge distillation},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging facial landmarks improves generalization ability
for deepfake detection. <em>PR</em>, <em>164</em>, 111528. (<a
href="https://doi.org/10.1016/j.patcog.2025.111528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, facial forgery technology has become increasingly sophisticated and published datasets aim to cover a wide range of data variations. Existing deepfake detection models have benefited from the powerful feature embedding of deep networks and carefully designed fine-tuning modules, resulting in an excellent performance on in-dataset evaluations. However, the performance declines in cross-dataset evaluations due to various forgery methods and dataset shifts. In this study, we concentrate on the generalization issue of deepfake detection and find that forgery traces appear to gather around the facial interest points even manipulated by different forgery methods. To facilitate this, we propose a Trail Tracing Network (TTNet) to capture the generalized feature representation, which leverages facial landmarks to eliminate redundant information and expand the forged traces in the feature space. We conduct extensive experiments on the widely employed benchmarks, including FaceForensics++, DFDCp, and Celeb-DF. Experimental results demonstrate the outstanding generalization ability of our method against existing state-of-the-art methods by a large margin. In addition, the proposed method also exhibits excellent performance on the in-dataset evaluation.},
  archive      = {J_PR},
  author       = {Qi Gao and Baopeng Zhang and Jianghao Wu and Wenxin Luo and Zhu Teng and Jianping Fan},
  doi          = {10.1016/j.patcog.2025.111528},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111528},
  shortjournal = {Pattern Recognition},
  title        = {Leveraging facial landmarks improves generalization ability for deepfake detection},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TSTKD: Triple-spike train kernel-driven supervised learning
algorithm. <em>PR</em>, <em>164</em>, 111525. (<a
href="https://doi.org/10.1016/j.patcog.2025.111525">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precise artificial intelligence is one of the most promising research fields, where supervised learning for spiking neurons (SNs) plays an imperative and fundamental role. This study proposes a novel supervised learning algorithm based on triple-spike train kernels to address the shortcomings of the latest learning algorithms, such as local best learning and low learning accuracy. First, we divided the time intervals of the spike trains, including the firing time of the input spikes. Subsequently, we discovered and analyzed the relationship between the firing times of all spikes, added a third spike to solve the existing problem, and constructed a triple-spike-driven (TSD) minimum direct computational unit. In addition to the simple and efficient adjustment of synaptic weights based on pair-spike, TSD maintains a relationship between all useful spikes to approximate the global best learning. Finally, we proposed a triple-spike train kernel driven (TSTKD) supervised learning algorithm to improve the learning performance. Many fundamental experiments were implemented to demonstrate the learning performance, which proved that the successful learning ability and some learning factors of our proposed algorithm in spike train learning. We then verified the positive effect of the TSD on the proposed algorithm. Many experiments also proved the much higher learning accuracy of the proposed state-of-the-art algorithm compared to some of the latest algorithms, especially in the complex spike train learning. In addition, the proposed algorithm is more adaptive to SNs and much better at generalizing, memorizing, and classifying than the corresponding algorithm with pair-spike and some of the latest algorithms. Considering the above experimental results, our study blazes a trail for pattern recognition using spike train supervised learning with global optimization.},
  archive      = {J_PR},
  author       = {Guojun Chen and Guoen Wang},
  doi          = {10.1016/j.patcog.2025.111525},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111525},
  shortjournal = {Pattern Recognition},
  title        = {TSTKD: Triple-spike train kernel-driven supervised learning algorithm},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Partial multi-label feature selection based on label
distribution learning. <em>PR</em>, <em>164</em>, 111523. (<a
href="https://doi.org/10.1016/j.patcog.2025.111523">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial Multi-label Learning (PML) induces a multi-classifier in an imprecise supervised environment, where the candidate labels associated with each training sample are partially valid. The high-dimensional feature space, presented in PML data accompanied by ambiguous labeling information, is a significant challenge for learning. In this paper, we propose a PML feature selection method based on Label Distribution Learning (LDL), which handles the above challenges by correcting misleading and then selecting common and label-specific features. In the first procedure, the error distribution hypothesis is constructed, which divides the structure of ambiguous label information into minority and majority error distribution according to the error amount that may appear in the data annotation process. Under the analysis of the hypothesis, the label credibility distribution data (LCDD) was generated by identifying and correcting errors, where the fractional category of each label associated with each training sample describes the probability that the label belongs to that sample. In the second procedure, a discriminative feature subset is selected for PML based on LCDD by common and label-specific feature constraints. Experiments on three synthetic and five real PML datasets demonstrate the effectiveness of the proposed method.},
  archive      = {J_PR},
  author       = {Yaojin Lin and Yulin Li and Shidong Lin and Lei Guo and Yu Mao},
  doi          = {10.1016/j.patcog.2025.111523},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111523},
  shortjournal = {Pattern Recognition},
  title        = {Partial multi-label feature selection based on label distribution learning},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DEVICE: Depth and visual concepts aware transformer for
OCR-based image captioning. <em>PR</em>, <em>164</em>, 111522. (<a
href="https://doi.org/10.1016/j.patcog.2025.111522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {OCR-based image captioning is an important but under-explored task, aiming to generate descriptions containing visual objects and scene text. Recent studies have made encouraging progress, but they are still suffering from a lack of overall understanding of scenes and generating inaccurate captions. One possible reason is that current studies mainly focus on constructing the plane-level geometric relationship of scene text without depth information. This leads to insufficient scene text relational reasoning so that models may describe scene text inaccurately. The other possible reason is that existing methods fail to generate fine-grained descriptions of some visual objects. In addition, they may ignore essential visual objects, leading to the scene text belonging to these ignored objects not being utilized. To address the above issues, we propose a Depth and Visual Concepts Aware Transformer (DEVICE) for OCR-based image captioning. Concretely, to construct three-dimensional geometric relations, we introduce depth information and propose a depth-enhanced feature updating module to ameliorate OCR token features. To generate more precise and comprehensive captions, we introduce semantic features of detected visual concepts as auxiliary information, and propose a semantic-guided alignment module to improve the model’s ability to utilize visual concepts. Our DEVICE is capable of comprehending scenes more comprehensively and boosting the accuracy of described visual entities. Sufficient experiments demonstrate the effectiveness of our proposed DEVICE, which outperforms state-of-the-art models on the TextCaps test set.},
  archive      = {J_PR},
  author       = {Dongsheng Xu and Qingbao Huang and Xingmao Zhang and Haonan Cheng and Feng Shuang and Yi Cai},
  doi          = {10.1016/j.patcog.2025.111522},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111522},
  shortjournal = {Pattern Recognition},
  title        = {DEVICE: Depth and visual concepts aware transformer for OCR-based image captioning},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A generically contrastive spatiotemporal representation
enhancement for 3D skeleton action recognition. <em>PR</em>,
<em>164</em>, 111521. (<a
href="https://doi.org/10.1016/j.patcog.2025.111521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skeleton-based action recognition is a central task in computer vision and human–robot interaction. However, most previous methods suffer from overlooking the explicit exploitation of the latent data distributions ( i.e. , the intra-class variations and inter-class relations), thereby leading to confusion about ambiguous samples and sub-optimum solutions of the skeleton encoders. To mitigate this, we propose a C ontrastive S patiotemporal R epresentation E nhancement (CSRE) framework to obtain more discriminative representations from the sequences, which can be incorporated into various previous skeleton encoders and can be removed when testing. Specifically, we decompose the representation into spatial- and temporal-specific features to explore fine-grained motion patterns along the corresponding dimensions. Furthermore, to explicitly exploit the latent data distributions, we employ the attentive features to contrastive learning, which models the cross-sequence semantic relations by pulling together the features from the positive pairs and pushing away the negative pairs. Extensive experiments show that CSRE with five various skeleton encoders (HCN, 2S-AGCN, CTR-GCN, Hyperformer, and BlockGCN) achieves solid improvements on five benchmarks. The code will be released at https://github.com/zhshj0110/CSRE .},
  archive      = {J_PR},
  author       = {Shaojie Zhang and Jianqin Yin and Yonghao Dang},
  doi          = {10.1016/j.patcog.2025.111521},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111521},
  shortjournal = {Pattern Recognition},
  title        = {A generically contrastive spatiotemporal representation enhancement for 3D skeleton action recognition},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TextDiff: Enhancing scene text image super-resolution with
mask-guided residual diffusion models. <em>PR</em>, <em>164</em>,
111513. (<a href="https://doi.org/10.1016/j.patcog.2025.111513">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of scene text image super-resolution (STISR) is to reconstruct high-resolution text-line images from unrecognizable low-resolution inputs. The existing methods relying on the optimization of pixel-level loss tend to yield text edges that exhibit a notable degree of blurring, thereby exerting a substantial impact on both the readability and recognizability of the text. To address these issues, we propose TextDiff, the first diffusion-based framework tailored for STISR. It contains two modules: the Text Enhancement Module (TEM) and the Mask-Guided Residual Diffusion Module (MRD). The TEM generates an initial deblurred text image and a mask that encodes the spatial location of the text. The MRD is responsible for effectively sharpening the text edge by modeling the residuals between the ground-truth images and the initial deblurred images. Extensive experiments demonstrate that our TextDiff achieves state-of-the-art (SOTA) performance on public benchmark datasets, with a maximum improvement of 2.0% in recognition accuracy over existing methods while enhancing the readability of scene text images. Moreover, our proposed MRD module is plug-and-play that effectively sharpens the text edges produced by SOTA methods. This enhancement not only improves the readability and recognizability of the results generated by SOTA methods but also does not require any additional joint training.},
  archive      = {J_PR},
  author       = {Baolin Liu and Zongyuan Yang and Chinwai Chiu and Yongping Xiong},
  doi          = {10.1016/j.patcog.2025.111513},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111513},
  shortjournal = {Pattern Recognition},
  title        = {TextDiff: Enhancing scene text image super-resolution with mask-guided residual diffusion models},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Iterative knowledge distillation and pruning for model
compression in unsupervised domain adaptation. <em>PR</em>,
<em>164</em>, 111512. (<a
href="https://doi.org/10.1016/j.patcog.2025.111512">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical applications, deep learning models often face the challenges of inconsistent distribution between training data and test data and insufficient labeled data. To address these problems, unsupervised domain adaptation (UDA) based transfer learning has gained significant attention. However, the existing UDA models are difficult to meet the requirements of real-time and resource-constrained scenarios. Although model compression can accelerate UDA, it usually leads to performance degradation. In this paper, we propose an iterative transfer model compression (ITMC) method, which centers on two key modules, i.e., transfer knowledge distillation (TKD) and adaptive channel pruning (ACP), by executing them alternately. The tight coupling of the two modules realizes the effective compression of the model while ensuring the performance of the model on the target domain. In the TKD phase, the teacher model and the student model are gradually adapted to the target domain, and the real-time updated teacher model efficiently guides the student model learning, while the ACP phase employs a dynamic pruning strategy based on the training epoch, which removes unimportant channels based on the loss of the TKD student model. Experimental results demonstrate that ITMC approach achieves higher accuracy under the same compression ratio compared with the state-of-the-art methods.},
  archive      = {J_PR},
  author       = {Zhiyuan Wang and Long Shi and Zhen Mei and Xiang Zhao and Zhe Wang and Jun Li},
  doi          = {10.1016/j.patcog.2025.111512},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111512},
  shortjournal = {Pattern Recognition},
  title        = {Iterative knowledge distillation and pruning for model compression in unsupervised domain adaptation},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RhythmFormer: Extracting patterned rPPG signals based on
periodic sparse attention. <em>PR</em>, <em>164</em>, 111511. (<a
href="https://doi.org/10.1016/j.patcog.2025.111511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote photoplethysmography (rPPG) is a non-contact method for detecting physiological signals based on facial videos, holding high potential in various applications. Due to the periodicity nature of rPPG signals, the long-range dependency capturing capacity of the transformer was assumed to be advantageous for such signals. However, existing methods have not conclusively demonstrated the superior performance of transformers over traditional convolutional neural networks. This may be attributed to the quadratic scaling exhibited by transformer with sequence length, resulting in coarse-grained feature extraction, which in turn affects robustness and generalization. To address that, this paper proposes a periodic sparse attention mechanism based on temporal attention sparsity induced by periodicity. A pre-attention stage is introduced before the conventional attention mechanism. This stage learns periodic patterns to filter out a large number of irrelevant attention computations, thus enabling fine-grained feature extraction. Moreover, to address the issue of fine-grained features being more susceptible to noise interference, a fusion stem is proposed to effectively guide self-attention towards rPPG features. It can be easily integrated into existing methods to enhance their performance. Extensive experiments show that the proposed method achieves state-of-the-art performance in both intra-dataset and cross-dataset evaluations. The codes are available at https://github.com/zizheng-guo/RhythmFormer .},
  archive      = {J_PR},
  author       = {Bochao Zou and Zizheng Guo and Jiansheng Chen and Junbao Zhuo and Weiran Huang and Huimin Ma},
  doi          = {10.1016/j.patcog.2025.111511},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111511},
  shortjournal = {Pattern Recognition},
  title        = {RhythmFormer: Extracting patterned rPPG signals based on periodic sparse attention},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning multi-granularity representation with transformer
for visible-infrared person re-identification. <em>PR</em>,
<em>164</em>, 111510. (<a
href="https://doi.org/10.1016/j.patcog.2025.111510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visible-infrared person re-identification (VI-ReID) aims to match pedestrian images from visible and near-infrared modalities. The pedestrian images of two modalities contain discriminative features in different sizes and positions, e.g. , the global color of the cloth, the body’s local pose, and the shoe’s pixel size. However, existing methods mainly capture features at a single granularity, ignoring multi-granularity information contributing to pedestrian identification. Therefore, we propose a cross-modality multi-granularity Transformer (CM 2 GT) framework to solve this issue. CM 2 GT learns coarse-to-fine feature representations and integrates discriminative information across various granularities, which alleviates problems of the irrelevant matching and ambiguous alignment caused by matching single granularity features. Specifically, we first design a multi-granularity feature extractor (MGFE) module based on Transformer to capture the global-patch-pixel level features of each modality, which can flexibly represent semantic information at multiple scales. Secondly, a multi-granularity fusion Transformer (MGFT) module mines the hierarchical relationships between multi-granularity features by a saliency-enhanced Transformer, which ensures the identity-wise saliency consistency across different granularities and modalities. Furthermore, to further enhance cross-modality intra-class clustering in latent space, we design a cross-modality nearest-neighbor clustering (CNC) loss function to minimize the distance between the anchor sample and its cross-modality nearest neighbor. Extensive experiments demonstrate that our approach outperforms state-of-the-art methods.},
  archive      = {J_PR},
  author       = {Yujian Feng and Feng Chen and Guozi Sun and Fei Wu and Yimu Ji and Tianliang Liu and Shangdong Liu and Xiao-Yuan Jing and Jiebo Luo},
  doi          = {10.1016/j.patcog.2025.111510},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111510},
  shortjournal = {Pattern Recognition},
  title        = {Learning multi-granularity representation with transformer for visible-infrared person re-identification},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mask-aware 3D axial transformer for video inpainting.
<em>PR</em>, <em>164</em>, 111509. (<a
href="https://doi.org/10.1016/j.patcog.2025.111509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a Mask-Aware 3D Axial Transformer for efficient and effective video inpainting, which aims to recover the missing content of a video by leveraging long-range information in an efficient way. Recent works show that the transformer architecture achieves promising video inpainting performance, due to its powerful capability to exploit long-range consistency across frames. However, it requires high time complexity to compute the global self-attention. On the other hand, existing transformer-based inpainting methods treat the valid and invalid regions in the masked image the same when calculating self-attention, causing the network not to distinguish their differences. To address these issues, we first design a 3D Axial Transformer which splits the input features into three shapes of stripes, including a horizontal stripe, a vertical stripe to perform intra-frame attention, and a temporal stripe for inter-frame attention. With three such transformer blocks stacked, the relevance between two arbitrary spatial–temporal pixels across all video frames can be reached while maintaining high efficiency. We also devise a mask-aware module to predict the reliability score of masked pixels, which helps the transformer avoid leveraging information from the invalid region. Extensive experimental results on the Youtube-VOS and DAVIS datasets show that our approach outperforms the state-of-the-arts.},
  archive      = {J_PR},
  author       = {Hongyi Sun and Wanhua Li and Jiwen Lu and Jie Zhou},
  doi          = {10.1016/j.patcog.2025.111509},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111509},
  shortjournal = {Pattern Recognition},
  title        = {Mask-aware 3D axial transformer for video inpainting},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised group re-identification from aerial perspective
via strategic member harmonization. <em>PR</em>, <em>164</em>, 111508.
(<a href="https://doi.org/10.1016/j.patcog.2025.111508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Group re-identification (G-ReID) aims to match group images of the same identity. Existing G-ReID methods perform well on ground-based datasets, but remain unexplored in aerial perspective. One reason is the significant human effort required for aerial associations and the inability of unsupervised methods to address low-quality aerial pedestrian detection and reduced feature visibility. To address these issues, we propose Strategic Member Harmonization. Strategic members are harmonized to complement potential information lost or destroyed due to low-quality detections or significant member variations, thus forming harmonization groups. Harmonization groups introduce a richer layer of the underlying information, mitigating clustering inaccuracies gradually. To address the lack of aerial G-ReID datasets, we construct a new aerial dataset with 10,168 group images and 653 different group identities. Our approach achieves state-of-the-art performance on our dataset and performs well on other ground-based datasets. Our dataset is available at https://github.com/chen1hx/UAV-Group.},
  archive      = {J_PR},
  author       = {Hongxu Chen and Quan Zhang and Xiaohua Xie and Jianhuang Lai},
  doi          = {10.1016/j.patcog.2025.111508},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111508},
  shortjournal = {Pattern Recognition},
  title        = {Unsupervised group re-identification from aerial perspective via strategic member harmonization},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scientific poster generation: A new dataset and approach.
<em>PR</em>, <em>164</em>, 111507. (<a
href="https://doi.org/10.1016/j.patcog.2025.111507">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automating poster creation from research papers saves scientists time. However, training models for this task is challenging due to limited datasets. Moreover, existing methods are mostly rule/template-based, which lack the flexibility to adapt to different content and design requirements in scientific posters. Our contributions aim to address these issues. We introduce Sci-PosterLayout , a dataset comprising 1,226 scientific posters with greater variety in content , layout and domains . Using a template-free method with a seq2seq model and Design Pattern Schema ( DPS ), we learn various content and design patterns for poster layout generation. Evaluations against existing methods and datasets show our approach produces high-quality posters with diverse layouts. Our work seeks to advance research in scientific poster generation by building a new dataset and proposing template-free methods that require minimal human intervention. The Sci-PosterLayout dataset will be publicly available at https://github.com/kitman0000/Sci-PosterLayout-Data .},
  archive      = {J_PR},
  author       = {Xinyi Zhong and Zusheng Tan and Jing Li and Shen Gao and Jing Ma and Shanshan Feng and Billy Chiu},
  doi          = {10.1016/j.patcog.2025.111507},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111507},
  shortjournal = {Pattern Recognition},
  title        = {Scientific poster generation: A new dataset and approach},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). S2DiNet: Towards lightweight and fast high-resolution
dichotomous image segmentation. <em>PR</em>, <em>164</em>, 111506. (<a
href="https://doi.org/10.1016/j.patcog.2025.111506">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Dichotomous Image Segmentation task aims to achieve ultra-high precision binary segmentation for category-agnostic objects, including salient, camouflaged, structurally complex, or feature-similar entities. Traditional methods designed for low-resolution inputs produce blurred segmentation, failing to meet such critical safety and stability requirements. Although existing DIS methods achieve high accuracy, they are often parameter-heavy and slow, neglecting practical application needs. To address these challenges, this paper proposes a light-weight and fast framework, aims at improving processing efficiency while ensuring accuracy in high-resolution natural scenes. The proposed method utilizes a shared-weight ResNet-18 backbone to process inputs of different scales. A Feature Synchronization module is employed to enhance the correlation between encoded features of different resolutions. To reduce the parameter and increase the inference speed, the number of feature channels are decreased; however, this also resulted in information loss. The Star Fusion module is introduced to mitigate this issue. Furthermore, a Decoupling and Integration Decoder is adopted to progressively decode and fuse the body, detail, and mask features of the object, enhancing feature decoding accuracy. The proposed model runs at 26.3 FPS with a 48.7 MB size, reducing parameters by 72.4% and increasing speed by 30.8% compared to baseline method ISNet, while maintaining superior performance. Moreover, it surpasses several existing high-resolution methods in terms of accuracy.},
  archive      = {J_PR},
  author       = {Shuhan Chen and Haonan Tang and Yuan Huang and Lifeng Zhang and Xuelong Hu},
  doi          = {10.1016/j.patcog.2025.111506},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111506},
  shortjournal = {Pattern Recognition},
  title        = {S2DiNet: Towards lightweight and fast high-resolution dichotomous image segmentation},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CGViT: Cross-image GroupViT for zero-shot semantic
segmentation. <em>PR</em>, <em>164</em>, 111505. (<a
href="https://doi.org/10.1016/j.patcog.2025.111505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, with the increase of image-text data, such coarse data has also been introduced to address the image semantic segmentation task. However, previous works simply transfer the methods used in other visual tasks to image semantic segmentation, ignoring the task characteristics of semantic segmentation. In this work, we propose a C ross-image G roup ViT (CGViT) for zero-shot semantic segmentation, constructing a semantically consistent feature representation across images. Specifically, we improve the previous work GroupViT in two aspects. We propose two grouping blocks and update them with a momentum-based method, constructing a semantically consistent feature representation across images. Then we introduce an image-level supervision for learning semantic information and a token-level supervision for fine-grained information, obtaining hierarchical information for semantic segmentation. We train the model with image-text data and transfer it to zero-shot semantic segmentation without fine-tuning. Furthermore, the CGViT achieves new state-of-the-art results on three challenging datasets. Especially, the CGViT obtains 49.30% in mIoU on PASCAL VOC dataset, when only pre-trained on CC12M dataset.},
  archive      = {J_PR},
  author       = {Jie Jiang and Xingjian He and Xinxin Zhu and Weining Wang and Jing Liu},
  doi          = {10.1016/j.patcog.2025.111505},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111505},
  shortjournal = {Pattern Recognition},
  title        = {CGViT: Cross-image GroupViT for zero-shot semantic segmentation},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning to restore arbitrary hybrid adverse weather
conditions in one go. <em>PR</em>, <em>164</em>, 111504. (<a
href="https://doi.org/10.1016/j.patcog.2025.111504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adverse conditions typically suffer from stochastic hybrid weather degradations (e.g., rainy and hazy night), while existing image restoration algorithms envisage that weather degradations occur independently, thus may fail to handle real-world complicated scenarios. Besides, supervised training is not feasible due to the lack of comprehensive paired dataset to characterize hybrid weather conditions. To this end, we have advanced the forementioned limitations with two tactics: framework and data. First, we present a novel unified framework, dubbed RAHC, to Restore Arbitrary Hybrid adverse weather Conditions in one go. Specifically, our RAHC leverages a multi-head aggregation architecture to learn multiple degradation representation subspaces and then constrains the network to flexibly handle multiple hybrid adverse weather in a unified paradigm through a discrimination mechanism in the output space. Furthermore, we devise a reconstruction vectors aided scheme to provide auxiliary visual content cues for reconstruction, thus can comfortably cope with hybrid scenarios with insufficient remaining image constituents. Second, we establish a new dataset, termed HAC, for learning and benchmarking arbitrary Hybrid Adverse Conditions restoration. HAC contains 31 scenarios composed of an arbitrary fusion of five common weather, with a total of ∼ 316 K adverse-weather/clean pairs. As for fabrication, the training set is automatically generated by a dedicated AdverseGAN with no-frills labor, while the test set is manually modulated by experts for authoritative evaluation. Extensive experiments yield superior results and in particular establish new state-of-the-art results on both HAC and conventional datasets.},
  archive      = {J_PR},
  author       = {Yecong Wan and Mingwen Shao and Yuanshuo Cheng and Yuexian Liu and Zhiyuan Bao},
  doi          = {10.1016/j.patcog.2025.111504},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111504},
  shortjournal = {Pattern Recognition},
  title        = {Learning to restore arbitrary hybrid adverse weather conditions in one go},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Progressive class-aware instance enhancement for aircraft
detection in remote sensing imagery. <em>PR</em>, <em>164</em>, 111503.
(<a href="https://doi.org/10.1016/j.patcog.2025.111503">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aircraft detection and type identification in optical remote sensing imagery are critical for civilian and military applications, including air traffic control and strategic surveillance. However, existing methods ignore the unique cross-shaped geometric structure and low spatial occupancy of aircraft, leading to inaccurate localization and category confusion. In response, this paper proposes a novel anchor-free detection network that leverages point set representation, integrating the progressive class-aware dual branches (PCA-DB) and instance-guided enhancement module (IGEM). Specifically, considering the underlying structure of aircraft, PCA-DB consists of the coarse foreground instance branch and the refined cross-shaped branch to facilitate high-quality point set generation. Through multi-task learning, the auxiliary branches implicitly inject geometric priors into shared features, effectively suppressing background interference. Subsequently, IGEM introduces the interactive attention mechanism to adaptively fuse the instance-level information in the auxiliary branch with features in the main branches, explicitly enhancing the discriminative features of aircraft. Extensive experiments validate the superior performance of the proposed method on several aircraft datasets, including MAR20, FAIR1M-Plane, and CORS-ADD. There are 5.42%, 4.28%, and 1.37% improvements in mAP in our method compared to the baseline network.},
  archive      = {J_PR},
  author       = {Tianjun Shi and Jinnan Gong and Jianming Hu and Yu Sun and Guangzhen Bao and Pengfei Zhang and Junjie Wang and Xiyang Zhi and Wei Zhang},
  doi          = {10.1016/j.patcog.2025.111503},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111503},
  shortjournal = {Pattern Recognition},
  title        = {Progressive class-aware instance enhancement for aircraft detection in remote sensing imagery},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning for efficient registration
between intraoral-scan meshes and CT images. <em>PR</em>, <em>164</em>,
111502. (<a href="https://doi.org/10.1016/j.patcog.2025.111502">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Registration between computed tomography (CT) images and intraoral-scan (IOS) meshes facilitates dental procedure planning. However, the spatial complexity of 3D-space computations presents a significant challenge, necessitating the reduction of computational cost through efficient sampling while maintaining robustness via global approximation without segmentation. Herein, we introduce an efficient and robust method for registering CT images and IOS meshes, eliminating the need for segmentation. We utilized an effective sampling technique to identify key vertices in IOS meshes by calculating the negative curvatures between adjacent faces. The significant vertices are transformed into a novel graph representation, serving as the input state for the graph convolution-based backbone network within a deep reinforcement learning (DRL) framework. This framework approximates an optimal solution through sequential decision-making, selecting the best among 12 actions by considering translation and rotation to accurately locate the 3D mesh at arbitrary positions and angles on maxillary or mandibular teeth in CT images. The proposed method was evaluated against conventional and deep learning-based methods, demonstrating mean absolute errors of 1.955 ± 1.310 and 1.399 ± 0.644 mm for maxillary and mandibular teeth, respectively. Additionally, it required only 0.48 M floating-point operations for the calculations, making it more efficient than existing methods.},
  archive      = {J_PR},
  author       = {Seungpil Choi and Seoyeon Jang and Sunghee Jung and Heon Jae Cho and Byunghwan Jeon},
  doi          = {10.1016/j.patcog.2025.111502},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111502},
  shortjournal = {Pattern Recognition},
  title        = {Deep reinforcement learning for efficient registration between intraoral-scan meshes and CT images},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal fusion via voting network for 3D object detection
in indoors. <em>PR</em>, <em>164</em>, 111501. (<a
href="https://doi.org/10.1016/j.patcog.2025.111501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, 3D object detection has become essential in machine vision systems, as it requires more spatial information, such as position and size, compared to traditional 2D detection. Numerous studies have successfully achieved accurate localization, size estimation, orientation estimation, and classification of objects in diverse scenarios. Building on this foundation, we propose a novel method called &quot;Point Cloud and Image VoteNet,&quot; which enhances 3D object detection through the early fusion of radar point cloud data and image features. Our Point-Fusion technique projects radar point clouds onto images to extract complementary features. By incorporating point cloud density parameters, we improve the object matching mechanism, resulting in precise detections. Experimental results demonstrate that our model effectively leverages the combined information from point clouds and images, achieving superior performance. The fusion techniques and optimization strategies employed significantly enhance accuracy and robustness, showcasing promising potential in applications such as autonomous driving, robotics, and augmented reality.},
  archive      = {J_PR},
  author       = {Jianxin Li and Guannan Si and Xinyu Liang and Zhaoliang An and Pengxin Tian and Fengyu Zhou and Xiaoliang Wang},
  doi          = {10.1016/j.patcog.2025.111501},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111501},
  shortjournal = {Pattern Recognition},
  title        = {Multimodal fusion via voting network for 3D object detection in indoors},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention-based vector quantized variational autoencoder for
anomaly detection by using orthogonal subspace constraints. <em>PR</em>,
<em>164</em>, 111500. (<a
href="https://doi.org/10.1016/j.patcog.2025.111500">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new framework that uses a vector quantized variational autoencoder (VQVAE) enhanced by orthogonal subspace constraints (OSC) and pyramid criss-cross attention (PCCA). The framework was designed for anomaly detection in industrial product image datasets. Previous studies on modeling low-dimensional feature distributions have been unable to effectively distinguish between normal features and noisy/abnormal information, which is effectively addressed using OSC in this study. Then, the vector quantized mechanism is embodied in these two complementary subspaces to obtain normal and abnormal embedding subspaces and discrete representations for normal and noisy information, respectively. The proposed approach robustly represents low-dimensional discrete manifolds to present the information from normal data using a limited number of feature vectors. Additionally, two PCCA modules are proposed to capture feature maps from different layers in the encoder and decoder, benefitting the low-dimensional mapping and reconstruction process. The features of different layers are treated as the query (Q), key (K), and value (V), which could capture both low-level and high-level features, incorporating comprehensive contextual information. The effectiveness of the proposed framework for anomaly detection is assessed by comparing its performance with those of the state-of-the-art approaches on various publicly available industrial product image datasets.},
  archive      = {J_PR},
  author       = {Qien Yu and Shengxin Dai and Ran Dong and Soichiro Ikuno},
  doi          = {10.1016/j.patcog.2025.111500},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111500},
  shortjournal = {Pattern Recognition},
  title        = {Attention-based vector quantized variational autoencoder for anomaly detection by using orthogonal subspace constraints},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal urban traffic flow prediction based on
multi-scale time series imaging. <em>PR</em>, <em>164</em>, 111499. (<a
href="https://doi.org/10.1016/j.patcog.2025.111499">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic flow prediction is of great significance for administrators and travelers to make informed decisions in advance. Since the increasing correlation between predicted flow and historical flow from more recent periods, most existing traffic flow prediction models generally learn spatial-temporal patterns from historical single-scale time series data with time steps not exceeding 12. However, such short-term flow does not contain continuous and dynamic long-term spatial-temporal patterns. Thus, how to comprehensively learn the diverse patterns and achieve a satisfactory balance between effectiveness and efficiency presents a challenge. To this end, we propose a multimodal urban traffic flow prediction model based on multi-scale time series imaging (MM-TSI). Specifically, a data processing mechanism of multi-scale time series imaging is specially designed to efficiently learn both short- and long-term spatial-temporal patterns. After that, an image-based module is proposed to be parallelly integrated into a traditional time series-based module. By adaptively fusing the two-modal features extracted from image-based module and time series-based module, MM-TSI is capable of effectively learning more comprehensive and diverse spatial-temporal patterns while maintaining efficiency to a certain extent. Extensive experiments are conducted on three real-world urban traffic flow datasets. The results demonstrate that the proposed MM-TSI significantly outperforms the state-of-the-art (SOTA) models and exhibits generalization ability in both short- and long-term prediction.},
  archive      = {J_PR},
  author       = {Qinzhi Lv and Lijuan Liu and Ruotong Yang and Yan Wang},
  doi          = {10.1016/j.patcog.2025.111499},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111499},
  shortjournal = {Pattern Recognition},
  title        = {Multimodal urban traffic flow prediction based on multi-scale time series imaging},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bayesian dual-pathway network for unsupervised domain
adaptation. <em>PR</em>, <em>164</em>, 111498. (<a
href="https://doi.org/10.1016/j.patcog.2025.111498">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised Domain Adaptation (UDA) endeavors to address the challenges presented by domain shifts between domains characterized by differing yet related distributions. Traditional adversarial approaches typically adopt a single-pathway adversarial paradigm, which relies on a singular pathway to align the marginal distributions at the domain level. Despite notable advancements, this paradigm is constrained by two major limitations that lead to sub-optimal performance in both source and target domains. First, naive domain-level alignment often results in class mismatches. Second, the single-pathway adversarial approach grapples with the conflicting demands of reducing domain shift while simultaneously learning comprehensive features. Drawing inspiration from cognitive neuroscience, we propose a Bayesian Dual-Pathway Network (BDNet) for UDA to compute a classification prior for each domain, comprising a domain-shared pathway and a domain-specific pathway, designed to enhance target domain performance while preserving source domain efficacy. Specifically, the domain-shared pathway is employed to learn classification prior features through an adversarial paradigm grounded in structural alignment. Concurrently, a domain-specific pathway is crafted to extract distinct features, incorporating domain likelihood and domain prior features. Comprehensive features are synthesized through the fusion of common and specific attributes via a lightweight fusion module. Extensive experiments across three publicly available datasets demonstrate the efficacy of our approach, evidencing superior performance in both source and target domains.},
  archive      = {J_PR},
  author       = {Yuhang He and Junzhe Chen and Jiehua Zhang and Wei Ke and Yihong Gong},
  doi          = {10.1016/j.patcog.2025.111498},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111498},
  shortjournal = {Pattern Recognition},
  title        = {A bayesian dual-pathway network for unsupervised domain adaptation},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Guiding prototype networks with label semantics for few-shot
text classification. <em>PR</em>, <em>164</em>, 111497. (<a
href="https://doi.org/10.1016/j.patcog.2025.111497">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot text classification aims to recognize unseen classes with limited labeled text samples. Typical meta-learning methods, e.g., Prototypical Networks, face several problems. (1) The limited words in each sentence make it difficult to extract fine-grained class-related semantic information. (2) The semantic information from labels is not fully utilized, leading to ambiguities in class definitions. (3) The randomly selected support samples cannot represent their corresponding classes well. In this paper, we propose to leverage label semantics tackling the above problems and present L abel G uided P rototype N etworks (LGPN). Firstly, we use prompt encoding to generate text representations instead of aggregating the words in the sentences, extracting more class-related semantic information. Secondly, we propose Label-guided Distance Scaling (LDS), in the training stage, we design label-guided loss to pull the samples closer to their corresponding labels, making class distributions distinguishable. Thirdly, in the testing stage, we scale the text representations with the label semantics to pull each support sample closer to the class center, which reduces the prediction contradictions caused by randomly selected support samples (i.e., unsatisfactory support sample representations). We conduct extensive experiments on six benchmark datasets, and our LGPN shows obvious advantages over state-of-the-art models. Additionally, we further explore the effectiveness and universality of our modules.},
  archive      = {J_PR},
  author       = {Xinyue Liu and Yunlong Gao and Linlin Zong and Wenxin Liang and Bo Xu},
  doi          = {10.1016/j.patcog.2025.111497},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111497},
  shortjournal = {Pattern Recognition},
  title        = {Guiding prototype networks with label semantics for few-shot text classification},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rank gap sensitive deep AUC maximization for CTR prediction.
<em>PR</em>, <em>164</em>, 111496. (<a
href="https://doi.org/10.1016/j.patcog.2025.111496">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Network (DNN) stands out as one widely adopted and effective technique for Click-Through Rate (CTR) prediction in live recommender systems. However, the prevalent DNN-based CTR methods exhibit two main drawbacks. On one hand, they fail to align their optimization objectives with the benchmark metric, such as the Area Under the ROC Curve (AUC), designed for ranking tasks. On the other hand, current DNN-based CTR solutions indiscriminately treat all positive-negative item pairs, ignoring the fact that each item pair differently contributes to AUC optimization. To this end, we propose R ank G ap S ensitive Deep AUC maximization method for accurate CTR prediction, namely RgsAUC. Specifically, we target AUC as the learning objective by relaxing the Heaviside function via sigmoid function to render it differentiable and thus can be optimized directly using gradient-descent methods, which is the de facto choice for solving DNN-based CTR tasks. Furthermore, we incorporate a rank gap sensitive weight in estimating gradients for items, aiming to assign greater significance to item pairs with substantial rank gaps during the learning process. In particular, we reduce the computational complexity from quadratic to linear through reformulation, enabling efficient deployment. Consequently, these designs sharply minimize the number of erroneously-ranked item pairs, which is beneficial to AUC optimization. Notably, RgsAUC is model-agnostic and we implement it in five classic DNN models for the CTR prediction task. Extensive experiments on six real-world datasets clearly demonstrate the effectiveness of our proposed method.},
  archive      = {J_PR},
  author       = {Fangyuan Luo and Yankai Chen and Jun Wu and Yidong Li},
  doi          = {10.1016/j.patcog.2025.111496},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111496},
  shortjournal = {Pattern Recognition},
  title        = {Rank gap sensitive deep AUC maximization for CTR prediction},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extremely fast graph integration for semi-supervised
learning via gaussian fields with neumann approximation. <em>PR</em>,
<em>164</em>, 111495. (<a
href="https://doi.org/10.1016/j.patcog.2025.111495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth in data availability, it has become more important to utilize multiple data sources containing different but complementary information for a given task. Using multiple graphs can technically be interpreted as finding the optimal combination of each graph. There have been various approaches for graph integration or graph fusion, but most of them have suffered from scalability issues as data size increases due to long computation time. This makes them difficult to utilize in the current trend of data size becoming huge. To circumvent this difficulty, our approach introduces a fast graph integration method based on semi-supervised learning (SSL), which incorporates the Neumann approximation during the maximum likelihood estimation process. Empirical studies show that the proposed method significantly reduces computation time by at least a factor of two compared to state-of-the-art methods, while still performing competitively with other methods. This advantage becomes more apparent as the size of the data increases, since the complexity of the proposed method depends mostly on the number of graphs to be integrated and not on the number of nodes, unlike other methods. Experimental results demonstrate the scalability and efficiency of the proposed method for graph integration.},
  archive      = {J_PR},
  author       = {Taehwan Yun and Myung Jun Kim and Hyunjung Shin},
  doi          = {10.1016/j.patcog.2025.111495},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111495},
  shortjournal = {Pattern Recognition},
  title        = {Extremely fast graph integration for semi-supervised learning via gaussian fields with neumann approximation},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Auxiliary action unit model for facial expression
adversarial training. <em>PR</em>, <em>164</em>, 111493. (<a
href="https://doi.org/10.1016/j.patcog.2025.111493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The adversarial training of neural networks against adversarial attacks is increasingly gaining attention due to the demands for artificial intelligence security. However, there have been few studies on adversarial training for facial expression recognition (FER) models. In this work, we propose a novel adversarial training method for FER models. Specifically, we employ an action unit (AU) model to enhance the adversarial robustness of the FER model during the training process. Experimental results demonstrate that our method (i) exhibits greater generalization and robustness than other existing methods for FER models; (ii) incurs feasible computational training costs; and (iii) can converge under extreme circumstances, such as random labels. Our research makes sense as it paves the way for future studies in adversarial training for FER models.},
  archive      = {J_PR},
  author       = {Yudao Sun and Fan Zhang and Minjiao Yang},
  doi          = {10.1016/j.patcog.2025.111493},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111493},
  shortjournal = {Pattern Recognition},
  title        = {Auxiliary action unit model for facial expression adversarial training},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A perturbed match filtering approach for face image quality
assessment. <em>PR</em>, <em>164</em>, 111492. (<a
href="https://doi.org/10.1016/j.patcog.2025.111492">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face image quality assessment (FIQA) that estimates the utility of face images is essential for reliable face recognition. However, current state-of-the-art analysis-based FIQA methods suffer from excessively long execution time. Inspired by an observation that comparing to low-quality images, the features of high-quality images more likely maintain stronger robustness after perturbation, we propose a novel training-free FIQA approach, called Perturbed Match Filtering (PMF), in which a quality score function is defined based on the output of a match filter that takes as input the perturbed feature manipulated by selectively dropping a proportion of elements within an internal activation of the network. In addition, our proposed PMF approach can be implemented as a post-processing step for a pre-trained quality regression model to further improve its performance. We conduct extensive experiments on eight benchmark datasets with four target face recognition models. The experimental results demonstrate the superiority of our proposed approach compared to twelve state-of-the-art FIQA algorithms.},
  archive      = {J_PR},
  author       = {Yuying Zhao and Mei Wang and Jiani Hu and Weihong Deng and Chun-Guang Li},
  doi          = {10.1016/j.patcog.2025.111492},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111492},
  shortjournal = {Pattern Recognition},
  title        = {A perturbed match filtering approach for face image quality assessment},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Refining attention weights for facial super-resolution with
counterfactual attention learning. <em>PR</em>, <em>164</em>, 111491.
(<a href="https://doi.org/10.1016/j.patcog.2025.111491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face Super-resolution is a challenging problem involving reconstructing High- Resolution (HR) images from Low-Resolution (LR) inputs with attention mechanisms being a widely used approach. This paper introduces counterfactual attention learning (CAL), a novel framework based on causal inference that enhances attention quality in super-resolution tasks. CAL provides a strong supervisory signal, enabling the refinement of attention mechanisms during training. Through counterfactual interventions, CAL optimizes learned attention to improve super-resolution outcomes. This method is evaluated using the Scale- Arbitrary Super-Resolution model (ArbSR), which accommodates non-integer scale factors. Experiments conducted on CelebA, FFHQ, and CMU Multi-PIE datasets across different scale factors show that CAL significantly enhances super-resolution performance. On the CMU Multi-PIE dataset, CAL improves Peak Signal-to-Noise Ratio (PSNR) by up to 13.6 % compared to baseline attention mechanisms, even under challenging variations in illumination, pose, and expression. PSNR improvement of 15.5 % was observed for CelebA dataset whereas for the FFHQ dataset, 14.5 % improvement was observed under occlusion conditions. These results highlight the robustness and effectiveness of CAL in advancing the state of super-resolution, offering substantial quantitative and qualitative improvements and showcasing its potential for face superresolution in real-world conditions.},
  archive      = {J_PR},
  author       = {Jayanthi Raghavan and Majid Ahmadi},
  doi          = {10.1016/j.patcog.2025.111491},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111491},
  shortjournal = {Pattern Recognition},
  title        = {Refining attention weights for facial super-resolution with counterfactual attention learning},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NRGAN: A noise-resilient GAN with adaptive feature
modulation for SAR image segmentation. <em>PR</em>, <em>164</em>,
111490. (<a href="https://doi.org/10.1016/j.patcog.2025.111490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The information extraction of offshore aquaculture rafts from synthetic aperture radar (SAR) images is important for large-scale marine resource exploration and utilization. In this paper, a deep learning model, called Noise-Resilient Generative Adversarial Network (NRGAN), is proposed for SAR image segmentation captured under varying sea conditions to monitor aquaculture rafts. NRGAN consists of an image generator and two regressors. The image generator is used for image segmentation and the regressors for discriminating the generated results and the actual labels. As a key component of the generator, a pixel-level contextual feature adaptation module is designed to improve the performance of the model in dealing with issues such as noise interference and complex image features commonly found in SAR images. The module consists of three parts: one for spatial-feature adaptation to aggregate spatial information from input feature maps and generate a spatial attention map to focus on relevant areas in images, one for contextual-feature adaptation to integrate contextual information for improving feature learning and increasing the expressiveness of input data, and one for pixel-level feature adaptation to refine the contribution of regions within the images, thereby enhancing the coherence of the overall segmentation.},
  archive      = {J_PR},
  author       = {Shuo Lian and Jianchao Fan and Jun Wang},
  doi          = {10.1016/j.patcog.2025.111490},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111490},
  shortjournal = {Pattern Recognition},
  title        = {NRGAN: A noise-resilient GAN with adaptive feature modulation for SAR image segmentation},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-modality average precision optimization for visible
thermal person re-identification. <em>PR</em>, <em>164</em>, 111489. (<a
href="https://doi.org/10.1016/j.patcog.2025.111489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metric learning has emerged as a popular approach for addressing the challenges of visible thermal person re-identification (VT-ReID), such as the cross-modality discrepancy and intra-class variations. However, existing metric learning-based methods often focus on optimizing the model for hard positive samples, neglecting the importance of high-ranking ones, due to failing to consider the overall ranking order within a batch. To overcome this limitation, we propose a novel approach called Cross-modality Average Precision (CAP) that directly optimizes the cross-modality overall ranking order in VT-ReID. Unlike the recently introduced Smooth Average Precision (Smooth-AP), which primarily corrects misordered samples at high ranks, CAP specifically targets the main challenge of cross-modality discrepancy in VT-ReID. Our method involves setting a query instance from one modality and calculating the CAP using galleries from another modality. CAP encompasses two complementary aspects: CAP with Visible queries (CAPV) and CAP with Thermal queries (CAPT). By jointly optimizing these two aspects, we can effectively improve the cross-modality overall ranking order. Additionally, to enhance the effectiveness of CAP, we introduce two techniques. The first technique is Dynamic Modality Alignment (DMA), which reduces the cross-modality discrepancy by adaptively adjusting the weights of modality alignment. The second technique involves implementing CAP and DMA on the Global and Local Features (GLF), enabling us to optimize the model at both global and local levels, further enhancing the advantages of CAP and DMA. We conducted extensive experiments on two VT-ReID datasets, and the results demonstrate the effectiveness of our proposed method, which achieves state-of-the-art performance.},
  archive      = {J_PR},
  author       = {Yongguo Ling and Zhiming Luo and Dazhen Lin and Shaozi Li and Min Jiang and Nicu Sebe and Zhun Zhong},
  doi          = {10.1016/j.patcog.2025.111489},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111489},
  shortjournal = {Pattern Recognition},
  title        = {Cross-modality average precision optimization for visible thermal person re-identification},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view diabetic retinopathy grading via cross-view
spatial alignment and adaptive vessel reinforcing. <em>PR</em>,
<em>164</em>, 111487. (<a
href="https://doi.org/10.1016/j.patcog.2025.111487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our research introduces a novel deep learning framework that leverages multi-view fundus images for Diabetic Retinopathy (DR) grading. Existing models for fundus image analysis often prioritize salient features, such as the optic disk, potentially overlooking finer details critical for DR detection, like retinal vessel information. To address this, we introduce a learnable retinal vessel reinforcement block to enhance the representation of retinal vessels. Additionally, recognizing the limitations of traditional multi-view models in capturing the spatial correlation between 2D appearances from different views, we propose a cross-view spatial region aligning vision transformer (ViT). This ViT-structured model is crucial for modeling cross-view relationships and integrating lesion information across individual views. Furthermore, a multi-view decision fusion module synergistically fuses diagnostic insights from multiple perspectives, enhancing the model’s diagnostic capabilities. Our method demonstrates significant superiority over existing single-view and multi-view models across key performance metrics, including accuracy, precision, sensitivity, specificity, and F1 score.},
  archive      = {J_PR},
  author       = {Yuxin Lin and Xiaoyan Dou and Xiaoling Luo and Zhihao Wu and Chengliang Liu and Tianyi Luo and Jie Wen and Bingo Wing-kuen Ling and Yong Xu and Wei Wang},
  doi          = {10.1016/j.patcog.2025.111487},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111487},
  shortjournal = {Pattern Recognition},
  title        = {Multi-view diabetic retinopathy grading via cross-view spatial alignment and adaptive vessel reinforcing},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CLEAR: Cross-transformers with pre-trained language model
for person attribute recognition and retrieval. <em>PR</em>,
<em>164</em>, 111486. (<a
href="https://doi.org/10.1016/j.patcog.2025.111486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person attribute recognition and attribute-based person retrieval are two core human-centric tasks. In the recognition task, the challenge lies in identifying attributes based on a person’s appearance, while the retrieval task involves searching for matching persons using attribute-based queries. In this paper, we present CLEAR , a unified network designed to address both tasks. We leverage our C 2 T-Net, a strong Cross-Transformers backbone that achieved state-of-the-art performance in the person attribute recognition task during the UPAR Challenge 2024, to extract visual embeddings. We then adapt it for the attribute-based person retrieval task.To extend its capabilities for the attribute-based person retrieval task, we construct pseudo-textual descriptions for attribute queries, leverage a pretrained language model to generate language-rich feature embeddings, and introduce an effective training strategy, which involves finetuning only a few additional parameters in the form of adapters to produce visual and query embeddings within the retrieval space. As the visual embeddings extracted by C 2 T-Net are highly discriminative, they align well with the proposed query embeddings during the finetuning process, facilitating improved retrieval performance.The unified CLEAR , model is evaluated on five benchmarks: PETA, PA100K, Market-1501, RAPv2, and UPAR2024, achieving state-of-the-art or competitive results for both tasks. Notably, it ranks as the top performer on the large-scale UPAR2024 dataset, specifically designed to test domain generalizability in real-world scenarios where test samples differ from training samples.},
  archive      = {J_PR},
  author       = {Doanh C. Bui and Thinh V. Le and Ba Hung Ngo and Tae Jong Choi},
  doi          = {10.1016/j.patcog.2025.111486},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111486},
  shortjournal = {Pattern Recognition},
  title        = {CLEAR: Cross-transformers with pre-trained language model for person attribute recognition and retrieval},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Balanced multi-modal learning with hierarchical fusion for
fake news detection. <em>PR</em>, <em>164</em>, 111485. (<a
href="https://doi.org/10.1016/j.patcog.2025.111485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal fake news detection (MFND) leverages data from various modalities, including text, image, video, and audio, to identify the authenticity of news content. Most existing MFND methods focus on extracting feature representations of each modality and integrating them by fusion strategies. However, they ignore the problem of modality imbalance where the dominant modality suppresses the performance of other modalities during optimization process, which leads to insufficient utilization of multi-modal information. To address the issue of modality imbalance and guarantee the effective utilization of each modality, we propose an approach called Balanced Multi-modal Learning with Hierarchical Fusion (BMLHF), which contains a Multi-modal Information Balancing (MIB) module and a Hierarchical Fusion (HF) module. Specifically, we extract multi-view semantic and pattern features of text and image. MIB calculates the modal information firstly to estimate the modal difference ratio, and it dynamically allocates corresponding weight for optimization of each view of modalities, which facilitates the modal information balance state. HF fully explores the diversity and correlation of multi-modal information in two stages. Intra-modal multi-view information fusion stage designs multi-view attention sub-network to sufficiently fuse semantic and pattern features within modalities. Inter-modal correlation fusion stage designs the joint correlation matrix based cross-attention strategy to learn multi-modal fused features with complementary characteristics. Extensive benchmark experiments demonstrate that our approach significantly surpasses state-of-the-art MFND methods.},
  archive      = {J_PR},
  author       = {Fei Wu and Shu Chen and Guangwei Gao and Yimu Ji and Xiao-Yuan Jing},
  doi          = {10.1016/j.patcog.2025.111485},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111485},
  shortjournal = {Pattern Recognition},
  title        = {Balanced multi-modal learning with hierarchical fusion for fake news detection},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GAD: Domain generalized diabetic retinopathy grading by
grade-aware de-stylization. <em>PR</em>, <em>164</em>, 111484. (<a
href="https://doi.org/10.1016/j.patcog.2025.111484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic retinopathy (DR) is a prevalent complication of diabetes that can result in vision impairment and blindness, making accurate DR grading essential for early diagnosis and treatment. Most existing DR grading methods assume that the training and test images share the same distribution. However, the generalization performance on unseen target domains has not been adequately addressed. In this paper, we observe that images from the same domain tend to cluster together in the feature space, rather than images of the same grade. This is largely due to the fact that when the representation of lesions is influenced by style variations, the network tends to remember features of different image domains through separate channels. This phenomenon significantly impacts the generalization capability of deep learning models. To address this issue, we propose a global-aware channel similarity to reduce the influence of lesion position and size when measuring the distance in the feature space. This is further utilized in a grade-aware contrastive learning approach, which guides the learning of domain-invariant features by mapping images of the same grade into a compact subspace. Additionally, we develop a multi-scale de-stylization method to explicitly eliminate style information from the features, which also compels the model to exploit diverse representations of the lesion. Extensive experiments on multiple DR grading datasets show the state-of-the-art generalization ability of the proposed method.},
  archive      = {J_PR},
  author       = {Qi Bi and Jingjun Yi and Hao Zheng and Haolan Zhan and Yawen Huang and Wei Ji and Yuexiang Li and Yefeng Zheng},
  doi          = {10.1016/j.patcog.2025.111484},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111484},
  shortjournal = {Pattern Recognition},
  title        = {GAD: Domain generalized diabetic retinopathy grading by grade-aware de-stylization},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised feature selection via maximum relevance and
minimum global redundancy. <em>PR</em>, <em>164</em>, 111483. (<a
href="https://doi.org/10.1016/j.patcog.2025.111483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised feature selection has been an important research topic in various fields since real datasets often lack complete label information. Many existing unsupervised feature selection algorithms select features based on feature relevance only without considering the redundancy between features, which may result in the selection of suboptimal features. To obtain the optimal feature subset, we propose a new unsupervised feature selection algorithm, called unsupervised Feature Selection with Max-Relevance and Minimum Global Redundancy (MRMGRFS) to select a subset of features with max-relevance and minimum global redundancy. In terms of relevance, we propose an unsupervised Feature Selection algorithm based on Spectral Clustering (SCFS), which divides all features into different clusters using spectral clustering and evaluates the relevance of features by measuring the distance between the features and the mean centers of own-cluster and heterogeneous-clusters. In terms of redundancy, the SCFS algorithm only considers the relevance of features and ignores the redundancy between features, which may select the redundant features that degrade performance. To tackle this issue, a Global Redundancy Minimization model (SJGRM) based on the SCFS and Jensen–Shannon divergence (JSD) is proposed to optimize the relevance score of the features. Furthermore, we propose an effective iterative algorithm for solving SJGRM based on the Alternating Direction Method of Multipliers (ADMM). Extensive experimental results on various public datasets demonstrate the superiority of the proposed algorithm.},
  archive      = {J_PR},
  author       = {Xianyu Zuo and Wenbo Zhang and Xiangyu Wang and Lanxue Dang and Baojun Qiao and Yadi Wang},
  doi          = {10.1016/j.patcog.2025.111483},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111483},
  shortjournal = {Pattern Recognition},
  title        = {Unsupervised feature selection via maximum relevance and minimum global redundancy},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On inferring prototypes for multi-label few-shot learning
via partial aggregation. <em>PR</em>, <em>164</em>, 111482. (<a
href="https://doi.org/10.1016/j.patcog.2025.111482">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label few-shot learning (ML-FSL) aims to endow the learning system to recognize multiple objects within an image, trained with insufficient samples. Existing methods have significantly improved ML-FSL and focused on mining the correlation of labels, resulting in a discriminative prototype per class. However, those methods often engage irrelevant information, i.e. , the tangled region with other classes, in the phase of constructing prototypes, limiting their performance gain. Following the intuition that only part regions of an image correspond to a target label, this paper addresses this issue by creating prototypes via a partial aggregation scheme. This is realized by first generating aggregation weights via partial optimal transport (POT) between image and label features and producing features per class using relevant regions within an image. Having the refined class features in a support set, one can obtain a better prototype for each class. We evaluate our model on multiple benchmarks and obtain state-of-the-art performance. A thorough study also reveals the superiority of POT as a way of mining important information for generating prototypes.},
  archive      = {J_PR},
  author       = {Pengfei Fang and Zhihong Chen and Hui Xue},
  doi          = {10.1016/j.patcog.2025.111482},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111482},
  shortjournal = {Pattern Recognition},
  title        = {On inferring prototypes for multi-label few-shot learning via partial aggregation},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ALStereo: Active learning for stereo matching. <em>PR</em>,
<em>164</em>, 111480. (<a
href="https://doi.org/10.1016/j.patcog.2025.111480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With advancements in deep stereo matching, recent networks have achieved impressive accuracy in estimating depth information from image pairs. However, stereo matching networks require sufficient disparity labels, which always come at high annotation costs. In this paper, we propose the ALStereo framework for training stereo matching networks under limited labeling budgets, which selects informative samples for manual labeling and conducts semi-supervised learning to propagate the knowledge to unlabeled samples. Specifically, we embed image pairs as nodes in a graph representation, where edges denote the similarity in terms of stereo matching challenges. Based on the graph representation, we divide the labeling budget into two parts for conducting representativeness-based and uncertainty-based strategies, balancing the selection of the most representative and challenging samples. To fully exploit the labeled samples to train networks, we propose a two-stage semi-supervised training pipeline, where the first stage mitigates the domain shifts and the second stage propagates the knowledge of manually annotated samples to unlabeled samples. We set the first benchmark for evaluating training stereo matching networks under limited labeling budgets and demonstrate our method significantly outperforms the compared methods. We also provide analysis to demonstrate our graph representation effectively models the similarity between samples in terms of stereo matching challenges.},
  archive      = {J_PR},
  author       = {Jiawei Zhang and Jiahe Li and Meiying Gu and Xiaohan Yu and Jin Zheng and Xiao Bai and Edwin Hancock},
  doi          = {10.1016/j.patcog.2025.111480},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111480},
  shortjournal = {Pattern Recognition},
  title        = {ALStereo: Active learning for stereo matching},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Token-aware and step-aware acceleration for stable
diffusion. <em>PR</em>, <em>164</em>, 111479. (<a
href="https://doi.org/10.1016/j.patcog.2025.111479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stable Diffusion has shown strong ability to generate high-quality and diverse images. However, Stable Diffusion suffers from high computational cost, due to the heavy model and step-by-step denoising process. To address these issues, we propose a token-aware and step-aware acceleration approach for Stable Diffusion, named TSA-SD. We first build a simple and efficient baseline by combining exiting intra-step and cross-step acceleration strategies, including token merging and feature caching, into Stable Diffusion. To improve image generation quality of the baseline, we introduce token-aware merging–unmerging and step-aware acceleration. The token-aware merging–unmerging aims to select informative tokens when merging and recover merged tokens using token ratio information. Therefore, the token-aware merging–unmerging can fully utilize token-specific information, thereby reducing token information loss. In addition, we observe that different steps have different functional linearity, and propose step-aware acceleration to perform different merging operations according to functional linearity at different steps. With these two modules, our proposed TSA-SD is able to generate high-quality images at a high speed. We perform the experiments on two widely-used datasets, including ImageNet and MS-COCO. The experimental results demonstrate the effectiveness and efficiency of our proposed method. For instance, on ImageNet validation set, compared to Stable Diffusion, ToMe-SD has a lower FID of 33.68 at 1.96 × speedup, while our method achieves a lower FID of 32.49 at 4.68 × speedup.},
  archive      = {J_PR},
  author       = {Ting Zhen and Jiale Cao and Xuebin Sun and Jing Pan and Zhong Ji and Yanwei Pang},
  doi          = {10.1016/j.patcog.2025.111479},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111479},
  shortjournal = {Pattern Recognition},
  title        = {Token-aware and step-aware acceleration for stable diffusion},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optical remote sensing image salient object detection via
bidirectional cross-attention and attention restoration. <em>PR</em>,
<em>164</em>, 111478. (<a
href="https://doi.org/10.1016/j.patcog.2025.111478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Salient object detection (SOD) in optical remote sensing images (ORSI) has garnered considerable attention in recent years. The inherent high complexity of scenes in ORSI poses significant challenges to SOD methods. Current models face two major limitations. First, they fail to fully exploit the relationships between features due to ignoring the bidirectional attention relationship and continuity among adjacent feature layers. Second, while non-local modules are designed to enhance global context understanding by modeling pixel-wise relationships, their traditional implementations suffer from attention vacuity, as they treat all spatial locations equally without focusing on the most informative regions. To overcome these limitations, we introduce a novel Bidirectional Cross-Attention and Attention Restoration Neural Network (BCAR-Net), comprising the Bidirectional Cross-Attention Module (BCAM) and the Attention Restoration Module (ARM). BCAM enhances the semantic representation of detail features in lower-level maps and improves the detail representation of semantic features in higher-level maps. This is achieved by computing cross-attention between two adjacent layers in a parallel bidirectional manner, playing a crucial role in spatial information representation. Additionally, ARM addresses attention vacuity through the Foreground-Background Decoupling (FBD) and Local Attention Vacuity Supplementation (LAVS) components. Specifically, FBD refines the segmentation of salient objects from their backgrounds, while LAVS remedies local object detection omissions. Experimental results demonstrate that our proposed model performs favorably and outperforms existing methods overall. Specifically, on the ORSSD and EORSSD benchmark datasets, our method outperforms the SOTA approaches by 10% and 5% in terms of MAE, respectively. The source codes and the outcomes can be accessed at https://github.com/ClimBin/BCARNet .},
  archive      = {J_PR},
  author       = {Yubin Gu and Siting Chen and Xiaoshuai Sun and Jiayi Ji and Yiyi Zhou and Rongrong Ji},
  doi          = {10.1016/j.patcog.2025.111478},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111478},
  shortjournal = {Pattern Recognition},
  title        = {Optical remote sensing image salient object detection via bidirectional cross-attention and attention restoration},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning pathways for automatic sign language
processing. <em>PR</em>, <em>164</em>, 111475. (<a
href="https://doi.org/10.1016/j.patcog.2025.111475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study provides a comprehensive review of the current state of the sign language processing (SLP) field, encompassing sign language recognition (SLR), translation (SLT), production (SLPn), and the associated datasets (SLD). It analyzes the advancements and challenges in each area, highlighting key methodologies and technologies. The authors explore feature extraction techniques, model architectures, and multimodal data integration in SLR. For SLT, they examine neural machine translation and sequence-to-sequence frameworks, emphasizing the need for context-aware systems. In SLPn, they review avatar-based systems and motion capture techniques, identifying gaps in generating natural and expressive sign language. The survey of SLD evaluates existing datasets and underscores the importance of comprehensive data collection. It also discusses current SLP systems’ limitations and proposes future research directions to enhance accuracy, naturalness, and user-centric applications.},
  archive      = {J_PR},
  author       = {Mukhiddin Toshpulatov and Wookey Lee and Jaesung Jun and Suan Lee},
  doi          = {10.1016/j.patcog.2025.111475},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111475},
  shortjournal = {Pattern Recognition},
  title        = {Deep learning pathways for automatic sign language processing},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inversed pyramid network with spatial-adapted and
task-oriented tuning for few-shot learning. <em>PR</em>, <em>164</em>,
111415. (<a href="https://doi.org/10.1016/j.patcog.2025.111415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of artificial intelligence, deep neural networks have achieved great performance in many tasks. However, traditional deep learning methods require a large amount of training data, which may not be available in certain practical scenarios. In contrast, few-shot learning aims to learn a model that can be readily adapted to new unseen classes from only one or a few labeled examples. Despite this success, most existing methods rely on pre-trained feature extractor networks trained with global features, ignoring the discrimination of local features, and weak generalization capabilities limit their performance. To address the problem, according to the human’s coarse-to-fine cognition paradigm, we propose an Inverted Pyramid Network with Spatial-adapted and Task-oriented Tuning (TIPN) for few-shot learning. Specifically, the proposed framework represents local features for categories that are difficult to distinguish by global features and recognizes objects from both global and local perspectives. Moreover, to ensure the calibration validity of the proposed model at the local stage, we introduce the Spatial-adapted Layer to preserve the discriminative global representation ability of the pre-trained backbone network. Meanwhile, as the representations extracted from the past categories are not applicable to the current new tasks, we further propose the Task-oriented Tuning strategy to adjust the parameters of the Batch Normalization layer in the pre-trained feature extractor network, to explicitly transfer knowledge from base classes to novel classes according to the support samples of each task. Extensive experiments conducted on multiple benchmark datasets demonstrate that our method can significantly outperform many state-of-the-art few-shot learning methods.},
  archive      = {J_PR},
  author       = {Xiaowei Zhao and Duorui Wang and Shihao Bai and Shuo Wang and Yajun Gao and Yu Liang and Yuqing Ma and Xianglong Liu},
  doi          = {10.1016/j.patcog.2025.111415},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111415},
  shortjournal = {Pattern Recognition},
  title        = {Inversed pyramid network with spatial-adapted and task-oriented tuning for few-shot learning},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ras---12">RAS - 12</h2>
<ul>
<li><details>
<summary>
(2025). Development of a soft gripper for replicating human grasps
in forest nursery tasks. <em>RAS</em>, <em>189</em>, 104987. (<a
href="https://doi.org/10.1016/j.robot.2025.104987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research aims to automate labour-intensive tasks in forest nurseries by developing a soft gripper that mimics human workers&#39; grasps to perform the singulation and sorting of tree saplings. By analysing human workers and conducting experimental investigations, the required grasp types and grip forces were identified. The Fin Ray Effect (FRE) structure, noted for its adaptability to asymmetric shapes, was chosen as the gripper&#39;s basis. However, modifications were necessary to achieve the required power and pinch grasp types and to provide the desired grip forces. Simulation analysis explored various beam configurations and boundary conditions of FRE fingers, resulting in a proposed modified design. Experimental investigations confirmed that the proposed gripper effectively delivered required grasps and grip forces. The new design enabled three additional grasp types for FRE grippers and increased grip forces by over 200 %. This gripper design is suitable for industrial pick-and-place applications where precise pinching grasp and various power grasps with sufficient payload capacity are needed.},
  archive      = {J_RAS},
  author       = {Mohammad Sheikh Sofla and Hanita Golshanian and Elizabeth I. Sklar and Marcello Calisti},
  doi          = {10.1016/j.robot.2025.104987},
  journal      = {Robotics and Autonomous Systems},
  month        = {7},
  pages        = {104987},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Development of a soft gripper for replicating human grasps in forest nursery tasks},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online optimization enhanced closed-loop control of
multi-section continuum robots. <em>RAS</em>, <em>189</em>, 104986. (<a
href="https://doi.org/10.1016/j.robot.2025.104986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the inherent characteristics of continuum robots (high flexibility, multiple degrees of freedom), controlling the continuum robots safely and precisely in practical applications has always been a challenging task. In this paper,a real-time kinematic closed-loop controller that optimizes the step length to boost control performance is proposed. Initially, a differential-based generalized inverse kinematics solution is formulated to resolve the DOF coupling in twin-pivot continuum robots that intertwined two DOFs in one joint. Subsequently, an adaptive online optimization strategy utilizing the algorithm of Particle Swarm Optimization (PSO) is proposed to refine the controller, overcoming the limitations of traditional Jacobian-based approaches. This novel method innovatively decouples control direction and step length, optimizing safety and efficiency. Comparative simulations and tracking tests confirm the controller&#39;s superior precision and efficiency, with an average accuracy of 0.33 %, a 35 % enhancement over the Jacobian controller, thus facilitating the broader application of multi-section continuum robots.},
  archive      = {J_RAS},
  author       = {Laihao Yang and Yi Zheng and Yu Sun and Xuefeng Chen},
  doi          = {10.1016/j.robot.2025.104986},
  journal      = {Robotics and Autonomous Systems},
  month        = {7},
  pages        = {104986},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Online optimization enhanced closed-loop control of multi-section continuum robots},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Resilient nonlinear model predictive control for
formation-containment of multi-mobile robot systems. <em>RAS</em>,
<em>189</em>, 104983. (<a
href="https://doi.org/10.1016/j.robot.2025.104983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on resilient nonlinear model predictive control (NMPC) for the formation containment of multiple nonholonomic mobile robots in the presence of Denial-of-Service (DoS) attacks. The proposed strategy addresses obstacle and collision avoidance between agents by defining a safe circular region for each agent. The scenario-based cost function of NMPC encompasses terms dedicated to achieving the desired formation by leaders, converging the states of followers to the convex hull spanned by leaders, and minimizing control efforts. Utilizing an acknowledgment-based packet transmission strategy, coupled with a buffer mechanism on the actuator side, alleviates the impact of control signal absence during DoS attacks on the controller-to-actuator (C-A) channel. As a Lyapunov-based approach, the contractive constraint in MPC is employed to establish the stability of Multi-Robot Systems (MRS) throughout the mission. A search and rescue application, utilized as a simulation case study, verifies the proposed method’s usefulness and efficiency. Moreover, In the evaluation of real-time implementation, the proposed scheme was validated through a laboratory-based experiment involving a customized mobile robot and low-cost hardware-in-the-loop (HIL) agents based on Raspberry Pi.},
  archive      = {J_RAS},
  author       = {Alireza Kazemi and Iman Sharifi},
  doi          = {10.1016/j.robot.2025.104983},
  journal      = {Robotics and Autonomous Systems},
  month        = {7},
  pages        = {104983},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Resilient nonlinear model predictive control for formation-containment of multi-mobile robot systems},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal path planning for unmanned aerial vehicles with
multiple round-trip flights in coverage tasks. <em>RAS</em>,
<em>189</em>, 104970. (<a
href="https://doi.org/10.1016/j.robot.2025.104970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As high-tech equipment for rescue and relief, unmanned aerial vehicles (UAVs) are widely used in remote relief operations during disasters, significantly improving the efficiency of rescue efforts. However, one significant challenge of UAVs is the limitation of their onboard battery, which prohibits them from completing coverage tasks in a single journey, requiring multiple round-trip flights and frequent battery charging or replacement. As a result, it will greatly prolong the task time. To improve the efficiency of coverage tasks, we allocate task points reasonably to minimize the coverage rounds, and carry out path planning to optimize the travel time of each UAV. This study first formulates a path planning model with the optimization objective of minimizing the overall task time. Then, a task allocation strategy is designed based on the priority of task points, including a max-weight allocation scheme for special scenarios with absolute priority rules and a min-delay allocation scheme for general scenarios with relative priority rules. To optimize the paths of UAVs, we further develop an improved beetle antennae search algorithm based on mutation operations (MBAS). The performance of the developed integrated methods is finally tested through simulation, yielding good results. Source code of the algorithm can be found at https://github.com/lijing0966/MBAS.git .},
  archive      = {J_RAS},
  author       = {Jing Li and Yonghua Xiong and Jinhua She and Anjun Yu},
  doi          = {10.1016/j.robot.2025.104970},
  journal      = {Robotics and Autonomous Systems},
  month        = {7},
  pages        = {104970},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Optimal path planning for unmanned aerial vehicles with multiple round-trip flights in coverage tasks},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive bézier curve-based path following control for
autonomous driving robots. <em>RAS</em>, <em>189</em>, 104969. (<a
href="https://doi.org/10.1016/j.robot.2025.104969">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a concise and efficient path-following strategy, along with a set of real robot experiments to evaluate its superior performance. The following trajectory is generated in the form of a quartic Bézier curve with an adaptive control point generation method based on the integral length and curvature of the reference path. An impressive merit is that the cutting-corner problem during sharp turns can be avoided and smooth speed regulation can be achieved automatically. Another advantage is that the robot can quickly return to the reference path from a large lateral position or heading deviation, without any large space requirement for adjustment. The first few commands derived from the differentiation of the following trajectory are utilized. Simulation results show that the proposed method has a higher accuracy under the same-level computation time compared with other simple geometric methods . Real-world robot experiments are conducted in various environments to verify the proposed algorithm&#39;s accuracy, robustness, and flexibility. The average path-following error of real-world experiments is under 0.1 m, even with sudden path changing for obstacle avoidance. Additionally, with the proposed algorithm, the robot can navigate safely in a residential community where frequent pedestrian incursions occur.},
  archive      = {J_RAS},
  author       = {Li An and Xiuwei Huang and Peng Yang and Zhen Liu},
  doi          = {10.1016/j.robot.2025.104969},
  journal      = {Robotics and Autonomous Systems},
  month        = {7},
  pages        = {104969},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Adaptive bézier curve-based path following control for autonomous driving robots},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model predictive variable impedance control towards safe
robotic interaction in unknown disturbance-rich environments.
<em>RAS</em>, <em>189</em>, 104961. (<a
href="https://doi.org/10.1016/j.robot.2025.104961">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic systems have evolved to handle various significant interaction tasks in different environments. Under these conditions, the involvement of humans in the environment drastically complicates such interaction tasks; as the safety of humans should be prioritized while seeking to achieve the desired task aim. It is thus paramount that appropriate developments should be pursued with specific considerations for such safety-performance-balanced interaction tasks on unknown soft environments (e.g., humans). Towards this end, we present an adaptive robust, and passive control scheme based on model predictive control and variable impedance control that addresses this challenge. Under this control scheme, during robotic interaction tasks with complex environments (e.g., humans), the presented development and design incorporate safety thresholds that are carefully satisfied via impedance adaptation, and realized by a safety-related mode-switching mechanism. Once the safety thresholds are satisfied, task performance is then focused on. Additionally, a real-time adaptive robust parameter estimator is designed and utilized to estimate the environment contact model for the model predictive control, and thus this control scheme is robust against disturbances (e.g., which would invariably arise from the inevitable small bounded human motions) during the interaction tasks. Finally, the key safety and performance attainments of the proposed control scheme are verified via experiments. The experiments are conducted on two silicone rubber models and a human arm. These show that the proposed control scheme effectively outperformed various currently available control schemes in these interaction tasks with unknown environment contact models, and bounded but unpredictable environment position shifts, such as in robotic ultrasound scanning applications.},
  archive      = {J_RAS},
  author       = {Junyuan Xue and Wenyu Liang and Yan Wu and Tong Heng Lee},
  doi          = {10.1016/j.robot.2025.104961},
  journal      = {Robotics and Autonomous Systems},
  month        = {7},
  pages        = {104961},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Model predictive variable impedance control towards safe robotic interaction in unknown disturbance-rich environments},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sli-EfficientDet: A slimming and efficient water surface
object detection model. <em>RAS</em>, <em>189</em>, 104960. (<a
href="https://doi.org/10.1016/j.robot.2025.104960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of water surface object detection, deep learning technology has become a mainstream method. Unmanned Surface Vehicles (USVs), which perform precise sensing and measurement tasks on water surfaces, particularly benefit from these advancements. However, for hardware resource-constrained USVs, current detection models still struggle to find a balance between being lightweight and maintaining accuracy. To address this challenge, we first reduce parameters by clipping channels in the backbone network through a dependency graph based pruning method. Additionally, we introduce the Simple Attention Module (SimAM) into the backbone network to derive excellent three-dimensional attention weights without adding additional parameters during computation. Furthermore, we utilize the ghost module to reconstruct the feature fusion network by using simple linear operations to process feature maps, which enhances the network performance in feature extraction while further compressing the model. Experiments show that our model achieves a 15.56 % improvement in mean Average Precision (mAP) while reducing the count of model parameters by 55 % compared to the original EfficientDet-D0 model, and balancing lightweight and accuracy compared to the majority of current models.},
  archive      = {J_RAS},
  author       = {Sai Ma and Zhibin Xie and Changbin Shao and Xin Shu and Peiyu Yan},
  doi          = {10.1016/j.robot.2025.104960},
  journal      = {Robotics and Autonomous Systems},
  month        = {7},
  pages        = {104960},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Sli-EfficientDet: A slimming and efficient water surface object detection model},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A combined learning and optimization framework to transfer
human whole-body loco-manipulation skills to mobile manipulators.
<em>RAS</em>, <em>189</em>, 104958. (<a
href="https://doi.org/10.1016/j.robot.2025.104958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans’ ability to smoothly switch between locomotion and manipulation is a remarkable feature of sensorimotor coordination. Learning and replicating such human-like strategies can lead to the development of more sophisticated robots capable of performing complex whole-body tasks in real-world environments. To this end, this paper proposes a combined learning and optimization framework for transferring human loco-manipulation soft-switching skills to mobile manipulators. The methodology starts with data collection of human demonstrations for locomotion-integrated manipulation tasks through a vision system. Next, the wrist and pelvis motions are mapped to the mobile manipulators’ End-Effector (EE) and mobile base. A kernelized movement primitive algorithm learns the wrist and pelvis trajectories and generalizes them to new desired points according to task requirements. Then, the reference trajectories are sent to a hierarchical quadratic programming controller, where the EE and the mobile base reference trajectories are provided as the first and second priority tasks, respectively, generating the feasible and optimal joint level commands. Locomotion-integrated pick-and-place and door opening tasks have been chosen to validate the proposed approach. After a human demonstrates the two tasks, a mobile manipulator executes them with the same and new settings. The results showed that the proposed approach successfully transfers and generalizes the human loco-manipulation skills to mobile manipulators, even with different geometry.},
  archive      = {J_RAS},
  author       = {Jianzhuang Zhao and Francesco Tassi and Yanlong Huang and Elena De Momi and Arash Ajoudani},
  doi          = {10.1016/j.robot.2025.104958},
  journal      = {Robotics and Autonomous Systems},
  month        = {7},
  pages        = {104958},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A combined learning and optimization framework to transfer human whole-body loco-manipulation skills to mobile manipulators},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A feasibility-driven MPC scheme for robust gait generation
in humanoids. <em>RAS</em>, <em>189</em>, 104957. (<a
href="https://doi.org/10.1016/j.robot.2025.104957">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a Robust Intrinsically Stable Model Predictive Control (RIS-MPC) framework for humanoid gait generation, which realizes as closely as possible a predefined sequence of footsteps in the presence of both persistent and impulsive perturbations. The MPC-based controller has two modes of operations, each involving a Quadratic Program. Since perturbations act by modifying the state, as well as the feasibility region itself, the fundamental idea is to select in real time the operation mode based on the feasibility properties of the current state. In standard mode , footsteps are regarded as fixed and the MPC computes a Center of Mass (CoM) and a Zero Moment Point (ZMP) trajectory. Robustness is ensured by a robust stability constraint which uses a disturbance estimate and by restricted ZMP constraints along the control horizon. In the presence of strong perturbations, that violate the aforementioned conditions, the system switches to recovery mode , in which footsteps positions and timings can be modified in order to recover feasibility. We analyze the feasibility of both modes of operation and provide conditions for recursive feasibility of the standard mode. Simulations on an HRP-4 robot as well as experiments on NAO and OP3 are provided to validate the scheme.},
  archive      = {J_RAS},
  author       = {Nicola Scianca and Filippo M. Smaldone and Leonardo Lanari and Giuseppe Oriolo},
  doi          = {10.1016/j.robot.2025.104957},
  journal      = {Robotics and Autonomous Systems},
  month        = {7},
  pages        = {104957},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A feasibility-driven MPC scheme for robust gait generation in humanoids},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning-based optimal formation control of
multiple robotic rollers in cooperative rolling compaction.
<em>RAS</em>, <em>189</em>, 104947. (<a
href="https://doi.org/10.1016/j.robot.2025.104947">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the sake of enhancing the rolling compaction quality and operation efficiency in infrastructure construction, this paper addresses the issue of optimal formation control for cooperative rolling compaction of a group of robotic rollers (RRs) by a combination of the reinforcement learning (RL)-based tracking control technique and the virtual structure method. The RR’s kinematic model is first established by fully considering the structural characteristics of the active revolute joint. Via the kinematic model and the virtual structure method, formation control of multiple RRs is formulated as path-following control with respect to their corresponding node in the desired rolling compaction formation shape. Then, optimal formation control policies of RRs are derived by the value functional that is the solution to tracking Hamilton–Jacobi-Bellman equation. By resorting to the RL-based tracking control, approximate optimal control policies are obtained by forward-in-time online neural network estimation of the value functional. Locally uniform ultimate boundedness of the closed-loop formation error system is analyzed rigorously by the Lyapunov technique. Finally, numerical simulation results are presented for three-RR cooperative rolling compaction of a clay core wall dam in Qianping reservoir to show the effectiveness of the main results of this paper.},
  archive      = {J_RAS},
  author       = {Yong-Hang Wei and Jun-Wei Wang and Qinglong Zhang},
  doi          = {10.1016/j.robot.2025.104947},
  journal      = {Robotics and Autonomous Systems},
  month        = {7},
  pages        = {104947},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Reinforcement learning-based optimal formation control of multiple robotic rollers in cooperative rolling compaction},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A task and motion planning framework using iteratively
deepened AND/OR graph networks. <em>RAS</em>, <em>189</em>, 104943. (<a
href="https://doi.org/10.1016/j.robot.2025.104943">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present an approach for integrated task and motion planning based on an AND/OR graph network, which is used to represent task-level states and actions, and we leverage it to implement different classes of task and motion planning problems (TAMP). Several problems that fall under task and motion planning do not have a predetermined number of sub-tasks to achieve a goal. For example, while retrieving a target object from a cluttered workspace, in principle the number of object re-arrangements required to finally grasp it cannot be known ahead of time. To address this challenge, and in contrast to traditional planners, also those based on AND/OR graphs, we grow the AND/OR graph at run-time by progressively adding sub-graphs until grasping the target object becomes feasible, which yields a network of AND/OR graphs. The approach is extended to enable multi-robot task and motion planning, and (i) it allows us to perform task allocation while coordinating the activity of a given number of robots, and (ii) can handle multi-robot tasks involving an a priori unknown number of sub-tasks. The approach is evaluated and validated both in simulation and with a real dual-arm robot manipulator, that is, Baxter from Rethink Robotics. In particular, for the single-robot task and motion planning, we validated our approach in three different TAMP domains. Furthermore, we also use three different robots for simulation, namely, Baxter, Franka Emika Panda manipulators, and a PR2 robot. Experiments show that our approach can be readily scaled to scenarios with many objects and robots, and is capable of handling different classes of TAMP problems.},
  archive      = {J_RAS},
  author       = {Hossein Karami and Antony Thomas and Fulvio Mastrogiovanni},
  doi          = {10.1016/j.robot.2025.104943},
  journal      = {Robotics and Autonomous Systems},
  month        = {7},
  pages        = {104943},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A task and motion planning framework using iteratively deepened AND/OR graph networks},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging motion perceptibility and deep reinforcement
learning for visual control of nonholonomic mobile robots. <em>RAS</em>,
<em>189</em>, 104920. (<a
href="https://doi.org/10.1016/j.robot.2025.104920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel deep reinforcement learning framework to tackle the problem of visual servoing of nonholonomic mobile robots. The visual control of nonholonomic mobile robots becomes particularly challenging within the classical paradigm of visual servoing, mainly due to motion and visibility constraints, which makes it impossible to reach a given desired pose for certain configurations without losing essential visual information from the camera field of view. Previous work has demonstrated the effectiveness of deep reinforcement learning in addressing various vision-based robotics tasks. In light of this, we propose a framework that integrates deep recurrent policies, intrinsic motivation, and a novel auxiliary task that leverages the interaction matrix, the core of classical visual servoing approaches, to address the problem of vision-based control of nonholonomic robotic systems. Firstly, we analyze the influence of the nonholonomic constraints on control policy learning. Subsequently, we validate and evaluate our approach in both simulated and real-world environments. Our approach exhibits an emergent control behavior that enables the robot to accurately attain the desired pose while maintaining the desired visual content within the camera’s field of view. The proposed method outperforms the state-of-the-art approaches, demonstrating its effectiveness, robustness, and accuracy.},
  archive      = {J_RAS},
  author       = {Takieddine Soualhi and Nathan Crombez and Alexandre Lombard and Yassine Ruichek and Stéphane Galland},
  doi          = {10.1016/j.robot.2025.104920},
  journal      = {Robotics and Autonomous Systems},
  month        = {7},
  pages        = {104920},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Leveraging motion perceptibility and deep reinforcement learning for visual control of nonholonomic mobile robots},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="spa---13">SPA - 13</h2>
<ul>
<li><details>
<summary>
(2025). A lower bound for pc in range-r bond percolation in four,
five and six dimensions. <em>SPA</em>, <em>185</em>, 104637. (<a
href="https://doi.org/10.1016/j.spa.2025.104637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the range- R bond percolation in d = 4 , 5 , 6 , we obtain a lower bound for the critical probability p c for R large, agreeing with the conjectured asymptotics and thus complementing the corresponding results of Van der Hofstad and Sakai (2005) for d &gt; 6 , and Frei and Perkins (2016), Hong (2023) for d ≤ 3 . The lower bound proof is completed by showing the extinction of the associated SIR epidemic model. To prove the extinction of the SIR epidemics, we introduce a refined model of the branching random walk, called a self-avoiding branching random walk, whose total range dominates that of the SIR epidemic process.},
  archive      = {J_SPA},
  author       = {Jieliang Hong},
  doi          = {10.1016/j.spa.2025.104637},
  journal      = {Stochastic Processes and Their Applications},
  month        = {7},
  pages        = {104637},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {A lower bound for pc in range-R bond percolation in four, five and six dimensions},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Symmetric KL-divergence by stein’s method. <em>SPA</em>,
<em>185</em>, 104635. (<a
href="https://doi.org/10.1016/j.spa.2025.104635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the symmetric KL-divergence between the sum of independent variables and a Gaussian distribution, and obtain a convergence rate of order O ln n n . The proof is based on Stein’s method. The convergence rate of order O 1 n and O 1 n are also obtained under higher moment condition.},
  archive      = {J_SPA},
  author       = {Liu-Quan Yao and Song-Hao Liu},
  doi          = {10.1016/j.spa.2025.104635},
  journal      = {Stochastic Processes and Their Applications},
  month        = {7},
  pages        = {104635},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Symmetric KL-divergence by stein’s method},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergence of the open WASEP stationary measure without
liggett’s condition. <em>SPA</em>, <em>185</em>, 104634. (<a
href="https://doi.org/10.1016/j.spa.2025.104634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We demonstrate that Liggett’s condition can be relaxed without disrupting the convergence of open ASEP stationary measures to the open KPZ stationary measure. This is equivalent to demonstrating that, under weak asymmetry scaling and appropriate scaling of time and space, the four-parameter Askey–Wilson process converges to a two-parameter continuous dual Hahn process. We conjecture that the convergence of the open ASEP height function process to solutions to the open KPZ equation will hold for a wider range of ASEP parameters than those permitted by Liggett’s condition.},
  archive      = {J_SPA},
  author       = {Zoe Himwich},
  doi          = {10.1016/j.spa.2025.104634},
  journal      = {Stochastic Processes and Their Applications},
  month        = {7},
  pages        = {104634},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Convergence of the open WASEP stationary measure without liggett’s condition},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A benamou–brenier formula for transport distances between
stationary random measures. <em>SPA</em>, <em>185</em>, 104633. (<a
href="https://doi.org/10.1016/j.spa.2025.104633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We derive a Benamou–Brenier type dynamical formulation for the Kantorovich–Wasserstein extended metric W p between stationary random measures recently introduced in Erbar et al., (2024). A key step is a reformulation of the extended metric W p using Palm probabilities.},
  archive      = {J_SPA},
  author       = {Martin Huesmann and Bastian Müller},
  doi          = {10.1016/j.spa.2025.104633},
  journal      = {Stochastic Processes and Their Applications},
  month        = {7},
  pages        = {104633},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {A Benamou–Brenier formula for transport distances between stationary random measures},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Partial divisibility of random sets. <em>SPA</em>,
<em>185</em>, 104632. (<a
href="https://doi.org/10.1016/j.spa.2025.104632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we ask the following question: Let V X be the void functional of a random closed set X . For which α &gt; 0 is V X α a void functional? We answer this question when X is a random subset of a finite set. The result is then generalized to exponents which preserve complete monotonicity of functions on finite lattices. Also, we study the question of approximating an m -divisible random set by infinitely divisible random sets. We prove a theorem analogous to that of Arak’s classical result (Arak, 1981, 1982) on approximating an m -divisible random variable by infinitely divisible random variables.},
  archive      = {J_SPA},
  author       = {Jnaneshwar Baslingker and Biltu Dan},
  doi          = {10.1016/j.spa.2025.104632},
  journal      = {Stochastic Processes and Their Applications},
  month        = {7},
  pages        = {104632},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Partial divisibility of random sets},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Asymptotics for irregularly observed long memory processes.
<em>SPA</em>, <em>185</em>, 104631. (<a
href="https://doi.org/10.1016/j.spa.2025.104631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the effect of observing a long-memory stationary process at irregular time points via a renewal process. We establish a sharp difference in the asymptotic behaviour of the self-normalized sample mean of the observed process depending on the renewal process. In particular, we show that if the renewal process has a moderate heavy-tail distribution, then the limit is a so-called Normal Variance Mixture (NVM) and we characterize the randomized variance part of the limiting NVM as an integral function of a Lévy stable motion. Otherwise, the normalized sample mean will be asymptotically normal.},
  archive      = {J_SPA},
  author       = {Mohamedou Ould Haye and Anne Philippe},
  doi          = {10.1016/j.spa.2025.104631},
  journal      = {Stochastic Processes and Their Applications},
  month        = {7},
  pages        = {104631},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Asymptotics for irregularly observed long memory processes},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On a class of exponential changes of measure for stochastic
PDEs. <em>SPA</em>, <em>185</em>, 104630. (<a
href="https://doi.org/10.1016/j.spa.2025.104630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a mild solution X to a semilinear stochastic partial differential equation (SPDE), we consider an exponential change of measure based on its infinitesimal generator L , defined in the topology of bounded pointwise convergence. The changed measure P h depends on the choice of a function h in the domain of L . In our main result, we derive conditions on h for which the change of measure is of Girsanov-type. The process X under P h is then shown to be a mild solution to another SPDE with an extra additive drift-term. We illustrate how different choices of h impact the law of X under P h in selected applications. These include the derivation of an infinite-dimensional diffusion bridge as well as the introduction of guided processes for SPDEs, generalizing results known for finite-dimensional diffusion processes to the infinite-dimensional case.},
  archive      = {J_SPA},
  author       = {Thorben Pieper-Sethmacher and Frank van der Meulen and Aad van der Vaart},
  doi          = {10.1016/j.spa.2025.104630},
  journal      = {Stochastic Processes and Their Applications},
  month        = {7},
  pages        = {104630},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {On a class of exponential changes of measure for stochastic PDEs},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Preventing finite-time blowup in a constrained potential for
reaction–diffusion equations. <em>SPA</em>, <em>185</em>, 104627. (<a
href="https://doi.org/10.1016/j.spa.2025.104627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We examine stochastic reaction–diffusion equations of the form ∂ u ∂ t = A u ( t , x ) + f ( u ( t , x ) ) + σ ( u ( t , x ) ) W ̇ ( t , x ) on a bounded spatial domain D ⊂ R d , where f models a constrained, dissipative force that keeps solutions between − 1 and 1. To model this, we assume that f ( u ) , σ ( u ) are unbounded as u approaches ± 1 . We identify sufficient conditions on the growth rates of f and σ that guarantee solutions to not escape this bounded set.},
  archive      = {J_SPA},
  author       = {John Ivanhoe and Michael Salins},
  doi          = {10.1016/j.spa.2025.104627},
  journal      = {Stochastic Processes and Their Applications},
  month        = {7},
  pages        = {104627},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Preventing finite-time blowup in a constrained potential for reaction–diffusion equations},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Expected hitting time estimates on finite graphs.
<em>SPA</em>, <em>185</em>, 104626. (<a
href="https://doi.org/10.1016/j.spa.2025.104626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The expected hitting time from vertex a to vertex b , H ( a , b ) , is the expected value of the time it takes a random walk starting at a to reach b . In this paper, we give estimates for H ( a , b ) when the distance between a and b is comparable to the diameter of the graph, and the graph satisfies a Harnack condition. We show that, in such cases, H ( a , b ) can be estimated in terms of the volumes of balls around b . Using our results, we estimate H ( a , b ) on various graphs, such as rectangular tori, some convex traces in Z d , and fractal graphs. Our proofs use heat kernel estimates.},
  archive      = {J_SPA},
  author       = {Laurent Saloff-Coste and Yuwen Wang},
  doi          = {10.1016/j.spa.2025.104626},
  journal      = {Stochastic Processes and Their Applications},
  month        = {7},
  pages        = {104626},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Expected hitting time estimates on finite graphs},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On strong solutions of time inhomogeneous itô’s equations
with morrey diffusion gradient and drift. A supercritical case.
<em>SPA</em>, <em>185</em>, 104619. (<a
href="https://doi.org/10.1016/j.spa.2025.104619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove the existence of strong solutions of Itô’s stochastic time dependent equations with irregular diffusion and drift terms of Morrey spaces. Strong uniqueness is also discussed. The results are new even if there is no drift.},
  archive      = {J_SPA},
  author       = {N.V. Krylov},
  doi          = {10.1016/j.spa.2025.104619},
  journal      = {Stochastic Processes and Their Applications},
  month        = {7},
  pages        = {104619},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {On strong solutions of time inhomogeneous itô’s equations with morrey diffusion gradient and drift. a supercritical case},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Averaging principle for slow–fast systems of stochastic PDEs
with rough coefficients. <em>SPA</em>, <em>185</em>, 104618. (<a
href="https://doi.org/10.1016/j.spa.2025.104618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines a class of slow–fast systems of stochastic partial differential equations in which the nonlinearity in the slow equation is unbounded and discontinuous. We establish conditions that guarantee the existence of a martingale solution, and we demonstrate that the laws of the slow motions are tight, with any of their limiting points serving as a martingale solution for an appropriate averaged equation. Our findings have particular relevance for systems of stochastic reaction–diffusion equations, where the reaction term in the slow equation is only continuous and has arbitrary polynomial growth.},
  archive      = {J_SPA},
  author       = {Sandra Cerrai and Yichun Zhu},
  doi          = {10.1016/j.spa.2025.104618},
  journal      = {Stochastic Processes and Their Applications},
  month        = {7},
  pages        = {104618},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Averaging principle for slow–fast systems of stochastic PDEs with rough coefficients},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fluctuations of omega-killed level-dependent spectrally
negative lévy processes. <em>SPA</em>, <em>185</em>, 104617. (<a
href="https://doi.org/10.1016/j.spa.2025.104617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we solve exit problems for a level-dependent Lévy process which is exponentially killed with a killing intensity that depends on the present state of the process. Moreover, we analyse the respective resolvents. All identities are given in terms of new generalisations of scale functions (counterparts of the scale function from the theory of Lévy processes), which are solutions of Volterra integral equations. Furthermore, we obtain similar results for the reflected level-dependent Lévy processes. The existence of the solution of the stochastic differential equation for reflected level-dependent Lévy processes is also discussed. Finally, to illustrate our result, the probability of bankruptcy is obtained for an insurance risk process.},
  archive      = {J_SPA},
  author       = {Zbigniew Palmowski and Meral Şimşek and Apostolos D. Papaioannou},
  doi          = {10.1016/j.spa.2025.104617},
  journal      = {Stochastic Processes and Their Applications},
  month        = {7},
  pages        = {104617},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Fluctuations of omega-killed level-dependent spectrally negative lévy processes},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intersections of poisson k-flats in hyperbolic space:
Completing the picture. <em>SPA</em>, <em>185</em>, 104613. (<a
href="https://doi.org/10.1016/j.spa.2025.104613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let η be an isometry invariant Poisson process of k -flats, 0 ≤ k ≤ d − 1 , in d -dimensional hyperbolic space. For d − m ( d − k ) ≥ 0 , the m -th order intersection process of η consists of all nonempty intersections of distinct flats E 1 , … , E m ∈ η . Of particular interest is the total volume F r ( m ) of this intersection process in a ball of radius r . For 2 k &gt; d + 1 , we determine the asymptotic distribution of F r ( m ) , as r → ∞ , previously known only for m = 1 , and derive rates of convergence in the Kolmogorov distance. Properties of the non-Gaussian limit distribution are discussed. We further study the asymptotic covariance matrix of the vector ( F r ( 1 ) , … , F r ( m ) ) ⊤ .},
  archive      = {J_SPA},
  author       = {Tillmann Bühler and Daniel Hug},
  doi          = {10.1016/j.spa.2025.104613},
  journal      = {Stochastic Processes and Their Applications},
  month        = {7},
  pages        = {104613},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Intersections of poisson k-flats in hyperbolic space: Completing the picture},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="swevo---51">SWEVO - 51</h2>
<ul>
<li><details>
<summary>
(2025). An improved NSGA-II algorithm based on reinforcement
learning for aircraft moving assembly line integration optimization
problem. <em>SWEVO</em>, <em>94</em>, 101911. (<a
href="https://doi.org/10.1016/j.swevo.2025.101911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the aircraft moving assembly line, the focus of the assembly line balancing problem is to balance the workload in each workstation, the scheduling of aircraft assembly lines must consider the parallel relationship between assembly tasks and meet supply constraints. The aircraft moving assembly line integration optimization problem integrates the aircraft assembly line balancing problem with the aircraft assembly line scheduling problem to enhance aircraft assembly efficiency. The decision involves allocating all assembly tasks to a given number of workstations, auxiliary decisions pertain to determining the start times for assembly operations and the number of operators required. The objective is to minimize the cycle time and smoothness of the assembly line while ensuring that the number of workers on the assembly line is minimized. An integer linear programming model has been established to solve the aircraft moving assembly line integration optimization problem, and a new decoding method has been designed for this problem. A Bayesian reinforcement learning-improved NSGA-II algorithm (RLINSGA-II) has been proposed. After non-dominated sorting, the population is hierarchically divided, and a selection strategy is established among individuals of different levels. Through Bayesian reinforcement learning formulas, the selection strategy undergoes continuous adjustment throughout the population iteration process, thereby enhancing the quality of offspring individuals produced by the crossover operator. Finally, five test cases of different scales were designed based on actual cases, and the proposed RLINSGA-II was compared with five multi-objective optimization algorithms. Computational experiments and a real case study reveal the superiority of our proposed approach.},
  archive      = {J_SWEVO},
  author       = {Xiaoyu Wen and Xinyu Zhang and Hao Li and Shuo Ji and Haoqi Wang and Guoyong Ye and Hongwen Xing and Siren Liu},
  doi          = {10.1016/j.swevo.2025.101911},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101911},
  shortjournal = {Swarm Evol. Comput.},
  title        = {An improved NSGA-II algorithm based on reinforcement learning for aircraft moving assembly line integration optimization problem},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel deep self-learning method for flexible job-shop
scheduling problems with multiplicity: Deep reinforcement learning
assisted the fluid master-apprentice evolutionary algorithm.
<em>SWEVO</em>, <em>94</em>, 101907. (<a
href="https://doi.org/10.1016/j.swevo.2025.101907">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s dynamic environment, companies must navigate highly competitive markets. They consistently need to implement new technologies and deliver the right product at the right time in response to customer demand. This necessitates a high level of adaptability and efficiency in their manufacturing processes. Flexible job-shops offer a more efficient alternative to traditional manufacturing practices by accommodating these needs. Additionally, in actual manufacturing plants, multiple jobs are typically required for each part type. To address this complexity, this article investigates the flexible job-shop scheduling problem with multiplicity (MFJSP). We propose a deep self-learning method based on deep reinforcement learning and fluid master-apprentice evolutionary algorithm (DSLFMAE) to minimize makespan for the MFJSP. The proposed DSLFMAE is the integration of a fluid master-apprentice evolutionary (FMAE) algorithm and a proximal policy optimization (PPO) algorithm. The FMAE algorithm serves as the core optimization method, employing the PPO algorithm to dynamically adjust the control parameters of the FMAE algorithm during the optimization process. Twelve state features are extracted to capture the evolutionary states of the FMAE algorithm accurately, and a long short-term memory Q-network (LSTM-Q) is designed to encode these continuous states. Subsequently, to adjust multiple interrelated control parameters of the FMAE algorithm simultaneously, a multivariate Gaussian distribution-based PPO algorithm is developed to train the LSTM-Q network. Numerical outcomes show the efficacy and superiority of the DSLFMAE in addressing the flexible job-shop scheduling problem with multiplicity (MFJSP) across different scales.},
  archive      = {J_SWEVO},
  author       = {Linshan Ding and Dan Luo and Rauf Mudassar and Lei Yue and Leilei Meng},
  doi          = {10.1016/j.swevo.2025.101907},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101907},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A novel deep self-learning method for flexible job-shop scheduling problems with multiplicity: Deep reinforcement learning assisted the fluid master-apprentice evolutionary algorithm},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Un-evaluated solutions may be valuable in expensive
optimization. <em>SWEVO</em>, <em>94</em>, 101905. (<a
href="https://doi.org/10.1016/j.swevo.2025.101905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Expensive optimization problems (EOPs) are prevalent in real-world applications, where the evaluation of a single solution requires a significant amount of resources. In our study of surrogate-assisted evolutionary algorithms (SAEAs) in EOPs, we discovered an intriguing phenomenon. Because only a limited number of solutions are evaluated in each iteration, relying solely on these evaluated solutions for evolution can lead to reduced disparity in successive populations. This, in turn, hampers the reproduction operators’ ability to generate superior solutions, thereby reducing the algorithm’s convergence speed. To address this issue, we propose a strategic approach that incorporates high-quality, un-evaluated solutions predicted by surrogate models during the selection phase. This approach aims to improve the distribution of evaluated solutions, thereby generating a superior next generation of solutions. This work details specific implementations of this concept across various reproduction operators and validates its effectiveness using multiple surrogate models. Experimental results demonstrate that the proposed strategy significantly enhances the performance of surrogate-assisted evolutionary algorithms. Compared to mainstream SAEAs and Bayesian optimization algorithms, our approach incorporating the un-evaluated solution strategy shows a marked improvement.},
  archive      = {J_SWEVO},
  author       = {Hao Hao and Xiaoqun Zhang and Aimin Zhou},
  doi          = {10.1016/j.swevo.2025.101905},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101905},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Un-evaluated solutions may be valuable in expensive optimization},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical multi-objective optimization for precise
performance design of closed-chain legged mechanisms. <em>SWEVO</em>,
<em>94</em>, 101904. (<a
href="https://doi.org/10.1016/j.swevo.2025.101904">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decades, the performance design of closed-chain legged mechanisms (CLMs) has not been adequately addressed. Most existing design methodologies have predominantly relied on trajectory synthesis, which inadvertently prioritizes less critical performance aspects. This study proposes a hierarchical multi-objective optimization strategy to address this limitation. First, the numerical performance-trajectory mapping is derived based on a foot-ground contact model, aiming to decouple the performance characteristics. Subsequently, a hierarchical optimization strategy is employed for two types of CLM design scenarios: In trajectory shape-constrained scenarios, a coarse-to-fine optimization process, integrating Fourier descriptors, refines the design from overall shape to local features. In scenarios without trajectory shape constraints, a stepwise optimization process is proposed for reconfigurable CLMs to transition from primary motion to auxiliary motion. The robustness of the proposed design strategy is validated across three configurations and seven algorithms. The effectiveness of the proposed design strategy is verified by comparison with other existing CLM design methods. The applicability of the proposed strategy is confirmed through simulation and prototype experiments. The results demonstrate that the hierarchical strategy effectively addresses the challenges of precise performance design in CLMs. Our work provides a general framework for the CLM design and offers insights for the optimization design of other closed-chain linkages.},
  archive      = {J_SWEVO},
  author       = {Long Guo and Ying Zhang and Qi Qin and Guanjun Liu and Hanyu Chen and Yan-an Yao},
  doi          = {10.1016/j.swevo.2025.101904},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101904},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Hierarchical multi-objective optimization for precise performance design of closed-chain legged mechanisms},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constrained multi-objective evolutionary algorithm based on
the correlation between objectives and constraints. <em>SWEVO</em>,
<em>94</em>, 101903. (<a
href="https://doi.org/10.1016/j.swevo.2025.101903">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many engineering optimization problems require simultaneous optimization of multiple objective functions under certain constraints, which are collectively referred to as constrained multi-objective problems (CMOPs). The crucial issue in solving CMOPs is to balance constraints and objectives. This paper proposes a constrained multi-objective evolutionary algorithm based on the correlation between objectives and constraints, termed CORCMO. CORCMO mainly comprises two stages: the learning stage and the evolving stage. The learning stage focuses on analyzing the correlation between each objective and constraints. In the evolving stage, the CMOP is decomposed into M constraint single-objective problems, which are optimized by M subpopulations cooperatively. For each subproblem, the corresponding fitness function, computed based on the correlation, is adopted to guide the evolution. Subsequently, CORCMO employs archive population update strategy to find the optimal solutions of the given CMOP. Experiments conducted on a series of benchmark problems demonstrate that CORCMO is promising to solve CMOPs.},
  archive      = {J_SWEVO},
  author       = {Jianxia Li and Ruochen Liu and Xilong Zhang and Ruinan Wang},
  doi          = {10.1016/j.swevo.2025.101903},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101903},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Constrained multi-objective evolutionary algorithm based on the correlation between objectives and constraints},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed heterogeneous flexible job-shop scheduling
problem considering automated guided vehicle transportation via improved
deep q network. <em>SWEVO</em>, <em>94</em>, 101902. (<a
href="https://doi.org/10.1016/j.swevo.2025.101902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed manufacturing has become a research hotspot in the context of economic globalization. The distributed heterogeneous flexible job-shop scheduling problem considering automated guided vehicle transportation (DHFJSP-AGV) extends the classic flexible job-shop scheduling problem (FJSP) but remains underexplored. DHFJSP-AGV involves four subproblems: assigning jobs to heterogeneous factories, scheduling jobs to machines, sequencing operations on machines and transporting jobs between machines using AGVs. Due to its complexity, this study proposes an improved deep Q network (DQN) real-time scheduling method aimed at minimizing makespan. A mixed integer linear programming model (MILP) of DHFJSP-AGV is developed and transformed into a Markov decision process (MDP). Eight general state features are extracted and normalized to represent the state space, while appropriate combination dispatching rules are selected as the action space. The state features of each scheduling point are input to the DQN, determining the factory, job, machine, and AGV for each process. Additionally, double DQN and an improved ε-greedy exploration are used to enhance the DQN. Numerical comparison experiments under different production configurations and real-world application in distributed flexible job-shop with dynamic map environment demonstrate the effectiveness and generalization capabilities of improved DQN.},
  archive      = {J_SWEVO},
  author       = {Minghai Yuan and Songwei Lu and Liang Zheng and Qi Yu and Fengque Pei and Wenbin Gu},
  doi          = {10.1016/j.swevo.2025.101902},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101902},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Distributed heterogeneous flexible job-shop scheduling problem considering automated guided vehicle transportation via improved deep q network},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A learning-based dual-population optimization algorithm for
hybrid seru system scheduling with assembly. <em>SWEVO</em>,
<em>94</em>, 101901. (<a
href="https://doi.org/10.1016/j.swevo.2025.101901">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the personalized demand increases, the hybrid seru system (HSS) has emerged as an efficient production paradigm to address the volatile market and intricate production conditions due to its reconfigurability. To satisfy the actual production demands, it is common to consider multiple assembly stages in the HSS. However, the increasing complexity poses challenges for the design of scheduling optimization algorithms. In this paper, a learning-based dual-population optimization algorithm (LDPOA) is designed for the hybrid seru system scheduling problem with assembly. Based on a problem-specific decomposition paradigm, a dual-population cooperative search framework is proposed to enhance the exploration capability by focusing on different subproblem optimizations in different populations. During the evolution, a fusion strategy and filtering mechanism are designed to avoid invalid searches by allocating computing resources to more potential individuals. A learning-guided search mode selection strategy and a population communication strategy are proposed to further improve search efficiency and population diversity. Finally, the adjustment strategies are proposed to improve the solution quality by leveraging problem knowledge. Extensive experiments are conducted to assess the performance of the LDPOA. The comparisons show that the HSS can improve production efficiency by 35.3 % compared to the traditional manufacturing mode.},
  archive      = {J_SWEVO},
  author       = {Yuting Wu and Ling Wang and Rui Li and Yuxiang Xu and Jie Zheng},
  doi          = {10.1016/j.swevo.2025.101901},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101901},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A learning-based dual-population optimization algorithm for hybrid seru system scheduling with assembly},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parking vehicle-assisted task offloading in edge computing:
A dynamic multi-objective evolutionary algorithm with multi-strategy
fusion response. <em>SWEVO</em>, <em>94</em>, 101900. (<a
href="https://doi.org/10.1016/j.swevo.2025.101900">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle-edge computing, as a promising paradigm, is employed to support applications that require low latency and high computational capability. In this study, we consider the idle resources of the surrounding parked vehicles (PVs) and roadside units (RSUs) as service providers to enhance the performance of User Equipment (UE). We propose a joint offloading architecture that uses parked vehicles. Additionally, owing to the dynamic and uncertain nature of the environment, we model computation offloading as a dynamic multi-objective optimization problem to simultaneously optimize the latency and energy consumption of UE applications. In this study, we propose a dynamic multi-objective evolutionary algorithm with a multi-strategy fusion response (DMOEA/D-MSFR). Specifically, we introduce a population center positioning strategy and a learnable prediction mechanism using Long Short-Term Memory (LSTM) in DMOEA-MSFR, which divides the prediction optimization process into two stages and exhibits a rapid response to environmental changes. In the static optimization phase, an adaptive weight vector adjustment strategy is employed, which significantly aids in the distribution and diversity of the solutions. Comprehensive experiments demonstrate that our proposed framework balances the trade-off between latency and energy consumption, and the convergence, feasibility, and diversity of the non-dominated solutions obtained.},
  archive      = {J_SWEVO},
  author       = {Yingbo Zhou and Zheng-Yi Chai and Ya-Lun Li and Jun-Jie Li},
  doi          = {10.1016/j.swevo.2025.101900},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101900},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Parking vehicle-assisted task offloading in edge computing: A dynamic multi-objective evolutionary algorithm with multi-strategy fusion response},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A high-dimensional feature selection algorithm via fast
dimensionality reduction and multi-objective differential evolution.
<em>SWEVO</em>, <em>94</em>, 101899. (<a
href="https://doi.org/10.1016/j.swevo.2025.101899">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-objective feature selection problem typically involves two key objectives: minimizing the number of selected features and maximizing classification performance. However, most multi-objective evolutionary algorithms (MOEAs) face challenges in high-dimensional datasets, including low search efficiency and potential loss of search space. To address these challenges, this paper proposes a hybrid algorithm based on fast dimensionality reduction and multi-objective differential evolution with redundant and preference processing (termed DR-RPMODE). In DR-RPMODE, the DR phase uses the freezing and activation operators to remove many irrelevant and redundant features in the high-dimensional datasets, thereby achieving fast dimensionality reduction. Subsequently, the RPMODE algorithm continues the search on the reduced datasets, improving the traditional differential evolutionary framework from two aspects: duplicated and redundant solutions are filtered by redundant handling, and a preference handling method that pays more attention to classification performance is designed for different preference objectives of decision-makers. In the experiment, DR-RPMODE is compared with seven feature selection algorithms on 16 classification datasets. The results indicate that DR-RPMODE outperforms the comparison algorithms on most datasets, demonstrating that it not only achieves outstanding optimization performance but also obtains good classification and scalability results.},
  archive      = {J_SWEVO},
  author       = {Xuezhi Yue and Yihang Liao and Hu Peng and Lanlan Kang and Yuan Zeng},
  doi          = {10.1016/j.swevo.2025.101899},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101899},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A high-dimensional feature selection algorithm via fast dimensionality reduction and multi-objective differential evolution},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A heuristic distributed and no-wait method for solving
multiagent task allocation problems with coupled temporal constraints.
<em>SWEVO</em>, <em>94</em>, 101898. (<a
href="https://doi.org/10.1016/j.swevo.2025.101898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal constraints, primarily arising from engagement rules and requiring tasks to be performed in a specific order, are critical in task allocation problems (TAPs). However, existing allocation methods often fall short of handling temporal constraints. This paper proposes a heuristic distributed and no-wait algorithm, called the Temporal-Constraints Performance Impact (TC-PI) algorithm, for solving multi-agent TAPs with temporal constraints. By requiring each agent either travels to or immediately executes its assigned task, the TC-PI eliminates unnecessary waiting time and effectively reduces the average task completion time . The proposed algorithm consists of three phases. Firstly, each agent sequentially adds tasks to its task list while ensuring temporal constraints are satisfied. Secondly, conflicts where multiple agents select the same task are resolved through local communication. Finally, any remaining conflicts caused by temporal constraints are further addressed. To maintain task order and minimize completion time, task significance is redefined by incorporating temporal relationships among tasks. A penalty mechanism prevents infinite task reallocation cycles, enhancing system robustness and avoiding deadlocks. Simulation results demonstrate that TC-PI effectively resolves temporal conflicts, achieves no-wait task allocations, and flexibly handles dynamic task arrivals.},
  archive      = {J_SWEVO},
  author       = {Wei Cui and Yanxiang Feng and Ye Cao and Xiaoling Li and Yikang Yang},
  doi          = {10.1016/j.swevo.2025.101898},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101898},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A heuristic distributed and no-wait method for solving multiagent task allocation problems with coupled temporal constraints},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A discrete water source cycle algorithm design for solving
production scheduling problem in flexible manufacturing systems.
<em>SWEVO</em>, <em>94</em>, 101897. (<a
href="https://doi.org/10.1016/j.swevo.2025.101897">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at solving the production scheduling problems in flexible manufacturing systems including the flexible job shop scheduling (FJSP) and distributed flexible job shop scheduling (DFJSP) with operation outsourcing, which are two kinds of typical NP-hard problems, the general mathematical model with two optimization objectives including minimizing the total costs as well as makespan are developed. Then, an innovative discrete water source cycle algorithm (IDWCA) inspired by the water cycle process is proposed to address the model. In the IDWCA, the operators including evaporation mixing, precipitation, local mixing, modification of water source composition and water source loss are designed to search for optimization solutions. Finally, 15 FJSP comparison experiments and 45 DFJSP comparison experiments with different scales are provided to verify the comprehensive performance of the IDWCA, in which the IDWCA, the original water cycle algorithm (OWCA), and the two general meta-heuristic algorithms genetic algorithm (GA) and particle swarm optimization (PSO) are involved. Compared with OWCA, GA and PSO, IDWCA performs significantly better in all FJSP experiments, while it performs better in 43 out of 45 DFJSP experiments, and its advantages are more significant in solving the medium-scale and large-scale problems. In addition, the evolutionary curves of the above algorithms indicate that the IDWCA has the better convergence speed and results than that of OWCA, GA and PSO. Therefore, the developed mathematical model and IDWCA are effective in solving the studied FJSP and DFJSP, the proposed algorithm enriches the theoretical researches on meta-heuristic algorithms and production scheduling.},
  archive      = {J_SWEVO},
  author       = {Wenxiang Xu and Shimin Xu and Junyong Liang and Tao Qin and Dezheng Liu and Lei Wang},
  doi          = {10.1016/j.swevo.2025.101897},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101897},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A discrete water source cycle algorithm design for solving production scheduling problem in flexible manufacturing systems},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online feature subset selection for mining feature streams
in big data via incremental learning and evolutionary computation.
<em>SWEVO</em>, <em>94</em>, 101896. (<a
href="https://doi.org/10.1016/j.swevo.2025.101896">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online streaming feature subset selection (OSFSS) presents a noteworthy challenge when data samples arrive rapidly and in a time-dependent manner. The complexity of this problem is further exacerbated when features arrive as a stream. Despite several attempts to solve OSFSS over feature streams, existing methods lack scalability, cannot handle interaction effects among features, and fail to efficiently handle high-velocity feature streams. To address these challenges, we propose a novel wrapper-for OSFSS named OSFSS-W (wrapper-for OSFSS), specifically designed to mine feature streams within the Apache Spark environment. Our proposed method incorporates (i) two vigilance tests: for removing (a) irrelevant features and (b) redundant features (ii) incremental learning and (iii) a tolerance-based feedback mechanism that retains and utilizes previous knowledge while adhering to the predefined tolerance thresholds. Additionally, for the purpose of optimization, we introduce a Bare Bones Particle Swarm Optimization (BBPSO-L) algorithm driven by the logistic distribution. Further, the BBPSO-L is parallelized within Apache Spark, following an island-based approach. We evaluated the performance of the proposed algorithm on the datasets taken from the cybersecurity, bioinformatics, and finance domains. The results demonstrate that incorporating two vigilance tests coupled with a tolerance-based feedback mechanism significantly improved the median Area under the receiver operating characteristic curve (AUC) and median cardinality across all datasets.},
  archive      = {J_SWEVO},
  author       = {Yelleti Vivek and Vadlamani Ravi and P. Radha Krishna},
  doi          = {10.1016/j.swevo.2025.101896},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101896},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Online feature subset selection for mining feature streams in big data via incremental learning and evolutionary computation},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Benchmarking footprints of continuous black-box optimization
algorithms: Explainable insights into algorithm success and failure.
<em>SWEVO</em>, <em>94</em>, 101895. (<a
href="https://doi.org/10.1016/j.swevo.2025.101895">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The practices for comparing black-box optimization algorithms based on performance statistics over a benchmark suite are being increasingly criticized. Critics argue that these practices fail to explain why particular algorithms outperform others. Consequently, there is a growing demand for more robust comparison methods that assess the overall efficiency of the algorithms in terms of performance and also consider the specific landscape properties of the optimization problems on which the algorithms are compared. This study introduces a novel approach for comparing algorithms based on the concept of an algorithm footprint , which aims to identify easy and challenging problem instances for a given algorithm. A unique footprint is assigned to each algorithm and then compared, to highlight problem instances where an algorithm either uniquely succeeds or falls, as well as how the algorithms complement each other across the problem instances. Our solution employs a multi-task regression model (MTR) to simultaneously link the performance of multiple algorithms with the landscape features of the problem instances. By applying an Explainable Machine Learning (XML) technique, we quantify and compare the importance of the landscape features for each algorithm. The methodology is applied to a portfolio of three different BBO algorithms, highlighting their success and failure on the Black-Box Optimization Benchmarking (BBOB) suite. The efficacy of our approach is further demonstrated through a comparative analysis with two existing algorithm comparison methods, showcasing the robustness and depth of insights provided by the proposed approach.},
  archive      = {J_SWEVO},
  author       = {Ana Nikolikj and Mario Andrés Muñoz and Tome Eftimov},
  doi          = {10.1016/j.swevo.2025.101895},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101895},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Benchmarking footprints of continuous black-box optimization algorithms: Explainable insights into algorithm success and failure},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Landscape features in single-objective continuous
optimization: Have we hit a wall in algorithm selection generalization?
<em>SWEVO</em>, <em>94</em>, 101894. (<a
href="https://doi.org/10.1016/j.swevo.2025.101894">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The process of identifying the most suitable optimization algorithm for a specific problem, referred to as algorithm selection (AS), entails training models that leverage problem landscape features to forecast algorithm performance. A significant challenge in this domain is ensuring that AS models can generalize effectively to novel, unseen problems. This study evaluates the generalizability of AS models based on different problem representations in the context of single-objective continuous optimization. In particular, it considers the most widely used Exploratory Landscape Analysis features, as well as recently proposed Topological Landscape Analysis features, and features based on deep learning, such as DeepELA, TransOptAS and Doe2Vec. Our results indicate that when presented with out-of-distribution evaluation data, none of the feature-based AS models outperform a simple baseline model, i.e., a Single Best Solver.},
  archive      = {J_SWEVO},
  author       = {Gjorgjina Cenikj and Gašper Petelin and Moritz Seiler and Nikola Cenikj and Tome Eftimov},
  doi          = {10.1016/j.swevo.2025.101894},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101894},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Landscape features in single-objective continuous optimization: Have we hit a wall in algorithm selection generalization?},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EABC-AS: Elite-driven artificial bee colony algorithm with
adaptive population scaling. <em>SWEVO</em>, <em>94</em>, 101893. (<a
href="https://doi.org/10.1016/j.swevo.2025.101893">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Artificial Bee Colony Algorithm (ABC) is a widely recognized optimization algorithm known for its effectiveness. However, many variants of the ABC algorithm fail to fully leverage the potential of each population, and their inherent random search strategies often limit the algorithm’s convergence capabilities, leading to diminished performance. To address these issues, we introduce an enhanced version of the ABC algorithm, which incorporates two essential features: adaptive population scaling and an elite-driven evolutionary strategy. The adaptive population scaling mechanism dynamically adjusts the population size of each bee colony based on their respective function, and the elite-driven evolutionary strategy with external archive makes bees evolve by utilizing information from elite individuals while ensuring diversity is maintained. These two features enhance the algorithm’s convergence ability. We employ the CEC 2017 and CEC 2022 benchmarks to assess the optimization capabilities of the proposed algorithm. The experimental results indicate that the EABC-AS algorithm displays significant competitiveness relative to CEC excellent algorithms and other state-of-the-art (SOTA) algorithms.},
  archive      = {J_SWEVO},
  author       = {Ruiyang Lin and Zesong Xu and Liyang Yu and Tongquan Wei},
  doi          = {10.1016/j.swevo.2025.101893},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101893},
  shortjournal = {Swarm Evol. Comput.},
  title        = {EABC-AS: Elite-driven artificial bee colony algorithm with adaptive population scaling},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An indicator-based multi-objective evolutionary algorithm
assisted by improved graph convolutional networks. <em>SWEVO</em>,
<em>94</em>, 101892. (<a
href="https://doi.org/10.1016/j.swevo.2025.101892">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, graph convolutional networks (GCN) have attracted significant attention due to their superior performance in handling non-Euclidean spaces, which enables GCN to model and analyze complex data structures that cannot be handled by traditional methods. Neural network-based multi-objective evolutionary algorithms (NNMOEAs) have made significant strides, predominantly focusing on mapping the decision space to the objective space, but may fail to focus on the interconnectedness of solutions within the decision space. To address this problem, this paper proposes a two-stage multi-objective optimization algorithm that utilizes graph convolutional networks to enhance population evolution. In the initial stage, the algorithm employs cosine similarity to represent the population as graph-structured data. A hypervolume-guided self-attention update mechanism is then introduced to balance exploration and exploitation, achieved by establishing an exploratory neighborhood population alongside an expanded neighborhood population. In the subsequent stage, a key node detection strategy is implemented, which considers both the global influence and local mediation roles of nodes. This strategy selects individuals with highly concentrated information to generate new solutions, thereby facilitating a thorough exploration of the solution space. The proposed algorithm is evaluated against five state-of-the-art MOEAs across five benchmark test suites and five real-world problems. The experimental results demonstrate its superior performance in addressing robust, variable linkages and imbalance mapping multi-objective optimization problems, as well as its feasibility in practical problems.},
  archive      = {J_SWEVO},
  author       = {Pengguo Yan and Ye Tian and Yu Liu},
  doi          = {10.1016/j.swevo.2025.101892},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101892},
  shortjournal = {Swarm Evol. Comput.},
  title        = {An indicator-based multi-objective evolutionary algorithm assisted by improved graph convolutional networks},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Strengthened grey wolf optimization algorithms for numerical
optimization tasks and AutoML. <em>SWEVO</em>, <em>94</em>, 101891. (<a
href="https://doi.org/10.1016/j.swevo.2025.101891">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The grey wolf optimization algorithm (GWO) is an efficient optimization technology. However, it still has some problems such as immature convergence and stagnation at local optima. In this paper, a strengthened grey wolf optimization algorithm (SGWO) is proposed based on three strengthening mechanisms: the exponential decreasing convergence factor, the elite reselection strategy in per generation and the Cauchy mutation (CM) operator. Seven variants of SGWO are designed according to different deployment modes of three reinforcement mechanisms. Experiments on thirteen numerical optimization problems are carried out to compare the differences between GWO and SGWOs. The experimental results reveal that SGWOs can significantly improve the search performance of GWO in most tasks. Among them, SGWO7 is the most successful competitor. Furthermore, several optimizers have demonstrated through comparison on engineering design problems that SGWO7 outperforms the vast majority of competitors. Subsequently, MHHO, TLBO, GWO and SGWO7 are used to build automatic machine learning (AutoML) model. The experimental results of the four methods on MNIST dataset further illustrate the advantages of SGWO7 designed in this research.},
  archive      = {J_SWEVO},
  author       = {Xuefen Chen and Chunming Ye and Yang Zhang},
  doi          = {10.1016/j.swevo.2025.101891},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101891},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Strengthened grey wolf optimization algorithms for numerical optimization tasks and AutoML},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive distance-based multi-objective particle swarm
optimization algorithm with simple position update. <em>SWEVO</em>,
<em>94</em>, 101890. (<a
href="https://doi.org/10.1016/j.swevo.2025.101890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, multi-objective particle swarm optimization algorithms have been widely used in science and engineering due to their advantages of fast convergence speed and easy implementation. However, the selection of globally optimal particle is an important and challenging problem in the design of multi-objective particle swarm optimization algorithms. In this regard, this paper proposes an adaptive distance-based multi-objective particle swarm optimization algorithm with simple position update, named ADMOPSO. First, an adaptive penalty-based boundary intersection (PBI) distance strategy is designed to select the globally optimal particle from two elite particles which are randomly chosen from an elite particle set. This strategy better balances the diversity and convergence requirements of particle swarm optimization algorithm in the optimization process. Second, a simple position probabilistic update strategy is constructed to rewrite the velocity update method with the weight and use the learning rate to control the scale of the updated velocity in the position update equation to avoid particle swarm falling into the local optimum. Finally, an extensive experimental study is conducted to test the performance of several selected multi-objective optimization algorithms on ZDT, WFG and DTLZ benchmark problems, as well as 7 real-world problems were conducted to test the proposed algorithm. Comparative experimental results show that the algorithm proposed in this paper has significant advantages over other algorithms. This shows that the ADMOPSO algorithm is competitive in dealing with multi-objective problems.},
  archive      = {J_SWEVO},
  author       = {Liangying Wang and Lihuan Hong and Haoxuan Fu and Zhiling Cai and Yiwen Zhong and Lijin Wang},
  doi          = {10.1016/j.swevo.2025.101890},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101890},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Adaptive distance-based multi-objective particle swarm optimization algorithm with simple position update},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Smart cities optimization using computational intelligence
in power-constrained IoT sensor networks. <em>SWEVO</em>, <em>94</em>,
101889. (<a href="https://doi.org/10.1016/j.swevo.2025.101889">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the Innovative Clustering Energy Efficient Equilibrium Optimizer-based Multi-Hop Routing Protocol (ICEE-EO-MHRP) for addressing the energy constraint in Internet of Things (IoT) network clustering utilizing the Equilibrium Optimizer (EO), a yet efficient computational intelligence method that is used for selecting Designated Cluster Head (DCH) and Backup DCH (BDCH). Additionally, ICEE-EO-MHRP deals with the IoT energy problem by incorporating a novel cost function that ends up of selecting Designated Relays (DRs) and backup DRs for the purpose of forwarding the traffic towards the sink node. Our protocol substantially reduces messages’ exchanges between IoT Sensor Nodes (SNs) by making the replacement of DCH and BDCH dependent on their energy levels dropping below a threshold. To ensure a balanced communication load and efficient scheduling, an innovative deterministic distributed-time division multiple access system is employed. Not only to this extent, but we address data redundancy issue, raised among those quite adjacent SNs, and accordingly propose an efficient management that guarantees having a coherent protocol. In addition to that, device and link failures are professionally addressed by suggesting recovery mechanisms that optimize the proposed protocol. Dealing with these impairments puts our approach well ahead of the competition since it addresses the most practical issues and scenarios, particularly those with challenging environmental constraints. The simulation results demonstrate primarily that our protocol significantly improves the network lifetime by 157.83 % and 109.81 % in comparison to Particle Swarm Optimization and Tabu Search (Tabu-PSO) and Energy-Efficient CH Selection by Improved Sparrow Search Algorithm utilizing Differential Evolution (EECHS-ISSADE), respectively. Comparing ICEE-EO-MHRP to Tabu-PSO and EECHS-ISSADE reveals improvements in residual energy of 335.87 % and 230.05 %, respectively. Furthermore, in comparison to Tabu-PSO and EECHS-ISSADE, the proposed protocol optimizes the throughput by 252.36 % and 168.64 %, respectively. In terms of average delay, our protocol outperforms Tabu-PSO, EECHS-ISSADE, PEGASIS with Artificial Bee Colony (PEG-ABC), Metaheuristics Cluster-based Routing Technique for Energy-Efficient WSN (MHCRT-EEWSN), as well as Hybrid Bald Eagle Search Optimization Algorithm (HBESAOA) by improvements of 57.53 %, 55.15 %, 86.89 %, 20.52 %, and 94.60 %, respectively.},
  archive      = {J_SWEVO},
  author       = {Khalid A. Darabkh and Muna Al-Akhras},
  doi          = {10.1016/j.swevo.2025.101889},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101889},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Smart cities optimization using computational intelligence in power-constrained IoT sensor networks},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning assisted differential evolution with
adaptive resource allocation strategy for multimodal optimization
problems. <em>SWEVO</em>, <em>94</em>, 101888. (<a
href="https://doi.org/10.1016/j.swevo.2025.101888">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal optimization problems (MMOPs) present the challenge of identifying multiple optimal solutions within a search space, requiring algorithms to effectively balance exploration and exploitation. To enhance solution accuracy, the local search methods often focus on elite individuals, allocating additional fitness evaluations (FEs) to refine their solutions. However, once the optima near these elite individuals are identified, continued allocation of FEs becomes inefficient, leading to a waste of limited resources. This highlights the inherent difficulty of achieving a balance between exploration and exploitation within the population under constrained resources. To solve this problem, this paper proposes a new reinforcement learning-assisted differential evolution (RLDE) algorithm with adaptive resource allocation strategy. Firstly, the exploitation population is proposed, and the original population focuses on exploring undiscovered optimal regions and generating exploitation populations, while each exploitation population focuses on finding high-precision optima within its responsible optimal region. Secondly, a reinforcement learning-assisted adaptive resource allocation (RLRA) strategy is proposed to allocate FEs, which can reduce the waste of FEs and balance the exploration and exploitation ability among multiple populations. Finally, a local greedy mutation (LGM) strategy is proposed to help individuals evolve toward the neighborhood with better fitness values. Compared with 11 state-of-the-art multimodal algorithms, the RLDE achieves better or more competitive results in all accuracy levels. Besides, the results on the dielectric composite optimization problem verify the practicality of RLDE.},
  archive      = {J_SWEVO},
  author       = {Tao Ma and Hong Zhao and Xiangqian Li and Fang Yang and Chun-sheng Liu and Jing Liu},
  doi          = {10.1016/j.swevo.2025.101888},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101888},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Reinforcement learning assisted differential evolution with adaptive resource allocation strategy for multimodal optimization problems},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning-assisted improvements in adaptive variable
neighborhood search. <em>SWEVO</em>, <em>94</em>, 101887. (<a
href="https://doi.org/10.1016/j.swevo.2025.101887">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents the design and integration of novel adaptive components within the Double-Adaptive General Variable Neighborhood Search (DA-GVNS) algorithm, aimed at improving its overall efficiency. These adaptations utilize iteration-based data to refine the search process, with enhancements such as an adaptive reordering mechanism in the refinement phase and a knowledge-guided approach to adjust the search strategy. Additionally, an adaptive mechanism for dynamically controlling the shaking intensity was introduced. The proposed knowledge-guided adaptations demonstrated superior performance over the original DA-GVNS framework, with the most effective scheme selected for further evaluation. Initially, the symmetric Traveling Salesman Problem (TSP) was used as a benchmark to quantify the impact of these mechanisms, showing significant improvements through rigorous statistical analysis. A comparative study was then conducted against six advanced heuristics from the literature. Finally, the most promising knowledge-guided GVNS (KG-GVNS) was tested against the original DA-GVNS on selected instances of the Quadratic Assignment Problem (QAP), where detailed statistical analysis highlighted its competitive advantage and robustness in addressing complex combinatorial optimization problems.},
  archive      = {J_SWEVO},
  author       = {Panagiotis Karakostas and Angelo Sifaleras},
  doi          = {10.1016/j.swevo.2025.101887},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101887},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Learning-assisted improvements in adaptive variable neighborhood search},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Novel MINLP model and lamarckian learning-enhanced
multi-objective optimization algorithm for smart household appliance
scheduling. <em>SWEVO</em>, <em>94</em>, 101886. (<a
href="https://doi.org/10.1016/j.swevo.2025.101886">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of information and communication technology, a home energy management system (HEMS) on the demand side, embedded with advanced scheduling models and optimization algorithms, has the potential to conserve energy, reduce users’ electricity costs and dissatisfaction, while ensuring the stable operation of the power grid. This paper first develops a novel mixed-integer non-linear programming (MINLP) model for the smart household appliance scheduling problem with solar energy and energy storage to minimize the total electricity consumption cost and the user dissatisfaction simultaneously over a day. Next, to the best of our knowledge, this is the first work to propose a novel Lamarckian-learning enhanced multi-objective particle swarm optimization (LLMOPSO) algorithm to solve the studied problem. To validate the effectiveness of the improved model and algorithm, comparative experiments are conducted on four case studies under different scenarios. The experimental results demonstrate that the proposed LLMOPSO outperforms the existing ones in terms of eight commonly used performance metrics, such as the number of non-dominated solutions ( ND ), the ratio of non-dominated solutions ( R nd ), the generational distance ( GD ), and the metric of diversity ( DM ). Compared to four existing optimization algorithms, our novel approach can provide better schedules for users, enabling them to manage smart household appliances in a more flexible, comfortable, and cost-effective way.},
  archive      = {J_SWEVO},
  author       = {Weidong Lei and Ziheng You and Jiawei Zhu and Pengyu Yan and Zhen Zhou and Jikun Chen},
  doi          = {10.1016/j.swevo.2025.101886},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101886},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Novel MINLP model and lamarckian learning-enhanced multi-objective optimization algorithm for smart household appliance scheduling},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning-based memetic algorithm for
solving dynamic distributed green flexible job shop scheduling problem
with finite transportation resources. <em>SWEVO</em>, <em>94</em>,
101885. (<a href="https://doi.org/10.1016/j.swevo.2025.101885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve the dynamic distributed green flexible job shop scheduling problem with integrated multi-automated guided vehicles (AGVs) transportation (DDGFJSP-MT), a coupled mathematical model is constructed in this study with the objective of minimizing the makespan and total carbon emissions. The complex coupled roles between factories, jobs, machines, and AGVs induced by machine breakdown are explored. Meanwhile, a deep Q-network-based dynamic efficient memetic algorithm (DQN-DEMA) is proposed to solve the problem. First, a four-layer coding is designed to characterize the DDGFJSP-MT, and a novel dynamic decoding technique is developed based on the state variations of the involved subjects and their strong coupling effects following the machine breakdown. Second, an alternating hybrid initialization strategy is employed to improve the quality and diversity of the rescheduled population. Then, several neighborhood search structures are designed based on critical path and bottleneck operation, and DQN is applied to recommend the most suitable local search operator for each elite individual, accelerating the convergence of the rescheduled population and effectively avoiding the waste of algorithmic resources. Finally, performance validation on 20 instances demonstrates that DQN-DEMA obtains the Pareto frontier with higher quality and diversity in 15 instances compared to the six state-of-the-art algorithms.},
  archive      = {J_SWEVO},
  author       = {Xinxin Zhou and Fuyu Wang and Bin Wu and Yan Li and Nannan Shen},
  doi          = {10.1016/j.swevo.2025.101885},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101885},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Deep reinforcement learning-based memetic algorithm for solving dynamic distributed green flexible job shop scheduling problem with finite transportation resources},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic quadratic decomposition-based evolutionary algorithm
for multi-objective fuzzy flexible jobshop scheduling. <em>SWEVO</em>,
<em>94</em>, 101884. (<a
href="https://doi.org/10.1016/j.swevo.2025.101884">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective Fuzzy Flexible Jobshop Scheduling Problems (MFFJSPs) have garnered widespread attention since they are able to handle the uncertainty of processing time in actual production. Nevertheless, making a good balance between the diversity and convergence of non-dominated solutions is a challenging issue that cannot be overlooked when MFFJSP is solved. To deal with these issues, this work proposes a Dynamic Quadratic Decomposition-based Multi-objective Evolutionary Algorithm (DQD-MOEA) to solve MFFJSP by minimizing makespan and total machine workload. To solve a problem that the distribution and diversity of searched non-dominant solutions are poor due to the discrete decision space and objective space of MFFJSP, it proposes a dynamic quadratic decomposition method. Its core idea is to eliminate all the failed reference vectors because they have no intersection with a real Pareto front, and ensure that solutions evolve along effective reference vectors. This work also introduces a problem-specific local search method to accelerate the solution convergence for MFFJSP. It proposes a hybrid initialization method to improve the quality of initial solutions. Finally, a series of experiments are performed and the results demonstrate that DQD-MOEA is significantly better than state-of-the-art algorithms in terms of convergence and solution diversity when solving widely-tested benchmark cases.},
  archive      = {J_SWEVO},
  author       = {XuWei Zhang and ZiYan Zhao and ShuJin Qin and ShiXin Liu and MengChu Zhou},
  doi          = {10.1016/j.swevo.2025.101884},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101884},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Dynamic quadratic decomposition-based evolutionary algorithm for multi-objective fuzzy flexible jobshop scheduling},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gaussian process regression for evolutionary dynamic
multiobjective optimization in complex environments. <em>SWEVO</em>,
<em>94</em>, 101883. (<a
href="https://doi.org/10.1016/j.swevo.2025.101883">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiobjective Evolutionary Algorithms (MOEAs) face significant challenges when addressing dynamic multiobjective optimization problems, particularly those with frequent changes. The complexity of dynamic environments makes it difficult for MOEAs to accurately approximate the true Pareto-optimal solutions before subsequent changes occur. Typically, historical approximations of Pareto-optimal solutions are utilized to predict solutions in future environments. However, existing predictors often overlook the nondeterministic nature of historical solutions, potentially compromising prediction accuracy. In this paper, we propose a novel predictor based on Gaussian Process Regression (GPR) for evolutionary dynamic multiobjective optimization. Unlike traditional deterministic predictors, our approach aims to provide a probability distribution of predicted results, thereby addressing the inherent nondeterminism of historical solutions. We employ GPR to model relationships among historical solutions across different time steps. Within the framework of the classical MOEA, MOEA/D, we introduce a new method MOEA/D-GPR for Evolutionary Dynamic Multiobjective Optimization (EDMO). Experimental results demonstrate that our method achieves state-of-the-art performance.},
  archive      = {J_SWEVO},
  author       = {Youpeng Deng and Yan Zheng and Zhaopeng Meng and Haobo Gao and Yueyang Hua and Qiangguo Jin and Leilei Cao},
  doi          = {10.1016/j.swevo.2025.101883},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101883},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Gaussian process regression for evolutionary dynamic multiobjective optimization in complex environments},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constrained multi-objective particle swarm optimization for
bistatic RFID network planning with distributed antennas.
<em>SWEVO</em>, <em>94</em>, 101882. (<a
href="https://doi.org/10.1016/j.swevo.2025.101882">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radio Frequency Identification (RFID) network planning (RNP) is crucial for optimizing network performance by setting system parameters. The new bistatic RFID architecture with a distributed antenna system (DAS) offers advantages for the passive Internet of Things (IoT). It separates transmission and reception to minimize self-interference and extend uplink communication range, while using distributed antennas for broader coverage. Bistatic DAS RNP differs from monostatic in various aspects. Monostatic RNP focuses on factors like reader number, location, and power, while bistatic DAS RNP involves more parameters, including antenna and device numbers, locations, and interconnections. Coverage and interference are more complex, and practical planning faces constraints on antenna ports and feeder line length. Consequently, bistatic DAS RFID network planning (BDRNP) problems are novel, complex, high-dimensional, and constrained, making them relatively unexplored and highly challenging. This paper analyzes bistatic DAS RFID network coverage and interference, and proposes a mathematical model for BDRNP problems. A modified multi-objective discrete particle optimization (M2DPSO) algorithm is introduced, incorporating a modified k-means clustering method to group antennas, which ensures satisfaction constraints and reduces decision variable dimensionality from 4 | C S | + | C S | 2 to 4 | C S | to 4 | C S | where | C S | is the problem size. Redundant SDRs/carrier emitters are dynamically eliminated based on global best solution set changes. Experimental results show that M2DPSO algorithm significantly outperforms three existing popular algorithms – nondominated sorting genetic algorithm II (NSGAII), discrete particle swarm optimization (DPSO), and multi-objective evolutionary algorithm based on decomposition (MOEAD) – by 265%, 361%, and 726% respectively, in average inverted generational distance (IGD) metrics.},
  archive      = {J_SWEVO},
  author       = {Yamin Wang and Shuai Ma and Yuan Li and Hongyu Qian and Qianfan Jia and Shanpeng Xiao and Yuhong Huang},
  doi          = {10.1016/j.swevo.2025.101882},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101882},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Constrained multi-objective particle swarm optimization for bistatic RFID network planning with distributed antennas},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving sparse multi-objective optimization problems via
dynamic adaptive grouping and reward-penalty sparse strategies.
<em>SWEVO</em>, <em>94</em>, 101881. (<a
href="https://doi.org/10.1016/j.swevo.2025.101881">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse Multi-Objective Optimization Problems (SMOPs) are commonly encountered in various fields such as machine learning, signal processing, and data mining. While evolutionary algorithms have shown good performance in tackling complex problems, many algorithms tend to exhibit performance degradation when dealing with SMOPs. The primary reasons for this performance decline are the curse of dimensionality and the inability to effectively leverage the sparsity of Pareto-optimal solutions. To address this issue, this paper proposes a model method to solve sparse multi-objective optimization problems through dynamic adaptive grouping and reward-penalty sparse strategies. Specifically, to obtain more effective prior information, a sparse initialization strategy is proposed in the initialization phase. This strategy aims to incorporate more prior knowledge and information about the sparsity of Pareto-optimal solutions. In the evolutionary phase, a decision variable dynamic adaptive grouping strategy is introduced. This strategy, combined with crossover and mutation operators, guides the population towards effective sparse directions. Furthermore, to further identify zero-value decision variables in Pareto-optimal solutions, a reward-penalty mechanism is designed to update the scores of decision variables. By combining this mechanism with the adaptive grouping strategy, this method can effectively flip low-scoring decision variables to zero with a higher probability. To validate the advantages of the proposed algorithm, experiments were conducted on eight benchmark problems, with comparative experiments conducted for different initialization methods. The results indicate that our algorithm exhibits significant advantages in solving SMOPs.},
  archive      = {J_SWEVO},
  author       = {Zhenxing Yu and Qinwei Fan and Jacek M. Zurada and Jigen Peng and Haiyang Li and Jian Wang},
  doi          = {10.1016/j.swevo.2025.101881},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101881},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Solving sparse multi-objective optimization problems via dynamic adaptive grouping and reward-penalty sparse strategies},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data stream driven evolutionary algorithm for cost sensitive
robust optimization over time. <em>SWEVO</em>, <em>94</em>, 101880. (<a
href="https://doi.org/10.1016/j.swevo.2025.101880">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many dynamic optimization problems in real-world domains like engineering and management science require considerations of robustness, where a balance between tracking optimal solutions in changing environments and managing costs of switching solutions is needed. However, in some cases, the objective functions are not analytically available and must be approximated based on data collected from numerical simulations or experiments. These dynamic problems are formulated as data stream driven robust optimization over time (DDROOT G ) problems, which cannot be satisfactorily addressed by existing dynamic optimization algorithms. Therefore, we propose a data stream driven multi-form evolutionary algorithm (DDMFEA), employing two separate Kriging models to approximate the unavailable objective function and the computationally expensive robustness estimation, respectively. In the proposed algorithm, DDROOT G problems are addressed with two distinct formulations with single- and multi-objectives. These formulations are utilized as a multi-form optimization process to mitigate the impact of approximation errors from both Kriging models. In addition, a novel solution selection mechanism is designed to consider both robustness and predicted objective values, facilitating the deployment of the optimal robust solution. Throughout the experiment, four robust comparison algorithms are employed to assess the performance of the proposed DDMFEA across various problems in different decision dimensions. The experimental results validate the significance of each proposed contribution and demonstrate the exceptional performance of DDMFEA.},
  archive      = {J_SWEVO},
  author       = {Zhening Liu and Handing Wang and Jinliang Ding and Cuie Yang and Yaochu Jin},
  doi          = {10.1016/j.swevo.2025.101880},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101880},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Data stream driven evolutionary algorithm for cost sensitive robust optimization over time},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Surrogate-assisted differential evolution: A survey.
<em>SWEVO</em>, <em>94</em>, 101879. (<a
href="https://doi.org/10.1016/j.swevo.2025.101879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Expensive Optimization Problems (EOPs) are a pressing challenge in real-world applications because they require high-quality solutions under tight computational budgets. To tackle this, numerous Surrogate-Assisted Evolutionary Algorithms (SAEAs) have been proposed that combine Evolutionary Algorithms (EAs) with surrogate models. Recently, researchers have conducted systematic surveys on SAEAs to better showcase their potential in solving EOPs. However, most of these efforts have focused on surrogate models, while largely overlooking EAs. This imbalance poses a challenge to the long-term development of SAEAs. Among various SAEAs, Surrogate-Assisted Differential Evolution (SADE) is widely favored by researchers due to the competitive performance of DE in Evolutionary Computation. It has been broadly applied across diverse engineering and scientific domains. Nevertheless, there is still no work that systematically investigates the progress of SADE. To balance the research direction of SAEAs and fill the gap, this paper provides a comprehensive survey of SADE. Its contributions are summarized as follows: This paper first introduces the general optimization framework of SAEAs and briefly reviews the research directions and advances of its key components. Next, a comprehensive survey of SADE is conducted, covering commonly used surrogate models and DE algorithms. It also examines how existing SADE algorithms use DE, performance evaluation methods, and real-world applications. Finally, future challenges and potential research directions are discussed. We hope this work will draw attention to EAs and inspire further research to advance related fields.},
  archive      = {J_SWEVO},
  author       = {Laiqi Yu and Zhenyu Meng and Lingping Kong and Vaclav Snasel and Jeng-Shyang Pan},
  doi          = {10.1016/j.swevo.2025.101879},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101879},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Surrogate-assisted differential evolution: A survey},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-agent reinforcement learning for task allocation in
the internet of vehicles: Exploring benefits and paving the future.
<em>SWEVO</em>, <em>94</em>, 101878. (<a
href="https://doi.org/10.1016/j.swevo.2025.101878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Vehicles (IoV) and its applications are undergoing massive development, requiring diverse autonomous or self-directed vehicles/agents to fulfill various objective and responsibilities in vehicular technology. Similarly, Multi-Agent Systems (MAS) and multi-agent task allocation are currently the main focus of multiple researchers and scholars, and they play a key role in IoV and the Internet of Things (IoT). The development of the IoV and autonomous vehicles plays a significant role in Intelligent Transportation Systems (ITS), which are empowered by vehicular networks. However, the dynamic nature of these networks presents substantial challenges that need to be addressed. In this regard, we trace the historical evolution of the multi-agent task allocation of IoV, highlight its fundamentals and progress, and discuss the existing survey works. This paper comprehensively reviews various IoV strategies, both multi-agent task allocation strategies and Multi-Agent Reinforcement Learning (MARL), emphasizing the intelligent learning architecture, concepts, and security-related issues. Additionally, we highlight various computing platforms and the diverse applications of multi-agent task allocation in IoV, where task allocation is challenging and presents security concerns of multi-agent task allocation in IoV. Finally, we discuss major open problems regarding multi-agent task allocation scalability, complexity, communication overhead, resource allocation, security, privacy, etc., and potential future perspectives on multi-agent task allocation methods are highlighted.},
  archive      = {J_SWEVO},
  author       = {Inam Ullah and Sushil Kumar Singh and Deepak Adhikari and Habib Khan and Weiwei Jiang and Xiaoshan Bai},
  doi          = {10.1016/j.swevo.2025.101878},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101878},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Multi-agent reinforcement learning for task allocation in the internet of vehicles: Exploring benefits and paving the future},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy-efficient task scheduling with binary random faults
in cloud computing environments. <em>SWEVO</em>, <em>94</em>, 101877.
(<a href="https://doi.org/10.1016/j.swevo.2025.101877">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault management and energy consumption control have become focal topics in the rapid development of cloud computing services. This paper addresses the task scheduling problem with binary random faults in the networking and power supply of cloud computing environments and proposes a task scheduling model with the multiobjectives of minimizing energy consumption and task completion time while maximizing task completion rate. An estimation of distribution algorithm (EDA) with crowding distance (C) and neighborhood search (N) (EDA-CN) is designed for the model, into which a multi-model probability matrix, regional dislocation backup mechanism, neighborhood search operator, and crowding distance operator are integrated. Numerical experiments examine the effectiveness of EDA-CN in comparison with EDA, EDA-C, and the classic non-dominated sorting genetic algorithm III (NSGA3). The results show that EDA-CN consistently outperformed EDA and EDAC, and EDA-CN and NSGA3 performed comparably often yet EDA-CN still outperformed statistically significantly.},
  archive      = {J_SWEVO},
  author       = {Lei Jin and Jie Yuan and Dequn Zhou and Xiuzhi Sang and Shi Chen and Xianyu Yu and Guohui Lin},
  doi          = {10.1016/j.swevo.2025.101877},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101877},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Energy-efficient task scheduling with binary random faults in cloud computing environments},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic multi-objective evolutionary algorithm based on
dual-layer collaborative prediction under multiple perspective.
<em>SWEVO</em>, <em>94</em>, 101876. (<a
href="https://doi.org/10.1016/j.swevo.2025.101876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prediction-based strategies become increasingly prominent in addressing dynamic multi-objective optimization problems (DMOPs). However, challenges remain in selecting predictive models and effectively utilizing historical solutions. In this paper, we propose a multiple perspective dual-layer collaborative prediction strategy to efficiently tackle both challenges. The multi-perspective approach is further divided into a search perspective and a spatial perspective and realized through the collaboration of three sub-strategies. From the search perspective, we employ a dual-layer prediction strategy that focuses on both global and local information. Specifically, the first layer utilizes Gaussian process regression (GPR) to predict centrality, which serves as a measure of the population’s collective intelligence. This layer effectively captures global insights into population dynamics, identifying overarching movement trends over time. Building on these global insights, the second layer employs a knee-point interval partitioning strategy that combines vector partitioning with knee-point-based predictions. This layer provides localized insights that complement the broader movement trends identified by the first layer. From the spatial perspective, we implement dual-layer historical similarity detection across non-dominated solutions in both decision and objective spaces. Specifically, the historical Pareto-similarity selection strategy identifies populations in these spaces that demonstrate the greatest similarity to the current population’s non-dominated solutions. The spatial perspective complements the search perspective, forming a coherent framework that systematically integrates global, local, and historical information. Experimental results indicate that the proposed algorithm performs better than previous state-of-the-art methods.},
  archive      = {J_SWEVO},
  author       = {Yaru Hu and Yana Li and Junwei Ou and Jiankang Peng and Jun Li and Jinhua Zheng},
  doi          = {10.1016/j.swevo.2025.101876},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101876},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Dynamic multi-objective evolutionary algorithm based on dual-layer collaborative prediction under multiple perspective},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective genetic programming based on decomposition
for feature learning in image classification. <em>SWEVO</em>,
<em>94</em>, 101875. (<a
href="https://doi.org/10.1016/j.swevo.2025.101875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image classification presents a challenge due to its high dimensionality and extensive variations. Feature learning is a powerful method in addressing this challenge, constituting a multi-objective problem aimed at maximizing classification accuracy and minimizing the number of learned features. A few multi-objective genetic programming (MOGP) methods have been proposed to optimize these two objectives, simultaneously. However, existing MOGP methods ignore the characteristics of feature learning tasks. Therefore, this work proposes a decomposition-based MOGP approach with a global replacement strategy for feature learning in data-efficient image classification. To handle the different value ranges of the two objectives, a transformation function is designed to uniform the range of the number of learned features. In addition, a preference-based decomposition strategy is proposed to address the preference for the objective of classification accuracy. The proposed approach is compared with existing MOGP methods for feature learning on five different image classification datasets with different numbers of training images. The experimental results demonstrate the effectiveness of the proposed approach by achieving better HVs than or comparable to the existing MOGP methods in at least 13 out of 20 cases and classification accuracy significantly better than a popular neural architecture search method in all cases.},
  archive      = {J_SWEVO},
  author       = {Tuo Zhang and Ying Bi and Jing Liang and Bing Xue and Mengjie Zhang},
  doi          = {10.1016/j.swevo.2025.101875},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101875},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Multi-objective genetic programming based on decomposition for feature learning in image classification},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convolutional neural network combined with reinforcement
learning-based dual-mode grey wolf optimizer to identify crop diseases
and pests. <em>SWEVO</em>, <em>94</em>, 101874. (<a
href="https://doi.org/10.1016/j.swevo.2025.101874">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agriculture is crucial for national food security, but crop pests and diseases pose significant threats. Traditional manual methods for detection are subjective, costly, and less accurate. Deep learning, especially convolutional neural network, is revolutionizing crop pest and disease identification, manual hyperparameter tuning can lead to suboptimal results. In contrast, grey wolf optimizer has demonstrated effective global search capabilities in hyperparameter optimization, improving model performance. Therefore, a reinforcement learning-based dual-mode grey wolf optimizer is introduced to enhance the performance of the original algorithm in hyperparameter optimization and identify the optimal hyperparameters, which combines a dynamic elite learning strategy and a dual-mode adaptive strategy well balanced with the exploration and exploitation of populations, while the integration of the reinforcement learning technique strengthens the information feedback. To validate the effectiveness of the proposed algorithm, additional ablation experiments were conducted, and experiments using CPU time as the termination criterion were included to increase rigor and ensure fairness. The main hyperparameters of convolutional neural network optimized by the proposed algorithm is utilized for the recognition of the pentatomidae stinkbug pests and corn diseases, with experimental results compared against six other intelligent optimization algorithms. Results from two sets of experiments indicate that the proposed algorithm improves the recognition accuracy of the original convolutional neural networks model, achieving the highest accuracy on the pest dataset at 95.83 % and on the corn disease dataset at 96.51 %.},
  archive      = {J_SWEVO},
  author       = {Yangchen Lu and Xiaobing Yu and Zhengpeng Hu and Xuming Wang},
  doi          = {10.1016/j.swevo.2025.101874},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101874},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Convolutional neural network combined with reinforcement learning-based dual-mode grey wolf optimizer to identify crop diseases and pests},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved adaptive hybrid algorithm for solving
distributed flexible job shop scheduling problem. <em>SWEVO</em>,
<em>94</em>, 101873. (<a
href="https://doi.org/10.1016/j.swevo.2025.101873">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With economic globalization, collaboration between enterprises has increased significantly. Complex products are now often produced in multiple workshops, either within a single company or across several. This shift has led to the rise of distributed manufacturing, a modern and rapidly expanding production method. This paper puts forward an Improved Adaptive Hybrid Algorithm (IAHA) to address the Distributed Flexible Job Shop Problem (DFJSP). A mathematical model of DFJSP is established based on the characteristics of distributed manufacturing. A hybrid decoding rule is proposed, using a dual-layer encoding approach to represent both factories and jobs. The initialization, crossover, and mutation operators are designed to efficiently tackle the job allocation challenge across distributed factories. In the local search phase, an adaptive variable neighborhood search method focuses on critical factories. Numerical experiments on a benchmark set of DFJSP instances with 2, 3, and 4 factories demonstrate the effectiveness of IAHA, breaking records for several instances and achieving optimal results for others. Comparisons with other algorithms show the IAHA&#39;s superior performance in solving the DFJSP.},
  archive      = {J_SWEVO},
  author       = {Cuiyu Wang and Mengxi Wei and Qihao Liu and Xinjian Zhang and Xinyu Li},
  doi          = {10.1016/j.swevo.2025.101873},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101873},
  shortjournal = {Swarm Evol. Comput.},
  title        = {An improved adaptive hybrid algorithm for solving distributed flexible job shop scheduling problem},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced QPSO driven by swarm cooperative evolution and its
applications in portfolio optimization. <em>SWEVO</em>, <em>94</em>,
101872. (<a href="https://doi.org/10.1016/j.swevo.2025.101872">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Being a simple and popular method grounded in swarm evolution, Quantum-behaved particle swarm optimization (QPSO) has been extensively implemented to seek the optimal solution of various practical cases. Nevertheless, while managing intricate multimodal problems, the original QPSO algorithm renders the algorithm susceptible to premature convergence, characterized by slow iteration speed and suboptimal searching precision. To deal with these disadvantages, this paper puts forward an enhanced QPSO driven by swarm cooperative evolution (SCQPSO). In the SCQPSO algorithm, a binary swarm cooperative evolution strategy is designed to enhance QPSO’s convergence speed and optimization precision. Additionally, some improvement measures including Halton sequence initialization of individual locations, maintenance of population diversity, and mutation strategy for out-of-bounds particles, are also adopted to facilitate prevention of premature convergence and assist the algorithm in overcoming local optimality. Then, compared results obtained by SCQPSO and six improved intelligent approaches on CEC 2017 cases indicate that SCQPSO offers highly competitive solutions when solving complex multimodal problems. Further, the exceptional capability of SCQPSO in addressing two portfolio optimization issues demonstrates its outstanding global search performance.},
  archive      = {J_SWEVO},
  author       = {Xiao-li Lu and Guang He},
  doi          = {10.1016/j.swevo.2025.101872},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101872},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Enhanced QPSO driven by swarm cooperative evolution and its applications in portfolio optimization},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning-assisted particle swarm algorithm for
effluent scheduling problem with an influent estimation of WWTP.
<em>SWEVO</em>, <em>94</em>, 101871. (<a
href="https://doi.org/10.1016/j.swevo.2025.101871">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effluent scheduling of wastewater treatment process (WWTP) is essential to ensure compliance with regulatory standards regarding effluent quality. Through the integration of pipe and plant systems, the influent can be estimated prior to entering the treatment process, providing additional information for scheduling. However, the traditional evolutionary computation methods face challenges in utilizing information from inflow estimation, resulting in decisions that do not account for long-term returns. For solving effluent scheduling problems with influent estimation, reinforcement learning can facilitate decision-making based on long-term environmental factors to improve the optimization ability of evolutionary computations. Thus, a framework of reinforcement learning-assisted particle swarm optimization algorithm (RLA-PSO) is proposed, using reinforcement learning part to generate solutions and guide optimization by learning from the influent estimation on a long-time scale. Meanwhile, it employs the optimization part to find the optimal solutions to intensify the learning effect of the reinforcement learning part. For the reinforcement learning part, a deep Q -network method with appropriate states and rewards is designed to efficiently learn the relationship between state, action and reward for the coming period. For the optimization part, a set-based particle optimization algorithm is employed to search for the optimized solution in a future period. The benchmark simulation model No.1(BSM1) is used to evaluate the performance of the proposed RLA-PSO algorithm for the effluent scheduling problem of WWTP. The computational experiments to the state-of-the-art methods show the proposed algorithm can achieve superior performance in effluent quality and process efficiency.},
  archive      = {J_SWEVO},
  author       = {HAN HongGui and XU ZiAng and WANG JingJing},
  doi          = {10.1016/j.swevo.2025.101871},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101871},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Reinforcement learning-assisted particle swarm algorithm for effluent scheduling problem with an influent estimation of WWTP},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interval many-objective evolutionary algorithm guided by
dynamic dual-sequence mechanism. <em>SWEVO</em>, <em>94</em>, 101870.
(<a href="https://doi.org/10.1016/j.swevo.2025.101870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval many-objective evolutionary algorithms (IMaOEAs) have received significant achievements in recent years. However, it is difficult for the algorithm to quickly select good interval individuals since the uncertainty affects the definition of interval dominance relations. To further reduce the computational burden of uncertainty on the interval optimization process, this paper proposes a dual-sequence mechanism-guided interval many-objective evolutionary algorithm. First, the interval binary R2 evaluation indicator IR2 was designed, which can effectively evaluate the convergence and diversity of interval individuals. Second, an uncertainty dominance relation for interval individuals is proposed and uncertainty is quantified using the weighted LP norm (WLP). Finally, the dynamic dual-sequence (DDS) mechanism was ultimately employed to retain the most exceptional individuals within the population, while simultaneously eliminating those with subpar performance in terms of convergence, diversity, and uncertainty. To extensively evaluate the performance of the proposed approach, 16 benchmark problems were used as the test suite. The experimental results demonstrate that the approach outperforms five advanced interval many-objective evolutionary algorithms, showcasing its superior performance and competitiveness.},
  archive      = {J_SWEVO},
  author       = {Xingjuan Cai and Jinli Li and Jinlong Ma and Zhixia Zhang and Qingyuan Xu and Wensheng Zhang and Jinjun Chen},
  doi          = {10.1016/j.swevo.2025.101870},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101870},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Interval many-objective evolutionary algorithm guided by dynamic dual-sequence mechanism},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). State-space adaptive exploration for explainable particle
swarm optimization. <em>SWEVO</em>, <em>94</em>, 101868. (<a
href="https://doi.org/10.1016/j.swevo.2025.101868">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A systems theory framework for swarm optimization algorithms promises the rigorous analysis of swarm behaviors and systematic approaches that could avoid ad hoc parameter settings and achieve guaranteed performances. However, optimization processes must treat various systems theory concepts, such as stability and controllability, differently, as swarm optimization relies on preserving diversity rather than reaching uniform agent behavior. This work addresses this duality of perspective and proposes State-Space Particle Swarm Optimization (SS-PSO) using the feedback concept in control systems theory. By exploiting the hidden analogy between these two paradigms, we introduce the concept of controllability for optimization purposes through state-space representation. Extending controllability to particle swarm optimization (PSO) highlights the ability to span the search space, emphasizing the significance of particles&#39; movement rather than their loss of diversity. Furthermore, adaptive exploration (AE) using an iterative bisection algorithm is proposed for the PSO parameters that leverages this controllability measure and its minimum singular value to facilitate explainable swarm behaviors and escape local minima. Theoretical and numerical analyses reveal that SS-PSO is only uncontrollable when the cognitive factor is zero, implying less exploration. Finally, AE enhances exploration by increasing the controllability matrix&#39;s minimum singular value. This result underscores the profound connection between the controllability matrix and exploration, a critical insight that significantly enhances our understanding of swarm optimization. AE-based State-Space-PSO (AESS-PSO) shows improved exploration and performance over PSO in 86 SOP and CEC benchmarks, particularly for smaller populations.},
  archive      = {J_SWEVO},
  author       = {Mehdi Alimohammadi and Mohammad-R. Akbarzadeh-T},
  doi          = {10.1016/j.swevo.2025.101868},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101868},
  shortjournal = {Swarm Evol. Comput.},
  title        = {State-space adaptive exploration for explainable particle swarm optimization},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A spiking neural network based proximal policy optimization
method for multi-point imaging mission scheduling of earth observation
satellite. <em>SWEVO</em>, <em>94</em>, 101867. (<a
href="https://doi.org/10.1016/j.swevo.2025.101867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to the escalating demand for earth observation, a solitary satellite will be required to undertake an expanded array of missions, thereby rendering the scheduling of multipoint earth observation satellite imaging missions increasingly intricate. Herein, we propose a proximal policy optimization (PPO) algorithm based on a spiking neural network (SNN) to solve the multipoint satellite mission scheduling problem. Initially, we preprocess the mission–transition time by incorporating satellite attitude constraints and conceptualize the mission planning process as a Markov decision. Then, our methodology integrates SNN with PPO to effectively handle a high-dimensional state space by leveraging temporal information–processing capabilities. The SNN-based actor-critic network is trained to enhance the scheduling policy via PPO. Our method exhibits superior performance across various satellite orbits, satellite attitude maneuver speeds, and mission scales. In comparison with heuristic methods and traditional reinforcement learning techniques, our method shows a swifter convergence rate and an increased success rate of observation, coupled with superior convergence speed, robustness, and stability.},
  archive      = {J_SWEVO},
  author       = {Wei Yao and Xin Shen and Guo Zhang and Zezhong Lu and Jiaying Wang and Yanjie Song and Zhiwei Li},
  doi          = {10.1016/j.swevo.2025.101867},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101867},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A spiking neural network based proximal policy optimization method for multi-point imaging mission scheduling of earth observation satellite},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective optimization-assisted single-objective
differential evolution by reinforcement learning. <em>SWEVO</em>,
<em>94</em>, 101866. (<a
href="https://doi.org/10.1016/j.swevo.2025.101866">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {“Learning to optimize” design systems for evolutionary algorithm (EA) automatic design have become a trend, especially for differential evolution (DE). “Learning to optimize” design systems for EAs have two main parts: an excellent “backbone” algorithm with learnable components, and a learning scheme to determine the components of the “backbone” algorithm. A good “backbone” algorithm is of great importance for the algorithm design, because it determines the algorithm design space and potential. The learning scheme determines whether we can realize the potential or not. Existing studies generally choose one developed EA as the “backbone” algorithm, which constrains the potential of the design system because the “backbone” algorithm is relatively simple. To solve the problem and design a good EA, in this paper, we first propose a three-stage hybrid DE framework for single objective optimization, called SMS-DE, which implements single-objective DE, multi-objective DE, and single-objective DE sequentially. The multi-objective DE aims to enhance exploration ability. Second, we apply the framework to two advanced DEs, JADE and LSHADE, which results in two new algorithms: SMS-JADE and SMS-LSHADE. Third, the newly proposed algorithm, SMS-LSHADE, is considered the “backbone” algorithm, and the reinforcement learning method (Q-learning) is used to control the parameter for allocating computational resources to each stage, which results in another algorithm called QSMS-LSHADE. Experimental results on the CEC 2018 test suite show that SMS-DE, SMS-JADE, and SMS-LSHADE can perform significantly better than their counterparts and that SMS-QLSHADE performs the best among many developed DEs.},
  archive      = {J_SWEVO},
  author       = {Haotian Zhang and Xiaohong Guan and Yixin Wang and Nan Nan},
  doi          = {10.1016/j.swevo.2025.101866},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101866},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Multi-objective optimization-assisted single-objective differential evolution by reinforcement learning},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neuro-PSO algorithm for large-scale dynamic optimization.
<em>SWEVO</em>, <em>94</em>, 101865. (<a
href="https://doi.org/10.1016/j.swevo.2025.101865">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last few decades, dynamic optimization and large-scale optimization have been two challenging research topics. In this context, dynamic optimization with high dimensionality is undoubtedly another important research topic. For such a combined problem, this paper develops: (1) an algorithm that incorporates problem decomposition to deal with high dimensionality, (2) a search algorithm for optimization, and (3) a prediction strategy to deal with dynamic changes. Firstly, a decomposition method is introduced to divide the problem into multiple subproblems based on the level of interactions among the decision variables. For optimization, a multi-population search algorithm is proposed, where each subpopulation evolves individually. Finally, a machine learning-based prediction strategy is developed to learn information from historical solutions and predict some solutions that may be useful for the new environment. The proposed algorithm is tested using the generalized moving peaks benchmark problems. The results show that the proposed algorithm can find better solutions than existing approaches.},
  archive      = {J_SWEVO},
  author       = {Mohamed Radwan and Saber Elsayed and Ruhul Sarker and Daryl Essam and Carlos Coello Coello},
  doi          = {10.1016/j.swevo.2025.101865},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101865},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Neuro-PSO algorithm for large-scale dynamic optimization},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scheduling two-stage healthcare appointment systems via a
knowledge-based biased random-key genetic algorithm. <em>SWEVO</em>,
<em>94</em>, 101864. (<a
href="https://doi.org/10.1016/j.swevo.2025.101864">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the scheduling problem of two-stage healthcare appointment systems, previous studies always assume that a positive linear correlation is obeyed between the customer waiting time and service dissatisfaction, and an arrived customer is served immediately if the provider at the first stage becomes available, which usually leads to heavy congestion at the second stage and a rapid decline in service satisfaction. To tackle this problem further, this paper assumes that customer waiting time within different ranges impacts service dissatisfaction differently. Then, it develops an efficient real-time scheduling strategy to decide the exact starting time of each customer&#39;s service at the first stage. Considering no-shows and non-punctual appointments, a knowledge-based biased random-key genetic algorithm ( K-BRKGA ) is used to determine the number of customers at each appointment slot, such that the total weighted cost associated with customers’ waiting time, providers’ idle time, and overtime at two stages can be minimized. Based on the data sets used, K-BRKGA reduces the total cost by 2.01 % and 1.01 % compared to the other two famous algorithms.},
  archive      = {J_SWEVO},
  author       = {Fajun Yang and Chao Li and Feng Wang and Zhi Yang and Kaizhou Gao},
  doi          = {10.1016/j.swevo.2025.101864},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101864},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Scheduling two-stage healthcare appointment systems via a knowledge-based biased random-key genetic algorithm},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A large-scale optimization algorithm based on variable
decomposition and space compression. <em>SWEVO</em>, <em>94</em>,
101863. (<a href="https://doi.org/10.1016/j.swevo.2025.101863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing large-scale problem is very challenging due to the unknown landscape, huge search space of countless combinations of decision variables and the inner complexity of the problem. To better solve this kind of problem, a decomposition and compression based algorithm (DCBA) is proposed to decompose the problem and compress the search space for efficient optimization. Firstly, three space compression based linear search methods are designed with two functionalities: (1) to carry out a quick and rough optimization and find relatively good initial solutions; (2) to gather important information of each dimension (decision variable) for subsequent processing. In the three linear search methods, we design ways to evaluate the search region and compress it into smaller regions that may contain better solutions. Then, four decomposition methods are designed for fully non-separable large-scale problems. These methods can generate as many as twenty-nine different decomposition results to enhance the decomposition diversity in order to make a better trade-off of the non-separability characteristic and the decomposition for complexity reduction of fully non-separable large-scale problems. Finally, a decomposition and compression based algorithm (DCBA) is proposed to solve large-scale problems. Numerical experiments are conducted on two widely used benchmark suites and comparisons with state-of-the-art algorithms are made. The results show that the proposed algorithm is effective and efficient.},
  archive      = {J_SWEVO},
  author       = {Haiyan Liu and Wenlong Song and Yi Cheng and Shouheng Tuo and Yuping Wang},
  doi          = {10.1016/j.swevo.2025.101863},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101863},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A large-scale optimization algorithm based on variable decomposition and space compression},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-population co-evolution algorithm with balanced
environmental selection for constrained multimodal multiobjective
optimization problems. <em>SWEVO</em>, <em>94</em>, 101862. (<a
href="https://doi.org/10.1016/j.swevo.2025.101862">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In constrained multimodal multiobjective optimization problems (CMMOPs), the principal challenge is to explore multiple conflicting objectives and multiple equivalent Pareto sets under complex constraints, while balancing feasibility, convergence, and diversity of solutions. This paper proposes the DPCMMOEA-BES algorithm, which is based on dual-population co-evolution and incorporates a balanced environmental selection (BES) component to solve CMMOPs. In DPCMMOEA-BES, parent information from dual populations is shared through the mating selection operator based on speciation to generate offspring. Additionally, the BES component proposed in this paper enhances the algorithm’s overall performance by utilizing the dynamic-range-based constrained dominance principle and the accurate selection operation based on global Bi-crowding Distance, where the introduction of Bi-crowding Distance effectively balances the diversity of solutions in both the objective and decision spaces. The BES component also demonstrates its potential as a universal plugin, which can be integrated into various constrained multiobjective evolutionary algorithms and multimodal multiobjective evolutionary algorithms. The proposed DPCMMOEA-BES is evaluated on 31 test instances and compared with other state-of-the-art algorithms. The experimental results show that it is a highly competitive approach. Moreover, the comparative results confirm that integrating the BES component significantly improves the algorithm’s performance in solving CMMOPs.},
  archive      = {J_SWEVO},
  author       = {FuLong Wu and Yu Sun},
  doi          = {10.1016/j.swevo.2025.101862},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101862},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A dual-population co-evolution algorithm with balanced environmental selection for constrained multimodal multiobjective optimization problems},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrated scheduling problem of multi-load AGVs and
parallel machines considering the recovery process. <em>SWEVO</em>,
<em>94</em>, 101861. (<a
href="https://doi.org/10.1016/j.swevo.2025.101861">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern manufacturing workshops, parallel machine scheduling and automated guided vehicle (AGV) scheduling are two closely coupled problems. However, the two problems are often solved independently, which reduces the performance of manufacturing system to a large extent. To address this issue, this paper investigates the integrated scheduling problem of multi-load AGV and parallel machine considering the recovery process (MAGVPM-R). Firstly, a mathematical model is established to optimize the completion time. Second, a weight priority integration heuristic (WPIH) and four neighborhood operators are designed based on MAGVPM-R characteristics. Third, a discrete grey wolf optimization (DGWO) algorithm is proposed. Finally, the mathematical model is validated using the GUROBI solver and the performance of DGWO is tested with 100 instances of different scales. The experimental results show that DGWO solves the MAGVPM-R problem better than other competing algorithms.},
  archive      = {J_SWEVO},
  author       = {Xin Fan and Hongyan Sang and Mengxi Tian and Yang Yu and Song Chen},
  doi          = {10.1016/j.swevo.2025.101861},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101861},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Integrated scheduling problem of multi-load AGVs and parallel machines considering the recovery process},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Handling objective preference and variable uncertainty in
evolutionary multi-objective optimization. <em>SWEVO</em>, <em>94</em>,
101860. (<a href="https://doi.org/10.1016/j.swevo.2025.101860">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary algorithms (EAs) are widely employed in multi-objective optimization (MOO) to find a well-distributed set of near-Pareto solutions. Among various types of practicalities that demand standard evolutionary multi-objective optimization (EMO) algorithms to be modified suitably, we propose here a framework for handling two important ones: (i) decision-making to choose one or more preferred Pareto regions, rather than finding the entire Pareto set, and (i) uncertainty in variables and parameters of the problem which is inevitable in any practical problem. While the first practicality will allow a focused set of preferred solutions to be found, the second practicality will enable finding robust yet high-performing non-dominated solutions. We propose and analyze four different approaches for finding preferred and robust solutions for handling both practicalities simultaneously. Our results on a number of two to 10-objective tests and engineering problems indicate the superiority of one specific approach. For a comprehensive evaluation of new EMO algorithms for finding a preferred and robust solution set, we also propose a new performance metric by identifying and utilizing a number of desired properties of such trade-off solutions. The study is comprehensive and should encourage researchers to develop more competitive EMO algorithms for finding preferred and robust Pareto solutions.},
  archive      = {J_SWEVO},
  author       = {Deepanshu Yadav and Palaniappan Ramu and Kalyanmoy Deb},
  doi          = {10.1016/j.swevo.2025.101860},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101860},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Handling objective preference and variable uncertainty in evolutionary multi-objective optimization},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing healthcare resource allocation through large
language models. <em>SWEVO</em>, <em>94</em>, 101859. (<a
href="https://doi.org/10.1016/j.swevo.2025.101859">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognizing the growing capabilities of large language models (LLMs) and their potential in healthcare, this study explores the application of LLMs in healthcare resource allocation using Prompt Engineering, Retrieval-Augmented Generation (RAG), and Tool Utilization. It addresses both optimizable and non-optimizable challenges in allocating operating rooms (ORs), postoperative beds, and surgeons, while also identifying key factors like ethical and legal constraints through a medical knowledge Q&amp;A survey. Among the seven evaluated LLMs, including LaMDA 2, PaLM 2, and Qwen, ChatGPT-4o demonstrated superior performance by reducing OR and surgeon overtime, alleviating peak bed demand, and achieving the highest accuracy in medical knowledge queries. Comprehensive comparisons with traditional methods (exact and heuristic algorithm), varying problem sizes, and hybrid approaches from the literature revealed that as problem size increased, LLMs performed better and faster by integrating historical experience with new data. They adapted to changes in problem scale or demand without requiring re-optimization, effectively addressing the runtime limitations of traditional methods. These findings underscore the potential of LLMs in advancing dynamic and efficient healthcare resource management.},
  archive      = {J_SWEVO},
  author       = {Fang Wan and Kezhi Wang and Tao Wang and Hu Qin and Julien Fondrevelle and Antoine Duclos},
  doi          = {10.1016/j.swevo.2025.101859},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101859},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Enhancing healthcare resource allocation through large language models},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective neural policy approach for agile earth
satellite scheduling problem considering image quality. <em>SWEVO</em>,
<em>94</em>, 101857. (<a
href="https://doi.org/10.1016/j.swevo.2025.101857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The agile earth satellite scheduling problem (AEOSSP) aims to output reasonable execution plans to manage observation requests and satisfy different user requirements. By analyzing the factors which impact the quality of satellite observation, a specific multi-objective AEOSSP (MO-AEOSSP) is studied, integrating observation profit and average image quality as optimization objectives. To overcome the limitations of traditional iterative methods, we introduce a multi-objective neural policy approach (MONP) which consists of problem decomposition, parameter initialization and subproblem modeling. Through problem decomposition a given MO-AEOSSP can be partitioned into several subproblems, subsequently modeled and trained as encoder–decoder structure neural networks. Various features including the most typical satellite attitude angle are characterized to support the MONP, while parameter transfer initialization is employed to accelerate the overall deep reinforcement learning procedure by leveraging params acquired from optimized subproblem. An end-to-end manner is implemented after all subproblems are trained to output the final non-dominated solutions. Experimental results on various scenarios demonstrate that MONP outperforms four representative multi-objective evolutionary algorithms in terms of metrics including Pareto Front, hypervolume and computational overhead, appearing remarkable ability of convergence, distribution, efficiency and scalability. Experiments further verify the effectiveness of the adopted parameter initialization strategy. To the best of our understanding, this study is an innovative attempt to combine the neural policy approach with MO-AEOSSP considering time-dependent satellite transition.},
  archive      = {J_SWEVO},
  author       = {Luona Wei and Yongqiang Cui and Ming Chen and Qian Wan and Lining Xing},
  doi          = {10.1016/j.swevo.2025.101857},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101857},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Multi-objective neural policy approach for agile earth satellite scheduling problem considering image quality},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DANCE: Distributed co-evolutionary design of velocity
controllers for swarm intelligence robots in flocking and entrapping
tasks. <em>SWEVO</em>, <em>94</em>, 101854. (<a
href="https://doi.org/10.1016/j.swevo.2025.101854">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study combined evolutionary algorithm and reinforcement learning to propose a new automated design method for generating swarm robots velocity controller model. It alternately evolves heterogeneous swarm and homogeneous swarm through a gene expression programming method that introduces reinforcement learning, and assembles function nodes and leaf nodes into new mathematical formulas during the evolution process. The method enable to realize the effect of swarm robots emerging to perform swarm tasks such as flocking and entrapping. What is more, a new swarm rule was discovered during the evolution process, which is used to realize the flocking of swarm robots at any angle. The experimental results show that the swarm motion controller automatically generated by the model has high task completion efficiency and strong generalization.},
  archive      = {J_SWEVO},
  author       = {Chen Wang and Cheng Zhu and Xianqiang Zhu and Hongtao Lei and Weiming Zhang and Meng Wu},
  doi          = {10.1016/j.swevo.2025.101854},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101854},
  shortjournal = {Swarm Evol. Comput.},
  title        = {DANCE: Distributed co-evolutionary design of velocity controllers for swarm intelligence robots in flocking and entrapping tasks},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary algorithm based on multi-probability
distribution model for stochastic optimization. <em>SWEVO</em>,
<em>94</em>, 101839. (<a
href="https://doi.org/10.1016/j.swevo.2024.101839">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic optimization, which aims at optimizing the expected value of a stochastic objective function, is challenging and commonly-seen in engineering applications. One crucial challenge of stochastic optimization problems (SOPs) is that the objective function value is impossible to calculate accurately due to the existence of uncertainty. As probability distribution is a common mathematical tool for handling uncertainty, this paper intends to explore the use of probability-distribution-based evolutionary algorithms (EAs) for solving complicated SOPs. First, an in-depth analysis of how to sample and construct probability distributions for probability-distribution-based EAs in SOPs is performed through both empirical and theoretical studies. Based on the analysis, it can be concluded that the implicit averaging method is helpful for probability-distribution-based EAs to solve SOPs. Second, evolutionary algorithm based on multiple probability distribution models (EA-mPD) framework is proposed. Instead of using a single probability distribution, the whole population is divided into several clusters by clustering, and several local probability models are built for different clusters. Finally, probability-distribution-based EAs such as estimation of distribution algorithm (EDA) and ant colony optimization (ACO) are introduced in the proposed EA-mPD to solve SOPs. Experimental results show that the proposed EA-mPD method is promising in terms of both accuracy and efficiency.},
  archive      = {J_SWEVO},
  author       = {Hao Cong and Xiao-Min Hu and Wei-Neng Chen and Wen Shi and Jun Zhang},
  doi          = {10.1016/j.swevo.2024.101839},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101839},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Evolutionary algorithm based on multi-probability distribution model for stochastic optimization},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="tcs---21">TCS - 21</h2>
<ul>
<li><details>
<summary>
(2025). Byzantine fault-tolerant protocols for (n,f)-evacuation from
a circle. <em>TCS</em>, <em>1038</em>, 115185. (<a
href="https://doi.org/10.1016/j.tcs.2025.115185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we address the problem of ( n , f ) -evacuation on a circle, which involves evacuating n robots, with f of them being faulty, from a hidden exit located on the perimeter of a unit radius circle. The robots commence at the center of the circle and possess a speed of 1. We introduce algorithms for both the Wireless and Face-to-Face communication models tolerating f Byzantine faults. We set constraints on f and we analyze the time requirements of these algorithms and we establish upper bounds on their performance. We propose an algorithm for the Wireless communication model, proving the following upper bound E ( n , f ) ≤ 1 + ( f + 1 ) ⋅ 2 π n + max ⁡ { G e ( k ⁎ ) , H e ( k ⁎ ) } where G e ( k ⁎ ) and H e ( k ⁎ ) is the time needed to evacuate two crucial groups of robots, during the execution of our algorithm. For the Face-to-Face communication model we propose an algorithm and we prove an upper bound of E ( n , f ) ≤ 3 + ( f + 1 ) ⋅ 2 π n + max 2 ≤ k ≤ n ⁡ { 2 ( k − 1 ) ⋅ sin ⁡ ( f − k + 2 k − 1 ⋅ π n ) } where k is the number of conflicting accounts of the exit position.},
  archive      = {J_TCS},
  author       = {Pourandokht Behrouz and Orestis Konstantinidis and Nikos Leonardos and Aris Pagourtzis and Ioannis Papaioannou and Marianna Spyrakou},
  doi          = {10.1016/j.tcs.2025.115185},
  journal      = {Theoretical Computer Science},
  month        = {5},
  pages        = {115185},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Byzantine fault-tolerant protocols for (n,f)-evacuation from a circle},
  volume       = {1038},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unfolding state variables improves model checking
performance. <em>TCS</em>, <em>1038</em>, 115181. (<a
href="https://doi.org/10.1016/j.tcs.2025.115181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When describing the behavior of systems, state variables are typically modeled using complex data types. This use of data types allows for concise models that are easy to read. However, model checking tools that aim to automatically establish the correctness of such models use static analyses of state variables to improve their performance. Therefore, the use of complex data types in behavioral models negatively affects the performance of model checking tools. To address this, in this article we revisit a technique by Groote and Lisser that can be used to replace a single state variable of a complex data type by multiple state variables of simpler data types. We introduce and study several extensions in the context of the process algebraic specification language mCRL2, and establish their correctness. We demonstrate that our technique typically reduces the verification times when using symbolic model checking, and show that sometimes it enables static analysis to reduce the underlying state space from infinite to finite.},
  archive      = {J_TCS},
  author       = {Anna Stramaglia and Jeroen J.A. Keiren and Thomas Neele},
  doi          = {10.1016/j.tcs.2025.115181},
  journal      = {Theoretical Computer Science},
  month        = {5},
  pages        = {115181},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Unfolding state variables improves model checking performance},
  volume       = {1038},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A signature scheme constructed from zero knowledge argument
of knowledge for the subgraph isomorphism problem. <em>TCS</em>,
<em>1038</em>, 115180. (<a
href="https://doi.org/10.1016/j.tcs.2025.115180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose an honest-verifier zero knowledge argument of knowledge for subgraph isomorphism and convert it into a signature scheme by using the well-known Fiat-Shamir transformation. Our protocol generalizes the famous Blum&#39;s zero knowledge proof for graph Hamiltonicity, but with a major difference: we additionally commit to the permuted subgraph isomorphism during commitment phase. This modification is made to satisfy a property called “quantum computationally unique response”, which ensures that an efficient quantum adversary cannot distinguish whether the superposition of the response is measured. This property is utilized to prove that the resulting signature scheme achieves EUF-CMA security in the quantum random oracle model.},
  archive      = {J_TCS},
  author       = {Chii Liang Ng and Denis C.K. Wong and Gek L. Chia and Bok Min Goi and Wai Kong Lee and Wun She Yap},
  doi          = {10.1016/j.tcs.2025.115180},
  journal      = {Theoretical Computer Science},
  month        = {5},
  pages        = {115180},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A signature scheme constructed from zero knowledge argument of knowledge for the subgraph isomorphism problem},
  volume       = {1038},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Move-optimal arbitrary pattern formation by mobile robots on
rectangular grid using near-optimal spatial area. <em>TCS</em>,
<em>1038</em>, 115179. (<a
href="https://doi.org/10.1016/j.tcs.2025.115179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Arbitrary pattern formation (APF) is a well-studied problem in swarm robotics. To the best of our knowledge, the problem has been considered in two different settings: one in a euclidean plane and another in an infinite grid. This work deals with the problem in an infinite rectangular grid setting. The previous works in literature dealing with the APF problem in an infinite grid had a fundamental issue. These deterministic algorithms use a lot of spatial area in the grid to solve the problem, mainly to maintain the asymmetry of the configuration and avoid any collision. These solution techniques cannot be useful if there is a spatial constraint in the application field. In this work, we consider luminous robots (each robot equipped with a light that can take three colors) to avoid symmetry, but we carefully designed a deterministic algorithm that solves the APF problem using the minimal required spatial area in the grid if the initial pattern is asymmetric. The robots are autonomous, identical, and anonymous, and they operate in Look-Compute-Move cycles under a fully-asynchronous scheduler. The APF algorithm proposed in [1] by Bose et al. can be modified using luminous robots so that it uses minimal spatial area, but that algorithm is not move-optimal. The algorithm proposed in this paper not only uses minimal spatial area but is also asymptotically move-optimal.},
  archive      = {J_TCS},
  author       = {Avisek Sharma and Satakshi Ghosh and Pritam Goswami and Buddhadeb Sau},
  doi          = {10.1016/j.tcs.2025.115179},
  journal      = {Theoretical Computer Science},
  month        = {5},
  pages        = {115179},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Move-optimal arbitrary pattern formation by mobile robots on rectangular grid using near-optimal spatial area},
  volume       = {1038},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Theoretical foundations for parent divorcing transformations
in bayesian networks. <em>TCS</em>, <em>1038</em>, 115176. (<a
href="https://doi.org/10.1016/j.tcs.2025.115176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parent divorcing is a commonly used technique to reduce the complexity of Bayesian models. In particular, this transformation decreases the number of parents of some nodes in a given Bayesian Network (BN). Such transformations must be done in such a way that solutions to inference problems for the original BN can be readily obtained from the solutions to the new BN. Despite its wide use in practice, there have been no attempts to formally analyze these transformations. In this work, we present a first step towards the development of theoretical foundations for the use of divorce transformations in BNs and establish analytical results. Specifically, we develop a formalism that captures a structural relationship between the original BN and the new BN. Using this formalism, we present an algorithm for parent divorcing which ensures that the treewidth of the modified BN is within a constant factor of that of the original BN. We also present an algorithm that carries out parent divorcing while preserving the domain size of each node. Further, we present lower bound results to prove that there are BNs for which parent divorcing transformations can cause an exponential increase in the domain size or lead to an exponentially large new BN.},
  archive      = {J_TCS},
  author       = {Daniel J. Rosenkrantz and Madhav V. Marathe and Zirou Qiu and S.S. Ravi},
  doi          = {10.1016/j.tcs.2025.115176},
  journal      = {Theoretical Computer Science},
  month        = {5},
  pages        = {115176},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Theoretical foundations for parent divorcing transformations in bayesian networks},
  volume       = {1038},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Compact zero-knowledge arguments for blum integers.
<em>TCS</em>, <em>1038</em>, 115155. (<a
href="https://doi.org/10.1016/j.tcs.2025.115155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a communication-efficient zero-knowledge argument of knowledge for the factorization of Blum integers, a special class of integers of the form n = p q , where p and q are distinct prime numbers satisfying p ≡ q ≡ 3 mod 4 and p ≃ q ≃ n . Existing protocols for proving such statements often incur significant communication costs, especially when demonstrating that p and q are of nearly equal size. We leverage the MPC-in-the-head paradigm, a cryptographic technique that transforms secure multi-party computation protocols into efficient zero-knowledge proof systems. In our protocol, the prover uses additive sharing of p and q over the integers. This approach simplifies proving the size relationship p ≃ q ≃ n and the congruence p ≡ q ≡ 3 mod 4 without requiring costly range proofs. To verify the primality of p and q , we employ the Boneh-Franklin biprimality test. Our protocol achieves a significant reduction in communication complexity. For a 2048-bit integer n and 128-bit security, we construct an argument as small as 6.3 KB, with prover and verifier computational costs comparable to existing protocols that require over 131 KB.},
  archive      = {J_TCS},
  author       = {Jules Maire and Damien Vergnaud},
  doi          = {10.1016/j.tcs.2025.115155},
  journal      = {Theoretical Computer Science},
  month        = {5},
  pages        = {115155},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Compact zero-knowledge arguments for blum integers},
  volume       = {1038},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reconfigurable routing in data center networks.
<em>TCS</em>, <em>1038</em>, 115154. (<a
href="https://doi.org/10.1016/j.tcs.2025.115154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A hybrid network is a static (electronic) network that is augmented with optical switches. The Reconfigurable Routing Problem (RRP) in hybrid networks is the problem of finding settings for the optical switches augmenting a static network so as to achieve optimal delivery of some given workload. The problem has previously been studied in various scenarios with both tractability and NP-hardness results obtained. However, the data center and interconnection networks to which the problem is most relevant are almost always such that the static network is highly structured (and often node-symmetric) whereas all previous results assume that the static network can be arbitrary (which makes existing computational hardness results less technologically relevant and also easier to obtain). In this paper, and for the first time, we prove various intractability results for RRP where the underlying static network is highly structured, for example consisting of a hypercube, and also extend some existing tractability results.},
  archive      = {J_TCS},
  author       = {David C. Kutner and Iain A. Stewart},
  doi          = {10.1016/j.tcs.2025.115154},
  journal      = {Theoretical Computer Science},
  month        = {5},
  pages        = {115154},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Reconfigurable routing in data center networks},
  volume       = {1038},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Some new results on equitable tree-coloring parameters of
graphs. <em>TCS</em>, <em>1037</em>, 115178. (<a
href="https://doi.org/10.1016/j.tcs.2025.115178">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Equitable tree-coloring addresses a structure decomposition problem in communication networks while considering security aspects. Specifically, an equitable tree- t -coloring of a graph is a vertex t -coloring such that each color class induces a forest and the size of any two color classes differs by at most one. This paper demonstrated if G is an equitably tree- t -colorable graph and H is an arbitrary graph with less than 2 t vertices ( n &lt; 2 t ), it is possible to construct an equitable tree- t -coloring of the corona product graph G ∘ H in cubic time. Additionally, the equitable tree-coloring of the extended corona product formed by combining graphs G and H has also been investigated.},
  archive      = {J_TCS},
  author       = {Bei Niu},
  doi          = {10.1016/j.tcs.2025.115178},
  journal      = {Theoretical Computer Science},
  month        = {5},
  pages        = {115178},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Some new results on equitable tree-coloring parameters of graphs},
  volume       = {1037},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Kolmogorov-loveland betting strategies lose the betting game
on open sets. <em>TCS</em>, <em>1037</em>, 115177. (<a
href="https://doi.org/10.1016/j.tcs.2025.115177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Whether Kolmogorov-Loveland randomness (KLR) is the same as Martin-Löf randomness (MLR) is a major open problem in the study of algorithmic randomness. More general classes of betting strategies than Kolmogorov-Loveland ones have been studied in [8] , [13] , [12] . In each case it was proven that the class induces a notion of randomness equivalent to MLR. In all of those proofs, it was shown that the class contains a finite set of betting strategies such that for any given bound, when betting on a binary sequence contained in an effective open set of small enough measure, at least one of the betting strategies in the set earns capital larger than the bound. We show that the class of Kolmogorov-Loveland betting strategies does not have this property.},
  archive      = {J_TCS},
  author       = {Tomislav Petrović},
  doi          = {10.1016/j.tcs.2025.115177},
  journal      = {Theoretical Computer Science},
  month        = {5},
  pages        = {115177},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Kolmogorov-loveland betting strategies lose the betting game on open sets},
  volume       = {1037},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On 1-planar graphs with bounded cop-number. <em>TCS</em>,
<em>1037</em>, 115160. (<a
href="https://doi.org/10.1016/j.tcs.2025.115160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cops and Robbers is a type of pursuit-evasion game played on a graph where a set of cops try to capture a single robber. The cops first choose their initial vertex positions, and later the robber chooses a vertex. The cops and robbers make their moves in alternate turns: in the cops&#39; turn, every cop can either choose to move to an adjacent vertex or stay on the same vertex, and likewise the robber in his turn. If the cops can capture the robber in a finite number of rounds, the cops win, otherwise the robber wins. The cop-number of a graph is the minimum number of cops required to catch a robber in the graph. It has long been known that graphs embedded on surfaces (such as planar graphs and toroidal graphs) have a small cop-number. Recently, Durocher et al. [21] investigated the problem of cop-number for the class of 1-planar graphs, which are graphs that can be embedded in the plane such that each edge is crossed at most once. They showed that unlike planar graphs which require just three cops, 1-planar graphs have an unbounded cop-number. On the positive side, they showed that maximal 1-planar graphs require only three cops by crucially using the fact that the endpoints of every crossing in an embedded maximal 1-planar graph induce a K 4 . In this paper, we show that the cop-number remains bounded even under the relaxed condition that the endpoints induce at least three edges. More precisely, let an ×-crossing of an embedded 1-planar graph be a crossing whose endpoints induce a matching; i.e., there is no edge connecting the endpoints apart from the crossing edges themselves. We show that any 1-planar graph that can be embedded without ×-crossings has cop-number at most 21. Moreover, any 1-planar graph that can be embedded with at most γ ×-crossings has cop-number at most γ + 21 .},
  archive      = {J_TCS},
  author       = {Prosenjit Bose and Jean-Lou De Carufel and Anil Maheshwari and Karthik Murali},
  doi          = {10.1016/j.tcs.2025.115160},
  journal      = {Theoretical Computer Science},
  month        = {5},
  pages        = {115160},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On 1-planar graphs with bounded cop-number},
  volume       = {1037},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complete decomposition of symmetric tensors in linear time
and polylogarithmic precision. <em>TCS</em>, <em>1037</em>, 115159. (<a
href="https://doi.org/10.1016/j.tcs.2025.115159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study symmetric tensor decompositions, i.e., decompositions of the form T = ∑ i = 1 r u i ⊗ 3 where T is a symmetric tensor of order 3 and u i ∈ C n . In order to obtain efficient decomposition algorithms, it is necessary to require additional properties from the u i . In this paper we assume that the u i are linearly independent. This implies r ≤ n , i.e., the decomposition of T is undercomplete . We will moreover assume that r = n (we plan to extend this work to the case r &lt; n in a forthcoming paper). We give a randomized algorithm for the following problem: given T , an accuracy parameter ε , and an upper bound B on the condition number of the tensor, output vectors u i ′ such that | | u i − u i ′ | | ≤ ε (up to permutation and multiplication by phases) with high probability. The main novel features of our algorithm are: • We provide the first algorithm for this problem that works in the computation model of finite arithmetic and requires only poly-logarithmic (in n , B and 1 ε ) many bits of precision. • Moreover, this is also the first algorithm that runs in linear time in the size of the input tensor. It requires O ( n 3 ) arithmetic operations for all accuracy parameters ε = 1 poly ( n ) . In order to obtain these results, we rely on a mix of techniques from algorithm design and algorithm analysis. The algorithm is a modified version of simultaneous diagonalisation algorithm for symmetric tensors. In terms of algorithm design, our main contribution lies in replacing the usual appeal to resolution of a linear system of equations [30] , [7] by a matrix trace-based method. The analysis of the algorithm depends on the following components: 1. We use the fast and numerically stable diagonalisation algorithm from [9] . We provide better guarantees for the approximate solution returned by the diagonalisation algorithm when the input matrix is diagonalisable. 2. We show strong anti-concentration bounds for certain families of polynomials when the randomness is sampled uniformly from a discrete grid.},
  archive      = {J_TCS},
  author       = {Pascal Koiran and Subhayan Saha},
  doi          = {10.1016/j.tcs.2025.115159},
  journal      = {Theoretical Computer Science},
  month        = {5},
  pages        = {115159},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Complete decomposition of symmetric tensors in linear time and polylogarithmic precision},
  volume       = {1037},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). (Min⁡,+) matrix and vector products for inputs decomposable
into few monotone subsequences. <em>TCS</em>, <em>1037</em>, 115158. (<a
href="https://doi.org/10.1016/j.tcs.2025.115158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the time complexity of computing the ( min ⁡ , + ) matrix product of two n × n integer matrices in terms of n and the number of monotone subsequences the rows of the first matrix and the columns of the second matrix can be decomposed into. In particular, we show that if each row of the first matrix can be decomposed into at most m 1 monotone subsequences and each column of the second matrix can be decomposed into at most m 2 monotone subsequences such that all the subsequences are non-decreasing or all of them are non-increasing then the ( min ⁡ , + ) product of the matrices can be computed in O ( m 1 m 2 n 2.569 ) time. On the other hand, we observe that if all the rows of the first matrix are non-decreasing and all columns of the second matrix are non-increasing or vice versa then this case is as hard as the general one. We also present six cases of the restrictions on the input integer matrices under which the problem of computing the ( min ⁡ , + ) matrix product is equally hard as that of computing the minimum and maximum witnesses of Boolean matrix product. Similarly, we also study the time complexity of computing the ( min ⁡ , + ) convolution of two n -dimensional integer vectors in terms of n and the number of monotone subsequences the two vectors can be decomposed into. We show that if the first vector can be decomposed into at most m 1 monotone subsequences and the second vector can be decomposed into at most m 2 subsequences such that all the subsequences of the first vector are non-decreasing and all the subsequences of the second vector are non-increasing or vice versa then their ( min ⁡ , + ) convolution can be computed in O ˜ ( m 1 m 2 n 1.5 ) time. On the other, the case when both sequences of consecutive coordinates of the vectors are non-decreasing or both of them are non-increasing is as hard as the general case. Finally, we present six cases of the restrictions on the input integer vectors under which the problem of computing the ( min ⁡ , + ) vector convolution is equally hard as that of computing the minimum and maximum witnesses of the Boolean vector convolution.},
  archive      = {J_TCS},
  author       = {Andrzej Lingas and Mia Persson},
  doi          = {10.1016/j.tcs.2025.115158},
  journal      = {Theoretical Computer Science},
  month        = {5},
  pages        = {115158},
  shortjournal = {Theor. Comput. Sci.},
  title        = {(min⁡,+) matrix and vector products for inputs decomposable into few monotone subsequences},
  volume       = {1037},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving NP-hard problems on GaTEx graphs: Linear-time
algorithms for perfect orderings, cliques, colorings, and independent
sets. <em>TCS</em>, <em>1037</em>, 115157. (<a
href="https://doi.org/10.1016/j.tcs.2025.115157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The class of Ga lled- T ree Ex plainable ( GaTEx ) graphs has recently been discovered as a natural generalization of cographs. Cographs are precisely those graphs that can be uniquely represented by a rooted tree where the leaves correspond to the vertices of the graph. As a generalization, GaTEx graphs are precisely those that can be uniquely represented by a particular rooted acyclic network, called a galled-tree. This paper explores the use of galled-trees to solve combinatorial problems on GaTEx graphs that are, in general, NP-hard. We demonstrate that finding a maximum clique, an optimal vertex coloring, a perfect order, as well as a maximum independent set in GaTEx graphs can be efficiently done in linear time. The key idea behind the linear-time algorithms is to utilize the galled-trees that explain the GaTEx graphs as a guide for computing the respective cliques, colorings, perfect orders, or independent sets.},
  archive      = {J_TCS},
  author       = {Marc Hellmuth and Guillaume E. Scholz},
  doi          = {10.1016/j.tcs.2025.115157},
  journal      = {Theoretical Computer Science},
  month        = {5},
  pages        = {115157},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Solving NP-hard problems on GaTEx graphs: Linear-time algorithms for perfect orderings, cliques, colorings, and independent sets},
  volume       = {1037},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The exact spanning ratio of the parallelogram delaunay
graph. <em>TCS</em>, <em>1037</em>, 115152. (<a
href="https://doi.org/10.1016/j.tcs.2025.115152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding the exact spanning ratio of a Delaunay graph has been one of the longstanding open problems in Computational Geometry. Currently there are only four convex shapes for which the exact spanning ratio of their Delaunay graph is known: the equilateral triangle, the square, the regular hexagon and the rectangle. We add a fifth convex shape by proving the exact spanning ratio of the parallelogram Delaunay graph. The worst-case spanning ratio is exactly 2 1 + A 2 + 2 A cos ⁡ ( θ 0 ) + ( A + cos ⁡ ( θ 0 ) ) 1 + A 2 + 2 A cos ⁡ ( θ 0 ) sin ⁡ ( θ 0 ) , where A is the aspect ratio and θ 0 is the non-obtuse angle of the parallelogram.},
  archive      = {J_TCS},
  author       = {Prosenjit Bose and Jean-Lou De Carufel and Sandrine Njoo},
  doi          = {10.1016/j.tcs.2025.115152},
  journal      = {Theoretical Computer Science},
  month        = {5},
  pages        = {115152},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The exact spanning ratio of the parallelogram delaunay graph},
  volume       = {1037},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Closure and decision properties for higher-dimensional
automata. <em>TCS</em>, <em>1036</em>, 115156. (<a
href="https://doi.org/10.1016/j.tcs.2025.115156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We report some further developments regarding the language theory of higher-dimensional automata (HDAs). Regular languages of HDAs are sets of finite interval partially ordered multisets (pomsets) with interfaces. We show a pumping lemma which allows us to expose a class of non-regular languages. Concerning decision and closure properties, we show that inclusion of regular languages is decidable (hence is emptiness), and that intersections of regular languages are again regular. Yet complements of regular languages are not always regular. We introduce a width-bounded complement and show that width-bounded complements of regular languages are again regular. We also study determinism and ambiguity. We show that it is decidable whether a regular language is accepted by a deterministic HDA and that there exist regular languages with unbounded ambiguity. Finally, we characterize one-letter deterministic languages in terms of ultimately periodic functions.},
  archive      = {J_TCS},
  author       = {Amazigh Amrane and Hugo Bazille and Uli Fahrenberg and Krzysztof Ziemiański},
  doi          = {10.1016/j.tcs.2025.115156},
  journal      = {Theoretical Computer Science},
  month        = {5},
  pages        = {115156},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Closure and decision properties for higher-dimensional automata},
  volume       = {1036},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Computational power of autonomous robots: Transparency
vs. opaqueness. <em>TCS</em>, <em>1036</em>, 115153. (<a
href="https://doi.org/10.1016/j.tcs.2025.115153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The research on distributed computing by robot swarms has formalized different models where robots act through a sequence of Look-Compute-Move cycles in the Euclidean plane. Models mostly under study differ for (i) the possibility of storing constant-size information, (ii) the possibility of communicating constant-size information, (iii) the synchronization mode, and (iv) the visibility of robots. By varying features (i) and (ii) , we obtain the noted four base models: OBLOT (silent and oblivious robots), FSTA (silent and finite-state robots), FCOM (oblivious and finite-communication robots), and LUMI (finite-state and finite-communication robots). Feature (iii) comprehends the three main synchronization modes: fully synchronous , semi-synchronous , and asynchronous . According to robot visibility (iv) , models can assume robots to be transparent (thus enjoying complete visibility ) or opaque (thus experiencing obstructed visibility in case of collinearities). By combining features (i-iv) , we obtain 24 models. Extensive research has studied the computational power of the 12 transparent models, proving the hierarchical relations among them; to this regard, it is worth noticing that robots have been assumed to be collision-tolerant. In this work, we assume our robots to be collision-intolerant and we lay down the computational hierarchy by considering all 24 models. Firstly, we study the relations between the transparent and the opaque framework, focusing on how obstructed visibility affects the computational power of a model. Then, we introduce five witness problems that prove most of the computational relations among the 24 models.},
  archive      = {J_TCS},
  author       = {Caterina Feletti and Lucia Mambretti and Carlo Mereghetti and Beatrice Palano},
  doi          = {10.1016/j.tcs.2025.115153},
  journal      = {Theoretical Computer Science},
  month        = {5},
  pages        = {115153},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Computational power of autonomous robots: Transparency vs. opaqueness},
  volume       = {1036},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ordinal maximin guarantees for group fair division.
<em>TCS</em>, <em>1036</em>, 115151. (<a
href="https://doi.org/10.1016/j.tcs.2025.115151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate fairness in the allocation of indivisible items among groups of agents using the notion of maximin share (MMS). While previous work has shown that no nontrivial multiplicative MMS approximation can be guaranteed in this setting for general group sizes, we demonstrate that ordinal relaxations are much more useful. For example, we show that if n agents are distributed equally across g groups, there exists a 1-out-of- k MMS allocation for k = O ( g log ⁡ ( n / g ) ) , while if all but a constant number of agents are in the same group, we obtain k = O ( log ⁡ n / log ⁡ log ⁡ n ) . We also establish the tightness of these bounds and provide non-asymptotic results for the case of two groups. Our proofs leverage connections to combinatorial covering designs.},
  archive      = {J_TCS},
  author       = {Pasin Manurangsi and Warut Suksompong},
  doi          = {10.1016/j.tcs.2025.115151},
  journal      = {Theoretical Computer Science},
  month        = {5},
  pages        = {115151},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Ordinal maximin guarantees for group fair division},
  volume       = {1036},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bribery in elections with randomly selected voters: Hardness
and algorithm. <em>TCS</em>, <em>1036</em>, 115150. (<a
href="https://doi.org/10.1016/j.tcs.2025.115150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many research works in computational social choice assume a fixed set of voters in an election and study the resistance of different voting rules against electoral manipulation. In recent years, however, a new technique known as random sample voting has been adopted in many multi-agent systems. One of the most prominent examples is blockchain. Many proof-of-stake based blockchain systems like Algorand will randomly select a subset of participants of the system to form a committee, and only the committee members will be involved in the decision of some important system parameters. This can be viewed as running an election where the voter committee (i.e., the voters whose votes will be counted) is randomly selected. It is generally expected that the introduction of such randomness should make the election more resistant to electoral manipulation, despite the lack of theoretical analysis. In this paper, we present a systematic study on the resistance of an election with a randomly selected voter committee against bribery. Since the committee is randomly generated, by bribing any fixed subset of voters, the designated candidate may or may not win. Consequently, we consider the problem of finding a feasible solution that maximizes the winning probability of the designated candidate. We show that for most voting rules, this problem becomes extremely difficult for the briber as even finding any non-trivial solution with non-zero objective value becomes NP-hard. However, for plurality and veto, there exists a polynomial time approximation scheme that computes a near-optimal solution efficiently. The algorithm builds upon a novel integer programming formulation together with techniques from n -fold integer programming, which may be of separate interest.},
  archive      = {J_TCS},
  author       = {Liangde Tao and Lin Chen and Lei Xu and Weidong Shi and Md Mahabub Uz Zaman and Ahmed Sunny},
  doi          = {10.1016/j.tcs.2025.115150},
  journal      = {Theoretical Computer Science},
  month        = {5},
  pages        = {115150},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Bribery in elections with randomly selected voters: Hardness and algorithm},
  volume       = {1036},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weighted connected matchings. <em>TCS</em>, <em>1036</em>,
115149. (<a href="https://doi.org/10.1016/j.tcs.2025.115149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A matching M of a graph is a P -matching if the subgraph induced by the endpoints of the edges of M satisfies property P . As examples, for appropriate choices of P , the problems Induced Matching , Uniquely Restricted Matching , Connected Matching and Disconnected Matching arise. For many of these problems, finding a P -matching of a given size is a known problem, with few exceptions, such as Connected Matching , which has the same time complexity as the usual Maximum Matching problem. The weighted variant of Maximum Matching has been studied for decades, with many applications, including the well-known Assignment problem. Motivated by this fact and by some recent research in weighted versions of acyclic and induced matchings, we study Maximum Weight Connected Matching and its decision version, Weighted Connected Matching . The former problem asks for a matching M such that the endpoints of its edges induce a connected subgraph and the sum of the edge weights of M is maximum, while the latter asks if there is an M of at least a given weight. Unlike the unweighted Connected Matching problem, which is in ¶ for general graphs, we show that Weighted Connected Matching is even for bounded diameter bipartite graphs, starlike graphs, planar bipartite graphs, and 3-regular planar graphs, while solvable in linear time for trees and for graphs of maximum degree at most two. When we restrict edge weights to be non-negative, we show that the problem turns out to be polynomially solvable for chordal graphs, while it remains for most of the other cases. In addition, we consider the parameterized complexity of the problem. On the positive side, we present a single-exponential time algorithm when parameterized by treewidth. As for kernelization, we show that, even when restricted to binary weights, Weighted Connected Matching does not admit a polynomial kernel when parameterized by vertex cover number under standard complexity-theoretical hypotheses.},
  archive      = {J_TCS},
  author       = {Guilherme C.M. Gomes and Bruno P. Masquio and Paulo E.D. Pinto and Vinicius F. dos Santos and Jayme L. Szwarcfiter},
  doi          = {10.1016/j.tcs.2025.115149},
  journal      = {Theoretical Computer Science},
  month        = {5},
  pages        = {115149},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Weighted connected matchings},
  volume       = {1036},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Notes on smyth-completes and local yoneda-completes.
<em>TCS</em>, <em>1036</em>, 115148. (<a
href="https://doi.org/10.1016/j.tcs.2025.115148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we first introduce the notion of d -net which is obtained being inspired by an elegant characterization: a quasi-metric space ( X , d ) is Smyth-complete if and only if B ( X , d ) is sober in its open ball topology. Then, we obtain the characterizations of Smyth-complete quasi-metric spaces via d -nets in quasi-metric spaces. Or rather, we prove that a quasi-metric space is Smyth-complete if and only if every d -net has a d -limit and converges to its d -limit. For a local Yoneda-complete quasi-metric space, we provide a necessary and sufficient condition such that the open ball topology coincides with the Scott topology on its formal ball space. In addition, we show that local Yoneda-completeness is preserved by some constructions, such as coproducts, products, function spaces, formal ball spaces and so on. Finally, we prove that the formal ball construction B induces the monads on the categories of Smyth-complete quasi-metric spaces with 1-Lipschitz maps, local Yoneda-complete quasi-metric spaces with 1-Lipschitz maps, Smyth-complete quasi-metric spaces with Y-continuous maps and local Yoneda-complete quasi-metric spaces with Y-continuous maps.},
  archive      = {J_TCS},
  author       = {Zhenhua Jia and Qingguo Li},
  doi          = {10.1016/j.tcs.2025.115148},
  journal      = {Theoretical Computer Science},
  month        = {5},
  pages        = {115148},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Notes on smyth-completes and local yoneda-completes},
  volume       = {1036},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sequential decision based learning method for influence
maximization. <em>TCS</em>, <em>1036</em>, 115147. (<a
href="https://doi.org/10.1016/j.tcs.2025.115147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influence maximization (IM) involves choosing an initial group of users within a social network to optimize the expected spread of influence across other users. Recently, learning-based combinatorial optimization (CO) methods have been developed to learn generalized policies for specific CO problems on graphs. However, current learning-based algorithms struggle with diverse diffusion patterns, which restricts their generalization ability. In this paper, we apply reverse influence sampling to simplify the IM problem, reducing it to a stochastic maximum coverage problem using hyperedges. We then model this as a Markov decision process and propose two sequential decision-based learning methods. These methods leverage the symmetry of solutions with respect to sequence order and utilize the submodular reward function. By jointly training on multiple graphs, our approach learns a transferable seed selection policy that generalizes effectively to previously unseen test graphs. Extensive experiments demonstrate that our method outperforms recent learning-based approaches as well as traditional methods on both real and synthetic datasets for the IM problem.},
  archive      = {J_TCS},
  author       = {Zizhen Zhang and Deying Li and Yongcai Wang and Wenping Chen and Yuqing Zhu},
  doi          = {10.1016/j.tcs.2025.115147},
  journal      = {Theoretical Computer Science},
  month        = {5},
  pages        = {115147},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Sequential decision based learning method for influence maximization},
  volume       = {1036},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
