<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AIJ_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aij---3">AIJ - 3</h2>
<ul>
<li><details>
<summary>
(2025). ICCMA 2023: 5th international competition on computational
models of argumentation. <em>AIJ</em>, <em>342</em>, 104311. (<a
href="https://doi.org/10.1016/j.artint.2025.104311">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study of computational models of argumentation and the development of practical automated approaches to reasoning over the models has developed into a vibrant area of artificial intelligence research in recent years. The series of International Competitions on Computational Models of Argumentation (ICCMA) aims at nurturing research and development of practical reasoning algorithms for models of argumentation. Organized biennially, the ICCMA competitions provide a snapshot of the current state of the art in algorithm implementations for central fundamental reasoning tasks over models of argumentation. The year 2023 marked the 5th instantiation of International Competitions on Computational Models of Argumentation, ICCMA 2023. We provide a comprehensive overview of ICCMA 2023, including details on the various new developments introduced in 2023, overview of the participating solvers, extensive details on the competition benchmarks and results, as well as lessons learned.},
  archive      = {J_AIJ},
  author       = {Matti Järvisalo and Tuomo Lehtonen and Andreas Niskanen},
  doi          = {10.1016/j.artint.2025.104311},
  journal      = {Artificial Intelligence},
  month        = {5},
  pages        = {104311},
  shortjournal = {Artif. Intell.},
  title        = {ICCMA 2023: 5th international competition on computational models of argumentation},
  volume       = {342},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lifted inference beyond first-order logic. <em>AIJ</em>,
<em>342</em>, 104310. (<a
href="https://doi.org/10.1016/j.artint.2025.104310">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weighted First Order Model Counting (WFOMC) is fundamental to probabilistic inference in statistical relational learning models. As WFOMC is known to be intractable in general (#P-complete), logical fragments that admit polynomial time WFOMC are of significant interest. Such fragments are called domain liftable . Recent works have shown that the two-variable fragment of first order logic extended with counting quantifiers (C 2 ) is domain-liftable. However, many properties of real-world data, like acyclicity in citation networks and connectivity in social networks, cannot be modeled in C 2 , or first order logic in general. In this work, we expand the domain liftability of C 2 with multiple such properties. We show that any C 2 sentence remains domain liftable when one of its relations is restricted to represent a directed acyclic graph, a connected graph, a tree (resp. a directed tree) or a forest (resp. a directed forest). All our results rely on a novel and general methodology of counting by splitting . Besides their application to probabilistic inference, our results provide a general framework for counting combinatorial structures. We expand a vast array of previous results in discrete mathematics literature on directed acyclic graphs, phylogenetic networks, etc.},
  archive      = {J_AIJ},
  author       = {Sagar Malhotra and Davide Bizzaro and Luciano Serafini},
  doi          = {10.1016/j.artint.2025.104310},
  journal      = {Artificial Intelligence},
  month        = {5},
  pages        = {104310},
  shortjournal = {Artif. Intell.},
  title        = {Lifted inference beyond first-order logic},
  volume       = {342},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). (Re)conceptualizing trustworthy AI: A foundation for change.
<em>AIJ</em>, <em>342</em>, 104309. (<a
href="https://doi.org/10.1016/j.artint.2025.104309">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developers and academics have grown increasingly interested in developing “trustworthy” artificial intelligence (AI). However, this aim is difficult to achieve in practice, especially given trust and trustworthiness are complex, multifaceted concepts that cannot be completely guaranteed nor built entirely into an AI system. We have drawn on the breadth of trust-related literature across multiple disciplines and fields to synthesize knowledge pertaining to interpersonal trust, trust in automation, and risk and trust. Based on this review we have (re)conceptualized trustworthiness in practice as being both (a) perceptual, meaning that a user assesses whether, when, and to what extent AI model output is trustworthy, even if it has been developed in adherence to AI trustworthiness standards, and (b) context-dependent, meaning that a user&#39;s perceived trustworthiness and use of an AI model can vary based on the specifics of their situation (e.g., time-pressures for decision-making, high-stakes decisions). We provide our reconceptualization to nuance how trustworthiness is thought about, studied, and evaluated by the AI community in ways that are more aligned with past theoretical research.},
  archive      = {J_AIJ},
  author       = {Christopher D. Wirz and Julie L. Demuth and Ann Bostrom and Mariana G. Cains and Imme Ebert-Uphoff and David John Gagne II and Andrea Schumacher and Amy McGovern and Deianna Madlambayan},
  doi          = {10.1016/j.artint.2025.104309},
  journal      = {Artificial Intelligence},
  month        = {5},
  pages        = {104309},
  shortjournal = {Artif. Intell.},
  title        = {(Re)Conceptualizing trustworthy AI: A foundation for change},
  volume       = {342},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
