<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ASOC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="asoc---106">ASOC - 106</h2>
<ul>
<li><details>
<summary>
(2025). Data preprocessing techniques and neural networks for
trended time series forecasting. <em>ASOC</em>, <em>174</em>, 113063.
(<a href="https://doi.org/10.1016/j.asoc.2025.113063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on time series forecasting continues to attract significant attention, particularly in the use of Artificial Neural Networks (ANN) due to their ability to model nonlinear behaviors. However, forecasting economic time series with steep upward trends presents challenges, often leading to poorly fitting predictions. This study addresses the issue by applying differentiation as a preprocessing step. Three real-world time series exhibiting this behavior were analyzed and forecasted using two neural network models—Long Short-Term Memory (LSTM) and Multilayer Perceptron (MLP)—with and without preprocessing. The differentiated series were further processed using techniques such as Empirical Mode Decomposition (EMD) and trend-fluctuation decomposition via Moving Average of Wavelet Transform. The results demonstrate that differentiation significantly enhances forecasting accuracy across all tested models, reducing errors by up to 30 % compared to models without preprocessing. This approach effectively mitigates trend-related distortions, leading to more reliable predictions in complex economic time series.},
  archive      = {J_ASOC},
  author       = {Ana Lazcano and Miguel A. Jaramillo-Morán},
  doi          = {10.1016/j.asoc.2025.113063},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113063},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Data preprocessing techniques and neural networks for trended time series forecasting},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unveiling authenticity with diffusion-based face retouching
reversal. <em>ASOC</em>, <em>174</em>, 113062. (<a
href="https://doi.org/10.1016/j.asoc.2025.113062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unveiling the real appearance of retouched faces to prevent malicious users from deceptive advertising and economic fraud has been an increasing concern in the era of digital economics. This article makes the first attempt to investigate the face retouching reversal (FRR) problem. We first build an FRR dataset, named deepFRR, by collecting 50,000 StyleGAN-generated high-resolution (1024 × 1024) facial images and retouching them via a commercial online API. Then, we present a novel diffusion-based FRR network (FRRffusion) for the FRR task. Our FRRffusion consists of a coarse-to-fine two-stage architecture: A diffusion-based Facial Morpho-Architectonic Restorer (FMAR) is constructed to generate the basic contours of low-resolution faces in the first stage, while a Transformer-based Hyperrealistic Facial Detail Generator (HFDG) is designed to create high-resolution facial details in the second stage. Tested on deepFRR, our FRRffusion surpasses the state-of-the-art image restoration method with 22%, 11%, 20%, and 6% performance improvement in SSIM, PSNR, VGGS, and CLIPS, respectively. Especially, the de-retouched images by our FRRffusion are visually much closer to the raw face images than both the retouched face images and those restored by the state-of-the-art, like GP-UNIT and Stable Diffusion, in terms of qualitative evaluation with 85 subjects. These results sufficiently validate the efficacy of our FRRffusion, bridging the gap between the FRR and generic image restoration tasks. The code is available at https://github.com/GZHU-DVL/FRRffusion .},
  archive      = {J_ASOC},
  author       = {Fengchuang Xing and Xiaowen Shi and Yuan-Gen Wang and Chunsheng Yang},
  doi          = {10.1016/j.asoc.2025.113062},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113062},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Unveiling authenticity with diffusion-based face retouching reversal},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nested deep learning with learned network embeddings for
software defect prediction. <em>ASOC</em>, <em>174</em>, 113057. (<a
href="https://doi.org/10.1016/j.asoc.2025.113057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing software (SW) defect prediction approaches and the models are majorly based on features extracted from the code of the software to build defect datasets for predictive modeling. However, these models fail to sufficiently capture the complex, latent dependencies within the software components, which acts as a hindrance in achieving higher predictive accuracy. This study introduces an improved defect prediction model, the Nested Deep Learning (NDL) model, that leverages network embeddings from call graphs for enhanced representation of intricate hierarchical class dependencies and interactions. This work evaluates six network-embedding algorithms by applying them to call graphs of 10 real software projects, generating embeddings of dimensions 32 and 128. A total of 50 NDL models—with and without dropout layers—are developed, and a comparative evaluation of these models is conducted against traditional classifier-based models. This evaluation demonstrated the superiority of the NDL model with dropout, achieving a mean AUC of 0.87, an 8.98 % improvement over the traditional classifier-based models. Among the evaluated embedding methods, LINE embeddings outperformed others, and integrating network embeddings with software metrics led to a 15.85 % AUC improvement over using software metrics alone. The optimal configuration—combining software metrics with LINE embeddings (dimension 128) in an NDL model with three deep learning layers and dropout—achieved a mean AUC of 0.93, surpassing all other configurations by 3.33–14.81 % . This study is the first to validate the effectiveness of a nested deep learning framework for modeling call graph dependencies through network embeddings, providing a scalable and robust approach for improving software defect prediction.},
  archive      = {J_ASOC},
  author       = {Sweta Mehta and Lov Kumar and Sanjay Misra and K.Sridhar Patnaik and Vikram Singh},
  doi          = {10.1016/j.asoc.2025.113057},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113057},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Nested deep learning with learned network embeddings for software defect prediction},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view self-supervised learning on heterogeneous graphs
for recommendation. <em>ASOC</em>, <em>174</em>, 113056. (<a
href="https://doi.org/10.1016/j.asoc.2025.113056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have significantly contributed to data mining but face challenges due to sparse graph data and lack of labels. Typically, GNNs rely on simple feature aggregation to leverage unlabeled information, neglecting the richness inherent in unlabeled data within graphs. Graph self-supervised learning methods effectively capitalize on unlabeled information. Nevertheless, most existing graph self-supervised learning methods focus on homogeneous graphs, ignoring the heterogeneity of graphs and mainly considering the graph structure from a single perspective. These methods cannot fully capture the complex semantics and correlations in heterogeneous graphs. It is challenging to design self-supervised learning tasks that can fully capture and represent complex relationships in heterogeneous graphs. In order to address the above problems, we investigate the problem of self-supervised HGNN and propose a new self-supervised learning mechanism for HGNN called Multi-view Self-supervised Learning on Heterogeneous Graphs for Recommendation (MSRec). We introduce a maximum entropy path sampler to help sample meta-paths containing structural context. Encoding information from diverse views defined by various meta-paths, decoding it into a semantic space different from own and optimizing tasks in both local-view and global-view contrastive learning, which facilitates collaborative and mutually supervisory interactions between the two views, leveraging unlabeled information for node embedding learning effectively. According to experimental results, our method demonstrates an optimal performance improvement of approximately 7% in NDCG@10 and about 8% in Prec@10 compared to state-of-the-art models. The experimental results on three real-world datasets demonstrate the superior performance of MSRec compared to state-of-the-art recommendation methods.},
  archive      = {J_ASOC},
  author       = {Yunjia Zhang and Yihao Zhang and Weiwen Liao and Xiaokang Li and Xibin Wang},
  doi          = {10.1016/j.asoc.2025.113056},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113056},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-view self-supervised learning on heterogeneous graphs for recommendation},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-branch attention coupled convolutional domain
adaptation network for bearing intelligent fault recognition under
unlabeled sample scenarios. <em>ASOC</em>, <em>174</em>, 113053. (<a
href="https://doi.org/10.1016/j.asoc.2025.113053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bearing intelligent fault recognition is important to maintain the healthy and stable operation of mechanical equipment. However, it is difficult to have a consistent distribution of the acquired source and target domain data due to the constantly changing operating state of the equipment. Moreover, the acquisition of sufficient labeled data is constrained by both time and economic costs. Most of the existing recognition methods are difficult to perform effective fault recognition when faced with inconsistent data distribution and unlabeled small sample data. To address these issues, this paper proposes a multi-branch attention coupled convolutional domain adaptation network (MACCDAN) for unsupervised cross-domain fault recognition, which contains three unique parts. A cross-attention coupled module (CACM) is firstly designed between two parallel feature extraction branches to guide the intertwined coupling of the two branch features through a dual synergetic attention mechanism. A global feature aggregation module (GFAM) is further presented to conduct the global information fusion, which integrates the dependencies between different branch features and enhances the perception of key features. Additionally, the maximum-similarity minimum-discrepancy adversarial loss (MSMDAL) is formulated as an optimization objective to reduce the discrepancy between the source and target domain, and promote the learning of domain-invariant and discriminative features. The results of the four performance evaluation metrics (i.e., accuracy, precision, recall and F1 score) of the proposed method are all 1.0000 on two datasets. The F1 score of the proposed method is improved by at least 0.03 compared to other methods.},
  archive      = {J_ASOC},
  author       = {Maoyou Ye and Xiaoan Yan and Dong Jiang and Ning Chen},
  doi          = {10.1016/j.asoc.2025.113053},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113053},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-branch attention coupled convolutional domain adaptation network for bearing intelligent fault recognition under unlabeled sample scenarios},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A morphological difference and statistically sparse
transformer-based deep neural network for medical image segmentation.
<em>ASOC</em>, <em>174</em>, 113052. (<a
href="https://doi.org/10.1016/j.asoc.2025.113052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image segmentation plays a pivotal role in enhancing disease diagnosis and treatment planning. However, existing methods often struggle with the complexity of lesion boundaries and the computational demands of Transformer-based approaches. To address these challenges, we propose a morphological difference and statistically sparse Transformer-based deep neural network for medical image segmentation, termed MD-SSFormer. It comprises two critical modules: the dual branch encoder (DBEncoder) module, and the morphological difference catcher (MDC). To extract abundant information at different aspects, a novel DBEncoder module integrates the capability of the convolutional neural network-based method in capturing local texture and the ability of the Transformer-based method in modeling global information. Compared to the conventional feature extraction methods, DBEncoder achieves comprehensive improvement. Furthermore, the statistics-based sparse Transformer (SSFormer) module develops an innovative statistical analysis and an adaptive patch-dividing strategy to perform attention-computing, which addresses the computational challenges associated with conventional Transformer-based models. Finally, considering the impacts of the blurry and complex boundaries, the MDC module employs the morphological operation and differential information extractor to refine the details, which achieves high-precision boundary understanding. Experimental results on five public datasets demonstrate MD-SSFormer&#39;s superior performance, achieving state-of-the-art Dice scores of 83.60 % on ISIC 2017, 79.52 % on Kvasir-SEG, 61.89 % on BUSI, 78.62 % on BraTS21, and 85.85 % on 3DIRCADb, outperforming other methods in accuracy, precision, and computational efficiency respectively.},
  archive      = {J_ASOC},
  author       = {Dongxu Cheng and Zifang Zhou and Hao Li and Jingwen Zhang and Yan Yang},
  doi          = {10.1016/j.asoc.2025.113052},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113052},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A morphological difference and statistically sparse transformer-based deep neural network for medical image segmentation},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A heuristic-based multi-stage machine learning-based model
to design a sustainable, resilient, and agile reverse corn supply chain
by considering third-party recycling. <em>ASOC</em>, <em>174</em>,
113042. (<a href="https://doi.org/10.1016/j.asoc.2025.113042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the reverse supply chain configuration problem for the agri-food sector with agility, resilience, and sustainability aspects. To do this, this article proposes a heuristic-based multi-stage machine learning-based model to design a corn reverse logistics based on agility, resilience, and sustainability features. In this way, at the first stage, the performance of the potential recycling partners is evaluated by combining the Categorical Boosting Algorithm (CatBoost) method. In the next stage, a multi-objective model is suggested to configure the corn reverse logistics in which the resilience, agility, and sustainability dimensions are incorporated. Afterwards, we deal with uncertainty by developing a data-driven method based on the chance-constrained fuzzy programming method and the seasonal autoregressive integrated moving average approach. Finally, by choosing a real-world case study, the suggested model is solved by developing a heuristic-based solution procedure. The obtained results showed that the developed heuristic-based solution approach able to find optimal and near-optimal solution in a reasonable time. Based on the achieved outputs, increasing the capacity parameter has a positive impact in the efficiency of the supply chain. Also, results show that when the amount of the initial waste increases, the total profit and environmental impacts of the supply chain have increased, too. Also, the achieved outputs confirm the robustness and efficiency of the developed machine learning-based approach. Then, several sensitivity analyses are presented to examine the role of the key parameters in the research problem. Finally, the managerial insights are provided.},
  archive      = {J_ASOC},
  author       = {Fardin Rezaei Zeynali and Mohammad Parvin and Ali Akbar ForouzeshNejad and Emaad Jeyzanibrahimzade and Mohssen Ghanavati-Nejad and AmirReza Tajally},
  doi          = {10.1016/j.asoc.2025.113042},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113042},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A heuristic-based multi-stage machine learning-based model to design a sustainable, resilient, and agile reverse corn supply chain by considering third-party recycling},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multidimensional fitness function based heuristic
algorithm for set covering problems. <em>ASOC</em>, <em>174</em>,
113038. (<a href="https://doi.org/10.1016/j.asoc.2025.113038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The set covering problem (SCP) is a conventional integer programming challenge in combinatorial optimization, with applications spanning fields such as transportation, logistics, and location problems. Solving SCPs efficiently is crucial for optimizing operations in these domains, particularly in location problems, where traditional algorithms often struggle with multidimensional objective spaces. To address such challenges, this study proposes a novel problem-dependent heuristic algorithm to solve SCPs, featuring a new multi-dimensional fitness function, which was evaluated by benchmarking against other heuristic and metaheuristic algorithms. A collection of reproduced and selected OR-library problems of various scales were chosen as benchmark instances to assess the performance of the algorithm. The performance of the algorithm was confirmed as it constructs solutions by leveraging a novel fitness function to address the limitations of time complexity, applicability, and scalability. Computational results demonstrate that the developed algorithm offers competitive solutions for SCPs, showing improvements of up to 88 % and 20 % in terms of time compared to simulated annealing and a preliminary heuristic algorithm, respectively. In terms of quality, the developed algorithm achieved cost reductions of up to 21 % and 11 % compared to these algorithms, respectively.},
  archive      = {J_ASOC},
  author       = {Ahmad Hashemi and Hamed Gholami and Xavier Delorme and Kuan Yew Wong},
  doi          = {10.1016/j.asoc.2025.113038},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113038},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multidimensional fitness function based heuristic algorithm for set covering problems},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessing the industry 4.0 strategies in the automobile
manufacturing firm using a combined compromise solution-based ranking
method. <em>ASOC</em>, <em>174</em>, 113037. (<a
href="https://doi.org/10.1016/j.asoc.2025.113037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Implementing industry 4.0 (I4.0) strategies in automobile manufacturing firm leads to the higher demand for newer services, drives innovation, continuously innovates to meet the changing needs and expectations of customers, and enables the development of sustainable solutions. This paper develops a q-rung orthopair fuzzy information (q-ROFI)-based decision support tool to evaluate I4.0 strategies in the automobile manufacturing firm. The proposed framework firstly calculates weight of decision expert using a procedure considering the q-rung orthopair fuzzy set (q-ROFS). Next, an individual opinions of decision experts are aggregated into single decision through q-ROF weighted averaging operator. Further, criteria weights are computed by a combined weighting procedure involving objective weighting through entropy-based procedure and subjective weighting by stepwise weight assessment ratio analysis (SWARA) model with q-ROFI. In the following purpose, new entropy is introduced based on the cross entropy of q-ROFS and new score function is proposed for q-ROFS to evade the limitation of existing q-ROF-score function. On the basis of these steps, a modified combined compromise solution (CoCoSo) approach is presented to assess and prioritize the alternatives under q-ROFS context. Finally, the proposed framework is applied to a case study of I4.0 strategies evaluation problem in automobile manufacturing firm. According to the outcomes, the most suitable strategy among the other strategies over considered twenty-five evaluation criteria for assessing I4.0 strategies in the automobile manufacturing firms is as new business models development strategies (0.319), improving information systems strategies (0.273) and human resource management (HRM) strategies (0.210), respectively. The most significant criteria for assessing I4.0 strategies in the automobile manufacturing firms are technology (0.055), coordination (0.052), and legal problems (0.048), respectively. Moreover, comparison with different existing methods is presented to validate the robustness of introduced method.},
  archive      = {J_ASOC},
  author       = {Arunodaya Raj Mishra and Pratibha Rani and Ahmad M. Alshamrani and Adel Fahad Alrasheedi and Dragan Pamucar},
  doi          = {10.1016/j.asoc.2025.113037},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113037},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Assessing the industry 4.0 strategies in the automobile manufacturing firm using a combined compromise solution-based ranking method},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A feature engineering based model architecture for modeling
initial public offerings. <em>ASOC</em>, <em>174</em>, 113035. (<a
href="https://doi.org/10.1016/j.asoc.2025.113035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a model architecture for modeling Initial Public Offerings (IPOs) by incorporating a diverse range of data sources, encompassing both textual and numerical inputs. Language models, machine learning models, and deep learning architectures are combined to make the final ensemble predictions. Several rich features are engineered and interpreted while providing scope for debugging using the game theory-based Shapley Additive exPlanations (SHAP) values. The study results indicate that the feature-engineering is highly eloquent in IPO performance modelling. The study findings have high economic implications range from detecting the market trends to overall market stability.},
  archive      = {J_ASOC},
  author       = {Durga Vaidynathan and Parthajit Kayal and Moinak Maiti},
  doi          = {10.1016/j.asoc.2025.113035},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113035},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A feature engineering based model architecture for modeling initial public offerings},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-reference super-resolution reconstruction of remote
sensing images based on hierarchical similarity mapping. <em>ASOC</em>,
<em>174</em>, 113027. (<a
href="https://doi.org/10.1016/j.asoc.2025.113027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To make full use of the details from multi-reference images and improve the quality of super-resolution reconstruction of remote sensing images, a multi-reference super-resolution reconstruction of remote sensing images based on hierarchical similarity mapping is proposed. It is very important in both military and civilian fields. Firstly, one low resolution image and three reference images are used as the input of VGG network to extract their feature maps at 4 × , 2 × , and 1 × scales. These feature maps at each scale are respectively blocked and used as a set of inputs in subsequent operations. Specifically, the low resolution features are divided into N i blocks, and each block is further divided into N c sub-feature-blocks. And the N m reference image features are divided into N r sub-feature-blocks. Then the N c low-resolution sub-feature blocks are mapped for similarity with the reference features within the range of all reference sub-feature blocks, individual reference features, and all reference image features. The outputs of each layer are then iteratively mapped with the low-resolution features as inputs for next layers. Thus the final features include information from all the reference images and low-resolution image. Subsequently, an adaptive transfer module with multi-reference features and channel attention is used to match and transfer the information of each reference image, while achieving edge smoothing and noise filtering between different reference features. Finally, the quadruple super-resolution reconstruct result is got from the multi-scale feature fusion module and decoder. Experimental results show that our improvements can reconstruct better super-resolution results with more details for utilizing information of multi-reference images, which is superior to single image super-resolution methods and single reference super-resolution methods.},
  archive      = {J_ASOC},
  author       = {Fuzhen Zhu and Qi Zhang and Bing Zhu and Chen Wang},
  doi          = {10.1016/j.asoc.2025.113027},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113027},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-reference super-resolution reconstruction of remote sensing images based on hierarchical similarity mapping},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Flight anomaly detection and localization based on flight
data fusion and random channel masking. <em>ASOC</em>, <em>174</em>,
113023. (<a href="https://doi.org/10.1016/j.asoc.2025.113023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flight anomaly detection and localization are critical for enhancing aircraft safety through effective analysis of flight data. However, existing methods only detect the timing of anomalies, failing to identify and recover the specific abnormal parameters necessary for assisting flight control systems in correcting the aircraft&#39;s state. To address these limitations, this paper proposes a novel anomaly detection and localization method based on random channel masking (RCM). The proposed approach integrates a multi-node synchronous prediction (MNSP) model, which combines graph attention networks and convolutional neural networks to extract both normal and anomalous patterns from extensive flight data. RCM is employed to generate pseudo-anomalous data, enabling the MNSP model to accurately localize and recover affected parameters. The effectiveness of proposed method is validated using real flight data from unmanned aerial vehicle, achieving an average anomaly detection accuracy of 95 % across four distinct types of anomalies. Furthermore, the method successfully localizes specific abnormal parameters with a localization accuracy of no less than 92.5 % across three different anomaly scenarios. In single-parameter anomaly scenarios, the mean squared error of data recovery remains below 0.000082. The study also explores the boundaries of anomaly localization in multi-parameter scenarios, highlighting the algorithm&#39;s robustness and applicability under diverse conditions.},
  archive      = {J_ASOC},
  author       = {Jie Zhong and Heng Zhang and Qiang Miao},
  doi          = {10.1016/j.asoc.2025.113023},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113023},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Flight anomaly detection and localization based on flight data fusion and random channel masking},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A quantum entanglement-based optimization method for complex
expensive engineering problems. <em>ASOC</em>, <em>174</em>, 113019. (<a
href="https://doi.org/10.1016/j.asoc.2025.113019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the computational costliness and time-consuming nature of complex and expensive engineering (CEE) problems, this paper proposes a genetic algorithm based on quantum entanglement to address these challenges. This method encodes individuals into quantum genes, where each gene bit stores not 0 or 1, but a superposition state of both. By leveraging the uncertainty of the superposition state during the collapse, this method effectively preserves population diversity even with a very small population size. A smaller population size implies fewer calls to time-consuming simulations. Additionally, quantum entangled states are created for parts of an individual&#39;s gene, utilizing the characteristic that entangled states instantly affect each other upon collapse, to achieve parallel evolution of parts of the genes in multiple individuals. This parallel evolution significantly increases the search speed of the algorithm, thereby reducing the number of iterations. Fewer iterations also mean fewer calls to simulations. Benchmark function experiments demonstrate that the proposed method is significantly superior to other similar algorithms in a 30D solution space with a population size of 20 and also has certain advantages in a 100D solution space.},
  archive      = {J_ASOC},
  author       = {Fengling Peng and Xing Chen},
  doi          = {10.1016/j.asoc.2025.113019},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113019},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A quantum entanglement-based optimization method for complex expensive engineering problems},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). State-space recurrent neural networks for predictive
analytics and latent state estimation. <em>ASOC</em>, <em>174</em>,
113017. (<a href="https://doi.org/10.1016/j.asoc.2025.113017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a framework to predict the remaining life (RL) of degrading systems under sensor condition monitoring. By integrating state-space modeling with stochastic recurrent neural networks, our approach efficiently processes condition-monitoring time-series data and models systems’ latent degradation states. We propose a stochastic model that captures dependencies among latent degradation states, sensor outputs, and RL in a causally coherent manner and utilizes stochastic neural networks to navigate the inherent uncertainties of system dynamics. To enhance the interpretability of RL estimation and latent state modeling, we propose interpretable regularization terms. These terms are incorporated into the loss function to optimize both the prediction precision of estimating remaining life and latent states and control the monotonic behavior of their estimates, thereby improving the model’s overall performance and interpretability. Our methodology is validated through numerical experiments and comparison with benchmark models, demonstrating its potential to improve predictive maintenance strategies by effectively estimating the remaining life and monitoring the state of latent degradation over time.},
  archive      = {J_ASOC},
  author       = {Ramin Moghaddass and Cheng-Bang Chen},
  doi          = {10.1016/j.asoc.2025.113017},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113017},
  shortjournal = {Appl. Soft. Comput.},
  title        = {State-space recurrent neural networks for predictive analytics and latent state estimation},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-label learning for fault diagnosis of pumping units
with one positive label. <em>ASOC</em>, <em>174</em>, 113014. (<a
href="https://doi.org/10.1016/j.asoc.2025.113014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis using the indicator diagram is a fundamental method to evaluate the working status of pumping units. In applications, human experts typically identify only one fault for each indicator diagram. However, multiple types of faults may occur simultaneously. In this paper, we propose a Single-Positive Multi-label learning for Fault Diagnosis of Pumping Units (SPM-FDPU) algorithm to address this issue. Although trained on single-label data, it is capable of multi-label prediction. First, HU invariant moments and convolutional neural networks are used to extract common and label-specific features, respectively. Second, instance, feature, and label correlations are injected into the training process by feature and label manifolds to enhance supervised information. Third, the manifold is used to augment the latent label matrix to help explore discriminant information. Experiments are conducted on the three real indicator diagram data of an oil field and sixteen multi-label benchmark datasets. The results show that the accuracy of the proposed method has achieved 98% in diagnosing multiple faults on indicator diagram datasets, and the mean rank of the proposed method is optimal in terms of six popular evaluation metrics on multi-label benchmark datasets. The source code is available at github.com/Kqian2020/SPM-FDPU .},
  archive      = {J_ASOC},
  author       = {Kun Qian and Jinyu Tang and Qimei Zhao and Shu Zhao and Fan Min},
  doi          = {10.1016/j.asoc.2025.113014},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113014},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-label learning for fault diagnosis of pumping units with one positive label},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-agent modeling for indoor fire risk prediction during
evacuation based on cellular automata and artificial neural network.
<em>ASOC</em>, <em>174</em>, 113013. (<a
href="https://doi.org/10.1016/j.asoc.2025.113013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fire cases have always posed threats to human lives and property safety, and new approaches have been developed to investigate how people behave during the fire process. Understanding the underlying mechanism under specific scenarios and conditions is critical to find possible ways of reducing social losses. Here, we propose a coupled model that combines FDS and CA, to assess fire risks in a multi-story dormitory building at a university. For this real target case, the settings of automatic sprinklers and temperature alarms will be considered in our coupled model. The aim is to investigate how pedestrians behave under the fire emergencies and how fire safety facilities (exits) shape final evacuation outcomes. To analysis the final outcomes and related factors, we use Event Tree and BP neural network methods to assess and predict individual risk levels. It suggests that controlling the number of people in each dormitory will effectively reduce the fire risk, and the existence of safety facilities can significantly contain fire risks. Early fire warning systems and quick response times are critical to reduce casualties during the evacuation process. Individual risk levels can be efficiently calculated by Event Tree method, and BP neural network can accurately predict fire risk levels. By integrating technologies such as FDS, CA, ETA, and BP neural networks, our model can effectively simulate the dynamic process of the fire evacuation while accurately predicting the fire risks, which establishes an effective link between environmental factors and fire risk assessment. This provides a methodological reference for future fire risk assessment research.},
  archive      = {J_ASOC},
  author       = {Peng Lu},
  doi          = {10.1016/j.asoc.2025.113013},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113013},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-agent modeling for indoor fire risk prediction during evacuation based on cellular automata and artificial neural network},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Short-term forecasting of electricity price using ensemble
deep kernel based random vector functional link network. <em>ASOC</em>,
<em>174</em>, 113012. (<a
href="https://doi.org/10.1016/j.asoc.2025.113012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate short-term electricity price forecasting in a deregulated electrical market is a difficult task as the electricity price exhibits high nonlinearity, sharp price spikes, and seasonality in different frequencies, etc. Thus, this study presents a new approach using an Ensemble Deep Kernel Random Vector Functional Link Network (EDKRVFLN) model hybridized with a Chaotic Sine Cosine Improved Firefly Algorithm (CSCIFA) for short-term electricity price forecasting with better generalization capacity, simple structure, and significant accuracy. Unlike the Ensemble Deep Random Vector Functional Link Network (EDRVFLN) where each stacked layer requires proper choice of the number of hidden nodes and manual tuning of random weights and biases along with the pseudoinverse solution of the output weights in each layer leading to suboptimal model generalization. However, the choice of random weights and biases along with the number of hidden neurons in the proposed EDKRVFLN model can be dispensed by using kernel-based transformation and representation learning. Further each stacked layer of the proposed model utilizes kernel based linear features from the direct links and nonlinearly transformed features from the enhancement nodes from the preceding layers of the prediction model. Also, each layer produces an output by simple invertible kernel matrix inversion based on generalized least squares, and the final output is the ensemble of the outputs from each layer, thus simultaneously producing an ensemble and deep learning framework. Seven electricity price datasets are examined to confirm the supremacy of the proposed model in comparison to several benchmark models.},
  archive      = {J_ASOC},
  author       = {Someswari Perla and Ranjeeta Bisoi and P.K. Dash and A.K. Rout},
  doi          = {10.1016/j.asoc.2025.113012},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113012},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Short-term forecasting of electricity price using ensemble deep kernel based random vector functional link network},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing AI safety of machine unlearning for ensembled
models. <em>ASOC</em>, <em>174</em>, 113011. (<a
href="https://doi.org/10.1016/j.asoc.2025.113011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, machine unlearning (MU) has received significant attention for its ability to remove specific undesired knowledge from a trained model, thereby ensuring AI safety. Furthermore, efforts have been made to integrate MU into existing Machine Learning as a Service (MLaaS), allowing users to raise requests to remove the influence of their data used in the training phase, after which the server conducts MU to remove its influence based on the unlearning requests. However, previous research reveals that malicious users may manipulate the requests so that the model utility may be significantly compromised after unlearning, which is known as malicious unlearning. In addition, privacy leakage may be exploited by malicious users by analyzing inference results obtained from the original model and the unlearned model. In this connection, we investigate these potential risks, specifically in ensemble models, which are widely adopted in MU because of their efficiency in unlearning and robustness in learning. However, despite these advantages, their vulnerabilities to malicious unlearning and privacy leakage remain largely unexplored. Our work explores malicious unlearning and malicious inference in ensemble settings. We propose a method in which malicious unlearning requests can trigger hidden poisons in ensembles, causing target images to be misclassified as intended by adversaries. Additionally, we introduce a privacy leakage attack where adversaries with black-box access to voting outputs can infer the unlearned label by analyzing the differences between the original and unlearned ensemble outputs. Experimental results demonstrate that these attacks can be highly stealthy and achieve a high success rate. Furthermore, comparative experiments reveal that these attacks present slightly lower stealthiness in ensemble settings compared to single-model scenarios, suggesting that ensemble models have advantages in detecting such malicious activities. These findings reveal that ensemble models are vulnerable to malicious unlearning and privacy leakage and highlight the urgent need for more robust MU designs to ensure AI safety.},
  archive      = {J_ASOC},
  author       = {Huanyi Ye and Jiale Guo and Ziyao Liu and Yu Jiang and Kwok-Yan Lam},
  doi          = {10.1016/j.asoc.2025.113011},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113011},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Enhancing AI safety of machine unlearning for ensembled models},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual degradation image inpainting method via adaptive
feature fusion and u-net network. <em>ASOC</em>, <em>174</em>, 113010.
(<a href="https://doi.org/10.1016/j.asoc.2025.113010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing image inpainting methods are designed to address a single specific task, such as super-resolution, denoising, or colorization, with few models capable of handling dual degradation simultaneously. Moreover, current algorithms that tackle multiple image degradation problems often suffer from complex structures, prolonged training times, and high labor costs. In this paper, we propose a Dual Degradation Network via Adaptive Feature Fusion and U-Net (AFFU). The network employs a Self-Guided Module (SGM) to fuse multi-scale image information, effectively eliminating certain defects in the image. A coder-decoder module with null convolution is utilized to consolidate the semantic information of the image, enabling intermediate image colorization. Additionally, an Adaptive Multi-feature Fusion Module (AMF) and Information Transfer Mechanism (ITM) are introduced to link these two major structures, adaptively selecting and retaining image features during network progression to prevent the loss of useful information. Experimental results demonstrate that the proposed dual image degradation restoration network model, based on adaptive multi-feature fusion, achieves optimal visual generation. Evaluations on CelebA dataset and Landscape dataset show that the proposed method outperforms comparable approaches in terms of Structural Similarity (SSIM) and Learned Perceptual Image Patch Similarity (LPIPS).},
  archive      = {J_ASOC},
  author       = {Yuantao Chen and Runlong Xia and Kai Yang and Ke Zou},
  doi          = {10.1016/j.asoc.2025.113010},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113010},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dual degradation image inpainting method via adaptive feature fusion and U-net network},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention-aware graph contrastive learning with topological
relationship for recommendation. <em>ASOC</em>, <em>174</em>, 113008.
(<a href="https://doi.org/10.1016/j.asoc.2025.113008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems are a vital tool to guide the overwhelming amount of online information for users, which has been successfully applied to online retail platforms, social networks, etc. Recently, contrastive learning has revealed outstanding performance in recommendation by data augmentation strategies to handle highly sparse data. Most existing work fails to leverage the original network’s topology to construct attention-aware modules that identify user–item interaction importance for guiding node aggregation while preserving key semantics and reducing noise in the reconstructed graph during data augmentation. In this paper, our work proposes an At t e ntion-aware G raph C ontrastive L earning architecture with Topological Relationship (AteGCL) for recommendation. In particular, our AteGCL proposes an attention-aware mechanism with topological relationships to learn the importance between users and items for extracting the local graph dependency, which identifies the importance between nodes by constructing an attention-aware matrix into graph convolutional networks using a random walk with a restart strategy for generating node feature aggregation. We then employ principal component analysis (PCA) for contrastive augmentation and utilize the attention-aware matrix to ease noise from the reconstructed graph generated by PCA and to generate a new view with global collaborative relationships and less noise. Comprehensive experiments on three real-world user–item networks reveal the superiority of our AteGCL over diverse state-of-the-art recommendation approaches. Our code is available at https://github.com/ZZHCodeZera/AteGCL .},
  archive      = {J_ASOC},
  author       = {Xian Mo and Jun Pang and Zihang Zhao},
  doi          = {10.1016/j.asoc.2025.113008},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113008},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Attention-aware graph contrastive learning with topological relationship for recommendation},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Category-level pipe pose and size estimation via
geometry-aware adaptive curvature convolution. <em>ASOC</em>,
<em>174</em>, 113006. (<a
href="https://doi.org/10.1016/j.asoc.2025.113006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pipe pose estimation provides crucial positional information for robots, enhancing assembly efficiency and precision, while its accuracy critically impacts the final product&#39;s reliability and quality. To handle unseen pipes, we propose a category-level pipe pose and size estimation network via Normalized Object Coordinate Space (NOCS) representation. Given an RGB image and its corresponding depth map, our network predicts class labels, bounding boxes and instance masks for detection, as well as NOCS maps for pose estimation. Then these predictions are aligned with the depth map to estimate pipe’s pose and size. To better extract complex and variable pipe morphology, geometry-aware adaptive curvature convolution is introduced to dynamically adapt to the slender structure and improve segmentation performance. Facing the lack of pipe pose datasets with enough instances, pose, clutter, occlusion, and illumination variation, we propose a novel domain randomization mixed reality approach to efficiently generate synthetic data, which addresses the limitations of training datasets, making data generation more time- and effort-efficient. Experimental results demonstrate that our Geometry-Aware Adaptive Convolutional Network (GACNet) outperforms other methods and robustly estimates the pose and size of unseen pipes in real-world environments.},
  archive      = {J_ASOC},
  author       = {Jia Hu and Jianhua Liu and Shaoli Liu and Lifeng Wang},
  doi          = {10.1016/j.asoc.2025.113006},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113006},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Category-level pipe pose and size estimation via geometry-aware adaptive curvature convolution},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discrete differentiated creative search for traveling
salesman problem. <em>ASOC</em>, <em>174</em>, 112998. (<a
href="https://doi.org/10.1016/j.asoc.2025.112998">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel population-based Discrete Differentiated Creative Search (DDCS) is proposed in this paper for solving the traveling salesman problem (TSP). DDCS introduces greedy beam search to adaptively initialize the population and improve the quality of the initial solutions. Second, a multi-edge construction operator, edge-based mathematical operations and a similarity attraction operator are used to guide individuals from different population categories towards higher-quality solutions based on the current solutions. Finally, a random nearest neighbor replacement strategy is used to replace individuals with the same distance heuristically, reducing the assimilation rate of the population. DDCS is tested with 50 instances from TSPLIB and compared with a variety of state-of-the-art and variants of classical algorithms. The results demonstrate that DDCS exhibits superior optimization capability and higher stability.},
  archive      = {J_ASOC},
  author       = {Qi Xu and Kewen Xia and Xiaoyu Chu},
  doi          = {10.1016/j.asoc.2025.112998},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112998},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Discrete differentiated creative search for traveling salesman problem},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long-short term cross echo state network for time series
forecasting task. <em>ASOC</em>, <em>174</em>, 112997. (<a
href="https://doi.org/10.1016/j.asoc.2025.112997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Investigating the dynamics of time series in nonlinear systems has become a prominent research focus in both theoretical and practical domains. Unveiling the intrinsic characteristics of nonlinear time series can significantly enhance the understanding and modelling of nonlinear systems. Among the various time prediction models, Reservoir Computing (RC) has garnered widespread attention due to its distinctive hidden layer architecture. The Echo State Network (ESN) is one of the most representative instances within the RC framework. However, most existing ESNs do not explicitly capture the fixed multi-scale dependencies in time series, and their short-term memory (STM) cannot meet the needs of specific time series. To address these limitations, this paper introduces a novel Echo State Network with a heterogeneous topology, named the Long-short Term Cross Echo State Network (LS-CrossESN). The overall architecture of this model consists of three different types of reservoirs in parallel. And it incorporates a heterogeneous topology structure known as the cross architecture, which merges those of the first reservoir with the state characteristics of the second reservoir, so that the information between the two reservoirs can be transmitted to each other. At the same time, a time-delay operator is inserted in the second reservoir, so that the fused characteristics would not be immediately input to the next layer but transmitted to the deep layer. In this way, the characteristics of input would not decay with the update of the layers. The structure of third reservoir captures the influence of recent historical memory through a specific sliding window technology, and finally the multi-scale states from each layer would be collected for combined prediction. To optimize parameters in this model, an Improved Salp Swarm Algorithm (ISSA) is proposed. The model was tested of eight datasets spanning three categories: Mackey-Glass series, Lorenz chaotic series, Sunspot series, airport temperature series, and two real network traffic datasets. The experimental results demonstrate that the STM of LS-CrossESN is significantly improved compared with Deep-ESN, LS-ESN, DATDR and ADRC. Across all eight datasets, the model exhibits robust performance in both one-step-ahead and multi-step predictions.},
  archive      = {J_ASOC},
  author       = {Dongchen Jiang and Li Cui and Yi Zeng and Meiming You and Guoqiang Wang},
  doi          = {10.1016/j.asoc.2025.112997},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112997},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Long-short term cross echo state network for time series forecasting task},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A crude oil price forecasting framework based on constraint
guarantee and pareto fronts shrinking strategy. <em>ASOC</em>,
<em>174</em>, 112996. (<a
href="https://doi.org/10.1016/j.asoc.2025.112996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of crude oil prices is essential for making informed energy policy decisions and ensuring energy security. However, crude oil price forecasting is inherently challenging due to the volatile, nonlinear, and complex nature of the market. While ensemble learning approaches have shown promise in enhancing forecasting accuracy, many existing models rely on multi-objective optimization techniques that generate a Pareto frontier of optimal solutions, often making it difficult to select the best solution for practical application. This issue is exacerbated by the fact that some Pareto-optimal solutions are not suitable for real-world decision-making, leading to inefficiencies in model performance. To address these limitations, this research proposes a novel ensemble learning framework that incorporates a Constraint Guarantee Strategy (CGS) and a Pareto Front Shrinking Strategy (PFSS) to enhance both the accuracy and stability of crude oil price forecasting models. The CGS filters out inferior solutions during the optimization process, ensuring that the ensemble model outperforms individual models in terms of forecasting accuracy. The PFSS helps decision-makers select the most relevant solutions from the Pareto frontier by balancing trade-offs between objectives and narrowing down the set of solutions. Our framework is evaluated on three widely used datasets: Brent, WTI, and Dubai crude oil prices, and compared with state-of-the-art models from both the general time-series forecasting domain and crude oil price forecasting. It improves prediction accuracy by approximately 23.2% on the Brent dataset, 4.0% on the WTI dataset, and 21.7% on the Dubai dataset, based on improvements in MAPE. Ablation studies confirm the effectiveness of each component. The discussion further emphasizes the practical applicability and robustness of the framework, confirming its potential for real-world crude oil price forecasting.},
  archive      = {J_ASOC},
  author       = {Yujie Chen and Zhirui Tian},
  doi          = {10.1016/j.asoc.2025.112996},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112996},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A crude oil price forecasting framework based on constraint guarantee and pareto fronts shrinking strategy},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating competitive framework into differential
evolution: Comprehensive performance analysis and application in brain
tumor detection. <em>ASOC</em>, <em>174</em>, 112995. (<a
href="https://doi.org/10.1016/j.asoc.2025.112995">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an efficient and effective optimizer based on the Success History Adaptive DE (SHADE) named Competitive Framework DE (CFDE). We integrate three tailored strategies into CFDE: (1) the competitive framework to identify and prioritize potential individuals, (2) the novel DE/loser-to-best/loser-to-winner mutation scheme to fully leverage the information from the population and competition to construct high-quality offspring individuals, and (3) the random memory initialization to diversify the search patterns of the individual. We conduct comprehensive numerical experiments on CEC2017, CEC2020, CEC2022, and eight engineering problems against eleven state-of-the-art optimizers to confirm the superiority and competitiveness of CFDE. Moreover, the sensitivity experiments on hyperparameters validate the robustness of CFDE, and the ablation experiments practically prove the independent contribution of integrated components. Furthermore, we propose a hybrid model named DenseNet-CFDE-ELM for brain tumor detection, where DenseNet-169 is employed for feature selection and CFDE-optimized Extreme Learning Machine (ELM) classifies the brain tumors in MRI scans. Experimental results on the brain tumor dataset downloaded from Kaggle confirm that the proposed DenseNet-CFDE-ELM achieves improvements in accuracy with 1.794%, precision with 1.696%, recall with 1.794%, and F1 score with 1.812% against the second-best ResNet-18 model. These results reveal the potential of CFDE in extensive real-world optimization scenarios. The source code of this research can be downloaded from https://github.com/RuiZhong961230/CFDE .},
  archive      = {J_ASOC},
  author       = {Rui Zhong and Zhongmin Wang and Yujun Zhang and Junbo Jacob Lian and Jun Yu and Huiling Chen},
  doi          = {10.1016/j.asoc.2025.112995},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112995},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Integrating competitive framework into differential evolution: Comprehensive performance analysis and application in brain tumor detection},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fuzzy AHP-based trust management mechanism for
self-sovereign identity in the metaverse. <em>ASOC</em>, <em>174</em>,
112994. (<a href="https://doi.org/10.1016/j.asoc.2025.112994">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-sovereign identity (SSI) technology has advantages and potential for application in the metaverse. However, the decentralization and anonymous interaction of SSI create convenience for malicious attacks, frauds, and conspiracies in the metaverse. It leads to various trust risks and threats to the meta-universe system. To address these challenges, we analyze the risks of SSI systems and constructed a reputation index system. Moreover, we propose a blockchain-based reputation management framework (BBRMF), which can constrain users from engaging in illegal activities such as forgery, fraud, and conspiracy, thereby guaranteeing the security and trustworthiness of the entities involved in the metaverse. In BBRMF, we constructed a reputation evaluation model based on fuzzy analytical hierarchy process (FAHP) to assess the user’s reputation in three dimensions: reliability, trustworthiness and security. To motivate users to accumulate more positive reputation, we set the user’s reputation score into a reputation credential in the form of non-fungible token (NFT), through which users can obtain more benefits and opportunities. Finally, we calculated the reputation value of SSI related entities from multiple perspectives through simulation experiments and comparative analysis. The feasibility of the proposed method is verified, and it is proved that it can effectively resist the interference and attack of malicious scoring nodes. Moreover, the scheme adopts multi-dimensional evaluation indexes and behavioral feature values, which significantly improves the comprehensiveness and accuracy of the reputation assessment. Meanwhile, the weights of the evaluation indexes are derived through objective calculation, ensuring the fairness of the evaluation results, and improving the credibility and repeatability of the reputation assessment.},
  archive      = {J_ASOC},
  author       = {Xiaoling Song and Guangxia Xu and Yongfei Huang},
  doi          = {10.1016/j.asoc.2025.112994},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112994},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A fuzzy AHP-based trust management mechanism for self-sovereign identity in the metaverse},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combination weighting method using z-numbers for
multi-criteria decision-making. <em>ASOC</em>, <em>174</em>, 112992. (<a
href="https://doi.org/10.1016/j.asoc.2025.112992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a hybrid approach to determining criteria weights in Multi-Criteria Decision Making (MCDM), combining subjective weight methods with objective weighting techniques based on Z-number theory. The methodology is applied in a practical context involving the establishment of a bank&#39;s call center data analysis platform. Leveraging the inherent uncertainty and reliability considerations in decision-making processes, the hybrid method offers a robust framework for decision support. Through empirical validation and case study analysis, the effectiveness of the proposed approach is demonstrated, highlighting its ability to balance theoretical robustness with practical applicability. The study underscores the importance of ongoing research in MCDM, particularly in developing innovative methods to address the complexities of decision-making environments. Insights from this research provide valuable guidance for practitioners and researchers seeking to enhance MCDM processes across diverse domains.},
  archive      = {J_ASOC},
  author       = {Huan-Jyh Shyur},
  doi          = {10.1016/j.asoc.2025.112992},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112992},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Combination weighting method using Z-numbers for multi-criteria decision-making},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A three-way decision-based model for occupational risk
assessment and classification in the healthcare industry. <em>ASOC</em>,
<em>174</em>, 112991. (<a
href="https://doi.org/10.1016/j.asoc.2025.112991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, occupational health and safety risk assessment (OHSRA) has gained more importance since occupational hazards can cause loss of life, injuries, delays, and cost overruns in an organization. The OHSRA is a critical activity for identifying, analyzing and reducing the potential occupational hazards arising from workplace for corrective actions. In this study, a new OHSRA model is proposed for the risk assessment and classification of occupational hazards by utilizing the criteria importance through inter-criteria correlation (CRITIC) method and three-way decision (TWD). First, the 2-tuple linguistic variables are utilized to express the complex and uncertain risk assessments of occupational hazards provided by experts. Second, an extended CRITIC method is employed to compute the weights of risk criteria by considering their interactions. Then the TWD is improved to determine the risk classifications of occupational hazards by considering their correlations. Finally, a practical case in the healthcare industry is provided to illustrate the feasibility and strengths of the proposed OHSRA model. The results show that the proposed OHSRA model can generate more credible risk classifications of occupational hazards and offer a flexible way for analyzing the risk of occupational hazards.},
  archive      = {J_ASOC},
  author       = {Ran Liu and Hu-Chen Liu and Qi-Zhen Zhang and Hua Shi},
  doi          = {10.1016/j.asoc.2025.112991},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112991},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A three-way decision-based model for occupational risk assessment and classification in the healthcare industry},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive encoding and comprehensive attention decoding
network for medical image segmentation. <em>ASOC</em>, <em>174</em>,
112990. (<a href="https://doi.org/10.1016/j.asoc.2025.112990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image segmentation involves partitioning different tissues or lesion areas within medical images. Achieving automatic segmentation can markedly improve efficiency and accuracy, which is significant for biomedical clinical diagnosis. With the rapid development of deep convolutional neural networks (DCNN), U-Net has been widely used in medical image segmentation due to its encoder-decoder structure and skip connection. However, it is still hard for U-Net to handle certain challenging cases. In this study, we propose an adaptive encoding and comprehensive attention decoding network (AA-Net), which is derived from U-Net to address the issues of the semantic gap as well as the loss of spatial information during convolutions. AA-Net takes into account the different characteristics of the encoder and decoder. In the encoder, we design a simple Adaptive Calibration Module (ACM) to improve the representation ability of candidate features. In the decoder, we introduce a Comprehensive Attention Feature Extraction (CAFE) module, which employs multiple attention mechanisms after feature fusion to alleviate the semantic gap. Benefiting from CAFE, AA-Net can better handle the challenging cases where the segmentation targets vary in position, size, and scale. Additionally, we suggest a weighted hybrid loss function for precise boundary segmentation. We validate the effectiveness of AA-Net and each component on three biomedical image datasets. The results demonstrate that our method outperforms state-of-the-art methods in different medical segmentation tasks, proving it is lightweight, efficient, and general.},
  archive      = {J_ASOC},
  author       = {Xin Shu and Aoping Zhang and Zhaoyang Xu and Feng Zhu and Wei Hua},
  doi          = {10.1016/j.asoc.2025.112990},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112990},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Adaptive encoding and comprehensive attention decoding network for medical image segmentation},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A nondominated sorting simplified swarm optimization with
local search mechanisms for multi-objective vehicle routing problems
with time windows. <em>ASOC</em>, <em>174</em>, 112989. (<a
href="https://doi.org/10.1016/j.asoc.2025.112989">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In addressing the complexities of modern logistics, this study introduces a novel multi-objective formulation for vehicle routing problems with time windows (MO-VRPTW), targeting minimizing travel distance, enhancing customer satisfaction, and equalizing driver workloads. We introduce an innovative hybrid multi-objective evolutionary algorithm (MOEA) leveraging nondominated sorting simplified swarm optimization to effectively merge the advantages of various optimization strategies. A key aspect of this advancement is the incorporation of the Lin−Kernighan − Helsgaun (LKH) heuristic, which delivers a superior initial solution, thereby markedly enhancing the speed of convergence. Additionally, we pioneered a local search method inspired by the A* algorithm designed to refine the search process&#39;s exploration and exploitation stages. Solomon&#39;s benchmark instances, a recognized standard in the VRPTW field, were used to validate our algorithm&#39;s effectiveness. Our algorithm demonstrated superior performance in addressing MO-VRPTW through meticulous statistical analysis, outperforming state-of-the-art algorithms, such as MOPSO, NSGA-II, MOEA/D, and SPEA2, regarding efficiency and solution diversity. This study not only advances algorithmic performance but also thoughtfully considers the interests of key supply chain stakeholders.},
  archive      = {J_ASOC},
  author       = {Chyh-Ming Lai and Chun-Chih Chiu and Tzu-Li Chen},
  doi          = {10.1016/j.asoc.2025.112989},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112989},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A nondominated sorting simplified swarm optimization with local search mechanisms for multi-objective vehicle routing problems with time windows},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cluster-based prepositioning network for enhanced recovery
resilience of critical infrastructure system using multiplex network.
<em>ASOC</em>, <em>174</em>, 112987. (<a
href="https://doi.org/10.1016/j.asoc.2025.112987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient restoration of critical infrastructures for high-impact-low-frequency events heavily relies on pre-disaster restoration resource prepositioning and post-disaster assignment. To find proper locations of restoration resource depots and optimal assignment schemes, a multiplex network approach is proposed to simultaneously model the critical infrastructure network and restoration resource prepositioning network as a coupled multi-layered network. The proposed approach consists of load-weighted critical infrastructure network modeling, cluster-based restoration resource prepositioning network modeling and recovery resilience optimization of a multiplex network from the two networks. Tested on the Hangzhou metro network located in China, experimental results show that resilience loss optimized based on the proposed cluster-based multiplex network is lower than that based on four centrality-guaranteed competitors for all attack scenarios and significantly lower under random severe attacks representing the most severe scenarios. Link flow fluctuations and higher-order of resilience metrics are discussed to provide an insightful suggestion on the design and intervention decisions of infrastructure restoration.},
  archive      = {J_ASOC},
  author       = {Ying Wang and Ou Zhao and Limao Zhang},
  doi          = {10.1016/j.asoc.2025.112987},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112987},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Cluster-based prepositioning network for enhanced recovery resilience of critical infrastructure system using multiplex network},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-agent reinforcement learning system framework based on
topological networks in fourier space. <em>ASOC</em>, <em>174</em>,
112986. (<a href="https://doi.org/10.1016/j.asoc.2025.112986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, multi-agent reinforcement learning (MARL) has been applied to various domains such as communications, network management, power systems, and autonomous driving, showcasing broad application scenarios and significant research potential. However, in complex decision-making environments, agents that rely solely on temporal value functions often struggle to capture and extract hidden features and dependencies within long sequences in multi-agent settings. Each agent’s decisions are influenced by a sequence of prior states and actions, leading to complex spatiotemporal dependencies that are challenging to analyze directly in the time domain. Addressing these challenges requires a paradigm shift to analyze such dependencies from a novel perspective. To this end, we propose a Multi-Agent Reinforcement Learning system framework based on Fourier Topological Space from the foundational level. This method involves transforming each agent’s value function into the frequency domain for analysis. Additionally, we design a lightweight weight calculation method based on historical topological relationships in the Fourier topological space. This addresses issues of instability and poor reproducibility in attention weights, along with various other interpretability challenges. The effectiveness of this method is validated through experiments in complex environments such as the StarCraft Multi-Agent Challenge (SMAC) and Google Football. Furthermore, in the Non-monotonic Matrix Game, our method successfully overcame the limitations of non-monotonicity, further proving its wide applicability and superiority. On the application level, the proposed algorithm is also applicable to various multi-agent system domains, such as robotics and factory robotic arm control. The algorithm can control each joint in a coordinated manner to accomplish tasks such as enabling a robot to stand upright or controlling the movements of robotic arms.},
  archive      = {J_ASOC},
  author       = {Licheng Sun and Ao Ding and Hongbin Ma},
  doi          = {10.1016/j.asoc.2025.112986},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112986},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-agent reinforcement learning system framework based on topological networks in fourier space},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic light optimization in vertical farming using an
IoT-driven digital twin framework and artificial intelligence.
<em>ASOC</em>, <em>174</em>, 112985. (<a
href="https://doi.org/10.1016/j.asoc.2025.112985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The global agricultural sector faces mounting challenges from climate change, population growth, urbanization, and environmental degradation, necessitating innovative solutions to ensure food security. Urban and peri-urban agriculture, particularly vertical farming, offers a sustainable approach to increase food production while minimizing land use, reducing environmental impact, and enhancing resource efficiency. Unlike conventional vertical farming systems that rely on static spectral recipes with fixed light compositions (e.g., Red-to-Blue ratios derived from historical data), this study introduces an Internet of Things-enabled smart vertical farming system that leverages digital twin technology and a genetic algorithm (GA) to dynamically optimize lettuce growth by adjusting RGB LED spectra throughout the crop cycle. The system monitors and controls key environmental parameters within a growth tower, including temperature, humidity, and lighting. A digital twin facilitates real-time data exchange between physical and virtual components, while the GA iteratively refines the light composition. Over a 34-day cultivation period, the algorithm identified an optimal RGB configuration (R:211, G:169, B:243; maximum intensity: 255) that aligns with spectral values reported in literature for lettuce, despite not directly measuring photobiological metrics such as Photosynthetic Photon Flux Density. To our knowledge, this is the first study to implement a dynamic, GA-driven spectral optimization strategy in vertical farming. While the objective was not to surpass traditional static lighting recipes, the results validate that adaptive methods can reliably converge to established optima. The IoT platform demonstrated robust capabilities in data collection, processing, and actuation, underscoring the promise of adaptive lighting strategies for controlled agriculture. Future research will focus on incorporating additional spectra (e.g., deep red, ultraviolet), automating data collection via image recognition, and analyzing energy efficiency to enhance scalability.},
  archive      = {J_ASOC},
  author       = {Rafael Gomes Alves and Fábio Lima and Ítalo Moraes Rocha Guedes and Salvador Pinillos Gimenez},
  doi          = {10.1016/j.asoc.2025.112985},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112985},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dynamic light optimization in vertical farming using an IoT-driven digital twin framework and artificial intelligence},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neural priority model for agile earth observation
satellite scheduling using deep reinforcement learning. <em>ASOC</em>,
<em>174</em>, 112984. (<a
href="https://doi.org/10.1016/j.asoc.2025.112984">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The agile earth observation satellite scheduling problem (AEOSSP) is a time-dependent and complex combinatorial optimization challenge that has spurred extensive research for decades. Traditional methods have primarily relied on iterative searching processes to approximate near-optimal solutions, but their efficiency remains limited. To address this issue, we propose a Priority Construction Model (PCM) based on deep reinforcement learning (DRL), forming a learning-based, two-stage construction heuristic. The PCM integrates a Priority Construction Neural Network (PCNN) alongside a Backward-Slacken and Top-Insert (BS-TI) scheduling algorithm. In PCM, the PCNN sequences observation requests, while the BS-TI schedules each sequenced request in accordance with specific constraints, thus freeing the neural policy from the burden of complex constraint checking. Experimental results indicate that following a policy-gradient-based DRL training process, PCM outperforms the state-of-the-art AEOSSP iterative algorithm, achieving better average profits within an exceptionally short construction time in most scenarios. The model study further reveals that PCNN outperforms other DRL policies in terms of priority policy representation, while the PCM exhibits superior generalization capabilities across varying scales and distributions. Therefore, our proposed model presents a valuable reference solution that not only meets the large-scale and rapid response requirements of the AEOSSP but also holds potential for application in upcoming large constellations and emerging management paradigms. More importantly, we introduce a novel framework that separates the DRL optimization process from constraint management, lowering the entry barrier for applying DRL to complex problems. This makes the model adaptable to various optimization challenges in engineering and operations research, thus extending its applicability beyond the AEOSSP domain.},
  archive      = {J_ASOC},
  author       = {Ming Chen and Luona Wei and Jie Chun and Lei He and Shang Xiang and Lining Xing and Yingwu Chen},
  doi          = {10.1016/j.asoc.2025.112984},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112984},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A neural priority model for agile earth observation satellite scheduling using deep reinforcement learning},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transferable adversarial attacks against face recognition
using surrogate model fine-tuning. <em>ASOC</em>, <em>174</em>, 112983.
(<a href="https://doi.org/10.1016/j.asoc.2025.112983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Networks have significantly advanced Face Recognition performance yet remain susceptible to adversarial attacks, posing significant security and user privacy threats in real-world applications. In recent years, black box attacks have attracted wide attention to craft highly transferable adversarial examples by training surrogate models. However, most of these methods primarily depend on stealing knowledge by accessing the soft label from the target model using either synthetic training data or data free without awareness of the knowledge type, which can affect the improvement of transferability between the surrogate and the target models. Additionally, these attacks still need to improve the surrogate model’s accuracy without using many queries. To this end, we propose Tune2Transfer, a novel attack method that enhances adversarial transferability by fine-tuning the surrogate model with different types of knowledge with limited queries on the target model by the hard label only. Specifically, it collects a small face image dataset, considering the adversary’s limited knowledge. To overcome the challenge of knowledge type, Tune2Transfer imposes three sampling assumptions: clean images only, the perturbed images, or combining both, generating images on the surrogate model, and then feeding them to the target model to obtain the hard label. The perturbed images are generated by perturbing them using the Covariance Matrix Adaptation Evolution Strategy or Momentum Iteration Fast Gradient Sign Method. Besides, we leverage pre-trained models to fine-tune surrogate models to avoid large queries. In this way, we could leverage knowledge transferred from the target model, resulting in superior transferability. Extensive experiments conducted on two typical datasets demonstrate the efficacy of Tune2Transfer, increasing the attack success rates significantly.},
  archive      = {J_ASOC},
  author       = {Yasmeen M. Khedr and Xin Liu and Haobo Lu and Kun He},
  doi          = {10.1016/j.asoc.2025.112983},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112983},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Transferable adversarial attacks against face recognition using surrogate model fine-tuning},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A semi-supervised non-negative matrix factorization model
for scRNA-seq data analysis. <em>ASOC</em>, <em>174</em>, 112982. (<a
href="https://doi.org/10.1016/j.asoc.2025.112982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-cell RNA sequencing (scRNA-seq) technology enables the measurement of cellular gene expression at the single-cell level, thus facilitating cell clustering at the gene level. Despite numerous dimensionality reduction methods developed for scRNA-seq data, many are limited to analyzing individual gene expression matrices and struggle to address false positives and false zero expression entries effectively. Moreover, existing methods often underutilize prior knowledge of similarity and dissimilarity between multi-omics data, leading to the loss of intercellular correlations and shared structural information, thus hindering desired dimensionality reduction outcomes. To address these limitations, a novel model termed joint non-negative matrix factorization with similarity and dissimilarity constraints (SDJNMF) was proposed to tailor for scRNA-seq data clustering. The model leverages prior knowledge of similarity and dissimilarity across multiple gene expression matrices, facilitating joint non-negative matrix factorization to extract common features from multi-omics data. By preserving shared structural and cellular relevance information, SDJNMF enhances the clustering of similar cells while effectively separating dissimilar ones. Furthermore, the SDJNMF model incorporates sparse Singular Value Decomposition during initialization to mitigate noise and redundancy and ensure robust dimensionality reduction. The experimental results demonstrate that the SDJNMF model exhibits superior performance on the 10 datasets, not only outperforming the other 14 algorithms in terms of clustering accuracy on the 9 datasets, but also enhancing the A R I of SDJNMF by an average of 0.0687 in comparison to the second-best algorithm on each dataset. In the visual representation, the model is able to efficiently and accurately cluster similar cells and effectively discriminate different classes of cells from each other. Additionally, the SDJNMF model was applied to identify informative genes and conduct enrichment analysis, validating that genes identified by SDJNMF significantly influence biological processes. Overall, the SDJNMF offers innovative tools for cell cluster identification and advances biological research. The source code of SDJNMF is available online at https://github.com/Jindsmu/SDJNMF .},
  archive      = {J_ASOC},
  author       = {Junjie Lan and Xiaoling Zhuo and Siman Ye and Jin Deng},
  doi          = {10.1016/j.asoc.2025.112982},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112982},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A semi-supervised non-negative matrix factorization model for scRNA-seq data analysis},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AdvGrid: A multi-view black-box attack on infrared
pedestrian detectors in the physical world. <em>ASOC</em>, <em>174</em>,
112981. (<a href="https://doi.org/10.1016/j.asoc.2025.112981">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physical adversarial attacks in the visible spectrum have been extensively studied, but research on infrared attacks remains limited. Infrared pedestrian detectors are crucial for modern applications yet vulnerable to adversarial attacks, posing significant security risks. Existing methods using physical perturbations like light bulb arrays or hot/cold patches for black-box attacks have shown limitations in practicality and multi-view support. To address these challenges, we introduce Adversarial Infrared Grid (AdvGrid), a novel approach that models perturbations in a grid format and employs a genetic algorithm for black-box optimization. AdvGrid cyclically applies perturbations to various parts of a pedestrian’s clothing, enabling effective multi-view black-box attacks on infrared detectors. Our extensive experiments demonstrate AdvGrid’s superior performance: Effectiveness: Achieves 80.00% attack success rate in digital environments and 91.86% in physical environments. Stealthiness: Maintains high stealthiness, making it difficult for observers to identify the adversarial patterns. Robustness: Exceeds 50% average attack success rate against mainstream detectors, showcasing its robustness across different scenarios. We also conduct ablation studies, transfer attacks, and adversarial defense evaluations, further confirming AdvGrid’s superiority over baseline methods. Our findings highlight AdvGrid as a powerful tool for advancing the understanding and mitigation of adversarial threats in infrared detection systems.},
  archive      = {J_ASOC},
  author       = {Kalibinuer Tiliwalidi and Chengyin Hu and Guangxi Lu and Ming Jia and Weiwen Shi},
  doi          = {10.1016/j.asoc.2025.112981},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112981},
  shortjournal = {Appl. Soft. Comput.},
  title        = {AdvGrid: A multi-view black-box attack on infrared pedestrian detectors in the physical world},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Series clustering and dynamic periodic patching-based
transformer for multivariate time series forecasting. <em>ASOC</em>,
<em>174</em>, 112980. (<a
href="https://doi.org/10.1016/j.asoc.2025.112980">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series forecasting (MTSF) is widely employed in research-intensive domains, such as weather forecasting. Recently, Transformer-based models have outstanding ability to achieve SOTA performance, benefiting from its self-attention mechanism. However, existing models fall short in capturing multivariate inter-dependencies and local semantic representations. To tackle the above limitations, we propose a series clustering and dynamic periodic patching-based Transformer model named CMDPPformer, with two distinctive characteristics: (1) A channel-mixing module based on series clustering is proposed which can strengthen the association between variables with high sequence similarity, and weaken the effect of uncorrelated variables. Concretely, we use whole-time series clustering to group multivariate time series into clusters. After that, variables in the same cluster share the same Transformer backbone while variables in different clusters do not affect each other. (2) A dynamic periodic patching module is introduced which can better capture semantic information and improve Transformer’s local semantic representation. Concretely, multivariate time series after clustering are dynamically segmented into periodic patches as Transformer’s input token. Experimental results show that CMDPPformer can achieve an overall 13.76% and 10.16% relative improvements than SOTA Transformer-based models on seven benchmarks, covering four real-world applications: energy, weather, illness and economic.},
  archive      = {J_ASOC},
  author       = {Yijie Wang and Xiao Wu and Jiaying Zhang and Weiping Wang and Linjiang Zheng and Jiaxing Shang},
  doi          = {10.1016/j.asoc.2025.112980},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112980},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Series clustering and dynamic periodic patching-based transformer for multivariate time series forecasting},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic trend fusion module for traffic flow prediction.
<em>ASOC</em>, <em>174</em>, 112979. (<a
href="https://doi.org/10.1016/j.asoc.2025.112979">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic flow prediction is essential for applications like transport logistics but remains challenging due to complex spatio-temporal correlations and non-linear traffic patterns. Existing methods often model spatial and temporal dependencies separately, failing to effectively fuse them. To overcome this limitation, the D ynamic S patial- T emporal T rend Trans former ( DST 2 former ) is proposed to capture spatio-temporal correlations through adaptive embedding and to fuse dynamic and static information for learning multi-view dynamic features of traffic networks. The approach employs the D ynamic T rend R epresentation Trans former ( DTRformer ) to generate dynamic trends using encoders for both temporal and spatial dimensions, fused via Cross Spatial-Temporal Attention. Predefined graphs are compressed into a representation graph to extract static attributes and reduce redundancy. Experiments on four real-world traffic datasets demonstrate that our framework achieves state-of-the-art performance.},
  archive      = {J_ASOC},
  author       = {Jing Chen and Haocheng Ye and Zhian Ying and Yuntao Sun and Wenqiang Xu},
  doi          = {10.1016/j.asoc.2025.112979},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112979},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dynamic trend fusion module for traffic flow prediction},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Developing a forecasting model for time series based on
clustering and deep learning algorithms. <em>ASOC</em>, <em>174</em>,
112977. (<a href="https://doi.org/10.1016/j.asoc.2025.112977">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a new forecasting model for time series based on the improvement and combination of the cluster analysis (CA) algorithm and deep learning with Convolutional Neural Network (CNN) and Bi-Long Short Term Memory (BiLSTM) model. The proposed model is considered pioneering in this research direction with significant contributions to three main phases. For the first phase, the original series is converted into the percentage change series and is divided into clusters of an appropriate number using the CA algorithm. The next phase involves extracting the features of the new series based on the CNN with suitable parameters and input data enhancement from the results of the first phase. In the final phase, the BiLSTM model is applied to the series established from the second phase, and the forecasting principle for the future is established. The proposed model is detailed in the implementation steps, proving convergence, illustrated by numerical examples, and can be applied to real series using a Matlab procedure. The effectiveness of the proposed model is quite impressive as it surpasses many strong forecasting models on reputable benchmark datasets , including the M3-Competition dataset with 3,003 series, and M4-Competition dataset with 100,000 series.},
  archive      = {J_ASOC},
  author       = {Luan Nguyen-Huynh and Tai Vo-Van},
  doi          = {10.1016/j.asoc.2025.112977},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112977},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Developing a forecasting model for time series based on clustering and deep learning algorithms},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluation of international market entry strategies for
mineral oil companies using a neutrosophic SWARA-CRADIS methodology.
<em>ASOC</em>, <em>174</em>, 112976. (<a
href="https://doi.org/10.1016/j.asoc.2025.112976">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Businesses encounter risks when entering new countries, but there are also opportunities. The strategy a business employs when opting to enter a new market is directly tied to its success. In this regard, the study provides an approach for evaluating new market entry strategies for businesses facilitating in the mineral oil sector and manufacturing industries. The approach includes the development of the type 2 neutrosophic step-wise weight assessment ratio analysis (SWARA)-compromise ranking of alternatives from distance to ideal solution (CRADIS) methodology, which aims to solve the problem by determining the candidate strategies and the criteria to be utilized in their evaluation. The findings revealed that market conditions are the most crucial criterion in selecting strategies for mineral oil companies intending to enter new markets. The magnitude and development potential of the new market to be entered, as well as the status of the actors, all have an impact on market conditions, which are critical for businesses. Moreover, foreign direct investment is found to be the best market entry strategy. This strategy arises because businesses aim to maximize the potential in the market they have recently entered, as well as other factors such as government incentives. The study is expected to benefit production enterprises, the mineral oil sector, the marketing field, and the literature by identifying criteria and option sets, finding the importance degrees of the criteria, selecting the ideal entry strategy, and proposing a methodology for handling uncertain data.},
  archive      = {J_ASOC},
  author       = {Ahmet Aytekin and Hilal Öztürk Küçük and Makbule Aytekin and Vladimir Simic and Dragan Pamucar},
  doi          = {10.1016/j.asoc.2025.112976},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112976},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Evaluation of international market entry strategies for mineral oil companies using a neutrosophic SWARA-CRADIS methodology},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic environment adaptive online learning with fairness
awareness via dual disentanglement. <em>ASOC</em>, <em>174</em>, 112975.
(<a href="https://doi.org/10.1016/j.asoc.2025.112975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread application of Artificial Intelligence (AI) comes with the necessity to consider and mitigate discrimination in machine learning algorithms. Most existing fair machine learning methods are only suitable for short-term and static scenarios, and thus cannot adapt to dynamically changing environments or meet the needs for real-time updates. In open dynamic scenarios, data arriving in batches needs processing in real-time, and the constantly changing environment will lead to data distribution shifts, making it difficult to ensure the fairness of models in the long run. To achieve long-term fairness of models, we propose an online dual disentanglement method that captures fair representations of non-sensitive core information in real-time within constantly changing environments, thereby enhancing the robustness of fair models. Firstly, learned representations are disentangled from environment-specific variation factors through a constrained optimization setup to ensure semantic invariance. Further, a bias disentanglement method based on supervised contrastive learning is designed. While keeping the non-sensitive core information unchanged, the sensitive information is hidden from semantic representations and the spurious correlation with target labels is cut off, so as to achieve the long-term fairness of the model decision. By formulating the fairness-aware online learning problem in dynamic environments as an online optimization problem with the long-term fairness constraint, and theoretically proving that the algorithm achieves sublinear dynamic regret and sublinear violation of cumulative unfairness under certain assumptions. Experimental evaluations on real-world datasets demonstrate the effectiveness of the proposed method, which maintains overall fairness above 80% without compromising utility, outperforming state-of-the-art baseline methods.},
  archive      = {J_ASOC},
  author       = {Qiuling Chen and Ayong Ye and Chuan Huang and Fengyu Wu},
  doi          = {10.1016/j.asoc.2025.112975},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112975},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dynamic environment adaptive online learning with fairness awareness via dual disentanglement},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring coordinated motion patterns of facial landmarks
for deepfake video detection. <em>ASOC</em>, <em>174</em>, 112974. (<a
href="https://doi.org/10.1016/j.asoc.2025.112974">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the rich geometric and motion information they contain, recent studies indicate that facial landmark clues have significant potential for deepfake video detection. In this paper, we make a key observation that there exist coordinated motions among different facial landmarks for real individuals. While the forgery methods focus more on appearance realism, thus likely to disrupt the underlying coordinated motion patterns. Inspired by this observation, this paper explores how to leverage coordinated motion patterns among facial landmarks to enhance deepfake detection. First, we introduce a coordinated motion landmarks mining strategy (CMLMS), to effectively identify correlated landmarks. Utilizing these correlations, we propose a landmark temporal dynamic relation module (LTDRM), which focuses on the coordinated motion patterns between landmarks while extracting their spatiotemporal features. Specifically, LTDRM constructs an adjacency matrix based on the correlated landmarks and uses graph convolution to selectively aggregate information between correlated landmarks. Additionally, LTDRM is a plug-and-play module and can boost the performance of existing deepfake detection methods with minimal computational overhead. Experimental results validate the effectiveness and generalizability of our method.},
  archive      = {J_ASOC},
  author       = {Yue Zhang and Run Niu and Xianlin Zhang and Siqi Chen and Mingdao Wang and Xueming Li},
  doi          = {10.1016/j.asoc.2025.112974},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112974},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Exploring coordinated motion patterns of facial landmarks for deepfake video detection},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generative fuzzer-driven vulnerability detection in the
internet of things networks. <em>ASOC</em>, <em>174</em>, 112973. (<a
href="https://doi.org/10.1016/j.asoc.2025.112973">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) paradigm has displayed tremendous growth in recent years, driving innovations such as Industry 4.0 and the creation of smart environments that enhance efficiency and asset management and enable intelligent decision-making. However, these benefits come with considerable cybersecurity risks due to inherent vulnerabilities within IoT ecosystems. Introducing potentially vulnerable IoT devices into secure environments, like smart airports, introduces new attack surfaces and vectors for exploitation. Identifying such vulnerabilities is challenging, and while traditional methods like penetration testing and vulnerability identification offer solutions, they often fall short due to IoT’s unique data diversity, hardware constraints, and complexity. We propose an intelligent mutation-based fuzzer for IoT vulnerability detection in networks to address these limitations, demonstrated through a smart airport case study. This method leverages Generative Adversarial Network (GAN)-based mutation, utilizing legitimate network communications (i.e., payloads) to produce fuzzed payloads that expose vulnerabilities. Additionally, we incorporate a large language model (LLM)-based risk assessment framework to evaluate the likelihood and impact of identified vulnerabilities, which is crucial for effectively prioritizing threats in interconnected IoT environments. This dual approach of vulnerability detection and LLM-driven risk assessment provides comprehensive insights into IoT security, enabling prioritized response actions. Experiments conducted in the UNSW Canberra IoT testbed confirm that our approach outperforms conventional vulnerability identification methods, offering a scalable solution for effective vulnerability detection and risk prioritization in complex IoT networks.},
  archive      = {J_ASOC},
  author       = {Mohammed Tanvir Masud and Nickolaos Koroniotis and Marwa Keshk and Benjamin Turnbull and Shabnam Kasra Kermanshahi and Nour Moustafa},
  doi          = {10.1016/j.asoc.2025.112973},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112973},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Generative fuzzer-driven vulnerability detection in the internet of things networks},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Target temperature field prediction via a thermodynamic
knowledge-based artificial neural network. <em>ASOC</em>, <em>174</em>,
112972. (<a href="https://doi.org/10.1016/j.asoc.2025.112972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of artificial intelligence, representation-supervised neural networks have been widely used in the fast solution of physical field. However, a large number of temperature prediction networks do not take environmental parameters into account, or only use parameters as simple input conditions, which greatly reduces the accuracy of their results. This paper proposes an accurate and low-cost method for adding the conditional parameters to intelligent prediction networks. A novel parameter encoder block is designed based on the heat transfer theory achieving thermodynamic knowledge-based parameter feature extraction. Meanwhile, an improved method for inputting time condition is proposed to characterize the temporal characteristics, which can reduce the requirement of dataset for transient temperature prediction, compared with LSTM. In addition, a thermal loss for temperature images is introduced to accelerate the convergence process in the model. Moreover, a CycleGAN-based temperature prediction network (CBTPN) is constructed for fast temperature prediction of a cube or different tanks. Temperature or infrared images predicted by our network exhibit MAE of less than 2.33 % and SSIM of more than 80.21 %. By embedding physical mechanisms into neural networks, this study this study pioneers a structured approach to refining physical parameters into thermodynamic knowledge-based signals for improved image generation, addressing the accuracy and efficiency limitations of data-driven algorithms caused by their insufficient understanding of parameter mechanisms. Finally, parameter cognitive evaluation proves that our approach can not only recognize the accurate semantics of heat transfer parameters, but also sense the meteorological laws.},
  archive      = {J_ASOC},
  author       = {Jincheng Chen and Feiding Zhu and Yuge Han and Dengfeng Ren},
  doi          = {10.1016/j.asoc.2025.112972},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112972},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Target temperature field prediction via a thermodynamic knowledge-based artificial neural network},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning in produce perception of harvesting robots: A
comprehensive review. <em>ASOC</em>, <em>174</em>, 112971. (<a
href="https://doi.org/10.1016/j.asoc.2025.112971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the global demand for produce has surged, alongside labor shortages, driving the development of agricultural automation, particularly in harvesting robots. Deep learning-based computer vision algorithms have become key to produce perception, demonstrating significant potential. We systematically review the current application of deep learning in produce perception for harvesting robots, providing an in-depth analysis of existing public datasets, with a focus on 2D produce recognition and 3D produce localization. Furthermore, we review and analyze the existing algorithms, highlighting their limitations and challenges. In addition, we explore future research directions of deep learning in produce perception, aiming to promote the continued advancement and innovation of technologies in this area.},
  archive      = {J_ASOC},
  author       = {Yuhao Jin and Xiaoyu Xia and Qizhong Gao and Yong Yue and Eng Gee Lim and Prudence Wong and Weiping Ding and Xiaohui Zhu},
  doi          = {10.1016/j.asoc.2025.112971},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112971},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Deep learning in produce perception of harvesting robots: A comprehensive review},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unmanned aerial vehicle takeoff point search algorithm with
information sharing strategy of random trees for multi-area coverage
task. <em>ASOC</em>, <em>174</em>, 112970. (<a
href="https://doi.org/10.1016/j.asoc.2025.112970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a novel approach to optimize full-coverage search in distributed task areas using a single Unmanned Ground Vehicle (UGV) to deliver an Unmanned Aerial Vehicle (UAV) to the takeoff points of each task area along the shortest possible path. Unlike the traditional Traveling Salesman Problem (TSP), task areas are not fixed nodes, and obstacles must be considered. To address these challenges, a probability-based Rapid-exploration Random Tree ( p -RRT) with an information-sharing strategy is introduced, significantly improving the efficiency of locating takeoff points in complex environments. A dual optimization method further reduces the number of nodes and path length planned by the D* algorithm, achieving up to an 80 % reduction in nodes and improving path efficiency. Additionally, a simulated annealing (SA) algorithm optimizes the connection sequence of takeoff points, reducing total path length by 35.05 % compared to the initial path and 22.66 % compared to the traditional Random Sampling Method (RSM). Experiments confirm that the proposed algorithms can effectively enhance UGV-UAV collaboration with reducing path complexity and improving energy efficiency, and thus streamline multi-area coverage tasks.},
  archive      = {J_ASOC},
  author       = {Shouwen Yao and Xiaoyu Wang and Siqi Huang and Renjie Xu and Yinghua Zhao},
  doi          = {10.1016/j.asoc.2025.112970},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112970},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Unmanned aerial vehicle takeoff point search algorithm with information sharing strategy of random trees for multi-area coverage task},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive heuristic algorithm with a collaborative search
framework for multi-UAV inspection planning. <em>ASOC</em>,
<em>174</em>, 112969. (<a
href="https://doi.org/10.1016/j.asoc.2025.112969">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-UAV inspection path planning has become an important research topic for completing inspection tasks before the data acquisition deadline. In this study, we propose an adaptive heuristic algorithm with a collaborative search framework named Sa-VCO to solve the multi-UAV inspection path planning problem. Our study includes three main novelties. First, we design a region-gridding disperse approach that transforms the primitive target regions into a set of standard target subregions, allowing the target regions with greater costs to be inspected by multiple UAVs. Second, we propose an adaptive initial solution generation strategy using the information of graph structure constructed by all targets to reduce redundant computing. Third, we established a collaborative search framework to enhance search efficiency and increase population diversity. A large number of multiple-perspective comparative experiments are provided to test Sa-VCO&#39;s performance, and the comparison results demonstrate that Sa-VCO achieves better results than other advanced algorithms, especially on large-scale data sets.},
  archive      = {J_ASOC},
  author       = {Chang He and Haibin Ouyang and Weiqing Huang and Steven Li and Chunliang Zhang and Weiping Ding and Zhi-Hui Zhan},
  doi          = {10.1016/j.asoc.2025.112969},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112969},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An adaptive heuristic algorithm with a collaborative search framework for multi-UAV inspection planning},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficiency analysis of binary metaheuristic optimization
algorithms for uncapacitated facility location problems. <em>ASOC</em>,
<em>174</em>, 112968. (<a
href="https://doi.org/10.1016/j.asoc.2025.112968">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces binary adaptations of four metaheuristic optimization algorithms: the Binary Coati Optimization Algorithm (BCOA), Binary Mexican Axolotl Optimization Algorithm (BMAO), Binary Dynamic Hunting Leadership Optimization (BDHL), and Binary Aquila Optimizer (BAO). These algorithms were evaluated for their effectiveness in solving Uncapacitated Facility Location (UFL) problems, which aim to minimize total costs associated with customer-facility allocations and facility opening expenses by determining the optimal number of open facilities. Using 15 UFL problem instances from the OR-Lib dataset, the study assessed algorithm performance across 17 transfer functions (TFs), including S-shaped, V-shaped, and other variants, to address the binary nature of these problems. Performance metrics such as the best, worst, average, standard deviation, and GAP values were analyzed for each binary algorithm. Additionally, statistical analyses were conducted to further assess algorithmic performance. The Kolmogorov-Smirnov (KS) normality test was applied to determine the distribution characteristics of the results, followed by either ANOVA or Kruskal-Wallis tests, depending on the normality of the distributions. These statistical tests revealed significant differences in algorithm performance across different problem instances. Rank values were calculated based on GAP values and CPU times to facilitate comparisons across algorithm versions for the 15 UFL problems. Results underscored the critical role of TF selection in optimizing algorithm efficiency: BCOA performed best with TF11, BMAO with TF16 and TF17, BAO with TF10, and BDHL with TF15. Finally, a performance comparison on GAP values was conducted with two state-of-the-art PSO variants adapted for binary optimization. The proposed algorithms demonstrated either superior or competitive performance in solving UFL problems, validating their efficacy in complex optimization tasks and highlighting the influence of TFs on their performance.},
  archive      = {J_ASOC},
  author       = {Tahir Sag and Aysegul Ihsan},
  doi          = {10.1016/j.asoc.2025.112968},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112968},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Efficiency analysis of binary metaheuristic optimization algorithms for uncapacitated facility location problems},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph convolutional networks with multi-scale dynamics for
traffic speed forecasting. <em>ASOC</em>, <em>174</em>, 112966. (<a
href="https://doi.org/10.1016/j.asoc.2025.112966">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic speed forecasting remains challenging due to complex and variable road conditions. Prior research often overlooks both coarse-grained and fine-grained features in traffic data, hindering a comprehensive capture of traffic data&#39;s temporal dependencies. While graph convolutional networks (GCNs) are commonly employed to extract spatial dependencies in traffic networks, they typically view these networks from a static standpoint, failing to consider the dynamic nature of traffic network structures. This limitation restricts their effectiveness in modeling traffic networks. To address these issues, this study introduces a novel deep learning-based spatial-temporal model for precise traffic speed forecasting. This model incorporates a newly developed multi-scale transformation method, which enhances the coarse-grained and fine-grained features in traffic speed data by transforming and fusing traffic speed data, and enabling a more thorough modeling of its temporal dependencies. Additionally, we propose an innovative graph interaction strategy, combines the generated graphs with a dynamic graph convolutional network, to effectively mine the dynamic characteristics of traffic network structures, thereby enhancing the model&#39;s accuracy. Extensive experiments on two real-world datasets have demonstrated the robustness and superior performance of the proposed model, with improvements ranging from 2.2 % to 6.1 % over state-of-the-art baselines.},
  archive      = {J_ASOC},
  author       = {Dongping Zhang and Hao Lan and Mengting Wang and Jiabin Yu and Xinghao Jiang and Shifeng Zhang},
  doi          = {10.1016/j.asoc.2025.112966},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112966},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Graph convolutional networks with multi-scale dynamics for traffic speed forecasting},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LOSS-GAT: Label propagation and one-class semi-supervised
graph attention network for fake news detection. <em>ASOC</em>,
<em>174</em>, 112965. (<a
href="https://doi.org/10.1016/j.asoc.2025.112965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s world of social networks, fake news spreads quickly and causes serious problems. This has made it crucial to develop automated systems to detect and combat disinformation. Machine learning and deep learning are often used to identify fake news, but they struggle due to the lack of labeled news datasets. To address this, the One-Class Learning (OCL) approach uses a small set of labeled data. On the other hand, representing data as a graph enables access to diverse content and structural information, and label propagation methods on graphs can be effective in predicting node labels. In this paper, we adopt a graph-based model for data representation and introduce a semi-supervised and one-class approach for fake news detection, called LOSS-GAT. Initially, we employ a two-step label propagation algorithm, utilizing Graph Neural Networks (GNNs) as an initial classifier to categorize news into two groups: interest (fake) and non-interest (real). Subsequently, we enhance the graph structure using structural augmentation techniques. Ultimately, we predict the final labels for all unlabeled data using a GNN that induces randomness within the local neighborhood of nodes through the aggregation function. We evaluate our proposed method on six common datasets and compare the results against a set of baseline models, including both OCL and binary labeled models. The results demonstrate that LOSS-GAT achieves a significant improvement in performance, with enhancements ranging from 5% (on the FEVER dataset) to 20% (on the FakeNewsNet dataset) in terms of the Macro-F1 metric, all while utilizing only a limited set of labeled fake news data. Noteworthy, LOSS-GAT even outperforms binary labeled models.},
  archive      = {J_ASOC},
  author       = {Batool Lakzaei and Mostafa Haghir Chehreghani and Alireza Bagheri},
  doi          = {10.1016/j.asoc.2025.112965},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112965},
  shortjournal = {Appl. Soft. Comput.},
  title        = {LOSS-GAT: Label propagation and one-class semi-supervised graph attention network for fake news detection},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Art style classification via self-supervised dual-teacher
knowledge distillation. <em>ASOC</em>, <em>174</em>, 112964. (<a
href="https://doi.org/10.1016/j.asoc.2025.112964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Art style classification plays a crucial role in computational aesthetics. Traditional deep learning-based methods for art style classification typically require a large number of labeled images, which are scarce in the art domain. To address this challenge, we propose a self-supervised learning method specifically tailored for art style classification. Our method effectively learns image style features using unlabeled images. Specifically, we introduce a novel self-supervised learning approach based on the popular contrastive learning framework, incorporating a unique dual-teacher knowledge distillation technique. The two teacher networks provide complementary guidance to the student network. Each teacher network focuses on extracting distinct features, offering diverse perspectives. This collaborative guidance enables the student network to learn detailed and robust representations of art style attributes. Furthermore, recognizing the Gram matrix’s capability to capture image style through feature correlations, we explicitly integrate it into our self-supervised learning framework. We propose a relation alignment loss to train the network, leveraging image relationships. This loss function has shown promising results compared to the commonly used InfoNCE loss. To validate our proposed method, we conducted extensive experiments on three publicly available datasets: WikiArt, Pandora18k, and Flickr. The experimental results demonstrate the superiority of our method, significantly outperforming state-of-the-art self-supervised learning methods. Additionally, when compared with supervised methods, our approach shows competitive results, notably surpassing supervised learning methods on the Flickr dataset. Ablation experiments further verify the efficacy of each component of our proposed network. The code is publicly available at: https://github.com/lm-oc/dual_signal_gram_matrix .},
  archive      = {J_ASOC},
  author       = {Mei Luo and Li Liu and Yue Lu and Ching Y. Suen},
  doi          = {10.1016/j.asoc.2025.112964},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112964},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Art style classification via self-supervised dual-teacher knowledge distillation},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Saccade inspired attentive visual patch transformer for
image sentiment analysis. <em>ASOC</em>, <em>174</em>, 112963. (<a
href="https://doi.org/10.1016/j.asoc.2025.112963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The generation of image-evoked emotion is usually regarded as a transient process in the image sentiment analysis. However, according to the saccade mechanism of the human visual system, the evoked emotion generated during the saccade process changes over time and attention. Based on above analysis, we propose an Attentive Visual Patch Transformer (AVPT), using visual attention sequence to represent the sentiment context of images and predict the possible distribution of sentiment. In AVPT, the spatial structure in the form of patches are reconstructed and reorganized by visual attention shift sequentially. Simultaneously, the temporal characteristics of attention shift are introduced to the relative position encoding, and merged in a self-attention manner to form a spatial–temporal process similarly to the human visual system. Specifically, we propose a sequence attention shift module to simulate the saccade process, which obtains sequence attention and reduces the computational effort by group attentive convolutional gate recurrent unit. Then, a spatial–temporal correlation encoder module is proposed to encode temporal attention with spatial visual features and obtain the sequential visual features of saccade. Finally, a self-attention fusion module is used to extract the correlation hidden in the relative encoding features. Our proposed AVPT achieves excellent performance on visual sentiment distribution prediction and is comparable to state-of-the-art methods, as demonstrated by extensive experiments on the Flickr_LDL and Twitter_LDL datasets.},
  archive      = {J_ASOC},
  author       = {Jing Zhang and Jixiang Zhu and Han Sun and Xinzhou Zhang and Jiangpei Liu},
  doi          = {10.1016/j.asoc.2025.112963},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112963},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Saccade inspired attentive visual patch transformer for image sentiment analysis},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual linear latent space constrained generative adversarial
networks for hyperspectral image classification. <em>ASOC</em>,
<em>174</em>, 112962. (<a
href="https://doi.org/10.1016/j.asoc.2025.112962">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral image classification is a critical challenge in remote sensing due to the high dimensionality of the data and the scarcity of labeled samples. In this study, we propose a novel Dual-Line Latent Space Constrained Generative Adversarial Network (DLC-GAN) that integrates spatial and spectral feature extraction through dual pathways and incorporates latent space constraints to enhance classification robustness. Unlike existing methods, the DLC-GAN employs a bilinear structure to extract complementary information, improving both feature representation and classification accuracy. The model was evaluated on benchmark datasets such as Indian Pines, Pavia University, and Salinas, achieving state-of-the-art performance. Specifically, the DLC-GAN demonstrated improvements in overall accuracy by 5–11 % compared to recent methods and exhibited superior adaptability to limited training data. These findings underscore the potential of DLC-GAN in addressing critical challenges in hyperspectral image classification, with promising applications in environmental monitoring, agricultural management, and urban planning.},
  archive      = {J_ASOC},
  author       = {Kefen Mou and Sha Gao and Muhammet Deveci and Seifedine Kadry},
  doi          = {10.1016/j.asoc.2025.112962},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112962},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dual linear latent space constrained generative adversarial networks for hyperspectral image classification},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inter-block ladder-style transformer model with
multi-subspace feature adjustment for object re-identification.
<em>ASOC</em>, <em>174</em>, 112961. (<a
href="https://doi.org/10.1016/j.asoc.2025.112961">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object re-identification aims to retrieve specific objects across multiple cameras and has garnered significant attention. Currently, transformer-based methods have taken a dominant position. However, most approaches embed inherent transformer encoders for feature extraction directly. These methods handle all patch tokens uniformly, failing to distinguish salient and non-salient patch tokens for discriminative feature expression. To this end, this work proposes a novel inter-block ladder-style transformer (IBLSFormer) for object re-identification. Firstly, a multi-subspace feature adjustment (MSFA) module is designed to adjust the patch features via class-patch interaction in multiple subspaces including Euclidean distance subspace, cosine distance subspace, and KL divergence subspace. The MSFA module can enhance the salient patch tokens and weaken the non-salient patch tokens simultaneously to focus on discriminative patches. Afterwards, an IBLSFormer is designed by inserting MSFA modules with distinct configurations into the vision transformer. The narrow-to-wide ladder-style constraints are embedded in MSFA modules based on embedding depth to highlight the feature differences across different levels and ameliorate the feature learning. Our method achieves mAP/Rank-1 of 88.7%/95.3%, 81.4%/90.4%, 80.0%/97.1%, and 89.4%/83.6% on four object re-identification datasets. Extensive experiments show IBLSFormer is superior to other methods in learning discriminative and robust representations for object re-identification.},
  archive      = {J_ASOC},
  author       = {Zhi Yu and Zhiyong Huang and Mingyang Hou and Jiaming Pei and Daming Sun},
  doi          = {10.1016/j.asoc.2025.112961},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112961},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Inter-block ladder-style transformer model with multi-subspace feature adjustment for object re-identification},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Geometrical invariant generative invisible hyperlinks based
on feature points. <em>ASOC</em>, <em>174</em>, 112959. (<a
href="https://doi.org/10.1016/j.asoc.2025.112959">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To enhance the visual diversity of Quick Response (QR) codes while ensuring their robust decoding capabilities, this paper introduces an innovative invisible hyperlink generation system. The system can use a message sequence to directly generate a hyperlink image. By harnessing the latent space of a suggested feature point generation network, the system extends the robustness of image feature points to the hyperlink images it generates. Specially, an image generation network is first designed to synthesize high-quality images based on feature point data. Subsequently, a set of lightweight message encoder and decoder are introduced to embed message bits into the latent space of the image generation network. Experimental results show that the proposed invisible hyperlink generation system can successfully generate images containing hyperlinks, exhibiting remarkable resilience against common signal processing and geometric distortions. It harbors diverse potential applications, encompassing website URLs, contact information, product specifics, and numerous other use cases.},
  archive      = {J_ASOC},
  author       = {Zecheng Peng and Bingwen Feng and Xiaotao Xu and Jilian Zhang and Donghong Cai and Wei Lu},
  doi          = {10.1016/j.asoc.2025.112959},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112959},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Geometrical invariant generative invisible hyperlinks based on feature points},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sentiment analysis and emotion recognition in social media:
A comprehensive survey. <em>ASOC</em>, <em>174</em>, 112958. (<a
href="https://doi.org/10.1016/j.asoc.2025.112958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment Analysis (SA) and emotion recognition is the fundamental dialogue system that recently gained more attention. It is applied in many scenarios like mining the opinions of the speaker’s conversation and enhancing the feedback of the robot agent. Furthermore, the live conversation is used to generate the talks through certain sentiments to enhance the human-machine interaction. This survey focuses the researchers on handling the SA and classification of various sentences in social media by reviewing various approaches. This analysis explains the 50 research articles from different methods used for SA and sentiment classification in social media. Finally, the evaluation of this survey is performed based on the publication year, various approaches, evaluation metrics, and tools. Moreover, the collected 50 research papers are categorized into different techniques, such as deep learning (DL) based methods, machine learning (ML) based methods, lexicon-based methods, hybrid-based methods, and dependency-based methods. Therefore, from this survey, it is clearly shown that the DL-based method is the most utilized approach in many research papers. Similarly, python is the most used tool for SA and classification, and real-time dataset is a commonly used dataset for SA and classification. Likewise, accuracy is repeatedly employed in metrics with the highest value.},
  archive      = {J_ASOC},
  author       = {Mrunmayee Bachate and Suchitra S},
  doi          = {10.1016/j.asoc.2025.112958},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112958},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Sentiment analysis and emotion recognition in social media: A comprehensive survey},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Short-term forecasting for port throughput time series based
on multi-modal fuzzy information granule. <em>ASOC</em>, <em>174</em>,
112957. (<a href="https://doi.org/10.1016/j.asoc.2025.112957">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Port throughput forecasting is a crucial task that enables port managers to efficiently plan operations, optimize resource utilization, and manage risks. Simultaneously, accurate throughput predictions can prevent port congestion, reduce logistics delays, and enhance cargo handling efficiency, thereby improving port operational efficiency and customer satisfaction. While the existing models often show poor prediction accuracy, because they fail to capture data information comprehensive and produce the iterative errors in short-term forecasting. To address these challenges, a novel short-term time series prediction model is designed, fuzzy information granule (FIG) based model. Different from the existing models, our model incorporates an algorithm based on l 1 -trend filtering to dissect port throughput data into linear trend series and random series, effectively revealing the multi-modal information within data--linear modality and non-linear modality. These multiple modalities allow for a better understanding of throughput changes. Following such multi-modal characteristics, the multi-modal FIG, comprising Gaussian polynomial FIG and Gaussian FIG, is constructed, where the former reflects data linear modality and the latter reflects non-linear modality. Through meticulous data information mining and description, the innovative model achieves short-term forecasting at the granular level, reducing the cumulative errors in iteration. The novel designed FIG based model demonstrates superior accuracy and reliability compared to other 10 models across four metrics, mean absolute error, root mean squared error, mean absolute percentage error, and Wilcoxon signed rank test, which are tested on the data from ports including Ningbo, New York, Shanghai, Singapore, Qingdao, and Malaysia. The application of our model in short-term port throughput forecasting holds significant potential impact in both port operations management and computer science domains.},
  archive      = {J_ASOC},
  author       = {Fang Li and Wen Tong and Xiyang Yang},
  doi          = {10.1016/j.asoc.2025.112957},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112957},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Short-term forecasting for port throughput time series based on multi-modal fuzzy information granule},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiplex network influence maximization based on
representation learning method. <em>ASOC</em>, <em>174</em>, 112956. (<a
href="https://doi.org/10.1016/j.asoc.2025.112956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influence maximization based on representation learning has garnered significant attention in recent years, with numerous studies focusing on monolayer networks. However, given the inherent complexity and multiplicity of social networks, addressing the Multiplex network Influence Maximization (MIM) problem is more practical. The MIM problem aims to find a set of seed nodes to maximize the spread of influence throughout the multiplex network. To tackle this issue, this paper introduces a reverse random walk centrality method based on multiplex network representation learning. This method leverages multiplex network representation learning to derive node embeddings across different layers of the network. By calculating similarity weights between nodes within each layer, a reverse random walk is performed to quantify node importance based on the frequency of visits. The top-k nodes with the highest visit counts are then selected as seed nodes. Both single influence propagation and a coupled spread model that integrates competitive and cooperative influence dynamics are considered. Extensive experiments on several real-world datasets demonstrate that the proposed method outperforms existing techniques in terms of effectiveness, providing robust seed node selection for influence maximization. These findings highlight the efficiency and applicability of the proposed method for practical multiplex network scenarios.},
  archive      = {J_ASOC},
  author       = {Hegui Zhang and Dapeng Zhang and Yun Wan and Renbin Pan and Gang Kou},
  doi          = {10.1016/j.asoc.2025.112956},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112956},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multiplex network influence maximization based on representation learning method},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal fine-grained reasoning for post quality
evaluation. <em>ASOC</em>, <em>174</em>, 112955. (<a
href="https://doi.org/10.1016/j.asoc.2025.112955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate assessment of post quality frequently necessitates complex relational reasoning skills that emulate human cognitive processes, thereby requiring the modeling of nuanced relationships. However, existing research on post-quality assessment suffers from the following problems: (1) They are often categorization tasks that rely solely on unimodal data, which inadequately captures information in multimodal contexts and fails to differentiate the quality of students’ posts finely. (2) They ignore the noise in the multimodal deep fusion between posts and topics, which may produce misleading information for the model. (3) They do not adequately capture the complex and fine-grained relationships between post and topic, resulting in an inaccurate evaluation, such as relevance and comprehensiveness. Based on the above challenges, the Multimodal Fine-grained Topic-post Relational Reasoning(MFTRR) framework is proposed for modeling fine-grained cues by simulating the human thinking process. It consists of the local–global semantic correlation reasoning module and the multi-level evidential relational reasoning module. Specifically, MFTRR addresses the challenge of unimodal and categorization task limitations by framing post-quality assessment as a ranking task and integrating multimodal data to more effectively distinguish quality differences. To capture the most relevant semantic relationships, the Local–Global Semantic Correlation Reasoning Module enables deep interactions between posts and topics at both local and global scales. It is complemented by a topic-based maximum information fusion mechanism to filter out noise. Furthermore, to model complex and subtle relational reasoning, the Multi-Level Evidential Relational Reasoning Module analyzes topic-post relationships at both macro and micro levels by identifying critical cues and delving into granular relational cues. MFTRR is evaluated using three newly curated multimodal topic-post datasets, in addition to the publicly available Lazada-Home dataset. Experimental results indicate that MFTRR outperforms state-of-the-art baselines, achieving a 9.52% improvement in the NDCG@3 metric compared to the best text-only method on the Art History course dataset.},
  archive      = {J_ASOC},
  author       = {Xiaoxu Guo and Siyan Liang and Yachao Cui and Juxiang Zhou and Lei Wang and Han Cao},
  doi          = {10.1016/j.asoc.2025.112955},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112955},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multimodal fine-grained reasoning for post quality evaluation},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A method based on generative adversarial networks for
disentangling physical and chemical properties of stars in astronomical
spectra. <em>ASOC</em>, <em>174</em>, 112954. (<a
href="https://doi.org/10.1016/j.asoc.2025.112954">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents the design of an autoencoder architecture that uses adversarial training in the context of astrophysical spectral analysis. We aim to develop a middle representation of stellar spectra in which the influence of the most prominent physical properties, such as surface temperature and gravity, is effectively removed. This allows the variance within the representation to primarily reflect the effects of the star’s chemical composition on the spectrum. We apply a scheme of deep learning to unravel in the latent space the desired parameters of the rest of the information contained in the data. This work proposes a version of adversarial training that uses one discriminator per parameter to be disentangled, avoiding the exponential combination that occurs when using a single discriminator. Synthetic astronomical data from the APOGEE and Gaia surveys were used to test the method’s effectiveness. Our approach demonstrates a marked improvement in disentangling, reflected in an improvement in the R 2 score of up to 0.7. Additionally, we introduce an ad-hoc framework, GANDALF, designed to facilitate visualization and adaptation of the methodology to other domains in astronomical spectroscopy.},
  archive      = {J_ASOC},
  author       = {Raúl Santoveña and Carlos Dafonte and Minia Manteiga},
  doi          = {10.1016/j.asoc.2025.112954},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112954},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A method based on generative adversarial networks for disentangling physical and chemical properties of stars in astronomical spectra},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hyperspectral image classification based on ConvGRU and
spectral–spatial joint attention. <em>ASOC</em>, <em>174</em>, 112949.
(<a href="https://doi.org/10.1016/j.asoc.2025.112949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In hyperspectral image classification, methods based on spectral–spatial joint attention mechanisms have demonstrated the ability to effectively enhance feature extraction. However, existing approaches still face limitations: spectral attention mechanisms often lack local–global feature interaction, spatial attention fails to fully exploit multi-scale information, and the joint modeling of spectral and spatial features remains insufficiently explored. To address these issues, this paper proposes a spectral–spatial joint attention network based on Convolutional Gated Recurrent Units (ConvGRU). First, a Local-Global Spectral Attention (LGSA) mechanism is designed, where one-dimensional convolution extracts local spectral features and fully connected layers enable global feature interaction. Second, a Multi-Scale Spatial Attention (MSSA) mechanism is introduced, employing three convolutional branches with different receptive fields to capture spatial features, followed by hierarchical feature fusion via 1 × 1 convolution. Finally, a channel-level feature fusion strategy based on ConvGRU is proposed, leveraging sequence modeling to achieve channel-wise joint enhancement of LGSA and MSSA, thereby enabling deep coupling of spectral and spatial features. Comparative experiments on three public datasets demonstrate that the proposed method outperforms seven state-of-the-art algorithms in terms of classification performance.},
  archive      = {J_ASOC},
  author       = {Ronghua Shang and Jie Yang and Jie Feng and Yangyang Li and Songhua Xu},
  doi          = {10.1016/j.asoc.2025.112949},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112949},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Hyperspectral image classification based on ConvGRU and spectral–spatial joint attention},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptation framework with unified embedding
reconstruction for cross-corpus speech emotion recognition.
<em>ASOC</em>, <em>174</em>, 112948. (<a
href="https://doi.org/10.1016/j.asoc.2025.112948">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is challenging for speech emotion recognition (SER) to maintain robustness under cross-domain scenarios. Unsupervised domain adaptation (UDA) algorithms have been explored to address the domain shift in SER without relying on emotion labels in the target domain. As a promising framework in UDAs, self-supervised learning (SSL)-based domain exploration (SDE) investigates the domain and structural information within the target domain, aligning domain discrepancies while preserving the model’s emotion discrimination capability. However, SSL often inadvertently introduces emotion-irrelevant information, adversely affecting the UDA performance. To resolve this, we introduce a novel UDA framework called unified SDE (U-SDE), where both source and target domains conduct a unified SSL task. In the source domain, U-SDE guides the source SSL to focus on emotion-related information due to supervised emotion classification constraints. Simultaneously, in the target domain, shared network weights enable the target SSL branch to concentrate on intrinsic emotional and domain features. However, simply using existing SSL algorithms to implement this framework might disrupt the training of the supervised SER branch. To overcome this, we propose the embedding reconstruction of masked speech (ERMS) algorithm. In ERMS, the emotion encoder transforms the embedding of the masked speech to match the embedding of its corresponding unmasked speech, thereby capturing the emotion discriminative feature within the sample. Finally, we employ ERMS to realize the proposed U-SDE paradigm, termed unified ERMS (U-ERMS). We conducted systematic cross-domain SER experiments by designing 52 scenarios using seven well-known datasets. Experimental results showed that the proposed U-ERMS achieved state-of-the-art performance in cross-domain SERs.},
  archive      = {J_ASOC},
  author       = {Ruiteng Zhang and Jianguo Wei and Xugang Lu and Yongwei Li and Wenhuan Lu and Lin Zhang and Junhai Xu},
  doi          = {10.1016/j.asoc.2025.112948},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112948},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An adaptation framework with unified embedding reconstruction for cross-corpus speech emotion recognition},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Grey prediction evolution algorithm with a dominator
guidance strategy for solving multi-level image thresholding.
<em>ASOC</em>, <em>174</em>, 112947. (<a
href="https://doi.org/10.1016/j.asoc.2025.112947">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-level thresholding (MLT) stands as a pivotal method for extracting target information from images. Meta-heuristic algorithms provide an efficient way to implement MLT and retains more research space for accuracy optimization of high-dimensional multi-level thresholding (HDMLT) of images than they do for low-dimensional multi-level thresholding (LDMIT). In order to improve the algorithmic accuracy in solving the high-dimensional problems, a grey prediction evolution algorithm with a dominator guidance strategy (GPEdg) is proposed in this paper. GPEdg employs Otsu’s method as its objective function to find the best threshold configuration. The novel operator in the algorithm, i.e., a dominator guidance (dg) strategy, uses a linear combination of three difference vectors to guide the top 50% individuals of populations to learn from the top 20% of them. An efficient balance of search abilities suitable for solving HDMLT problems is expected to be achieved by injecting the local search capability of the dg strategy into GPE’s powerful global search capability. Furthermore, a thresholding morphological profile based method (TMP) leverages the thresholding results generated by GPEdg to train a support vector machine (SVM) for hyperspectral image classification. Numerical experiments are conducted for the newly proposed algorithm and five state-of-the-art algorithms on three image datasets to compare the performance in six metrics, i.e., peak signal-to-noise ratio, structural similarity index, features similarity index, objective function value, stability and time consumption. Overall accuracy and average accuracy are tested on two commonly used hyperspectral image data. The results show that GPEdg exhibits outstanding thresholding performance while TMP enhances the classification accuracy of these images. If this paper is accepted, Matlab_codes associated with this paper will be uploaded to https://github.com/Zhongbo-Hu/Prediction-Evolutionary-Algorithm-HOMEPAGE},
  archive      = {J_ASOC},
  author       = {Peixin Yang and Zhongbo Hu and Yang Zhou and Qinghua Su and Wentao Xiong},
  doi          = {10.1016/j.asoc.2025.112947},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112947},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Grey prediction evolution algorithm with a dominator guidance strategy for solving multi-level image thresholding},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pseudo-deep unsupervised model-based clustering for brain
tumor detection in magnetic resonance images. <em>ASOC</em>,
<em>174</em>, 112940. (<a
href="https://doi.org/10.1016/j.asoc.2025.112940">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel unsupervised pseudo-deep algorithm, Mixtures of Factor Analyzers based on Rows Iterative Clustering with Image Rotation according to Dimension (MFARICIRD), for accurate and automatic detection of brain tumors in grayscale magnetic resonance images. The main goal is to extract the region of interest (ROI) containing tumors using a pseudo-deep framework with iterative clustering. This framework incorporates a layer by layer structure inspired by deep learning, using a mixture of agent analysts to optimize the clustering process. In each computational layer, the algorithm first rotates the image 90 degrees clockwise if the number of rows is greater than the number of columns. Then, it performs clustering on the image using the estimated parameters of optimal clusters and the optimal number of clusters until the tumor-containing cluster is identified. The identified cluster is used as input for the next layer. These computational processes are iterated layer by layer until the proposed convergence criterion, which acts as the stopping rule, is satisfied. The algorithm uses fuzzy c-mean clustering to binarize the output cluster of the final layer (ROI), enabling the exact extraction of the tumor shape. Finally, it localizes the detected tumor within the original image. A comprehensive evaluation of the effectiveness of the proposed algorithm is presented on the BraTS2020, BraTS2019, and BraTS2018 datasets, demonstrating exceptional performance in detecting tumors with different locations, sizes, and complexities. The algorithm achieved an accuracy and Dice similarity coefficient of 99.96 + 0.0073 % and 98.97 % on the BraTS2018, 99.97 + 0.0087 % and 99.22 + 0.0051 % on the BraTS2019, and 99.98 + 0.0038 % and 99.33 + 0.0072 % on the BraTS2020. The results highlight the remarkable capability of the algorithm in dealing with complex and high-dimensional images, especially in detecting small and unclear tumors. Moreover, it outperforms existing diagnostic methods, significantly improving the accuracy and reliability of brain tumor detection.},
  archive      = {J_ASOC},
  author       = {Rahman Farnoosh and Fatemeh Aghagoli},
  doi          = {10.1016/j.asoc.2025.112940},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112940},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Pseudo-deep unsupervised model-based clustering for brain tumor detection in magnetic resonance images},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mindful human digital twins: Integrating theory of mind with
multi-agent reinforcement learning. <em>ASOC</em>, <em>174</em>, 112939.
(<a href="https://doi.org/10.1016/j.asoc.2025.112939">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Agent Reinforcement Learning (MARL) is focused on enabling autonomous agents to learn and adapt to complex environments through interactions with their surroundings and other agents. A key challenge in MARL is developing agents with the human-like capacity to understand, predict, and respond to the intentions and mental states of their peers. This capability, commonly referred to as the Theory of Mind (ToM), is central to fostering more sophisticated and realistic interactions among autonomous agents. In this paper, we propose a novel approach that leverages Theory-Theory (TT) and Simulation-Theory (ST) to enhance ToM within the MARL framework. Building on the Digital Twins (DT) framework, we introduce the Mindful Human Digital Twin (MHDT). These intelligent systems enriched with ToM capabilities bridge the gap between artificial agents and human-like interactions. In this work, we utilized OpenAI Gymnasium to perform simulations and evaluate the effectiveness of our approach. This work represents a significant step forward in Artificial Intelligence (AI), resulting in socially intelligent systems capable of natural and intuitive interactions with both their environment and other agents. This approach is particularly effective in addressing critical social challenges such as school bullying. This research not only advances the growing field of MARL but also paves the way for sophisticated AI systems with enhanced ToM abilities, tailored for complex and sensitive real-world applications.},
  archive      = {J_ASOC},
  author       = {Luis Zhinin-Vera and Elena Pretel and Víctor López-Jaquero and Elena Navarro and Pascual González},
  doi          = {10.1016/j.asoc.2025.112939},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112939},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Mindful human digital twins: Integrating theory of mind with multi-agent reinforcement learning},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A particle swarm optimization and constraint
programming-based approach for integrated process planning and
scheduling with lot streaming problem. <em>ASOC</em>, <em>174</em>,
112938. (<a href="https://doi.org/10.1016/j.asoc.2025.112938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the integrated process planning and scheduling with lot streaming (IPPS-LS) problem, which consists of lot splitting, process planning, and shop scheduling. Although the IPPS-LS problem is common in the manufacturing of flexible process products, it has not been extensively studied due to its high complexity. Hence, this study develops an enhanced particle swarm optimization algorithm based on constraint programming (CP) to minimize makespan. The proposed algorithm employs finite condition and relaxation models for particle reconfiguration and re-optimization. To achieve it, two types of relaxation models are constructed by decomposing the multiple constraints of the CP model. The algorithm dynamically updates particle encoding sequences based on model accuracy, effectively reducing invalid searches and accelerating the search process. The proposed algorithm is compared with models and other metaheuristic algorithms on 120 test instances. The impact of the relaxed CP strategy and particle swarm optimization algorithm on the proposed algorithm performance is also analyzed. Finally, a significance of difference validation is performed. Computational experiments demonstrate the efficiency of the proposed algorithm in solving the IPPS-LS problem of varying scales. In addition, the relaxed CP strategy exhibits a more significant improvement effect for medium-scale problems compared to small and large-scale problems.},
  archive      = {J_ASOC},
  author       = {Mengya Zhang and Xinyu Li and Liang Gao and Qihao Liu},
  doi          = {10.1016/j.asoc.2025.112938},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112938},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A particle swarm optimization and constraint programming-based approach for integrated process planning and scheduling with lot streaming problem},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heuristic-aided fusion serial cascaded deep network for
handwritten character recognition from handwritten images using
optimization strategy. <em>ASOC</em>, <em>174</em>, 112937. (<a
href="https://doi.org/10.1016/j.asoc.2025.112937">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handwritten Character Recognition (HCR) identifies and interprets handwritten text, converting it into machine-readable characters. However, it faces challenges with South Indian languages due to their complex scripts and intricate characters. So, in this work, a novel HCR model was introduced for automatic recognition of handwritten characters in South Indian languages. At first, required Telugu and Kannada handwritten images are collected from standard sources, and given into the segmentation phase using Active Contour. Then, the textural pattern generation is performed using the Adaptive Local Weber Pattern (ALWP). The weights in the ALWP are optimally tuned using the Improved Snow Leopard Optimization Algorithm (ISLOA). Finally, the ALWP generates a textural pattern, and then the generated textural pattern is given to the Hybrid Serial Cascaded Deep Network (HSCDNet) for the final handwritten character recognition process. Here, the Convolutional Autoencoder (CAE) and Deep Belief Network (DBN) are serially connected to the network. Finally, the implemented HCR model’s performance is evaluated by comparing it with various traditional approaches. The developed model attained the accuracy of dataset 1 is 93.45 %, dataset 2 is 93.11 %, and dataset 3 is 94.13 %. Thus, it proved that the developed model can effectively and easily recognize the curves in the Telugu and Kannada handwritten scripts, making it suitable for a wide range of applications.},
  archive      = {J_ASOC},
  author       = {Triveni Banavatu and Govindaswamy Parthasarathy},
  doi          = {10.1016/j.asoc.2025.112937},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112937},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Heuristic-aided fusion serial cascaded deep network for handwritten character recognition from handwritten images using optimization strategy},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized echo state network for error compensation based on
transfer learning. <em>ASOC</em>, <em>174</em>, 112935. (<a
href="https://doi.org/10.1016/j.asoc.2025.112935">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Echo State Network (ESN) is widely applied in nonlinear system modeling, but its performance is often limited by a lack of error autocorrelation analysis, leading to reduced modeling accuracy. Existing extensions, such as SR-ESN and ERBM, primarily focus on structural optimization or feature representation but fail to effectively address autocorrelation errors. To overcome these limitations, we propose a Transfer Learning-based Echo State Network (TLESN) that compensates for errors in realtime to enhance prediction accuracy. The TLESN integrates a computing layer based on ESN and a compensation layer employing transfer learning, which dynamically adjusts output weights. To validate the proposed model, experiments are conducted on the Mackey-Glass time series, a practical Sunspot dataset, and a real-world industrial dataset. Results demonstrate that TLESN effectively mitigates autocorrelation errors, achieving at least a 17% improvement in prediction accuracy compared to existing ESN extensions.},
  archive      = {J_ASOC},
  author       = {Yingqin Zhu and Yue Liu and Zhaozhao Zhang and Wen Yu},
  doi          = {10.1016/j.asoc.2025.112935},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112935},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Optimized echo state network for error compensation based on transfer learning},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain adaptive person re-identification with noise
optimization and dynamic weighting. <em>ASOC</em>, <em>174</em>, 112932.
(<a href="https://doi.org/10.1016/j.asoc.2025.112932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptive person re-identification (Re-ID) faces challenges due to inherent noise from limited domain transferability and the uncertainty in pseudo-label generation. To address this, we propose NODW (Noise Optimization and Dynamic Weighting), a comprehensive domain adaptive person Re-ID framework that systematically tackles these issues through quantitative noise assessment and dynamic optimization. Our method proposes: (1) an enhanced ResNet50-pro backbone specifically designed for cross-domain feature extraction, (2) a silhouette coefficient-based module for pseudo-label quality assessment with dynamic weighting, (3) a Maximum Mean Discrepancy (MMD)-based module for minimizing domain transferability limitations, and (4) a robust consistency supervision mechanism to ensure stable feature learning. Extensive experiments demonstrate state-of-the-art performance across multiple domain transfer tasks, achieving mAP scores of 73.8% (Market to Duke), 84.7% (Duke to Market), 34.2% (Market to MSMT), and 35.6% (Duke to MSMT). These results represent significant improvements over existing methods, particularly in challenging scenarios with large domain gaps, validating the effectiveness of our noise-aware adaptation strategy.},
  archive      = {J_ASOC},
  author       = {Zhengyang Wang and Xiufen Ye and Xue Shang and Shuxiang Guo},
  doi          = {10.1016/j.asoc.2025.112932},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112932},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Domain adaptive person re-identification with noise optimization and dynamic weighting},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Software and hardware synergy for accelerated plant disease
identification. <em>ASOC</em>, <em>174</em>, 112926. (<a
href="https://doi.org/10.1016/j.asoc.2025.112926">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Plant diseases are one of the main causes of reduced crop yields. Therefore, it is necessary to adopt timely and effective identification methods and take corresponding measures. Some physical and biological detection methods have been proposed by researchers, but these methods require specialized techniques and expensive detection costs. Furthermore, the limited number of skilled technicians means that disease identification is not always timely or effective. To achieve real-time identification of plant diseases in remote areas where network and circuit are not well connected, We adopted a hardware and software co-acceleration approach to implement the design. First, we designed a lightweight convolutional neural network (CNN) and trained this network using a knowledge distillation approach. Then, we quantified the model parameters into int8 type using a method of model quantization to further compress the model size. After compression, the model size of the network is 0.035 MB and the recognition accuracy is 94.06% on the test set of the experiment. In order to deploy the proposed network on resource constrained Field-Programmable Gate Array (FPGA) devices, we used time-division multiplexing and feature map segmentation to deploy the network. Finally, our design is implemented on ZYNQ7020 with an inference speed of 35.73ms/frame and a power consumption of 1.97 W. The experimental results show that our design has the advantages of consuming less FPGA resources, low power consumption, high speed and portability. It can be used for disease recognition in multiple plant classes.},
  archive      = {J_ASOC},
  author       = {Hongxing Wen and Chuandong Li and Xinpei Wang and Ling Chen},
  doi          = {10.1016/j.asoc.2025.112926},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112926},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Software and hardware synergy for accelerated plant disease identification},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced function approximation and applications to image
scaling: A new family of exponential sampling neural network kantorovich
operators. <em>ASOC</em>, <em>174</em>, 112923. (<a
href="https://doi.org/10.1016/j.asoc.2025.112923">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel family of exponential sampling type neural network Kantorovich operators, extending the work of Bajpeyi and Kumar (2021) and Bajpeyi (2023). Unlike previous research focused on approximating continuous functions, our operators are designed to handle Lebesgue integrable functions, offering enhanced versatility. We establish convergence theorems, analyze asymptotic behavior, and demonstrate the effectiveness of linear combinations for improving convergence rates. Our analysis extends to the multivariate setting, highlighting the operators’ capability in approximating a wide range of functions. To evaluate the practical performance of our proposed operators, we conducted numerical experiments with different sigmoidal functions and parameter values. Our findings reveal that operators activated by the Parametric sigmoid function consistently outperform those activated by other sigmoidal functions, achieving up to 20.70% reduction in maximum absolute error and 10.03% reduction in root mean squared errors. When applied to image scaling, our operators demonstrated superior performance compared to state-of-the-art methods like nearest neighbor, bilinear, and bicubic interpolation. For the ’Baboon’ image, we observed up to 5.62% increase in Peak Signal-to-Noise Ratio (PSNR) and 5.25% increase in Structural Similarity Index Measure (SSIM). Similar enhancements were observed for the ’Flowers’ and ’Retina’ images. The paper includes a detailed description of the image processing algorithm, along with a flowchart illustrating the implementation. These results underscore the operators’ potential in various machine learning tasks, motivating further research into their applications and optimization.},
  archive      = {J_ASOC},
  author       = {P.N. Agrawal and Behar Baxhaku and Artan Berisha},
  doi          = {10.1016/j.asoc.2025.112923},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112923},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Enhanced function approximation and applications to image scaling: A new family of exponential sampling neural network kantorovich operators},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust ensemble classifier for imbalanced data via
adaptive variety oversampling and embedded sampling rate. <em>ASOC</em>,
<em>174</em>, 112922. (<a
href="https://doi.org/10.1016/j.asoc.2025.112922">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel hybrid approach for addressing imbalanced data classification. The core concept involves devising a data-based oversampling algorithm to partially re-balance the data and employing an ensemble algorithm to enhance model performance. The merits of the proposed hybrid method can be highlighted as follows: (1) rather than re-balancing the data completely, an incomplete yet rational sampling rate is adopted to synthesize new samples, which can reduce the extreme imbalance ratio as well as avoid the overlap and redundancy by the complete re-balance. After oversampling, an improved adaptive boosting method is used to further contribute to the classification result; (2) with the help of temporarily generating samples in a triangular region of four selected target samples, a new synthesizing method is provided, which contributes greatly to the diversity of the new synthetic samples and the guarantee of the correctness and safety; (3) besides the number of correctly classified minority samples, the imbalance ratio of raw data is considered to make the ensemble classifier serve a further focus on minority samples and proved theoretically effective in mitigating the skew of the classification hyperplane on minority samples.},
  archive      = {J_ASOC},
  author       = {Jun Dou and Yan Song and Guoliang Wei and Xinchen Guo},
  doi          = {10.1016/j.asoc.2025.112922},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112922},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A robust ensemble classifier for imbalanced data via adaptive variety oversampling and embedded sampling rate},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forecasting time series using convolutional neural network
with multiplicative neuron. <em>ASOC</em>, <em>174</em>, 112921. (<a
href="https://doi.org/10.1016/j.asoc.2025.112921">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) are proven to be efficient in time series forecasting, however architectural selection remains a challenging task. This work aims to propose CNN, utilizing single multiplicative neuron model in forecasting time series, intended to eliminate architectural complexities of classical CNN ensuring its computational efficiency. Applicability of proposed approach is employed on financial time series datasets such as Index, Stocks, Cryptocurrencies and a commodity in evaluating the model’s performance on the basis of RMSE, MAE and R 2 values. Further, time-delay effects were also observed in datasets which has been analyzed to improve the accuracy of the proposed model. Based on the lowest RMSE and MAE values, and higher R 2 values, the optimal delay value has been analyzed which has been used for forecasting. The result demonstrates that in data sets like NIFTY50, SBI, Bitcoin, and Natural Gas, the forecasting efficiency is improved when compared to classical CNN. The results obtained can be used to draw valuable insights for decision making, which will enable future studies and facilitate easy adaptation in analyzing time series.},
  archive      = {J_ASOC},
  author       = {Shobhit Nigam},
  doi          = {10.1016/j.asoc.2025.112921},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112921},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Forecasting time series using convolutional neural network with multiplicative neuron},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised partially labeled heterogeneous feature
selection based on information-theoretic three-way decision model.
<em>ASOC</em>, <em>174</em>, 112880. (<a
href="https://doi.org/10.1016/j.asoc.2025.112880">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection plays an increasingly vital role in addressing large-scale partially labeled heterogeneous data. Three-way decision (TWD) theory is an important extension of classical two-way decision, which provides an approach to acquire a ternary classification of the universe as acceptance region, rejection region and boundary region, respectively, while the boundary region can capture the uncertain information. In this paper, taking consideration of heterogeneous data possessing tremendous unlabeled samples, we present two kinds of feature representation metric based on unlabeled sample selection mechanism to construct more effective feature selection models. Specifically, a generalized variable-precision neighborhood rough set model is first proposed based on a TWD model developed by optimal threshold pair, which describes the relationships between features and labels from a more fine-grained level. Second, a unlabeled sample selection framework is proposed to comprehensively measure the importance of unlabeled samples based on their uncertainty, graph density and label transfer ability. We then define six TWD-based measures which reveal nonlinear correlation and inconsistency between features and labels by extended information entropy and complementary entropy, respectively. Furthermore, the unified feature measures are established to boost global feature selection in partially labeled heterogeneous datasets. Finally, the corresponding feature selection algorithm is designed, and the comparative experiments demonstrate the effectiveness and efficiency.},
  archive      = {J_ASOC},
  author       = {Qianqian Sun and Hongying Zhang and Weiping Ding},
  doi          = {10.1016/j.asoc.2025.112880},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112880},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Semi-supervised partially labeled heterogeneous feature selection based on information-theoretic three-way decision model},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse-view planar 3D reconstruction method based on
hierarchical token pooling transformer. <em>ASOC</em>, <em>174</em>,
112833. (<a href="https://doi.org/10.1016/j.asoc.2025.112833">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse-view planar 3D reconstruction aims to recover scene information from limited camera frames, which poses a fundamental problem in computer vision. Although previous methods have made significant improvements in this field, they have not adequately considered the multi-scale properties of the surrounding environment, thus limiting the reconstruction performance. Additionally, the conventional feed-forward network in the vanilla Transformer is constructed using fully connected layers, lacking the ability to capture local information from image features. To address these two problems, this paper proposes a sparse-view planar 3D reconstruction method based on hierarchical token pooling Transformer ( i.e . HTP-Formers). Specifically, we utilize average pooling layers with various ratios in Transformer model to capture multi-scale features. Subsequently, we propose a depth-wise convolution based inverted residual feed-forward network to enhance local information extraction performance at negligible computational cost. To demonstrate the effectiveness of HTP-Formers on planar 3D reconstruction tasks, we thoroughly evaluate the proposed model on Matterport3D public dataset. Especially, HTP-Formers improves performance by 6.1% and 18.3% in translational and rotational errors, respectively, outperforming most existing planar 3D reconstruction methods in terms of planar correspondence inference and relative camera pose estimation.},
  archive      = {J_ASOC},
  author       = {Jiahui Zhang and Jinfu Yang and Fuji Fu and Jiaqi Ma},
  doi          = {10.1016/j.asoc.2025.112833},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112833},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Sparse-view planar 3D reconstruction method based on hierarchical token pooling transformer},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-path geometric relation-aware transformer for point
cloud classification and segmentation. <em>ASOC</em>, <em>174</em>,
112801. (<a href="https://doi.org/10.1016/j.asoc.2025.112801">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point cloud analysis is a challenging task due to the disorder and irregularity of the point cloud data. Traditional methods focus on constructing local or global geometric feature extractors to leverage the geometric features of the point cloud. However, traditional methods have the disadvantage of high time complexity and consume numerous resources because of the sophisticated extractors. This paper proposes a dual-path geometric relation-aware transformer network (DuGREAT) to aggregate local and global features, which balances computational cost, efficiency, and accuracy. DuGREAT constructs a channel adaptive multi-layer perceptron module by expanding channels of residual blocks to reinforce the local feature extraction. To obtain the geometric relation of a 3D object, we design a geometric point disentangler to categorize the point cloud into key and non-key points, respectively represented by an object’s local and global regions. With a relation-aware transformer network, the global path processes the non-key points to extract deep-level global features, and the local path focuses on the key points to calculate the difference between the local and global features. To the best of our knowledge, this is one of the successful attempts to capture and enhance geometric relations and feature fusion between key and non-key points, which provides insights for point cloud classification and segmentation. Fitted with a soft geometric affine module to alleviate the irregularity of the point cloud, DuGREAT acts better than several state-of-the-art methods on multiple datasets. Specifically, our DuGREAT achieves 94.6% accuracy on the ModelNet40 classification task and 87.3% accuracy on the ScanObjectNN classification task, outperforming the other transformer models. DuGREAT-simple, a simple version with fewer FLOPs, attains 94.2% and 87.0% accuracy on the ModelNet40 classification and ScanObjectNN classification tasks, respectively, while maintaining a faster inference speed (595.7 samples/s). Furthermore, we validate the effectiveness of the modules in DuGREAT and achieve instance mean Intersection over Union (mIoU) of 86.5% (DuGREAT) and 86.1% (DuGREAT-simple) on the ShapeNetPart segmentation task.},
  archive      = {J_ASOC},
  author       = {Xiangli Li and Qifan Wang and Baozhi Qiu},
  doi          = {10.1016/j.asoc.2025.112801},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112801},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dual-path geometric relation-aware transformer for point cloud classification and segmentation},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-objective multi-task evolutionary algorithm based on
source task transfer. <em>ASOC</em>, <em>174</em>, 112732. (<a
href="https://doi.org/10.1016/j.asoc.2025.112732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the real world, many optimization problems often do not exist in isolation, they usually have complex interactions and dependencies, and have multiple optimization goals. In order to improve the performance of individual task solving, an evolutionary multi-task multi-objective optimization algorithm (MTMOO) is proposed. However, most of the current evolutionary algorithms are based on the assumption that the prior knowledge (experience in solving optimization problems) is zero, which makes the ability of the algorithm to solve problems cannot be improved with the increase of historical experience, and greatly limits the adaptability and learning ability of the algorithm. In order to overcome this limitation, this paper proposed a multi-objective and multi-task adaptive migration Evolutionary algorithm (MOMFEA-STT). The algorithm constructs the parameter sharing model of historical task and target task online. By identifying the degree of association between different tasks, the intensity of cross-task knowledge transfer is automatically adjusted to maximize the capture, sharing and utilization of common useful knowledge to solve related tasks. In addition, in order to strengthen the exploration and exploitation ability of the algorithm and avoid the problem that the algorithm is easy to fall into the local optimum, the MOMFEA-STT adopts a new method of generation of children, generates children by using spiral search mode, and constantly adjusts the search direction of the algorithm. Experimental results show that the proposed method outperforms the existing algorithms on the multi-task optimization benchmark problems.},
  archive      = {J_ASOC},
  author       = {Zheng-Yi Chai and ying Nie and Yan-Lun Li},
  doi          = {10.1016/j.asoc.2025.112732},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112732},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-objective multi-task evolutionary algorithm based on source task transfer},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Calculating forgotten effects using fuzzy numbers based on
embedded experton structures. <em>ASOC</em>, <em>174</em>, 112720. (<a
href="https://doi.org/10.1016/j.asoc.2025.112720">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The method of calculating Forgotten Effects is designed to process a single source of information, preventing the use of multiple sources, which can generate bias in the results and avoid the wide use of this methodology in the investigations. This research aims to establish a mechanism for processing Expertons as structured data in their natural form, without decreasing entropy within the matrices of the Forgotten Effects, and thus be able to process information from many sources. This process aims to maintain the original values during the whole calculating process and avoid distorted information. The presented algorithm for calculating Forgotten Effects in decision-making under uncertainty utilizes fuzzy numbers in Expertons embedded and constitutes an innovative approach. This approach complements conventional methodologies that often rely on averages or weights to derive a single value and confirm hypotheses. This model has a different paradigm, as it detects relationships that are not visible for systematic analysis. Additionally, this research introduces various types of focus based on risk profiles for calculation strategies, yielding prudent, optimistic, and pessimistic scenarios. Moreover, the proposed algorithm provides the flexibility to choose between uncertainty or precision-focused processing to adapt to the specific approach of each context. Ultimately, an applied example is presented to validate the effectiveness and validity of the proposed model. As a contribution, this research offers the novelty of being able to calculate forgotten effects, not only based on one expert but also with an unlimited number by using the algorithm designed through the Expertons.},
  archive      = {J_ASOC},
  author       = {Darley Biviana Pacheco Cubillos and Josefa Boria Reverter and Jaime Gil Lafuente},
  doi          = {10.1016/j.asoc.2025.112720},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112720},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Calculating forgotten effects using fuzzy numbers based on embedded experton structures},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale frequency feature fusion transformer for
pediatric echocardiography analysis. <em>ASOC</em>, <em>173</em>,
112950. (<a href="https://doi.org/10.1016/j.asoc.2025.112950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Congenital heart disease (CHD) is the most common birth defect. Echocardiography analysis is essential for identifying pediatric CHD, yet existing methods often focus on single functions and lack comprehensive analysis. In ultrasound data analysis, low-frequency features reflect the overall structure and morphology of the heart, while high-frequency features emphasize the detailed characteristics of cardiac structures. However, existing intelligent analysis models apply a uniform feature processing approach to all echocardiography features, lacking adaptive learning for features at different frequencies. This limitation reduces the model’s capacity to effectively capture both the global shape and local details of echocardiography target structures. Therefore, this paper proposes a multi-scale frequency feature fusion Transformer (MFT-Former) model for the multi-functional analysis of pediatric echocardiography. Specifically, this paper first effectively implements the extraction and aggregation of coarse and fine-grained features of echocardiography by setting a multi-scale patch embedding unit. Secondly, we design a grouped frequency feature fusion Transformer block (GFFT_Block), which contains two parallel branches: an adaptive frequency feature fusion branch (AFF_Branch) and a cross-learning wavelet Transformer branch (CWT_Branch). The former is used for adaptive learning of different frequency features in a local range. The latter achieves cross-learning of different frequency features on a global range and avoids the loss of information caused by dimensionality reduction operations. Based on the parasternal short-axis view, this model identifies ventricular septal defects via echocardiography classification and realizes quantitative analysis through structural segmentation and measurement. Experimental results demonstrate that the MFT-Former outperforms the state-of-the-art algorithms and offers new perspectives for multi-functional echocardiography analysis.},
  archive      = {J_ASOC},
  author       = {Cheng Zhao and Yuanlin Liu and Weiling Chen and Zhuo Xiang and Yiyao Liu and Bei Xia and Jing Qin and Tianfu Wang and Baiying Lei},
  doi          = {10.1016/j.asoc.2025.112950},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112950},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-scale frequency feature fusion transformer for pediatric echocardiography analysis},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An interpretable dahl-LRN neural-network for accurately
modelling the systems with rate-dependent asymmetric hysteresis.
<em>ASOC</em>, <em>173</em>, 112936. (<a
href="https://doi.org/10.1016/j.asoc.2025.112936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The motion accuracy and stability of piezoelectric positioning systems are significantly compromised by inherent hysteresis and other nonlinearities. This paper presents an innovative method integrating the Dahl model with Layer Recurrent Neural Networks (LRN) to model piezoelectric actuators accurately. Initially, the Dahl model is reformulated into a neural network structure, resulting in the Dahl Neural Network (DahlNN), which strictly adheres to the underlying mathematical equations. The weights of this network directly correspond to the parameters of the Dahl equations, thereby creating a transparent neural network architecture with clear physical significance and interpretability. Subsequently, the DahlNN is enhanced by incorporating feedback mechanisms and recurrent effects from LRN, improving its ability to describe asymmetric and rate-dependent hysteresis characteristics. Extensive experiments demonstrate that, compared to LRN models without physical knowledge guidance, the proposed Dahl-LRN model reduces peak-to-valley fluctuations by 70 % and decreases the average error by approximately 97.3 %, with only a 5 % increase in computational time while maintaining interpretability and achieving superior modelling performance. Through this approach, this paper aims to provide a novel perspective on leveraging physical information to advance the application of deep learning in modelling complex physical phenomena.},
  archive      = {J_ASOC},
  author       = {Lei Ni and Hongfei Wang and Guoqiang Chen and Lanqiang Zhang and Na Yao and Geng Wang},
  doi          = {10.1016/j.asoc.2025.112936},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112936},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An interpretable dahl-LRN neural-network for accurately modelling the systems with rate-dependent asymmetric hysteresis},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous collaborative filtering contrastive learning
for social recommendation. <em>ASOC</em>, <em>173</em>, 112934. (<a
href="https://doi.org/10.1016/j.asoc.2025.112934">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative filtering methods based on Graph Neural Networks (GNNs) have gained increasing popularity in recommendation systems. These methods enhance the representation of users and items by leveraging the information of graph structure from interaction data, improving recommendation performance. However, they often face limitations due to the data sparsity issue that is common in recommendation systems. In the constructed user–item heterogeneous bipartite graph, sparse interaction data leads to a scarcity of neighbor nodes impeding the acquisition of sufficient collaborative signals via the message-passing mechanism among these neighbor nodes. We have observed that users and items can be grouped according to characteristic similarities. These groups’ common feature information can serve as supplementary data to aid in the embedding learning. So, we present the Heterogeneous Collaborative Filtering Contrastive Learning (HCFCL) method, which aims to extract two types of heterogeneous collaborative signals from interaction data: those based on neighbor nodes and those based on group features. Specifically, we design an embedding generative hypergraph network to extract group common feature information founded on the heterogeneous bipartite graph. The group common feature information is transferred via a meta network and personalized bridge functions according to individual characteristics. Additionally, the HCFCL model, combined with contrastive learning, captures the consistency of the heterogeneous collaborative signals to enhance representation. The experiment demonstrates the superior performance of the HCFCL model compared to other methods evaluated on three public datasets, demonstrating excellent and stable performance in mitigating the data sparsity issue.},
  archive      = {J_ASOC},
  author       = {Chaojun Meng and Changfan Pan and Hongji Shu and Qing Wang and Hanghui Guo and Jia Zhu},
  doi          = {10.1016/j.asoc.2025.112934},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112934},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Heterogeneous collaborative filtering contrastive learning for social recommendation},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automatic optimization for generating adversarial malware
based on prioritized evolutionary computing. <em>ASOC</em>,
<em>173</em>, 112933. (<a
href="https://doi.org/10.1016/j.asoc.2025.112933">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning has been widely applied to malware detection tasks; but unfortunately, they exhibit significant vulnerability to adversarial attacks and can be easily circumvented using perturbation carefully crafted. Concurrently, we are witnessing a corresponding increase in the attention dedicated to adversarial attacks against malware detection models. Nevertheless, current research on adversarial examples still faces obstacles such as poor escape effectiveness and difficulty in preserving functionality. Particularly, greedily recruiting the best manipulations from a vast search space often leads to poor diversity of adversarial perturbation sequence. To rectify these shortcomings, this paper proposes an automated, continuously optimized approach for generating malware adversarial examples based on evolutionary computing. Our method filters effective action sequences from a large pool of random manipulations, assigning different priorities to different actions. The generation and optimization of adversarial examples are formalized as a sparse minimization optimization problem based on a fixed-length action vector. We introduce AOP-Mal, a novel genetic framework to automatically generate and optimize adversarial examples. The initialization and evolution of the population depend on the priority of actions, as well as the proposed novel evolutionary operator. The experimental results demonstrate that our attack strategy effectively bypasses the detection mechanisms and outperforms most state-of-the-art malware adversarial frameworks. Our hope is to help researchers understand the intentions of attackers and explore more powerful defense mechanisms.},
  archive      = {J_ASOC},
  author       = {Yaochang Xu and Yong Fang and Yijia Xu and Zhan Wang},
  doi          = {10.1016/j.asoc.2025.112933},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112933},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Automatic optimization for generating adversarial malware based on prioritized evolutionary computing},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online ensemble learning-based anomaly detection for IoT
systems. <em>ASOC</em>, <em>173</em>, 112931. (<a
href="https://doi.org/10.1016/j.asoc.2025.112931">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the modern era of digital transformation, the evolution of fifth-generation (5G) wireless networks has played a pivotal role in revolutionizing communication technology and accelerating the growth of smart technology applications. As an integral element of smart technology, the Internet of Things (IoT) grapples with the problem of limited hardware performance. Cloud and fog computing-based IoT systems offer an effective solution but often encounter concept drift issues in real-time data processing due to the dynamic and imbalanced nature of IoT environments, leading to performance degradation. In this study, we propose a novel framework for drift-adaptive ensemble learning called the Adaptive Exponentially Weighted Average Ensemble (AEWAE), which consists of three stages: IoT data preprocessing, base model learning, and online ensembling. It integrates four advanced online learning methods within an ensemble approach. The crucial parameter of the AEWAE method is fine-tuned using the Particle Swarm Optimization (PSO) technique. Experimental results on four public datasets demonstrate that AEWAE-based anomaly detection effectively detects concept drift and identifies anomalies in imbalanced IoT data streams, outperforming other baseline methods in terms of accuracy, F1 score, false alarm rate (FAR), and latency.},
  archive      = {J_ASOC},
  author       = {Yafeng Wu and Lan Liu and Yongjie Yu and Guiming Chen and Junhan Hu},
  doi          = {10.1016/j.asoc.2025.112931},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112931},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Online ensemble learning-based anomaly detection for IoT systems},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual residual learning of frequency fingerprints in
detecting synthesized biomedical imagery. <em>ASOC</em>, <em>173</em>,
112930. (<a href="https://doi.org/10.1016/j.asoc.2025.112930">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial synthesis of biomedical imagery is an evolving threat yet under-addressed. The integrity of medical imaging is important for accurate diagnosis and treatment. This study addresses the potential threat of fabricated biomedical imagery, focusing on synthetic dermatological lesions and CT nodules. The Representation Similarity Matrix measured the quantitative authenticity to account for similarities of synthesized data with authentic data. The study explores traces of manipulation from frequency signatures of synthesized imagery. We propose a novel combinatorial architecture, the Dual Residual Network (DRN), capturing hidden residual traces from low-frequency fingerprints of synthetic data and exposing hidden forgeries. DRN achieves near-perfect detection rates with an accuracy of 98.80% for CT nodules and 98.97% for lesions. Equal Error Rates of the model on the two datasets exhibited a marginal improvement of 57.87% in the CT nodules compared to the skin lesions. Sensitivity and specificity play a significant role in medical diagnostics. The model achieved sensitivities of 99.31% and 98.45% and specificity of 98.80% and 99.60% for each dataset, respectively. Further verification of the frequency traces was performed by analyzing gradients in the target concepts that led to decision-making. This study equips the medical field with a powerful tool to combat the evolving threat of synthetic fraud, safeguarding patient and client safety. The potential of the technique extends beyond healthcare, offering a blueprint for tackling synthetic data across diverse domains.},
  archive      = {J_ASOC},
  author       = {Misaj Sharafudeen and Vinod Chandra S.S.},
  doi          = {10.1016/j.asoc.2025.112930},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112930},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dual residual learning of frequency fingerprints in detecting synthesized biomedical imagery},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A graph attention-based policy gradient method with an
adaptive embedding strategy for k-center problems. <em>ASOC</em>,
<em>173</em>, 112929. (<a
href="https://doi.org/10.1016/j.asoc.2025.112929">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The k -center problem (KCP) is a well-known NP-hard combinatorial optimization challenge in the field of computer science and operations research, aiming to determine optimal locations for k centers within a given set of nodes to minimize the maximum distance from each node to its nearest center. In contrast to conventional algorithms that have inherent limitations in handling the trade-off between solution quality and computational efficiency, this study proposes a new method based on a graph attention mechanism with an encoder-decoder architecture to find high-quality solutions for KCPs by directly learning heuristics from the graph. Specifically, the encoder processes the input feature of the graph and capture intricate spatial patterns and dependencies among nodes, whereas the decoder leverages the encoded information and attention weights to iteratively generate solutions for the KCP. Moreover, an adaptive embedding strategy is developed to handle the specific attributes and constraints inherent in different KCP instances. To find high-quality solutions, a policy gradient method with an exponential moving average baseline is developed to update and learn the optimal model parameters. A comprehensive set of experiments on multiple problem sizes are conducted to systematically compared the performance of the proposed method with a wide range of baseline methods across four types of KCPs, including the standard KCP, capacitated KCP, non-uniform KCP, and dynamic KCP. The experimental results demonstrate the competitive performance of the graph attention-based method in addressing KCPs.},
  archive      = {J_ASOC},
  author       = {Zhonghao Zhao and Carman K.M. Lee and Xiaoyuan Yan},
  doi          = {10.1016/j.asoc.2025.112929},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112929},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A graph attention-based policy gradient method with an adaptive embedding strategy for k-center problems},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified transductive and inductive learning framework for
few-shot learning using graph neural networks. <em>ASOC</em>,
<em>173</em>, 112928. (<a
href="https://doi.org/10.1016/j.asoc.2025.112928">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have shown their effectiveness in integrating feature embeddings for image and video processing tasks. While initially developed for inductive learning, GNNs have been extended to support transductive learning, enabling them to learn from partially labeled graphs. However, the combination of transductive and inductive learning in existing GNN-based models lacks proper theoretical justification, and GNNs with information propagation mechanisms often encounter the over-smoothing problem, especially in Few-Shot Learning (FSL) tasks. In this paper, we propose a unified transductive and inductive learning GNN model named FGCN for FSL tasks. The proposed FGCN differentiates between the roles of inductive and transductive learning, while quantifying the contributions of intra-properties within entities and inner-relationships between neighboring entities. By addressing the over-smoothing problem comprehensively, the FGCN offers a promising approach for FSL tasks. Our findings demonstrate that the proposed FGCN model achieves a significant improvement in accuracy over state-of-the-art methods, as evidenced by experiments on four standard Few-Shot Learning benchmarks. For example, in the 5-Way 5-Shot scenario, the proposed FGCN achieved an accuracy increase of 7.70% on the Mini-ImageNet, compared to the state-of-the-art result obtained by the MCGN model.},
  archive      = {J_ASOC},
  author       = {Jie Chang and Haodong Ren and Zuoyong Li and Yinlong Xu and Taotao Lai},
  doi          = {10.1016/j.asoc.2025.112928},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112928},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A unified transductive and inductive learning framework for few-shot learning using graph neural networks},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective evolutionary algorithm with two balancing
mechanisms for heterogeneous UAV swarm path planning. <em>ASOC</em>,
<em>173</em>, 112927. (<a
href="https://doi.org/10.1016/j.asoc.2025.112927">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicle (UAV) swarm path planning involves creating efficient routes based on task requirements to enable collaborative flight. Compared to homogeneous UAV swarm, the application scenarios of heterogeneous UAV swarm have become increasingly widespread. They can fully leverage the various capabilities of drones and show higher economic benefits. Existing research mainly focuses on homogeneous UAV swarms, and the model for uniformly describing heterogeneous UAV swarm from a functional perspective is insufficient. Differences in dynamic constraints and energy consumption models create challenges for accurately characterizing the path planning problem of heterogeneous UAV swarm. To supplement the above deficiencies, this article designs the scenario and composition structure of heterogeneous UAV swarm. The path-planning problem of heterogeneous UAV swarm is modeled as a multi-objective optimization (MOO) problem, in which a comprehensive energy consumption objective is constructed. To better balance multiple objectives and obtain high-quality solutions, a MOO evolutionary algorithm based on heterogeneous UAV swarm, namely HMOEA, is proposed. Specifically, HMOEA is implemented by combining the proposed two strategies. To verify the model’s feasibility and the algorithm’s effectiveness, numerical simulations and prototype simulations are provided. In numerical simulations, the proposed algorithm was compared with various advanced algorithms, i.e., NSGA-II, CIACO, AP-GWO, CL-DMSPSO, and DSNSGA-III, in two designed terrain problems. The results demonstrate that HMOEA not only outperforms the compared algorithms on convergence and diversity indicators increased over 4% and 2% respectively. Normal flight results were achieved in the two scenarios served by the prototype simulation, namely, urban buildings and forest scenes. Specific implementation and application can be achieved in military or civilian scenarios like reconnaissance and strike missions, search and rescue missions. The proposed model can adapt to more task scenarios, and the proposed method can provide faster and higher quality results for heterogeneous UAV swarm routes. In actual deployment, adjusting model parameters and optimizing the computing environment according to application requirements are worth further investigation to achieve optimal effect.},
  archive      = {J_ASOC},
  author       = {Xiuju Xu and Chengyu Xie and Linru Ma and Lin Yang and Tao Zhang},
  doi          = {10.1016/j.asoc.2025.112927},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112927},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-objective evolutionary algorithm with two balancing mechanisms for heterogeneous UAV swarm path planning},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A random searching algorithm for efficiently solving the
connectivity-oriented robust optimization problem on large-scale
networked systems. <em>ASOC</em>, <em>173</em>, 112924. (<a
href="https://doi.org/10.1016/j.asoc.2025.112924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By consolidating part of the links to be invulnerable, there will be no connectivity degradation in a network under expected network failure intensity. Although existing link consolidation methods can handle large-scale networks, their solutions are far from optimal. Redundancy in existing solutions can be quantified by the connectivity of the pure graph consisting of the necessary subset of links, and existing methods improve pure graph connectivity to far above the expected value. Fortunately, we have found a special superset of link cuts, and proved that it can reduce consolidation links by removing the right set of links from existing solutions while maintaining the desired connectivity. In response to the high complexity of searching for the optimal superset, we found one kind of superset that is close to the optimal solution and easy to locate, significantly reducing the number of links that need to be consolidated with a slight increase in preprocessing overhead. Experiments have shown that in large networks, the algorithm can provide a protection effect of over 99.9%, and can lead to 60% overhead savings compared to existing high-speed algorithms under the same computing time. On small-scale networks where the optimal algorithm is feasible, the average additional cost compared to the optimal result can be controlled within 1%. Thus, while ensuring accuracy, it can further approach the optimal solution compared to existing algorithms, significantly reducing the overhead of infrastructure consolidation.},
  archive      = {J_ASOC},
  author       = {Wei Wei and Guobin Sun and Qinghui Zhang},
  doi          = {10.1016/j.asoc.2025.112924},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112924},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A random searching algorithm for efficiently solving the connectivity-oriented robust optimization problem on large-scale networked systems},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hesitant fuzzy linguistic mahalanobis distance-based TOPSIS
method for evaluating regional green development levels. <em>ASOC</em>,
<em>173</em>, 112920. (<a
href="https://doi.org/10.1016/j.asoc.2025.112920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objectively understanding regional green development levels (GDLs) is a key prerequisite for the implementation of green development strategies. In this study, we propose an innovative hesitant fuzzy linguistic Mahalanobis distance-based TOPSIS (HLMD-TOPSIS) method to evaluate regional GDLs with hesitant fuzzy linguistic term sets (HFLTSs). The developed HLMD-TOPSIS method can well optimize the weight allocation based on the correlation relationship between criteria under HFLTSs environments. The improved relative closeness index used in the HLMD-TOPSIS method not only optimizes the evaluated index to better adapt the actual contexts but also reflects some balance between the shortest distance from positive ideal solution and the farthest distance from negative ideal solution. More importantly, a new evaluation index system of regional GDLs within twelve criteria is further established from three dimensions of green economy, ecological environment, and green policy. With this new evaluation index system, the developed HLMD-TOPSIS method is applied to evaluate the GDLs of Hubei province in China, and its feasibility is demonstrated. The results show that the innovative HLMD-TOPSIS method is reliable for evaluating regional GDLs, and provides valuable inspiration and references for improving the evaluation efficiency of practical regional GDLs. The advantage of the developed HLMD-TOPSIS method is also indicated with comparison analysis. Besides, a series of new hesitant fuzzy linguistic Mahalanobis distance measures and new statistical measurements are also proposed to measure HFLTSs data, which provide a theoretical basis for the processing of HFLTSs information.},
  archive      = {J_ASOC},
  author       = {Xiaolu Zhang and Haiyan Wu},
  doi          = {10.1016/j.asoc.2025.112920},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112920},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Hesitant fuzzy linguistic mahalanobis distance-based TOPSIS method for evaluating regional green development levels},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating commuters’ travel mode choice using the z-number
extension of parsimonious best worst method. <em>ASOC</em>,
<em>173</em>, 112918. (<a
href="https://doi.org/10.1016/j.asoc.2025.112918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates commuters&#39; travel mode choices in Dublin City, Ireland, using a novel fuzzy multi-criteria decision-making model. The model integrates the Best-Worst Method (BWM) with fuzzy Z-numbers and the Parsimonious concept to handle uncertainties and simplify decision-making. The innovative aspect of this model lies in its ability to combine these methodologies, offering a streamlined yet comprehensive tool for urban transportation analysis. The hypothesis tested is whether the proposed model can effectively evaluate and prioritize travel mode choices while maintaining simplicity and reliability. The methodology involves surveying four experts and applying fuzzy Parsimonious Z-BWM to assess six travel modes. The results indicate that the model provides a robust framework for evaluating travel mode choices, with cars being identified as the most preferred mode. A comparative analysis with traditional BWM and direct evaluation methods demonstrates the model&#39;s efficiency and consistency in ranking preferences.},
  archive      = {J_ASOC},
  author       = {Sarbast Moslem},
  doi          = {10.1016/j.asoc.2025.112918},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112918},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Evaluating commuters&#39; travel mode choice using the Z-number extension of parsimonious best worst method},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel multi-strategy combined whale optimization algorithm
for cascade reservoir operation of complex engineering optimization.
<em>ASOC</em>, <em>173</em>, 112917. (<a
href="https://doi.org/10.1016/j.asoc.2025.112917">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reservoir operation optimization is a complex nonlinear problem involving multiple variables and physical constraints, making it one of the most challenging optimal issues in water resources management. The Whale Optimization Algorithm (WOA) features a straightforward mechanism and exceptional optimization performance. However, with escalating problem complexity, problems such as premature convergence and inadequate global exploration emerge. This study proposes a multi-strategy combined whale optimization algorithm (SCWOA) to address these problems. The approach retains the powerful exploitation mechanism of WOA while implementing the following improvements: introducing parallel multiplication and division operators to enhance global exploration capability, adopting the dual-strategy encirclement mechanism to enrich population diversity, and integrating dynamic spiral mechanism to improve solution accuracy coupling the adaptive escape mechanism to reduce the local stagnation times. Subsequently, numerical experiments are conducted to compare and analyze SCWOA with seven commonly used optimization algorithms across 53 benchmark functions. The analysis results indicate that SCWOA surpasses existing algorithms in global optimization accuracy, robustness, and exploration ability when handling most complex problems with varying dimensions and modes. Furthermore, a generation operation model of a practical hydropower system in China is developed under multiple constraints, such as ice prevention, flood control, and water supply. The operation results show that the schemes of SCWOA generate higher power generation than existing algorithms under different scenarios, effectively improving hydropower utilization rates. Therefore, a novel approach is provided for solving complex reservoir operation optimization problems.},
  archive      = {J_ASOC},
  author       = {Ziqi Hou and Huichun Peng and Jiqing Li},
  doi          = {10.1016/j.asoc.2025.112917},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112917},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A novel multi-strategy combined whale optimization algorithm for cascade reservoir operation of complex engineering optimization},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine-learning component for multi-start metaheuristics to
solve the capacitated vehicle routing problem. <em>ASOC</em>,
<em>173</em>, 112916. (<a
href="https://doi.org/10.1016/j.asoc.2025.112916">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Start metaheuristics (MSM) are commonly used to solve vehicle routing problems (VRPs). These methods create different initial solutions and improve them through local-search. The goal of these methods is to deliver the best solution found. We introduce initial-solution classification (ISC) to predict if a local-search algorithm should be applied to initial solutions in MSM. This leads to a faster convergence of MSM and higher-quality solutions when computation time is limited. In this work, we extract features of a capacitated VRP (CVRP) solution, by transforming the structure of a solution into quantitative metrics (i.e.number of customers in each route, average compactness of a route, or number of intersections between routes). With these features and a machine-learning classifier (random forest), we show how ISC – significantly – improves the performance of greedy randomized adaptive search procedure (GRASP), over benchmark instances from the CVRP literature. With the objective of evaluating ISC’s performance with different local-search algorithms, we implemented a local-search composed of classical neighborhoods from the literature and another local-search with only a variation of Ruin-and-Recreate. In both cases, ISC significantly improves the quality of the solutions found in almost all the evaluated instances.},
  archive      = {J_ASOC},
  author       = {Juan Pablo Mesa and Alejandro Montoya and Raul Ramos-Pollan and Mauricio Toro},
  doi          = {10.1016/j.asoc.2025.112916},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112916},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Machine-learning component for multi-start metaheuristics to solve the capacitated vehicle routing problem},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CaRGI: Causal semantic representation learning via
generative intervention for single domain generalization. <em>ASOC</em>,
<em>173</em>, 112910. (<a
href="https://doi.org/10.1016/j.asoc.2025.112910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single Domain Generalization (SDG) is a realistically challenging case in domain generalization, which has only one available source domain and is committed to generalizing the knowledge acquired from this single domain to unseen target domains. Due to the lack of diversity information, data augmentation to expand the data distribution is the mainstream method for SDG. Most low-level data augmentation methods cannot model large domain shifts and simulated domains are fragile, which prevents the model from thoroughly improving the generalization ability. We bridge SDG to causal concepts, novelly analyzing the reason why limited generated domain shifts restrict the improvement of generalization ability from the view of the backdoor path, and propose a causally stable framework CaRGI ( Ca usal Semantic R epresentation Learning via G enerative I ntervention). Firstly, we construct the inclusive causal directed acyclic graph and utilize causal analysis to gradually explore the relationship between the generated domain shift and generalization ability. We regard domain expansion as the causal intervention and secondly propose the joint generative intervention module with dynamic to enlarge the domain shift with semantic consistency, which is dedicated to eliminating spurious confounding effects by blocking the backdoor path. Thirdly, counterfactual inference is applied to implement causal semantic representation learning. In this process, the min–max game in the latent space plays between the generative intervention module and the prediction module, which engage in alternating training that benefit each other in the spiral development. Specially, we innovatively perform maximization and minimization operations in shallow and deep layers respectively. CaRGI can finally learn causal semantic representations and improve the stable generalization ability. Extensive experimental results on several widely used datasets verify the feasibility and effectiveness of the proposed method.},
  archive      = {J_ASOC},
  author       = {Youjia Shao and Shaohui Wang and Wencang Zhao},
  doi          = {10.1016/j.asoc.2025.112910},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112910},
  shortjournal = {Appl. Soft. Comput.},
  title        = {CaRGI: Causal semantic representation learning via generative intervention for single domain generalization},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive trustworthy prototype learning for
multi-modality myocardial pathology segmentation. <em>ASOC</em>,
<em>173</em>, 112909. (<a
href="https://doi.org/10.1016/j.asoc.2025.112909">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modality Myocardial Pathology Segmentation (MyoPS) is essential for assessing risks and planning treatments in myocardial infarction (MI). However, multi-modality myocardial semantic segmentation remains challenging due to the low contrast of pathologic regions between modalities and limited medical training data. To address these issues, we propose C ontrastive TR ustworthy prototype L earning (CTRL) for the dynamic fusion of multi-modality cardiac MRI images. Specifically, CTRL enhances the contrast of intra-modality features by discriminating the intra-modality contribution to the segmentation effect with instance-level confidence and then introduces contrast loss to constrain the modality-specific pathological region features. To incorporate cross-modality information, we combine frequency and spatial domain features to dynamically aggregate global and specific pathological features between modalities and discriminatively aggregate cross-modality semantic expressions. In addition, we constructed a prototype learning memory module to recall multi-modality data a priori, which enables the model to retain essential information to leverage limited data fully. Extensive experimental results on the available MyoPS 2020 dataset for myocardial pathology segmentation demonstrate that CTRL outperforms state-of-the-art methods by 1.6% and can be adapted for heterogeneous medical image representation.},
  archive      = {J_ASOC},
  author       = {Jingjing Liu and Ao Wei and Lijuan Cao and Xiao He and Chang Tang},
  doi          = {10.1016/j.asoc.2025.112909},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112909},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Contrastive trustworthy prototype learning for multi-modality myocardial pathology segmentation},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An advanced ensemble framework for defending against
obfuscated windows, android, and IoT malware. <em>ASOC</em>,
<em>173</em>, 112908. (<a
href="https://doi.org/10.1016/j.asoc.2025.112908">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection and analysis of malware binaries pose significant challenges due to their obfuscated and packed nature, rendering traditional static analysis techniques ineffective. Extracting static features in a dynamic environment where malware exhibits its actual behavior becomes crucial to detecting malware accurately. This article addresses this challenge by analyzing static features extracted from real-time Windows, Android, and IoT applications within a dynamic environment. To tackle this problem, we propose an Advanced Ensemble Framework (AEF) that combines embedded feature selection and an advanced stacking ensemble technique. The embedded feature selection approach effectively reduces the number of highly correlated features by over 70%, employing a combination of filter and wrapper methods. Furthermore, the advanced stacking ensemble approach combines two-level learners: a base learner with state-of-the-art classifiers adept at handling raw features and meta-learner trains using transfer features and probabilities obtained from the previous base classifiers. A 5-fold cross-training scheme based on cross-validation is introduced to prevent overfitting during the training. It also helps to reduce overfitting by training the model on multiple subsets of the data. The model learns patterns from different parts of the dataset, which can lead to a more generalized model. Pre-processed datasets from the Canadian Institute of Cybersecurity comprising obfuscated Windows malware, Android malware, and IoT malicious attacks are used to evaluate AEF. Additionally, to further assess the efficiency, compatibility, and robustness of AEF, we utilized an additional dataset of obfuscated Windows malware that includes memory dump images. Extensive experiments are conducted to evaluate the proposed defender using publicly available real-time datasets. The results show that AEF effectively counters obfuscation techniques, offering a flexible, practical, and efficient solution for malware detection across various datasets. Furthermore, the prediction time of the proposed approach is 0 . 042 ms for CICMalDroid-2020, 0 . 16 ms for IoMT-2024, 0 . 055 ms for CIC-MalMemory-2022, and 0 . 15 ms for Dumpaware10 malware datasets.},
  archive      = {J_ASOC},
  author       = {Danish Vasan and Junaid Akram and Mohammad Hammoudeh and Adel F. Ahmed},
  doi          = {10.1016/j.asoc.2025.112908},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112908},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An advanced ensemble framework for defending against obfuscated windows, android, and IoT malware},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention-based backdoor attacks against natural language
processing models. <em>ASOC</em>, <em>173</em>, 112907. (<a
href="https://doi.org/10.1016/j.asoc.2025.112907">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Backdoor attacks against natural language processing (NLP) models are surging with enhanced attack success rates. However, these backdoor attacks are limited in sentence fluency, grammar errors, and stealthiness. To address these issues, this study proposes an attention-based backdoor attack that generates high-quality backdoor-poisoned samples. The proposed backdoor employs class activation mapping (CAM) to generate backdoor texts with a baseline convolutional neural network in two steps: trigger generation and trigger insertion. The trigger generation leverages high-frequency words as candidate trigger patterns that are subsequently used to generate poisoned texts with high stealthiness and effectiveness. These candidate words are then inserted into computed positions of clean texts, under a low poisoning rate, based on available positions computed with the CAM-based attention method. Through extensive experiments on five benchmark datasets, the proposed CAM-based backdoor attack demonstrates a more excellent performance than the other five backdoor attacks from multiple aspects, including utility, effectiveness, and stealthiness. The proposed method is more robust than other attacks because it maintains almost the highest attack success rate against four benchmark defense methods.},
  archive      = {J_ASOC},
  author       = {Yunchun Zhang and Qi Wang and Shaohui Min and Ruifeng Zuo and Feiyang Huang and Hao Liu and Shaowen Yao},
  doi          = {10.1016/j.asoc.2025.112907},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112907},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Attention-based backdoor attacks against natural language processing models},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy-preserving federated UAV data collection framework
for autonomous path optimization in maritime operations. <em>ASOC</em>,
<em>173</em>, 112906. (<a
href="https://doi.org/10.1016/j.asoc.2025.112906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring data privacy and operational security has become critical in light of escalating cyber threats and the logistical complexity of autonomous maritime operations. Autonomous maritime systems face such challenges in securely processing and managing large amounts of real-time data while maintaining resilience against cyber attacks. This paper considers these challenges by presenting a federated privacy-preserving UAV data collection framework to optimize autonomous path planning and protect sensitive maritime information. Using UAVs as edge nodes for decentralized data processing allows the framework to integrate federated learning, maintain data privacy, and improve cybersecurity. The proposed framework contains five distinct layers, where the data collection layer’s role is to collect real-time data on vessel and environmental conditions. The privacy-preserving edge intelligence layer enables secure localized data processing at the edge. The threat mitigation and optimization layer performs machine learning models for route optimization and intrusion detection. The orchestration layer is implemented to coordinate UAV operations and manages aggregated model parameters for system-wide efficiency, whereas the user interaction layer provides operators with secure, real-time insights into system performance and operational metrics. Simulations and implementations demonstrate that this multilayered architecture improves route accuracy, fortifies data security, and achieves a 20% reduction in emissions, underscoring its potential to advance autonomous navigation and secure, efficient mission planning in maritime cyber–physical systems. The proposed edge-intelligent federated UAV system demonstrates superior performance compared to other approaches, achieving the highest accuracy (99.1%), F1 score (98.9%), and recall (99.3%), while utilizing a larger hybrid dataset (80,000 samples) with 30 features, optimized through principal component analysis, and addressing multiple target attributes such as C O 2 emissions, energy efficiency, and route accuracy.},
  archive      = {J_ASOC},
  author       = {Wei Min and Mohammed Saleh Ali Muthanna and Maha Ibrahim and Reem Alkanhel and Ammar Muthanna and Abdelkader Laouid},
  doi          = {10.1016/j.asoc.2025.112906},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112906},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Privacy-preserving federated UAV data collection framework for autonomous path optimization in maritime operations},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unknown web attack threat detection based on large language
model. <em>ASOC</em>, <em>173</em>, 112905. (<a
href="https://doi.org/10.1016/j.asoc.2025.112905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unknown attacks pose a significant threat to current cyber defenses. Traditional methods for detecting abnormal user behaviors rely on explicit associations and content information, often overlooking implicit causal relationships. Additionally, the frequent emergence of new attack types and the scarcity of training data limit their effectiveness. The paper proposes a novel approach for detecting abnormal user behaviors using large language models (LLMs), addressing these challenges under low-resource conditions. Our method extracts implicit causal relationships from system logs to build behavior graphs and employs label-free graph contrastive invariant learning to generate causal feature vectors. A multi-agent framework, including narrator and decision-maker agents, is used to improve descriptive text generation, while the Translator more efficiently converts causal vectors into meaningful descriptions. Experimental results on the WAB-dataset demonstrate that implicit causal relationships enhance the graph structure’s ability to represent abnormal behaviors. The integration of LLMs enables superior behavior analysis with fewer resources compared to traditional methods. Additionally, the comprehensibility of the generated texts and the efficiency of the Translator provide a strong foundation for supporting security professionals in understanding and analyzing abnormal behaviors in real-world scenarios.},
  archive      = {J_ASOC},
  author       = {Yijia Xu and Qiang Zhang and Huaxin Deng and Zhonglin Liu and Cheng Yang and Yong Fang},
  doi          = {10.1016/j.asoc.2025.112905},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112905},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Unknown web attack threat detection based on large language model},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A simplified swarm optimization-based restricted boltzmann
machine algorithm for a time series clustering. <em>ASOC</em>,
<em>173</em>, 112903. (<a
href="https://doi.org/10.1016/j.asoc.2025.112903">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series clustering is an important area of research, driven by the prevalence of time series data in domains such as power and maintenance data. However, most existing clustering algorithms are not specialized for time series data. Therefore, this study introduces a metaheuristics-based approach, utilizing a restricted Boltzmann machine (RBM) for feature extraction in time series clustering. The RBM, a neural network algorithm with two layers and undirected weights, is kept simple to avoid complex parameter settings. The study employs the RBM as an encoder, coupled with a K -step contrastive divergence and an improved, simplified swarm optimization (iSSO) algorithm for training. The proposed hybrid of iSSO-based RBM and K -means algorithm is compared with RBM and particle swarm optimization-based RBM across the tested time series datasets. Results indicate that the proposed algorithm yields superior performance, reconstructing time series data with minimal error and achieving the highest clustering accuracy compared to other baseline algorithms.},
  archive      = {J_ASOC},
  author       = {Ferani E. Zulvia and R.J. Kuo},
  doi          = {10.1016/j.asoc.2025.112903},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112903},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A simplified swarm optimization-based restricted boltzmann machine algorithm for a time series clustering},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent decision making under conflicting and
cooperative scenarios with incomplete information. <em>ASOC</em>,
<em>173</em>, 112898. (<a
href="https://doi.org/10.1016/j.asoc.2025.112898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the real business world, banks and firms often need to make decisions under uncertainty using incomplete information. In this study, an intelligent game arena will be established to demonstrate the dynamic decision process with information asymmetry under heterogeneous competition scenarios (Conflicting and Cooperative). The game is such implemented that actions (drawn from a serial of real policies) and the consequenced rewards for banks and firms are first to be linked by a Hybrid Archimedean Copula ( HAC ). Then, the HAC would be further optimized by the Multi-objective Integer Quadratic Programming ( MIQP ) in order to mimic the dynamic decision process in the true business environment. Finally, a Double Deep-Q Network ( DDQN ) algorithm is used to simulate dynamic decision processes. The intelligent dynamic game presented in this study not only shows the outcomes (optimal rewards, actions, and competition strategies) resulting from authenic dynamic human rational intelligent decision-making processes under conflicting and cooperative competitions scenarios with incomplete information, both also give the probabilities of taking such actions and strategies in order to reach the optimal long-term rewards. The area goes one step forward by presenting the entire convergence processes of the games before they could reach equilibriums based on heterogeneous actions and strategies. As a result, the framework proposed in this study would offer a transparent experimentable arena to dissect the black-boxed human decision-making process in the real business world and thus might be of importance for studying organizational behaviors, operations, and strategies.},
  archive      = {J_ASOC},
  author       = {Chang Liu and Bowen Deng and Xuancheng Ye and Min Guo},
  doi          = {10.1016/j.asoc.2025.112898},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112898},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Intelligent decision making under conflicting and cooperative scenarios with incomplete information},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SDSINet: A spatiotemporal dual-scale interaction network for
traffic prediction. <em>ASOC</em>, <em>173</em>, 112892. (<a
href="https://doi.org/10.1016/j.asoc.2025.112892">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic forecasting is essential for smart city development. However, existing spatiotemporal modeling methods often face significant challenges, including limitations in handling complex temporal dependencies, capturing multiscale spatial relationships, and modeling the interaction between temporal and spatial features. These challenges arise due to the reliance on extended historical data, fixed adjacency matrices, and the lack of dynamic spatiotemporal interaction modeling. To address these issues, we propose the Spatiotemporal Dual-Scale Interaction Network (SDSINet). SDSINet introduces an implicit temporal information enhancement method that embeds temporal identity information into feature representations, reducing the computational overhead and improving the modeling of global temporal features. Additionally, SDSINet integrates a dynamic multiscale spatial modeling approach that combines adaptive and scale-specific graphs, enabling the model to capture both local and global spatial dependencies. Furthermore, SDSINet incorporates a dual-scale spatiotemporal interaction learning framework that captures short-term and long-term temporal dependencies as well as multiscale spatial correlations. Extensive experiments on real-world datasets – traffic flow (PeMS04), speed (PeMSD7(M)), and demand (NYCBike Drop-off/Pick-up) – demonstrate that SDSINet outperforms existing state-of-the-art methods in prediction accuracy and computational efficiency. Notably, SDSINet achieves a 14.03% reduction in MAE on the NYCBike Drop-off dataset compared to AFDGCN, setting a new benchmark for traffic forecasting.},
  archive      = {J_ASOC},
  author       = {Shiyu Yang and Qunyong Wu},
  doi          = {10.1016/j.asoc.2025.112892},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112892},
  shortjournal = {Appl. Soft. Comput.},
  title        = {SDSINet: A spatiotemporal dual-scale interaction network for traffic prediction},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Many-objective optimisation of offshore wind farms.
<em>ASOC</em>, <em>173</em>, 112879. (<a
href="https://doi.org/10.1016/j.asoc.2025.112879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design of offshore wind farms is computationally challenging, requiring the simultaneous optimisation of many conflicting objectives. Solving this problem is of paramount importance if society is to meet ambitious net zero goals. The problem is solved by identifying an optimal arrangement of individual turbines such that all objectives are optimised. However, a single solution does not exist due to the inherent conflict between objectives, and a set of solutions must be identified. As well as the challenge in generating optimal solution sets, there exists a decision support task if the solutions are to be effectively presented to a decision maker. This study focuses on six key objectives: wind farm efficiency, annual energy production, electric cable length, number of wind turbines, levelised cost of energy, and total area. Two evolutionary algorithms, NSGA-II and NSGA-III, were employed to explore the solution space efficiently. Performance evaluation was performed using spacing, generational distance, and hypervolume metrics. The aforementioned algorithms and metrics were applied to three wind farm layouts: a discrete layout and two continuous layouts. The NSGA-III algorithm was shown to perform better than its predecessor (NSGA-II). The difference was small, albeit significant. Previous works (e.g., Rodrigues et al. (2016); Mytilinou and Kolios (2017)) in which many-objective optimisations were discussed provided little insight into the visualisation and interpretation of the results. While the mentioned work used parallel coordinate plots, this work provides a deeper insight by presenting the results via Principal Component Analysis (PCA) and Multi Dimensional Scaling (MDS) plots. The best solution, containing 6188 wind farm layouts, was found by the NSGA-III algorithm on a continuous wind farm layout with repair mechanism. From the best solution, the wind farms containing 27, 102 and 160 wind turbines were selected and compared with the real wind farms located around the UK. It was demonstrated that the optimiser could identify better wind farm layouts concerning annual energy production, efficiency, and LCOE than the real wind farm layouts of Rhyl Flats and Greater Gabbard.},
  archive      = {J_ASOC},
  author       = {Pawel L. Manikowski and Matthew J. Craven and David J. Walker},
  doi          = {10.1016/j.asoc.2025.112879},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112879},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Many-objective optimisation of offshore wind farms},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Collaborative transformer u-shaped network for medical image
segmentation. <em>ASOC</em>, <em>173</em>, 112841. (<a
href="https://doi.org/10.1016/j.asoc.2025.112841">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in the Transformer have shown significant ability to understand the relationship between the lesion area and surrounding tissue, especially for medical image analysis. Existing medical image segmentation algorithms based on transformers often suffer from limited feature extraction granularity and overlook the semantic relationships between multi-scale features. To solve the above limitations, we propose CoTransUNet: a collaborative transformer U-shaped network, that effectively captures fine-grained features and long-range dependencies by performing context extraction between multiple scales. The designed Correlation Extraction (CE) module bridges the encoder and decoder to achieve effective interaction and information transfer. Specifically, a collaborative mechanism in the encoder is proposed that can efficiently exploit inductive bias to extract local fine-grained features of the image while having the ability to capture long-distance feature dependencies. Besides, the CE module focuses on deeply integrating contextual information of multi-scale features, which enriches feature representation by exploiting the intrinsic correlation between features at different scales. It can extract not only local and global features but also capture semantic information related to different multi-scale features simultaneously. Compared to TransUNet, CoTransUNet achieves a 4.91% improvement in DSC on the Synapse multi-organ segmentation dataset while using only a quarter of the parameters. The extensive experiments on three datasets, including skin lesion segmentation (ISIC2016, ISIC2017, ISIC2018) demonstrates that CoTransUNet achieves DSC scores of 92.18%, 85.59%, and 88.75%, respectively, and on Synapse multi organ segmentation achieves DSC score of 82.39% , which outperforms the baseline and other promising methods.},
  archive      = {J_ASOC},
  author       = {Yufei Gao and Shichao Zhang and Lei Shi and Guohua Zhao and Yucheng Shi},
  doi          = {10.1016/j.asoc.2025.112841},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112841},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Collaborative transformer U-shaped network for medical image segmentation},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A two-stage coevolutionary algorithm based on adaptive
weights for complex constrained multiobjective optimization.
<em>ASOC</em>, <em>173</em>, 112825. (<a
href="https://doi.org/10.1016/j.asoc.2025.112825">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the constrained multiobjective optimization problems (CMOPs), various complex constraints need to be satisfied simultaneously, which further challenges evolutionary algorithms in balancing feasibility, convergence and diversity. Recent advances in evolutionary computation have led to the development of multi-stage and multi-population strategies for handling CMOPs. However, most algorithms have shown poor performance when dealing with problems with low feasible ratio or discontinuous feasible regions. To address this issue, we propose a two-stage coevolutionary algorithm based on adaptive weights (AW-TCEA), aiming to balance convergence, diversity and feasibility to handle CMOPs with complex Pareto fronts (PFs). Specifically, the first stage uses two populations to explore the objective space and feasible regions respectively, one driven by objective information and the other by feasible information. The second stage adopts a set of weight vectors to search for unexplored feasible regions to enhance diversity. In addition, for handling complex constrained PFs, a novel adaptive weight adjustment strategy is proposed to explore ineffective directions and develop potential regions. Experimental comparisons with multiple state-of-the-art algorithms are performed on 50 test problems and 5 real-world problems. The results show that the proposed algorithm exhibits better performance on various CMOPs.},
  archive      = {J_ASOC},
  author       = {Guangpeng Li and Li Li and Guoyong Cai},
  doi          = {10.1016/j.asoc.2025.112825},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112825},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A two-stage coevolutionary algorithm based on adaptive weights for complex constrained multiobjective optimization},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A TG-AGD anomaly image detection model based on residual
bottleneck attention and time series prediction. <em>ASOC</em>,
<em>173</em>, 112746. (<a
href="https://doi.org/10.1016/j.asoc.2025.112746">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection is a crucial task in the field of deep learning, with applications in security monitoring, quality control, and medical diagnosis. However, existing anomaly detection methods often consume significant computational resources, leading to premature bottlenecks. This study proposes an anomaly image detection method based on residual bottleneck attention integrated with time series prediction. Initially, the study explores several common time series prediction models and establishes a time prediction model tailored to the abnormal characteristics of images. It then examines the limitations of current attention mechanisms in anomaly detection. The proposed method combines the most widely applicable and effective residual bottleneck processing with the previously developed time series prediction model to create the TG-AGD anomaly image detection model. Extensive experiments were conducted using detailed anomaly image data from various fields. The results indicate that the TG-AGD anomaly image detection model significantly outperforms traditional single time series prediction or attention mechanism approaches, demonstrating high accuracy and robustness in detecting anomalies.},
  archive      = {J_ASOC},
  author       = {Yang Li and Suqin Xiong and Qiuyang Li and Zhiru Chen},
  doi          = {10.1016/j.asoc.2025.112746},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112746},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A TG-AGD anomaly image detection model based on residual bottleneck attention and time series prediction},
  volume       = {173},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
