<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>EAAI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="eaai---150">EAAI - 150</h2>
<ul>
<li><details>
<summary>
(2025). Multimodal data imputation and fusion for trustworthy fault
diagnosis of mechanical systems. <em>EAAI</em>, <em>150</em>, 110663.
(<a href="https://doi.org/10.1016/j.engappai.2025.110663">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The presence of missing values in the collected data due to sensor failure, communication interruption, or environmental interference can greatly diminishes the trustworthiness of fault diagnosis for mechanical systems. Therefore, this study proposes and evaluates a novel multimodal data imputation and fusion method to perform the trustworthy fault diagnosis of mechanical systems. First, a generative adversarial imputation network, termed as the L2 regularization temporal–spatial generative adversarial imputation network (L2-TSGAIN), is developed. This L2-TSGAIN network, based on a temporal–spatial feature extraction module and L2 regularization loss function, can comprehensively extract data features from both temporal and spatial perspectives, thus achieving high-quality imputation of anomalous sensor data. Subsequently, a multi-input single-output autoencoder (MISO-AE) is designed to extract a universal representation of the imputed data from different modalities and recover features in the fusion data. Finally, the fusion data from different health states of mechanical systems are input into a convolutional neural network classifier to perform fault diagnosis. Experiment validations, considering the presence of missing values in sensor data, have been carried out on the planetary transmission system and gearbox test bench. Compared with several mainstream data imputation methods for fault diagnosis, the optimal diagnostic accuracy of 99.68 % and 100 % on these two datasets can be obtained using the proposed method, respectively, confirming its superior performance and reliability. Thus, the proposed method can provide a trustworthy fault diagnosis tool for mechanical systems in industrial scenarios considering anomalous sensor data.},
  archive      = {J_EAAI},
  author       = {Jie Zhang and Yun Kong and Qinkai Han and Tianyang Wang and Mingming Dong and Hui Liu and Fulei Chu},
  doi          = {10.1016/j.engappai.2025.110663},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110663},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multimodal data imputation and fusion for trustworthy fault diagnosis of mechanical systems},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Atrous spatial pyramid pooling with swin transformer model
for classification of gastrointestinal tract diseases from videos with
enhanced explainability. <em>EAAI</em>, <em>150</em>, 110656. (<a
href="https://doi.org/10.1016/j.engappai.2025.110656">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and early identification of gastrointestinal (GI) lesions is crucial for treating and preventing GI diseases, including cancer. Automated computer-aided diagnosis methods can assist physicians in early and accurate detection. Video classification of GI endoscopic videos is challenging due to the complexity and variability of visual data. This research proposes a novel method for classifying GI diseases using endoscopic videos. Leveraging the public HyperKvasir dataset, we applied preprocessing algorithms to enhance GI frames by removing noise and artifacts with morphological opening and closing techniques, ensuring high-quality visuals. We addressed dataset imbalance by proposing a novel algorithm. Our hybrid model, Atrous Spatial Pyramid Pooling with Swin Transformer (ASPPST), combines advanced Convolutional Neural Networks and the Swin Transformer to classify GI videos into 30 distinct classes. We incorporated Gradient-Class Activation Mapping (Grad-CAM) in ASPPST&#39;s final layer to improve model explainability. The proposed model achieved 97.49 % accuracy in classifying 30 GI diseases, outperforming other transfer learning models and transformers by 8.04 % and 3.99 %, respectively. It also demonstrated a precision of 97.80 %, recall of 97.77 %, and an F1 score of 97.75 %, showcasing robustness across metrics. The high accuracy of ASPPST makes it suitable for real-world use, delivering fewer errors and more precise results in GI endoscopy video classification. Our approach advances artificial intelligence (AI) in computer vision and deep learning for biomedical engineering applications. Grad-CAM integration enhances transparency, boosting clinician trust and adoption of AI tools in diagnostic workflows.},
  archive      = {J_EAAI},
  author       = {Arefin Ittesafun Abian and Mohaimenul Azam Khan Raiaan and Mirjam Jonkman and Sheikh Mohammed Shariful Islam and Sami Azam},
  doi          = {10.1016/j.engappai.2025.110656},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110656},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Atrous spatial pyramid pooling with swin transformer model for classification of gastrointestinal tract diseases from videos with enhanced explainability},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solution and application of two-dimensional seismic
wavefield evolution based on physics-informed neural networks.
<em>EAAI</em>, <em>150</em>, 110652. (<a
href="https://doi.org/10.1016/j.engappai.2025.110652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-Informed Neural Networks (PINN) integrate partial differential equations, initial conditions, and boundary conditions into the loss function to predict the solutions of partial differential equations, and have already demonstrated their value in solving two-dimensional (2D) seismic wavefields. However, when dealing with wave problems involving boundary conditions, the added complexity of boundary conditions can lead to imbalanced convergence rates among different loss terms, which may affect both the efficiency and accuracy of the computations. Moreover, the need to retrain the model for different problems limits the flexibility of its application. Therefore, this paper introduces an adaptive weight balancing method and presents a 2D wave simulation based on Self-Adaptive PINN (SA-PINN). This method automatically adjusts the weights in the loss function, improving the solving performance. Additionally, to improve the computational efficiency of PINN in solving similar wave problems, a transfer learning strategy is adopted. By leveraging the similarities between the PINN models of related wave problems, this strategy enhances the generalization ability of PINN when dealing with variations in source location and medium wave speed. Numerical examples in semi-infinite domains and V-shaped valleys demonstrate that this method effectively achieves intelligent and efficient simulation of 2D seismic wavefields, providing a more efficient and intelligent solution for complex seismic wave problems.},
  archive      = {J_EAAI},
  author       = {Zhihui Zhu and Zong Wang and Yang Feng and Weiqi Zheng},
  doi          = {10.1016/j.engappai.2025.110652},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110652},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Solution and application of two-dimensional seismic wavefield evolution based on physics-informed neural networks},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive human in the loop system for identifying
non-optimal states in natural product manufacturing process.
<em>EAAI</em>, <em>150</em>, 110650. (<a
href="https://doi.org/10.1016/j.engappai.2025.110650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the extraction of natural products, the identification of non-optimal production states is pivotal for ensuring consistent product quality. Currently, there is a deficiency in online, automated detection methods. This study introduces an online machine vision strategy in a real industrial setting to maintain optimal production state. Specifically, the strategy incorporates an adaptive human in the loop deep learning approach to select high-value samples. This method achieves over 90 % accuracy with fewer training samples, effectively addressing the challenges posed by the low-value density characteristic of industrial data. Additionally, a convolutional neural networks-transformer framework is employed as a classifier for video data to meet the demands of time-series data. To enhance the efficiency of processing multiple video streams, we have implemented a knowledge distillation technique to lighten the model. Finally, this model has been deployed in an actual industrial environment for online monitoring of three extraction devices. The system encapsulates the expertise of engineers to standardize the criteria for assessing production states. This integration of innovative technologies ensures a more reliable and efficient extraction process, meeting the industry&#39;s need for consistent product quality.},
  archive      = {J_EAAI},
  author       = {Qilong Xue and Yang Yu and Shixin Cen and Yequan Yan and Jiping Pang and Ping Li and Yehan Hou and Lei Wang and Zheng Li},
  doi          = {10.1016/j.engappai.2025.110650},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110650},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive human in the loop system for identifying non-optimal states in natural product manufacturing process},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A chinese medical named entity recognition method
considering length diversity of entities. <em>EAAI</em>, <em>150</em>,
110649. (<a
href="https://doi.org/10.1016/j.engappai.2025.110649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting clinical entity concepts from professional medical materials is crucial for medical information analysis and knowledge extraction. Whereas, the Chinese medical named entity recognition (CMNER) task faces challenges due to the knowledge specialization and the diversity in entity lengths. To address these challenges, a novel method by considering length diversity of entities for CMNER is proposed, focusing on the integration of local information based on the predominance of large language models (LLMs). The method pre-trains a bidirectional encoder representation from transformers (BERT) based on open Chinese medical texts and designs a multi-dimensional convolutional residual module to enhance the semantic information for characters. This module effectively mines local information across various ranges and employs a local channel self-attention block to integrate this information, establishing a link between local information and entity length. Meanwhile, an adaptive optimization strategy for a learning rate is designed to improve the method&#39;s ability to search for the optimal solution. Experimental results reveal that, compared with state-of-the-art models, our approach achieves the optimal Recall and F1 , especially Recalls achieve 94.50 % (p &lt; 0.05) and 93.51 % (p &lt; 0.05) with effective performance in current task. The ablation results suggest that incorporating local information within 1–7 characters effectively addresses the challenges mentioned, highlighting the potential of our method to advance CMNER task.},
  archive      = {J_EAAI},
  author       = {Hongyu Zhang and Long Lyu and Weifu Chang and Yuexin Zhao and Xiaoqing Peng},
  doi          = {10.1016/j.engappai.2025.110649},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110649},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A chinese medical named entity recognition method considering length diversity of entities},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving weak magnetic detection of ferromagnetic material
defects diagnostics via transfer learning-enhanced residual networks.
<em>EAAI</em>, <em>150</em>, 110647. (<a
href="https://doi.org/10.1016/j.engappai.2025.110647">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of weak magnetic detection technology to identify defect sizes in ferromagnetic materials poses significant challenges due to the large volume of data and the relatively low prediction accuracy of conventional methods. Therefore, this paper proposes an improved Residual Networks (ResNet18) model that integrates transfer learning and channel attention mechanisms. Compared to traditional methods, the following improvements have been made: First, transfer learning has significantly reduced the data volume and time cost required for training from scratch, enhancing the model&#39;s generalization capability. Second, we have added a channel attention mechanism to the ResNet18 model, which involves calculating the importance of each channel through adaptive average pooling and fully connected layers, and generating channel weights using a Sigmoid function. This improvement allows the model to more accurately focus on features with higher relevance to defect sizes. Experimental results demonstrate that for grayscale images with defect lengths of 50 mm, depths of 2 mm, and widths of 1, 2, 3, 4, and 5 mm, the prediction accuracies reached 100 %, 100 %, 98.84 %, 99.58 %, and 100 %, respectively. For grayscale images with defect lengths of 50 mm, widths of 2 mm, and depths of 1, 2, 3, 4, and 5 mm, the prediction accuracies were 99.68 %, 100 %, 99.63 %, 100 %, and 99.60 %, respectively. Compared to the traditional ResNet18 model, the improved model not only enhances the accuracy of defect size prediction but also exhibits greater robustness, providing a new and effective method for defect classification in weak magnetic detection of ferromagnetic materials.},
  archive      = {J_EAAI},
  author       = {Yu Chen and Liangliang Li and Zhengxiang Ma and Xinling Wen and Jiabao Pang and Weitao Yuan},
  doi          = {10.1016/j.engappai.2025.110647},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110647},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improving weak magnetic detection of ferromagnetic material defects diagnostics via transfer learning-enhanced residual networks},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-adaptive production scheduling for discrete
manufacturing workshop using multi-agent cyber physical system.
<em>EAAI</em>, <em>150</em>, 110638. (<a
href="https://doi.org/10.1016/j.engappai.2025.110638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, the production control process of a discrete manufacturing workshop is characterized by high concurrency, mixed production lines and difficulty in prediction, which lead to uncertainty caused by dynamic disturbances and challenges in production control. Traditional system architectures struggle to handle these uncertainties flexibly and adaptively. To address these issues, an adaptive production scheduling system for the workshop is proposed, utilizing the Multi-agent Cyber Physical System (CPS-MAS) framework. This system integrates self-organization mechanisms and self-adaptive decision-making mechanisms to achieve cooperative optimal control of manufacturing resources. Using multi-agent technology, the resource model in the information space is encapsulated into an intelligent Cyber Physical System (CPS)-Agent model with cognitive interaction and autonomous decision-making capabilities. The improved contract network protocol (CNP) is utilized to the constructed agent, enabling their collaboration and competition to support the self-organization, negotiation, and assignment of manufacturing tasks. Based on multi-agent real-time perception and interactive negotiation, an adaptive control model of the manufacturing process is constructed based on Proportion Integration Differentiation (PID) control principle. This model is trained with the multi-layer perceptron that integrates an attention mechanism. The production strategy and parameters of the agent cooperative network are dynamically adjusted to enable dynamic decision-making optimization under disturbances. The proposed method is verified by experiments in scenarios involving machine failure, emergency order insertion and due date changes, proving its effectiveness.},
  archive      = {J_EAAI},
  author       = {Jie Chen and Zequn Zhang and Liping Wang and Dunbing Tang and Qixiang Cai and Kai Chen},
  doi          = {10.1016/j.engappai.2025.110638},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110638},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-adaptive production scheduling for discrete manufacturing workshop using multi-agent cyber physical system},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A pencil lead break-triggered, adversarial autoencoder-based
approach for rapid and robust rail damage detection. <em>EAAI</em>,
<em>150</em>, 110637. (<a
href="https://doi.org/10.1016/j.engappai.2025.110637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting early-stage damage is essential for railway maintenance, ruling out potential risks that could undermine railway ride comfort and safety. Ultrasonic testing methods, featuring high precision and non-destructive characteristics, have gained widespread use for on-site inspections in modern railway systems. However, current ultrasonic testing remains a highly complex technique that requires expensive ultrasonic devices and trained professionals for operation. This study presents a novel approach for rail damage detection utilizing a disposable mechanical pencil. By intentionally breaking the pencil lead on rail surface, the accumulated potential energy is released in the form of ultrasonic bursts which are acquired by sensors mounted on the rail. The rail damage diagnosis is empowered by an adversarial autoencoder (AAE) which learns representations of ultrasonic signals induced by pencil lead break (PLB). A damage-sensitive indicator is developed based on the Jensen-Shannon Divergence (JSD) between the AAE model output distributions of the baseline and an unknown signal, facilitating rapid and accurate damage diagnosis. Both laboratory experiments and on-site verifications were conducted to validate the proposed approach. The results demonstrate the effectiveness of the damage detection framework in identifying rail damage, exhibiting excellent robustness and reliability. Comparative studies are also conducted to demonstrate the adaptability and effectiveness of the proposed method against field testing environments. The research outcomes of this study will significantly contribute to the development of more efficient on-site inspection techniques for railway maintenance and sustainability.},
  archive      = {J_EAAI},
  author       = {Da-Zhi Dang and Bo-Yang Su and You-Wu Wang and Wai Kei Ao and Yi-Qing Ni},
  doi          = {10.1016/j.engappai.2025.110637},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110637},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A pencil lead break-triggered, adversarial autoencoder-based approach for rapid and robust rail damage detection},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-dimensional temperature field prediction with in-situ
data in metal additive manufacturing using physics-informed neural
networks. <em>EAAI</em>, <em>150</em>, 110636. (<a
href="https://doi.org/10.1016/j.engappai.2025.110636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately predicting the temperature field in metal additive manufacturing (AM) processes is critical for preventing overheating, adjusting process parameters, and ensuring process stability. While physics-based computational models offer precision, they are often time-consuming and unsuitable for real-time predictions. Machine learning models, on the other hand, rely heavily on high-quality datasets, which can be costly and difficult to obtain in the metal AM domain. Existing studies on physics-informed neural networks (PINNs) have made progress in integrating physics with machine learning but often lack in-situ data integration, which is essential for capturing real-time thermal dynamics. Additionally, their methodologies are typically heavily dependent on specific process characteristics, limiting their flexibility. Our work addresses these gaps by introducing a PINN-based framework specifically designed for temperature field prediction in metal AM. The framework incorporates in-situ temperature data gathered during the manufacturing process, combining it with physics-informed inputs and a custom loss function. The approach is demonstrated through two case studies. In the first case, using a small set of experimental data, the model achieves an error below 3 % with a mean absolute error (MAE) of 11 °C. In the second case, using simulation data, the model achieves an error below 1 % with an MAE of 7 °C. In addition, the framework shows promising adaptability for different metal AM scenarios with different geometries, deposition patterns, and process parameters.},
  archive      = {J_EAAI},
  author       = {Pouyan Sajadi and Mostafa Rahmani Dehaghani and Yifan Tang and G. Gary Wang},
  doi          = {10.1016/j.engappai.2025.110636},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110636},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Two-dimensional temperature field prediction with in-situ data in metal additive manufacturing using physics-informed neural networks},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A real-time onboard compressor stall warning method based on
attention multiple sensors fusion and lightweight network.
<em>EAAI</em>, <em>150</em>, 110635. (<a
href="https://doi.org/10.1016/j.engappai.2025.110635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compressor stall is one of the critical faults in aero-engines. An effective stall warning model can assist operators and aviation power systems in taking timely measures to avoid or minimize the impact of compressor stall on flight. Real-time onboard stall warning systems for compressors demand models that possess sufficient accuracy, high reliability, and fast execution speed. Therefore, this paper proposes a novel lightweight network based on attention mechanism for multiple sensors feature fusion, named attention feature fusion lightweight network (AFF-LWNet). Specifically, the network first accomplishes multi-sensor feature fusion through an attention feature fusion block. It then learns input features through a lightweight network with two lightweight feature extraction units and finally employs a multi-layer perceptron (MLP) to output stall warning signals. To verify the feasibility of this approach, the proposed method is evaluated on the aero-engine compressor stall dataset. The results demonstrate that the proposed method achieves an average testing accuracy of 99.453 % and an actual average lead time of 241.87ms on the stall dataset, which surpasses the other five competing methods. Therefore, we believe that the proposed method can effectively achieve real-time onboard stall warning for aero-engine compressors with outstanding performance.},
  archive      = {J_EAAI},
  author       = {Huijie Jin and Yong-Ping Zhao and Zhiqiang Wang},
  doi          = {10.1016/j.engappai.2025.110635},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110635},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A real-time onboard compressor stall warning method based on attention multiple sensors fusion and lightweight network},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable graph convolutional network based on catastrophe
theory and its application to group activity recognition. <em>EAAI</em>,
<em>150</em>, 110634. (<a
href="https://doi.org/10.1016/j.engappai.2025.110634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks (graph models for short) are crucial for understanding model decisions through mathematical white-box interpretation, which can radically improve the performance and credibility of downstream artificial intelligence applications. To address the limitations of existing interpretability of over-smoothing and over-squashing, we propose an explainable graph model based on nonlinear catastrophe theory and apply it to group activity recognition to validate the usefulness of interpretability. (1) We introduce catastrophe mathematical theory to explore the internal processes of graph models and construct the explainable dynamical equations of the graph convolutional network; (2) When graph node features lose uniqueness, leading to over-smoothing, which reduces the discriminative power of the graph model, we propose a mathematical method to predict over-smoothing; (3) In response to the over-squashing of the node feature values that is excessively compressed, we design a channel expansion unit to extend the transmission paths of graph nodes and alleviate the over-squashing in the graph structure. Finally, we apply our model to group activity recognition tasks to capture complex interactions within groups. We obtain the competitive results on five publicly available graph structure datasets (Actor, Chameleon, Texas, Cornell, Cora) and our self-built group activity dataset. Our model can effectively capture node and graph-level features with stronger generalization capabilities. For complex and diverse real-world group activity data, our model offers intuitive graph-level explanations for group activity analysis. Through the analysis of over-smoothing and over-squashing, our method extends new theoretical approaches in explainable artificial intelligence.},
  archive      = {J_EAAI},
  author       = {Junpeng Kang and Jing Zhang and Lin Chen and Hui Zhang and Li Zhuo},
  doi          = {10.1016/j.engappai.2025.110634},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110634},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Explainable graph convolutional network based on catastrophe theory and its application to group activity recognition},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A knowledge graph for the vulnerability of construction
safety system in megaprojects based on accident inversion.
<em>EAAI</em>, <em>150</em>, 110630. (<a
href="https://doi.org/10.1016/j.engappai.2025.110630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing vulnerability of construction safety systems in megaprojects (CSSMs) poses significant challenges to their safety management and control. To address this obstacle, this study retrodicts the accidents based on text mining using the Bidirectional Encoder Repre-sentations from Transformers Topic (BER-Topic) model to uncover topic and topic words related to the vulnerabilities of CSSMs. The vulnerability indicator system (VIS) is established by considering the exposure, sensitivity, and adaptability of the vulnerability of CSSMs. Subsequently, an improved Decision-making Trial and Evaluation Laboratory (DEMATEL) method based on association rules is proposed to reduce the subjectivity in assigning weights to vulnerability indicators, and a topological network based on complex network is constructed to identify the characteristics of VIS. Based on this, a knowledge graph of vulnerabilities in CSSMs is developed. Finally, taking into account the occurrence probability and the actual losses incurred of vulnerability indicators, a vulnerability assessment model for CSSMs is proposed. The research findings are: 1) Based on the BER-Topic model, 32 topics and topic words related to the vulnerability of CSSMs are mined. 2) A VIS for CSSMs is constructed, including 42 indicators across three dimensions of exposure (19), sensitivity (14), and adaptability (9), involving four aspects: humans, machines, environment, and management. 3) The key points for vulnerability management and control in CSSMs are Inaccurate implementation of geological remediation plans, Rusting of connecting components, and Unlicensed personnel operating, among others, which have strong intermediary roles.},
  archive      = {J_EAAI},
  author       = {Yingliu Yang and Pengcheng Xiang},
  doi          = {10.1016/j.engappai.2025.110630},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110630},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A knowledge graph for the vulnerability of construction safety system in megaprojects based on accident inversion},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust sparse discriminative least squares regression for
image classification. <em>EAAI</em>, <em>150</em>, 110626. (<a
href="https://doi.org/10.1016/j.engappai.2025.110626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discriminative Least Squares Regression (DLSR) is a method used for multi-class classification tasks that expands the distance between different classes through an ε -dragging technique. However, it also amplifies the differences in intra-class regression targets. Moreover, the samples contain a significant amount of noise, which negatively affect the classification performance. To mitigate these problems, we propose Robust Sparse Discriminative Least Squares Regression (RSDLSR) approach to enhance the model&#39;s discriminative power. Firstly, we maintain the original data structure by matrix decomposition in the label space. Secondly, the noise is fitted using sparse constrained noise matrix to enhance the model&#39;s denoising ability. Furthermore, we select important features from label space using a linear discriminant analysis criterion to minimize the influence of redundant features. Finally, l 2 , 1 norm constraint is imposed on the relaxation matrix to improve the sparsity and robustness of the model. Comparative evaluations demonstrate that our proposed method exhibits significant advantages over various existing methods across different classification tasks.},
  archive      = {J_EAAI},
  author       = {Zhangjing Yang and Dingan Wang and Pu Huang and Minghua Wan and Fanlong Zhang},
  doi          = {10.1016/j.engappai.2025.110626},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110626},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust sparse discriminative least squares regression for image classification},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A physics informed convolution neural network for
spatiotemporal temperature analysis of concrete dams. <em>EAAI</em>,
<em>150</em>, 110624. (<a
href="https://doi.org/10.1016/j.engappai.2025.110624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural health monitoring is indispensable throughout the life cycle of dams, and the loading conditions determines the reliability of the assessment. Among them, temperature plays an important role on the behavior of arch dams, which are sparsely monitored in practice. How to use these sparsely measured data to obtain the accurate spatiotemporal temperature field becomes a critical problem. This study proposes a physics informed convolutional neural network for spatiotemporal temperature field of arch dams. A dual thread convolutional neural network considers the effects of spatiotemporal and temporal variables distinctively. The proposed model is validated using measured data from an existing arch dam. Compared with applied convolutional neural network, the proposed model improves the accuracy of temperature field reconstruction by 18 % and reduces reliance on measured data. Benefit of consideration of the continuity and heat transfer, the spatial distribution of the temperature field is more reasonable in continuity, and can retain accuracy even with limited monitoring data. The proposed model can provide the actual spatiotemporal non-uniform temperature field of the arch dam, providing basic data for the analysis and safety evaluation of arch dams throughout their life-cycle.},
  archive      = {J_EAAI},
  author       = {Jiaqi Yang and Jinting Wang and Feng Jin and Jianwen Pan},
  doi          = {10.1016/j.engappai.2025.110624},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110624},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A physics informed convolution neural network for spatiotemporal temperature analysis of concrete dams},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A decision modeling approach for the development of
sustainable transportation oil companies. <em>EAAI</em>, <em>150</em>,
110623. (<a
href="https://doi.org/10.1016/j.engappai.2025.110623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constructing sustainable transportation infrastructure to address climate change by reducing carbon dioxide and greenhouse gas emissions is unfeasible without the involvement of international oil companies (IOCs). Identifying the most sustainable IOC can significantly enhance legitimacy, corporate image, brand value, transparency, and reputation. The environmental impact of oil transportation is crucial to the sector&#39;s long-term growth, and modeling IOCs can guide decision-making that aligns with regulatory, environmental, and societal expectations, ensuring successful project implementation. Modeling IOCs presents multiple-attribute decision-analysis (MADA) challenges. Previous research proposed a decision matrix that crossed IOC alternatives with attributes, sub-attributes, and measurement items, utilizing assessments from 483 experts across 11 IOCs based on 2 attributes, 9 sub-attributes, and 47 measurements. Despite the literature review, challenges such as score deviations in the ranking method, as well as informational vagueness, ambiguity, and uncertainty in both weighting and ranking processes, remain unsolved, and early MADA methods exhibit theoretical flaws. This study aims to formulate and develop a decision modeling approach using multi-attribute ideal-real comparative analysis (MAIRCA) and fuzzy weighted zero inconsistency (FWZIC) within a homogeneous interval-valued intuitionistic fuzzy rough set (IIFRS) environment. This solution addresses the limitations in the literature and effectively handles the complexity of the decision matrix. The findings reveal that cost leadership under a hybrid competitive strategy (HCS-CL) emerged as the most sensitive attribute, holding the highest weight, highlighting the importance of cost efficiency and competitive pricing. IOC11 ranked highest, followed by IOC3 and IOC10, providing benchmarks for other companies. Lesser-ordered companies, such as IOC4, preserve employ these comprehensions to recognize intentional gaps and embrace best attempts from extraordinary-ordered participants. Sensitivity-analysis, Spearman&#39;s-correlation, and comparative-analysis proven the robustness of the proposed approach. The study highlights the require for oil and gas administrators to spotlight cost leadership advantages, raise-efficiency, lower-production costs, and influence economies of ratio to maintain a reasonable edge and enhance-market-positioning.},
  archive      = {J_EAAI},
  author       = {Hassan A. Alsattar and Sarah Qahtan and Nahia Mourad and A.A. Zaidan and Muhammet Deveci and Dragan Pamucar and Jurgita Antucheviciene and Weiping Ding},
  doi          = {10.1016/j.engappai.2025.110623},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110623},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A decision modeling approach for the development of sustainable transportation oil companies},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving model calibration in bone marrow cell
classification through mixup and center loss fusion. <em>EAAI</em>,
<em>150</em>, 110620. (<a
href="https://doi.org/10.1016/j.engappai.2025.110620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The analysis of bone marrow cell morphology is essential for the accurate diagnosis of hematological disorders. Traditional manual classification methods are time-consuming and labor-intensive. Although current automatic deep learning techniques mitigate these issues, they may still present significant risks in critical medical diagnostics due to overconfidence in predictions. To tackle these challenges, this paper proposes a novel calibration method called MixCL (Mix-Center Loss). MixCL combines the simple and effective data augmentation method Mixup with deep metric learning Center Loss, achieved through the design of a new loss function. By utilizing Mixup to generate mixing centers that enrich the feature sampling in the feature space, and leveraging the clustering effect of Center Loss to enhance the grouping of similar samples, MixCL combines the strengths of both methods. The effectiveness of MixCL is validated using three real bone marrow cell image datasets, demonstrating significant reductions in Expected Calibration Error (ECE) and Overconfidence Error (OE) for in-distribution samples. For example, in Shifted Windows Transformer model, ECE and OE metrics decreased across all datasets, with reductions averaging 1.72% in ECE and 2.10% in OE. The confidence Kernel Density Estimation (KDE) plot reveals that models using MixCL more effectively manage uncertainty in out-of-distribution samples, ensuring better differentiation between in-distribution and out-of-distribution samples. Thus, the proposed method effectively improves the calibration performance of the model while exhibiting better generalization performance, significantly improved when compared with current advanced bone marrow cell classification methods. Moreover, it has potential applications in various image classification fields, providing reliable confidence estimates.},
  archive      = {J_EAAI},
  author       = {Shuming Cheng and Qinghang Lu and Qianhang Guo and Yunqi Lin and Mingxin Li and Xingyu Zhao and Liang Guo and Jiaming Li and Jie Li and Qingmao Zhang and Qiongxiong Ma},
  doi          = {10.1016/j.engappai.2025.110620},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110620},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improving model calibration in bone marrow cell classification through mixup and center loss fusion},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Precise step counting algorithm for pedestrians using
ultra-low-cost foot-mounted accelerometer. <em>EAAI</em>, <em>150</em>,
110619. (<a
href="https://doi.org/10.1016/j.engappai.2025.110619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-velocity update (ZUPT) is one of the most widely used step counting methods in pedestrian inertial navigation. Existing accelerometer-based methods encounter issues with misjudgments of zero velocity and step counting errors in various activities. To tackle these challenges, we present a precise step counting algorithm leveraging ultra-low-cost foot-mounted accelerometer for pedestrians with extremely low complexity. This algorithm mainly contains two key points: adaptive acceleration threshold selection and state vector update, implemented by twice zero-velocity detections (ZVD, generating state vectors to depict pedestrian&#39;s status) and length comparisons. Accelerations undergo gravity correction, magnitude calculation, data smoothing, and parameters initialization. Subsequently, the zero-acceleration threshold is adaptively selected through ZVD, and the length of state intervals (LSI) is compared with the first length threshold. Then, the state vector is updated by ZVD, and the LSI is compared with the second length threshold. Finally, the number of state intervals is interpreted as step counts. Step counting experiments were conducted utilizing three diverse datasets, which comprised a self-constructed ultra-low-cost accelerometer-based dataset and two public datasets. These datasets covered various activities, such as normal walking, fast walking, running, multiple turns in a corridor, stationary stepping, and upstairs/downstairs. The proposed algorithm could achieve an accuracy of 100 % under the above situations. Compared to long short term memory (LSTM) and other algorithms, it exhibited an accuracy improvement of at least 13.05 %, with a processing time only 0.07 % of that required by LSTM. The proposed algorithm enables accurate step counting across a range of activities performed by different pedestrians with high precision, low complexity, and robust applicability.},
  archive      = {J_EAAI},
  author       = {Jingxue Bi and Jianhui Wang and Baoguo Yu and Guobiao Yao and Yunjia Wang and Hongji Cao and Lu Huang and Huaqiao Xing},
  doi          = {10.1016/j.engappai.2025.110619},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110619},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Precise step counting algorithm for pedestrians using ultra-low-cost foot-mounted accelerometer},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-stream structure-oriented neighbor enhancement network
for dental model segmentation. <em>EAAI</em>, <em>150</em>, 110618. (<a
href="https://doi.org/10.1016/j.engappai.2025.110618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary objective of digital orthodontic treatment is to achieve accurate tooth segmentation of the three-dimensional (3D) dental mesh model obtained from oral scanning equipment. However, current advanced deep learning-based methods often consolidate all features into a single vector during the feature learning process, thus overlooking the distinct information among features and subsequently weakening their complementary roles. To address this issue, we propose a two-stream structure-oriented neighbor enhancement network (TSNEN) to improve the complementary effect among different features. Specifically, TSNEN develops an input-specific two-stream structure and feature enhancement modules to emphasize the geometric disparities among various meshes and achieve the complementary enhancement of different features, respectively. Furthermore, the self-attention module is modified to fully integrate the local features derived from the branches of the two streams, which effectively balances the data differences among different features to mitigate feature confusion, and ultimately achieves accurate segmentation of the dental model. The real dental model dataset is analyzed to verify the effectiveness and capability of the proposed method which reached an overall accuracy (OA) at 96.83 % and mean over union (mIoU) at 92.06 %. Finally, the comparative analysis is implemented and the results further show that the proposed method has better performance both in prediction accuracy and robustness.},
  archive      = {J_EAAI},
  author       = {Zhihua Liu and Hao Tang and Jiutao Xue and Yuhe Liao},
  doi          = {10.1016/j.engappai.2025.110618},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110618},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Two-stream structure-oriented neighbor enhancement network for dental model segmentation},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time prediction of axial force in concrete-filled steel
tubular columns under fire conditions using modular artificial
intelligence techniques. <em>EAAI</em>, <em>150</em>, 110617. (<a
href="https://doi.org/10.1016/j.engappai.2025.110617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The axial force plays a critical role in assessing the functional integrity of columns within a building in fire. However, it cannot be measured directly and is influenced by factors such as temperature, load ratio, and axial restraint. This study proposes a real-time methodology to predict the axial force of restrained concrete-filled steel tubular (CFST) columns exposed to real fires, utilizing modular artificial intelligence. A module is developed that combines a convolutional neural network (CNN) and long short-term memory (LSTM) networks to predict the temperature field of CFST columns caused by fire in real time. This module estimates the current temperature field using past data and the current surface temperature, which is continuously monitored with inherent noise. It effectively mitigates noise interference, achieving an R 2 of 0.97 on the test dataset, which ensures accurate estimations. Additionally, a separate LSTM module with a skip connection is employed to predict the axial force ratio, integrating temperature predictions and real-time measurements of axial deformation. Finally, the accuracy of this modular model demonstrates better performance in predicting real-time axial force compared to the conventional integrated deep learning model, achieving an R 2 of 0.99. The proposed approach enables accurate prediction of axial force in restrained CFST columns across various fire scenarios and structural conditions, aiming at increasing the scientificity of fire rescue decisions.},
  archive      = {J_EAAI},
  author       = {Hong-Hui Qi and Guo-Qiang Li and Shaojun Zhu},
  doi          = {10.1016/j.engappai.2025.110617},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110617},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Real-time prediction of axial force in concrete-filled steel tubular columns under fire conditions using modular artificial intelligence techniques},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A real-time prediction model for instantaneous dam-break
flood evolution of concrete gravity dams based on attention mechanism
and spatiotemporal multiple features. <em>EAAI</em>, <em>150</em>,
110616. (<a
href="https://doi.org/10.1016/j.engappai.2025.110616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simulating the flood evolution following the sudden breach of concrete gravity dams is crucial for enabling prompt emergency flood control decisions. The real-time performance and reliability of these flood propagation simulations are essential for improving the accuracy and speed of emergency responses. This study introduces a deep learning model that integrates an attention mechanism to predict flood evolution parameters in real time. Initially, parameters such as water depth and flow rate were measured under 32 distinct dam-break scenarios using a hydrodynamic model. By combining terrain data with time-series flood discharge data, we compiled a dataset containing 1984 entries, enhanced through reduced-order methods. A novel deep learning model, the Flood-Swin-Transformer, was then developed to predict the spatiotemporal evolution of dam-break floods. This model was benchmarked against 11 baseline models and four state-of-the-art deep learning models. The results indicate: (1) Baseline models accurately predict water depth but are less effective at predicting flow rate parameters; (2) Deep learning models outperform baseline models in both accuracy and classification capabilities for water depth and flow rate parameters, showing robust performance; (3) Extensive analyses, including error, classification accuracy, effectiveness, robustness, and flood parameter error mapping, demonstrate the superior performance of the proposed model; (4) The proposed model predicts flood evolution up to 43.75 times faster than traditional hydrodynamic models, facilitating real-time prediction capabilities.},
  archive      = {J_EAAI},
  author       = {Chao Wang and Yaofei Zhang and Sherong Zhang and Xiaohua Wang and Xingbo Zhou and Yishu Lai},
  doi          = {10.1016/j.engappai.2025.110616},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110616},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A real-time prediction model for instantaneous dam-break flood evolution of concrete gravity dams based on attention mechanism and spatiotemporal multiple features},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dialogue response coherency evaluation with feature
sensitive negative sample using multi list-wise ranking loss.
<em>EAAI</em>, <em>150</em>, 110609. (<a
href="https://doi.org/10.1016/j.engappai.2025.110609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic evaluation of dialogue coherency is crucial for developing high-quality dialogue systems. However, traditional evaluation metrics such as Bilingual Evaluation Understudy (BLEU) and Recall-Oriented Understudy for Gisting Evaluation (ROUGE) have limitations when it comes to assessing diverse and creative responses because they heavily rely on reference responses. For learnable metrics which utilize contrastive learning, challenges are encountered due to the use of randomly selected negative samples that do not reflect conversational features (i.e. topic, emotion, intention) and the lack of granularity in assessing response appropriateness. To address these limitations, we propose the Feature sensitive Multi-Listwise Ranking (FMListR) response coherency evaluation model. This model aims to evaluate dialogue coherency in degrees while considering conversational sensitive features. This approach involves sampling feature-sensitive responses that share conversational features with ground truth responses and utilizing them as hard negative samples. The model is trained using Multi-Listwise Ranking (MListR) loss, which is designed to learn the ranking between negative samples and identify response features. The experimental results demonstrate that Feature sensitive Multi-Listwise Ranking exhibits stronger correlations with human judgment compared to other response coherency evaluation metrics. By considering conversational features and training the model using a specialized loss function, FMListR provides a more robust and accurate evaluation of dialogue coherency.},
  archive      = {J_EAAI},
  author       = {YeongJun Hwang and Dongjun Kang and JinYeong Bak},
  doi          = {10.1016/j.engappai.2025.110609},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110609},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dialogue response coherency evaluation with feature sensitive negative sample using multi list-wise ranking loss},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comprehensive assessment of failure mode and shear capacity
of reinforced concrete circular columns based on data-driven machine
learning methods. <em>EAAI</em>, <em>150</em>, 110603. (<a
href="https://doi.org/10.1016/j.engappai.2025.110603">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforced concrete (RC) columns are critical elements in frame structures. A common challenge in structural engineering is estimating the seismic capacity of circular RC columns, as existing methods typically require transforming circular columns into equivalent square sections due to the absence of direct formulas. To address this, this study introduces data-driven machine learning (ML) methods to directly assess both failure modes and seismic shear capacity of circular RC columns. With the help of automated machine learning (AutoML), seven ML algorithms were selected and fine-tuned, resulting in 40 distinct models that were analyzed and compared in detail. The results indicate that the Multilayer Perceptron (MLP) model outperforms others in predicting seismic failure modes, achieving a high accuracy of 88 %. For seismic shear capacity predictions, the Weighted Ensemble (WE) model achieved the best performance with Root Mean Squared Error of 53.49, Mean Absolute Error of 39.23, Coefficient of Determination of 0.88 and Mean Squared Error of 2861.18 among all the ML models. Furthermore, the results (the predicted maximum lateral force/the experimental results) of the WE model, with a mean value of 0.98, a standard deviation of 0.11, and a coefficient of variation (mean/standard deviation) of 12.8 %, surpass those of traditional theoretical and empirical models. Besides, the ML models offer fast, accurate seismic performance evaluations for circular RC columns, eliminating the need for complex and time-consuming calculations. Furthermore, SHapley Additive exPlanations (SHAP) analysis provided visual insights into parameter contributions, enhancing model transparency and trust for engineering applications.},
  archive      = {J_EAAI},
  author       = {Yue Wen and Shiqiao Zhou and Gaochuang Cai and Zhili He and Amir Si Larbi},
  doi          = {10.1016/j.engappai.2025.110603},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110603},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Comprehensive assessment of failure mode and shear capacity of reinforced concrete circular columns based on data-driven machine learning methods},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging large language models to examine the interaction
between investor sentiment and stock performance. <em>EAAI</em>,
<em>150</em>, 110602. (<a
href="https://doi.org/10.1016/j.engappai.2025.110602">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the relationship between investor sentiment and stock performance is crucial in dynamic financial markets. Existing researches often focus on financial news and stock prices, while studies on investor sentiment typically rely on traditional machine learning models that require extensive data labeling. Additionally, most researches focus on single stock indices, overlooking the impact of brand popularity. To address these gaps, this study proposes a novel framework to analyze the interaction between investor sentiment and stock performance, using Chinese Baijiu industry stocks as a case example. It further explores how brand popularity influences this relationship, offering insights for informed investment decisions through artificial intelligence technology. In this study, we leverage Generative Pre-trained Transformer 4 (GPT-4), a state-of-the-art black-box large language model, to process vast volumes of unstructured text data from stock forums. By employing in-context learning with human-labeled examples, GPT-4 generates weak labels that are subsequently used to fine-tune Large Language Model Meta AI (LLaMA), a smaller and more efficient open-source LLM from Meta AI, thereby enabling sentiment-driven decision-making in real-world scenarios. To construct a comprehensive sentiment indicator, we integrate both direct and indirect factors influencing sentiment and use principal component analysis to combine them effectively. To examine interaction between sentiment and stock yield, we apply the Granger causality test and vector autoregression models across stocks with different brand popularity levels. The results show that our framework achieves state-of-the-art performance investor sentiment analysis. Moreover, with brand popularity significantly amplifying the interaction between investor sentiment and stock yield, it leads to bidirectional Granger causality in highly popular brands.},
  archive      = {J_EAAI},
  author       = {Yong Zhuang and Feilong Wang and Dickson K.W. Chiu and Kevin K.W. Ho},
  doi          = {10.1016/j.engappai.2025.110602},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110602},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Leveraging large language models to examine the interaction between investor sentiment and stock performance},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lane change trajectory planning based on improved model
predictive control with artificial potential field for autonomous
vehicles in medium-high speed scenarios. <em>EAAI</em>, <em>150</em>,
110601. (<a
href="https://doi.org/10.1016/j.engappai.2025.110601">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the design of a lane change control system for autonomous vehicles (AVs) in medium-high speed scenarios. A lane change trajectory planning method based on the combination of artificial potential field (APF) and model predictive control (MPC), referred to as APF-MPC, is proposed. To ensure a smooth transition at the beginning and end of the lane change, a reference trajectory based on a sinusoidal curve is designed. The obstacle potential field, constructed using a two-dimensional joint probability density function, is combined with the road potential field to enhance lane change safety. The potential field function is integrated into the MPC optimal control problem, which is constructed based on the point-mass model. This problem is then solved to obtain the planned trajectory within the predicted time domain. The lateral and longitudinal tracking controllers, designed using linear MPC, are employed to track the planned trajectory in real-time, thereby demonstrating the real-time performance of this method. The feasibility of the APF-MPC method is verified through a co-simulation platform. The simulation results indicate that the trajectories planned by the APF-MPC method meet the requirements of safety, occupant comfort, and lane change efficiency. In different scenarios, the front wheel angle of the AV during the lane change ranges from -2 to 2 degrees. Compared with non-adaptive APF and traditional MPC methods, the maximum lateral acceleration, maximum lateral velocity, and maximum front wheel steering angle of the AV during lane changing are reduced by more than 40%.},
  archive      = {J_EAAI},
  author       = {Zhaojun Zhang and Jiale Qin and Simeng Tan and Hongjie Luo},
  doi          = {10.1016/j.engappai.2025.110601},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110601},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lane change trajectory planning based on improved model predictive control with artificial potential field for autonomous vehicles in medium-high speed scenarios},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Input parameterized physics informed neural networks for de
noising, super-resolution, and imaging artifact mitigation in time
resolved three dimensional phase-contrast magnetic resonance imaging.
<em>EAAI</em>, <em>150</em>, 110600. (<a
href="https://doi.org/10.1016/j.engappai.2025.110600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivation: Hemodynamic analysis is crucial for diagnosing and predicting cardiovascular diseases. However, methods relying on fluid flow simulations or blood flow imaging are complex, time-consuming, and require specialized expertise, limiting their clinical use. Goal: This research aims to automate the enhancement of blood flow images, providing clinicians with a fast, accurate tool for hemodynamic analysis without requiring advanced expertise. Objectives: A software tool based on physics-constrained neural networks was developed to enable clinicians to easily select and process regions of interest (ROIs) in time-resolved three-dimensional phase contrast magnetic resonance imaging (4D-Flow MRI) blood flow images for quick, accurate analysis. Methods: The Input Parameterized Physics-Informed Neural Network (IP-PINN) was introduced to improve the spatio-temporal resolution of 4D-Flow MRI. IP-PINN mitigates noise, velocity aliasing, and phase errors. A convolutional neural network processes ROI data into latent vectors, which are then used to predict velocity, pressure, and spin density via a multi-layer perceptron. The method is trained with synthetic blood flow data using an innovative loss function that addresses noise and artifacts. Results: IP-PINN successfully enhanced image resolution, reducing noise and artifacts when tested on synthetic 4D-Flow MRI data derived from blood flow simulations of intracranial aneurysms. For data with 20 decibels (dB) signal-to-noise ratio, results closely matched the ground truth with less than 5.5% relative error. Processing took under two minutes. The method also has the potential to reduce data acquisition time by 25%. Conclusions: IP-PINN could significantly enhance the clinical use of 4D-Flow MRI for personalized hemodynamic analysis in cardiovascular diseases.},
  archive      = {J_EAAI},
  author       = {Amin Pashaei Kalajahi and Hunor Csala and Zayeed Bin Mamun and Sangeeta Yadav and Omid Amili and Amirhossein Arzani and Roshan M. D’Souza},
  doi          = {10.1016/j.engappai.2025.110600},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110600},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Input parameterized physics informed neural networks for de noising, super-resolution, and imaging artifact mitigation in time resolved three dimensional phase-contrast magnetic resonance imaging},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing machine learning algorithms for fault
classification in rolling bearings: A bayesian optimization approach.
<em>EAAI</em>, <em>150</em>, 110597. (<a
href="https://doi.org/10.1016/j.engappai.2025.110597">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern power machinery is inherently complex and operates under dynamic operating conditions, so they demand advanced solutions based on deep learning to diagnose bearing faults inside rotating equipment that cause unplanned downtime and safety issues, leading to operational challenges. However, most deep learning approaches aim to improve performance by incorporating hybrid neural networks that rely on multiple convolutional and temporal units, often overlooking optimizing the large number of hyperparameters that define the structure and performance of hybrid models along with the associated computational constraints. To address this gap, this study presents an innovative approach for the detection and classification of bearing faults by integrating an optimized sparse deep autoencoder (DAE) with a Bidirectional Long Short-Term Memory model (Bi-LSTM). The optimal network structure and hyperparameters are determined through Bayesian optimization (BO) with parallel settings, which automatically searches for network configurations that improve the feature extraction ability of the DAE and the generalization ability of the Bi-LSTM for more efficient fault classification in rolling bearings. Parallel optimization accelerates network structure and hyperparameter tuning by evaluating multiple configurations at once. It leverages the full potential of available multi-core Central Processing Units (CPUs)/Graphics Processing Units (GPUs) in conjunction with a lightweight BO surrogate model. This autonomous and user-friendly framework generates inputs from principal component analysis for linear and BO-DAE for non-linear feature extraction and selection, which are then used to train a BO-enhanced Bi-LSTM. This three-stage optimized method effectively captures spatial and temporal dependencies in vibrational signals, achieving superior efficiency, accuracy, and reliability compared to shallow and deep learning models. Evaluation metrics, including macro precision (99.50 %), recall (99.60 %), F1-Score (99.57 %), and Cohen&#39;s Kappa metric (Cκ = 99.53 %), demonstrate the efficacy of our approach for bearing fault classification in industrial applications.},
  archive      = {J_EAAI},
  author       = {Muhammad Zain Yousaf and Josep M. Guerrero and Muhammad Tariq Sadiq},
  doi          = {10.1016/j.engappai.2025.110597},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110597},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimizing machine learning algorithms for fault classification in rolling bearings: A bayesian optimization approach},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic scheduling in flexible and hybrid disassembly
systems with manual and automated workstations using reward-shaping
enhanced reinforcement learning. <em>EAAI</em>, <em>150</em>, 110588.
(<a href="https://doi.org/10.1016/j.engappai.2025.110588">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As e-waste grows at an alarming rate, efficient disassembly systems have become crucial for sustainable production practices. Existing disassembly systems rely heavily on fixed automation and limited manual intervention, making it challenging to adapt to dynamic issues such as workstation failures and system bottlenecks, leading to inefficiencies and suboptimal resource allocation. To address these issues, a hybrid disassembly system is developed that integrates manual and automated workstations, allowing for the flexible variation of manual resources as needed to optimize the disassembly process, with a focus on reducing time and maximizing profit. Through the proposal of a Proximal Policy Optimization (PPO) algorithm enhanced with Reward-Shaping, the research effectively tackles key challenges of uncertainty and dynamic conditions in disassembly systems, including workstation failures and system bottlenecks. These issues are explored through a refrigerator disassembly simulation model. The results demonstrate that the PPO algorithm significantly outperforms traditional rule-based methods and two other reinforcement learning techniques in managing complex dynamic scheduling and resource allocation tasks, offering greater efficiency and flexibility. These findings contribute to the advancement of automated disassembly processes and their integration into modern industrial systems.},
  archive      = {J_EAAI},
  author       = {Jinlong Wang and Qihuiyang Liang and Min Li and Zelin Qu and Yuanyuan Zhang},
  doi          = {10.1016/j.engappai.2025.110588},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110588},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic scheduling in flexible and hybrid disassembly systems with manual and automated workstations using reward-shaping enhanced reinforcement learning},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Soft actor-critic enhanced nonsingular terminal synergetic
control for serial manipulators with quantized input and state.
<em>EAAI</em>, <em>150</em>, 110587. (<a
href="https://doi.org/10.1016/j.engappai.2025.110587">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synergetic control is vulnerable to model uncertainty, which affects control performances and stability. In addition, quantized sensor measurements and control signals compound these challenges. Equally important, a unique problem in serial manipulator robots is the varying control response across joints, which affects the end effector’s pose when moving to the desired position. The mentioned challenges motivate this study to propose soft actor-critic reinforcement learning as a novel adaptive approach for nonsingular terminal synergetic control on a 4-degree-of-freedom serial manipulator robot. The control law is designed based on the nonsingular terminal synergetic control evolution constraint, manifold, and macrovariable. Subsequently, the soft actor-critic reinforcement learning dynamically adjusts the evolution constraint parameters, adapting to the changing state of the environment. The Lyapunov stability theorem proves the control law stability. This study also introduces a novel reinforcement learning reward function that encourages state convergence using the Cauchy probability density function and macrovariable. The agent training environment accounts for state and input quantization, enabling a seamless sim-to-real transition. The simulations and physical experiments validate the effectiveness of the proposed controller in improving transient response, tracking response, and uniform performance across joints. Additionally, online training validates the safe exploration property of the proposed adaptive control.},
  archive      = {J_EAAI},
  author       = {Muhammad Auzan and Yong-Lin Kuo},
  doi          = {10.1016/j.engappai.2025.110587},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110587},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Soft actor-critic enhanced nonsingular terminal synergetic control for serial manipulators with quantized input and state},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial neural networks for finger vein recognition: A
survey. <em>EAAI</em>, <em>150</em>, 110586. (<a
href="https://doi.org/10.1016/j.engappai.2025.110586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finger vein recognition is an emerging biometric recognition technology. Different from the other biometric features on the body surface, the venous vascular tissue of the fingers is buried deep inside the skin. Due to this advantage, finger vein recognition is highly stable and private. Finger veins are virtually impossible to steal and difficult to interfere with by external conditions. Unlike the finger vein recognition methods based on traditional machine learning, the artificial neural network technique, especially deep learning, does not rely on feature engineering and has superior performance. To summarize the development of finger vein recognition based on artificial neural networks,this paper collects 174 related papers. First, we introduce the background of finger vein recognition and the motivation for this survey. Then, the development history of artificial neural networks and the representative networks on finger vein recognition tasks are introduced. The public datasets widely used in finger vein recognition are then described. After that, we summarize the related finger vein recognition tasks based on classical neural networks and deep neural networks, respectively. Finally, the challenges and potential development directions in finger vein recognition are discussed. This paper provides a comprehensive and novel summary of the application of artificial neural networks in the finger vein recognition field.},
  archive      = {J_EAAI},
  author       = {Yimin Yin and Renye Zhang and Pengfei Liu and Wanxia Deng and Dayu Hu and Siliang He and Chen Li and Jinghua Zhang},
  doi          = {10.1016/j.engappai.2025.110586},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110586},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Artificial neural networks for finger vein recognition: A survey},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-module cooperative control method for on-ramp area in
heterogeneous traffic flow using reinforcement learning. <em>EAAI</em>,
<em>150</em>, 110584. (<a
href="https://doi.org/10.1016/j.engappai.2025.110584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the on-ramp area, vehicle conflicts significantly reduce traffic efficiency and increase collision risks. This study introduces a novel dual-module cooperative control approach designed for on-ramps that accommodate heterogeneous traffic flows, including connected and automated vehicles (CAVs) and human driving vehicles (HDVs). By utilizing reinforcement learning techniques, the approach aims to enhance both traffic efficiency and safety. The approach comprises two key modules: the merging control module and the lane-changing control module. The merging control module facilitates cooperation between mainline and ramp vehicles, while the lane-changing control module assists mainline CAVs in making informed lane-change decisions. Agents within these modules are trained using the proximal policy optimization algorithm, known for its strong convergence properties. After 100 to 200 training episodes, the agents achieve stable peak average rewards. Simulation results demonstrate significant improvements in traffic efficiency and safety with the dual-module control method in on-ramp areas, especially in scenarios involving CAV-HDV heterogeneous traffic flows. With a CAV penetration rate of just 0.2, average vehicle delay is reduced by 26 %. Furthermore, from a safety perspective, when the CAV penetration rate reaches or exceeds 0.3, the time-exposed time-to-collision decreases by approximately 45 %. Transferability analysis indicates that integrating reinforcement learning agents into the control strategy produces positive results across varying maximum speeds and flow rates. In heterogeneous traffic environments, it is advisable to train agents at high CAV penetration rates. Comparative studies further show that the proposed method significantly enhances traffic efficiency and safety, maintaining robust performance even at lower CAV penetration rates.},
  archive      = {J_EAAI},
  author       = {Wenzhang Yang and Changyin Dong and Ziqian Zhang and Xu Chen and Hao Wang},
  doi          = {10.1016/j.engappai.2025.110584},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110584},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A dual-module cooperative control method for on-ramp area in heterogeneous traffic flow using reinforcement learning},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Class imbalance-aware domain specific transfer learning
approach for medical image classification: Application on COVID-19
detection. <em>EAAI</em>, <em>150</em>, 110583. (<a
href="https://doi.org/10.1016/j.engappai.2025.110583">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional Neural Networks (CNNs) show promise in medical image classification; however, their effectiveness is often constrained by the availability of large, annotated datasets, which are not always accessible. Additionally, the lack of medically relevant transfer models limits the potential of Transfer Learning (TL) in addressing this challenge. Existing TL methods typically employ conventional approaches that result in suboptimal performance and exhibit issues related to network bias, especially in imbalanced datasets. To overcome these limitations, we introduce a novel class imbalance-aware, domain-specific transfer learning framework (CIDSTL-Net) designed specifically for medical imaging tasks. CIDSTL-Net adopts a two-stage training approach: initially developing domain-specific models followed by fine-tuning on targeted medical datasets. This method incorporates an innovative class weighting strategy in its loss calculation to address dataset bias and enhances the transfer head network with a novel combination of fully connected, batch normalization, and dropout layers. Additionally, CIDSTL-Net employs cyclically scheduled learning rates to optimize parameter exploration and exploitation during training. We have rigorously evaluated CIDSTL-Net on four publicly available COVID-related datasets, covering chest X-ray and Computed Tomography (CT) images for the classification of COVID, Non-COVID, Normal, Pneumonia, and Lung Opacity conditions. The results demonstrate state-of-the-art performance with 5-fold cross-validation mean accuracies of 96.87 %, 96.50 %, 99.70 %, and 99.55 % for the respective datasets, marking significant improvements over existing methods. Among various CNN architectures tested, DenseNet-121 proved to be the most effective, offering superior accuracy with fewer parameters. Given the pressing global challenge posed by the COVID-19 pandemic, CIDSTL-Net holds significant potential to aid medical practitioners in the rapid and accurate classification of COVID-19 cases.},
  archive      = {J_EAAI},
  author       = {Marut Jindal and Birmohan Singh},
  doi          = {10.1016/j.engappai.2025.110583},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110583},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Class imbalance-aware domain specific transfer learning approach for medical image classification: Application on COVID-19 detection},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent evaluation of pavement friction at high speeds
with artificial intelligence powered three-dimensional laser imaging
technology. <em>EAAI</em>, <em>150</em>, 110580. (<a
href="https://doi.org/10.1016/j.engappai.2025.110580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate non-contact pavement friction evaluation at high speeds faces many challenges when using low-resolution (LR) three-dimensional (3D) texture images or other deficient texture data. With artificial intelligence (AI) powered 0.1-mm (0.1-mm) 3D laser imaging technology, this paper proposed a two-step deep learning (DL) network, named Friction-8KNet, for accurate and intelligent non-contact pavement friction evaluation at high speeds. Particularly, a 3D laser imagining device was employed to collect LR texture images at a speed of 30 mph, which were processed via a DL-based super-resolution (SR) algorithm to obtain 0.1 mm high-resolution (HR) images with a size of 8192 × 4096 (8K) pixels. The Friction-8KNet comprises a network backbone for texture feature extraction in Step 1 and a triple attention network for friction evaluation in Step 2. The network backbone is developed to precisely extract features of an HR image without requiring large graphics processing unit (GPU) memory. The triple attention net is designed with three function-specific attention modules to utterly mine the extracted features for accurate friction prediction. Experimental results show that Friction-8KNet can achieve 99.19 % prediction accuracy and transcends models using other texture data, including small HR 3D images, LR 3D images, and two-dimensional (2D) texture profiles. This research promotes an accurate and efficient measurement of pavement friction for production level in a non-contact manner in the future.},
  archive      = {J_EAAI},
  author       = {Guolong Wang and Kelvin C.P. Wang and Guangwei Yang},
  doi          = {10.1016/j.engappai.2025.110580},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110580},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent evaluation of pavement friction at high speeds with artificial intelligence powered three-dimensional laser imaging technology},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Corrigendum to “understanding the disparities in mathematics
performance: An interpretability-based examination” [eng. Appl. Artif.
Intell. 133 part b (2024) 108109]. <em>EAAI</em>, <em>150</em>, 110579.
(<a href="https://doi.org/10.1016/j.engappai.2025.110579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EAAI},
  author       = {Ismael Gómez-Talal and Luis Bote-Curiel and José Luis Rojo-Álvarez},
  doi          = {10.1016/j.engappai.2025.110579},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110579},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Corrigendum to “Understanding the disparities in mathematics performance: An interpretability-based examination” [Eng. appl. artif. intell. 133 part b (2024) 108109]},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Standalone and hybrid machine learning approaches to predict
sediment load in an alluvial channel. <em>EAAI</em>, <em>150</em>,
110578. (<a
href="https://doi.org/10.1016/j.engappai.2025.110578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A significant amount of sediment transported in an alluvial river can alter the morphology and shape of the river. Accurate prediction of sediment load is essential in studying the change in geomorphology and dynamics of rivers and also to evaluate its impact on aquatic ecosystems, infrastructure, and human activities dependent on water resources. The present study demonstrates framework for predicting sediment load in alluvial channels using both standalone and hybrid machine learning (ML) models. Multiple datasets collected from various river surveys and flume studies were used to evaluate the significance of key variables such as friction slope ( Sf ), channel discharge ( Q ), and bed shear stress ( τ b ) affecting the sediment transport employing ML models (Bagging (BA), Random Committee (RC)) and the standalone ML models (Multi-Layer Perceptron Regression (MLPR) and Reduced Error Pruning Tree (REPT). The hybrid Bagging-REPT (BA-REPT) model outperformed other models with a Nash-Sutcliffe Efficiency (NSE) of 0.915, followed by RC-REPT (NSE = 0.906). Among the various variables, friction slope ( S f ) was identified as the most influential variable affecting sediment transport behavior. It was also observed that Hybrid models can predict sediment transport behavior more accurately as compared to standalone models and empirical equations. The findings of the study thus demonstrate the importance of hybrid learning in addressing the nonlinear complexity of sediment transport processes.},
  archive      = {J_EAAI},
  author       = {Sanjit Kumar and Vishal Deshpande and Mayank Agarwal},
  doi          = {10.1016/j.engappai.2025.110578},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110578},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Standalone and hybrid machine learning approaches to predict sediment load in an alluvial channel},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight vision transformer with embedded hybrid
attention for quick response code defect classification. <em>EAAI</em>,
<em>150</em>, 110575. (<a
href="https://doi.org/10.1016/j.engappai.2025.110575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quick Response (QR) code label printing quality is crucial to product control. Due to the limited number of defect samples, unclear features, and the need to detect a large number of labels in real time, automated visual inspection faces challenges. For efficient and accurate automated visual defect recognition of printed QR code production, we propose a lightweight Vision Transformer network, Vision Transformer with Embedded Hybrid Attention (ViT-EHA). First, the Mixed Depthwise Convolution Block (MDConvBlock) is introduced to capture QR code defect details and feature information. This method additionally reduces the number of model parameters and computational costs. Furthermore, the LeAttention-Local Convolution-Multilayer Perceptron (LeALCM) module is proposed to enhance the ability to capture global information of the model and improve the effect of minor defect recognition. Ultimately, a hybrid attention (HA) module has been integrated to enhance the processing of low-level image features and to strengthen the interplay between shallow and deep features. To verify the validity and generalization of the model, the experimental results show that the proposed ViT-EHA method achieved an accuracy of 99.00% and a parameter count of 4.198 million (M) on the self-constructed dataset Code-10 (QR Code Dataset with 10 Classes), and the accuracy reached 98.33% and 97.73% on the public datasets NEU-CLS (Northeastern University Classification Dataset) and NEU-CLS-64 (Northeastern University Classification Dataset with 64 × 64 images), respectively.},
  archive      = {J_EAAI},
  author       = {Dianlu Hu and Lun Zhao and Yu Ren and Sen Wang and Xuanlin Ye and Haohan Zhang and Changqing Peng},
  doi          = {10.1016/j.engappai.2025.110575},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110575},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight vision transformer with embedded hybrid attention for quick response code defect classification},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating pre-trained convolutional neural networks and
foundation models as feature extractors for content-based medical image
retrieval. <em>EAAI</em>, <em>150</em>, 110571. (<a
href="https://doi.org/10.1016/j.engappai.2025.110571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image retrieval refers to the task of finding similar images for given query images in a database, with applications such as diagnosis support. While traditional medical image retrieval relied on clinical metadata, content-based medical image retrieval (CBMIR) depends on image features, which can be extracted automatically or semi-automatically. Many approaches have been proposed for CBMIR, and among them, using pre-trained convolutional neural networks (CNNs) is a widely utilized approach. However, considering the recent advances in the development of foundation models for various computer vision tasks, their application for CBMIR can also be investigated. In this study, we used several pre-trained feature extractors from well-known pre-trained CNNs and pre-trained foundation models and investigated the CBMIR performance on eight types of two-dimensional (2D) and three-dimensional (3D) medical images. Furthermore, we investigated the effect of image size on the CBMIR performance. Our results show that, overall, for the 2D datasets, foundation models deliver superior performance by a large margin compared to CNNs, with the general-purpose self-supervised model for computational pathology (UNI) providing the best overall performance across all datasets and image sizes. For 3D datasets, CNNs and foundation models deliver more competitive performance, with contrastive learning from captions for histopathology model (CONCH) achieving the best overall performance. Moreover, our findings confirm that while using larger image sizes (especially for 2D datasets) yields slightly better performance, competitive CBMIR performance can still be achieved even with smaller image sizes. Our codes to reproduce the results are available at: https://github.com/masih4/MedImageRetrieval .},
  archive      = {J_EAAI},
  author       = {Amirreza Mahbod and Nematollah Saeidi and Sepideh Hatamikia and Ramona Woitek},
  doi          = {10.1016/j.engappai.2025.110571},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110571},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Evaluating pre-trained convolutional neural networks and foundation models as feature extractors for content-based medical image retrieval},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Thermal image-guided complementary masking with multiscale
fusion for multi-spectral image semantic segmentation. <em>EAAI</em>,
<em>150</em>, 110569. (<a
href="https://doi.org/10.1016/j.engappai.2025.110569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation of visible and thermal image is a kind of significant method for harsh environments. Most existing works focus on designing a multi-modal feature fusion module. However, these works may result in over-dependence on a specific modality and a lack of consideration for local and global context-aware information. Motivated by these issues, (1) a thermal image-guided complementary masking strategy is proposed to encourage the network to focus on regions with abundant semantic information; (2) a multi-modal fusion module is developed to integrate both local and global information and ensure consistency for semantic segmentation; (3) a self-distillation loss between unmasked and masked input modalities is introduced to enhance the robustness and consistency of the network. Particularly, the proposed masking strategy can force the network to concentrate on the meaningful area in all modalities, and thus the network can enhance the ability to connect context information. Experimental results on three public datasets demonstrate the superiority of our model.},
  archive      = {J_EAAI},
  author       = {Zeyang Chen and Mingnan Hu and Bo Chen},
  doi          = {10.1016/j.engappai.2025.110569},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110569},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Thermal image-guided complementary masking with multiscale fusion for multi-spectral image semantic segmentation},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An electric vehicle sales hybrid forecasting method based on
improved sentiment analysis model and secondary decomposition.
<em>EAAI</em>, <em>150</em>, 110561. (<a
href="https://doi.org/10.1016/j.engappai.2025.110561">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The swift proliferation of electric vehicles has triggered profound shifts in consumer behavior, emphasizing the critical role of precise sales forecasts as the cornerstone for data-driven policy and production planning by both governments and electric vehicle manufacturers. However, extant forecasting models face challenges in accurately capturing consumer sentiment conveyed by online reviews and effectively extracting multiscale features of high-frequency sequences. Therefore, an electric vehicle sales hybrid forecasting method based on BERT-Bi-LSTM (Bidirectional Encoder Representations from Transformers-Bidirectional long short-term memory) sentiment analysis and secondary decomposition is proposed. First, the BERT-Bi-LSTM model is developed to perform sentiment analysis on online reviews. The model can better capture the relationship between each word and its surrounding words in text information. Second, a secondary decomposition model is constructed to decompose multisource data series, it can extract the seasonal components of the series and high-frequency complex data features, also solve potential issues of incomplete decomposition that may arise from a single decomposition. Finally, machine learning methods are utilized for hybrid forecasting. To verify the effectiveness of the proposed model, multiple sets of comparative experiments are conducted. The empirical results indicate the proposed model has higher prediction accuracy and robustness.},
  archive      = {J_EAAI},
  author       = {Jinpei Liu and Hui Pan and Rui Luo and Huayou Chen and Zhifu Tao and Zhijing Wu},
  doi          = {10.1016/j.engappai.2025.110561},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110561},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An electric vehicle sales hybrid forecasting method based on improved sentiment analysis model and secondary decomposition},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Causal explanation of nitrogen oxide emission predictions
for fluid catalytic cracking unit based on convergent cross mapping:
Predict the future and explain how. <em>EAAI</em>, <em>150</em>, 110560.
(<a href="https://doi.org/10.1016/j.engappai.2025.110560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial chemical processes are inherently intricate, characterized by prolonged operational sequences and correlations among features. Solely utilizing temporal information limits the prediction precision of deep learning methods. Moreover, causative features identified based on data may not align with the principles of chemical process. To solve these problems, this study proposes a spatial–temporal information based deep learning method, attention-based temporal graph convolutional network and convergent cross mapping (ATGCN-CCM). The devices are abstracted as nodes in a computational graph (CG) to represent the process, enabling the incorporation of spatial information into the predictive model. Attention mechanism is conducted within each node to dynamically weight the features. The CG is also used to select input features for causal analysis, ensuring that the identified causative features are not only consistent with the characteristics of the data, but also with the prior knowledge of the process. ATGCN-CCM is applied to datasets from industrial fluid catalytic cracking (FCC) units for nitrogen oxides (NOx) concentration prediction and causative feature identification. The prediction results demonstrate superior precision of ATGCN-CCM compared to some state-of-the-art spatial feature based, temporal feature based and hybrid methods. The identified features exhibit strong alignment with the principles of the chemical processes and the field experiences, thereby significantly enhancing model interpretability. The proposed ATGCN-CCM method illustrate its advanced capabilities in both precision and robustness, compared with attention-based methods and other causal analysis methods.},
  archive      = {J_EAAI},
  author       = {Han Jiang and Shucai Zhang and Jingru Liu and Xin Peng and Weimin Zhong},
  doi          = {10.1016/j.engappai.2025.110560},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110560},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Causal explanation of nitrogen oxide emission predictions for fluid catalytic cracking unit based on convergent cross mapping: Predict the future and explain how},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Keypoint-guided feature enhancement and alignment for
cross-resolution vehicle re-identification. <em>EAAI</em>, <em>150</em>,
110557. (<a
href="https://doi.org/10.1016/j.engappai.2025.110557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resolution mismatch between low-resolution query images and high-resolution gallery images in vehicle re-identification is rarely studied but ubiquitous in real-world applications. An intuitive approach to solving cross-resolution vehicle re-identification is to utilize super-resolution algorithms to recover detailed information from low-resolution query images. However, vehicle super-resolution algorithms not only recover the detailed information of the vehicle but also enhance the background noise, which would degrade the re-identification performance. In addition, the view mismatch problem also significantly limits the performance of vehicle re-identification. To handle these problems, we propose a novel Keypoint Guiding Network, which simultaneously addresses the problems of resolution mismatch and view mismatch from the perspective of keypoints in an end-to-end learning framework, for cross-resolution vehicle re-identification. In particular, we first generate a set of vehicle keypoints via an effective Gaussian localization method, and then adaptively construct two keypoint-based guidances using attention models. We integrate these two guidances into vehicle super-resolution and view alignment to handle the problems of resolution mismatch and view mismatch respectively. Moreover, to alleviate the heterogeneity between super-resolution query images and high-resolution gallery ones, we design a dual-path teacher–student distillation scheme to narrow their feature distributions. Comprehensive experiments on two down-sampled benchmark datasets demonstrate the effectiveness of our Keypoint Guiding Network against the state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Aihua Zheng and Longfei Zhang and Weijun Zhang and Zi Wang and Chenglong Li and Xiaofei Sheng},
  doi          = {10.1016/j.engappai.2025.110557},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110557},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Keypoint-guided feature enhancement and alignment for cross-resolution vehicle re-identification},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Runner system geometry prediction using variational
autoencoder deep learning model. <em>EAAI</em>, <em>150</em>, 110555.
(<a href="https://doi.org/10.1016/j.engappai.2025.110555">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The novelty of this article is the choice of the architecture of neural networks for fluid channel topology optimization and its application in the design of multi-cavity injection molds. A generative deep learning model was developed to extract characteristics representing the inverse field of the permeability of a fluid in a porous medium, which in turn represents the runner system geometry of a thermoplastic injection mold. The model comprises a variational autoencoder network and multilayer perceptron. The characteristics extracted from the variational autoencoder are used as a set of multilayer perceptron output vectors, whereas the input data are determined by the positions of the input and outputs of the injection channels. The field of the inverse permeability in each case was obtained by topology optimization using a heuristic algorithm. The trained model displayed statistical metrics indicating good performance and task generalizability. The mean absolute error was 0.0106 for the entire dataset. Speed up compared to traditional computational fluid dynamics software was 625 times faster in one case. For 150 cases, it was 76907 times faster⁠. The purpose of generating a deep learning model in this area is to reduce the design time of injection molds and the computational requirements. The developed neural network reduces the runner system volume by 16% or its hydraulic resistance by 25%.},
  archive      = {J_EAAI},
  author       = {Evgenii Kurkin and Jose Gabriel Quijada Pioquinto and Vladislava Chertykovtseva and Evgenii Minaev},
  doi          = {10.1016/j.engappai.2025.110555},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110555},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Runner system geometry prediction using variational autoencoder deep learning model},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature selection considering synergy between features based
on soft neighborhood rough sets. <em>EAAI</em>, <em>150</em>, 110553.
(<a href="https://doi.org/10.1016/j.engappai.2025.110553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neighborhood entropy-based measures provide a powerful framework for feature selection to select features that are more useful for classification. However, most of these feature selection methods do not pay attention to the complementarities and synergies between features, as well as the interactions between them. In addition, most existing neighborhood rough sets are subjective in the determination of neighborhood radius when dealing with classification problems, which may lead to the omission of useful information. To solve these problems, a soft neighborhood rough set model-based feature selection method (SNCMI) is proposed. Firstly, the method dynamically adjusts the neighborhood radius, significantly minimizing its influence on the uncertainty measurement. Secondly, it comprehensively considers the correlation, redundancy, complementarity, and synergy between features through soft neighborhood uncertainty measures. Thirdly, an innovative objective evaluation function is introduced to evaluate the interactions between features. Finally, we compare the proposed SNCMI algorithm with several well-known feature selection algorithms on twenty public datasets and demonstrate the effectiveness of SNCMI.},
  archive      = {J_EAAI},
  author       = {Lubin Chen and Jinkun Chen and Yaojin Lin},
  doi          = {10.1016/j.engappai.2025.110553},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110553},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature selection considering synergy between features based on soft neighborhood rough sets},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forecasting train travel times of china–europe railway
express through a hybrid deep learning model optimized with a
bandit-based approach. <em>EAAI</em>, <em>150</em>, 110552. (<a
href="https://doi.org/10.1016/j.engappai.2025.110552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the globalization of economic trade, the China–Europe Railway Express (CRE) has emerged as a crucial means of international freight transportation. However, since the travel process of CRE trains is subject to various factors (e.g., customs clearance efficiency, weather changes, etc.), existing models struggle to handle the complex nonlinear characteristics of the travel time data, failing to achieve accurate train travel time predictions. This significantly affects the scheduling and utilization of capacity resources along the CRE routes. To address this issue, this study proposes a novel hybrid deep learning model, i.e., Discrete Wavelet Transform (DWT)-Convolutional Neural Networks (CNN)-Bidirectional Gated Recurrent Unit (BiGRU) (DWT-CNN-BiGRU). Specifically, the DWT technique is first used to preprocess historical train travel time data to reduce noise interference and improve data quality. Then, the CNN module focuses on extracting local spatial features from the data, whereas the BiGRU module emphasizes its long-term temporal dependencies. Furthermore, a bandit-based approach is applied to hyperparameter optimization to further exploit model potentials. By testing on a real-life CRE dataset, the DWT-CNN-BiGRU model demonstrates superior prediction accuracy with root mean square error (RMSE), mean absolute error (MAE), and mean absolute percentage error (MAPE) values respectively equal to 10.7347 h, 7.5482 h, and 2.2034%, and it outperforms the other ten popular baseline models. In conclusion, the proposed DWT-CNN-BiGRU model features a lightweight structure and strong robustness, offering reliable technical support to alleviate capacity resource shortages and improve the service quality of CRE.},
  archive      = {J_EAAI},
  author       = {Yongxiang Zhang and Liting Gu and Jingwei Guo and Xu Yan and Xin Hu and Zhen-Song Chen},
  doi          = {10.1016/j.engappai.2025.110552},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110552},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Forecasting train travel times of China–Europe railway express through a hybrid deep learning model optimized with a bandit-based approach},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid architecture of sparse convolutional neural
network-transformer for enhanced spatial-geometric feature learning in
surface reconstruction. <em>EAAI</em>, <em>150</em>, 110550. (<a
href="https://doi.org/10.1016/j.engappai.2025.110550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning-based methods have garnered significant attention in indoor scene reconstruction tasks. However, researchers have often overlooked the crucial role of the surface prediction stage. Our study specifically focuses on this phase. According to our experiments and analysis, this phase primarily addresses spatial voxel occupancy and geometric structure maintenance. Simple structural designs are insufficient to effectively solve these problems. To address these challenges, we propose a hybrid model, which combines the strengths of Convolution Neural Networks and Transformer architectures for fine reconstruction. Additionally, we introduce several new techniques, including the Sparse Positional Attention mechanism, Sparse Channel Decoding Block, and Mixed Feature Fusion mechanism. These techniques, leveraging the characteristics of sparse computation, enhance feature utilization in both spatial and channel dimensions. With limited training and testing resources, our network achieves optimal results on the ScanNet dataset, improving precision and F-score by 2.1% and 1.6%, respectively, and reducing the Chamfer distance to 0.055 m. To our knowledge, our model is the first use of hybrid structures in the surface prediction phase of an indoor scene reconstruction task. Moreover, we hope that our design and analysis can provide a new paradigm for task network design in this phase.},
  archive      = {J_EAAI},
  author       = {Mingyang Li and Wei Zhang and Yanyan Liu and Xiang Feng and Changsong Liu and Yimeng Fan and Lixue Xu},
  doi          = {10.1016/j.engappai.2025.110550},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110550},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid architecture of sparse convolutional neural network-transformer for enhanced spatial-geometric feature learning in surface reconstruction},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing pose estimation for mobile robots: A comparative
analysis of deep reinforcement learning algorithms for adaptive extended
kalman filter-based estimation. <em>EAAI</em>, <em>150</em>, 110548. (<a
href="https://doi.org/10.1016/j.engappai.2025.110548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Extended Kalman Filter (EKF) is a widely used algorithm for state estimation in control systems. However, its lack of adaptability limits its performance in dynamic and uncertain environments. To address this limitation, we used an approach that leverages Deep Reinforcement Learning (DRL) to achieve adaptive state estimation in the EKF. By integrating DRL techniques, we enable the state estimator to autonomously learn and update the values of the system dynamics and measurement noise covariance matrices, Q and R, based on observed data, which encode environmental changes or system failures. In this research, we compare the performance of four DRL algorithms, namely Deep Deterministic Policy Gradient (DDPG), Twin Delayed Deep Deterministic Policy Gradient (TD3), Soft Actor-Critic (SAC), and Proximal Policy Optimization (PPO), in optimizing the EKF’s adaptability. The experiments are conducted in both simulated and real-world settings using the Gazebo simulation environment and the Robot Operating System (ROS). The results demonstrate that the DRL-based adaptive state estimator outperforms traditional methods in terms of estimation accuracy and robustness. The comparative analysis provides insights into the strengths and limitations of different DRL agents, showing that the TD3 and the DDPG are the most effective algorithms, with TD3 achieving superior performance, resulting in a 91% improvement over the classic EKF, due to its delayed update mechanism that reduces training noise. This research highlights the potential of DRL to advance state estimation algorithms, offering valuable insights for future work in adaptive estimation techniques.},
  archive      = {J_EAAI},
  author       = {Islem Kobbi and Abdelhak Benamirouche and Mohamed Tadjine},
  doi          = {10.1016/j.engappai.2025.110548},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110548},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing pose estimation for mobile robots: A comparative analysis of deep reinforcement learning algorithms for adaptive extended kalman filter-based estimation},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph neural networks with scattering transform for network
anomaly detection. <em>EAAI</em>, <em>150</em>, 110546. (<a
href="https://doi.org/10.1016/j.engappai.2025.110546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As cyber-attacks become increasingly sophisticated and frequent, the demand for advanced and proactive Network Intrusion Detection Systems (NIDS) has become more urgent than ever. To address critical shortcomings in existing NIDS approaches, such as high false-positive rates that trigger unnecessary alerts, inability to capture complex relationships between network nodes, and oversimplified node representation initialization that fails to reflect real-world network behaviors, we introduce a novel solution called Scattering Transform Edge Graph (STEG). STEG harnesses the wavelet scattering transform to extract edge feature information and employs a graph-based representation to effectively capture the topological relationships between network nodes. Additionally, we enhance STEG by incorporating node embedding techniques like DeepWalk for initializing node representations, moving beyond conventional uniform initialization methods. Comprehensive evaluations on benchmark NIDS datasets reveal that STEG outperforms current state-of-the-art methods. Moreover, the integration of Node2Vec-based initialization further boosts performance, marking a significant advancement in the effectiveness of network intrusion detection systems.},
  archive      = {J_EAAI},
  author       = {Abdeljalil Zoubir and Badr Missaoui},
  doi          = {10.1016/j.engappai.2025.110546},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110546},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Graph neural networks with scattering transform for network anomaly detection},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparative analysis and evaluation of ageing forecasting
methods for semiconductor devices in online health monitoring.
<em>EAAI</em>, <em>150</em>, 110545. (<a
href="https://doi.org/10.1016/j.engappai.2025.110545">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semiconductor devices, especially MOSFETs (Metal–oxide–semiconductor field-effect transistor), are crucial in power electronics, but their reliability is affected by ageing processes influenced by cycling and temperature. The primary ageing mechanism in discrete semiconductors and power modules is the bond wire lift-off, caused by crack growth due to thermal fatigue. The process is empirically characterized by exponential growth and an abrupt end of life, making long-term ageing forecasts challenging. This research presents a comprehensive comparative assessment of different forecasting methods for MOSFET failure forecasting applications. Classical tracking, statistical forecasting and Neural Network (NN) based forecasting models are implemented along with novel Temporal Fusion Transformers (TFTs). A comprehensive comparison is performed assessing their MOSFET ageing forecasting ability for different forecasting horizons. For short-term predictions, all algorithms result in acceptable results, with the best results produced by classical NN forecasting models at the expense of higher computations. For long-term forecasting, only the TFT is able to produce valid outcomes owing to the ability to integrate covariates from the expected future conditions. Additionally, TFT attention points identify key ageing turning points, which indicate new failure modes or accelerated ageing phases.},
  archive      = {J_EAAI},
  author       = {Adrian Villalobos and Iban Barrutia and Rafael Peña-Alzola and Tomislav Dragicevic and Jose I. Aizpurua},
  doi          = {10.1016/j.engappai.2025.110545},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110545},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Comparative analysis and evaluation of ageing forecasting methods for semiconductor devices in online health monitoring},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of the flexural strength and elastic modulus of
cementitious materials reinforced with carbon nanotubes: An approach
with artificial intelligence. <em>EAAI</em>, <em>150</em>, 110544. (<a
href="https://doi.org/10.1016/j.engappai.2025.110544">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, researchers investigated incorporating carbon nanotubes (CNTs) to improve the mechanical properties of cementitious materials. Recently, few studies developed Machine Learning (ML)-based predictive models to maximize insights from limited experimental data. However, these models often fail to identify key parameters and their complex correlations with mechanical properties. This study aims to improve the prediction of the mechanical properties of CNT-reinforced cementitious materials, specifically, elastic modulus and flexural strength, by leveraging multiple predictive Artificial Intelligence (AI)-based models. Deep Neural Networks (DNN), ensemble-bagging, and Support Vector Regression (SVR) were proposed and rigorously tested to predict the flexural strength and elastic modulus of the composite material. The feature selection was performed based on the domain knowledge and the informative metrics including the permutation importance analyses and Pearson&#39;s correlation analyses. The research identified several parameters that have traditionally been overlooked but proved to be critical. With a total of nineteen input parameters analyzed, the findings indicate that the mechanical properties of the composite material are primarily influenced by surfactant-to-CNT mass ratio, CNT content and physical properties, as well as ultrasonication process. Conversely, sand type and CNT purity are found to have minimal importance to the change in mechanical properties. In addition, the proposed DNN models outperform other ML models in predicting both flexural strength and elastic modulus, achieving R-squared values of 0.93 and 0.86 with mean absolute percentage errors of 8.16% and 7.22%, respectively.},
  archive      = {J_EAAI},
  author       = {Mahyar Ramezani and Do-Eun Choe and Abdur Rasheed},
  doi          = {10.1016/j.engappai.2025.110544},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110544},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Prediction of the flexural strength and elastic modulus of cementitious materials reinforced with carbon nanotubes: An approach with artificial intelligence},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reparameterization convolutional neural networks for
handling imbalanced datasets in solar panel fault classification.
<em>EAAI</em>, <em>150</em>, 110541. (<a
href="https://doi.org/10.1016/j.engappai.2025.110541">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solar photovoltaic technology has grown significantly as a renewable energy, with unmanned aerial vehicles equipped with thermal infrared cameras effectively inspecting solar panels. However, long-distance capture and low-resolution infrared cameras make the targets small, complicating feature extraction. Additionally, the large number of normal photovoltaic modules results in a significant imbalance in the dataset. Furthermore, limited computing resources on unmanned aerial vehicles further challenge real-time fault classification. These factors limit the performance of current fault classification systems for solar panels. The multi-scale and multi-branch Reparameterization of convolutional neural networks can improve model performance while reducing computational demands at the deployment stage, making them suitable for practical applications. This study proposes an efficient framework based on reparameterization for infrared solar panel fault classification. We propose a Proportional Balanced Weight asymmetric loss function to address the class imbalance and employ multi-branch, multi-scale convolutional kernels for extracting tiny features from low-resolution images. The designed models were trained with Exponential Moving Average for better performance and reparameterized for efficient deployment. We evaluated the designed models using the Infrared Solar Module dataset. The proposed framework achieved an accuracy of 83.8% for the 12-Class classification task and 74.0% for the 11-Class task, both without data augmentation to enhance generalization. The accuracy improvements of up to 16.4% and F1-Score gains of up to 18.7%. Additionally, we achieved an inference speed that is 3.4 times faster than the training speed, while maintaining high fault classification performance.},
  archive      = {J_EAAI},
  author       = {Jielong Guo and Chak Fong Chong and Pedro Henriques Abreu and Chao Mao and Jiaxuan Li and Chan-Tong Lam and Benjamin K. Ng},
  doi          = {10.1016/j.engappai.2025.110541},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110541},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reparameterization convolutional neural networks for handling imbalanced datasets in solar panel fault classification},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Blockchain data with ransomware detection based on deep feed
forward maxout network. <em>EAAI</em>, <em>150</em>, 110538. (<a
href="https://doi.org/10.1016/j.engappai.2025.110538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread use of the internet and technology has become more common and essential in daily life. The main risk to the network is malware, and ransomware is considered a destructive kind of malware. The ransomware resulted in massive data losses and produced huge financial losses. In order to overcome this issue, the Deep Feed Forward Maxout Network (DFFMN) is developed to detect ransomware using blockchain data in this study. To accomplish this, initially, the input data from the blockchain is given to feature extraction to extract features. Then, data normalization is performed and the extracted features are fused together using a Deep Belief Network (DBN) with Lorentzian similarity. Lastly, ransomware detection is executed by utilizing the DFFMN technique, which is created by the integration of Deep Maxout Network and Deep Feedforward Neural Network. The experimental results exemplify that the proposed DFFMN acquired accuracy value of 91.57 %, sensitivity value of 91.04 %, precision value of 89.35 %, False Negative Rate (FNR) of 0.086, False Positive Rate (FPR) of 0.090 and F-Measure of 89.44 %.},
  archive      = {J_EAAI},
  author       = {Vemireddi Srinadh and Buddi Padmaja and Dhanunjaya Rao Chigurukota and Mallikharjuna Rao Karreddula and Balajee Maram and Smritilekha Das},
  doi          = {10.1016/j.engappai.2025.110538},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110538},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Blockchain data with ransomware detection based on deep feed forward maxout network},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025a). Dual-branch crack segmentation network with multi-shape
kernel based on convolutional neural network and mamba. <em>EAAI</em>,
<em>150</em>, 110536. (<a
href="https://doi.org/10.1016/j.engappai.2025.110536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cracks are one of the most common pavement diseases. If not promptly repaired, they will hasten the deterioration of the road. Semantic segmentation is the most convenient pavement crack detection method to assess the damage level. Convolutional neural networks (CNN) excel at extracting local spatial information, but they have limitations in capturing global contextual information. Therefore, a dual-branch crack segmentation network (DBCNet) with Mamba and multi-shape convolutional kernels is proposed. First, a dual-branch encoder is employed to extract both spatial and contextual information, consisting of the spatial branch and the context branch. The cross-like block (CrossBlock) that excels in extracting spatial information horizontally and vertically from cracks is proposed. Multiple CrossBlocks are stacked to construct a lightweight network as a spatial branch. The improved Visual State Space Model (VMamba) serves as a context branch for modeling long-range dependencies for more accurate pixel-by-pixel segmentation. Second, the Feature Fusion Module (FFM), based on squeeze-and-excitation attention, is constructed to dynamically fuse the features from the two branches layer by layer. Third, a Cross-aware Mamba Module (CMM) with the hybrid CNN-Mamba architecture is proposed to compose the decoder. Fourth, comprehensive evaluations were conducted on three public datasets. Performs on multiple metrics achieved considerable progress, outperforming the seven state-of-the-art models. The mean intersection over union (mIoU) on Deepcrack, CrackTree 260, and CFD reached 87.87%, 85.34%, and 81.35%, respectively. Code and data will be available at https://github.com/name191/DBCNet .},
  archive      = {J_EAAI},
  author       = {Jianming Zhang and Dianwen Li and Zhigao Zeng and Rui Zhang and Jin Wang},
  doi          = {10.1016/j.engappai.2025.110536},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110536},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dual-branch crack segmentation network with multi-shape kernel based on convolutional neural network and mamba},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FA-SconvAE-LSTM: Feature-aligned stacked convolutional
autoencoder with long short-term memory network for soft sensor
modeling. <em>EAAI</em>, <em>150</em>, 110535. (<a
href="https://doi.org/10.1016/j.engappai.2025.110535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement of soft sensor technology has enabled the real-time estimation of critical parameters in complex industrial processes, where direct measurement through hardware sensors is often infeasible. Industrial process data typically exhibit both spatial correlations and temporal dependencies, necessitating sophisticated modeling approaches to capture these characteristics effectively. In this study, a spatio-temporal model, termed the feature-aligned stacked convolutional autoencoder with long short-term memory, is proposed to develop soft sensors for nonlinear dynamic industrial processes. The proposed model begins with the systematic training of a stacked convolutional autoencoder using a layer-by-layer pre-training technique. This approach facilitates the extraction of high-level spatial feature representations from the process variables. To address the issue of feature misalignment in the spatial features extracted by the stacked convolutional autoencoder, a feature alignment strategy is implemented, ensuring that the extracted spatial features are properly aligned. Subsequently, the aligned spatial features are fed into a long short-term memory network to capture temporal dependencies, with quality variables serving as the output for soft sensor development. The effectiveness and superiority of the proposed method are demonstrated through experiments conducted on two industrial processes: the sulfur recovery unit and the multiphase flow process. Comparative analyses with other state-of-the-art methods reveal that the proposed model achieves the highest performance, with R 2 values of 0.86222 for the sulfur recovery unit and 0.94307 for the multiphase flow process, outperforming all compared methods.},
  archive      = {J_EAAI},
  author       = {Ping Wu and Zengdi Miao and Ke Wang and Jinfeng Gao and Xujie Zhang and Siwei Lou and Chunjie Yang},
  doi          = {10.1016/j.engappai.2025.110535},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110535},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {FA-SconvAE-LSTM: Feature-aligned stacked convolutional autoencoder with long short-term memory network for soft sensor modeling},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Surrogate-assisted motion planning and layout design of
robotic cellular manufacturing systems. <em>EAAI</em>, <em>150</em>,
110530. (<a
href="https://doi.org/10.1016/j.engappai.2025.110530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A surrogate-assisted multi-objective evolutionary algorithm is proposed for simultaneous optimization of robot motion planning and layout design in robotic cellular manufacturing systems. A sequence-pair is used to represent the layout of components in a robotic cell to avoid overlapping in the evolutionary computation. The robot motion planning with Rapidly exploring Random Trees Star (RRT*) is applied to compute the total operation time of a robot arm for each layout. Non-dominated Sorting Genetic Algorithm II (NSGA-II) is used to minimize the total required layout area and the operation time for a robot arm. The proposed surrogate model can estimate the robot’s operation time with 98% of accuracy without explicit computations of the motion planning algorithm. The experimental results with a physical 6 Degree of Freedom (DOF) manipulator show that the total computation time is approximately 1/400, significantly shorter than the conventional methods.},
  archive      = {J_EAAI},
  author       = {Tomoya Kawabe and Tatsushi Nishi and Ziang Liu and Tomofumi Fujiwara},
  doi          = {10.1016/j.engappai.2025.110530},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110530},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Surrogate-assisted motion planning and layout design of robotic cellular manufacturing systems},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-labeled framework with semi-supervised ball k-means
clustering-based synthetic example generation for semi-supervised
classification in industrial applications. <em>EAAI</em>, <em>150</em>,
110528. (<a
href="https://doi.org/10.1016/j.engappai.2025.110528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While self-labeled methods can exploit labeled and unlabeled instances to train classifiers, they are severely restricted by the labeled instance number and distribution. One category of the existing solutions tends to combine oversampling techniques, with the goal of creating labeled synthetic instances to improve the labeled instance number and distribution. The synthetic example generation-based framework for semi-supervised classification (SEG-SSC) is the only state-of-the-art instance of the above category. Nevertheless, it still suffers from the following issues: a) relying on 7 hyper-parameters, b) ineffectively improving the labeled instance number and distribution in sparser regions with fewer labeled instances, and c) having a relatively high time complexity of O ( nlogn + G×n ). To this end, a self-labeled framework with semi-supervised ball k -means clustering-based synthetic example generation (SEGBallKmeans-SSC), having only one hyper-parameter and the time complexity of O ( n ), is proposed for semi-supervised classification. The main uniqueness is that: a) firstly, a semi-supervised ball k -means clustering (SSBallKmeans) with a compact-cluster assumption is proposed to divide semi-supervised data into compact ball clusters, intending to reveal regions with different labeled instance numbers; b) secondly, an SSBallKmeans-based oversampling method (OMSSBallKmean) is proposed to create more labeled synthetic instances on compact ball clusters with fewer labeled instances, intending to improve the labeled instance number and distribution, especially on sparser regions with fewer labeled instances. After that, any self-labeled method are executed on improved labeled instances and unlabeled instances to train more accurate classifiers. Experiments have proven that SEGBallKmeans-SSC outperforms 7 state-of-the-art self-labeled frameworks on extensive benchmark datasets from various industrial applications.},
  archive      = {J_EAAI},
  author       = {Junnan Li and Lufeng Wang and Shun Fu ( Revision ) and Wei Fu and Xin Pan},
  doi          = {10.1016/j.engappai.2025.110528},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110528},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-labeled framework with semi-supervised ball K-means clustering-based synthetic example generation for semi-supervised classification in industrial applications},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep learning-based sentiment flow analysis model for
predicting financial risk of listed companies. <em>EAAI</em>,
<em>150</em>, 110522. (<a
href="https://doi.org/10.1016/j.engappai.2025.110522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of natural language processing technology, more studies are applying deep learning models to extract features from unstructured data and predict corporate financial risk through horizontal comparisons. This paper proposes the Sentiment Flow Analysis (SFA) model designed to capture the nuanced emotional dynamics present in corporate annual reports and analyst reports from a longitudinal perspective. By leveraging advanced contextual embeddings from a Transformer architecture and employing a sophisticated recurrent neural network, the model effectively processes sequential data, allowing for a comprehensive understanding of sentiment trends over a five-year period. The effectiveness of our model was validated through experiments predicting the removal of special treatment (ST) status for 344 listed companies under special treatment in 2022 and 2023, achieving a prediction accuracy of up to 82.27%. Compared to state-of-the-art models in the same field, our model demonstrates improvements in prediction accuracy and recall, showcasing the application of Artificial Intelligence (AI) in financial risk assessment.},
  archive      = {J_EAAI},
  author       = {Feifei Tao and Wenya Wang and Rongke Lu},
  doi          = {10.1016/j.engappai.2025.110522},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110522},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep learning-based sentiment flow analysis model for predicting financial risk of listed companies},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient self-learning disturbance-resistant control for
high-speed flight vehicle based on dual heuristic dynamic programming.
<em>EAAI</em>, <em>150</em>, 110521. (<a
href="https://doi.org/10.1016/j.engappai.2025.110521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in high-speed flight vehicles (HSFVs) have sparked significant interest due to their strategic importance and emerging civilian applications. These vehicles exhibit strong nonlinearities and multi-axis interactions and are usually influenced by uncertainties such as modeling errors, parameter perturbations, and external disturbances. Neglecting these challenges in attitude controller design can lead to trajectory tracking deviations and potential mission failure due to instability. Motivated by this issue, an efficient disturbance-resistant control method with online self-learning capability is proposed. Firstly, a feedback linearization baseline controller combined with finite-time extended state observers (FESOs) is designed to ensure stability. Next, a dual heuristic dynamic programming (DHP) controller with critic-only structure is developed for online performance optimization. Update laws of the critic neural network (NN) are derived based on policy iteration, and zero-sum game (ZSG) theory is incorporated to enhance the system’s adaptive capacity to uncertainties. Lyapunov theory is subsequently employed to validate the convergence of network weights and the system stability. The proposed method, compared to common adaptive dynamic programming (ADP) approaches for attitude control, demonstrates superior learning efficiency and guarantees the convergence of online learning without the necessity for pre-training. Simulation results indicate that the method equips the HSFV with robust dynamic performance throughout a broad flight envelope, with attitude tracking errors constrained to less than 0.5°. Future research will focus on developing fault-tolerant and prescribed performance control frameworks with online learning ability, representing an advancement in the current technique.},
  archive      = {J_EAAI},
  author       = {Xu Huang and Jiarun Liu and Yue Peng and Yuan Zhang and Zhaolei Wang and Weimin Bao},
  doi          = {10.1016/j.engappai.2025.110521},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110521},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Efficient self-learning disturbance-resistant control for high-speed flight vehicle based on dual heuristic dynamic programming},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Remote sensing scene classification with relation-aware
dynamic graph neural networks. <em>EAAI</em>, <em>150</em>, 110513. (<a
href="https://doi.org/10.1016/j.engappai.2025.110513">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote sensing scene classification (RSSC) is challenging due to the complexity and diversity of scenes. Existing methods need help to capture long-range and structural relationships among image regions, limiting their performance. This paper proposes a novel graph-based model that learns relation-aware dynamic graph representations for remote sensing scene classification tasks. The proposed model consists of three main components: Multi-Scale Feature Extraction (MSFE), Relation-Aware Graph Processing (RAGP), and Scene Classification with Weighted Pooling (SCWP). MSFE uses a multi-scale feature extraction strategy to generate low-level feature nodes from remote sensing images. RAGP applies several cascaded graph processing blocks to dynamically learn the relations between nodes in high-level semantic spaces using relation-aware graph convolutional and node feature update operators. SCWP performs weighted pooling on the learned node features from RAGP to obtain global representations of remote sensing images and makes scene decisions using a fully feed-forward network-based classifier. We evaluate our model on three benchmark datasets and compare it with state-of-the-art RSSC methods. Our experimental results show that our model outperforms existing methods on all three datasets, demonstrating the effectiveness of a graph-based model with the proposed techniques for RSSC tasks.},
  archive      = {J_EAAI},
  author       = {Qionghao Huang and Fan Jiang and Changqin Huang},
  doi          = {10.1016/j.engappai.2025.110513},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110513},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Remote sensing scene classification with relation-aware dynamic graph neural networks},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning adaptive distractor-aware-suppression appearance
model for visual tracking. <em>EAAI</em>, <em>150</em>, 110511. (<a
href="https://doi.org/10.1016/j.engappai.2025.110511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some algorithms based on Siamese networks aim to improve the representation of target by combining background and target information, but they seldom consider adjusting the influence of background distractors on appearance modeling. In this paper, we propose an adaptive distractor suppression appearance model for robust visual tracking. Firstly, to fully utilize the valuable clues provided by the background, a new distractor model is specially designed to determine the weight of each distractor based on the similarity between the distractor and the target. This model adaptively fuses the distractors according to their weights, thereby focusing on distractors that are highly similar to the target. Secondly, a distractor model transformation strategy is constructed to rank the influence of the distractor model on appearance modeling, which mines the similarity relationship between the background distractor and target using regularized linear regression, effectively controlling the influence of the distractor model. Finally, we unify them into a learning adaptive distractor-aware-suppression appearance model for improving the discriminant ability of the appearance model, which selectively introduces the distractor model to suppress distractors according to the intensity of the distractor, achieving robust tracking in the presence of background interference. Experimental results on six benchmarks demonstrate that the proposed tracker achieves excellent performance in various challenging tracking tasks, particularly when facing background interference, where the tracking precision and success rate of our algorithm reach state-of-the-art levels.},
  archive      = {J_EAAI},
  author       = {Huanlong Zhang and Linwei Zhu and Yanchun Zhao and Fusheng Li and Deshuang Huang},
  doi          = {10.1016/j.engappai.2025.110511},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110511},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning adaptive distractor-aware-suppression appearance model for visual tracking},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multiagent architecture for industrial internet of things
safety applications. <em>EAAI</em>, <em>150</em>, 110495. (<a
href="https://doi.org/10.1016/j.engappai.2025.110495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial Internet of Things (IIoT) is a key technological pillar of the Fourth Industrial Revolution, also known as Industry 4.0. In this context, an area of considerable interest is human safety technology. Solutions rely on multiple sensors connected to a central monitoring system and supported with software to autonomously or semi-autonomously identify safety hazards. To this end, Computer vision systems are leveraged. However, streaming continuous video from numerous sensors can strain network resources, risking timely hazard response in large industrial setups. This work proposes a reference IIoT architecture based on Multi-Agent Systems to manage safety risks. It allows for scalable sensor integration and dynamically assesses sensor input based on risk levels. To prevent network overload, the architecture uses sensor-level intelligence at the edge layer to assess situational risks and decide whether to forward video signals to a centralized local cloud agent. The central cloud agent, using strategies like ensemble learning, selectively requests additional data from distributed edge agents based on the diagnosed risk. This approach was tested in monitoring safety during aircraft assembly, showing that edge processing reduces network load by limiting unnecessary data transmission without compromising accuracy. This architecture effectively distributes processing to the edge, maintaining detection accuracy while minimizing network traffic compared to continuous centralized video transmission.},
  archive      = {J_EAAI},
  author       = {Gibson Barbosa and Djamel F.H. Sadok and Judith Kelner and Luis Ribeiro},
  doi          = {10.1016/j.engappai.2025.110495},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110495},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multiagent architecture for industrial internet of things safety applications},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A systematic review of end-to-end framework for contactless
fingerprint recognition: Techniques, challenges, and future directions.
<em>EAAI</em>, <em>150</em>, 110493. (<a
href="https://doi.org/10.1016/j.engappai.2025.110493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contactless fingerprint biometrics have seen rapid advancements in the recent years due to its intrinsic advantages such as resilience against latent fingerprints, and enhanced hygiene due to the absence of physical contact between a finger and the sensor. These advantages boosted the development of novel techniques for contactless fingerprint recognition. An exponentially increasing number of publications related to these developments are becoming part of the literature. However, no systematic review that consolidates these developments has been presented to date, thereby leaving a significant void. Hence, there is a need to fill this void by presenting a comprehensive review of contactless fingerprint biometric technology. A review of this kind will be highly beneficial for individuals keen on pursuing research in this domain. This study presents a systematic review of the methods used in an end-to-end framework for contactless fingerprint recognition, including acquisition, segmentation, enhancement, feature extraction, and matching, using both traditional and deep learning techniques. As per the review protocol and inclusion-exclusion criteria, 112 papers have been finally included in this review. The primary focus of the review is to present the underlying methods, their reported performance outcomes, and their strengths and weaknesses. The review evaluates the recent research findings, highlights the research issues that have been effectively addressed, presents the biases in the studies, identifies ongoing challenges that remain in the field, and provides the future research directions.},
  archive      = {J_EAAI},
  author       = {Pooja Kaplesh and Aastha Gupta and Divya Bansal and Sanjeev Sofat and Ajay Mittal},
  doi          = {10.1016/j.engappai.2025.110493},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110493},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A systematic review of end-to-end framework for contactless fingerprint recognition: Techniques, challenges, and future directions},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Thoughtful and cautious reasoning: A fine-tuned knowledge
graph-based multi-hop question answering framework. <em>EAAI</em>,
<em>150</em>, 110479. (<a
href="https://doi.org/10.1016/j.engappai.2025.110479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of Knowledge Graph Question Answering (KGQA) is to find the answer entity by utilizing the Knowledge Graph (KG). Despite remarkable successes in recent years, the existing multi-hop KGQA research still faces numerous challenges. First, a multi-hop question often contains multiple entities and their relationships, and the semantic information is complex. The current methods extract the semantics of the question through an encoder that cannot completely extract the complex and rich semantic information in the multi-hop questions. Second, current question answering models use the coarse information filtering mechanism in the process of reasoning, which lead to the loss of effective information and introduce additional noise. To address these issues, we propose a Thoughtful and Cautious Reasoning framework for Knowledge Graph Question Answering (TCR-KGQA). We design a new question encoder that can extract and fully fuse the local semantic information of the question at different levels, focusing on the unique local features of the multi-hop question text. Based on the advantages of Gated Recurrent Unit (GRU) for information filtering, we propose a loop instruction update framework based on residual-GRU to effectively capture key information in the reasoning process. Extensive experiments on three broad benchmark datasets demonstrate the effectiveness of our model on KGQA tasks, and it also yields excellent results in the case of incomplete knowledge graphs with missing question–answer pairs.},
  archive      = {J_EAAI},
  author       = {Yinghao Zheng and Ling Lu and Yang Hu and Yinong Chen and Aijuan Wang},
  doi          = {10.1016/j.engappai.2025.110479},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110479},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Thoughtful and cautious reasoning: A fine-tuned knowledge graph-based multi-hop question answering framework},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A surrogate-assist quasi-affine transformation evolutionary
for multi-objective optimization of empty train deployment on heavy-haul
railways. <em>EAAI</em>, <em>150</em>, 110475. (<a
href="https://doi.org/10.1016/j.engappai.2025.110475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surrogate-assisted evolutionary algorithms have become increasingly popular for solving expensive and time-consuming single-objective and multi-objective problems. However, in multi-objective optimization, the Pareto non-dominated solution set space can quickly become computationally intractable, making it challenging to select which samples to evaluate using the expensive fitness function. In this paper, we propose a Surrogate-Assist Quasi-Affine Transformation Evolutionary algorithm (SA-QUATRE/MO) for solving multi-objective optimization problems. The SA-QUATRE/MO algorithm uses a radial basis function network as a surrogate model to improve the speed of the algorithm operation by replacing the expensive fitness evaluation with the surrogate model. To ensure the excellence and diversity of the selected samples while keeping the archived sample space fixed, we propose a technique called Vector Space Sampling, which samples objective points in the current set of non-dominated solutions by dividing several sub-vector spaces. Additionally, we propose an uncertain sample infilling strategy to select samples for real fitness evaluation using a designed uncertainty function. We compare the SA-QUATRE/MO algorithm with three state-of-the-art algorithms for multi-objective problems in three test function suites. Finally, we applied the SA-QUATRE/MO algorithm to optimize empty train deployment in a heavy-haul railway at the loading end and build a model based on the S12 section of a specific railway. The final experimental results demonstrate the practicality and effectiveness of our proposed method.},
  archive      = {J_EAAI},
  author       = {Zhi-Gang Du and Jeng-Shyang Pan and He-Ying Xu and Shu-Chuan Chu and Shao-Quan Ni},
  doi          = {10.1016/j.engappai.2025.110475},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110475},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A surrogate-assist quasi-affine transformation evolutionary for multi-objective optimization of empty train deployment on heavy-haul railways},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Navigating beyond the training set: A deep learning
framework for inverse design of architected composite materials.
<em>EAAI</em>, <em>150</em>, 110473. (<a
href="https://doi.org/10.1016/j.engappai.2025.110473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a deep learning (DL)-based inverse design framework for two-phase composite materials. The artificial intelligence (AI) contribution lies in the integration of Deep Convolutional Generative Adversarial Networks (DCGAN) and Convolutional Neural Networks (CNN) into a framework that enhances material discovery and design, particularly for out-of-distribution (OOD) targets. The major contribution is the development of a strategy that balances latent space exploration and optimization, achieving low design errors – below 10% – for targeted properties located in near- and extreme-OOD regions of the material property space (MPS). The engineering application focuses on designing composites with tailored linear elastic properties, accelerating inverse design and reducing reliance on traditional simulation-based approaches. An image dataset of 12,000 Representative Unit Cells (RUCs) was assembled using a parametric Voronoi diagram generator, with elastic responses computed through finite element (FE) simulations. The DCGAN generated synthetic samples with novel features not present in the original dataset, demonstrating interpolation and extrapolation capabilities. A single round of Active Learning (AL) and Transfer Learning (TL) enhanced the CNN’s predictive accuracy on synthetic data. The framework offers significant computational efficiency, with optimization complexity O ( m ⋅ n 2 ) , where m is the number of iterations and n the latent vector dimensionality. This complexity is considerably lower than that of direct FE-based topology optimization, which ranges from O ( m ⋅ N 4 ) to O ( m ⋅ N 6 ) , where N × N represents the RUC grid size. These findings demonstrate the scalability and adaptability of the framework for advanced material design and engineering applications.},
  archive      = {J_EAAI},
  author       = {José Pablo Quesada-Molina and Hossein Mofatteh and Abdolhamid Akbarzadeh and Stefano Mariani},
  doi          = {10.1016/j.engappai.2025.110473},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110473},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Navigating beyond the training set: A deep learning framework for inverse design of architected composite materials},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Thermal buckling of graphene platelets reinforced
microplates with piezoelectric layers using artificial neural network.
<em>EAAI</em>, <em>150</em>, 110469. (<a
href="https://doi.org/10.1016/j.engappai.2025.110469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Functionally graded microplates are extensively employed in advanced engineering applications, including aerospace, micro-electromechanical systems, and smart structures, due to their exceptional mechanical performance, thermal resistance, and adaptability to multifunctional environments. This study examines the thermal buckling behavior of functionally graded graphene platelet-reinforced composite microplates integrated with piezoelectric layers under externally applied voltage. The modified couple stress theory is utilized to account for micro-scale effects, and the material properties of the composite layers are determined using the Halpin-Tsai micromechanical model. The governing equations based on first shear deformation theory are solved using the Ritz method to generate training data for an artificial neural network (ANN). To address computational challenges inherent in conventional methods, an ANN-based framework, leveraging the Levenberg-Marquardt algorithm, is developed to predict the critical buckling temperature with high precision and significantly reduced computational effort. The nanofiller dimensions, weight fraction, and piezoelectric layer thickness serve as inputs, while the thermal buckling load is the output. The obtained results show that the ANN offers a significant reduction in computational time, achieving speed improvements of over 85% across all cases. Also, the ANN reliably predicts the critical buckling temperatures, achieving a maximum discrepancy of only 0.26% when compared with the Ritz method. The novelty of this work lies in combining modified couple stress theory with ANN-assisted prediction models for efficient thermal buckling analysis. This methodology offers a practical solution for the rapid and reliable design of graphene platelet-reinforced composite microplates integrated with piezoelectric layers in applications demanding high precision and performance under thermal loading.},
  archive      = {J_EAAI},
  author       = {Hongxia Liu and Qiyu Wang and Zilin Zhang},
  doi          = {10.1016/j.engappai.2025.110469},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110469},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Thermal buckling of graphene platelets reinforced microplates with piezoelectric layers using artificial neural network},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization strategy for batch-stochastic configuration
network models and their application in component content prediction.
<em>EAAI</em>, <em>150</em>, 110461. (<a
href="https://doi.org/10.1016/j.engappai.2025.110461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the challenges of inefficiency and uncertain quality in incrementally adding hidden layer nodes to a stochastic configuration network (SCN). An optimized approach for batch-wise stochastic configuration network (BSCN) using an enhanced differential evolution (DE)algorithm is introduced. Initially, the inequality constraints of SCN is studied to analyze and establish the correlation between objective parameters and network residuals. Subsequently, to speed the network’s training velocity, a BSCN is utilized for developing the regression model. Combining the DE algorithm with regional contraction and greedy selection strategies. Specifically it leverages the robust global search prowess of the standard DE while mitigating its limitations in local search and ensuring global convergence. The formulation of this enhanced DE, termed regional contraction and greedy selection differential evolution (SGDE), is elaborated in detail, and an analysis and validation of its global convergence are conducted. Comparative experiments with the conventional DE underscore the superior optimization efficacy of SGDE. The applicability of SGDE enhanced BSCN (SGDE-BSCN) is corroborated through six real-world regression tasks. These tasks demonstrate that SGDE-BSCN not only excels in configuring hidden layer nodes but also exhibits enhanced error minimization and superior generalization capabilities with an equivalent number of hidden layer nodes. Additionally, a practical case study focused on predicting component content in rare earth extraction processes validates the effectiveness of the proposed method. The empirical results show that the application of SGDE-BSCN to artificial intelligence (AI) and artificial intelligence in the field of rare earth extraction shows high prediction accuracy and fast processing speed.},
  archive      = {J_EAAI},
  author       = {RongXiu Lu and XingRong Hu and Cong Pei and Hui Yang and WenHao Dai and JianYong Zhu},
  doi          = {10.1016/j.engappai.2025.110461},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110461},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimization strategy for batch-stochastic configuration network models and their application in component content prediction},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Continual learning for behavior-based driver identification.
<em>EAAI</em>, <em>150</em>, 110459. (<a
href="https://doi.org/10.1016/j.engappai.2025.110459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Behavior-based Driver Identification is an emerging technology that recognizes drivers based on their unique driving behaviors, offering important applications such as vehicle theft prevention and personalized driving experiences. However, most studies fail to account for the real-world challenges of deploying Deep Learning models within vehicles. These challenges include operating under limited computational resources, adapting to new drivers, and changes in driving behavior over time. The objective of this study is to evaluate if Continual Learning (CL) is well-suited to address these challenges, as it enables models to retain previously learned knowledge while continually adapting with minimal computational overhead and resource requirements. We tested several CL techniques across three scenarios of increasing complexity based on a well-known dataset for the Driver Identification problem. This work provides an important step forward in scalable driver identification solutions, demonstrating that CL approaches, such as Dark Experience Replay (DER), can obtain strong performance with only an 11% reduction in accuracy compared to the static scenario. Furthermore, to enhance the performance, we propose two new methods, Smooth Experience Replay (SmooER) and Smooth Dark Experience Replay (SmooDER), that leverage the temporal continuity of driver identity over time to enhance classification accuracy. Our novel method, SmooDER, achieves optimal results with only a 2% accuracy reduction compared to the 11% of the DER approach. In conclusion, this study proves the feasibility of CL approaches to address the challenges of Driver Identification in dynamic environments, making them suitable for deployment on cloud infrastructure or directly within vehicles.},
  archive      = {J_EAAI},
  author       = {Mattia Fanan and Davide Dalle Pezze and Emad Efatinasab and Ruggero Carli and Mirco Rampazzo and Gian Antonio Susto},
  doi          = {10.1016/j.engappai.2025.110459},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110459},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Continual learning for behavior-based driver identification},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised contrastive representation learning for
classifying internet of things malware. <em>EAAI</em>, <em>150</em>,
110299. (<a
href="https://doi.org/10.1016/j.engappai.2025.110299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid increase in malware prevalence poses a substantial security threat to Internet of Things (IoT) devices. Classifying IoT malware has emerged as a crucial area, essential for identifying attack patterns and developing effective defense strategies. Many methods for classifying malware utilize supervised learning. However, supervised learning in malware classification requires a considerable amount of labeled samples, which poses challenges and costs in acquiring and labeling malware samples. Furthermore, Some malware classification models struggle to fully extract features. This article proposes a self-supervised contrastive learning framework. Initially, the malware is converted to greyscale. The encoder is then pre-trained by self-supervised contrastive learning. The encoder with the new structure is able to extract features more comprehensively, while the projection header with attention is enabled to project features into the low-dimensional space more efficiently. Finally, the pre-trained encoder and classifier are fine-tuned to form a classification model using labeled samples. Experiments have shown that the proposed method has better accuracy regardless of the number of labeled samples. Experiments conducted using the publicly benchmarked datasets, Malware Image (Malimg) and the Microsoft Malware Classification Challenge (BIG2015), demonstrate that our framework outperforms state-of-the-art deep learning models and traditional methods in terms of accuracy, with achieved rates of 99.46% and 99.22%, respectively. Using only 5% of the labels from BIG2015, the proposed framework produces an impressive accuracy of 94.76%. Furthermore, it also outperforms baseline methods in identifying evolving malware, as indicated by its accuracy of 79% in a benchmarked dataset for trustworthy malware family classification (BenchMFC-G1P1P2).},
  archive      = {J_EAAI},
  author       = {Fangwei Wang and Yinhe Chen and Hongfeng Gao and Qingru Li and Changguang Wang},
  doi          = {10.1016/j.engappai.2025.110299},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110299},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-supervised contrastive representation learning for classifying internet of things malware},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid rough aggregation approach for the selection of
artificial intelligence-based industrial cleaning robots used in public
spaces from the perspective of urban waste management. <em>EAAI</em>,
<em>150</em>, 109566. (<a
href="https://doi.org/10.1016/j.engappai.2024.109566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Waste management is becoming increasingly complex and challenging, especially in megacities with large populations. Unlike the past, when urban waste was simply collected and disposed of, modern waste management requires careful planning and execution of collection, separation, recycling, and reuse processes. Effective management of this complex system now needs more than just human effort. Integrating artificial intelligence (AI)-based systems into waste management can enhance waste reduction, reuse, and recycling effectiveness and efficiency. Selecting suitable AI-based cleaning robots (AI-ICR) for crowded public spaces, such as stations, train stations, and airports, poses complex decision-making challenges. The primary challenge is the novelty of the technology, which leads to uncertainties in selecting AI-ICRs. To address this challenge, we have developed a decision-making approach based on rough Archimedean-Dombi partitioned aggregation. This approach, termed “rough Archimedean-Dombi partitioned aggregation,” combines the flexibility of Archimedean operators, the smoothness of Dombi operators, and the structured decomposition of Partitioned operators. This model is mainly chosen for its ability to handle the uncertainty and complexity inherent in multiple criteria decision-making (MCDM) processes. Leveraging rough numbers provides a robust framework for evaluating AI-ICRs under uncertain conditions. The main advantage of this model is its robustness, consistency, stability, and ability to handle complex uncertainties. We applied the proposed model to assess four AI-ICR alternatives identified through extensive research. We evaluated these alternatives using eighteen criteria established through comprehensive field studies. Based on the results, “Recycling cost (B12)” emerged as the most crucial criterion for selecting AI-ICRs. Additionally, the research identifies the SD45 manufactured by Peppermint Robotics Co. as the optimal AI-ICR candidate. Finally, the sensitivity and benchmark analyses to validate the proposed model confirm its robustness, consistency, and reliability.},
  archive      = {J_EAAI},
  author       = {Ömer Faruk Görçün and Abhijit Saha and Pydimarri Venkata Ravi Kumar and Bijoy Krishna Debnath},
  doi          = {10.1016/j.engappai.2024.109566},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {109566},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid rough aggregation approach for the selection of artificial intelligence-based industrial cleaning robots used in public spaces from the perspective of urban waste management},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A study on sustainable system for managing municipal solid
waste through a multi-criteria group decision-making technique.
<em>EAAI</em>, <em>150</em>, 109393. (<a
href="https://doi.org/10.1016/j.engappai.2024.109393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Municipal solid waste management, a unique aspect of sustainable development, is a crucial social-ecological system that intersects with the economy, society, and environment. The introduction of volume-based waste fees in some developed countries has been a step towards promoting recycling and waste reduction. However, the sustainability of high recycling targets and the impact of public satisfaction on waste management efficiency are areas that demand further exploration. A review of the literature on municipal solid waste management and technology selection from various countries reveals that many studies need more precise justification and a resolution to the ambiguity in decision-making. Meanwhile, some researchers have developed the fuzzy multi-criteria decision-making technique in the context of waste management. However, significant performance criteria for ’5R’s (refuse, reduce, reuse, repurpose, recycle)’ waste management technology selection and cause-and-effect group criteria still need to be identified. This study strongly emphasizes the potential of the ’5R’s’ waste management system to revolutionize waste management practices. The ’5R’s’ waste management system uses a multi-criteria group decision-making technique using fuzzy-based artificial intelligence methods, employing the novel fuzzy technique for order of preference by similarity to the ideal solution. This study also proposes a new way to rank generalized interval type-2 trapezoidal fuzzy numbers and defuzzifies them to address the uncertainties that arise when using fuzzy linguistic terms to make decisions. Finally, a numerical example of the ’5R’s’ waste management problem is discussed with new ranking methods and compared with existing methods, underscoring the significant potential of the ’5R’s’ waste management system.},
  archive      = {J_EAAI},
  author       = {Marimuthu Dharmalingam and Daekook Kang},
  doi          = {10.1016/j.engappai.2024.109393},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {109393},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A study on sustainable system for managing municipal solid waste through a multi-criteria group decision-making technique},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A graph convolutional network and gated recurrent unit-based
surrogate for agent-based diffusion models. <em>EAAI</em>, <em>149</em>,
110610. (<a
href="https://doi.org/10.1016/j.engappai.2025.110610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the challenge of high computational costs in agent-based diffusion models (ABMs), which are widely used for simulating complex diffusion processes but become prohibitively expensive in large-scale applications. To mitigate this issue, we introduce a Graph Convolutional Network (GCN) and Gated Recurrent Unit (GRU)-based Surrogate Network (G2SN) for ABMs. The GCN module captures the social network structure and seed set, while the GRU module models the diffusion time series. Computational complexity analysis demonstrates that G2SN significantly outperforms ABM simulations in efficiency. Experimental results confirm that G2SN accurately predicts ABM dynamics, reducing the mean absolute deviation (MAD) by 71.7 % on training sets and 77.7 % on test sets compared to traditional machine learning surrogate models. Case studies on new product diffusion further illustrate the effectiveness of the G2SN-based calibration approach, improving parameter search efficiency by 50.8 % and 37.2 % over alternative surrogate model-based methods. Additionally, these studies underscore the critical importance of social network and seed set in enhancing ABM prediction accuracy. This approach provides a more efficient and scalable tool for ABM calibration and new product diffusion forecasting, aiding managers in production, inventory, and marketing decisions.},
  archive      = {J_EAAI},
  author       = {Yu Xiao and Yuanyuan Zhou and Ziyi Wang},
  doi          = {10.1016/j.engappai.2025.110610},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110610},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A graph convolutional network and gated recurrent unit-based surrogate for agent-based diffusion models},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertainty-aware focal loss for object segmentation.
<em>EAAI</em>, <em>149</em>, 110599. (<a
href="https://doi.org/10.1016/j.engappai.2025.110599">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the loss function of object segmentation models, misclassified pixels whose prediction are opposite to the ground truth and uncertain pixels whose predicted probability is close to 0.5 are more important for model training. Focusing on misclassified pixels can improve the segmentation accuracy of the model, and focusing on uncertain pixels can help the model to form better decision surfaces. However, existing methods fail to take both types of pixels into account simultaneously. To enhance the learning on these two types of important pixels, the Uncertainty-aware Focal Loss (UFL) is proposed based on the analysis of Uncertainty-aware Loss (UAL). Then, by leveraging the S-shaped property of the sigmoid function, a loss function is constructed that can simultaneously increase the loss and loss derivatives of misclassified and uncertain pixels. In order to solve the gradient vanishing problem of the sigmoid function on well-classified pixels, a regularization constraint term is defined, whose value is the square of predicted probability. Finally, the pixel loss value is dynamically adjusted at different stages of training according to the changes in the contributions of misclassified and uncertain pixels to the model training, which improves the targeted learning for misclassified and uncertain pixels. Experimental results on two different types of network structures and six datasets demonstrate that the proposed method can better segment the uncertain and misclassified pixels. Especially, on the DUT-O dataset, UFL improves mean Intersection over Union (mIoU ) by almost 2.7 % compared to UAL.},
  archive      = {J_EAAI},
  author       = {Lei Chen and Yang Wang and Jibin Yang and Yunfei Zheng and Tong Han and Bo Zhang and Tieyong Cao},
  doi          = {10.1016/j.engappai.2025.110599},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110599},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Uncertainty-aware focal loss for object segmentation},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised combustion state diagnosis using a
noise-augmented generative adversarial network and flame image
sequences. <em>EAAI</em>, <em>149</em>, 110574. (<a
href="https://doi.org/10.1016/j.engappai.2025.110574">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliable diagnosis of combustion states, particularly distinguishing between stable and unstable flame conditions, is crucial for maintaining power generation efficiency and stability. However, accurate detection of unseen unstable combustion states remains challenging due to the complex dynamics of flames and the limited availability of unstable flame data. To address this challenge, this study proposes a self-supervised combustion state diagnosing method based on a noise-augmented generative adversarial network (NAGAN) and flame image sequences. The proposed method employs a convolutional autoencoder (CAE) and principal component analysis (PCA) to extract abstract flame features from image sequences. A novel multi-generator NAGAN architecture, comprising a long short-term memory (LSTM)-based generator and two Gaussian noise-augmented generators, is designed to synthesize diverse unstable flame feature sequences with temporal dynamics and identify the combustion state. A Gaussian abnormal flame feature generator (GAFG) leveraging Gaussian noise and binary masking is introduced to simulate a wide range of anomalies, enabling the discriminator to learn diverse representations of unstable combustion states. Experimental results on methane-air flames show that the proposed NAGAN achieves an accuracy of 0.978 and an F1 score of 0.986 on the flame stability diagnosis, with a recall rate of 0.975 for unseen unstable flames, outperforming most existing unsupervised machine learning and deep-learning based diagnostic methods. These results demonstrate the potential of the proposed method to improve combustion state monitoring, enhancing the reliability and efficiency of power generation systems.},
  archive      = {J_EAAI},
  author       = {Xiaojing Bai and Liwen Fei and Weiqi Liu and Hua Wu and Yong Yan and Weicheng Xu},
  doi          = {10.1016/j.engappai.2025.110574},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110574},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-supervised combustion state diagnosis using a noise-augmented generative adversarial network and flame image sequences},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An extended multi-criteria group decision-making method
based on preference ranking under z-number environments. <em>EAAI</em>,
<em>149</em>, 110573. (<a
href="https://doi.org/10.1016/j.engappai.2025.110573">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared with traditional fuzzy numbers, using Z-numbers to illustrate fuzzy events offers two key advantages. It makes fuzzy events more intuitive for decision-makers, and the second component of Z-numbers acts as a measure of the reliability of the first component. While significant progress has been made on Z-numbers, from the theoretical and practical perspectives, some gaps remain. For example, scholars have seldom focused on the likelihood of Z-numbers, most existing decision-making methods with Z-numbers rarely consider the consensus-reaching processes, and little has been reported on the superior ordering methods in the Z-number environment. To overcome these limitations, first, the likelihood of Z-numbers is defined in combination with the preference ranking organization method for enrichment evaluations (PROMETHEE) type V preference function. Second, the ordering rules for PROMETHEE are discussed. Then, a procedure of the feedback-adjustment method is introduced to help the consensus level of group-alternative ranking reach the threshold. On these bases, an extended PROMETHEE multi-criteria group decision-making method with Z-numbers is proposed. Finally, to verify the feasibility and effectiveness of the proposed method, we examined an intelligent medical-diagnostic-system selection problem and conducted a comparison analysis. We applied the Z-number PROMETHEE approach to a challenging case study requiring a dual-data-driven application. Furthermore, the study suggests future directions for improving the proposed framework in other related contexts.},
  archive      = {J_EAAI},
  author       = {Jian Li and Yuanyuan Xiang and Honggang Peng and Jianqiang Wang},
  doi          = {10.1016/j.engappai.2025.110573},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110573},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An extended multi-criteria group decision-making method based on preference ranking under Z-number environments},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigating the effectiveness of hybrid gradient boosting
models and optimization algorithms for concrete strength prediction.
<em>EAAI</em>, <em>149</em>, 110568. (<a
href="https://doi.org/10.1016/j.engappai.2025.110568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to evaluate and predict the compressive strength of concrete using 8 different machine learning (ML) models, including Extreme Gradient Boosting (XGBoost), Light Gradient Boosting machine (LightGBM), Gradient Boosting with Categorical features support (CatBoost), Gradient Boosting Regressor (GBR), Adaptive Boosting (AdaBoost), Decision Tree (DT), Random Forest (RF), and Support Vector Machine Regression (SVR). The study employed Bayesian optimisation process with two surrogate models (Gaussian Processes and Random Forest) and Random Search optimisation process to optimise the hyperparameters of these ML models. 1030 data samples were used to train the models and analyse the feature importance of each input variable using SHapley Additive exPlanations (SHAP). The results indicated that all 8 hybrid ML models performed well with R2 values larger than 0.80 and four models (XGBoost, CatBoost, GBR, and LightGBM) being the standout models, achieving R2 values of 0.94, 0.94, 0.92, and 0.92 on testing dataset, respectively. The four leading models (XGBoost, CatBoost, GBR, LightGBM) were applied to six sub-databases of concrete types, significantly enhancing accuracy with all models achieving R2 values over 0.98 on the testing dataset. The study also found that curing age, cement content, and amount of water were the most important variables affecting compressive strength while fly ash was the least important. By deploying the three best models to the cloud, it is now possible to make predictions using any web browser on any device.},
  archive      = {J_EAAI},
  author       = {Khuong Le Nguyen and Mahmoud Shakouri and Lanh Si Ho},
  doi          = {10.1016/j.engappai.2025.110568},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110568},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Investigating the effectiveness of hybrid gradient boosting models and optimization algorithms for concrete strength prediction},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An agent-based emotional persuasion model driven by
integrated trust assessment. <em>EAAI</em>, <em>149</em>, 110567. (<a
href="https://doi.org/10.1016/j.engappai.2025.110567">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research on automated negotiation has primarily focused on improving the artificial intelligence of agents and equipping them with more flexible internal mechanisms to facilitate high-quality negotiations. However, the study on the systematic modeling of human-like psychological and behavioral activities and their role in the negotiation process is still in its early stages. In light of this, this paper proposes an emotional persuasion model that takes into account the effect of negotiators&#39; integrated trust assessments on negotiation. Firstly, the paper presents a negotiation agent with both cognitive and emotional functions, detailing its internal system and operating mechanism. Secondly, the integrated trust of a negotiator is obtained by evaluating multiple single trusts, and the mapping of the integrated trust to the negotiation round parameter is modeled. Integrated trust is also parameterized into the agent&#39;s cognitive processes. Finally, the paper introduces a new framework for the generation of emotional persuasive behavior to assist agents in making new proposals. A series of experiments were conducted, yielding the following results: Compared with the non-emotional model, the performance of negotiation rounds and utility differences improved by 7.97 % and 4.81 %, respectively. Furthermore, the trust-driven emotional persuasion model outperformed the several existing competing models by at least 31.1 % in utility difference and 81.0 % in negotiation rounds. Additionally, a case study of human-computer negotiation demonstrated that the agent designed using the proposed method has negotiating capabilities comparable to those of a real human, which further showcases the application effect of the artificial intelligence agent in practice.},
  archive      = {J_EAAI},
  author       = {Jinghua Wu and Ya Zhang and Ruiyang Cao and Yan Li},
  doi          = {10.1016/j.engappai.2025.110567},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110567},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An agent-based emotional persuasion model driven by integrated trust assessment},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Strength prediction of recycled concrete using hybrid
artificial intelligence models with gaussian noise addition.
<em>EAAI</em>, <em>149</em>, 110566. (<a
href="https://doi.org/10.1016/j.engappai.2025.110566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research uses machine learning and computational techniques to investigate methods for the compressive strength of recycled concrete prediction. Waste management and environmental sustainability are addressed using construction and mineral waste as aggregate. Previous attempts with traditional linear and polynomial models were insufficient for capturing complex data relationships, achieving R-squared (R 2 ) values of only 0.22. Therefore, advanced models were employed, including support vector regression (SVR), one-dimensional convolutional neural networks (1D-CNN), and a multi-model hybrid approach. Combining Elastic Networks, Random Forest Algorithm, and Light Gradient Boosting Decision (LGBM), the hybrid model demonstrated exceptional performance, achieving an R 2 value of 0.9072 - a 312 % improvement over traditional methods. Gaussian noise augmentation during training enhanced the model&#39;s generalization capabilities. Experimental data validation confirmed the hybrid model&#39;s predictive accuracy. The potential of computational methods is highlighted to optimize the use of recycled materials in concrete, promoting sustainable construction practices and laying the foundation for selecting recycled materials for future practical civil engineering applications. Future research should focus on expanding datasets and exploring additional data augmentation techniques to improve model accuracy further.},
  archive      = {J_EAAI},
  author       = {Yuzheng Geng and Yongcheng Ji and Dayang Wang and Hecheng Zhang and Zhizhu Lu and Aotian Xing and Mingjie Gao and Maoyang Chen},
  doi          = {10.1016/j.engappai.2025.110566},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110566},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Strength prediction of recycled concrete using hybrid artificial intelligence models with gaussian noise addition},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast stereo conformer: Real-time stereo matching with
enhanced feature fusion for autonomous driving. <em>EAAI</em>,
<em>149</em>, 110565. (<a
href="https://doi.org/10.1016/j.engappai.2025.110565">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate stereo matching is critical for depth estimation in autonomous driving, yet remains challenging in weakly-textured regions where conventional convolutional neural networks (CNNs) lack global context and Transformers overlook local details. We propose Fast Stereo Conformer Net (FSCN), a real-time parallel network integrating CNNs and Transformers, enhanced by a Convolutional Coupling Transformer (CCT) for synergistic local-global feature fusion. To address data scarcity, we introduce random translation transformations (RTTs) during pretraining and fine-tuning. On the Karlsruhe Institute of Technology and Toyota Technological Institute at Chicago 2015 Dataset (KITTI 2015) benchmark, FSCN achieves a 3-pixel error rate of 1.79 %, representing a 7.25 % improvement over the baseline and a 5.29 % superior performance compared to state-of-the-art real-time methods, while processing frames efficiently in 57 milliseconds (ms). It also demonstrates outstanding generalization on other datasets, achieving improvements of 6.98 % on KITTI 2012, 9.72 % on Middlebury, and 9.30 % on Swiss Federal Institute of Technology in Zurich 3D Dataset (ETH3D) compared to the baseline. These results highlight the synergistic effectiveness of CNNs and Transformers in feature extraction and the significant potential of our approach for advancing stereo matching technology in autonomous driving applications.},
  archive      = {J_EAAI},
  author       = {Yunhua Lu and Xianzhong He and Qingwei Zhang and Ding Zhang},
  doi          = {10.1016/j.engappai.2025.110565},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110565},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fast stereo conformer: Real-time stereo matching with enhanced feature fusion for autonomous driving},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Speech signal-based accurate neurological disorders
detection using convolutional neural network and recurrent neural
network based deep network. <em>EAAI</em>, <em>149</em>, 110558. (<a
href="https://doi.org/10.1016/j.engappai.2025.110558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neurological diseases often manifest in subtle alterations to the human voice due to damage in the sound-related regions of the brain. Leveraging advancements in artificial intelligence (AI) technologies, computers can discern minute variations in sound imperceptible to the human ear, enabling rapid and precise diagnostic support. This paper presents a novel approach to neurological disease classification utilizing voice recordings of individuals diagnosed with various neurological conditions alongside healthy controls. By employing AI techniques, particularly a hybrid deep network framework integrating Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN), we aimed to classify one-sentence audio inputs of Multiple Sclerosis (MS) patients, healthy individuals, and other neurological diseases. In our dataset, we have compiled audio recordings from 95 healthy individuals, 99 individuals diagnosed with multiple sclerosis (MS), and 96 individuals with other neurological disorders. Of these, 20 % of the data was reserved for testing. Our proposed architecture achieved remarkable performance metrics in experimental evaluations, exhibiting 96.55 % accuracy, 98.25 % specificity, 96.49 % sensitivity, 96.97 % precision, and 96.56 % F1-Score. The results obtained are more successful compared to the methods of AlexNet from scratch, fine-tuned AlexNet, Long Short-Term Memory (LSTM) based CNN, and Gated Recurrent Unit (GRU) based CNN. The results of our study highlight the potential of this framework to be integrated into clinical diagnostic workflows, providing clinicians with an effective tool for early and precise detection of neurological diseases, ultimately improving patient outcomes through timely intervention and personalized treatment strategies.},
  archive      = {J_EAAI},
  author       = {Emel Soylu and Sema Gül and Kübra Aslan Koca and Muammer Türkoğlu and Murat Terzi and Abdulkadir Şengür},
  doi          = {10.1016/j.engappai.2025.110558},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110558},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Speech signal-based accurate neurological disorders detection using convolutional neural network and recurrent neural network based deep network},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel multimodal deep learning framework for predicting
residual strength of corroded rectangular hollow-section columns.
<em>EAAI</em>, <em>149</em>, 110554. (<a
href="https://doi.org/10.1016/j.engappai.2025.110554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Corrosion, recognized as a thermodynamically spontaneous process, is one of the key issues affecting the health of rectangular hollow steel section columns under working conditions, and has attracted much attention in recent years. Traditional approaches, such as multi-layer perceptron, often rely solely on the degree of volume loss to predict residual strength, overlooking the spatial complexity of actual corrosion patterns. To address these limitations, this study presents a novel multimodal deep learning network for accurately predicting the residual strength of corroded hollow steel section columns with random, nonuniform corrosion distributions. Our approach integrates (i) image‐based corrosion distributions on four steel walls, and (ii) tabular geometric parameters, through five distinct data-fusion methods proposed in this work, three employing Late Fusion (via a novel multi‐head attention module) and two using Early Fusion (via pixel−level merging). The image information extraction core is built upon a lightweight convolutional neural network and a channel−spatial attention block, while the tabular extraction module leverages a revised multi-layer perceptron architecture. After Bayesian hyperparameter optimization, the best‐performing model achieves a coefficient of determination of 0.971 on the test set, surpassing conventional machine learning and other multimodal fusion techniques by 0.01–0.161. Further analysis shows that the reverse visualization technique highlights corrosion−critical regions that closely coincide with the experimentally validated failure zones. Consequently, the proposed framework not only predicts residual strength with high accuracy but also localizes vulnerable areas for targeted reinforcement. This methodology holds promise for large‐scale corrosion monitoring and structural health assessment of steel infrastructure.},
  archive      = {J_EAAI},
  author       = {Yu-Jia Zhang and Lei Zhang and Yu Zhou and Tian-Xiang Li and Reece Lincoln and Jing-Zhong Tong and Jia-Jia Shen},
  doi          = {10.1016/j.engappai.2025.110554},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110554},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel multimodal deep learning framework for predicting residual strength of corroded rectangular hollow-section columns},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025b). Comprehensive evaluation of deep reinforcement learning for
permanent magnet synchronous motor current tracking and speed control
applications. <em>EAAI</em>, <em>149</em>, 110551. (<a
href="https://doi.org/10.1016/j.engappai.2025.110551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Permanent Magnet Synchronous Motors (PMSMs) are indispensable in industrial applications, requiring precise control to ensure optimal performance. Traditional model-based methods, such as Proportional-Integral (PI) control and Model Predictive Control (MPC), face inherent limitations in robustness and adaptability under complex conditions. Deep Reinforcement Learning (DRL), as a model-free, data-driven approach, offers a transformative solution for PMSM control. This study proposes a DRL-based current control strategy and systematically evaluates the performance of three representative DRL algorithms: Deep Q-Network (DQN), Proximal Policy Optimization (PPO), and Advantage Actor-Critic (A2C) in PMSM control tasks. Key contributions include hyperparameter sensitivity analysis, transfer learning for improved training efficiency, and the application of DRL to multi-objective speed control under varying operational scenarios. Experimental results reveal the hyperparameter sensitivities of different DRL algorithms and provide theoretical insights. The findings demonstrate that transfer learning significantly improves DRL training efficiency and control performance. DRL outperforms traditional controllers in current and speed control, achieving superior dynamic response, tracking accuracy, and adaptability to complex conditions. This study offers new insights into the application of DRL in industrial PMSM control and serves as a reference for its further optimization and practical deployment.},
  archive      = {J_EAAI},
  author       = {Yiming Zhang and Jingxiang Li and Hao Zhou and Chin-Boon Chng and Chee-Kong Chui and Shengdun Zhao},
  doi          = {10.1016/j.engappai.2025.110551},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110551},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Comprehensive evaluation of deep reinforcement learning for permanent magnet synchronous motor current tracking and speed control applications},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient boundary prediction method based on
multi-fidelity gaussian classification process for class-imbalance.
<em>EAAI</em>, <em>149</em>, 110549. (<a
href="https://doi.org/10.1016/j.engappai.2025.110549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Failure boundary prediction aims to explore the boundary between failure and safety limit states in a given problem. In recent years, the use of surrogate models instead of physical experiments to explore the failure boundary has become one of the promising methods to reduce costs. Among various surrogate models, multi-fidelity Gaussian process classification (MFGPC) can produce accurate predictions while reducing simulation expenses by using a small set of high-fidelity samples and a larger set of low-fidelity samples. However, the current MFGPC model primarily utilizes Markov chain Monte Carlo sampling to estimate the model hyperparameters. The modeling process involves a significant amount of calculation and slow convergence speed. Additionally, the practical application of MFGPC in the engineering field is limited, and the presence of a class imbalance in real data can lead to poor model training performance. Therefore, to improve the modeling efficiency of MFGPC, this paper proposes an improved MFGPC method for the imbalanced problem. The improved MFGPC model utilizes the Stein variational gradient descent algorithm to reduce the computational cost of the model. Additionally, it incorporates a synthetic sampling algorithm to effectively handle class-imbalance issues in real-world engineering cases. Two engineering examples are solved, including the failure boundary prediction of the zero Poisson ratio structure and the operating boundary of an axial flow compressor. It is demonstrated that the proposed method can accelerate the convergence speed of the model by tens of magnitudes while maintaining good prediction accuracy.},
  archive      = {J_EAAI},
  author       = {Jinlang Luo and Lingzhi Liu and Youwei He and Kuan Tan},
  doi          = {10.1016/j.engappai.2025.110549},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110549},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An efficient boundary prediction method based on multi-fidelity gaussian classification process for class-imbalance},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Flow field reconstruction and prediction of the
two-dimensional cylinder flow using data-driven physics-informed neural
network combined with long short-term memory. <em>EAAI</em>,
<em>149</em>, 110547. (<a
href="https://doi.org/10.1016/j.engappai.2025.110547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-informed neural network (PINN) has attracted significant attention for various fluid related problems in recent years. Although the basic principle allows the PINN to require less data to train a reliable model, data-driven PINN often suffers from the quantity and quality of the training data, without which will result in diminishing fitting capability in the edge regions and extrapolation beyond the dataset. To address this issue, a new coupled model called LSTM-PINN (LP) is proposed, which combines the advantages of Long Short-Term Memory (LSTM) in handling long-term dependencies for time-sequenced data with the existing PINN framework. By incorporating the time-sequenced predictions at different spatial points generated by the LSTM into the training set of the PINN, the edge errors that refer to errors at boundary of space or time are reduced and the time-sequenced prediction capability of flow field is enhanced. The comparative study is conducted on the velocities along two directions predicted by the coupled model with those obtained from the benchmark PINN model, while the numerical solutions in the case of 2D (two-dimensional) flow around cylinder described by the Navier-Stokes (NS) equations are selected as training dataset. The results demonstrate that the proposed LP model improves the accuracy of prediction compared to the conventional PINN model, showing great potential for flow field reconstruction and time series prediction.},
  archive      = {J_EAAI},
  author       = {Yehao Dou and Xun Han and Pengzhi Lin},
  doi          = {10.1016/j.engappai.2025.110547},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110547},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Flow field reconstruction and prediction of the two-dimensional cylinder flow using data-driven physics-informed neural network combined with long short-term memory},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A large-scale mobile application knowledge graph for the
research of cybersecurity: Construction and application. <em>EAAI</em>,
<em>149</em>, 110543. (<a
href="https://doi.org/10.1016/j.engappai.2025.110543">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale datasets for mobile applications (terms as “apps”) have been developed and become important assets for malware identification and other tasks of cybersecurity. However, existing datasets focus on extending the scale of apps, while ignoring the relevance among apps. On the other hand, several works try to integrate different metadata of apps to discover the relevance among apps, but most of them pay little attention to the roles such as normal users, developers, cybersecurity analysts, and they do not take full advantage of these metadata so that the fine-grained correlations among apps are difficult to be captured. To fill these gaps, we present a mobile application knowledge graph, which collects millions of apps’ information from various resources, including application markets, encyclopedias and news. Precisely, a lightweight ontology is designed for our knowledge graph. It defines a unified semantic schema of collected apps so that more linkages of these apps can be shared with each other. Moreover, we employ several promising algorithms of information extraction and knowledge alignment, and evaluate their performances during the process of construction. To detect more relevance with respect to sensitive apps, we propose a hybrid embedding-based method, in which the vector representations of apps are iteratively encoded with knowledge graph embedding methods and network embedding models. Experimental results show that our hybrid method can obtain better performances than several existing models for the relevance detection of sensitive apps. Finally, we list three use cases of mobile application knowledge graph for cybersecurity and discuss their limitations that would be improved in future works.},
  archive      = {J_EAAI},
  author       = {Weizhuo Li and Heng Zhou and Yiming Tan and Weiqi Luo and Qiu Ji and Yuyang Bian},
  doi          = {10.1016/j.engappai.2025.110543},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110543},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A large-scale mobile application knowledge graph for the research of cybersecurity: Construction and application},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-layer knowledge graph transformer network-based question
and answer explainable recommendation. <em>EAAI</em>, <em>149</em>,
110542. (<a
href="https://doi.org/10.1016/j.engappai.2025.110542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The question and answer (Q&amp;A) recommendation in community question answering (CQA) helps users quickly and accurately find the desired Q&amp;A. However, existing studies face the problems of sparse interaction data, cold starts, and a lack of explanations. This paper proposes a novel Q&amp;A explainable recommendation approach based on a two-layer knowledge graph transformer network. It alleviates the sparse data and cold start problem by the novel two-layer knowledge graph. First, a two-layer knowledge graph in CQA is constructed. The interaction layer helps to enrich the associations between users and questions and answers (Q&amp;As). The semantic layer provides semantic associations and reflects contextual domain knowledge. Second, a critical meta-path recognition module is constructed to learn the critical meta-paths between users and documents from the interaction layer. Then, a user and Q&amp;A embedding method based on a two-layer knowledge graph is proposed to enhance the user and Q&amp;A representations. Finally, a recommendation and explanation layer is established to obtain personalized Q&amp;A recommendation results and corresponding explanations. Compared with the baselines, the proposed method shows superior performance. It achieves average improvements of 21.28%, 28.41% and 27.18% in precision, recall and F1-measure, respectively, in the top- K Q&amp;A recommendation separately. It improves the area under the curve and F1-measure of the click-through rate prediction recommendation by 11.32% and 23.06%, respectively.},
  archive      = {J_EAAI},
  author       = {Ying Li and Ming Li and Jin Ding and Yixue Bai},
  doi          = {10.1016/j.engappai.2025.110542},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110542},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Two-layer knowledge graph transformer network-based question and answer explainable recommendation},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Metal oxide semiconductor based electronic nose data
pre-processing, review. <em>EAAI</em>, <em>149</em>, 110540. (<a
href="https://doi.org/10.1016/j.engappai.2025.110540">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metal Oxide Semiconductor (MOS) based Electronic Nose (E-nose) mimics Human Olfaction mechanisms in Odor Detection by creating a Unique Odor-Print that is processed by Pattern Recognition (PARC) algorithms. Odor Metal Oxide Semiconductor sensors do not behave as independent sensors. Each gas sensor in E-nose responds more selectively to a certain group of Volatile Organic Compounds (VOCs) but also shows a broad, overlapping response and sensitivity to the other Gas Compounds. Like in Natural Olfaction, a key role is played by Data Analysis. In this comprehensive literature review, the current state of different design stages in Metal Oxide Semiconductor (MOS)-based Electronic Nose Raw Data Pre-processing to condition input data prior to array processing and pattern recognition were thoroughly discussed. In depth technical application of various data pre-processing techniques to both static and dynamic sensor responses, emphasizing their importance in improving the sensors&#39; performance and pattern recognition accuracy were provided. A use case has been attempted, discussing data samples, feature extraction processes, and dimensionality reduction. A sample MATLAB code was provided to show cluster formations. Transient feature extraction improved classification accuracy by up to 30 %, while piecemeal signal feature extraction proved highly effective. Multivariate analysis and chemometric methods reduced data dimensionality by approximately 50–80 %, for creating Parsimonious Odor Classification Models.},
  archive      = {J_EAAI},
  author       = {Meisam Vajdi},
  doi          = {10.1016/j.engappai.2025.110540},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110540},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Metal oxide semiconductor based electronic nose data pre-processing, review},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tube-LaneNet: Predict each three-dimensional lane as a
completed structure via geometric priors. <em>EAAI</em>, <em>149</em>,
110539. (<a
href="https://doi.org/10.1016/j.engappai.2025.110539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monocular three-dimensional lane detection is a critical task for intelligent vehicles. However, most current methods, which mainly extend the two-dimensional paradigms, regard lanes as separated points set and constrain loss through the orthogonal projection on the two-dimensional plane. In this work, a novel deep learning framework is proposed to detect each lane as a continuous completed three-dimensional spatial structure. Concretely, three-dimensional lane anchors are implemented to extract proposal features through geometric priors to guarantee the continuous linear spatial structure. To enhance the feature of proposals, a relation-aware mechanism is further introduced to extract the spatial relationship between three-dimensional lanes. In particular, a novel tube-like intersection over union (TubeIOU) is proposed, which extends each three-dimensional lane to the tube-like structure as a completed unified entity in the three-dimensional space. Experiments on different datasets demonstrate the state-of-art performance of the proposed framework, especially achieves the fastest efficiency with 69 frames per second. The code will be made publicly available.},
  archive      = {J_EAAI},
  author       = {Genghua Kou and Shihao Wang and Ying Li},
  doi          = {10.1016/j.engappai.2025.110539},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110539},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Tube-LaneNet: Predict each three-dimensional lane as a completed structure via geometric priors},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Q-learning based estimation of distribution algorithm for
scheduling distributed heterogeneous flexible flow-shop with mixed
buffering limitation. <em>EAAI</em>, <em>149</em>, 110537. (<a
href="https://doi.org/10.1016/j.engappai.2025.110537">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are growing interests in the distributed shop scheduling research owing to the diversification of market demand. However, most prevailing studies disregard the synergistic influence of mixed buffering and due window on production efficiency. To reduce cost loss caused by delay in due window, this paper studies a distributed heterogeneous flexible flow-shop scheduling with mixed buffering limitation, i.e., finite buffers and no-wait requirements. The motivation of this work is to fill in void and offer practical insights for exploring how to intelligently implement, optimize and deploy a distributed production system. A mathematical model is established, aiming to minimize total weighted earliness and tardiness cost. An innovative Q-learning based estimation of distribution algorithm (QLEDA) is well-designed to address this problem. The QLEDA proposes well-tailored three-stage dynamic decoding and opposition-based learning to decode and promote the job sequence group. To balance global and local searchability of QLEDA, we introduce problem-specific Q-learning and Chebyshev chaotic mapping. To build a probability model of self-adaptation and self-selection, the job sequence group implements discrete actions by interacting with distributed environment and state space through Q-learning. Numerous experiments demonstrate that the QLEDA can generate more satisfactory results over other three well-performing rivals. The finding corroborates the applicability and effectiveness of presented QLEDA in solving the considered problem.},
  archive      = {J_EAAI},
  author       = {Hua Xuan and Qian-Qian Zheng and Lin Lv and Bing Li},
  doi          = {10.1016/j.engappai.2025.110537},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110537},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Q-learning based estimation of distribution algorithm for scheduling distributed heterogeneous flexible flow-shop with mixed buffering limitation},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). State of the art: Application of machine learning in ground
motion modeling. <em>EAAI</em>, <em>149</em>, 110534. (<a
href="https://doi.org/10.1016/j.engappai.2025.110534">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a detailed review of the application of machine learning (ML) techniques in Ground Motion Models (GMMs), which are vital tools for predicting seismic responses during earthquakes. Traditional GMMs, or Ground Motion Prediction Equations (GMPEs), rely on statistical regression methods that use predefined functional forms to estimate ground motion intensity measures (IMs), such as peak ground acceleration (PGA) and pseudo-spectral acceleration (PSA). While effective, these models often struggle with limitations, including handling nonlinear relationships and managing large datasets as earthquake catalogs grow. In response to these challenges, researchers have turned to ML methods, which offer the flexibility to model complex patterns without requiring predefined forms. This article explores various ML techniques, such as artificial neural networks (ANNs), support vector regression (SVR), random forest (RF), and gradient boosting (GB), and their application in GMMs. The paper also discusses the advantages of ML, such as improved accuracy and the ability to process extensive data, alongside challenges like interpretability issues and the risk of overfitting. Several case studies are provided to illustrate the practical benefits of ML in enhancing GMMs, particularly in reducing residuals and variability, ultimately contributing to more accurate seismic hazard assessments.},
  archive      = {J_EAAI},
  author       = {Najme Alidadi and Shahram Pezeshk},
  doi          = {10.1016/j.engappai.2025.110534},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110534},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {State of the art: Application of machine learning in ground motion modeling},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing accuracy of one-dimensional characteristic
predictions for axial compressors using deep learning. <em>EAAI</em>,
<em>149</em>, 110533. (<a
href="https://doi.org/10.1016/j.engappai.2025.110533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To enhance the accuracy of one-dimensional (1D) characteristic predictions for multistage axial flow compressors and improve design efficiency, this paper presents a deviation angle prediction model based on deep learning, utilizing data generated from Computational Fluid Dynamics (CFD) simulations. This model was integrated into a compressor characteristic calculation program. A CFD simulation dataset was created with National Advisory Committee for Aeronautics 65-series (NACA65) blade profiles, parameterized through a Latin hypercube design. After solving blade cascade flow fields, deviation angles under various conditions were obtained, establishing a mapping between design variables and deviation angles using deep learning. Test results showed a correlation coefficient of 0.9978 and a mean absolute error of 0.0785°. The surrogate model was embedded into the axial flow compressor 1D calculation program (HARIKA), replacing the original deviation angle model. Performance calculations on transonic two-stage and high-subsonic eight-stage compressors at different speeds demonstrated that the updated HARIKA program provided predictions closer to experimental values at high speeds, though slightly overestimated at lower speeds. These results confirm the model’s accuracy and practicality, suggesting that the improved HARIKA algorithm has potential for engineering applications in predicting the aerodynamic performance of multistage axial flow compressors.},
  archive      = {J_EAAI},
  author       = {Yulin Ma and Zhou Du and Quanyong Xu},
  doi          = {10.1016/j.engappai.2025.110533},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110533},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing accuracy of one-dimensional characteristic predictions for axial compressors using deep learning},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel adaptive gating neurons model with physical features
weighted for bearing fault diagnosis under strong noise. <em>EAAI</em>,
<em>149</em>, 110532. (<a
href="https://doi.org/10.1016/j.engappai.2025.110532">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Learning (DL) has made significant progress in the field of intelligent diagnosis. However, existing intelligent diagnosis models encounter challenges, including inadequate fault feature extraction capability, poor generalization performance, and unclear diagnostic mechanisms, especially under strong noise interference. To address these issues, we first propose a novel adaptive gating neuron with physical features weighted, which can adaptively adjust the combination of quadratic convolutions based on the physical features of the signals. On this basis, we establish a mathematical connection between the physical features-weighted adaptive gating neuron and learnable weighted autocorrelation, and theoretically demonstrate its superior feature extraction capability, which assigns higher weights to periodic features in bearing time-domain signals. Secondly, an adaptive gating neurons convolutional network (AGNCN) with physical features weighted was proposed, incorporating a residual structure. By decomposing the physical features-weighted adaptive gating neuron, we reveal an embedded attention mechanism, which enhances the intrinsic interpretability of the AGNCN model for diagnosing bearing faults in the presence of noise interference. Experiments conducted on both public datasets and our proprietary dataset demonstrate that our proposed method can efficiently and reliably diagnose bearing faults under strong noise interference.},
  archive      = {J_EAAI},
  author       = {Panpan Guo and Weiguo Huang and Ning Jia and Chuancang Ding and Yifan Huangfu and Xingxing Jiang and Juanjuan Shi},
  doi          = {10.1016/j.engappai.2025.110532},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110532},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel adaptive gating neurons model with physical features weighted for bearing fault diagnosis under strong noise},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Loss of coolant accident monitoring and pipe break diagnosis
in pressurized water reactors using bayesian-optimized long short-term
memory models. <em>EAAI</em>, <em>149</em>, 110531. (<a
href="https://doi.org/10.1016/j.engappai.2025.110531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While safety systems have been established for nuclear power plant accidents, the risk of human error remains ever present, particularly in high-pressure situations. This work utilizes the long short-term memory model (LSTM) as surrogate for monitoring loss of coolant accidents (LOCA) and diagnosing pipe breaks, aiding operators in assessing LOCAs more accurately. The models were trained using simulated accident scenarios covering the entire range of hot leg and cold leg pipe break extents. To ensure generalizability, Bayesian optimization was implemented as an automatic hyperparameter tuning method to optimize each model. In total, 15 LSTM forecasters with varying lookbacks and epochs and 20 LSTM predictors with varying trimmed sizes were developed. The forecasters showed excellent results in the water level and hot leg temperature forecasting tasks with average root mean squared error (RMSE) values of 4% and 4 °C, respectively. The overall best forecasting model was determined to have a lookback of 7 and 100 epochs, and trends relating accuracy to the epochs and lookbacks were also identified. The study also showed that LSTM predictors can provide early pipe break diagnosis accurately, using only at least 4% of the accident time series data from the onset. These predictors were able to predict the extent of pipe break with RMSE ranging from 0.57% to 1.77% and the location of pipe break with classification accuracy from 94% to 99%. Lastly, the robustness of the pipe break extent predictions were verified within expected noise levels. This study has further demonstrated the potential of artificial intelligence methods in reinforcing nuclear safety and effective accident diagnostics.},
  archive      = {J_EAAI},
  author       = {Johndel Obra and Shuichiro Miwa},
  doi          = {10.1016/j.engappai.2025.110531},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110531},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Loss of coolant accident monitoring and pipe break diagnosis in pressurized water reactors using bayesian-optimized long short-term memory models},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Skyline recency–frequency–monetary pattern mining based on
different constraint degrees. <em>EAAI</em>, <em>149</em>, 110529. (<a
href="https://doi.org/10.1016/j.engappai.2025.110529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge discovery plays a pivotal role in the field of Artificial Intelligence as it involves extracting valuable and previously unknown patterns (information, insights) from vast datasets. Skyline pattern mining emerges to deal with multiple-objective knowledge discovery in a threshold-free manner. Existing Skyline pattern mining methods mainly have two limitations: they only settle the problem with the restriction in dimension two, which is not applicable in dimension three or more; they focus on frequency and utility (monetary) without considering the temporal information. In this paper, we aim to overcome those limitations by proposing the problem model for finding skyline patterns considering three dimensions: recency, frequency, and monetary. We also define degrees of constraints to formulate strict/weak skyline patterns and present algorithms to mine them. Several pruning strategies are designed to reduce the search space. The max monetary score matrix structure and corresponding sparse storage are designed to facilitate the implementation of the pruning strategies. The skyline pattern storage matrix helps to add and delete patterns in the mining process efficiently. Experimental results show that the proposed algorithms discover more patterns without losing to the baseline. The runtime difference is usually within 10s without a clear winner. The proposed method wins tens to hundreds of megabytes of memory in most cases.},
  archive      = {J_EAAI},
  author       = {Xiaojie Zhang and Guoting Chen and Linqi Song and Wensheng Gan},
  doi          = {10.1016/j.engappai.2025.110529},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110529},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Skyline recency–frequency–monetary pattern mining based on different constraint degrees},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identification of martian minerals based on multiscale
spatial-spectral fusion network. <em>EAAI</em>, <em>149</em>, 110527.
(<a href="https://doi.org/10.1016/j.engappai.2025.110527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate identification of Martian surface minerals is crucial for analyzing the planet&#39;s geological environment and resource potential. Deep learning offers a powerful solution for automating Martian mineral identification. However, existing methods suffer from recognition inaccuracies due to the insufficient representation of the multiscale spectral and spatial features. In this article, a multiscale spatial-spectral fusion network (MSSFNet) is proposed to identify Martian minerals from hyperspectral images. In MSSFNet, the spectral multiscale feature extraction (Spe-MFE) module is proposed to extract multiscale spectral features from adjacent mineral bands in the spectral dimension. The spatial multiscale feature extraction (Spa-MFE) module extracts the spatial correlations of minerals from low-frequency and high-frequency features and retains more spatial information. At the end of the model, the spatial-spectral feature adaptive fusion (SSFAF) module utilizes attention-based feature weighting to fuse spectral and spatial features, improving its representation ability. Experimental results demonstrate that the proposed method achieved 99.51% accuracy on a constructed Martian mineral identification dataset, improving the precision of deep learning models in Martian surface mineral recognition. On the benchmark hyperspectral datasets of Indian Pines and Pavia University, MSSFNet achieved overall accuracies of 98.87% and 99.42%, respectively, outperforming state-of-the-art methods and validating its effectiveness and superiority.},
  archive      = {J_EAAI},
  author       = {Kai Wang and Xubing Zhang and Xianmin Wang and Zhouyuan Qian},
  doi          = {10.1016/j.engappai.2025.110527},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110527},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Identification of martian minerals based on multiscale spatial-spectral fusion network},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention based spatial-temporal multi-graph ordinary
differential equation network for traffic flow prediction.
<em>EAAI</em>, <em>149</em>, 110526. (<a
href="https://doi.org/10.1016/j.engappai.2025.110526">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction plays an important role in the intelligent transportation systems. Most of the current state-of-the-art traffic flow prediction models extract the spatial and temporal features of traffic flow data through graph neural network (GNN) and temporal extraction module. However, the semantic relevance of road network nodes and historical data relevance are ignored in those models. Moreover, there exists an over-smoothing problem as the number of GNN layers increases, and it is impossible to capture spatial relevance of long-range nodes through modeling. To address this challenge, we propose an attention based spatial-temporal multi-graph ordinary differential equation network (ASTMGODE). Specifically, ASTMGODE mainly consists of three independent components, to jointly model the spatial-temporal correlations and semantic correlations with various features in the traffic flow. The three spatial attributes are distance matrix, semantical matrix and historical data correlation matrix, respectively, based on the distance between road nodes, functional similarities and historical data. Each component can effectively capture the spatial-temporal correlations in the traffic data via the spatial-temporal attention mechanism. Subsequently, spatial-temporal features are characterized by temporal and spatial extraction modules, in which the temporal extraction module is composed of temporal attention mechanism and temporal convolution (TCN), while the spatial extraction module comprises tensor-based ordinary differential equation (ODE) and graph convolution network (GCN). During experiments on six real-world traffic datasets, the ASTMGODE model reduced root mean square error (RMSE) by approximately 7.65% compared to the state-of-the-art known models.},
  archive      = {J_EAAI},
  author       = {Ying-Ting Chen and Cheng Li and Shuang Li},
  doi          = {10.1016/j.engappai.2025.110526},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110526},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Attention based spatial-temporal multi-graph ordinary differential equation network for traffic flow prediction},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Django-based framework database for leakage detection using
machine learning for water distribution networks. <em>EAAI</em>,
<em>149</em>, 110525. (<a
href="https://doi.org/10.1016/j.engappai.2025.110525">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leakage in water supply pipe networks is a critical issue, with traditional detection methods being inefficient and error-prone. Acoustic-based leak detection often lacks standardized databases, limiting its effectiveness. This study proposes an integrated system using MySQL, Python, and Django for managing and analyzing acoustic leakage data. The system incorporates Variable Modal Decomposition (VMD), Wavelet Threshold Noise Reduction, Feature Extraction, and Support Vector Machine (SVM) for accurate leak detection. Experimentation on 413 labeled acoustic samples achieved classification accuracies of 96.1% (training set) and 97.4% (test set). This approach enhances detection precision and offers a scalable solution for real-time monitoring, with significant practical implications for improving water distribution system management and decision-making.},
  archive      = {J_EAAI},
  author       = {Yiwei Xie and Mengze Gao and Fan Luo and Ao Zhou and Yunfeng Yang and Jian Hu and Wei Jiang and Yuanyao Ye},
  doi          = {10.1016/j.engappai.2025.110525},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110525},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Django-based framework database for leakage detection using machine learning for water distribution networks},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maneuvering target interception via deep reinforcement
learning guidance using only line-of-sight rate measurement.
<em>EAAI</em>, <em>149</em>, 110523. (<a
href="https://doi.org/10.1016/j.engappai.2025.110523">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intercepting a maneuvering target based solely on line-of-sight (LOS) rate measurement constitutes a classic partially observable Markov decision process (POMDP), posing significant challenges in formulating the interceptor&#39;s guidance law. To improve the interception probability, reduce energy consumption, and enhance the robustness of the guidance law for intercepting maneuvering targets, a deep reinforcement learning (DRL) compensated guidance law based on the gated recurrent unit (GRU) neural network is proposed. Firstly, based on the collision triangle, a three-dimensional uncertain confrontation model of maneuvering target and interceptor is established, and then the compensation of proportional guidance law is designed as the DRL action, which effectively improves the learning efficiency of the agent. Finally, a POMDP model for interception is established, and a process reward model with energy consumption and a soft terminal reward model with a “transition section&quot; is proposed. GRU is used to fully mine the characteristics of the LOS rate time series, and a high-performance interception policy is explored based on the proximal policy optimization algorithm. Monte Carlo simulation results reveal that the novel guidance law achieves an average miss distance value of 0.091 m (m) and energy consumption of 192.26 m per second ( m ⋅ s − 1 ), outperforming traditional guidance laws with improved interception probability and lower energy consumption.},
  archive      = {J_EAAI},
  author       = {Leliang Ren and Yong Xian and Zhenyu Liu and Shaopeng Li and Daqiao Zhang and Weilin Guo},
  doi          = {10.1016/j.engappai.2025.110523},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110523},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Maneuvering target interception via deep reinforcement learning guidance using only line-of-sight rate measurement},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). What is behind the curtain? Increasing transparency in
reinforcement learning with human preferences and explanations.
<em>EAAI</em>, <em>149</em>, 110520. (<a
href="https://doi.org/10.1016/j.engappai.2025.110520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we investigate whether the transparency of a robot’s behaviour is improved when human preferences on the actions the robot performs are taken into account during the learning process. For this purpose, a shielding mechanism called Preference Shielding is proposed and included in a reinforcement learning algorithm to account for human preferences. We also use the shielding to decide when to provide explanations of the robot’s actions. We carried out a within-subjects study involving 26 participants to evaluate the robot’s transparency. Results indicate that considering human preferences during learning improves legibility compared with providing only explanations. In addition, combining human preferences and explanations further amplifies transparency. Results also confirm that increased transparency leads to an increase in people’s perception of the robot’s safety, comfort, and reliability. These findings show the importance of transparency during learning and suggest a paradigm for robotic applications when a robot has to learn a task in the presence of or in collaboration with a human.},
  archive      = {J_EAAI},
  author       = {Georgios Angelopoulos and Luigi Mangiacapra and Alessandra Rossi and Claudia Di Napoli and Silvia Rossi},
  doi          = {10.1016/j.engappai.2025.110520},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110520},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {What is behind the curtain? increasing transparency in reinforcement learning with human preferences and explanations},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing histopathological image analysis: An explainable
vision transformer approach with comprehensive interpretation methods
and evaluation of explanation quality. <em>EAAI</em>, <em>149</em>,
110519. (<a
href="https://doi.org/10.1016/j.engappai.2025.110519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models are increasingly reshaping medical imaging, with growing attention on ensuring transparency and trust in their decision-making processes. This study presents the Explainable Vision Transformer (XViT), a model specifically designed for histopathological image analysis. By incorporating advanced interpretability techniques, the XViT model addresses three core aspects: feature learning and classification, generating explainable outputs, and qualitatively evaluating these explanations. Three novel interpretability methods are introduced: attention-based, model-agnostic, and gradient-based, offering diverse perspectives on model behavior. The model&#39;s performance and generalizability were rigorously evaluated on two histopathological datasets: lung colon 25000 (LCS25000) with 96.2% accuracy across three classes and Kangbuk Samsung Hospital (KBSMC) with 88.6% accuracy across four classes. XViT provides actionable insights by highlighting diagnostically relevant regions in input images, significantly enhancing clinical trust and decision-making. The evaluation of its explainability methods through metrics like sensitivity, faithfulness, and complexity demonstrated that layer-wise relevance propagation for transformers outperforms standard techniques like local interpretable model-agnostic explanations (LIME) and attention visualization. This robust performance underscores the XViT model&#39;s potential to bridge the gap between AI accuracy and interpretability in medical imaging. Our findings emphasize the need for well-defined evaluation criteria when comparing interpretability methods and highlight the model&#39;s potential for integration into clinical workflows. This work represents a step forward in creating reliable and interpretable AI solutions, ensuring that the benefits of advanced deep learning models extend seamlessly into practical healthcare settings.},
  archive      = {J_EAAI},
  author       = {Aqib Nazir Mir and Danish Raza Rizvi and Md Rizwan Ahmad},
  doi          = {10.1016/j.engappai.2025.110519},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110519},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing histopathological image analysis: An explainable vision transformer approach with comprehensive interpretation methods and evaluation of explanation quality},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automated processing of eXplainable artificial intelligence
outputs in deep learning models for fault diagnostics of large
infrastructures. <em>EAAI</em>, <em>149</em>, 110518. (<a
href="https://doi.org/10.1016/j.engappai.2025.110518">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Learning (DL) models processing images to recognize the health state of large infrastructure components can exhibit biases and rely on non-causal shortcuts. eXplainable Artificial Intelligence (XAI) can address these issues but manually analyzing explanations generated by XAI techniques is time-consuming and prone to errors. This work proposes a novel framework that combines post-hoc explanations with semi-supervised learning to automatically identify anomalous explanations that deviate from those of correctly classified images and may therefore indicate model abnormal behaviors. This significantly reduces the workload for maintenance decision-makers, who only need to manually reclassify images flagged as having anomalous explanations. The proposed framework is applied to drone-collected images of insulator shells for power grid infrastructure monitoring, considering two different Convolutional Neural Networks (CNNs), GradCAM explanations and Deep Semi-Supervised Anomaly Detection. The average classification accuracy on two faulty classes is improved by 8 % and maintenance operators are required to manually reclassify only 15 % of the images. We compare the proposed framework with a state-of-the-art approach based on the faithfulness metric: the experimental results obtained demonstrate that the proposed framework consistently achieves F 1 scores larger than those of the faithfulness-based approach. Additionally, the proposed framework successfully identifies correct classifications that result from non-causal shortcuts, such as the presence of ID tags printed on insulator shells.},
  archive      = {J_EAAI},
  author       = {G. Floreale and P. Baraldi and E. Zio and O. Fink},
  doi          = {10.1016/j.engappai.2025.110518},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110518},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automated processing of eXplainable artificial intelligence outputs in deep learning models for fault diagnostics of large infrastructures},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessment of hybrid kernel function in extreme support
vector regression model for streamflow time series forecasting based on
a bayesian estimator decomposition algorithm. <em>EAAI</em>,
<em>149</em>, 110514. (<a
href="https://doi.org/10.1016/j.engappai.2025.110514">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diverse decomposition algorithms have been widely employed to streamflow time series forecasting. Their applications, however, are hindered by the plausible high accuracy in the overall decomposition-based framework. This paper firstly introduces a novel decomposition algorithm named Bayesian estimator of abrupt change, seasonality and trend (BEAST) into streamflow forecasting to alleviate the boundary effect. Practical samples are generated under the modified two-stage decomposition prediction (TSDP) framework. A hybrid kernel function, which benefits from two different standalone ones, is designed for kernel extreme support vector regression and the HKESVR model is trained on the samples using 10-fold cross-validation strategy. Comparative experiments are conducted on three monthly streamflow series from basins with diverse hydroclimatic conditions. The results in different lead times (1-, 3-, and 5-month-ahead) show that the BEAST algorithm imposes an average improvement of 5.14% and 12.25% for the root-mean-square error and Nash-Sutcliffe efficiency coefficient respectively on the standalone models and shares a comprehensive similar performance on the mean absolute percentage error. And the nonparametric test results reveal that the BEAST method shows a significant improvement on the comprehensive performance compared with a conventional decomposition method. By contrast, the differences between machine learning models are much smaller. The hybrid kernel function works well in some specific cases in which the standalone kernel function fails. The hybrid BEAST-HKESVR is reliable enough to rank the second place among the fifteen tested models. Finally, the effects of hyperparameters in the BEAST algorithm are discussed and relevant suggestions on them are provided.},
  archive      = {J_EAAI},
  author       = {Peng Shi and Lei Xu and Simin Qu and Hongshi Wu and Qiongfang Li and Yiqun Sun and Xiaoqiang Yang and Wei Gao},
  doi          = {10.1016/j.engappai.2025.110514},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110514},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Assessment of hybrid kernel function in extreme support vector regression model for streamflow time series forecasting based on a bayesian estimator decomposition algorithm},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-stage manifold preserving mixed supervised learning for
bogie fault diagnosis under variable conditions. <em>EAAI</em>,
<em>149</em>, 110512. (<a
href="https://doi.org/10.1016/j.engappai.2025.110512">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bogie fault diagnosis for bogie is crucial to the safety of rail systems. However, since bogies work under normal states most of the time, the sporadic faulty samples are often submerged in massive normal samples, which are difficult to be distinguished and labeled. Therefore, the labeled training data are always insufficient or even lack of some certain fault states (novel faults), which brings great challenges to fault diagnosis, especially under variable working conditions. Therefore, this paper proposes a new framework named dual-stage manifold preserving mixed supervised learning (d-MMSL) to simultaneously absorb from labeled and unlabeled data effectively. Firstly, manifold similarity (MSLP) is presented to cluster unlabeled samples according to one-off calculation of the manifold similarity. In MSLP, the Best-versus-Second-Best differences and uncertain values are utilized to measure manifold distance and maintain the inherent structure of data. Secondly, Local manifold regularization - broad learning system (LMR-BLS) is presented to o deal with the problem of linear and nonlinear function transformation using simple incremental structure, which could further separate fuzzy sets from MSLP and distinguish the operation conditions of known states accurately. The proposed framework has been verified by a classical dataset and actual vibration data collected from bogies, which achieves a F1-score of 0.99. It is proven that this framework outperforms traditional methods in accuracy and efficiency.},
  archive      = {J_EAAI},
  author       = {Ning Wang and Limin Jia and Yong Qin and Dechen Yao and Jianwei Yang and Zhipeng Wang},
  doi          = {10.1016/j.engappai.2025.110512},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110512},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dual-stage manifold preserving mixed supervised learning for bogie fault diagnosis under variable conditions},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weighted class-aware matching adaptation network for
aero-engine imbalanced multi-source cross-domain fault diagnosis under
class shift. <em>EAAI</em>, <em>149</em>, 110510. (<a
href="https://doi.org/10.1016/j.engappai.2025.110510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation methods have been effectively applied in aero-engine fault diagnosis to address the issue of data distribution shifts. In practice, fault data for aero-engines are often collected from multiple source domains, each containing only a subset of health states, leading to class shift. Furthermore, the collection of fault data is costly, resulting in a long-tail distribution. However, most existing research focuses on single-source domain settings and lacks a unified framework to address both class shift and class imbalance. To address this gap, a weighted class-aware matching adaptation network is proposed. By leveraging the maximum mean discrepancy metric, we design a class-aware domain discrepancy metric that models class discrepancies between the source and target domains, enhancing alignment at class boundaries. This metric also integrates class balance weights to emphasize minority classes in a cost-sensitive manner. Moreover, a class-aware health state recognition loss encourages the model to focus on source domains resembling the target domain, enhancing knowledge transfer. Finally, the proposed method is validated through cross-domain fault diagnosis experiments using the turbofan engine fault dataset and the Case Western Reserve University bearing dataset, demonstrating its effectiveness compared to several advanced methods.},
  archive      = {J_EAAI},
  author       = {Yu-Qiang Wang and Yong-Ping Zhao and Bo-Yu Liang and Tian-Ding Zhang and Kuan-Xin Hou},
  doi          = {10.1016/j.engappai.2025.110510},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110510},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Weighted class-aware matching adaptation network for aero-engine imbalanced multi-source cross-domain fault diagnosis under class shift},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Applications of artificial intelligence in industry 4.0 and
smart manufacturing. <em>EAAI</em>, <em>149</em>, 110509. (<a
href="https://doi.org/10.1016/j.engappai.2025.110509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This special issue was initiated at the 10th IFAC triennial conference MIM 2022 concerning the topics dealing with applications of artificial intelligence in Industry 4.0, for especially process planning, reconfigurable manufacturing, robotics, production planning, fault detection and diagnostics.},
  archive      = {J_EAAI},
  author       = {Audrey Cerqueus and Alexandre Dolgui and Dmitry Ivanov and Alexandr Klimtchik and David Lemoine and Anatol Pashkevich},
  doi          = {10.1016/j.engappai.2025.110509},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110509},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Applications of artificial intelligence in industry 4.0 and smart manufacturing},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hyperspectral image mixed noised removal via jointly spatial
and spectral difference constraint with low-rank tensor factorization.
<em>EAAI</em>, <em>149</em>, 110508. (<a
href="https://doi.org/10.1016/j.engappai.2025.110508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The denoising of hyperspectral image (HSI) plays a crucial role in the subsequent interpretation and application. The rise of artificial intelligence technology has brought new opportunities for hyperspectral image denoising, and its potential and advantages in this field are gradually changing the traditional denoising pattern. This paper proposes a jointly spatial and spectral difference constraints with low-rank tensor factorization. Firstly, the spatial and spectral difference is combined in the framework of low-rank tensor factorization, to fully mine global spatial–spectral information and improve the removal ability of complex distribution noise. Secondly, based on the premise of effectively preserving HSI intrinsic three-dimensional structure, the spatial horizontal and vertical difference constraints are used to mine the local smoothness and similarity of spatial. Thirdly, the full-band spectral difference constraint could not only characterize the continuity and sparsity of the whole spectral domain, but also effectively characterize the noise distribution with linear structure. Finally, experiments on simulated and real HSIs show that the proposed method outperforms state-of-the-art methods in removing mixed noise performance.},
  archive      = {J_EAAI},
  author       = {Qiang Zhang and Yaming Zheng and Yushuai Dong and Chunyan Yu and Qiangqiang Yuan},
  doi          = {10.1016/j.engappai.2025.110508},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110508},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hyperspectral image mixed noised removal via jointly spatial and spectral difference constraint with low-rank tensor factorization},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An image segmentation method for solid-liquid separation on
shale shaker based on an improved U2Net. <em>EAAI</em>, <em>149</em>,
110507. (<a
href="https://doi.org/10.1016/j.engappai.2025.110507">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the actual production process of shale shakers, detecting the solid-liquid separation state of the screen surface faces numerous challenges, such as difficulty in recognizing the mud boundary, insufficient anti-interference ability, and misjudgment caused by background interference. To address these issues, this paper proposes a screen surface mud image segmentation method based on U 2 Net, namely CBAM-U 2 Net. By introducing the Convolutional Block Attention Module (CBAM) and combining it with Multi-layer Recursive Residual Blocks (RSU), a network structure is designed that can efficiently fuse global and local features, significantly improving segmentation accuracy and robustness. The network includes encoder and decoder parts, employing convolution, batch normalization, ReLU activation, and multi-scale feature fusion strategies. Experimental results show that the CBAM-U 2 Net method demonstrates excellent segmentation performance under various working conditions, achieving outstanding results with mIoU, F1-score, Precision, and Recall at 83.38%, 89.75%, 89.38%, and 92.64%, respectively, with significantly enhanced anti-interference capability. The CBAM-U 2 Net method provides an efficient and reliable solution for the intelligent monitoring of the solid-liquid separation state in shale shakers, offering significant practical application value.},
  archive      = {J_EAAI},
  author       = {Wenbin Wang and Yongjun Hou and Rui Jiang and Pan Fang and Hong Peng and Qing Li and Huachuan Li},
  doi          = {10.1016/j.engappai.2025.110507},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110507},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An image segmentation method for solid-liquid separation on shale shaker based on an improved U2Net},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient kriging-based wall deflection prediction in braced
excavation considering model and measurement errors. <em>EAAI</em>,
<em>149</em>, 110506. (<a
href="https://doi.org/10.1016/j.engappai.2025.110506">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The deflection prediction of diaphragm walls stands as a critical aspect of safety management for excavation construction. Bayesian updating holds a prominent position among several existing prediction methods, owing to its probabilistic predictions and the ability to simultaneously consider prior knowledge and observational data. This paper develops a comprehensive Bayesian updating framework for wall deflection prediction in braced excavation, taking into account both model error associated with the prediction model chosen and measurement error. Further, both of these errors typically exhibit depth dependency and spatial correlation and thus are modeled as stochastic processes. An innovative efficient Kriging (e-Kriging) surrogate model and an Expectation-Maximum algorithm based adaptive importance sampling (AIS) method are proposed to improve computational efficiency. The prediction performance of this proposed framework is verified via an exhaustively reported Taipei National Enterprise Center (TNEC) excavation project. Moreover, this paper compares the influences of different selections of prior distributions and measurement data on the predictions. Results suggest that using only a subset of the middle portion of measurement data for updating is often a more appropriate choice.},
  archive      = {J_EAAI},
  author       = {Xiong Xiao and Quanwang Li and Hao Zhang},
  doi          = {10.1016/j.engappai.2025.110506},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110506},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Efficient kriging-based wall deflection prediction in braced excavation considering model and measurement errors},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Consistency-based decision-making method with linguistic
q-rung orthopair fuzzy preference relation for power battery selection
of new energy vehicles. <em>EAAI</em>, <em>149</em>, 110505. (<a
href="https://doi.org/10.1016/j.engappai.2025.110505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of global petrochemical depletion and increasingly serious environmental pollution, new energy vehicles, as a key industry to build a sustainable low-carbon society, have been paid more and more attention by countries all over the world. As the “heart” of new energy vehicles, power battery plays an important role in the core competitiveness of enterprises. Aiming at the fuzziness and uncertainty of complex power battery selection, a two-stage consistency optimization model based on preference relations and an interactive consistency improvement process are established in this paper. Firstly, by considering the interaction between membership and non-membership, this paper proposes an improved linguistic q-rung orthopair fuzzy weighted averaging operator. Then, the concept of linguistic q-rung orthopair fuzzy preference relation (Lq-ROFPR) is proposed, and its additive consistency index is given based on linguistic scaling function. Whereafter, for the Lq-ROFPR with unacceptable consistency, an interactive mechanism is proposed to improve the consistency level, which considers the minimum adjustment size of preference modification and the minimum number of adjustment elements in turn. Moreover, the method for solving the multi-attribute decision-making problems is formed and applied to the selection of power batteries in XP automobile company. Finally, the simulation experiment and comparative analysis with other methods show the effectiveness and rationality of this method in consistency optimization.},
  archive      = {J_EAAI},
  author       = {Xin Dong and Peide Liu and Peng Wang and Xiaoming Wu},
  doi          = {10.1016/j.engappai.2025.110505},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110505},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Consistency-based decision-making method with linguistic Q-rung orthopair fuzzy preference relation for power battery selection of new energy vehicles},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Syn-rPPG: Improving unsupervised remote photoplethysmography
extraction with synthesized videos using generative models.
<em>EAAI</em>, <em>149</em>, 110504. (<a
href="https://doi.org/10.1016/j.engappai.2025.110504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote photoplethysmography (rPPG) is a non-contact technology used to capture cardiac activity from the face, providing measurements of physiological parameters. Current unsupervised methods for rPPG tasks often focus on contrastive learning, which highlights relationships between samples but struggles with a lack of diverse training data, particularly in terms of varying skin colors and motion types. This limits model effectiveness in complex real-world scenarios. Generative models offer a potential solution by creating synthetic samples to enrich the training data. In this study, we explore the impact of using synthetic videos generated by style transfer and motion transfer techniques to enhance unsupervised rPPG tasks. We generate two types of synthetic videos: skin color synthetic videos and motion synthetic videos. These address the key challenges in rPPG, namely skin color variations and motion artifacts. Our analysis shows that these synthetic videos provide valuable physiological information, improving the performance and robustness of unsupervised models. Additionally, we propose a novel lightweight rPPG network, Style-Aware rPPG Fusion Net (SAFNet), based on an encoder–decoder structure, which is optimized for joint training with synthetic videos. By incorporating a feature fusion approach, SAFNet captures richer spatiotemporal information, resulting in superior performance and robustness. Extensive experiments on four public benchmark datasets demonstrate that our method achieves excellent results, particularly in challenging conditions, proving the effectiveness of using synthetic data to enhance remote physiological measurements.},
  archive      = {J_EAAI},
  author       = {Tianqi Liu and Hanguang Xiao and Yisha Sun and Kun Zuo and Qihang Zhang and Zhipeng Li and Feizhong Zhou},
  doi          = {10.1016/j.engappai.2025.110504},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110504},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Syn-rPPG: Improving unsupervised remote photoplethysmography extraction with synthesized videos using generative models},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Democratizing eye-tracking? Appearance-based gaze estimation
with improved attention branch. <em>EAAI</em>, <em>149</em>, 110494. (<a
href="https://doi.org/10.1016/j.engappai.2025.110494">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Appearance-based gaze estimation in 2-dimensional screen coordinates–the prediction of the users’ gaze from webcam footage–cannot yet compete in accuracy with infrared (IR) eye trackers. Yet by circumventing the constraints of requiring dedicated hardware, it shows great potential in many technological industries, as evidenced by some readily available commercial solutions, bringing democratization of eye tracking closer to the people. We present Residual Appearance-based Gaze Estimation network (RAGE-net), a novel convolutional neural network for gaze estimation without need of calibration, utilizing a fraction of computational resources required by similar networks, while also achieving competitive accuracy. The angular error is measured as 4.08°in the MPIIFaceGaze dataset (Max Planck Institute for Informatics Faze Gaze) and 3.96°in the MPIIGaze dataset. The architecture’s principles, covered by a comprehensive ablation study, include an attention branch, residual learning, weight sharing between eye channels, batch normalization and an eye image input normalization pipeline that removes dependence on full face input. With RAGE-net, we conduct an applicability study for gaze estimation approaches of similar accuracy for interpreting on-screen gaze in praxis. Findings demonstrate low heatmap validity, with coarse heatmaps as potential adaptation to approximate IR eye tracking. The effects of environmental factors such as camera position, illumination, distance and glasses are analyzed in-depth.},
  archive      = {J_EAAI},
  author       = {Eduard Kuric and Peter Demcak and Jozef Majzel and Giang Nguyen},
  doi          = {10.1016/j.engappai.2025.110494},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110494},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Democratizing eye-tracking? appearance-based gaze estimation with improved attention branch},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A three-dimensional dynamic spatial-temporal graph neural
network for ocean temperature field prediction. <em>EAAI</em>,
<em>149</em>, 110492. (<a
href="https://doi.org/10.1016/j.engappai.2025.110492">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of the ocean temperature field is vital for the protection of marine ecosystems under climate change. However, most existing methods only consider temporal changes, ignoring the rich three-dimensional (3D) dynamic spatial characteristics of the ocean temperature field. To improve prediction accuracy, we propose a fine-grained modeling method that uses the spatial correlations in the ocean temperature field, called the 3D Dynamic Spatial-Temporal Graph Neural Network (3D-DSTGN). Specifically, according to the 3D spatial features and dynamic spatial dependencies of the ocean temperature field, we first decompose the spatial correlation of the ocean temperature field into long-term static and short-term dynamic parts through statistical analysis of real ocean temperature datasets. We then build a 3D dynamic graph structure learning module to create static and dynamic graph structures with 3D spatial features to model and capture the corresponding spatial correlations. Next, based on the two graph structures, we apply a dual-mode graph convolution block to fully capture the dynamic spatial dependencies of the ocean temperature field. Furthermore, we use a multi-scale temporal convolution block to capture complex temporal dependencies from historical ocean temperature data. Finally, the dual-mode graph convolution block and the multi-scale temporal convolution block construct the spatio-temporal recurrent module, which extracts complex dynamic spatio-temporal contextual dependencies. On a large-scale real ocean temperature dataset from the sea surface to a subsurface depth of approximately 2,000 m, 3D-DSTGN outperforms other baselines in experiments across different temporal and spatial scales, effectively modeling the dynamic three-dimensional spatial relationships of the ocean temperature field.},
  archive      = {J_EAAI},
  author       = {Shuai Zhang and ZhuoLin Li and XiaoYu He and Jie Yu and LingYu Xu},
  doi          = {10.1016/j.engappai.2025.110492},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110492},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A three-dimensional dynamic spatial-temporal graph neural network for ocean temperature field prediction},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ergonomic conscious scheduling of maintenance activities in
marine vehicles using an optimized non-dominated sorting genetic
algorithm-II – an application of job-shop scheduling. <em>EAAI</em>,
<em>149</em>, 110491. (<a
href="https://doi.org/10.1016/j.engappai.2025.110491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incorporating ergonomics in marine activities is critical due to the extreme working conditions and limited crew in marine vehicles, aiming to enhance productivity and job performance by reducing the risks of fatigue, stress, and work-related musculoskeletal disorders. This paper introduces an innovative analogy of the flexible job-shop scheduling problem with ergonomic considerations (AFJSP-ER) to schedule maintenance activities in marine systems, addressing the dual objectives of optimizing productivity and promoting ergonomic relief. A novel metric, ‘ergonomic impact load’ is introduced to assess the actual workload of the crew by combining the processing time and the rapid entire body assessment (REBA) score of an operation. To solve the AFJSP-ER, an optimized non-dominated sorting genetic algorithm-II (ONSGA) is proposed, incorporating an optimized random crossover (ORX) operator. The ORX operator is fine-tuned using the Taguchi method to determine the optimal number of elements for crossover, while non-dominated sorting ensures the selection of superior individuals after crossover and mutation. The effectiveness of the proposed ONSGA has been validated through extensive experiments on newly developed test instances and using an industrial case study from the ship engine compartment. The results also indicate that the AFJSP-ER approach effectively optimizes productivity and promotes ergonomic relief, offering a practical solution for scheduling in ergonomically challenging marine environments.},
  archive      = {J_EAAI},
  author       = {Shaban Usman and Cong Lu},
  doi          = {10.1016/j.engappai.2025.110491},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110491},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Ergonomic conscious scheduling of maintenance activities in marine vehicles using an optimized non-dominated sorting genetic algorithm-II – an application of job-shop scheduling},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-stage feature aggregation transformer for image rain
and haze joint removal. <em>EAAI</em>, <em>149</em>, 110490. (<a
href="https://doi.org/10.1016/j.engappai.2025.110490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the complex meteorological phenomenon of rain-haze mixtures, resulting from water vapor condensation in real-world rainy environments. Current methodologies predominantly focus on rain removal, often neglecting the image degradation caused by haze. We propose a multi-stage feature aggregation transformer (MFAFormer). The model consists of multiple stages, each comprising an information calibration module and a feature aggregation module. Specifically, the information calibration module extracts local high-frequency rain features, whereas the feature aggregation module extracts global low-frequency haze features and integrates features across stages. Benefiting from multi-stage feature extraction and aggregation, MFAFormer can efficiently and robustly address the complex degradations caused by the simultaneous presence of rain and haze. Additionally, we propose a novel rain and haze mixed dataset RainHaze Synscapes. The dataset contains large variations in rain streaks, haze density, and scene contents. Experimental results indicate that the model surpasses other methods on the dataset. MFAFormer demonstrates a remarkable improvement, achieving a 37.46% increase in peak signal-to-noise ratio (PSNR) and a 10.48% increase in structural similarity (SSIM) compared to the baseline model on the RainHaze Synscapes dataset. This accomplishment offers valuable insights for the research of rain and haze joint removal domain.},
  archive      = {J_EAAI},
  author       = {Zhengran Xia and Lei Dai and Zhihua Chen and Kai Chen and Ran Li},
  doi          = {10.1016/j.engappai.2025.110490},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110490},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-stage feature aggregation transformer for image rain and haze joint removal},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An end-to-end semantic-guided infrared and visible
registration-fusion network for advanced visual tasks. <em>EAAI</em>,
<em>149</em>, 110489. (<a
href="https://doi.org/10.1016/j.engappai.2025.110489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of infrared and visible images is key to complex visual tasks, with image registration as a fundamental initial step. We explore these tasks as a unified registration-fusion process. Traditional global registration may use a multitude of feature points for alignment, achieving global optimality. However, for advanced tasks like pose recognition, object tracking, and person re-identification, the relevant semantic information may not align accurately, impacting fusion effectiveness and task performance. To address this issue, we propose a Semantic-Aware on-Demand registration-fusion network. 1) We design the Semantic-Aware Module, employing Grounding DINO and Segment Anything to capture semantic regions of interest needed for advanced tasks. 2) Combining with the Semantic-Aware Module, we design a Hierarchical Orientation Line operator and a Deep Hybrid Matching to ensure precise feature matching within semantic regions of interest. 3) To enhance fusion visual effects, a novel image fusion module is designed to facilitate high-quality image fusion within these regions. This method is versatile and applicable to a wide range of advanced visual tasks. We compare this method with six image matching and nine image fusion methods, underscoring its efficacy in advanced visual tasks. The experimental results indicate that both the registration module and the fusion module achieve optimal performance individually. When it comes to joint tasks of registration and fusion in visual tasks, our method similarly exhibits the best performance in the 6 × 10 joint tasks.},
  archive      = {J_EAAI},
  author       = {Meng Sang and Housheng Xie and Jingrui Meng and Yukuan Zhang and Junhui Qiu and Shan Zhao and Yang Yang},
  doi          = {10.1016/j.engappai.2025.110489},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110489},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An end-to-end semantic-guided infrared and visible registration-fusion network for advanced visual tasks},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiscale self-attention for unmanned ariel vehicle-based
infrared thermal images detection. <em>EAAI</em>, <em>149</em>, 110488.
(<a href="https://doi.org/10.1016/j.engappai.2025.110488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection and recognition in unmanned aerial vehicle-based images is critical for various applications but is often challenged by complex backgrounds, diverse object scales, densely clustered small objects, and uneven object distributions. This paper introduces a novel deep learning-based artificial intelligence framework that integrates the Multiscale Self-Attention Guidance and Feature Fusion Network with the You Only Look Once model, tailored explicitly for artificial intelligence-driven unmanned aerial vehicle-based infrared thermal image analysis. The proposed methodology offers four key advancements in the You Only Look Once architecture to enhance object detection performance. First, the Multi-Head Self-Attention Transformer module combines global and local information, enabling precise object localization while mitigating the influence of complex backgrounds. Second, the Multiscale Parallel Sampling Feature Fusion module optimizes the fusion of multiscale features. Third, fine-grained shallow feature maps are integrated into the fusion process to detect densely packed small objects accurately. Lastly, the Inverse-Residual Feature Enhancement module, positioned before the detection head, enhances feature extraction for small objects. Experimental evaluations on the High Altitude Infrared Thermal Unmanned Aerial Vehicle dataset demonstrate significant improvements, achieving a Mean Average Precision of 95.1%, Recall of 92.0%, and F1-Score of 91.0%. The framework’s robustness is further validated on the Wildland-fire Infrared Thermal Unmanned Aerial System dataset, achieving a Mean Average Precision of 82.1%, Recall of 88.0%, and F1-Score of 82.0%. Comparative analyses with state-of-the-art methods confirm its superiority and offer a scalable artificial intelligence-driven solution for unmanned aerial vehicle applications, advancing object detection capabilities in critical scenarios.},
  archive      = {J_EAAI},
  author       = {Muhammad Shahroze Ali and Afshan Latif and Muhammad Waseem Anwar and Muhammad Hashir Ashraf},
  doi          = {10.1016/j.engappai.2025.110488},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110488},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multiscale self-attention for unmanned ariel vehicle-based infrared thermal images detection},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent fault diagnosis of nonlinear uncertain
industrial processes based on kernel local–global interval embedding
algorithm. <em>EAAI</em>, <em>149</em>, 110486. (<a
href="https://doi.org/10.1016/j.engappai.2025.110486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of a new generation of Big Data and artificial intelligence, intelligent fault diagnosis of industrial processes including chemical processes, coal mining equipment operations, etc., has become increasingly important. The local–global interval embedding algorithm (LGIEA) has attracted significant attention for its capability to simultaneously extract local and global features from interval data. However, this method can only process linear interval data and performs poorly in terms of extracting strong nonlinear features. To solve the problem, this study proposes a new intelligent fault diagnosis method based on kernel LGIEA (KLGIEA), which extends the linear process monitoring model to nonlinearity. First, the interval inner product estimation (IIPE) is transformed into the kernel IIPE by introducing kernel function, which can not only inherit the advantage that LGIEA can extract both global and local features of data simultaneously, but also has stronger applicability to nonlinear data in industrial processes. Second, the four statistics defined can effectively monitor the fault of industrial equipment under strong interference environment such as noises, and the nonlinear reconstruction contribution (NRC) can effectively identify the fault variables, improve the fault diagnosis ability of KLGIEA. Finally, two cases of the Tennessee Eastman process (TEP) simulation data from Eastman Company and site shearer fault data obtained from Shaqu No. 2 coal mine show that KLGIEA is significantly superior to complete information principal component analysis (PCA), midpoint-radius kernel PCA, and LGIEA in processing nonlinear interval data, improving accuracy, applicability, and reliability of algorithm.},
  archive      = {J_EAAI},
  author       = {Ning Li and Hua Ding and Xiaochun Sun and Zeping Liu},
  doi          = {10.1016/j.engappai.2025.110486},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110486},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent fault diagnosis of nonlinear uncertain industrial processes based on kernel local–global interval embedding algorithm},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed data-driven iterative learning consensus
tracking for unknown multi-agent systems using evolutionary neural
networks. <em>EAAI</em>, <em>149</em>, 110485. (<a
href="https://doi.org/10.1016/j.engappai.2025.110485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides a data-driven distributed parameter adaptive iterative learning consensus tracking strategy for nonlinear nonaffine discrete-time multi-agent systems with unknown dynamics. By transforming the ideal learning controller on the timeline into a direct iterative learning control strategy in the iterative domain, the design of the control protocol is only data-driven. Unlike existing parameter tuning control methods, the parameter tuning approach presented in this paper adjusts the parameters online through topological information, eliminating the need for multiple trials and adjustments based on experience. The gain time variability of multi-agent systems is learned and compensated by the extended generalized regression neural networks evolution control. By introducing a limited incremental evolution mechanism, the optimal control parameters can be adjusted online during the control process to find the system trajectory to achieve optimal output synchronization, so as to improve the control efficiency of iterative learning control. Different from the existing directed fixed topology works of multi-agent systems, the consensus convergence properties of fixed directed communication topologies and iterative time-varying communication topologies along the iterative domain are established by contraction mapping theorem. Two numerical simulation examples are conducted to validate the effectiveness of the proposed control protocol.},
  archive      = {J_EAAI},
  author       = {Kechao Xu and Bo Meng and Zhen Wang},
  doi          = {10.1016/j.engappai.2025.110485},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110485},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Distributed data-driven iterative learning consensus tracking for unknown multi-agent systems using evolutionary neural networks},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-point dam deformation prediction model based on
spatiotemporal graph convolutional network. <em>EAAI</em>, <em>149</em>,
110483. (<a
href="https://doi.org/10.1016/j.engappai.2025.110483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dams are essential for services such as water supply and flood protection, making their structural health and safety crucial to prevent catastrophic failures. Monitoring dam displacement is a critical method for assessing its current condition and predicting future behavior. Most displacement monitoring models primarily focus on temporal features and the relationship between environmental factors and dam displacement, often overlooking the spatial relationships in the data. Even multi-point models, designed to handle multiple measurement locations, struggle to effectively account for the spatial coordination between these points. To address these challenges, this paper proposes a multi-point displacement monitoring model based on a variational auto-encoder (VAE) and a spatiotemporal graph convolutional network (STGCN). The graph structure is utilized to represent the coordinated deformation relationships among monitoring points, while also capturing temporal features and nonlinear relationships between environmental factors and dam displacement. The VAE model is first used to extract latent feature representations from historical monitoring data and monitoring point coordinates. The K-nearest neighbors (KNN) method is then applied to calculate the connection weights between monitoring points, constructing the adjacency matrix. Graph convolutional network (GCN) is utilized to extract spatial features, while gated recurrent units (GRU) capture temporal dependencies, enabling accurate multi-point displacement prediction. The model&#39;s effectiveness and accuracy are validated through comparisons with both single-point and multi-point models, while the impact of K-nearest neighbors and learnable position encoding on model performance is also evaluated. The results demonstrate that the proposed model significantly outperforms others, showing superior predictive accuracy and generalization capabilities.},
  archive      = {J_EAAI},
  author       = {Taiqi Lu and Hao Gu and Chongshi Gu and Chenfei Shao and Dongyang Yuan},
  doi          = {10.1016/j.engappai.2025.110483},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110483},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-point dam deformation prediction model based on spatiotemporal graph convolutional network},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Visual object tracking using learnable target-aware token
emphasis. <em>EAAI</em>, <em>149</em>, 110482. (<a
href="https://doi.org/10.1016/j.engappai.2025.110482">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual object tracking, which involves tracking the spatial location of a target object either within a single viewpoint or across various camera perspectives, is an important task in computer vision. Deep neural networks, especially vision transformers, typically outperform traditional methods and have thus become the preferred choice for visual object tasks. However, existing visual object tracking frameworks still struggle to adapt to targets with continuously changing appearances within the current frame, as they rely heavily on the static initial target template rather than continuously emphasizing the evolving target features. In this paper, we introduce a visual object tracking network with a learnable target-aware token emphasis, which is composed of vision transformer backbone embedded in the token emphasizer, localization head and target template update decision module. The learnable target-aware token emphasizer and target template update decision modules in the proposed model contribute to stabilizing visual object tracking across various scenarios. This is achieved not only by emphasizing features that have a relationship between the target template and the search region but also by reducing irrelevant features and consistently updating the high-quality target template online during the process. Qualitative and quantitative analyses, including ablation analysis across a diverse set of tracking benchmark datasets, validate the robustness of the proposed tracking framework. The code and trained models are available at https://github.com/qkdkralsgh/TETrack .},
  archive      = {J_EAAI},
  author       = {Minho Park and Jinjoo Song and Sang Min Yoon},
  doi          = {10.1016/j.engappai.2025.110482},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110482},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Visual object tracking using learnable target-aware token emphasis},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Phased noise enhanced multiple feature discrimination
network for fabric defect detection. <em>EAAI</em>, <em>149</em>,
110480. (<a
href="https://doi.org/10.1016/j.engappai.2025.110480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fabric defect detection is crucial for evaluating the quality of textile products. However, the subtlety and scarcity of fabric defects pose challenges to the task of detecting. Therefore, we propose a P hased N oise Enhanced M ultiple F eature D iscrimination Network, which is based on phased noise enhancement strategy and multiple feature discrimination module to improve the model’s ability to identify complex and subtle flaws. Specifically, we propose the phased noise enhancement strategy in the feature space to simulate feature-level anomalies that are closer to reality. This strategy can improve the input quality of the feature reconstructor, so that helps its perception and reconstruction ability. Then, we propose the multiple feature discrimination module, which has dual feature branches to improve its ability to distinguish more complex detailed texture features. In addition, we propose a subsampling module to reduce feature redundancy and ensure efficient inference speed. Finally, we conduct extensive experiments and ablation studies on two publicly available fabric datasets, AITEX and Kaggle Fabric. The experimental results show that the proposed method achieved 92% and 100% image level metrics and 97.5% and 67.1% pixel level metrics on two datasets, respectively, which is superior to the current state-of-the-art methods. In addition, our method also demonstrated significant performance in generalization experiments.},
  archive      = {J_EAAI},
  author       = {Haoran Ma and Zuoyong Li and Haoyi Fan and Xiangpan Zheng and Jiaquan Yan and Rong Hu},
  doi          = {10.1016/j.engappai.2025.110480},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110480},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Phased noise enhanced multiple feature discrimination network for fabric defect detection},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Information extraction from multi-layout invoice images
using FATURA dataset. <em>EAAI</em>, <em>149</em>, 110478. (<a
href="https://doi.org/10.1016/j.engappai.2025.110478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document analysis and understanding models often require extensive annotated data to be trained. However, various document-related tasks extend beyond mere text transcription, requiring both textual content and precise bounding-box annotations to identify different document elements. Collecting such data becomes particularly challenging, especially in the context of invoices, where privacy concerns add an additional layer of complexity. Invoices are critical documents in many business processes, but existing datasets for invoice analysis are limited in size and diversity, hindering the development of robust models. Current datasets do not adequately address the need for diverse layouts and comprehensive annotations, which are essential for training models capable of handling real-world variations in invoice documents. In this paper, we introduce FATURA, a pivotal resource for researchers in the field of document analysis and understanding. FATURA is a highly diverse dataset featuring multi-layout, annotated invoice document images. Comprising 10,000 invoices with 50 distinct layouts, it represents the largest openly accessible image dataset of invoice documents known to date. We provide an extensive evaluation using different information extraction methods under diverse training and evaluation scenarios, including precision, recall, and F1-score. The evaluation includes a visual-based approach using object detection for text region classification, a multi-modal strategy integrating visual and textual data for granular content comprehension, and a hybrid approach combining these methods. The dataset is freely accessible at this https://zenodo.org/record/8261508 , empowering researchers to advance the field of document analysis and understanding.},
  archive      = {J_EAAI},
  author       = {Mahmoud Limam and Marwa Dhiaf and Yousri Kessentini},
  doi          = {10.1016/j.engappai.2025.110478},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110478},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Information extraction from multi-layout invoice images using FATURA dataset},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite time multilayer neural network command filter
backstepping controller design for large scale uncertain nonlinear
systems. <em>EAAI</em>, <em>149</em>, 110474. (<a
href="https://doi.org/10.1016/j.engappai.2025.110474">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel dynamical multilayer neural network finite time command filter backstepping control scheme. This method realizes the finite time robust tracking control of uncertain nonlinear system. The uncertainty in system varies in large scale around system states. Its boundary is unknown and unavailable before design. The multilayer neural network (MNN) approximater is redesigned into the backstepping controller instead of the common radial basis function (RBF) neural network (NN) and Fuzzy System (FS) to realize the accuracy approximation of the large scale uncertain structure. The introduction of the MNN approximater overcomes the drawback of local identification constraint of RBF NN and Fuzzy System without the structure knowledge and boundary of uncertainty before design. Otherwise, owing to the MNN structure is more complex than common three layer RBF NN, the approximation costs more time to dynamically tune weight parameters online. In order to make up the time consistent between the MNN approximation and the backstepping process, the finite time (FT) command filter (CF) backstepping control strategy balancing the two distinct procedures guarantees the MNN identification of larger scale uncertainty and backstepping control process consistently convergence into a smaller area in uniform finite time interval. Finally, through a practical example, the effectiveness and advantages of are illustrated by comparison between this mechanism and traditional RBF NN method.},
  archive      = {J_EAAI},
  author       = {Qitian Yin and Quanqi Mu and Jianbai Yang},
  doi          = {10.1016/j.engappai.2025.110474},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110474},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Finite time multilayer neural network command filter backstepping controller design for large scale uncertain nonlinear systems},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HT-AggNet: Hierarchical temporal aggregation network with
near-zero-cost layer stacking for human activity recognition.
<em>EAAI</em>, <em>149</em>, 110465. (<a
href="https://doi.org/10.1016/j.engappai.2025.110465">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the steady growth of sensor technology and wearable devices in pervasive computing applications, sensor-based human activity recognition has gained attention in fields such as healthcare monitoring and fitness tracking. This has resulted in an increased need for accurate and real-time systems. Recent studies to satisfy the real-time conditions have attempted to design lightweight neural networks by mainly restricting the number of layers shallowly, which has decreased both inference time and accuracy. To recover the loss of accuracy, we propose an innovative hierarchical temporal aggregation network (HT-AggNet) that allows the network architecture to be deeper, leading to an accuracy gain with only a near-zero increase in computational cost. Furthermore, a temporal glance convolution is presented to model the global context information of the signal patterns. Consequently, the HT-AggNet hierarchically extracts the local and global temporal information and then merges them based on hierarchical temporal aggregation. In our experiments, the HT-AggNet outperformed existing methods on seven publicly available datasets and achieved state-of-the-art performance. The source code for the HT-AggNet is publicly available at https://github.com/jgpark92/HT-AggNet .},
  archive      = {J_EAAI},
  author       = {Jaegyun Park and Dae-Won Kim and Jaesung Lee},
  doi          = {10.1016/j.engappai.2025.110465},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110465},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {HT-AggNet: Hierarchical temporal aggregation network with near-zero-cost layer stacking for human activity recognition},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reliability evaluation of solar integrated power
distribution systems using an evolutionary swarm algorithm.
<em>EAAI</em>, <em>149</em>, 110464. (<a
href="https://doi.org/10.1016/j.engappai.2025.110464">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The reliability of solar-integrated power distribution systems is significantly affected by intermittent solar generation and its impact on feeder voltages. While existing adequacy studies account for intermittency, they frequently overlook feeder voltages due to the computational burden of the Alternating Current Optimal Power Flow (AC-OPF) analysis. Addressing this gap, we propose an efficient framework based on an Evolutionary Swarm Algorithm (ESA) to integrate AC-OPF analysis into the reliability evaluation of power distribution systems. The sampling mechanism of ESA reduces the application of time-consuming AC-OPF and allows the fast estimation of reliability indices. The performance of the proposed framework is compared with Sequential Monte Carlo Simulation (SMCS), classical meta-heuristics, and three state-of-the-art meta-heuristics. Results demonstrate that our proposed framework can estimate the reliability indices approximately 34 times faster than SMCS without sacrificing accuracy. Furthermore, the ESA outperforms classical and state-of-the-art methods by over 23% in event sampling efficiency. Friedman and Nemenyi post-hoc tests conclude that ESA’s results significantly differ from others. We utilize the proposed framework in a case study to analyze the influence of solar photovoltaic integration on distribution system reliability. Another case study investigates the impact of dynamic tap changing of power transformers on the reliability improvement of distribution systems.},
  archive      = {J_EAAI},
  author       = {P.A.G.M. Amarasinghe and S.K. Abeygunawardane and C. Singh},
  doi          = {10.1016/j.engappai.2025.110464},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110464},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reliability evaluation of solar integrated power distribution systems using an evolutionary swarm algorithm},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic feature capturing in a fluid flow reduced-order
model using attention-augmented autoencoders. <em>EAAI</em>,
<em>149</em>, 110463. (<a
href="https://doi.org/10.1016/j.engappai.2025.110463">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study looks into how adding adaptive attention to convolutional autoencoders can help reconstruct flow fields in fluid dynamics applications. The study compares the effectiveness of the proposed adaptive attention mechanism with the convolutional block attention module approach using two different sets of datasets. The analysis encompasses the evaluation of reconstruction loss, latent space characteristics, and the application of attention mechanisms to time series forecasting. Combining adaptive attention with involution layers enhances its ability to identify and highlight significant features, surpassing the capabilities of the convolutional block attention module. This result demonstrates an increase of over 20% in the accuracy of reconstruction. Latent space analysis shows the adaptive attention mechanism’s complex and flexible encoding, which makes it easier for the model to represent different types of data. The study also looks at how attention works and how it affects time series forecasting. It shows that a new method that combines multi-head attention and bidirectional long-short-term memory works well for forecasting over 5 s of futures of flow fields. This research provides valuable insights into the role of attention mechanisms in improving model accuracy, generalization, and forecasting capabilities in the field of fluid dynamics.},
  archive      = {J_EAAI},
  author       = {Alireza Beiki and Reza Kamali},
  doi          = {10.1016/j.engappai.2025.110463},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110463},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic feature capturing in a fluid flow reduced-order model using attention-augmented autoencoders},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient generation of power system topology diagrams based
on graph neural network. <em>EAAI</em>, <em>149</em>, 110462. (<a
href="https://doi.org/10.1016/j.engappai.2025.110462">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Power system topology diagrams illustrate the physical and spatial relationship of system nodes and are widely used as a basic tool for displaying system structure. Well-presented topology diagrams provide better situational awareness for the operators, but their efficient generation remains a challenge. Existing approaches struggle to find a balance between visual aesthetics and the generation speed of the diagram. With the rapid changes in power system topology, there is a higher demand for the rendering speed of the graph data. To satisfy both the real-time requirement and the aesthetic quality, this paper proposes an integrated framework for efficiently generating power system topology diagrams. It consists of a Graph Neural Network (GNN) model and a graph fine-tuning model. This framework can directly optimize the raw topology diagram while preserving the relative positions of nodes in the initial layout. It achieves a decent trade-off between layout quality and computational expenses, enabling the generation of aesthetically satisfactory diagrams in a short time. Due to the strong generalization ability of GNN, the proposed model can be trained on small system datasets and used for inference on large systems. Case studies verify that the proposed GNN model can optimize the aesthetic metrics of topology diagram layouts within seconds to an average value of 0.55. Finally, it can be used in power system applications as a fundamental tool for topology diagram generation and optimization.},
  archive      = {J_EAAI},
  author       = {Chen Yang and Shengyang Wu and Tao Liu and Yixuan He and Jingyu Wang and Dongyuan Shi},
  doi          = {10.1016/j.engappai.2025.110462},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110462},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Efficient generation of power system topology diagrams based on graph neural network},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing small satellite image resolution via shrinking
rearranged mechanism and multiscale reparameterized attention.
<em>EAAI</em>, <em>149</em>, 110460. (<a
href="https://doi.org/10.1016/j.engappai.2025.110460">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small satellites, weighing under 1,000 kg, are increasingly used in defense, civil, and commercial sectors due to their cost-effectiveness and portability. However, their imaging resolution is limited by the size and cost of their apertures. Existing super-resolution (SR) algorithms struggle to reconstruct large-area surface information and fine local textures, and often require high computing power, making them unsuitable for small satellites. This study proposes a lightweight super-resolution network, MSRN (Multiscale Shrinking Rearranged Attention Network), engineered for deployment on small satellites. Specifically, MSRN employs a shrinking window-partition strategy to extract different ranges of feature priors and capture local high-frequency details. It also uses a channel rearranged mechanism to expand the receptive field and extract global context information. Additionally, a multiscale reparameterized attention group is designed to efficiently extract features and contours of objects at various scales, enhancing channel information representation. The use of reparameterization technology simplifies the model and enables fast response and processing of small satellite image data. Multiple comparisons on several popular public remote sensing datasets demonstrate that MSRN outperforms mainstream methods in terms of resource occupancy and reconstruction performance, and exhibits strong robustness and generalization across different scenarios.},
  archive      = {J_EAAI},
  author       = {Zhibo Zhao and Hu Liang and Yuchen Liu and Shengrong Zhao},
  doi          = {10.1016/j.engappai.2025.110460},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110460},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing small satellite image resolution via shrinking rearranged mechanism and multiscale reparameterized attention},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantically complex audio to video generation with audio
source separation. <em>EAAI</em>, <em>149</em>, 110457. (<a
href="https://doi.org/10.1016/j.engappai.2025.110457">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in artificial intelligence for audio-to-video generation have shown the ability to generate high-quality videos from audio, particularly by focusing on temporal semantics and magnitude. However, existing works struggle to capture all semantics from audio, as real world audios often consist of mixed sources, making it challenging to generate semantically aligned videos. To solve this problem, we present a novel multi-source audio-to-video generation framework that incorporates decomposed multiple audio sources into video generative models. Specifically, our proposed Attention Mosaic directly maps each decomposed audio feature to the corresponding spatial attention feature. In addition, our condition injection module is helpful for producing more natural contexts with non-audible objects by leveraging the knowledge of existing generative models. Our experiments show that the proposed framework achieves state-of-the-art performance in representing both multi- and single-source audio-to-video generation methods.},
  archive      = {J_EAAI},
  author       = {Sieun Kim and Jaehwan Jeong and Sumin In and Seung Hyun Lee and Seungryong Kim and Saerom Kim and Wooyeol Baek and Sang Ho Yoon and Eugenio Culurciello and Sangpil Kim},
  doi          = {10.1016/j.engappai.2025.110457},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110457},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Semantically complex audio to video generation with audio source separation},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel multivariate nonlinear time-delayed grey model for
forecasting electricity consumption. <em>EAAI</em>, <em>149</em>,
110452. (<a
href="https://doi.org/10.1016/j.engappai.2025.110452">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and stable annual electricity consumption forecasting play vital role in modern social and economic development, which can provide effective planning and guaranteeing a reliable supply of sustainable electricity. Given that electricity consumption series present nonlinearity, poor information, and time-delayed characteristics, this paper proposes a multivariate nonlinear time-delayed grey model. Three primary efforts have been made as follows. First, we introduce the nonlinear and time-delayed terms into the typical multivariate grey model to identify the relationship between electricity consumption sequence and its driving factor sequence. Second, based on the Monte-Carlo simulation, an intelligent algorithm matching framework is designed to seek for the optimal model parameters of the model, which enhances the model’s applicability and flexibility. Third, we use datasets of China’s and America’s electricity consumption from 2000 to 2021 to validate the effectiveness of the newly-proposed model. Additionally, sensitivity analysis under different time horizons further verifies the model’s robustness. The experiment results indicates the superior prediction accuracy and robustness when comparing with other prevailing benchmarks. Overall, the newly-designed model is an effective technique for forecasting electricity consumption in China and America. Based on this, the forecasts of China’s and America’s electricity consumption in the following years can serve as a valuable reference for formulating related policies.},
  archive      = {J_EAAI},
  author       = {Wen-Ze Wu and Naiming Xie},
  doi          = {10.1016/j.engappai.2025.110452},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110452},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel multivariate nonlinear time-delayed grey model for forecasting electricity consumption},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep reinforcement learning assisted adaptive genetic
algorithm for flexible job shop scheduling. <em>EAAI</em>, <em>149</em>,
110447. (<a
href="https://doi.org/10.1016/j.engappai.2025.110447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The flexible job shop scheduling problem (FJSP) is a challenging combinatorial optimization problem in manufacturing systems. Existing intelligent optimization algorithms for FJSP are often hard to tune key parameters and operations efficiently, which losses the optimality of the obtained solution. To address the issues of genetic algorithms (GA) being prone to local optima and slow convergence, this paper proposes a deep reinforcement learning-assisted adaptive genetic algorithm (DRL-A-GA) for solving FJSP. In the proposed algorithm, continuous state vectors are used to represent the population state of the GA, and four mutation operations with respect to FJSP are designed as actions. Deep reinforcement learning is employed to adaptively tune the key parameters of the GA and dynamically select appropriate genetic operations. To validate the performance of DRL-A-GA, three sets of benchmark instances are selected for testing, and the results are compared with those of classical optimization algorithms and hybrid algorithms. The experimental results demonstrate that the proposed DRL-A-GA significantly outperforms both traditional optimization and intelligent hybrid optimization algorithms for solving FJSP, effectively improving solution quality and accelerating convergence.},
  archive      = {J_EAAI},
  author       = {Jian Ma and Weinan Gao and Weitian Tong},
  doi          = {10.1016/j.engappai.2025.110447},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110447},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep reinforcement learning assisted adaptive genetic algorithm for flexible job shop scheduling},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An enhanced artificial bee colony algorithm with
self-learning optimization mechanism for multi-objective path planning
problem. <em>EAAI</em>, <em>149</em>, 110444. (<a
href="https://doi.org/10.1016/j.engappai.2025.110444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, path planning has been one of the most concerned problems in mobile robotics. This study investigates a multi-objective path planning problem focused on minimizing path length and maximizing path safety. Based on the characteristics of this problem, a mathematical model is established, and then an enhanced artificial bee colony algorithm is proposed to solve this problem. In the proposed algorithm, a new hybrid initialization strategy is designed to generate a high-quality initial population. In the employed bee phase, in addition to the crossover and mutation operators, two objective-oriented evolutionary operators are developed. In the onlooker bee phase, two self-learning optimization mechanisms are applied to the non-dominated and dominated individuals, respectively. Specifically, the collaborative-based optimization mechanism is designed to improve the quality of the non-dominated individuals. The dominance-guide optimization mechanism is developed to guide the dominated individuals to learn from the non-dominated ones. In the scout bee phase, a novel individual-restart strategy that considers the useful information of global best solutions is investigated, which increases the proposed algorithm’s exploration ability. Finally, the proposed algorithm is compared with five state-of-the-art algorithms on sixteen instances from four representative environments. Simulation results show that the proposed algorithm achieved average improvements of 2.60% and 90.77% on the hypervolume and inverted generational distance metrics, respectively, compared with the algorithm with the second-best performance. These demonstrate the effectiveness and high performance of the proposed algorithm for solving multi-objective path planning problems in terms of both population diversity and solution quality.},
  archive      = {J_EAAI},
  author       = {Fan Ye and Peng Duan and Leilei Meng and Hongyan Sang and Kaizhou Gao},
  doi          = {10.1016/j.engappai.2025.110444},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110444},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An enhanced artificial bee colony algorithm with self-learning optimization mechanism for multi-objective path planning problem},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An effective exploration method based on n-step updated
dirichlet distribution and dempster–shafer theory for deep reinforcement
learning. <em>EAAI</em>, <em>149</em>, 110443. (<a
href="https://doi.org/10.1016/j.engappai.2025.110443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning (DRL) has been regarded as a promising approach for solving decision-making problems. However, how to enhance the agent exploration ability is still an extremely challenging issue for existing methods, especially under sparse rewards. Facing with this challenge, we propose a novel efficient exploration method, which can comprehensively consider the uncertainty of the environment and the uncertainty of Q function, so as to improve the agent exploration efficiency. Specifically, we first construct an exploration policy by n-step updated Dirichlet distribution to implement the adaptive exploration of the agent to the environment, which can reduce the uncertainty of the agent about the environment to achieve global efficient exploration. Next, a state–action basic probability assignment (BPA) is constructed based on the Dempster–Shafer theory. On this basis, an interval Q function is designed by combining BPA and belief interval, which can effectively characterize the uncertainty of the Q function to achieve deep exploration. Then, the proposed method is applied to classic DRL algorithms, deep Q-network (DQN) and double DQN (DDQN), two novel algorithms are proposed. Finally, under a series of sparse external reward tasks, experimental results show that our proposed algorithms outperform several state-of-the-art DRL algorithms in term of exploring efficiency.},
  archive      = {J_EAAI},
  author       = {Fanghui Huang and Yixin He and Yu Zhang and Bin Chen and Lina Yang},
  doi          = {10.1016/j.engappai.2025.110443},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110443},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An effective exploration method based on N-step updated dirichlet distribution and Dempster–Shafer theory for deep reinforcement learning},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HMKRec: Optimize multi-user representation by hypergraph
motifs for knowledge-aware recommendation. <em>EAAI</em>, <em>149</em>,
110441. (<a
href="https://doi.org/10.1016/j.engappai.2025.110441">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph-based recommender systems can explore users’ potential interests by learning user similarities, thereby further improving recommendation performance. However, existing methods focus only on the similarity between two users without considering the interaction patterns among multiple users, which overlook the influence of other users in user representation modeling. In this paper, we propose a novel framework using Hypergraph Motifs to optimize Multi-users representation for Recommendation (HMKRec). Specifically, HMKRec constructs a user–item hypergraph and maps it into a user–user adjacency graph. Then, it utilizes hypergraph motifs to model the interaction patterns of multiple users and reconstructs an implicit relationship network with weights and directions to explore high-order associations among multiple users. To learn the features of items and user relationships, we design a hierarchical graph convolution that integrates hypergraph convolutional networks and graph convolutional networks to obtain high-order representations of users. Finally, we propagate user preferences in the knowledge graph using the attention mechanism to obtain high-order representations of items for recommendation. Extensive experiments on three real-world datasets indicate that our method achieves at least a 1% performance improvement over the best-performing state-of-the-art baselines.},
  archive      = {J_EAAI},
  author       = {Di Wu and Mingjing Tang and Shu Zhang and Wei Gao},
  doi          = {10.1016/j.engappai.2025.110441},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110441},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {HMKRec: Optimize multi-user representation by hypergraph motifs for knowledge-aware recommendation},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive traffic signal control scheme with proximal
policy optimization based on deep reinforcement learning for a single
intersection. <em>EAAI</em>, <em>149</em>, 110440. (<a
href="https://doi.org/10.1016/j.engappai.2025.110440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive traffic signal control (ATSC) is an important means to alleviate traffic congestion and improve the quality of road traffic. Although deep reinforcement learning (DRL) technology has shown great potential in solving traffic signal control problems, the state representation and reward design, as well as action interval time, still need to be further studied. The advantages of policy learning have not been fully applied in TSC. To address the aforementioned issues, we propose a DRL-based traffic signal control scheme with Poximal Policy Optimization (PPO-TSC). We use the waiting time of vehicles and the queue length of lanes represented the spatiotemporal characteristics of traffic flow to design the simplified traffic states feature vectors, and define the reward function that is consistent with the state. Additionally, we compare and analyze the performance indexes obtained by various methods using action intervals of 5s, 10s, and 15s. The algorithm is implemented based on the Actor-Critic architecture, using the advantage estimation and the clip mechanism to constrain the range of gradient updates. We validate the proposed scheme at a single intersection in Simulation of Urban MObility (SUMO) under two different traffic demand patterns of flat traffic and peak traffic. The experimental results show that the proposed method is significantly better than other compared methods. Specifically, PPO-TSC demonstrates a reduction of 24% in average travel time (ATT), a decrease of 45% in the average time loss (ATL), and an increase of 16% in average speed (AS) compared with the existing methods under peak traffic condition.},
  archive      = {J_EAAI},
  author       = {Lijuan Wang and Guoshan Zhang and Qiaoli Yang and Tianyang Han},
  doi          = {10.1016/j.engappai.2025.110440},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110440},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An adaptive traffic signal control scheme with proximal policy optimization based on deep reinforcement learning for a single intersection},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generative adversarial network-based inverse design of
self-deploying soft kirigami composites for targeted shape
transformation. <em>EAAI</em>, <em>149</em>, 110417. (<a
href="https://doi.org/10.1016/j.engappai.2025.110417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design and development of morphing structures that transition from compact, transportable forms to stable, deployable configurations is crucial for advances in soft robotics, healthcare applications, and biomimetic systems. These structures often require customized functionalities and must self-deploy into precise target shapes. Therefore, the deformed shapes of such structures are usually prescribed and the parameters for their design are unknown. To obtain the fabrication parameters, the inverse problem needs to be solved, which quickly becomes quite challenging using conventional methods due to the high-dimensional nature of the inverse problem as well as the material and geometric nonlinearities. To overcome these challenges, we combine the best of the two worlds – physics and data – and present a data-driven approach for the inverse design of two-layered soft composites that utilize the principles of kirigami and strain mismatch to self-deploy into different three-dimensional shapes. At the center of our methodology is the generative adversarial network, designed to generate the necessary fabrication parameters. By using a pre-trained simulator network, we condition the generative model to generate feasible and accurate fabrication parameters that are used to make composites that deploy into the target shapes. Our findings demonstrate that the generative model is able to effectively predict kirigami patterns and pre-stretch values required to realize complex three-dimensional shapes from simple and diverse planar designs. By performing simulations and precise desktop experiments, we compare the target with deployed shapes and demonstrate the predictive capacity of the method.},
  archive      = {J_EAAI},
  author       = {Tomaž Brzin and M. Khalid Jawed and Miha Brojan},
  doi          = {10.1016/j.engappai.2025.110417},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110417},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Generative adversarial network-based inverse design of self-deploying soft kirigami composites for targeted shape transformation},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image retrieval using deep saliency edge feature.
<em>EAAI</em>, <em>149</em>, 110416. (<a
href="https://doi.org/10.1016/j.engappai.2025.110416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploiting a compact representation has become a hotspot in deep learning-based image retrieval. Fine-tuning the deep networks can provide the high discriminating representations, but it is very difficult to obtain sufficient labeled data. However, using the unsupervised methods to provide efficient representations remains challenging. Therefore, we propose a compact and robust representation, namely deep saliency edge feature (DSEF), to image retrieval. Its main highlights are: (1) Color differences, spatial layout, and edge cues within various object regions are combined into saliency edge feature maps. It can reflect a large amount of discriminative information contain in deep feature maps, thereby improving the discriminative power of deep features. (2) Edge cues are utilized to highlight the rough targets contained in deep feature maps. It can reduce the semantic disconnect exists in the different kinds of features and promote the compatibility of deep features and handcrafted features, thereby providing convenience to combine them. (3) A feature aggregation method, namely crucial cues aggregation, is proposed to aggregate crucial cues hidden inside handcrafted features and deep feature maps into a compact and high discriminating representation. Comparative experiments demonstrated that our method has provided the outstandingly retrieval performance on some benchmark datasets. The mean average precision of our method is 2.9%, 4.6%, 3.2%, 6.0% and 3.7% higher than that of most methods on the Oxford5K, Paris6K, Oxford105K, Paris106K and Holidays datasets, respectively.},
  archive      = {J_EAAI},
  author       = {Zhou Lu and Guang-Hai Liu and Zuo-Yong Li and Bo-Jian Zhang},
  doi          = {10.1016/j.engappai.2025.110416},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110416},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Image retrieval using deep saliency edge feature},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SlimDL: Deploying ultra-light deep learning model on
sweeping robots. <em>EAAI</em>, <em>149</em>, 110415. (<a
href="https://doi.org/10.1016/j.engappai.2025.110415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced object detection methods have yielded impressive progress in recent years. However, the computational constraints of edge mobile devices present significant deployment challenges for state-of-the-art algorithms. We propose a deep learning deployment framework with two stages: model adaptation and compression. Our method enhance “You Only Look Once version 5” (YOLOv5) with lightweight modules, which improves detection performance while reducing computational load. Additionally, we present a pruning algorithm, employing adaptive batch normalization and iterative pruning. Our evaluation on “Microsoft Common Objects in Context” (MSCOCO) dataset and custom SweepRobot datasets demonstrates that our method consistently outperforms state-of-the-art approaches. On the SweepRobot dataset, our method doubled YOLOv5’s detection speed on the sweeping robot from 15.69 frames per second (FPS) to 30.77 FPS, maintaining 97.3% performance at 20% of the computational cost. Even on Graphics Processing Unit equipped devices, our method achieved 1.8% and 2.8% higher Average Precision compared to direct scaling and pruning with the original pruning algorithm.},
  archive      = {J_EAAI},
  author       = {Xudong Sun and Yu Wang and Zhanglin Liu and Shaoxuan Gao and Wenbo He and Chao Tong},
  doi          = {10.1016/j.engappai.2025.110415},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110415},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {SlimDL: Deploying ultra-light deep learning model on sweeping robots},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel group decision-making method for incomplete
interval-valued intuitionistic multiplicative linguistic preference
relations. <em>EAAI</em>, <em>149</em>, 110412. (<a
href="https://doi.org/10.1016/j.engappai.2025.110412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By conducting pairwise comparisons, decision-makers can construct interval-valued intuitionistic multiplicative linguistic preference relations (IVIMLPRs) to express the asymmetrically uncertain preferred and non-preferred qualitative judgments. Based on the consistency and consensus analysis, this paper proposes a new group decision-making (GDM) method with incomplete IVIMLPRs. Firstly, a reasonable and rational concept for IVIMLPR is defined. Inspired by the consistent intuitionistic multiplicative linguistic preference relations (IMLPRs), the consistency of IVIMLPRs is expressed by considering the corresponding lower and upper IMLPRs. After that, the acceptably consistent IVIMLPR is further introduced. Based on these concepts, two optimization models are constructed to estimate the missing linguistic variables and adjust an unacceptably consistent IVIMLPR, respectively. To obtain the priority weights from IVIMLPR in a reliable way, the consistency modeling method is employed. Before calculating the collective IVIMLPR, the weights of decision-makers are determined. Subsequently, the consensus analysis is conducted. If the consensus of an IVIMLPR is insufficient, a mathematical model is established to enhance the consensus level. Finally, the applications of the proposed GDM approach are offered and the comparative analysis is discussed. Compared with some existing methods, the proposed decision-making algorithm can perform a rational and effective process in the field of artificial intelligence computing.},
  archive      = {J_EAAI},
  author       = {Tao Li and Liyuan Zhang},
  doi          = {10.1016/j.engappai.2025.110412},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110412},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel group decision-making method for incomplete interval-valued intuitionistic multiplicative linguistic preference relations},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High frequency volatility forecasting and risk assessment
using neural networks-based heteroscedasticity model. <em>EAAI</em>,
<em>149</em>, 110397. (<a
href="https://doi.org/10.1016/j.engappai.2025.110397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High frequency volatility forecasting is essential for timely risk management and informed decision-making in dynamic financial markets. However, accurate forecasting is challenging due to the rapid nature of market movements and the complexity of underlying economic factors. This paper introduces a novel architecture combining Generalized Autoregressive Conditional Heteroscedasticity (GARCH) and Multi-layer Perceptron (MLP)-based models for enhanced volatility forecasting and risk assessment, where input variables are processed through GARCH-type models for volatility forecasting. The proposed GARCH-based MLP-Mixer (GaMM) model incorporates the stacking of multi-layer perceptrons, enabling deep representation learning, facilitating the extraction of temporal and feature information through operations along both time and feature dimensions, and addressing the complexity of high-frequency time-series data. The proposed model is evaluated on three high frequency financial times series datasets over three different years. The computational results demonstrate the proposed model’s superior performance over sixteen forecasting methods in three error metrics, Value-at-risk, and statistical tests for high frequency volatility forecasting and risk assessment tasks.},
  archive      = {J_EAAI},
  author       = {Aryan Bhambu and Koushik Bera and Selvaraju Natarajan and Ponnuthurai Nagaratnam Suganthan},
  doi          = {10.1016/j.engappai.2025.110397},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110397},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {High frequency volatility forecasting and risk assessment using neural networks-based heteroscedasticity model},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning based multi-perspective motion
planning of manned electric vertical take-off and landing vehicle in
urban environment with wind fields. <em>EAAI</em>, <em>149</em>, 110392.
(<a href="https://doi.org/10.1016/j.engappai.2025.110392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electric vertical-takeoff and landing (eVTOL) aircraft, known for their maneuverability and flexibility, offer a promising alternative to traditional transportation systems. However, these aircraft face significant challenges from various perspectives, including the need to increase energy efficiency, enhance passenger experience, and mitigate noise impact on urban environments. While mathematical modeling-based approaches have been employed for flight motion planning, they often struggle to adapt to dynamic and complex environments. In this work, we introduce a three-dimensional motion planning method based on deep reinforcement learning (DRL), tailored for manned eVTOL flights through urban wind fields. Our approach considers three crucial aspects: aircraft energy consumption, passenger experience, and noise impact on urban environment. We modify the Proximal Policy Optimization (PPO) algorithm and design comprehensive reward function that considers these objectives. By incorporating energy efficiency, passenger experience, and noise impact into our reward function, our method demonstrates improved policy learning compared to existing approaches. Comparative experiments conducted under various wind conditions show that our method outperforms commonly used techniques, effectively optimizing multiple objectives in challenging urban environments. Code of our work are available at https://github.com/cgchrfchscyrh/eVTOL_RL/tree/main.},
  archive      = {J_EAAI},
  author       = {Songyang Liu and Weizi Li and Haochen Li and Shuai Li},
  doi          = {10.1016/j.engappai.2025.110392},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110392},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reinforcement learning based multi-perspective motion planning of manned electric vertical take-off and landing vehicle in urban environment with wind fields},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leverage points in the bitcoin ecosystem: Impact on price
and climate change using dynamic systems and spherical fuzzy sets.
<em>EAAI</em>, <em>149</em>, 110390. (<a
href="https://doi.org/10.1016/j.engappai.2025.110390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the significant increase in Bitcoin&#39;s price to around $108,000 in 2025 and its growth of 100% in 2024, scrutiny of the Bitcoin ecosystem and its influencing factors is of particular importance. The research aims to provide a comprehensive model for analyzing the Bitcoin ecosystem in forecasting the factors affecting it.This research used the Total Interpretive Structural Modeling method (TISM) to come up with ideas, the Spherical Fuzzy Decision Making Trial And Evaluation method (SF-DEMATEL) to find and look into how the indices related to each other, and the Spherical Fuzzy Step-Wise Weight Assessment Ratio Analysis method (SF-SWARA) to figure out how important the indices were. The findings identify control rules (0.222) and network security (0.196) as the most fundamental factors.Also, price (0.107) and Bitcoin value (0.089) are the most important among the influencing factors, while other cryptocurrencies have a lesser impact on the Bitcoin ecosystem (0.037). Analyses conducted using System Dynamics (SD) modeling showed that policies that increase control rules or improve tool quality by 50% can directly affect Bitcoin&#39;s price and climate change. The leverage point&#39;s analysis showed that stakeholders can contribute to the long-term sustainability of the Bitcoin ecosystem by strategically managing control rules, tool quality, network capacity, and turnover. The research presents a hybrid approach (SF &amp; SD) to analyze the complexities and uncertainties of the Bitcoin ecosystem.The research implications can aid market participants in comprehending the Bitcoin ecosystem, forecasting Bitcoin prices, and assisting policymakers in implementing suitable regulations for the sustainable growth of this sector.},
  archive      = {J_EAAI},
  author       = {Saeed Alinejad and Zahra Khoshsepehr and Javad Nazarian-Jashnabadi and Samira Ebrahimi},
  doi          = {10.1016/j.engappai.2025.110390},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110390},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Leverage points in the bitcoin ecosystem: Impact on price and climate change using dynamic systems and spherical fuzzy sets},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Influence factor-based transformation method for translating
mass function to probability in dempster–shafer evidence theory.
<em>EAAI</em>, <em>149</em>, 110385. (<a
href="https://doi.org/10.1016/j.engappai.2025.110385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dempster–Shafer evidence theory provides an effective mathematical tool to represent uncertain information by assigning information into power set. Among its associated studies, a pivotal challenge is the transformation of mass functions into probability distributions which can enhance the robustness and reliability of decision-making. In this paper, influence factor is constructed by considering the impact of transformation between multi-element propositions and single-element propositions. Then based on influence factor, the novel transformation method is proposed. In addition, some numerical examples are used to explain effectiveness of new method by analyzing the probability information capacity of different methods. Finally, this paper applies the novel method to target recognition and validates its effectiveness as well as its enhanced support for decision-making through the utilization of real-world datasets.},
  archive      = {J_EAAI},
  author       = {Haocheng Shao and Lipeng Pan and Jiahui Chen and Xiaozhuan Gao and BingYi Kang},
  doi          = {10.1016/j.engappai.2025.110385},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110385},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Influence factor-based transformation method for translating mass function to probability in Dempster–Shafer evidence theory},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). REDIBAGG: Reducing the training set size in ensemble machine
learning-based prediction models. <em>EAAI</em>, <em>149</em>, 110382.
(<a href="https://doi.org/10.1016/j.engappai.2025.110382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning-based algorithms have gained wide acceptance over the years due to their high generalization capabilities for a wide range of classification applications. Although these algorithms demonstrate potential and promising performance, they are often limited by speed, particularly when training on large databases. Big data sets with many instances have storage requirements and execution times that can be excessive. This study proposes reducing the sample size generated by the bootstrap resampling method in Ensemble Machine Learning-based models and evaluates their generalization capability on unknown data. Reduced bootstrap samples are employed in the training phase of the Bagging ensemble model. This approach reduces execution times and, consequently, storage requirements. The proposed method was tested on classification tasks, effectively reducing training subset size without compromising performance. Experimental results demonstrate that this approach achieves execution times reductions of up to 70% for some data sets. This reduction has no impact on accuracy, whereas maintaining levels comparable to classical Bagging and its variants. On average, the training subset size was reduced by 25% compared to the original size.},
  archive      = {J_EAAI},
  author       = {Esther-Lydia Silva-Ramírez and Juan-Francisco Cabrera-Sánchez and Manuel López-Coello},
  doi          = {10.1016/j.engappai.2025.110382},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110382},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {REDIBAGG: Reducing the training set size in ensemble machine learning-based prediction models},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating permutation feature importance with conformal
prediction for robust explainable artificial intelligence in predictive
process monitoring. <em>EAAI</em>, <em>149</em>, 110363. (<a
href="https://doi.org/10.1016/j.engappai.2025.110363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As artificial intelligence (AI) systems are increasingly deployed in high-stakes environments, the need for explanations that convey uncertain information has become evident. Conventional explainable AI (XAI) methods often overlook uncertainty, focusing solely on point predictions. To address this gap, we propose using permutation feature importance (PFI) combined with predictive uncertainty evaluation measures. This novel approach examines the significance of features by relating them to the model’s confidence in its predictions. By using split conformal prediction (SCP) to quantify predictive uncertainty and integrating the outcomes to PFI, we aim to enhance the robustness and interpretability of machine learning (ML) algorithms. More importantly, we examine three scenarios for conformal prediction-based PFI explanations: permuting feature values in the test data, the calibration data, and both. These scenarios assess the impact of feature permutations from different perspectives, revealing feature sensitivity and the importance of features in various settings. We also perform a series of sensitivity analyses, particularly exploring calibration data size and computational efficiency, to demonstrate the robustness and scalability of our approach for industrial applications. Our comprehensive evaluation offers insights into feature impact on predictions and their associated confidence levels. We validate our proposed approach through a real-world predictive process monitoring use case in manufacturing.},
  archive      = {J_EAAI},
  author       = {Nijat Mehdiyev and Maxim Majlatow and Peter Fettke},
  doi          = {10.1016/j.engappai.2025.110363},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110363},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Integrating permutation feature importance with conformal prediction for robust explainable artificial intelligence in predictive process monitoring},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust sparse identification of nonlinear dynamics
approach by combining neural networks and an integral form.
<em>EAAI</em>, <em>149</em>, 110360. (<a
href="https://doi.org/10.1016/j.engappai.2025.110360">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One widely used methodology for uncovering governing equations from data is sparse regression for nonlinear dynamics, commonly known as Sparse Identification of Nonlinear Dynamics ( SINDy ). However, noisy and limited data remain a significant challenge for the success of the SINDy approach. In this work, we propose a robust strategy to discover nonlinear governing equations from both noisy and scarce data. Specifically, we employ neural networks to learn an implicit representation from measurement data, thereby ensuring that the network output remains close to the measurements while also admitting a dynamical system interpretation for its time evolution. Moreover, we identify this dynamical system in the spirit of the SINDy framework. By leveraging the neural network’s implicit representation, we employ automatic differentiation to obtain the derivative information required by SINDy . To further enhance the robustness of our approach, we incorporate an integral constraint on the output of the implicit networks. In addition, we extend our method to handle data acquired from multiple initial conditions. Through several examples, we demonstrate the proposed method’s effectiveness in discovering governing equations under noisy, data-scarce conditions and compare its performance against existing methods.},
  archive      = {J_EAAI},
  author       = {Ali Forootani and Pawan Goyal and Peter Benner},
  doi          = {10.1016/j.engappai.2025.110360},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110360},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A robust sparse identification of nonlinear dynamics approach by combining neural networks and an integral form},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-domain facial expression recognition: Bi-directional
fusion of active and stable information. <em>EAAI</em>, <em>149</em>,
110357. (<a
href="https://doi.org/10.1016/j.engappai.2025.110357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial expression recognition (FER) algorithms often encounter obstacles in cross-domain scenarios, attributed to variations in collection conditions such as lighting, weather, age, gender, and skin color of subjects. Unlike existing approaches that primarily focus on extracting globally invariant features and aligning domain distributions, we propose a novel framework that fundamentally shifts the approach to cross-domain FER. Our proposed algorithm, termed Bi-Directional Fusion of Active and Stable Information (FER-DAS), uniquely combines three innovative components: the Active Assessment Strategy (AAS), Cross-Domain Dynamic Class Threshold (CD-DCT), and Weighted Cross-Domain Alignment (WCDA). The AAS component selectively identifies and enhances active samples in the target domain, providing precise annotations for improved model robustness. Samples with the highest uncertainty are deemed active, indicating low prediction confidence and high informational value for model training. These are then filtered using a predefined threshold to ensure only the most informative samples are included in training iterations. In contrast to conventional static threshold techniques, our dynamic class threshold strategy (CD-DCT) adaptively filters stable samples across domains, thereby ensuring that only the most reliable information is utilized in training. The WCDA strategy further refines this process by dynamically assessing and weighting the contribution of target domain samples to class centers, effectively mitigating domain distribution discrepancies. Extensive experiments on multiple benchmark datasets confirm that FER-DAS sets a new standard in cross-domain FER, consistently outperforming existing state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Yanan Zhu and Jiaqiu Ai and Weibao Xue and Mingyang Wu and Sen Yang and Wei Jia and Min Hu},
  doi          = {10.1016/j.engappai.2025.110357},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110357},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cross-domain facial expression recognition: Bi-directional fusion of active and stable information},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Depression and anxiety detection method based on serialized
facial expression imitation. <em>EAAI</em>, <em>149</em>, 110354. (<a
href="https://doi.org/10.1016/j.engappai.2025.110354">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial recognition techniques are widely employed for automatic detection of depression and anxiety. However, current studies overlook the impact of varying spatial resolutions on model performance and lack a mechanism to share attention regions across sequential data. To advance research in this area, we conducted the Voluntary Facial Expression Mimicry Experiment (VFEM) and constructed the VFEM dataset. We also introduce the SFE-Former, a sequential facial expression recognition model designed for detecting depression and anxiety. SFE-Former features a mechanism that shares attention regions across sequence data, allowing each data point to enhance its features by leveraging shared information. Additionally, the model integrates features from different scales using fusion and weighting strategies. The experimental results indicate that SFE-Former achieved impressive accuracy rate: 0.893 for depression detection, 0.889 for anxiety detection, and 0.780 for co-occurrence detection of depression and anxiety. Meanwhile, SFE-Former also obtained state-of-the-art (SOAT) results on AVEC2014 dataset. This work can enhance the accuracy of identifying patients with depression and anxiety, providing doctors with reliable auxiliary diagnosis. The source code for SFE-Former is accessible at https://github.com/lulin-6k/SFE-Former .},
  archive      = {J_EAAI},
  author       = {Lin Lu and Yan Jiang and Xingyun Li and Hao Wang and Qingzhi Zou and Qingxiang Wang},
  doi          = {10.1016/j.engappai.2025.110354},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110354},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Depression and anxiety detection method based on serialized facial expression imitation},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Goal-oriented graph generation for transmission expansion
planning. <em>EAAI</em>, <em>149</em>, 110350. (<a
href="https://doi.org/10.1016/j.engappai.2025.110350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The electrification strategies that are being designed to meet sustainability objectives and rising energy demands pose significant challenges for power systems worldwide and require Transmission Expansion Planning (TEP). This study adopts a risk-informed approach to TEP, formulated as a multi-objective optimization problem that concurrently minimizes systemic risks and expansion costs. Given the intractability of this problem with conventional solvers, we turn to artificial intelligence techniques. In particular, we conceptualize power grids as graphs and introduce a goal-oriented graph generation methodology using deep reinforcement learning. We extend welfare-Q learning, a modified variant of Q-learning tailored to yield high rewards across multiple dimensions, by incorporating geometric deep learning for function approximation. This allows us to account for system security while minimizing grid expansion costs. Notably, system risk is evaluated by incorporating a Graph Neural Network (GNN) cascading failure meta-model into the proposed approach. The TEP method is applied to the IEEE 118-bus system, and the efficacy of this novel technique is compared against the state of the art. We conclude that the deep reinforcement learning method can compete with established methods for multi-objective optimization, identifying expansion strategies that improve system security at reduced costs. Furthermore, we test the robustness of the meta-model against topology changes in the transmission network, demonstrating its applicability to novel grid configurations.},
  archive      = {J_EAAI},
  author       = {Anna Varbella and Blazhe Gjorgiev and Federico Sartore and Enrico Zio and Giovanni Sansavini},
  doi          = {10.1016/j.engappai.2025.110350},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110350},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Goal-oriented graph generation for transmission expansion planning},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dealing with zero-inflated data: Achieving state-of-the-art
with a two-fold machine learning approach. <em>EAAI</em>, <em>149</em>,
110339. (<a
href="https://doi.org/10.1016/j.engappai.2025.110339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many cases, a machine learning model must learn to correctly predict a few data points with particular values of interest in a broader range of data where many target values are zero. Zero-inflated data can be found in diverse scenarios, such as lumpy and intermittent demands, power consumption for home appliances being turned on and off, impurities measurement in distillation processes, and even airport shuttle demand prediction. The presence of zeroes affects the models’ learning and may result in poor performance. Furthermore, zeroes also distort the metrics used to compute the model’s prediction quality. This paper showcases two real-world use cases (home appliances classification and airport shuttle demand prediction) where a hierarchical model applied in the context of zero-inflated data leads to considerable performance improvements. In particular, for home appliances classification, the weighted average of Precision, Recall, F1, and Area Under the Receiver Operating Characteristic Curve (AUC ROC) was increased by 39%, 49%, 88%, and 48%, respectively. Furthermore, it is estimated that the proposed approach is also four times more energy efficient than the state-of-the-art (SOTA) approach against which it was compared to. Two-fold modeling approaches significantly outperform regular regression, especially when predicting the occurrence of demand events. SOTA results were achieved using Gradient Boosting trees to determine whether an event will occur and Visual Geometry Group (VGG) or Support Vector Regressor (SVR) models for the subsequent classification/regression. The code has been released at two separate repositories.},
  archive      = {J_EAAI},
  author       = {Jože M. Rožanec and Gašper Petelin and João Costa and Gregor Cerar and Blaž Bertalanič and Marko Guček and Gregor Papa and Dunja Mladenić},
  doi          = {10.1016/j.engappai.2025.110339},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110339},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dealing with zero-inflated data: Achieving state-of-the-art with a two-fold machine learning approach},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid EfficientNet feed forward neural network for
ransomware detection in blockchain. <em>EAAI</em>, <em>149</em>, 110292.
(<a href="https://doi.org/10.1016/j.engappai.2025.110292">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ransomware, a type of malware, threatens to encrypt or block access to data until a ransom is paid, causing severe financial and operational impacts. Detecting ransomware in blockchain environments is crucial due to its increasing prevalence and the need for robust security measures. This research proposes an EfficientNet Feed Forward Neural Network (EFFNN) model for ransomware detection in blockchain. Initially, sequence-based statistical features are extracted from blockchain data and normalized using linear normalization. Feature selection is performed with Kumar Hassebrook and Czekanowski’s similarity measures to enhance relevant feature identification. The Hybrid EFFNN, integrating EfficientNet and Deep Feed Forward Neural Networks (DFFNN), is employed for detection. The model achieved high performance, with a True Negative Rate (TNR) of 0.960, accuracy of 0.955, and True Positive Rate (TPR) of 0.821, demonstrating its efficacy in identifying ransomware in blockchain systems.},
  archive      = {J_EAAI},
  author       = {Balajee Maram and Neelima Gullipalli and Rudra Kalyan Nayak and Ramamani Tripathy and Satish Muppidi and Madan Lal Saini},
  doi          = {10.1016/j.engappai.2025.110292},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110292},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybrid EfficientNet feed forward neural network for ransomware detection in blockchain},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unlocking language barriers: Assessing pre-trained large
language models across multilingual tasks and unveiling the black box
with explainable artificial intelligence. <em>EAAI</em>, <em>149</em>,
110136. (<a
href="https://doi.org/10.1016/j.engappai.2025.110136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have revolutionized many industrial applications and paved the way for fostering a new research direction in many fields. Conventional Natural Language Processing (NLP) techniques, for instance, are no longer necessary for many text-based tasks, including polarity estimation, sentiment and emotion classification, and hate speech detection. However, training a language model for domain-specific tasks is hugely costly and requires high computational power, thereby restricting its true potential for standard tasks. This study, therefore, provides a comprehensive analysis of the latest pre-trained LLMs for various NLP-related applications without fine-tuning them to evaluate their effectiveness. Five language models are thus employed in this study on six distinct NLP tasks (including emotion recognition, sentiment analysis, hate speech detection, irony detection, offensiveness detection, and stance detection) for 12 languages from low- to medium- and high-resource. Generative Pre-trained Transformer 4 (GPT-4) and Gemini Pro outperform state-of-the-art models, achieving average F1 scores of 70.6% and 68.8% on the Tweet Sentiment Multilingual dataset compared to the state-of-the-art average F1 score of 66.8%. The study further interprets the findings obtained by the LLMs using Explainable Artificial Intelligence (XAI). To the best of our knowledge, it is the first time any study has employed explainability on pre-trained language models.},
  archive      = {J_EAAI},
  author       = {Muhamet Kastrati and Ali Shariq Imran and Ehtesham Hashmi and Zenun Kastrati and Sher Muhammad Daudpota and Marenglen Biba},
  doi          = {10.1016/j.engappai.2025.110136},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110136},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unlocking language barriers: Assessing pre-trained large language models across multilingual tasks and unveiling the black box with explainable artificial intelligence},
  volume       = {149},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
