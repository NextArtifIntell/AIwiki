<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SIIMS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="siims---66">SIIMS - 66</h2>
<ul>
<li><details>
<summary>
(2022). Adaptive and implicit regularization for matrix completion.
<em>SIIMS</em>, <em>15</em>(4), 2000–2022. (<a
href="https://doi.org/10.1137/22M1489228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The explicit low-rank regularization, e.g., nuclear norm regularization, has been widely used in imaging sciences. However, it has been found that implicit regularization outperforms explicit ones in various image processing tasks. Another issue is that the fixed explicit regularization limits the applicability to broad images since different images favor different features captured by different explicit regularizations. As such, this paper proposes a new adaptive and implicit low-rank regularization that captures the low-rank prior dynamically from the training data. The core of our new adaptive and implicit low-rank regularization is parameterizing the Laplacian matrix in the Dirichlet energy-based regularization, which we call the adaptive and implicit regularization (AIR). Theoretically, we show that the adaptive regularization of AIR enhances the implicit regularization and vanishes at the end of training. We validate AIR&#39;s effectiveness on various benchmark tasks, indicating that the AIR is particularly favorable for the scenarios when the missing entries are nonuniform. The code can be found at https://github.com/lizhemin15/AIR-Net.},
  archive      = {J_SIIMS},
  author       = {Zhemin Li and Tao Sun and Hongxia Wang and Bao Wang},
  doi          = {10.1137/22M1489228},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {2000-2022},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Adaptive and implicit regularization for matrix completion},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Convergence results in image interpolation with the
continuous SSIM. <em>SIIMS</em>, <em>15</em>(4), 1977–1999. (<a
href="https://doi.org/10.1137/22M147637X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assessing the similarity of two images is a complex task that attracts significant efforts in the image processing community. The widely used structural similarity index measure (SSIM) addresses this problem by quantifying a perceptual structural similarity. In this paper we consider a recently introduced continuous SSIM (cSSIM), which allows one to analyze sequences of images of increasingly fine resolutions, and further extend the definition of the index to encompass the locally weighted version that is used in practice. For both the local and the global versions, we prove that the continuous index includes the classical SSIM as a special case, and we provide a precise connection between image similarity measured by the cSSIM and by the $L_2$ norm. Using this connection, we derive bounds on the cSSIM by means of bounds on the $L_2$ error, and we even prove that the two error measures are equivalent in certain circumstances. We exploit these results to obtain precise rates of convergence with respect to the cSSIM for several concrete image interpolation methods, and we further validate these findings by different numerical experiments. This newly established connection paves the way to obtain novel insights into the features and limitations of the SSIM, including on the effect of the local weighted window on the index performances.},
  archive      = {J_SIIMS},
  author       = {Francesco Marchetti and Gabriele Santin},
  doi          = {10.1137/22M147637X},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1977-1999},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Convergence results in image interpolation with the continuous SSIM},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A quantum information-based refoundation of color perception
concepts. <em>SIIMS</em>, <em>15</em>(4), 1944–1976. (<a
href="https://doi.org/10.1137/22M1476071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we deal with the problem of overcoming the intuitive definition of several color perception attributes by replacing them with novel mathematically rigorous ones. Our framework is a quantum-like color perception theory recently developed, which constitutes a radical change of view with respect to the classical Commission Interntional de l&#39;Éclairage models and their color appearance counterparts. We show how quantum information concepts, (e.g., effects, generalized states, postmeasurement transformations, and relative entropy) provide tools that seem to be perfectly fit to model color perception attributes such as brightness, lightness, colorfulness, chroma, saturation, and hue. An illustration of the efficiency of these novel definitions is provided by the rigorous derivation of the so-called lightness constancy phenomenon.},
  archive      = {J_SIIMS},
  author       = {Michel Berthier and Nicoletta Prencipe and Edoardo Provenzi},
  doi          = {10.1137/22M1476071},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1944-1976},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A quantum information-based refoundation of color perception concepts},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Recovery of piecewise smooth density and lamé parameters
from high frequency exterior cauchy data. <em>SIIMS</em>,
<em>15</em>(4), 1910–1943. (<a
href="https://doi.org/10.1137/22M1480951">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider an isotropic elastic medium occupying a bounded domain $\Omega \subset {\mathbb R}^3$ whose density and Lamé parameters are piecewise smooth. In the elastic wave initial value inverse problem, we are given the solution operator for the elastic wave equation, but only outside $\Omega$ and only for initial data supported outside $\Omega$, and we study the recovery of the density and Lamé parameters. For known density, results have recently been obtained using the scattering control method to recover wave speeds. Here, we extend this result to include the recovery of the density in addition to the Lamé parameters under certain geometric conditions using techniques from microlocal analysis and a connection to local tensor tomography.},
  archive      = {J_SIIMS},
  author       = {Sombuddha Bhattacharyya and Maarten V. de Hoop and Vitaly Katsnelson and Gunther Uhlmann},
  doi          = {10.1137/22M1480951},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1910-1943},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Recovery of piecewise smooth density and lamé parameters from high frequency exterior cauchy data},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Single pixel x-ray transform and related inverse problems.
<em>SIIMS</em>, <em>15</em>(4), 1894–1909. (<a
href="https://doi.org/10.1137/21M1468103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we analyze the nonlinear single pixel X-ray transform $K$ and study the reconstruction of $f$ from the measurement $Kf$. Different from the well-known X-ray transform, the transform $K$ is a nonlinear operator and uses a single detector that integrates all rays in the space. We derive stability estimates and an inversion of the linearization at zero. We also consider the case where we integrate along geodesics of a Riemannian metric. Moreover, we conduct several numerical experiments to corroborate the theoretical results.},
  archive      = {J_SIIMS},
  author       = {Ru-Yu Lai and Gunther Uhlmann and Jian Zhai and Hanming Zhou},
  doi          = {10.1137/21M1468103},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1894-1909},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Single pixel X-ray transform and related inverse problems},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Harmonic beltrami signature: A novel 2D shape representation
for object classification. <em>SIIMS</em>, <em>15</em>(4), 1851–1893.
(<a href="https://doi.org/10.1137/22M1470852">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There has been a growing interest in shape analysis in recent years. We present a novel shape signature for 2D Jordan domains. The proposed signature is based on Sharon&#39;s conformal welding signature [E. Sharon and D. Mumford, Internat. J. Comput. Vis., 70 (2006), pp. 55--75], which is one of the main building blocks of our proposed shape signature. The conformal welding signature is a well-known shape signature used to represent 2D shapes. Nevertheless, it is not invariant under rotation. It is also sensitive to the choice of particular feature points and shape perturbations. Motivated by this, we propose in this paper an invariant shape signature under rigid transformations and scaling. The proposed signature does not require the delineation of feature points and is robust under shape perturbations. More specifically, the proposed signature is a Beltrami coefficient of the harmonic extension of the conformal welding. We show that there is a one-to-one correspondence between a quotient space of Beltrami coefficients and the space of 2D Jordan domains up to a translation, rotation, and scaling. With a suitable normalization, each equivalence class in the quotient space is associated with a unique representative named the Harmonic Beltrami Signature (HBS). As such, each shape is associated with a unique HBS. Conversely, the associated shape of an HBS can be reconstructed based on quasiconformal Teichmüller theories, which are uniquely determined up to a translation, rotation, and scaling. The HBS is thus an effective fingerprint to represent a 2D shape. The robustness of the HBS is studied both theoretically and experimentally. With the HBS, simple metrics, such as $L^2$, can measure geometric dissimilarity between shapes. Experiments have been carried out to classify shapes into different classes using HBS. Results show good classification performance, which demonstrates the efficacy of our proposed shape signature.},
  archive      = {J_SIIMS},
  author       = {Chenran Lin and Lok Ming Lui},
  doi          = {10.1137/22M1470852},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1851-1893},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Harmonic beltrami signature: A novel 2D shape representation for object classification},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bioinspired random projections for robust, sparse
classification. <em>SIIMS</em>, <em>15</em>(4), 1833–1850. (<a
href="https://doi.org/10.1137/22M1503579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the use of random projections in biological sensing systems, we present a new algorithm for processing data in classification problems. This is based on observations of the human brain and the fruit fly&#39;s olfactory system and involves randomly projecting data into a space of greatly increased dimension before applying a cap operation to truncate the smaller entries. This leads to a simple algorithm that is very computationally efficient and can be used to either give a sparse representation with minimal loss in classification accuracy or give improved robustness, in the sense that classification accuracy is improved when noise is added to the data. This is demonstrated with numerical experiments, which supplement theoretical results demonstrating that the resulting signal transform is continuous and invertible, in an appropriate sense.},
  archive      = {J_SIIMS},
  author       = {Nina Dekoninck Bruhin and Bryn Davies},
  doi          = {10.1137/22M1503579},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1833-1850},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Bioinspired random projections for robust, sparse classification},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An algorithm to compute any simple <span
class="math inline"><em>k</em></span>-gon of a maximum area or perimeter
inscribed in a region of interest. <em>SIIMS</em>, <em>15</em>(4),
1808–1832. (<a href="https://doi.org/10.1137/22M1482676">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational and mathematical models are research subjects for solving engineering, computer science, and computer vision problems. Image preprocessing usually needs to efficiently compute polygons related to some previously delimited region of interest. Most of the solved problems are limited to the search for some type of polygon with $k$ sides (triangles, rectangles, squares, etc.) with maximum area, maximum perimeter, or similar. This paper presents a generic algorithm that computes in $O(n^5 k)$ computational time the polygon of any number of sides (any simple $k$-gon) inscribed in a region of interest (in any closed contour without restrictions). The polygon obtained fulfills the requirements specified by the user: maximum area or perimeter or minimum area or perimeter. No previous work has been proposed to obtain any $k$-gon inscribed in any unconstrained contour. The algorithms and mathematical models are presented and explained, and the source code is available in a GitHub repository for research purposes.},
  archive      = {J_SIIMS},
  author       = {Rubén Molano and Mar Ávila and José Carlos Sancho and Pablo G. Rodríguez and Andres Caro},
  doi          = {10.1137/22M1482676},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1808-1832},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {An algorithm to compute any simple $k$-gon of a maximum area or perimeter inscribed in a region of interest},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parallelizable global quasi-conformal parameterization of
multiply connected surfaces via partial welding. <em>SIIMS</em>,
<em>15</em>(4), 1765–1807. (<a
href="https://doi.org/10.1137/21M1466323">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conformal and quasi-conformal mappings have widespread applications in imaging science, computer vision, and computer graphics and can be used in surface registration, segmentation, remeshing, and texture map compression. While various conformal and quasi-conformal parameterization methods for simply connected surfaces have been proposed, efficient parameterization algorithms for multiply connected surfaces have been less explored. In this paper, we propose a novel parallelizable algorithm for computing the global conformal and quasi-conformal parameterizations of multiply connected surfaces onto a 2D circular domain using variants of the partial welding method and the Koebe&#39;s iteration. The main idea is to first partition a multiply connected surface into several subdomains and compute the free-boundary conformal and quasi-conformal parameterizations of them, respectively, and then apply a variant of the partial welding algorithm to reconstruct the global mapping. We apply the Koebe&#39;s iteration, together with the geodesic algorithm, to the boundary points and welding paths before and after the global welding to transform all the boundaries into circles conformally. After getting all the updated boundary conditions, we obtain the global parameterization of the multiply connected surface by solving the Laplace equation for each subdomain. Using this divide-and-conquer approach, the global conformal and quasi-conformal parameterizations of surfaces can be efficiently computed. Experimental results are presented to demonstrate the effectiveness of our proposed algorithm. More broadly, the proposed shift in perspective from solving a global quasi-conformal mapping problem to solving multiple local mapping problems paves a new way for computational quasi-conformal geometry.},
  archive      = {J_SIIMS},
  author       = {Zhipeng Zhu and Gary P. T. Choi and Lok Ming Lui},
  doi          = {10.1137/21M1466323},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1765-1807},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Parallelizable global quasi-conformal parameterization of multiply connected surfaces via partial welding},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning–based dictionary learning and tomographic
image reconstruction. <em>SIIMS</em>, <em>15</em>(4), 1729–1764. (<a
href="https://doi.org/10.1137/21M1445697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents an approach for image reconstruction in clinical low-dose tomography that combines principles from sparse signal processing with ideas from deep learning. First, we describe sparse signal representation in terms of dictionaries from a statistical perspective and interpret dictionary learning as a process of aligning the distribution that arises from a generative model with the empirical distribution of true signals. As a result, we can see that sparse coding with learned dictionaries resembles a specific variational autoencoder, where the encoder is a sparse coding algorithm and the decoder is a linear function. Next, we show that dictionary learning can also benefit from computational advancements introduced in the context of deep learning, such as parallelism and stochastic optimization. Finally, we show that regularization by dictionaries achieves competitive performance in computed tomography reconstruction compared to state-of-the-art model-based and data-driven approaches, while being unsupervised with respect to tomographic data.},
  archive      = {J_SIIMS},
  author       = {Jevgenija Rudzusika and Thomas Koehler and Ozan Oktem},
  doi          = {10.1137/21M1445697},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1729-1764},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Deep learning--based dictionary learning and tomographic image reconstruction},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bilevel training schemes in imaging for total variation–type
functionals with convex integrands. <em>SIIMS</em>, <em>15</em>(4),
1690–1728. (<a href="https://doi.org/10.1137/21M1467328">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of image processing, we study a class of integral regularizers defined in terms of spatially inhomogeneous integrands that depend on general linear differential operators. Particularly, the spatial dependence is assumed to be only measurable. The setting is made rigorous by means of the theory of Radon measures and of suitable function spaces modeled on functions of bounded variation. We prove the lower semicontinuity of the functionals at stake and existence of minimizers for the corresponding variational problems. Then, we embed the latter into a bilevel scheme in order to automatically compute the regularization parameters. These parameters are considered to be spatially varying, thus allowing for good flexibility and preservation of details in the reconstructed image. After identifying a series of spatially inhomogeneous regularization functionals commonly used in image processing that are included in our framework, we substantiate its feasibility by performing numerical denoising examples in which the spatial dependence of the integrand is measurable. Specifically, we use Huber versions of the first and second order total variation (and their sum) with both the Huber and the regularization parameter being spatially varying. Notably, the spatially varying version of second order total variation produces high quality reconstructions when compared to regularizations of similar type, and the introduction of the low regularity spatially dependent Huber parameter leads to a further enhancement of the image details. We expect that our theoretical investigations and our numerical feasibility study will support future work on setting up schemes where general differential operators with spatially dependent coefficients will also be part of the optimization scheme.},
  archive      = {J_SIIMS},
  author       = {Valerio Pagliari and Kostas Papafitsoros and Bogdan Raib̧tă and Andreas Vikelis},
  doi          = {10.1137/21M1467328},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1690-1728},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Bilevel training schemes in imaging for total variation--type functionals with convex integrands},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimality conditions for bilevel imaging learning problems
with total variation regularization. <em>SIIMS</em>, <em>15</em>(4),
1646–1689. (<a href="https://doi.org/10.1137/21M143412X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the problem of optimal scale-dependent parameter learning in total variation image denoising. Such problems are formulated as bilevel optimization instances with total variation denoising problems as lower-level constraints. For the bilevel problem, we are able to derive M-stationarity conditions, after characterizing the corresponding Mordukhovich generalized normal cone and verifying suitable constraint qualification conditions. We also derive B-stationarity conditions, after investigating the Lipschitz continuity and directional differentiability of the lower-level solution operator. A characterization of the Bouligand subdifferential of the solution mapping, by means of a properly defined linear system, is provided as well. Based on this characterization, we propose a two-phase nonsmooth trust-region algorithm for the numerical solution of the bilevel problem and test it computationally for two particular experimental settings.},
  archive      = {J_SIIMS},
  author       = {Juan Carlos De los Reyes and David Villacís},
  doi          = {10.1137/21M143412X},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1646-1689},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Optimality conditions for bilevel imaging learning problems with total variation regularization},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Image warp preserving content intensity. <em>SIIMS</em>,
<em>15</em>(4), 1623–1645. (<a
href="https://doi.org/10.1137/21M1452688">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An accurate method for warping images is presented. Different from most commonly used techniques, this method guarantees the conservation of the intensity of the transformed image, evaluated as the sum of its pixel values over the whole image or over corresponding transformed subregions of it. Such property is mandatory for quantitative analysis, as, for instance, when deformed images are used to assess radiances, to measure optical fluxes from light sources, or to characterize material optical densities. The proposed method enforces area resampling by decomposing each rectangular pixel into two triangles, and projecting the pixel intensity onto half pixels of the transformed image, with weights proportional to the area of overlap of the triangular half-pixels. The result is quantitatively exact, as long as the original pixel value is assumed to represent a constant image density within the pixel area, and as long as the coordinate transformation is diffeomorphic. Implementation details and possible variations of the method are discussed.},
  archive      = {J_SIIMS},
  author       = {Enrico Segre},
  doi          = {10.1137/21M1452688},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1623-1645},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Image warp preserving content intensity},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Gaussian patch mixture model guided low-rank covariance
matrix minimization for image denoising. <em>SIIMS</em>, <em>15</em>(4),
1601–1622. (<a href="https://doi.org/10.1137/21M1454262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image denoising is one of the most important tasks in image processing. In this paper, we study image denoising methods by using similar patches which have low-rank covariance matrices to recover an underlying image which is corrupted by additive Gaussian noise. In order to enhance global patch-matching results, we make use of a Gaussian mixture model with an auxiliary image to determine different groups of patches. The auxiliary image is an output of BM3D. The noisy version of covariance matrix is formed by each group of patches from the given noisy image. Its low-rank version can be estimated by using covariance matrix nuclear norm minimization, and the resulting denoised image can be obtained. Experimental results are reported to show that the proposed method outperforms the state-of-the-art denoising methods, including testing deep learning methods, in the peak signal-to-noise ratio, structural similarity values, and visual quality.},
  archive      = {J_SIIMS},
  author       = {Jing Guo and Yu Guo and Qiyu Jin and Michael Kwok-Po Ng and Shuping Wang},
  doi          = {10.1137/21M1454262},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {4},
  pages        = {1601-1622},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Gaussian patch mixture model guided low-rank covariance matrix minimization for image denoising},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An accelerated level-set method for inverse scattering
problems. <em>SIIMS</em>, <em>15</em>(3), 1576–1600. (<a
href="https://doi.org/10.1137/21M1457783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a rapid and robust iterative algorithm to solve inverse acoustic scattering problems formulated as a PDE constrained shape optimization problem. We use a level-set method to represent the obstacle geometry and propose a new scheme for updating the geometry based on an adaptation of accelerated gradient descent methods. The resulting algorithm aims at reducing the number of iterations and improving the accuracy of reconstructions. To cope with regularization issues, we propose a smoothing to the shape gradient using a single layer potential associated with $i k$ where $k$ is the wave number. Numerical experiments are given for several data types (full aperture, backscattering, phaseless, multiple frequencies) and show that our method outperforms a nonaccelerated approach in terms of convergence speed, accuracy, and sensitivity to initial guesses.},
  archive      = {J_SIIMS},
  author       = {Lorenzo Audibert and Houssem Haddar and Xiaoli Liu},
  doi          = {10.1137/21M1457783},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1576-1600},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {An accelerated level-set method for inverse scattering problems},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). WARPd: A linearly convergent first-order primal-dual
algorithm for inverse problems with approximate sharpness conditions.
<em>SIIMS</em>, <em>15</em>(3), 1539–1575. (<a
href="https://doi.org/10.1137/21M1455000">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sharpness conditions directly control the recovery performance of restart schemes for first-order optimization methods without the need for restrictive assumptions such as strong convexity. However, they are challenging to apply in the presence of noise or approximate model classes (e.g., approximate sparsity). We provide a first-order method: weighted, accelerated, and restarted primal-dual (WARPd), based on primal-dual iterations and a novel restart-reweight scheme. Under a generic approximate sharpness condition, WARPd achieves stable linear convergence to the desired vector. Many problems of interest fit into this framework. For example, we analyze sparse recovery in compressed sensing, low-rank matrix recovery, matrix completion, TV regularization, minimization of $\|Bx\|_{l^1}$ under constraints ($l^1$-analysis problems for general $B$), and mixed regularization problems. We show how several quantities controlling recovery performance also provide explicit approximate sharpness constants. Numerical experiments show that WARPd compares favorably with specialized state-of-the-art methods and is ideally suited for solving large-scale problems. We also present a noise-blind variant based on a square-root LASSO decoder. Finally, we show how to unroll WARPd as neural networks. This approximation theory result provides lower bounds for stable and accurate neural networks for inverse problems and sheds light on architecture choices. Code and a gallery of examples are available online as a MATLAB package.},
  archive      = {J_SIIMS},
  author       = {Matthew J. Colbrook},
  doi          = {10.1137/21M1455000},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1539-1575},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {WARPd: A linearly convergent first-order primal-dual algorithm for inverse problems with approximate sharpness conditions},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A general non-lipschitz infimal convolution regularized
model: Lower bound theory and algorithm. <em>SIIMS</em>, <em>15</em>(3),
1499–1538. (<a href="https://doi.org/10.1137/20M1356634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The convex infimal convolution model proposed in Chambolle and Lions [Numer. Math., 76 (1997), pp. 167--188] is a fundamental model to extract two useful components from a single input image and has various low level vision applications. In many of them, one target component has an (approximately) piecewise constant structure and the other is a smoothly varying function or repeated texture pattern. In this paper, we propose and study a general non-Lipschitz infimal convolution (GnLIC) regularization model, which covers most existing applications in this type. Therein the non-Lipschitz regularization enforces the piecewise constant property of the first component. For this GnLIC model, we prove a lower bound theory for its local minimizers and a local version for its stationary points. Motivated by these, we naturally extend previous works to design an inexact iterative support shrinking algorithm with proximal linearization for our GnLIC model (InISSAPL-GnLIC). Moreover, we establish the sequence convergence property and a sequence lower bound theory for InISSAPL-GnLIC, provided that an inexact subgradient condition generated by a subsolver holds. The subsolver is constructed by efficient ADMM and a specially designed feasibilization operation. We finally give numerical experiments in two low level vision applications: Retinex and cartoon-texture decomposition. These tests demonstrate that our non-Lipschitz regularization based method can indeed extract the piecewise constant component better than existing approaches, which is consistent with the established lower bound theory.},
  archive      = {J_SIIMS},
  author       = {Chunlin Wu and Xueyan Guo and Yiming Gao and Yunhua Xue},
  doi          = {10.1137/20M1356634},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1499-1538},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A general non-lipschitz infimal convolution regularized model: Lower bound theory and algorithm},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Color image inpainting via robust pure quaternion matrix
completion: Error bound and weighted loss. <em>SIIMS</em>,
<em>15</em>(3), 1469–1498. (<a
href="https://doi.org/10.1137/22M1476897">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study color image inpainting as a pure quaternion matrix completion problem. In the literature, the theoretical guarantee for quaternion matrix completion is not well established. Our main aim is to propose a new minimization problem with an objective combining nuclear norm and a quadratic loss weighted among three channels. To fill the theoretical vacancy, we obtain the error bound in both clean and corrupted regimes, which relies on some new results of quaternion matrices. A general Gaussian noise is considered in robust completion where all observations are corrupted. Motivated by the error bound, we propose to handle unbalanced or correlated noise via a cross-channel weight in the quadratic loss, with the main purpose of rebalancing noise level or removing noise correlation. Extensive experimental results on synthetic and color image data are presented to confirm and demonstrate our theoretical findings.},
  archive      = {J_SIIMS},
  author       = {Junren Chen and Michael K. Ng},
  doi          = {10.1137/22M1476897},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1469-1498},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Color image inpainting via robust pure quaternion matrix completion: Error bound and weighted loss},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiscale approach for three-dimensional conformal image
registration. <em>SIIMS</em>, <em>15</em>(3), 1431–1468. (<a
href="https://doi.org/10.1137/21M1455929">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image registration, especially for three-dimensional (3D) image registration, is widely used in clinical medicine. Many 3D image registration models have been proposed during the last decades. All these models achieve the minimum of the cost functional with some prior regularization. In addition, the physical mesh folding phenomenon is not taken into consideration in most models. This raises a question of whether one can achieve/approach the infimum of the cost functional without a regularization term and ensure no mesh folding. To give an answer to this question, a multiscale approach for 3D conformal image registration is presented in this paper. This approach ensures no mesh folding and gets close to the infimum of the cost functional without any regularization on the 3D conformal set. The 3D multiscale approach contains a series of deformation composition processes and the convergence of the process is presented. Furthermore, a numerical algorithm for this multiscale approach is proposed and the convergence of the numerical algorithm is proved. Moreover, several numerical tests are also listed to show the good performance of the proposed algorithm.},
  archive      = {J_SIIMS},
  author       = {Huan Han and Zhengping Wang and Yimin Zhang},
  doi          = {10.1137/21M1455929},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1431-1468},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Multiscale approach for three-dimensional conformal image registration},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A spatial color compensation model using saturation-value
total variation. <em>SIIMS</em>, <em>15</em>(3), 1400–1430. (<a
href="https://doi.org/10.1137/21M1453773">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Color image enhancement is one of the most important tasks in image processing. In this paper, we focus on the red and/or blue attenuation problem that arises in underwater image enhancement. We propose and develop a novel spatial color compensation model based on saturation-value total variation (SV-TV). In the proposed model, the compensation of the red and/or blue attenuation is achieved by adding a fraction of the green channel to the red and/or blue channel. The fraction is determined by a spatially varying function, which is controlled by the TV regularization. In order to avoid overcompensation and too many color artifacts, we make use of the SV-TV to regularize the objective compensation result. We numerically apply the proximal alternating linearized minimization to solve the proposed minimization problem, and we give the convergence analysis of the proposed algorithm. Numerical examples are presented to demonstrate that the performance of the proposed color compensation model is better than that of other testing methods in terms of visual quality and certain criteria, such as peak signal-to-noise ratio (PSNR), structure similarity (SSIM), and CIEde2000 color difference.},
  archive      = {J_SIIMS},
  author       = {Wei Wang and Yuming Yang and Michael K. Ng},
  doi          = {10.1137/21M1453773},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1400-1430},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A spatial color compensation model using saturation-value total variation},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Total variation-based reconstruction and phase retrieval for
diffraction tomography. <em>SIIMS</em>, <em>15</em>(3), 1373–1399. (<a
href="https://doi.org/10.1137/22M1474382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In optical diffraction tomography (ODT), the three-dimensional scattering potential of a microscopic object rotating around its center is recovered by a series of illuminations with coherent light. Reconstruction algorithms such as the filtered backpropagation require knowledge of the complex-valued wave at the measurement plane, whereas often only intensities, i.e., phaseless measurements, are available in practice. We propose a new reconstruction approach for ODT with unknown phase information based on three key ingredients. First, the light propagation is modeled using Born&#39;s approximation enabling us to use the Fourier diffraction theorem. Second, we stabilize the inversion of the nonuniform discrete Fourier transform via total variation regularization utilizing a primal-dual iteration, which also yields a novel numerical inversion formula for ODT with known phase. The third ingredient is a hybrid input-output scheme. We achieved convincing numerical results, which indicate that ODT with phaseless data is possible. The so-obtained 2-dimensional and 3-dimensional reconstructions are even comparable to the ones with known phase.},
  archive      = {J_SIIMS},
  author       = {Robert Beinert and Michael Quellmalz},
  doi          = {10.1137/22M1474382},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1373-1399},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Total variation-based reconstruction and phase retrieval for diffraction tomography},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). <span class="math inline"><em>L</em><sub>1</sub></span>-norm
regularization for short-and-sparse blind deconvolution: Point source
separability and region selection. <em>SIIMS</em>, <em>15</em>(3),
1345–1372. (<a href="https://doi.org/10.1137/21M144904X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blind deconvolution is about estimating both the convolution kernel and the latent signal from their convolution. Many blind deconvolution problems have a short-and-sparse (SaS) structure; i.e., the signal (or its gradient) is sparse and the kernel size is much smaller than the signal size. While $\ell_1$-norm relating regularizations have been widely used for solving SaS blind deconvolution problems, the so-called region/edge selection technique brings great empirical improvement to such $\ell_1$-norm relating regularizations in image deblurring. The essence of region/edge selection is during an alternative iterative scheme of SaS blind deconvolution: one estimates the kernel on an estimate of the latent image with well-separated image edges instead of the one with the least fitting error. In this paper, we first examine the validity and soundness of $\ell_1$-norm relating regularization in the setting of 1D SaS blind deconvolution. The analysis reveals the importance of the separation of nonzero signal entries toward the soundness of such a regularization. The studies laid out the foundation of region selection technique; i.e., during the iteration, an estimate of the latent image with well-separated edges is a better candidate for estimating the kernel than the one with the least fitting error. Based on the studies conducted in this paper, an alternating iterative scheme with region selection model is developed for SaS blind deconvolution, which is then applied to blind motion deblurring. The experiments show its effectiveness over many existing $\ell_1$-norm relating approaches.},
  archive      = {J_SIIMS},
  author       = {Weixi Wang and Ji Li and Hui Ji},
  doi          = {10.1137/21M144904X},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1345-1372},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {$L_1$-norm regularization for short-and-sparse blind deconvolution: Point source separability and region selection},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Image segmentation with adaptive spatial priors from joint
registration. <em>SIIMS</em>, <em>15</em>(3), 1314–1344. (<a
href="https://doi.org/10.1137/21M1444874">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image segmentation is a crucial but challenging task that has many applications. In medical imaging, for instance, intensity inhomogeneity and noise are common. In thigh muscle images, different muscles are closely packed together and there are often no clear boundaries between them. Intensity based segmentation models cannot separate one muscle from another. To solve such problems, in this work we present a segmentation model with adaptive spatial priors from joint registration. This model combines segmentation and registration in a unified framework to leverage their positive mutual influence. The segmentation is based on a modified Gaussian mixture model, which integrates intensity inhomogeneity and spatial smoothness. The registration plays the role of providing a shape prior. We adopt a modified sum of squared difference fidelity term and Tikhonov regularity term for registration and also utilize a Gaussian pyramid and parametric method for robustness. The connection between segmentation and registration is guaranteed by the cross entropy metric that aims to make the segmentation map (from segmentation) and deformed atlas (from registration) as similar as possible. This joint framework is implemented within a constraint optimization framework, which leads to an efficient algorithm. We evaluate our proposed model on synthetic and thigh muscle MR images. Numerical results show the improvement as compared to segmentation and registration performed separately and other joint models.},
  archive      = {J_SIIMS},
  author       = {Haifeng Li and Weihong Guo and Jun Liu and Li Cui and Dongxing Xie},
  doi          = {10.1137/21M1444874},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1314-1344},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Image segmentation with adaptive spatial priors from joint registration},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The whole and the parts: The minimum description length
principle and the a-contrario framework. <em>SIIMS</em>, <em>15</em>(3),
1282–1313. (<a href="https://doi.org/10.1137/21M145745X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work explores the connections between the minimum description length (MDL) principle as developed by Rissanen, and the a-contrario framework for structure detection proposed by Desolneux, Moisan, and Morel. The MDL principle focuses on the best interpretation for the whole data while the a-contrario approach concentrates on detecting parts of the data with anomalous statistics. Although framed in different theoretical formalisms, we show that both methodologies share many common concepts and tools in their machinery and yield very similar formulations in a number of interesting scenarios ranging from simple toy examples to practical applications such as polygonal approximation of curves and line segment detection in images. We also formulate the conditions under which both approaches are formally equivalent.},
  archive      = {J_SIIMS},
  author       = {Rafael Grompone von Gioi and Ignacio Ramírez Paulino and Gregory Randall},
  doi          = {10.1137/21M145745X},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1282-1313},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {The whole and the parts: The minimum description length principle and the A-contrario framework},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Lifting the convex conjugate in lagrangian relaxations: A
tractable approach for continuous markov random fields. <em>SIIMS</em>,
<em>15</em>(3), 1253–1281. (<a
href="https://doi.org/10.1137/21M1433241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dual decomposition approaches in nonconvex optimization may suffer from a duality gap. This poses a challenge when applying them directly to nonconvex problems such as MAP-inference in a Markov random field with continuous state spaces. To eliminate such gaps, this paper considers a reformulation of the original nonconvex task in the space of measures. This infinite-dimensional reformulation is then approximated by a semi-infinite one, which is obtained via a piecewise polynomial discretization in the dual. We provide a geometric intuition behind the primal problem induced by the dual discretization and draw connections to optimization over moment spaces. In contrast to existing discretizations which suffer from a grid bias, we show that a piecewise polynomial discretization better preserves the continuous nature of our problem. Invoking results from optimal transport theory and convex algebraic geometry we reduce the semi-infinite program to a finite one and provide a practical implementation based on semidefinite programming. We show, experimentally and in theory, that the approach successfully reduces the duality gap. To showcase the scalability of our approach, we apply it to the stereo matching problem between two images.},
  archive      = {J_SIIMS},
  author       = {Hartmut Bauermeister and Emanuel Laude and Thomas Möllenhoff and Michael Moeller and Daniel Cremers},
  doi          = {10.1137/21M1433241},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1253-1281},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Lifting the convex conjugate in lagrangian relaxations: A tractable approach for continuous markov random fields},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). High-resolution, quantitative signal subspace imaging for
synthetic aperture radar. <em>SIIMS</em>, <em>15</em>(3), 1229–1252. (<a
href="https://doi.org/10.1137/21M1467109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider synthetic aperture radar imaging of a region containing point-like targets. Measurements are the set of frequency responses to scattering by the targets taken over a collection of individual spatial locations along the flight path making up the synthetic aperture. Because signal subspace imaging methods do not work on these measurements directly, we rearrange the frequency response at each spatial location using the Prony method and obtain a matrix that is suitable for these methods. We arrange the set of these Prony matrices as one block-diagonal matrix and introduce a signal subspace imaging method for it. We show that this signal subspace method yields high-resolution and quantitative images provided that the signal-to-noise ratio is sufficiently high. We give a resolution analysis for this imaging method and validate this theory using numerical simulations. Additionally, we show that this imaging method is stable to random perturbations to the travel times and validate this theory with numerical simulations using the random travel time model for random media.},
  archive      = {J_SIIMS},
  author       = {Arnold D. Kim and Chrysoula Tsogka},
  doi          = {10.1137/21M1467109},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1229-1252},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {High-resolution, quantitative signal subspace imaging for synthetic aperture radar},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analysis for full-field photoacoustic tomography with
variable sound speed. <em>SIIMS</em>, <em>15</em>(3), 1213–1228. (<a
href="https://doi.org/10.1137/21M1463409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photoacoustic tomography (PAT) is a noninvasive imaging modality that requires recovering the initial data of the wave equation from certain measurements of the solution outside the object. In the standard PAT measurement setup, the used data consist of time-dependent signals measured on an observation surface. In contrast, the measured data from the recently invented full-field detection technique provide the solution of the wave equation on a spatial domain at a single instant in time. While reconstruction using classical PAT data has been extensively studied, not much is known for the full-field PAT problem. In this paper, we build mathematical foundations of the latter problem for variable sound speed and settle its uniqueness and stability. Moreover, we introduce an exact inversion method using time-reversal and study its convergence. Our results demonstrate the suitability of both the full-field approach and the proposed time-reversal technique for high-resolution photoacoustic imaging.},
  archive      = {J_SIIMS},
  author       = {Linh Nguyen and Markus Haltmeier and Richard Kowar and Ngoc Do},
  doi          = {10.1137/21M1463409},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1213-1228},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Analysis for full-field photoacoustic tomography with variable sound speed},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Compressive learning for patch-based image denoising.
<em>SIIMS</em>, <em>15</em>(3), 1184–1212. (<a
href="https://doi.org/10.1137/21M1459812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The expected patch log-likelihood algorithm (EPLL) and its extensions have shown good performances for image denoising. The prior model used by EPLL is usually a Gaussian mixture model (GMM) estimated from a database of image patches. Classical mixture model estimation methods face computational issues as the high dimensionality of the problem requires training on large datasets. In this work, we adapt a compressive statistical learning framework to carry out the GMM estimation. With this method, called sketching, we estimate models from a compressive representation (the sketch) of the training patches. The cost of estimating the prior from the sketch no longer depends on the number of items in the original large database. To accelerate further the estimation, we add another dimension reduction technique (low-rank modeling of the covariance matrices) to the compressing learning framework. To demonstrate the advantages of our method, we test it on real large-scale data. We show that we can produce denoising performances similar to performances obtained with models estimated from the original training database using GMM priors learned from the sketch with improved execution times.},
  archive      = {J_SIIMS},
  author       = {Hui Shi and Yann Traonmilin and Jean-Francois Aujol},
  doi          = {10.1137/21M1459812},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1184-1212},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Compressive learning for patch-based image denoising},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A generalized primal-dual algorithm with improved
convergence condition for saddle point problems. <em>SIIMS</em>,
<em>15</em>(3), 1157–1183. (<a
href="https://doi.org/10.1137/21M1453463">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We generalize the well-known primal-dual algorithm proposed by Chambolle and Pock for saddle point problems and relax the condition for ensuring its convergence. The relaxed convergence-guaranteeing condition is effective for the generic convex setting of saddle point problems, and we show by the canonical convex programming problem with linear equality constraints that the relaxed condition is optimal. It also allows us to discern larger step sizes for the resulting subproblems, and thus provides a simple and universal way to improve numerical performance of the original primal-dual algorithm. In addition, we present a structure-exploring heuristic to further relax the convergence-guaranteeing condition for some specific saddle point problems, which could yield much larger step sizes and hence significantly better performance. Effectiveness of this heuristic is numerically illustrated by the classic assignment problem.},
  archive      = {J_SIIMS},
  author       = {Bingsheng He and Feng Ma and Shengjie Xu and Xiaoming Yuan},
  doi          = {10.1137/21M1453463},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1157-1183},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A generalized primal-dual algorithm with improved convergence condition for saddle point problems},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Model-centric data manifold: The data through the eyes of
the model. <em>SIIMS</em>, <em>15</em>(3), 1140–1156. (<a
href="https://doi.org/10.1137/21M1437056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that deep ReLU neural network classifiers can see a low-dimensional Riemannian manifold structure on data. Such structure comes via the \sl local data matrix, a variation of the Fisher information matrix, where the role of the model parameters is taken by the data variables. We obtain a foliation of the data domain, and we show that the dataset on which the model is trained lies on a leaf, the \sl data leaf, whose dimension is bounded by the number of classification labels. We validate our results with some experiments with the MNIST dataset: paths on the data leaf connect valid images, while other leaves cover noisy images.},
  archive      = {J_SIIMS},
  author       = {Luca Grementieri and Rita Fioresi},
  doi          = {10.1137/21M1437056},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1140-1156},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Model-centric data manifold: The data through the eyes of the model},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stable image reconstruction using transformed total
variation minimization. <em>SIIMS</em>, <em>15</em>(3), 1104–1139. (<a
href="https://doi.org/10.1137/21M1438566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformed $L_1$ (TL1) regularization has been shown to have comparable signal recovery capability with $L_1-L_2$ regularization and $L_1/L_2$ regularization, regardless of whether the measurement matrix satisfies the restricted isometry property (RIP). In the spirit of the TL1 method, we introduce a transformed total variation (TTV) minimization model to investigate robust image recovery from a certain number of noisy measurements by the proposed TTV minimization model in this paper. An optimal error bound, up to a logarithmic factor, of robust image recovery from compressed measurements via the TTV minimization model is established, and the RIP based condition is improved compared with total variation (TV) minimization. Numerical results of image reconstruction demonstrate our theoretical results and illustrate the efficiency of the TTV minimization model among state-of-the-art methods. Empirically, the error bound between the reconstructed image and the original image is shown to be better than that produced by TV minimization.},
  archive      = {J_SIIMS},
  author       = {Limei Huo and Wengu Chen and Huanmin Ge and Michael K. Ng},
  doi          = {10.1137/21M1438566},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1104-1139},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Stable image reconstruction using transformed total variation minimization},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A fast averaged kaczmarz iteration with convex penalty for
inverse problems in hilbert spaces. <em>SIIMS</em>, <em>15</em>(3),
1079–1103. (<a href="https://doi.org/10.1137/21M1445181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we focus on developing a fast Kaczmarz-type method to solve inverse problems that can be written as systems of linear or nonlinear equations in Hilbert spaces. In order to capture the special feature of solutions, we incorporate nonsmooth convex functions into the averaged Kaczmarz iteration, leading to a new Kaczmarz-type method. In addition, aimed at further accelerating our proposed method, the choice of the step size is carefully discussed. Under the similar assumptions of the Kaczmarz-type method, we prove that our method is a convergent regularization method as long as it is terminated by an appropriate stopping rule. Finally, detailed numerical studies are presented for the limited data problem in photoacoustic tomography and the parameter identification problems to show the effectiveness of our method.},
  archive      = {J_SIIMS},
  author       = {Yuxin Xia and Wei Wang and Bo Han},
  doi          = {10.1137/21M1445181},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1079-1103},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A fast averaged kaczmarz iteration with convex penalty for inverse problems in hilbert spaces},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Compactification of the rigid motions group in image
processing. <em>SIIMS</em>, <em>15</em>(3), 1041–1078. (<a
href="https://doi.org/10.1137/21M1429448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image processing problems in general, and in particular in the field of single-particle cryo-electron microscopy, often require considering images up to their rotations and translations. Such problems were tackled successfully when considering images up to rotations only, using quantities which are invariant to the action of rotations on images. Extending these methods to cases where translations are involved is more complicated. Here we present a computationally feasible and theoretically sound approximate invariant to the action of rotations and translations on images. It allows one to approximately reduce image processing problems to similar problems over the sphere, a compact domain acted on by the group of three-dimensional rotations, a compact group. We show that this invariant is induced by a family of mappings deforming, and thereby compactifying, the group structure of rotations and translations of the plane, i.e., the group of rigid motions, into the group of three-dimensional rotations. Furthermore, we demonstrate its viability in two image processing tasks: multireference alignment and classification. To our knowledge, this is the first instance of a quantity that is either exactly or approximately invariant to rotations and translations of images that both rests on a sound theoretical foundation and is applicable in practice.},
  archive      = {J_SIIMS},
  author       = {Tamir Bendory and Ido Hadi and Nir Sharon},
  doi          = {10.1137/21M1429448},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1041-1078},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Compactification of the rigid motions group in image processing},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bar code decoding in a camera-based scanner: Analysis and
algorithm. <em>SIIMS</em>, <em>15</em>(3), 1017–1040. (<a
href="https://doi.org/10.1137/21M1449658">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of this work is to provide a foundational understanding of the resolution requirement for camera-based bar code scanning systems and to develop an effective algorithm for decoding. The main theoretical question we wish to address is how well resolved must the bar code image be for the system to be able to decode it. To facilitate the analysis we consider the UPC bar code, which is widely used in retail and commerce. We further assume that the pixels of the camera are aligned with the bar code, making the problem one-dimensional. We find that if the narrowest bar in the bar code is larger than two-thirds the size of the camera pixel, it is possible to uniquely determine the encoded message in the bar code. The result, which exploits the symbology of the UPC bar code, shows that under-resolved bar code images can be decoded. To further gain insight into the robustness of the decoding process, we perform numerical experiments.},
  archive      = {J_SIIMS},
  author       = {Fadil Santosa and Madeline Goh},
  doi          = {10.1137/21M1449658},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {3},
  pages        = {1017-1040},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Bar code decoding in a camera-based scanner: Analysis and algorithm},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Linear convergence of randomized kaczmarz method for solving
complex-valued phaseless equations. <em>SIIMS</em>, <em>15</em>(2),
989–1016. (<a href="https://doi.org/10.1137/21M1450537">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A randomized Kaczmarz method was recently proposed for phase retrieval, which has been shown numerically to exhibit empirical performance over other state-of-the-art phase retrieval algorithms both in terms of the sampling complexity and computation time. While the rate of convergence has been well studied in the real case where the signals and measurement vectors are all real-valued, there is no guarantee for the convergence in the complex case. In fact, the linear convergence of the randomized Kaczmarz method for phase retrieval in the complex setting is left as a conjecture by Tan and Vershynin [Inf. Inference, 8 (2019), pp. 97--123]. In this paper, we provide the first theoretical guarantees for it. We show that for random measurements ${a}_j \in \mathbb{C}^n,\, j=1,\ldots,m,$ which are drawn independently and uniformly from the complex unit sphere, or equivalently are independent complex Gaussian random vectors, when $m\ge Cn$ for some universal positive constant $C$, the randomized Kaczmarz scheme with a good initialization converges linearly to the target solution (up to a global phase) in expectation with high probability. This gives a positive answer to that conjecture.},
  archive      = {J_SIIMS},
  author       = {Meng Huang and Yang Wang},
  doi          = {10.1137/21M1450537},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {989-1016},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Linear convergence of randomized kaczmarz method for solving complex-valued phaseless equations},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A unifying framework for <span
class="math inline"><em>n</em></span>-dimensional quasi-conformal
mappings. <em>SIIMS</em>, <em>15</em>(2), 960–988. (<a
href="https://doi.org/10.1137/21M1457497">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of computer technology, there is a surge of interest in effective mapping methods for objects in higher-dimensional spaces. To establish a one-to-one correspondence between objects, higher-dimensional quasi-conformal theory can be utilized for ensuring the bijectivity of the mappings. In addition, it is often desirable for the mappings to satisfy certain prescribed geometric constraints and possess low distortion in conformality or volume. In this work, we develop a unifying framework for computing $n$-dimensional quasi-conformal mappings. More specifically, we propose a variational model that integrates quasi-conformal distortion, volumetric distortion, landmark correspondence, intensity mismatch, and volume prior information to handle a large variety of deformation problems. We further prove the existence of a minimizer for the proposed model and devise efficient numerical methods to solve the optimization problem. We demonstrate the effectiveness of the proposed framework using various experiments in two and three dimensions, with applications to medical image registration, adaptive remeshing, and shape modeling.},
  archive      = {J_SIIMS},
  author       = {Daoping Zhang and Gary P. T. Choi and Jianping Zhang and Lok Ming Lui},
  doi          = {10.1137/21M1457497},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {960-988},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A unifying framework for $n$-dimensional quasi-conformal mappings},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A splitting scheme for flip-free distortion energies.
<em>SIIMS</em>, <em>15</em>(2), 925–959. (<a
href="https://doi.org/10.1137/21M1433058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a robust optimization method for flip-free distortion energies used, for example, in parametrization, deformation, and volume correspondence. This method can minimize a variety of distortion energies, such as the symmetric Dirichlet energy and our new symmetric gradient energy. We identify and exploit the special structure of distortion energies to employ an operator splitting technique, leading us to propose a novel alternating direction method of multipliers (ADMM) algorithm to deal with the nonconvex, nonsmooth nature of distortion energies. The scheme results in an efficient method where the global step involves a single matrix multiplication and the local steps are closed-form per-triangle/per-tetrahedron expressions that are highly parallelizable. The resulting general-purpose optimization algorithm exhibits robustness to flipped triangles and tetrahedra in initial data as well as during the optimization. We establish the convergence of our proposed algorithm under certain conditions and demonstrate applications to parametrization, deformation, and volume correspondence.},
  archive      = {J_SIIMS},
  author       = {Oded Stein and Jiajin Li and Justin Solomon},
  doi          = {10.1137/21M1433058},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {925-959},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A splitting scheme for flip-free distortion energies},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian imaging with data-driven priors encoded by neural
networks. <em>SIIMS</em>, <em>15</em>(2), 892–924. (<a
href="https://doi.org/10.1137/21M1406313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new methodology for performing Bayesian inference in imaging inverse problems where the prior knowledge is available in the form of training data. Following the manifold hypothesis, we adopt a data-driven prior that is supported on a submanifold of the ambient space, which we can learn from the training data using a generative model, such as a variational autoencoder or generative adversarial network. We establish the existence and well-posedness of the associated posterior distribution and posterior moments under easily verifiable conditions, providing a rigorous underpinning for Bayesian estimators and uncertainty quantification analyses. Bayesian computation is performed using a parallel tempered version of the pCN algorithm on the manifold, which is shown to be ergodic and robust to the nonconvex nature of these data-driven models. In addition to point estimators and uncertainty quantification analyses, we derive a model misspecification test to automatically detect situations where the data-driven prior is unreliable, and we explain how to identify the dimension of the latent space directly from the training data. The proposed approach is illustrated with a range of experiments with the MNIST dataset and is compared with some variational and message passing image reconstruction approaches from the state of the art that also use data-driven regularization. A model accuracy analysis suggests that the Bayesian probabilities reported by the proposed data-driven models are also accurate under a frequentist definition of probability, suggesting that the learnt prior is close to the true marginal distribution of the unknown image.},
  archive      = {J_SIIMS},
  author       = {Matthew Holden and Marcelo Pereyra and Konstantinos C. Zygalakis},
  doi          = {10.1137/21M1406313},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {892-924},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Bayesian imaging with data-driven priors encoded by neural networks},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Imaging anisotropic conductivities from current densities.
<em>SIIMS</em>, <em>15</em>(2), 860–891. (<a
href="https://doi.org/10.1137/21M1437810">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose and analyze a reconstruction algorithm for imaging an anisotropic conductivity tensor in a second-order elliptic PDE with a nonzero Dirichlet boundary condition from internal current densities. It is based on a regularized output least-squares formulation with the standard $L^2(\Omega)^{d,d}$ penalty, which is then discretized by the standard Galerkin finite element method. We establish the continuity and differentiability of the forward map with respect to the conductivity tensor in the $L^p(\Omega)^{d,d}$-norms, the existence of minimizers and optimality systems of the regularized formulation using the concept of H-convergence. Further, we provide a detailed analysis of the discretized problem, especially the convergence of the discrete approximations with respect to the mesh size, using the discrete counterpart of H-convergence. In addition, we develop a projected Newton algorithm for solving the first-order optimality system. We present extensive two-dimensional numerical examples to show the efficiency of the proposed method.},
  archive      = {J_SIIMS},
  author       = {Huan Liu and Bangti Jin and Xiliang Lu},
  doi          = {10.1137/21M1437810},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {860-891},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Imaging anisotropic conductivities from current densities},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Solving inverse problems by joint posterior maximization
with autoencoding prior. <em>SIIMS</em>, <em>15</em>(2), 822–859. (<a
href="https://doi.org/10.1137/21M140225X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we address the problem of solving ill-posed inverse problems in imaging where the prior is a variational autoencoder (VAE). Specifically we consider the decoupled case where the prior is trained once and can be reused for many different log-concave degradation models without retraining. Whereas previous MAP-based approaches to this problem lead to highly nonconvex optimization algorithms, our approach computes the joint (space-latent) MAP that naturally leads to alternate optimization algorithms and to the use of a stochastic encoder to accelerate computations. The resulting technique (JPMAP) performs joint posterior maximization using an autoencoding prior. We show theoretical and experimental evidence that the proposed objective function is quite close to biconvex. Indeed it satisfies a weak biconvexity property which is sufficient to guarantee that our optimization scheme converges to a stationary point. We also highlight the importance of correctly training the VAE using a denoising criterion, in order to ensure that the encoder generalizes well to out-of-distribution images, without affecting the quality of the generative model. This simple modification is key to providing robustness to the whole procedure. Finally we show how our joint MAP methodology relates to more common MAP approaches, and we propose a continuation scheme that makes use of our JPMAP algorithm to provide more robust MAP estimates. Experimental results also show the higher quality of the solutions obtained by our JPMAP approach with respect to other nonconvex MAP approaches which more often get stuck in spurious local optima.},
  archive      = {J_SIIMS},
  author       = {Mario González and Andrés Almansa and Pauline Tan},
  doi          = {10.1137/21M140225X},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {822-859},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Solving inverse problems by joint posterior maximization with autoencoding prior},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An optimal bayesian estimator for absorption coefficient in
diffuse optical tomography. <em>SIIMS</em>, <em>15</em>(2), 797–821. (<a
href="https://doi.org/10.1137/21M1462842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffuse Optical Tomography (DOT) is a well-known imaging technique for detecting the optical properties of an object in order to detect anomalies, such as diffusive or absorptive targets. More specifically, DOT has many applications in medical imaging including breast cancer screening. It is an affordable and noninvasive method to recover the optical properties of a body using photon density measurements from applying laser sources placed at its surface. Mathematically, the reconstruction of the internal absorption or scattering is a severely ill-posed inverse problem and yields a poor quality image reconstruction. Studying coefficient inverse problems in a stochastic setting has increasingly gained in prominence in the past couple of decades. In this work, we will show convergence and optimality for a Bayesian estimator for the absorption coefficient built from the noisy data obtained in a simplified DOT Model. We establish the rate of convergence of such an estimator in the supremum norm loss and show that it is optimal. We also present numerical experiments in support of our theoretical findings.},
  archive      = {J_SIIMS},
  author       = {Anuj Abhishek and Thilo Strauss and Taufiquar Khan},
  doi          = {10.1137/21M1462842},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {797-821},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {An optimal bayesian estimator for absorption coefficient in diffuse optical tomography},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A PDE-based method for shape registration. <em>SIIMS</em>,
<em>15</em>(2), 762–796. (<a
href="https://doi.org/10.1137/21M1408932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the square root velocity framework and similar approaches, the computation of shape space distances and the registration of curves requires the solution of a nonconvex variational problem. In this paper, we present a new PDE-based method for solving this problem numerically. The method is constructed from numerical approximation of the Hamilton--Jacobi--Bellman equation for the variational problem and has quadratic complexity and global convergence for the distance estimate. In conjunction, we propose a backtracking scheme for approximating solutions of the registration problem, which additionally can be used to compute shape space geodesics. The methods have linear numerical convergence and improved efficiency compared previous global solvers.},
  archive      = {J_SIIMS},
  author       = {Esten Nicolai Wøien and Markus Grasmair},
  doi          = {10.1137/21M1408932},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {762-796},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A PDE-based method for shape registration},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Scheduled restart momentum for accelerated stochastic
gradient descent. <em>SIIMS</em>, <em>15</em>(2), 738–761. (<a
href="https://doi.org/10.1137/21M1453311">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic gradient descent (SGD) algorithms, with constant momentum and its variants such as Adam, are the optimization methods of choice for training deep neural networks (DNNs). There is great interest in speeding up the convergence of these methods due to their high computational expense. Nesterov accelerated gradient with a time-varying momentum (NAG) improves the convergence rate of gradient descent for convex optimization using a specially designed momentum; however, it accumulates error when the stochastic gradient is used, slowing convergence at best and diverging at worst. In this paper, we propose scheduled restart SGD (SRSGD), a new NAG-style scheme for training DNNs. SRSGD replaces the constant momentum in SGD by the increasing momentum in NAG but stabilizes the iterations by resetting the momentum to zero according to a schedule. Using a variety of models and benchmarks for image classification, we demonstrate that, in training DNNs, SRSGD significantly improves convergence and generalization; for instance, in training ResNet-200 for ImageNet classification, SRSGD achieves an error rate of 20.93\% versus the benchmark of 22.13\%. These improvements become more significant as the network grows deeper. Furthermore, on both CIFAR and ImageNet, SRSGD reaches similar or even better error rates with significantly fewer training epochs compared to the SGD baseline. Our implementation of SRSGD is available at https://github.com/minhtannguyen/SRSGD.},
  archive      = {J_SIIMS},
  author       = {Bao Wang and Tan Nguyen and Tao Sun and Andrea L. Bertozzi and Richard G. Baraniuk and Stanley J. Osher},
  doi          = {10.1137/21M1453311},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {738-761},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Scheduled restart momentum for accelerated stochastic gradient descent},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian imaging using plug &amp; play priors: When langevin
meets tweedie. <em>SIIMS</em>, <em>15</em>(2), 701–737. (<a
href="https://doi.org/10.1137/21M1406349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the seminal work of Venkatakrishnan, Bouman, and Wohlberg [Proceedings of the Global Conference on Signal and Information Processing, IEEE, 2013, pp. 945--948] in 2013, Plug &amp; Play (PnP) methods have become ubiquitous in Bayesian imaging. These methods derive estimators for inverse problems in imaging by combining an explicit likelihood function with a prior that is implicitly defined by an image denoising algorithm. In the case of optimization schemes, some recent works guarantee the convergence to a fixed point, albeit not necessarily a maximum a posteriori Bayesian estimate. In the case of Monte Carlo sampling schemes for general Bayesian computation, to the best of our knowledge there is no known proof of convergence. Algorithm convergence issues aside, there are important open questions regarding whether the underlying Bayesian models and estimators are well defined, are well posed, and have the basic regularity properties required to support efficient Bayesian computation schemes. This paper develops theory for Bayesian analysis and computation with PnP priors. We introduce PnP-ULA (Plug &amp; Play unadjusted Langevin algorithm) for Monte Carlo sampling and minimum mean square error estimation. Using recent results on the quantitative convergence of Markov chains, we establish detailed convergence guarantees for this algorithm under realistic assumptions on the denoising operators used, with special attention to denoisers based on deep neural networks. We also show that these algorithms approximately target a decision-theoretically optimal Bayesian model that is well posed and meaningful from a frequentist viewpoint. PnP-ULA is demonstrated on several canonical problems such as image deblurring and inpainting, where it is used for point estimation as well as for uncertainty visualization and quantification.},
  archive      = {J_SIIMS},
  author       = {Rémi Laumont and Valentin De Bortoli and Andrés Almansa and Julie Delon and Alain Durmus and Marcelo Pereyra},
  doi          = {10.1137/21M1406349},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {701-737},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Bayesian imaging using plug &amp; play priors: When langevin meets tweedie},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Steerable near-quadrature filter pairs in three dimensions.
<em>SIIMS</em>, <em>15</em>(2), 670–700. (<a
href="https://doi.org/10.1137/21M143529X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Steerable filter pairs that are near quadrature have many image processing applications. This paper proposes a new methodology for designing such filters. The key idea is to design steerable filters by minimizing a departure-from-quadrature function. These minimizing filter pairs are almost exactly in quadrature. The polar part of the filters is nonnegative, monotonic, and highly focused around an axis, and asymptotically the filters achieve exact quadrature. These results are established by exploiting a relation between the filters and generalized Hilbert matrices. These near-quadrature filters closely approximate three dimensional Gabor filters. We experimentally verify the asymptotic mathematical results and further demonstrate the use of these filter pairs by efficient calculation of local Fourier shell correlation of cryogenic electron microscopy.},
  archive      = {J_SIIMS},
  author       = {Tommy M. Tang and Hemant D. Tagare},
  doi          = {10.1137/21M143529X},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {670-700},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Steerable near-quadrature filter pairs in three dimensions},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust tensor completion: Equivalent surrogates, error
bounds, and algorithms. <em>SIIMS</em>, <em>15</em>(2), 625–669. (<a
href="https://doi.org/10.1137/21M1429539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust low-rank tensor completion (RTC) problems have received considerable attention in recent years such as in signal processing and computer vision. In this paper, we focus on the bound constrained RTC problem for third-order tensors which recovers a low-rank tensor from partial observations corrupted by impulse noise. A widely used convex relaxation of this problem is to minimize the tensor nuclear norm for low rank and the $\ell_1$-norm for sparsity. However, it may result in biased solutions. To handle this issue, we propose a nonconvex model with a novel nonconvex tensor rank surrogate function and a novel nonconvex sparsity measure for RTC problems under limited sample constraints and two bound constraints, where these two nonconvex terms have a difference of convex functions structure. Then, a proximal majorization-minimization (PMM) algorithm is developed to solve the proposed model and this algorithm consists of solving a series of convex subproblems with an initial estimator to generate a new estimator which is used for the next subproblem. Theoretically, for this new estimator, we establish a recovery error bound for its recoverability and give the theoretical guarantee that lower error bounds can be obtained when a reasonable initial estimator is available. Then, by using the Kurdyka--Ł ojasiewicz property exhibited in the resulting problem, we show that the sequence generated by the PMM algorithm globally converges to a critical point of the problem. Extensive numerical experiments including color images and multispectral images show the high efficiency of the proposed model.},
  archive      = {J_SIIMS},
  author       = {Xueying Zhao and Minru Bai and Defeng Sun and Libin Zheng},
  doi          = {10.1137/21M1429539},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {625-669},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Robust tensor completion: Equivalent surrogates, error bounds, and algorithms},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SISAL revisited. <em>SIIMS</em>, <em>15</em>(2), 591–624.
(<a href="https://doi.org/10.1137/21M1430613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simplex identification via split augmented Lagrangian (SISAL) is a popularly used algorithm in blind unmixing of hyperspectral images. Developed by José M. Bioucas-Dias in 2009, the algorithm is fundamentally relevant to tackling simplex-structured matrix factorization and, by extension, nonnegative matrix factorization, which have many applications under their umbrellas. In this article, we revisit SISAL and provide new meanings to this quintessential algorithm. The formulation of SISAL was motivated from a geometric perspective, with no noise. We show that SISAL can be explained as an approximation scheme from a probabilistic simplex component analysis framework, which is statistical and is principally more powerful in accommodating the presence of noise. The algorithm for SISAL was designed based on a successive convex approximation method, with a focus on practical utility. It was not known, by analyses, whether the SISAL algorithm has any kind of guarantee of convergence to a stationary point. By establishing associations between the SISAL algorithm and a line search--based proximal gradient method, we confirm that SISAL can indeed guarantee convergence to a stationary point. Our re-explanation of SISAL also reveals new formulations and algorithms. The performance of these new possibilities is demonstrated by numerical experiments.},
  archive      = {J_SIIMS},
  author       = {Chujun Huang and Mingjie Shao and Wing-Kin Ma and Anthony Man-Cho So},
  doi          = {10.1137/21M1430613},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {591-624},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {SISAL revisited},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distributed stochastic inertial-accelerated methods with
delayed derivatives for nonconvex problems. <em>SIIMS</em>,
<em>15</em>(2), 550–590. (<a
href="https://doi.org/10.1137/21M1435719">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic gradient methods (SGMs) are predominant approaches for solving stochastic optimization. On smooth nonconvex problems, a few acceleration techniques have been applied to improve the convergence rate of SGMs. However, little exploration has been made on applying a certain acceleration technique to a stochastic subgradient method (SsGM) for nonsmooth nonconvex problems. In addition, few efforts have been made to analyze an (accelerated) SsGM with delayed derivatives. The information delay naturally happens in a distributed system, where computing workers do not coordinate with each other. In this paper, we propose an inertial proximal SsGM for solving nonsmooth nonconvex stochastic optimization problems. The proposed method can have guaranteed convergence even with delayed derivative information in a distributed environment. Convergence rate results are established for three classes of nonconvex problems: weakly convex nonsmooth problems with a convex regularizer, composite nonconvex problems with a nonsmooth convex regularizer, and smooth nonconvex problems. For each problem class, the convergence rate is $O(1/K^{\frac{1}{2}})$ in the expected value of the gradient norm square, for $K$ iterations. In a distributed environment, the convergence rate of the proposed method will be slowed down by the information delay. Nevertheless, the slow-down effect will decay with the number of iterations for the latter two problem classes. We test the proposed method on three applications. The numerical results clearly demonstrate the advantages of using the inertial-based acceleration. Furthermore, we observe higher parallelization speed-up in asynchronous updates over the synchronous counterpart, though the former uses delayed derivatives. Our source code is available at https://github.com/RPI-OPT/Inertial-SsGM.},
  archive      = {J_SIIMS},
  author       = {Yangyang Xu and Yibo Xu and Yonggui Yan and Jie Chen},
  doi          = {10.1137/21M1435719},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {550-590},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Distributed stochastic inertial-accelerated methods with delayed derivatives for nonconvex problems},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Variational rician noise removal via splitting on spheres.
<em>SIIMS</em>, <em>15</em>(2), 521–549. (<a
href="https://doi.org/10.1137/21M1452792">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel variational method for Rician noise removal in magnitude-based magnetic resonance (MR) imaging. We first explore the link between the Gaussian noise removal for complex images and the Rician noise removal for magnitude images. Then we establish the constraint optimization model via signal-noise splitting, consisting of a total variation regularizer, two quadratic terms, and a constraint on the field of spheres. Specifically, this constraint represents the forward model of calculating the magnitude of complex images corrupted by Gaussian noises. Namely, the proposed model is completely different from the existing maximum a posteriori based methods, which inevitably involved the sophisticated Bessel function causing high computation costs. It is further efficiently solved by the alternating direction method of multipliers with convergence guarantee. Numerical comparisons with existing variational methods show that the proposed method produces comparable results in terms of image quality, but saves about 50\% of overall computational cost on average.},
  archive      = {J_SIIMS},
  author       = {Zhifang Liu and Huibin Chang and Yuping Duan},
  doi          = {10.1137/21M1452792},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {521-549},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Variational rician noise removal via splitting on spheres},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A spectral estimation framework for phase retrieval via
bregman divergence minimization. <em>SIIMS</em>, <em>15</em>(2),
491–520. (<a href="https://doi.org/10.1137/20M1388061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop a novel framework to guide the design of initial estimates for phase retrieval given measurements realized from an arbitrary forward model. Particularly, we propose a general formalism for spectral initialization as an approximate Bregman loss minimization procedure in the range of the lifted forward model, such that a search over rank-1, positive semidefinite matrices is tractable by the synthesis of a quadratic form using elementwise processing of the intensity-only measurements. Via the Bregman loss approach we transcend the Euclidean sense alignment based similarity measure between phaseless measurements that is inherent in the state-of-the art techniques in the literature, in favor of information theory inspired divergence metrics over the positive reals. We derive spectral methods that perform approximate minimization of Kullback--Leibler and Itakura--Saito divergences over phaseless measurements by using elementwise sample processing functions which are designed under a minimal distortion principle. Our formulation relates and extends existing results on model dependent design of optimal sample processing functions in the literature to a model independent sense of metric-based optimality. Numerical simulations confirm the effectiveness of our approach in imaging problems using synthetic and real data sets.},
  archive      = {J_SIIMS},
  author       = {Bariscan Yonel and Birsen Yazici},
  doi          = {10.1137/20M1388061},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {491-520},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A spectral estimation framework for phase retrieval via bregman divergence minimization},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The modulo radon transform: Theory, algorithms, and
applications. <em>SIIMS</em>, <em>15</em>(2), 455–490. (<a
href="https://doi.org/10.1137/21M1424615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, experiments have been reported where researchers were able to perform high dynamic range (HDR) tomography in a heuristic fashion, by fusing multiple tomographic projections. This approach to HDR tomography has been inspired by HDR photography and inherits the same disadvantages. Taking a computational imaging approach to the HDR tomography problem, we here suggest a new model based on the modulo Radon transform (MRT), which we rigorously introduce and analyze. By harnessing a joint design between hardware and algorithms, we present a single-shot HDR tomography approach, which to our knowledge, is the only approach that is backed by mathematical guarantees. On the hardware front, instead of recording the Radon transform projections that may potentially saturate, we propose to measure modulo values of the same. This ensures that the HDR measurements are folded into a lower dynamic range. On the algorithmic front, our recovery algorithms reconstruct the HDR images from folded measurements. Beyond mathematical aspects such as injectivity and inversion of the MRT for different scenarios including band-limited and approximately compactly supported images, we also provide a first proof-of-concept demonstration. To do so, we implement MRT by experimentally folding tomographic measurements available as an open source dataset using our custom designed modulo hardware. Our reconstruction clearly shows the advantages of our approach for experimental data. In this way, our MRT based solution paves a path for HDR acquisition in a number of related imaging problems.},
  archive      = {J_SIIMS},
  author       = {Matthias Beckmann and Ayush Bhandari and Felix Krahmer},
  doi          = {10.1137/21M1424615},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {455-490},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {The modulo radon transform: Theory, algorithms, and applications},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient boosted DC algorithm for nonconvex image
restoration with rician noise. <em>SIIMS</em>, <em>15</em>(2), 424–454.
(<a href="https://doi.org/10.1137/21M1421660">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image deblurring under Rician noise has attracted considerable attention in imaging science. Frequently appearing in medical imaging, Rician noise leads to an interesting nonconvex optimization problem, termed as the MAP-Rician model, which is based on the Maximum a Posteriori (MAP) estimation approach. As the MAP-Rician model is deeply rooted in Bayesian analysis, we want to understand its mathematical analysis carefully. Moreover, one needs to properly select a suitable algorithm for tackling this nonconvex problem to get the best performance. This paper investigates both issues. Indeed, we first present a theoretical result about the existence of a minimizer for the MAP-Rician model under mild conditions. Next, we aim to adopt an efficient boosted difference of convex functions algorithm (BDCA) to handle this challenging problem. Basically, BDCA combines the classical difference of convex functions algorithm (DCA) with a backtracking line search, which utilizes the point generated by DCA to define a search direction. In particular, we apply a smoothing scheme to handle the nonsmooth total variation (TV) regularization term in the discrete MAP-Rician model. Theoretically, using the Kurdyka--Lojasiewicz (KL) property, the convergence of the numerical algorithm can be guaranteed. We also prove that the sequence generated by the proposed algorithm converges to a stationary point with the objective function values decreasing monotonically. Numerical simulations are then reported to clearly illustrate that our BDCA approach outperforms some state-of-the-art methods for both medical and natural images in terms of image recovery capability and CPU-time cost.},
  archive      = {J_SIIMS},
  author       = {Tingting Wu and Xiaoyu Gu and Zeyu Li and Zhi Li and Jianwei Niu and Tieyong Zeng},
  doi          = {10.1137/21M1421660},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {424-454},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Efficient boosted DC algorithm for nonconvex image restoration with rician noise},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Compressive imaging through optical fiber with partial
speckle scanning. <em>SIIMS</em>, <em>15</em>(2), 387–423. (<a
href="https://doi.org/10.1137/21M1407586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fluorescence imaging through ultrathin fibers is a promising approach to obtain high-resolution imaging with molecular specificity at depths much larger than the scattering mean-free paths of biological tissues. Such imaging techniques, generally termed lensless endoscopy, rely upon the wavefront control at the distal end of a fiber to coherently combine multiple spatial modes of a multicore (MCF) or multimode fiber (MMF). Typically, a spatial light modulator (SLM) is employed to combine hundreds of modes by phase-matching to generate a high-intensity focal spot. This spot is subsequently scanned across the sample to obtain an image. We propose here a novel scanning scheme, partial speckle scanning (PSS), inspired by compressive sensing theory, that avoids the use of an SLM to perform fluorescent imaging with optical fibers with reduced acquisition time. Such a strategy avoids photo-bleaching while keeping high reconstruction quality. We develop our approach on two key properties of the MCF: (i) the ability to easily generate speckles, and (ii) the memory effect that allows one to use fast scan mirrors to shift light patterns. First, we show that speckles are subexponential random fields. Despite their granular structure, an appropriate choice of the reconstruction parameters makes them good candidates to build efficient sensing matrices. Then, we numerically validate our approach and apply it on experimental data. The proposed sensing technique outperforms conventional raster scanning: higher reconstruction quality is achieved with far fewer observations. For a fixed reconstruction quality, our speckle scanning approach is faster than compressive sensing schemes which require changing the speckle pattern for each observation.},
  archive      = {J_SIIMS},
  author       = {Stéphanie Guérit and Siddharth Sivankutty and John Lee and Hervé Rigneault and Laurent Jacques},
  doi          = {10.1137/21M1407586},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {2},
  pages        = {387-423},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Compressive imaging through optical fiber with partial speckle scanning},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parallel transport convolution: Deformable convolutional
networks on manifold-structured data. <em>SIIMS</em>, <em>15</em>(1),
367–386. (<a href="https://doi.org/10.1137/21M1407616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolution has played a prominent role in various applications in science and engineering for many years and has become a key operation in many neural networks. There has been a recent growth of interest in generalizing convolutions on three-dimensional surfaces, often represented as compact manifolds. However, existing approaches cannot preserve all the desirable properties of Euclidean convolutions, namely, compactly supported filters, directionality, and transferability across different manifolds. This paper develops a new generalization of the convolution operation, referred to as parallel transport convolution (PTC), on Riemannian manifolds and their discrete counterparts. PTC is designed based on parallel transportation that can translate information along a manifold and intrinsically preserve directionality. Furthermore, PTC allows for the construction of compactly supported filters and is also robust to manifold deformations. This enables us to perform waveletlike operations and to define convolutional neural networks on curved domains.},
  archive      = {J_SIIMS},
  author       = {Stefan C. Schonsheck and Bin Dong and Rongjie Lai},
  doi          = {10.1137/21M1407616},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {367-386},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Parallel transport convolution: Deformable convolutional networks on manifold-structured data},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Accelerated optimization in the PDE framework: Formulations
for the manifold of diffeomorphisms. <em>SIIMS</em>, <em>15</em>(1),
324–366. (<a href="https://doi.org/10.1137/20M1381927">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of optimization of cost functionals on the infinite dimensional manifold of diffeomorphisms. We present a new class of optimization methods, valid for any optimization problem setup on the space of diffeomorphisms by generalizing Nesterov accelerated optimization to the manifold of diffeomorphisms. While our framework is general for infinite dimensional manifolds, we specifically treat the case of diffeomorphisms, motivated by optical flow problems in computer vision. This is accomplished by building on a recent variational approach to a general class of accelerated optimization methods by Wibisono, Wilson, and Jordan [Proc. Natl. Acad. Sci. USA, 113 (2016), pp. E7351--E7358], which applies in finite dimensions. We generalize that approach to infinite dimensional manifolds. We derive the surprisingly simple continuum evolution equations, which are partial differential equations, for accelerated gradient descent, and relate them to simple mechanical principles from fluid mechanics. Our approach has natural connections to the optimal mass transport problem. This is because one can think of our approach as an evolution of an infinite number of particles endowed with mass (represented with a mass density) that moves in an energy landscape. The mass evolves with the optimization variable and endows the particles with dynamics. This is different from the finite dimensional case where only a single particle moves and hence the dynamics does not depend on the mass. We derive the theory, compute the PDEs for accelerated optimization, and illustrate the behavior of these new accelerated optimization schemes.},
  archive      = {J_SIIMS},
  author       = {Ganesh Sundaramoorthi and Anthony Yezzi and Minas Benyamin},
  doi          = {10.1137/20M1381927},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {324-366},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Accelerated optimization in the PDE framework: Formulations for the manifold of diffeomorphisms},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Diffusion bridges for stochastic hamiltonian systems and
shape evolutions. <em>SIIMS</em>, <em>15</em>(1), 293–323. (<a
href="https://doi.org/10.1137/21M1406283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastically evolving geometric systems are studied in shape analysis and computational anatomy for modeling random evolutions of human organ shapes. The notion of geodesic paths between shapes is central to shape analysis and has a natural generalization as diffusion bridges in a stochastic setting. Simulation of such bridges is key to solving inference and registration problems in shape analysis. We demonstrate how to apply state-of-the-art diffusion bridge simulation methods to recently introduced stochastic shape deformation models, thereby substantially expanding the applicability of such models. We exemplify these methods by estimating template shapes from observed shape configurations while simultaneously learning model parameters.},
  archive      = {J_SIIMS},
  author       = {Alexis Arnaudon and Frank van der Meulen and Moritz Schauer and Stefan Sommer},
  doi          = {10.1137/21M1406283},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {293-323},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Diffusion bridges for stochastic hamiltonian systems and shape evolutions},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new variational model for shape graph registration with
partial matching constraints. <em>SIIMS</em>, <em>15</em>(1), 261–292.
(<a href="https://doi.org/10.1137/21M1418587">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new extension of Riemannian elastic curve matching to a general class of geometric structures, which we call (weighted) shape graphs, that allows for shape registration with partial matching constraints and topological inconsistencies. Weighted shape graphs are the union of an arbitrary number of component curves in Euclidean space with potential connectivity constraints between some of their boundary points, together with a weight function defined on each component curve. The framework of higher-order invariant Sobolev metrics is particularly well suited for constructing notions of distances and geodesics between unparametrized curves. The main difficulty in adapting this framework to the setting of shape graphs is the absence of topological consistency, which typically results in an inadequate search for an exact matching between two shape graphs. We overcome this hurdle by defining an inexact variational formulation of the matching problem between (weighted) shape graphs of any underlying topology, relying on the convenient measure representation given by varifolds to relax the exact matching constraint. We then prove the existence of minimizers to this variational problem when we choose Sobolev metrics of sufficient regularity and a total variation (TV) regularization on the weight function. We propose a numerical optimization approach which adapts the smoothed fast iterative shrinkage-thresholding algorithm (SFISTA) to deal with $TV$ norm minimization and allows us to reduce the matching problem to solving a sequence of smooth unconstrained minimization problems. We finally illustrate the capabilities of our new model through several examples showcasing its ability to tackle partially observed and topologically varying data.},
  archive      = {J_SIIMS},
  author       = {Yashil Sukurdeep and Martin Bauer and Nicolas Charon},
  doi          = {10.1137/21M1418587},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {261-292},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A new variational model for shape graph registration with partial matching constraints},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An image registration model in electron backscatter
diffraction. <em>SIIMS</em>, <em>15</em>(1), 228–260. (<a
href="https://doi.org/10.1137/21M1426353">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, variational methods were successfully applied for computing the optical flow in gray and RGB-valued image sequences. A crucial assumption in these models is that pixel-values do not change under transformations. Nowadays, modern image acquisition techniques, such as electron backscatter diffraction (EBSD) used in materials science, can capture images with values in nonlinear spaces. Here, the image values belong to the quotient space ${SO}(3)/ \mathcal S$ of the special orthogonal group modulo the discrete symmetry group of the crystal. For such data, the assumption that pixel-values remain unchanged under transformations appears to be no longer valid. Hence, we propose a variational model for determining the optical flow in ${SO}(3)/\mathcal S$-valued image sequences, taking into account the dependence of pixel-values on the transformation. More precisely, the data is transformed according to the rotation part in the polar decomposition of the Jacobian of the transformation. To model nonsmooth transformations without obtaining so-called staircasing effects, we propose using total generalized variation, such as prior. Then, we prove existence of a minimizer for our model and explain how it can be discretized and minimized by a primal-dual algorithm. Numerical examples illustrate the performance of our method.},
  archive      = {J_SIIMS},
  author       = {Manuel Gräf and Sebastian Neumayer and Ralf Hielscher and Gabriele Steidl and Moritz Liesegang and Tilmann Beck},
  doi          = {10.1137/21M1426353},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {228-260},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {An image registration model in electron backscatter diffraction},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Patch-based image restoration using expectation propagation.
<em>SIIMS</em>, <em>15</em>(1), 192–227. (<a
href="https://doi.org/10.1137/21M1427541">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new Expectation Propagation (EP) framework for image restoration using patch-based prior distributions. While Monte Carlo techniques are classically used to sample from intractable posterior distributions, they can suffer from scalability issues in high-dimensional inference problems such as image restoration. To address this issue, EP is used here to approximate the posterior distributions using products of multivariate Gaussian densities. Moreover, imposing structural constraints on the covariance matrices of these densities allows for greater scalability and distributed computation. While the method is naturally suited to handle additive Gaussian observation noise, it can also be extended to non-Gaussian noise. Experiments conducted for denoising, inpainting, and deconvolution problems with Gaussian and Poisson noise illustrate the potential benefits of such a flexible approximate Bayesian method for uncertainty quantification in imaging problems, at a reduced computational cost compared to sampling techniques.},
  archive      = {J_SIIMS},
  author       = {Dan Yao and Stephen McLaughlin and Yoann Altmann},
  doi          = {10.1137/21M1427541},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {192-227},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Patch-based image restoration using expectation propagation},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Direct estimation of appearance models for segmentation.
<em>SIIMS</em>, <em>15</em>(1), 172–191. (<a
href="https://doi.org/10.1137/21M1400729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image segmentation algorithms often depend on appearance models that characterize the distribution of pixel values in different image regions. We describe a new approach for estimating appearance models directly from an image, without explicit consideration of the pixels that make up each region. Our approach is based on novel algebraic expressions that relate local image statistics to the appearance of spatially coherent regions. We describe two algorithms that can use the aforementioned algebraic expressions to estimate appearance models directly from an image. The first algorithm solves a system of linear and quadratic equations using a least squares formulation. The second algorithm is a spectral method based on an eigenvector computation. We present experimental results that demonstrate the proposed methods work well in practice and lead to effective image segmentation algorithms.},
  archive      = {J_SIIMS},
  author       = {Jeova F. S. Rocha Neto and Pedro Felzenszwalb and Marilyn Vazquez},
  doi          = {10.1137/21M1400729},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {172-191},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Direct estimation of appearance models for segmentation},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Limits of accuracy for parameter estimation and localization
in single-molecule microscopy via sequential monte carlo methods.
<em>SIIMS</em>, <em>15</em>(1), 139–171. (<a
href="https://doi.org/10.1137/21M1422823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assessing the quality of parameter estimates for models describing the motion of single molecules in cellular environments is an important problem in fluorescence microscopy. In this work, we consider the fundamental data model, where molecules emit photons at random time instances and these photons arrive at random locations on the detector according to complex point spread functions (PSFs). The randomness and non-Gaussian PSF of the detection process, and the random trajectory of the molecule, make inference challenging. Moreover, the presence of other closely spaced molecules causes further uncertainty in the origin of the measurements, which impacts the statistical precision of the estimates. We quantify the limits of accuracy of model parameter estimates and separation distance between closely spaced molecules (known as the resolution problem) by computing the Cramér--Rao lower bound (CRLB), or equivalently the inverse of the Fisher information matrix (FIM), for the variance of estimates. Results on the CRLB obtained from the fundamental model are crucial, in that they provide a lower bound for more practical scenarios. While analytic expressions for the FIM can be derived for static and deterministically moving molecules, the analytical tools to evaluate the FIM for molecules whose trajectories follow stochastic differential equations are still for the most part missing. We address this by presenting a general sequential Monte Carlo (SMC) based methodology for both parameter inference and computing the desired accuracy limits for nonstatic molecules and a non-Gaussian fundamental detection model. For the first time, we are able to estimate the FIM for stochastically moving molecules observed through the Airy and Born and Wolf detection models. This is achieved by estimating the score and observed information matrix via SMC. We summarize the outcome of our numerical work by delineating the qualitative behaviors for the accuracy limits as functions of various experimental settings like collected photon count, molecule diffusion, etc. We also verify that we can recover known results from the static molecule case.},
  archive      = {J_SIIMS},
  author       = {A. Marie d&#39;Avigneau and Sumeetpal S. Singh and Raimund J. Ober},
  doi          = {10.1137/21M1422823},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {139-171},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Limits of accuracy for parameter estimation and localization in single-molecule microscopy via sequential monte carlo methods},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hyperspectral super-resolution accounting for spectral
variability: Coupled tensor LL1-based recovery and blind unmixing of the
unknown super-resolution image. <em>SIIMS</em>, <em>15</em>(1), 110–138.
(<a href="https://doi.org/10.1137/21M1409354">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose to jointly solve the hyperspectral super-resolution problem and the unmixing problem of the underlying super-resolution image using a coupled LL1 block-tensor decomposition. We consider a spectral variability phenomenon occurring between the observed low-resolution images. Exact recovery conditions for the image and mixing factors are provided. We propose two algorithms, an unconstrained one and another one subject to nonnegativity constraints, to solve the problems at hand. We showcase performance of the proposed approach on synthetic and real images.},
  archive      = {J_SIIMS},
  author       = {Clémence Prévost and Ricardo A. Borsoi and Konstantin Usevich and David Brie and José C. M. Bermudez and Cédric Richard},
  doi          = {10.1137/21M1409354},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {110-138},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Hyperspectral super-resolution accounting for spectral variability: Coupled tensor LL1-based recovery and blind unmixing of the unknown super-resolution image},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A variational inequality model for the construction of
signals from inconsistent nonlinear equations. <em>SIIMS</em>,
<em>15</em>(1), 84–109. (<a
href="https://doi.org/10.1137/21M1420368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building up on classical linear formulations, we posit that a broad class of problems in signal synthesis and in signal recovery are reducible to the basic task of finding a point in a closed convex subset of a Hilbert space that satisfies a number of nonlinear equations involving firmly nonexpansive operators. We investigate this formalism in the case when, due to inaccurate modeling or perturbations, the nonlinear equations are inconsistent. A relaxed formulation of the original problem is proposed in the form of a variational inequality. The properties of the relaxed problem are investigated, and a provenly convergent block-iterative algorithm, whereby only blocks of the underlying firmly nonexpansive operators are activated at a given iteration, is devised to solve it. Numerical experiments illustrate robust recoveries in several signal and image processing applications.},
  archive      = {J_SIIMS},
  author       = {Patrick L. Combettes and Zev C. Woodstock},
  doi          = {10.1137/21M1420368},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {84-109},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A variational inequality model for the construction of signals from inconsistent nonlinear equations},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The linearized hellinger–kantorovich distance.
<em>SIIMS</em>, <em>15</em>(1), 45–83. (<a
href="https://doi.org/10.1137/21M1400080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we study the local linearization of the Hellinger--Kantorovich distance via its Riemannian structure. We give explicit expressions for the logarithmic and exponential maps and identify a suitable notion of a Riemannian inner product. Samples can thus be represented as vectors in the tangent space of a suitable reference measure where the norm locally approximates the original metric. Working with the local linearization and the corresponding embeddings allows for the advantages of the Euclidean setting, such as faster computations and a plethora of data analysis tools, while still enjoying approximately the descriptive power of the Hellinger--Kantorovich metric.},
  archive      = {J_SIIMS},
  author       = {Tianji Cai and Junyi Cheng and Bernhard Schmitzer and Matthew Thorpe},
  doi          = {10.1137/21M1400080},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {45-83},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {The linearized hellinger--kantorovich distance},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learnable empirical mode decomposition based on mathematical
morphology. <em>SIIMS</em>, <em>15</em>(1), 23–44. (<a
href="https://doi.org/10.1137/21M1417867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Empirical mode decomposition (EMD) is a fully data driven method for multiscale decomposing signals into a set of components known as intrinsic mode functions. EMD is based on lower and upper envelopes of the signal in an iterated decomposition scheme. In this paper, we put forward a simple yet effective method to learn EMD from data by means of morphological operators. We propose an end-to-end framework by incorporating morphological EMD operators into deeply learned representations, trained using standard backpropagation principle and gradient descent-based optimization algorithms. Three generalizations of morphological EMD are proposed: (a) by varying the family of structuring functions, (b) by varying the pair of morphological operators used to calculate the envelopes, and (c) by considering a convex sum of envelopes instead of the mean point used in classical EMD. We discuss in particular the invariances that are induced by the morphological EMD representation. Experimental results on supervised classification of hyperspectral images by one-dimensional convolutional networks demonstrate the interest of our method.},
  archive      = {J_SIIMS},
  author       = {Santiago Velasco-Forero and R. Pagès and Jesus Angulo},
  doi          = {10.1137/21M1417867},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {23-44},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Learnable empirical mode decomposition based on mathematical morphology},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel mesh denoising method based on relaxed second-order
total generalized variation. <em>SIIMS</em>, <em>15</em>(1), 1–22. (<a
href="https://doi.org/10.1137/21M1397945">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the paper, we develop a relaxed second-order total generalized variation model on triangulated surfaces, which couples the first-order gradient operator and the weighted divergence operator. An iterative two-stage mesh denoising method is proposed with the relaxed model, which contains facet normal filtering based on the relaxed model and robust vertex updating. The nondifferentiable optimization problem is solved by an iterative algorithm based on variable splitting and augmented Lagrangian method. Our denoising method is discussed and compared to several state-of-the-art techniques in terms of reconstruction quality, quantitative comparison, and computational costs. Experiments indicate that our approach is comparable to state-of-the-art algorithms at reasonable costs. It can produce denoising results with more structures, alleviate the staircase effect (false edges), and prevent edge flips. The quantitative errors also verify that the newly proposed algorithm is robust numerically.},
  archive      = {J_SIIMS},
  author       = {Huayan Zhang and Zhishuai He and Xiaochao Wang},
  doi          = {10.1137/21M1397945},
  journal      = {SIAM Journal on Imaging Sciences},
  number       = {1},
  pages        = {1-22},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A novel mesh denoising method based on relaxed second-order total generalized variation},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
