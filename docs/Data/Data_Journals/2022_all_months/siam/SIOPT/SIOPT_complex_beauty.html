<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SIOPT_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="siopt---111">SIOPT - 111</h2>
<ul>
<li><details>
<summary>
(2022). An unbiased approach to low rank recovery. <em>SIOPT</em>,
<em>32</em>(4), 2969–2996. (<a
href="https://doi.org/10.1137/19M1294800">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low rank recovery problems have been a subject of intense study in recent years. While the rank function is useful for regularization it is difficult to optimize due to its nonconvexity and discontinuity. The standard remedy for this is to exchange the rank function for the convex nuclear norm, which is known to favor low rank solutions under certain conditions. On the downside the nuclear norm exhibits a shrinking bias that can severely distort the solution in the presence of noise, which motivates the use of stronger nonconvex alternatives. In this paper we study two such formulations. We characterize the critical points and give sufficient conditions for a low rank stationary point to be unique. Moreover, we derive conditions that ensure global optimality of the low rank stationary point and show that these hold under moderate noise levels.},
  archive      = {J_SIOPT},
  author       = {Marcus Carlsson and Daniele Gerosa and Carl Olsson},
  doi          = {10.1137/19M1294800},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2969-2996},
  shortjournal = {SIAM J. Optim.},
  title        = {An unbiased approach to low rank recovery},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Frank–wolfe methods with an unbounded feasible region and
applications to structured learning. <em>SIOPT</em>, <em>32</em>(4),
2938–2968. (<a href="https://doi.org/10.1137/20M1387869">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Frank--Wolfe method is a popular algorithm for solving large-scale convex optimization problems appearing in structured statistical learning. However, the traditional Frank--Wolfe method can only be applied when the feasible region is bounded, which limits its applicability in practice. Motivated by two applications in statistical learning, the $\ell_1$ trend filtering problem and matrix optimization problems with generalized nuclear norm constraints, we study a family of convex optimization problems where the unbounded feasible region is the direct sum of an unbounded linear subspace and a bounded constraint set. We propose two new Frank--Wolfe methods, the unbounded Frank--Wolfe method and the unbounded away-step Frank--Wolfe method, for solving a family of convex optimization problems with this class of unbounded feasible regions. We show that under proper regularity conditions, the unbounded Frank--Wolfe method has an $O(1/k)$ sublinear convergence rate, and the unbounded away-step Frank--Wolfe method has a linear convergence rate, matching the best-known results for the Frank--Wolfe method when the feasible region is bounded. Furthermore, computational experiments indicate that our proposed methods appear to outperform alternative solvers.},
  archive      = {J_SIOPT},
  author       = {Haoyue Wang and Haihao Lu and Rahul Mazumder},
  doi          = {10.1137/20M1387869},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2938-2968},
  shortjournal = {SIAM J. Optim.},
  title        = {Frank--wolfe methods with an unbounded feasible region and applications to structured learning},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic stochastic variational inequalities and convergence
of discrete approximation. <em>SIOPT</em>, <em>32</em>(4), 2909–2937.
(<a href="https://doi.org/10.1137/21M145536X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies dynamic stochastic variational inequalities (DSVIs) to deal with uncertainties in dynamic variational inequalities (DVIs). We show the existence and uniqueness of a solution for a class of DSVIs in $C^1 \times {\cal Y}$, where $C^1$ is the space of continuously differentiable functions and ${\cal Y}$ is the space of measurable functions, and discuss non-Zeno behavior. We use the sample average approximation (SAA) and time-stepping schemes as discrete approximation for the uncertainty and dynamics of the DSVIs. We then show the uniform convergence and an exponential convergence rate of the SAA of the DSVI. A time-stepping EDIIS (energy direct inversion on the iterative subspace) method is proposed to solve the DVI arising from the SAA of DSVI; its convergence is established. Our results are illustrated by a point-queue model for an instantaneous dynamic user equilibrium in traffic assignment problems.},
  archive      = {J_SIOPT},
  author       = {Xiaojun Chen and Jinglai Shen},
  doi          = {10.1137/21M145536X},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2909-2937},
  shortjournal = {SIAM J. Optim.},
  title        = {Dynamic stochastic variational inequalities and convergence of discrete approximation},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the divergence of decentralized nonconvex optimization.
<em>SIOPT</em>, <em>32</em>(4), 2879–2908. (<a
href="https://doi.org/10.1137/20M1353149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we study a generic class of decentralized algorithms in which $N$ agents jointly optimize the nonconvex objective function $f({\mathbf u}):=1/N\sum_{i=1}^{N}f_i({\mathbf u})$, while only communicating with their neighbors. This class of problems has become popular in modeling many signal processing and decentralized machine learning applications, and efficient algorithms have been proposed for such a type of problem. However, most of the existing decentralized algorithms require that the local function gradients $\nabla f_i$&#39;s as well as the average function gradient $\nabla f$ are Lipschitz, that is, the local Lipschitz conditions (LLC) and global Lipschitz condition (GLC) are satisfied. In this work, we first demonstrate the importance of the above Lipschitzness assumptions on the state-of-the-art decentralized algorithms. First, by constructing a series of examples, we show that when the LLC on the local function gradient $\nabla f_i$&#39;s are not satisfied, a number of state-of-the-art decentralized algorithms diverge, even if the global Lipschitz condition (GLC) still holds. This observation brings out a fundamental theoretical issue of the existing decentralized algorithms---their convergence conditions are strictly stronger than centralized algorithms such as the gradient descent, which only requires the GLC. Our observation raises an important open question: How to design decentralized algorithms when the LLC, or even the GLC, is not satisfied? To address this question, we design two first-order algorithms, which are capable of computing stationary solutions of the original problem with neither the LLC nor the GLC condition. In particular, we show that the proposed algorithms converge sublinearly to a certain $\epsilon$-stationary solution, where the precise rate depends on various algorithmic and problem parameters. In particular, if the local function $f_i$&#39;s are lower bounded $Q$th order polynomials, then the rate becomes $\mathcal{O}(1/\epsilon^{Q-1})$ for $Q\ge 2$ (where the $\mathcal{O}$ notation hides some constants such as dependency on the network topology). Such a rate is tight for the special case of $Q=2$ where each $f_i$ satisfies LLC. To our knowledge, this is the first attempt that studies decentralized nonconvex optimization problems with neither the LLC nor the GLC.},
  archive      = {J_SIOPT},
  author       = {Mingyi Hong and Siliang Zeng and Junyu Zhang and Haoran Sun},
  doi          = {10.1137/20M1353149},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2879-2908},
  shortjournal = {SIAM J. Optim.},
  title        = {On the divergence of decentralized nonconvex optimization},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). From calmness to hoffman constants for linear semi-infinite
inequality systems. <em>SIOPT</em>, <em>32</em>(4), 2859–2878. (<a
href="https://doi.org/10.1137/21M1418228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we focus on different---global, semilocal, and local---versions of Hoffman-type inequalities expressed in a variational form. In a first stage our analysis is developed for generic multifunctions between metric spaces, and we finally deal with the feasible set mapping associated with linear semi-infinite inequality systems (finitely many variables and possibly infinitely many constraints) parameterized by their right-hand sides. The Hoffman modulus is shown to coincide with the Lipschitz upper semicontinuity modulus and the supremum of calmness moduli when confined to multifunctions with a convex graph and closed images in a reflexive Banach space, which is the case for our feasible set mapping. Moreover, for this particular multifunction a formula---involving only the system&#39;s left-hand side---of the global Hoffman constant is derived, providing a generalization to our semi-infinite context of finite counterparts developed in the literature. In the particular case of locally polyhedral systems, the paper also provides a point-based formula for the (semilocal) Hoffman modulus in terms of the calmness moduli at certain feasible points (extreme points when the nominal feasible set contains no lines), yielding a practically tractable expression for finite systems.},
  archive      = {J_SIOPT},
  author       = {J. Camacho and M. J. Cánovas and J. Parra},
  doi          = {10.1137/21M1418228},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2859-2878},
  shortjournal = {SIAM J. Optim.},
  title        = {From calmness to hoffman constants for linear semi-infinite inequality systems},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Extremal probability bounds in combinatorial optimization.
<em>SIOPT</em>, <em>32</em>(4), 2828–2858. (<a
href="https://doi.org/10.1137/21M1442504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we compute the tightest possible bounds on the probability that the optimal value of a combinatorial optimization problem in maximization form with a random objective exceeds a given number, assuming only knowledge of the marginal distributions of the objective coefficient vector. The bounds are “extremal&#39; since they are valid across all joint distributions with the given marginals. We analyze the complexity of computing the bounds, assuming discrete marginals, and identify instances when the bounds are computable in polynomial time. For compact 0/1 V-polytopes, we show that the tightest upper bound is weakly NP-hard to compute by providing a pseudopolynomial time algorithm. On the other hand, the tightest lower bound is shown to be strongly NP-hard to compute for compact 0/1 V-polytopes by restricting our attention to Bernoulli random variables. For compact 0/1 H-polytopes, for the special case of PERT networks arising in project management, we show that the tightest upper bound is weakly NP-hard to compute by providing a pseudopolynomial time algorithm. The results in the paper complement existing results in the literature for computing the probability with independent random variables.},
  archive      = {J_SIOPT},
  author       = {Divya Padmanabhan and Selin Damla Ahipasaoglu and Arjun Ramachandra and Karthik Natarajan},
  doi          = {10.1137/21M1442504},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2828-2858},
  shortjournal = {SIAM J. Optim.},
  title        = {Extremal probability bounds in combinatorial optimization},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Revisiting landscape analysis in deep neural networks:
Eliminating decreasing paths to infinity. <em>SIOPT</em>,
<em>32</em>(4), 2797–2827. (<a
href="https://doi.org/10.1137/19M1299074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional landscape analysis of deep neural networks aims to show that no suboptimal local minima exist in some appropriate sense. From this, one may be tempted to conclude that descent algorithms which escape saddle points will reach a good local minimum. However, basic optimization theory tell us that it is also possible for a descent algorithm to diverge to infinity if there are paths leading to infinity, along which the loss function decreases. It is not clear whether for nonlinear neural networks there exists one setting such that “no bad local-min” and “no decreasing paths to infinity” can be simultaneously achieved. In this paper, we give the first positive answer to this question. More specifically, for a large class of overparameterized deep neural networks with appropriate regularizers, the loss function has no bad local minima and no decreasing paths to infinity. The key mathematical trick is to show that the set of regularizers, which may be undesirable, can be viewed as the image of a Lipschitz continuous mapping from a lower-dimensional Euclidean space to a higher-dimensional Euclidean space and thus has zero measure.},
  archive      = {J_SIOPT},
  author       = {Shiyu Liang and Ruoyu Sun and R. Srikant},
  doi          = {10.1137/19M1299074},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2797-2827},
  shortjournal = {SIAM J. Optim.},
  title        = {Revisiting landscape analysis in deep neural networks: Eliminating decreasing paths to infinity},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Convex representatives of the value function and aumann
integrals in normed spaces. <em>SIOPT</em>, <em>32</em>(4), 2773–2796.
(<a href="https://doi.org/10.1137/22M1471377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convex representatives are proposed for the value function of an infinite-dimensional constrained nonconvex variational problem. All the involved variables in this problem take their values in (possibly of infinite dimension, not necessarily separable or complete) normed spaces, while the associated measure can be any $\sigma$-finite, nonnegative, and nonatomic complete measure. This in particular shows that the closure hull of the (possibly nonconvex) value function is always convex, as long as the sense of the integral within the cone-valued functional constraint is given and the type of the closure is appropriately determined. Correspondingly, similar convexity properties for the Aumann integral in general normed spaces of infinite dimension are established. Applications are given in a fairly general positively homogeneous framework.},
  archive      = {J_SIOPT},
  author       = {F. Flores-Bazán and A. Hantoute},
  doi          = {10.1137/22M1471377},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2773-2796},
  shortjournal = {SIAM J. Optim.},
  title        = {Convex representatives of the value function and aumann integrals in normed spaces},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). New first-order algorithms for stochastic variational
inequalities. <em>SIOPT</em>, <em>32</em>(4), 2745–2772. (<a
href="https://doi.org/10.1137/21M1441778">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose two new solution schemes to solve the stochastic strongly monotone variational inequality (VI) problems: the stochastic extra-point solution scheme and the stochastic extra-momentum solution scheme. The first one is a general scheme based on updating the iterative sequence and an auxiliary extra-point sequence. In the case of a deterministic VI model, this approach includes several state-of-the-art first-order methods as its special cases. The second scheme combines two momentum-based directions: the so-called heavy-ball direction and the optimism direction, where only one projection per iteration is required in its updating process. We show that if the variance of the stochastic oracle is appropriately controlled, then both schemes can be made to achieve optimal iteration complexity of $\mathcal{O}\left(\kappa\ln\left(\frac{1}{\epsilon}\right)\right)$ to reach an $\epsilon$-solution for a strongly monotone VI problem with condition number $\kappa$. As a specific application to stochastic VI, we demonstrate how to incorporate a zeroth-order approach for solving stochastic minimax saddle-point problems in our schemes, where only noisy and biased samples of the objective can be obtained, with a total sample complexity of $\mathcal{O}\left(\frac{\kappa}{\epsilon}\right)$.},
  archive      = {J_SIOPT},
  author       = {Kevin Huang and Shuzhong Zhang},
  doi          = {10.1137/21M1441778},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2745-2772},
  shortjournal = {SIAM J. Optim.},
  title        = {New first-order algorithms for stochastic variational inequalities},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Maximizing convergence time in network averaging dynamics
subject to edge removal. <em>SIOPT</em>, <em>32</em>(4), 2718–2744. (<a
href="https://doi.org/10.1137/21M1458867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the consensus interdiction problem (CIP), in which the goal is to maximize the convergence time of consensus averaging dynamics subject to removing a limited number of network edges. We first show that CIP can be cast as an effective resistance interdiction problem (ERIP), in which the goal is to remove a limited number of network edges to maximize the effective resistance between a source node and a sink node. We show that ERIP is strongly NP-hard, even for bipartite graphs of diameter three with fixed source/sink edges, and establish the same hardness result for the CIP. We then show that both ERIP and CIP cannot be approximated up to a (nearly) polynomial factor assuming the exponential time hypothesis. Subsequently, we devise a polynomial-time $mn$-approximation algorithm for the ERIP that only depends on the number of nodes $n$ and the number of edges $m$ but is independent of the size of edge resistances. Finally, using a quadratic program formulation for the CIP, we devise an iterative approximation algorithm to find a first-order stationary solution for the CIP and evaluate its good performance through numerical experiments.},
  archive      = {J_SIOPT},
  author       = {S. Rasoul Etesami},
  doi          = {10.1137/21M1458867},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2718-2744},
  shortjournal = {SIAM J. Optim.},
  title        = {Maximizing convergence time in network averaging dynamics subject to edge removal},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Riemannian conjugate gradient methods: General framework and
specific algorithms with convergence analyses. <em>SIOPT</em>,
<em>32</em>(4), 2690–2717. (<a
href="https://doi.org/10.1137/21M1464178">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conjugate gradient methods are important first-order optimization algorithms both in Euclidean spaces and on Riemannian manifolds. However, while various types of conjugate gradient methods have been studied in Euclidean spaces, there are relatively fewer studies for those on Riemannian manifolds (i.e., Riemannian conjugate gradient methods). This paper proposes a novel general framework that unifies existing Riemannian conjugate gradient methods such as the ones that utilize a vector transport or inverse retraction. The proposed framework also develops other methods that have not been covered in previous studies. Furthermore, conditions for the convergence of a class of algorithms in the proposed framework are clarified. Moreover, the global convergence properties of several specific types of algorithms are extensively analyzed. The analysis provides the theoretical results for some algorithms in a more general setting than the existing studies and new developments for other algorithms. Numerical experiments are performed to confirm the validity of the theoretical results. The experimental results are used to compare the performances of several specific algorithms in the proposed framework.},
  archive      = {J_SIOPT},
  author       = {Hiroyuki Sato},
  doi          = {10.1137/21M1464178},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2690-2717},
  shortjournal = {SIAM J. Optim.},
  title        = {Riemannian conjugate gradient methods: General framework and specific algorithms with convergence analyses},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Preference robust modified optimized certainty equivalent.
<em>SIOPT</em>, <em>32</em>(4), 2662–2689. (<a
href="https://doi.org/10.1137/21M1448069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ben-Tal and Teboulle [Management Sci., 32 (1986), pp. 1445--1466] introduce the concept of optimized certainty equivalent (OCE) of an uncertain outcome as the maximum present value of a combination of the cash to be taken out from the uncertain income at present and the expected utility value of the remaining uncertain income. In this paper, we consider two variations of the OCE. First, we introduce a modified OCE by maximizing the combination of the utility of the cash and the expected utility of the remaining uncertain income so that the combined quantity is in a unified utility value. Second, we consider a situation where the true utility function is unknown but it is possible to use partially available information to construct a set of plausible utility functions. To mitigate the risk arising from the ambiguity, we introduce a robust model where the modified OCE is based on the worst-case utility function from the ambiguity set. In the case when the ambiguity set of utility functions is constructed by a Kantorovich ball centered at a nominal utility function, we show how the modified OCE and the corresponding worst-case utility function can be identified by solving two linear programs alternatively. We also show that the robust modified OCE is statistically robust in a data-driven environment where the underlying data are potentially contaminated. Some preliminary numerical results are reported to demonstrate the performance of the modified OCE and the robust modified OCE model.},
  archive      = {J_SIOPT},
  author       = {Qiong Wu and Huifu Xu},
  doi          = {10.1137/21M1448069},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2662-2689},
  shortjournal = {SIAM J. Optim.},
  title        = {Preference robust modified optimized certainty equivalent},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MINRES: From negative curvature detection to monotonicity
properties. <em>SIOPT</em>, <em>32</em>(4), 2636–2661. (<a
href="https://doi.org/10.1137/21M143666X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conjugate gradient method (CG) has long been the workhorse for inner-iterations of second-order algorithms for large-scale nonconvex optimization. Prominent examples include line-search based algorithms, e.g., Newton-CG, and those based on a trust-region framework, e.g., CG-Steihaug. This is mainly thanks to CG&#39;s several favorable properties, including certain monotonicity properties and its inherent ability to detect negative curvature directions, which can arise in nonconvex optimization. This is despite the fact that the iterative method-of-choice when it comes to real symmetric but potentially indefinite matrices is arguably the celebrated minimal residual method (MINRES). However, limited understanding of similar properties implied by MINRES in such settings has restricted its applicability within nonconvex optimization algorithms. We establish several such nontrivial properties of MINRES, including certain useful monotonicity as well as an inherent ability to detect negative curvature directions. These properties allow MINRES to be considered as a potentially superior alternative to CG for all Newton-type nonconvex optimization algorithms that employ CG as their subproblem solver.},
  archive      = {J_SIOPT},
  author       = {Yang Liu and Fred Roosta},
  doi          = {10.1137/21M143666X},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2636-2661},
  shortjournal = {SIAM J. Optim.},
  title        = {MINRES: From negative curvature detection to monotonicity properties},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sum-of-squares hierarchies for polynomial optimization and
the christoffel–darboux kernel. <em>SIOPT</em>, <em>32</em>(4),
2612–2635. (<a href="https://doi.org/10.1137/21M1458338">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider the problem of minimizing a polynomial $f$ over a compact semialgebraic set $\mathbf{X} \subseteq \mathbb{R}^n$. Lasserre introduces hierarchies of semidefinite programs to approximate this hard optimization problem, based on classical sum-of-squares certificates of positivity of polynomials due to Putinar and Schmüdgen. When $\mathbf{X}$ is the unit ball or the standard simplex, we show that the hierarchies based on the Schmüdgen-type certificates converge to the global minimum of $f$ at a rate in $O(1/r^2)$, matching recently obtained convergence rates for the hypersphere and hypercube $[-1,1]^n$. For our proof, we establish a connection between Lasserre&#39;s hierarchies and the Christoffel--Darboux kernel, and make use of closed form expressions for this kernel derived by Xu.},
  archive      = {J_SIOPT},
  author       = {Lucas Slot},
  doi          = {10.1137/21M1458338},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2612-2635},
  shortjournal = {SIAM J. Optim.},
  title        = {Sum-of-squares hierarchies for polynomial optimization and the christoffel--darboux kernel},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). New primal-dual algorithms for a class of nonsmooth and
nonlinear convex-concave minimax problems. <em>SIOPT</em>,
<em>32</em>(4), 2580–2611. (<a
href="https://doi.org/10.1137/21M1408683">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop new primal-dual algorithms to solve a class of nonsmooth and nonlinear convex-concave minimax problems, which covers many existing and brand-new models as special cases. Our approach relies on a combination of a generalized augmented Lagrangian function, Nesterov&#39;s accelerated scheme, and adaptive parameter updating strategies. Our algorithmic framework is single-loop and unifies two important settings: general convex-concave and convex-linear cases. Under mild assumptions, our algorithms achieve $\mathcal{O}(1/k)$ convergence rates through three different criteria: primal-dual gap, primal objective residual, and dual objective residual, where $k$ is the iteration counter. Our rates are both ergodic (i.e., on a weighted averaging sequence) and nonergodic (i.e., on the last-iterate sequence). These convergence rates can be boosted up to $\mathcal{O}(1/k^2)$ if only one objective term is strongly convex (or, equivalently, its conjugate is $L$-smooth). To the best of our knowledge, this is the first algorithm achieving optimal rates on the primal last-iterate sequence for convex-linear minimax problems. As a byproduct, we specify our algorithms to solve a general convex cone constrained program with both ergodic and nonergodic rate guarantees. We test our algorithms and compare them with two recent methods on two numerical examples.},
  archive      = {J_SIOPT},
  author       = {Yuzixuan Zhu and Deyi Liu and Quoc Tran-Dinh},
  doi          = {10.1137/21M1408683},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2580-2611},
  shortjournal = {SIAM J. Optim.},
  title        = {New primal-dual algorithms for a class of nonsmooth and nonlinear convex-concave minimax problems},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Model-based derivative-free methods for convex-constrained
optimization. <em>SIOPT</em>, <em>32</em>(4), 2552–2579. (<a
href="https://doi.org/10.1137/21M1460971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a model-based derivative-free method for optimization subject to general convex constraints, which we assume are unrelaxable and accessed only through a projection operator that is cheap to evaluate. We prove global convergence and a worst-case complexity of $O(\epsilon^{-2})$ iterations and objective evaluations for nonconvex functions, matching results for the unconstrained case. We introduce new, weaker requirements on model accuracy compared to existing methods. As a result, sufficiently accurate interpolation models can be constructed only using feasible points. We develop a comprehensive theory of interpolation set management in this regime for linear and composite linear models. We implement our approach for nonlinear least-squares problems and demonstrate strong practical performance compared to general-purpose solvers.},
  archive      = {J_SIOPT},
  author       = {Matthew Hough and Lindon Roberts},
  doi          = {10.1137/21M1460971},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2552-2579},
  shortjournal = {SIAM J. Optim.},
  title        = {Model-based derivative-free methods for convex-constrained optimization},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Maximum a posteriori inference of random dot product graphs
via conic programming. <em>SIOPT</em>, <em>32</em>(4), 2527–2551. (<a
href="https://doi.org/10.1137/20M1389406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a convex cone program to infer the latent probability matrix of a random dot product graph (RDPG). The optimization problem maximizes the Bernoulli maximum likelihood function with an added nuclear norm regularization term. The dual problem has a particularly nice form, related to the well-known semidefinite program relaxation of the maxcut problem. Using the primal-dual optimality conditions, we bound the entries and rank of the primal and dual solutions. Furthermore, we bound the optimal objective value and prove asymptotic consistency of the probability estimates of a slightly modified model under mild technical assumptions. Our experiments on synthetic RDPGs not only recover natural clusters, but also reveal the underlying low-dimensional geometry of the original data. We also demonstrate that the method recovers latent structure in the Karate Club Graph and synthetic U.S. Senate vote graphs and is scalable to graphs with up to a few hundred nodes.},
  archive      = {J_SIOPT},
  author       = {David X. Wu and David Palmer and Daryl R. DeFord},
  doi          = {10.1137/20M1389406},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2527-2551},
  shortjournal = {SIAM J. Optim.},
  title        = {Maximum a posteriori inference of random dot product graphs via conic programming},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Convergent algorithms for a class of convex semi-infinite
programs. <em>SIOPT</em>, <em>32</em>(4), 2493–2526. (<a
href="https://doi.org/10.1137/21M1431047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We focus on convex semi-infinite programs with an infinite number of quadratically parametrized constraints. In our setting, the lower-level problem, i.e., the problem of finding the constraint that is the most violated by a given point, is not necessarily convex. We propose a new convergent approach to solve these semi-infinite programs. Based on the Lagrangian dual of the lower-level problem, we derive a convex and tractable restriction of the considered semi-infinite programming problem. We state sufficient conditions for the optimality of this restriction. If these conditions are not met, the restriction is enlarged through an inner-outer approximation algorithm, and its value converges to the value of the original semi-infinite problem. This new algorithmic approach is compared with the classical cutting plane algorithm. We also propose a new rate of convergence of the cutting plane algorithm, directly related to the iteration index, derived when the objective function is strongly convex, and under a strict feasibility assumption. We successfully test the two methods on two applications: the constrained quadratic regression and a zero-sum game with cubic payoff. Our results are compared to those obtained using the approach proposed in [A. Mitsos, Optimization, 60 (2011), pp. 1291--1308], as well as using the classical relaxation approach based on the KKT conditions of the lower-level problem.},
  archive      = {J_SIOPT},
  author       = {Martina Cerulli and Antoine Oustry and Claudia D&#39;Ambrosio and Leo Liberti},
  doi          = {10.1137/21M1431047},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2493-2526},
  shortjournal = {SIAM J. Optim.},
  title        = {Convergent algorithms for a class of convex semi-infinite programs},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dual certificates and efficient rational sum-of-squares
decompositions for polynomial optimization over compact sets.
<em>SIOPT</em>, <em>32</em>(4), 2461–2492. (<a
href="https://doi.org/10.1137/21M1422574">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of computing weighted sum-of-squares (WSOS) certificates for positive polynomials over a compact semialgebraic set. Building on the theory of interior-point methods for convex optimization, we introduce the concept of dual certificates, which allows us to interpret vectors from the dual of the sum-of-squares cone as rigorous nonnegativity certificates of a WSOS polynomial. Whereas conventional WSOS certificates are alternative representations of the polynomials they certify, dual certificates are distinct from the certified polynomials; moreover, each dual certificate certifies a full-dimensional convex cone of WSOS polynomials. For a theoretical application, we give a short new proof of Powers&#39;s theorems on the existence of rational WSOS certificates of positive polynomials. For a computational application, we show that exact WSOS certificates can be constructed from numerically computed dual certificates at little additional cost, without any rounding or projection steps applied to the numerical certificates. We also present an algorithm for computing the optimal WSOS lower bound of a given polynomial along with a rational dual certificate, with a polynomial-time computational cost per iteration and linear rate of convergence.},
  archive      = {J_SIOPT},
  author       = {Maria M. Davis and Dávid Papp},
  doi          = {10.1137/21M1422574},
  journal      = {SIAM Journal on Optimization},
  number       = {4},
  pages        = {2461-2492},
  shortjournal = {SIAM J. Optim.},
  title        = {Dual certificates and efficient rational sum-of-squares decompositions for polynomial optimization over compact sets},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Scaled, inexact, and adaptive generalized FISTA for strongly
convex optimization. <em>SIOPT</em>, <em>32</em>(3), 2428–2459. (<a
href="https://doi.org/10.1137/21M1391699">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a variable metric and inexact version of the fast iterative soft-thresholding algorithm (FISTA) type algorithm considered in [L. Calatroni and A. Chambolle, SIAM J. Optim., 29 (2019), pp. 1772--1798; A. Chambolle and T. Pock, Acta Numer., 25 (2016), pp. 161--319] for the minimization of the sum of two (possibly strongly) convex functions. The proposed algorithm is combined with an adaptive (nonmonotone) backtracking strategy, which allows for the adjustment of the algorithmic step-size along the iterations in order to improve the convergence speed. We prove a linear convergence result for the function values, which depends on both the strong convexity moduli of the two functions and the upper and lower bounds on the spectrum of the variable metric operators. We validate the proposed algorithm, named Scaled Adaptive GEneralized FISTA (SAGE-FISTA), on exemplar image denoising and deblurring problems where edge-preserving total variation (TV) regularization is combined with Kullback--Leibler-type fidelity terms, as is common in applications where signal-dependent Poisson noise is assumed in the data.},
  archive      = {J_SIOPT},
  author       = {Simone Rebegoldi and Luca Calatroni},
  doi          = {10.1137/21M1391699},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2428-2459},
  shortjournal = {SIAM J. Optim.},
  title        = {Scaled, inexact, and adaptive generalized FISTA for strongly convex optimization},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). High-order optimization methods for fully composite
problems. <em>SIOPT</em>, <em>32</em>(3), 2402–2427. (<a
href="https://doi.org/10.1137/21M1410063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study a fully composite formulation of convex optimization problems, which includes, as a particular case, the problems with functional constraints, max-type minimization problems, and problems with simple nondifferentiable components. We treat all these formulations in a unified way, highlighting the existence of very natural optimization schemes of different order $p \geq 1$. As the result, we obtain new high-order $(p \geq 2)$ optimization methods for composite formulation. We prove the global convergence rates for them under the most general conditions. Assuming that the upper-level component of our objective function is subhomogeneous, we develop efficient modification of the basic fully composite first-order and second-order methods and propose their accelerated variants.},
  archive      = {J_SIOPT},
  author       = {Nikita Doikov and Yurii Nesterov},
  doi          = {10.1137/21M1410063},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2402-2427},
  shortjournal = {SIAM J. Optim.},
  title        = {High-order optimization methods for fully composite problems},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Degenerate preconditioned proximal point algorithms.
<em>SIOPT</em>, <em>32</em>(3), 2376–2401. (<a
href="https://doi.org/10.1137/21M1448112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we describe a systematic procedure to analyze the convergence of degenerate preconditioned proximal point algorithms. We establish weak convergence results under mild assumptions that can be easily employed in the context of splitting methods for monotone inclusion and convex minimization problems. Moreover, we show that the degeneracy of the preconditioner allows for a reduction of the variables involved in the iteration updates. We show the strength of the proposed framework in the context of splitting algorithms, providing new simplified proofs of convergence and highlighting the link between existing schemes, such as Chambolle--Pock, forward Douglas--Rachford, and Peaceman--Rachford, that we study from a preconditioned proximal point perspective. The proposed framework allows us to devise new flexible schemes and provides new ways to generalize existing splitting schemes to the case of the sum of many terms. As an example, we present a new sequential generalization of forward Douglas--Rachford along with numerical experiments that demonstrates its interest in the context of nonsmooth convex optimization.},
  archive      = {J_SIOPT},
  author       = {Kristian Bredies and Enis Chenchene and Dirk A. Lorenz and Emanuele Naldi},
  doi          = {10.1137/21M1448112},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2376-2401},
  shortjournal = {SIAM J. Optim.},
  title        = {Degenerate preconditioned proximal point algorithms},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Amenable cones are particularly nice. <em>SIOPT</em>,
<em>32</em>(3), 2347–2375. (<a
href="https://doi.org/10.1137/20M138466X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Amenability is a geometric property of convex cones that is stronger than facial exposedness and assists in the study of error bounds for conic feasibility problems. In this paper we establish numerous properties of amenable cones and investigate the relationships between amenability and other properties of convex cones, such as niceness and projectional exposure. We show that the amenability of a compact slice of a closed convex cone is equivalent to the amenability of the cone, and we prove several results on the preservation of amenability under intersections and other convex operations. It then follows that homogeneous, doubly nonnegative, and other cones that can be represented as slices of the cone of positive semidefinite matrices are amenable. It is known that projectionally exposed cones are amenable and that amenable cones are nice; however, the converse statements have been open questions. We construct an example of a four-dimensional cone that is nice but not amenable. We also show that amenable cones are projectionally exposed in dimensions up to and including four. We conclude with a discussion on open problems related to facial structure of convex sets that we came across in the course of this work but were not able to fully resolve.},
  archive      = {J_SIOPT},
  author       = {Bruno F. Lourenço and Vera Roshchina and James Saunderson},
  doi          = {10.1137/20M138466X},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2347-2375},
  shortjournal = {SIAM J. Optim.},
  title        = {Amenable cones are particularly nice},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A global dual error bound and its application to the
analysis of linearly constrained nonconvex optimization. <em>SIOPT</em>,
<em>32</em>(3), 2319–2346. (<a
href="https://doi.org/10.1137/20M135474X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Error bound analysis, which estimates the distance of a point to the solution set of an optimization problem4 using the optimality residual, is a powerful tool for the analysis of first-order optimization algorithms. In this paper, we use global error bound analysis to study the iteration complexity of a first-order algorithm for a linearly constrained nonconvex minimization problem. We develop a global dual error bound analysis for a regularized version of this nonconvex problem by using a novel “decomposition” technique. Equipped with this global dual error bound, we prove that a suitably designed primal-dual first-order method can generate an $\epsilon$-stationary solution of the linearly constrained nonconvex minimization problem within $\mathcal{O}(1/\epsilon^2)$ iterations, which is the best known iteration complexity for this class of nonconvex problems. The iteration complexity of our algorithm for finding an $\epsilon$-stationary solution is $\mathcal{O}(1/\epsilon^2)$, which improves the best known complexity of $\mathcal{O}(1/\epsilon^3)$ for the problem under consideration. Furthermore, when the objective function is quadratic, we establish the linear convergence of the algorithm. Our proof is based on a new potential function and a novel use of error bounds.},
  archive      = {J_SIOPT},
  author       = {Jiawei Zhang and Zhi-Quan Luo},
  doi          = {10.1137/20M135474X},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2319-2346},
  shortjournal = {SIAM J. Optim.},
  title        = {A global dual error bound and its application to the analysis of linearly constrained nonconvex optimization},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A dimension reduction technique for large-scale structured
sparse optimization problems with application to convex clustering.
<em>SIOPT</em>, <em>32</em>(3), 2294–2318. (<a
href="https://doi.org/10.1137/21M1441080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel adaptive sieving (AS) technique and an enhanced AS (EAS) technique, which are solver independent and can accelerate optimization algorithms for solving large-scale convex optimization problems with intrinsic structured sparsity. We establish the finite convergence property of the AS and EAS techniques with inexact solutions of the reduced subproblems. As an important application, we apply the AS and EAS techniques to the convex clustering model, which can accelerate the state-of-the-art algorithm Ssnal by more than 7 times and the algorithm ADMM by more than 14 times.},
  archive      = {J_SIOPT},
  author       = {Yancheng Yuan and Tsung-Hui Chang and Defeng Sun and Kim-Chuan Toh},
  doi          = {10.1137/21M1441080},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2294-2318},
  shortjournal = {SIAM J. Optim.},
  title        = {A dimension reduction technique for large-scale structured sparse optimization problems with application to convex clustering},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stochastic difference-of-convex-functions algorithms for
nonconvex programming. <em>SIOPT</em>, <em>32</em>(3), 2263–2293. (<a
href="https://doi.org/10.1137/20M1385706">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper deals with stochastic difference-of-convex-functions (DC) programs, that is, optimization problems whose cost function is a sum of a lower semicontinuous DC function and the expectation of a stochastic DC function with respect to a probability distribution. This class of nonsmooth and nonconvex stochastic optimization problems plays a central role in many practical applications. Although there are many contributions in the context of convex and/or smooth stochastic optimization, algorithms dealing with nonconvex and nonsmooth programs remain rare. In deterministic optimization literature, the DC algorithm (DCA) is recognized to be one of the few algorithms able to effectively solve nonconvex and nonsmooth optimization problems. The main purpose of this paper is to present some new stochastic DCAs for solving stochastic DC programs. The convergence analysis of the proposed algorithms is carefully studied, and numerical experiments are conducted to justify the algorithms&#39; behaviors.},
  archive      = {J_SIOPT},
  author       = {Hoai An Le Thi and Van Ngai Huynh and Tao Pham Dinh and Hoang Phuc Hau Luu},
  doi          = {10.1137/20M1385706},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2263-2293},
  shortjournal = {SIAM J. Optim.},
  title        = {Stochastic difference-of-convex-functions algorithms for nonconvex programming},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bregman finito/MISO for nonconvex regularized finite sum
minimization without lipschitz gradient continuity. <em>SIOPT</em>,
<em>32</em>(3), 2230–2262. (<a
href="https://doi.org/10.1137/21M140376X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce two algorithms for nonconvex regularized finite sum minimization, where typical Lipschitz differentiability assumptions are relaxed to the notion of relative smoothness. The first one is a Bregman extension of Finito/MISO [A. Defazio and J. Domke, Proc. Mach. Learn. Res. (PMLR), 32 (2014), pp. 1125--1133; J. Mairal, SIAM J. Optim., 25 (2015), pp. 829--855], studied for fully nonconvex problems when the sampling is randomized, or under convexity of the nonsmooth term when it is essentially cyclic. The second algorithm is a low-memory variant, in the spirit of SVRG [R. Johnson and T. Zhang, Advances in Neural Information Processing Systems 26, Curran Associates, Red Hook, NY, 2013, pp. 315--323] and SARAH [L. M. Nguyen et al., Proc. Mach. Learn. Res. (PMLR), 70 (2017), pp. 2613--2621], that also allows for fully nonconvex formulations. Our analysis is made remarkably simple by employing a Bregman--Moreau envelope as the Lyapunov function. In the randomized case, linear convergence is established when the cost function is strongly convex, yet with no convexity requirements on the individual functions in the sum. For the essentially cyclic and low-memory variants, global and linear convergence results are established when the cost function satisfies the Kurdyka--Łojasiewicz property.},
  archive      = {J_SIOPT},
  author       = {Puya Latafat and Andreas Themelis and Masoud Ahookhosh and Panagiotis Patrinos},
  doi          = {10.1137/21M140376X},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2230-2262},
  shortjournal = {SIAM J. Optim.},
  title        = {Bregman Finito/MISO for nonconvex regularized finite sum minimization without lipschitz gradient continuity},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Higher-order methods for convex-concave min-max optimization
and monotone variational inequalities. <em>SIOPT</em>, <em>32</em>(3),
2208–2229. (<a href="https://doi.org/10.1137/21M1395764">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide improved convergence rates for constrained convex-concave min-max problems and monotone variational inequalities with higher-order smoothness. In min-max settings where the $p$th-order derivatives are Lipschitz continuous, we give an algorithm that achieves an iteration complexity of $O(1/T^{\frac{p+1}{2}})$ when given access to an oracle for finding a fixed point of a $p$th-order equation. We give analogous rates for the weak monotone variational inequality problem. For $p&gt;2$, our results improve upon the iteration complexity of the first-order Mirror Prox method by Nemirovski [SIAM J. Optim., 15 (2004), pp. 229--251] and the second-order method by Monteiro and Svaiter [SIAM J. Optim., 22 (2012), pp. 914--935]. We further instantiate our entire algorithm in the unconstrained $p=2$ case.},
  archive      = {J_SIOPT},
  author       = {Brian Bullins and Kevin A. Lai},
  doi          = {10.1137/21M1395764},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2208-2229},
  shortjournal = {SIAM J. Optim.},
  title        = {Higher-order methods for convex-concave min-max optimization and monotone variational inequalities},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Orthogonal trace-sum maximization: Tightness of the
semidefinite relaxation and guarantee of locally optimal solutions.
<em>SIOPT</em>, <em>32</em>(3), 2180–2207. (<a
href="https://doi.org/10.1137/21M1422707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies an optimization problem on the sum of traces of matrix quadratic forms in $m$ semiorthogonal matrices, which can be considered as a generalization of the synchronization of rotations. While the problem is nonconvex, this paper shows that its semidefinite programming relaxation solves the original nonconvex problems exactly with high probability under an additive noise model with small noise in the order of $O(m^{1/4})$. In addition, it shows that, with high probability, the sufficient condition for global optimality considered in Won, Zhou, and Lange [SIAM J. Matrix Anal. Appl., 2 (2021), pp. 859--882] is also necessary under a similar small noise condition. These results can be considered as a generalization of existing results on phase synchronization.},
  archive      = {J_SIOPT},
  author       = {Joong-Ho Won and Teng Zhang and Hua Zhou},
  doi          = {10.1137/21M1422707},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2180-2207},
  shortjournal = {SIAM J. Optim.},
  title        = {Orthogonal trace-sum maximization: Tightness of the semidefinite relaxation and guarantee of locally optimal solutions},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pivot rules for circuit-augmentation algorithms in linear
optimization. <em>SIOPT</em>, <em>32</em>(3), 2156–2179. (<a
href="https://doi.org/10.1137/21M1419994">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Circuit-augmentation algorithms are generalizations of the simplex method, where in each step one is allowed to move along a fixed set of directions, called circuits, that is a superset of the edges of a polytope. We show that in the circuit-augmentation framework the greatest-improvement and Dantzig pivot rules are NP-hard, already for 0/1-LPs. Differently, the steepest-descent pivot rule can be carried out in polynomial time in the 0/1 setting, and the number of circuit augmentations required to reach an optimal solution according to this rule is strongly polynomial for 0/1-LPs. The number of circuit augmentations has been of interest as a proxy for the number of steps in the simplex method, and the circuit-diameter of polyhedra has been studied as a lower bound to the combinatorial diameter of polyhedra. Extending prior results, we show that for any polyhedron $P$ the circuit-diameter is bounded by a polynomial in the input bit-size of $P$. This is in contrast with the best bounds for the combinatorial diameter of polyhedra. Interestingly, we show that the circuit-augmentation framework can be exploited to make novel conclusions about the classical simplex method itself: In particular, as a byproduct of our circuit results, we prove that (i) computing the shortest (monotone) path to an optimal solution on the 1-skeleton of a polytope is NP-hard, and hard to approximate within a factor better than 2, and (ii) for $0/1$ polytopes, a monotone path of strongly polynomial length can be constructed using steepest improving edges.},
  archive      = {J_SIOPT},
  author       = {Jesús A. De Loera and Sean Kafer and Laura Sanità},
  doi          = {10.1137/21M1419994},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2156-2179},
  shortjournal = {SIAM J. Optim.},
  title        = {Pivot rules for circuit-augmentation algorithms in linear optimization},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stochastic approximation methods for the two-stage
stochastic linear complementarity problem. <em>SIOPT</em>,
<em>32</em>(3), 2129–2155. (<a
href="https://doi.org/10.1137/20M1375796">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The two-stage stochastic linear complementarity problem (TSLCP), which can be regarded as a special and important reformulation of two-stage stochastic linear programming, has arisen in various fields, such as stochastic programming, game theory, traffic equilibrium, and theoretical economics. Considerable effort has been devoted to designing numerical methods for solving TSLCPs. A popular approach is to integrate the progressive hedging algorithm (PHA) as a sub-algorithm into a discretization framework. In this paper, aiming to solve large-scale TSLCPs, we propose two kinds of stochastic methods: the stochastic approximation method based on projection (SAP) and the dynamic sampling SAP (DS-SAP), both of which offering more direct and improved control of the computational costs of the involved subproblems, especially compared with the PHA. In particular, the linear complementarity subproblems are solved inexactly during each iteration, and the convergence analysis of both SAP and DS-SAP with an inexactness criterion is presented. Moreover, numerical implementations and practical applications demonstrate the efficiency of our proposed methods.},
  archive      = {J_SIOPT},
  author       = {Lin Chen and Yongchao Liu and Xinmin Yang and Jin Zhang},
  doi          = {10.1137/20M1375796},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2129-2155},
  shortjournal = {SIAM J. Optim.},
  title        = {Stochastic approximation methods for the two-stage stochastic linear complementarity problem},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hierarchy of standard polynomial programming formulations
for the maximum clique problem. <em>SIOPT</em>, <em>32</em>(3),
2102–2128. (<a href="https://doi.org/10.1137/21M1419775">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The maximum clique problem is a classical optimization problem which finds many important applications. Some of the most theoretically interesting and computationally successful approaches to this problem are based on the Motzkin--Straus formulation, expressing the clique number in terms of the maximal value of a standard quadratic program. This intriguing relationship has also motivated significant developments in quadratic optimization, copositive programming, and complexity in nonlinear optimization. Inspired by such developments, this paper establishes a hierarchy of polynomial programming formulations (\textbfP$^k$), $k\in{2,\ldots, \omega}$ for the maximum clique problem, relating the clique number $\omega$ of a given graph to the global maximal value of a multilinear polynomial function $f_k(x)$ of degree $k$ over the standard simplex in $\mathbb{R}^{|V|}$. The case of $k=2$ corresponds to the Motzkin--Straus formulation, and the hierarchical feature is in the fact that the set of local maxima of (\textbfP$^{k+1}$) is a subset of the set of local maxima of (\textbfP$^{k}$), $k\in{2,\ldots, \omega-1}$. In particular, every local maximum of (\textbfP$^{\omega}$) is global.},
  archive      = {J_SIOPT},
  author       = {Sergiy Butenko and Mykyta Makovenko and Miltiades Pardalos},
  doi          = {10.1137/21M1419775},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2102-2128},
  shortjournal = {SIAM J. Optim.},
  title        = {A hierarchy of standard polynomial programming formulations for the maximum clique problem},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). From the ravine method to the nesterov method and vice
versa: A dynamical system perspective. <em>SIOPT</em>, <em>32</em>(3),
2074–2101. (<a href="https://doi.org/10.1137/22M1474357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We revisit the Ravine method of Gelfand and Tsetlin from a dynamical system perspective, study its convergence properties, and highlight its similarities and differences with the Nesterov accelerated gradient method. The two methods are closely related. They can be deduced from each other by reversing the order of the extrapolation and gradient operations in their definitions. They benefit from similar fast convergence of values and convergence of iterates for general convex objective functions. We will also establish the high resolution ODE of the Ravine and Nesterov methods and reveal an additional geometric damping term driven by the Hessian for both methods. This will allow us to prove fast convergence toward zero of the gradients not only for the Ravine method but also for the Nesterov method for the first time. In the strongly convex case, we show linear convergence for the Ravine method at an optimal rate. We also highlight connections to other algorithms resulting from more subtle discretization schemes and finally describe a Ravine version of the proximal-gradient algorithms for general structured smooth + nonsmooth convex optimization problems.},
  archive      = {J_SIOPT},
  author       = {Hedy Attouch and Jalal Fadili},
  doi          = {10.1137/22M1474357},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2074-2101},
  shortjournal = {SIAM J. Optim.},
  title        = {From the ravine method to the nesterov method and vice versa: A dynamical system perspective},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Simple and optimal methods for stochastic variational
inequalities, i: Operator extrapolation. <em>SIOPT</em>, <em>32</em>(3),
2041–2073. (<a href="https://doi.org/10.1137/20M1381678">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we first present a novel operator extrapolation (OE) method for solving deterministic variational inequality (VI) problems. Similar to the gradient (operator) projection method, OE updates one single search sequence by solving a single projection subproblem in each iteration. We show that OE can achieve the optimal rate of convergence for solving a variety of VI problems in a much simpler way than existing approaches. We then introduce the stochastic operator extrapolation (SOE) method and establish its optimal convergence behavior for solving various stochastic VI problems. In particular, SOE achieves the optimal complexity for solving a fundamental problem, i.e., stochastic smooth and strongly monotone VI, for the first time in the literature. We also present a stochastic block operator extrapolation method to further reduce the iteration cost for the OE method applied to large-scale deterministic VIs with a certain block structure. Numerical experiments have been conducted to demonstrate the potential advantages of the proposed algorithms. In fact, all these algorithms are applied to solve generalized monotone variational inequality problems whose operator is not necessarily monotone. We will also discuss optimal OE-based policy evaluation methods for reinforcement learning in a companion paper.},
  archive      = {J_SIOPT},
  author       = {Georgios Kotsalis and Guanghui Lan and Tianjiao Li},
  doi          = {10.1137/20M1381678},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2041-2073},
  shortjournal = {SIAM J. Optim.},
  title        = {Simple and optimal methods for stochastic variational inequalities, i: Operator extrapolation},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Error bound characterizations of the conical constraint
qualification in convex programming. <em>SIOPT</em>, <em>32</em>(3),
2013–2040. (<a href="https://doi.org/10.1137/21M1428674">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with error bound characterizations of the conical constraint qualification (CCQ) for convex inequality systems in a Banach space $X$. We establish necessary and sufficient conditions for a closed convex set $S$ defined by a convex function $g$ to have CCQ. These conditions are expressed in terms of the notion of error bound. Our results show that these characterizations hold in the following special cases: 1. $g$ is the maximum of a finite number of differentiable convex functions. 2. $S$ is closed convex and polyhedral. 3. The dimension of the subspace $\hbox{span}(S)$ is less than 2 and $g$ is positively homogeneous. We construct technical examples showing that these characterizations are limited to the three situations above. We introduce a new condition in terms of the gauge function which allows us to give an error bound characterization of convex nondifferentiable systems and to obtain as a direct consequence different characterizations of the concept of the strong conical hull intersection property for a finite collection of convex sets.},
  archive      = {J_SIOPT},
  author       = {Abdessamad Barbara and Abderrahim Jourani},
  doi          = {10.1137/21M1428674},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {2013-2040},
  shortjournal = {SIAM J. Optim.},
  title        = {Error bound characterizations of the conical constraint qualification in convex programming},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Anisotropic diffusion in consensus-based optimization on the
sphere. <em>SIOPT</em>, <em>32</em>(3), 1984–2012. (<a
href="https://doi.org/10.1137/21M140941X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we are concerned with the global minimization of a possibly nonsmooth and nonconvex objective function constrained on the unit hypersphere by means of a multi-agent derivative-free method. The proposed algorithm falls into the class of the recently introduced consensus-based optimization. In fact, agents move on the sphere driven by a drift towards an instantaneous consensus point, which is computed as a convex combination of agent locations, weighted by the cost function according to Laplace&#39;s principle, and it represents an approximation to a global minimizer. The dynamics is further perturbed by an anisotropic random vector field to favor exploration. The main results of this paper are about the proof of convergence of the numerical scheme to global minimizers provided conditions of well-preparation of the initial datum. The proof of convergence combines a mean-field limit result with a novel asymptotic analysis and classical convergence results of numerical methods for stochastic differential equations. The main innovation with respect to previous work is the introduction of an anisotropic stochastic term, which allows us to ensure the independence of the parameters of the algorithm from the dimension and to scale the method to work in very high dimension. We present several numerical experiments, which show that the algorithm proposed in the present paper is extremely versatile and outperforms previous formulations with isotropic stochastic noise.},
  archive      = {J_SIOPT},
  author       = {Massimo Fornasier and Hui Huang and Lorenzo Pareschi and Philippe Sünnen},
  doi          = {10.1137/21M140941X},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1984-2012},
  shortjournal = {SIAM J. Optim.},
  title        = {Anisotropic diffusion in consensus-based optimization on the sphere},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Escaping strict saddle points of the moreau envelope in
nonsmooth optimization. <em>SIOPT</em>, <em>32</em>(3), 1958–1983. (<a
href="https://doi.org/10.1137/21M1430868">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent work has shown that stochastically perturbed gradient methods can efficiently escape strict saddle points of smooth functions. We extend this body of work to nonsmooth optimization, by analyzing an inexact analogue of a stochastically perturbed gradient method applied to the Moreau envelope. The main conclusion is that a variety of algorithms for nonsmooth optimization can escape strict saddle points of the Moreau envelope at a controlled rate. The main technical insight is that many algorithms applied to the proximal subproblem yield directions that approximate the gradient of the Moreau envelope.},
  archive      = {J_SIOPT},
  author       = {Damek Davis and Mateo Díaz and Dmitriy Drusvyatskiy},
  doi          = {10.1137/21M1430868},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1958-1983},
  shortjournal = {SIAM J. Optim.},
  title        = {Escaping strict saddle points of the moreau envelope in nonsmooth optimization},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Linearly constrained nonsmooth optimization for training
autoencoders. <em>SIOPT</em>, <em>32</em>(3), 1931–1957. (<a
href="https://doi.org/10.1137/21M1408713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A regularized minimization model with $l_1$-norm penalty (RP) is introduced for training the autoencoders that belong to a class of two-layer neural networks. We show that the RP can act as an exact penalty model which shares the same global minimizers, local minimizers, and d(irectional)-stationary points with the original regularized model under mild conditions. We construct a bounded box region that contains at least one global minimizer of the RP, and propose a linearly constrained regularized minimization model with $l_1$-norm penalty (LRP) for training autoencoders. A smoothing proximal gradient algorithm is designed to solve the LRP. Convergence of the algorithm to a generalized d-stationary point of the RP and LRP is delivered. Comprehensive numerical experiments convincingly illustrate the efficiency as well as the robustness of the proposed algorithm.},
  archive      = {J_SIOPT},
  author       = {Wei Liu and Xin Liu and Xiaojun Chen},
  doi          = {10.1137/21M1408713},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1931-1957},
  shortjournal = {SIAM J. Optim.},
  title        = {Linearly constrained nonsmooth optimization for training autoencoders},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stochastic decomposition method for two-stage
distributionally robust linear optimization. <em>SIOPT</em>,
<em>32</em>(3), 1901–1930. (<a
href="https://doi.org/10.1137/20M1378600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a sequential sampling-based algorithm for the two-stage distributionally robust linear programming (2-DRLP) models. The 2-DRLP models are defined over a general class of ambiguity sets with discrete or continuous probability distributions. The algorithm is a distributionally robust version of the well-known stochastic decomposition algorithm of Higle and Sen [Math. Oper. Res., 16 (1991), pp. 650--669] for a two-stage stochastic linear program. We refer to the algorithm as the distributionally robust stochastic decomposition (DRSD) method. The key features of the algorithm include (1) it works with data-driven approximations of ambiguity sets that are constructed using samples of increasing size and (2) efficient construction of approximations of the worst-case expectation function that solves only two second-stage subproblems in every iteration. We identify conditions under which the ambiguity set approximations converge to the true ambiguity sets and show that the DRSD method asymptotically identifies an optimal solution, with probability one. We also computationally evaluate the performance of the DRSD method for solving distributionally robust versions of instances considered in stochastic programming literature. The numerical results corroborate the analytical behavior of the DRSD method and illustrate the computational advantage over an external sampling-based decomposition approach (distributionally robust L-shaped method).},
  archive      = {J_SIOPT},
  author       = {Harsha Gangammanavar and Manish Bansal},
  doi          = {10.1137/20M1378600},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1901-1930},
  shortjournal = {SIAM J. Optim.},
  title        = {Stochastic decomposition method for two-stage distributionally robust linear optimization},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The stochastic auxiliary problem principle in banach spaces:
Measurability and convergence. <em>SIOPT</em>, <em>32</em>(3),
1871–1900. (<a href="https://doi.org/10.1137/21M1402467">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stochastic auxiliary problem principle (APP) algorithm is a general stochastic approximation (SA) scheme that turns the resolution of an original convex optimization problem into the iterative resolution of a sequence of auxiliary problems. This framework has been introduced to design decomposition-coordination schemes but also encompasses many well-known SA algorithms such as stochastic gradient descent or stochastic mirror descent. We study the stochastic APP in the case where the iterates lie in a Banach space and we consider an additive error on the computation of the subgradient of the objective. In order to derive convergence results or efficiency estimates for an SA scheme, the iterates must be random variables. This is why we prove the measurability of the iterates of the stochastic APP algorithm. Then, we extend convergence results from the Hilbert space case to the reflexive separable Banach space case. Finally, we derive efficiency estimates for the function values taken at the averaged sequence of iterates or at the last iterate, the latter being obtained by adapting the concept of modified Fejér monotonicity to our framework.},
  archive      = {J_SIOPT},
  author       = {Thomas Bittar and Pierre Carpentier and Jean-Philippe Chancelier and Jéro͂me Lonchampt},
  doi          = {10.1137/21M1402467},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1871-1900},
  shortjournal = {SIAM J. Optim.},
  title        = {The stochastic auxiliary problem principle in banach spaces: Measurability and convergence},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Escaping unknown discontinuous regions in blackbox
optimization. <em>SIOPT</em>, <em>32</em>(3), 1843–1870. (<a
href="https://doi.org/10.1137/21M1420915">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design of key nonlinear systems often requires the use of expensive blackbox simulations presenting inherent discontinuities whose positions in the variable space cannot be analytically predicted. Without further precautions, the solution of related optimization problems leads to design configurations which may be close to discontinuities of the blackbox output functions. These discontinuities may betray unsafe regions of the design space, such as nonlinear resonance regions. To account for possible changes of operating conditions, an acceptable solution must be away from unsafe regions of the space of variables. The objective of this work is to solve a constrained blackbox optimization problem with the additional constraint that the solution should be outside unknown zones of discontinuities or strong variations of the objective function or the constraints. The proposed approach is an extension of the mesh adaptive direct search (\sf Mads) algorithm and aims at building a series of inner approximations of these zones. The algorithm, called \sf DiscoMADS, relies on two main mechanisms: revealing discontinuities and progressively escaping the surrounding zones. A convergence analysis supports the algorithm and preserves the optimality conditions of \sf Mads. Numerical tests are conducted on analytical problems and on three engineering problems illustrating the following possible applications of the algorithm: the design of a simplified truss, the synthesis of a chemical component, and the design of a turbomachine blade. The \sf DiscoMADS algorithm successfully solves these problems by providing a feasible solution away from discontinuous regions.},
  archive      = {J_SIOPT},
  author       = {Charles Audet and Alain Batailly and Solène Kojtych},
  doi          = {10.1137/21M1420915},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1843-1870},
  shortjournal = {SIAM J. Optim.},
  title        = {Escaping unknown discontinuous regions in blackbox optimization},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Convergence rates of the heavy ball method for
quasi-strongly convex optimization. <em>SIOPT</em>, <em>32</em>(3),
1817–1842. (<a href="https://doi.org/10.1137/21M1403990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the behavior of solutions of the ODE associated to the heavy ball method. Since the pioneering work of B. T. Polyak in 1964, it has been well known that such a scheme is very efficient for $C^2$ strongly convex functions with Lipschitz gradient. But much less is known when the $C^2$ assumption is dropped. Depending on the geometry of the function to minimize, we obtain optimal convergence rates for the class of convex functions with some additional regularity such as quasi-strong convexity or strong convexity. We perform this analysis in continuous time for the ODE, and then we transpose these results for discrete optimization schemes. In particular, we propose a variant of the heavy ball algorithm which has the best state of the art convergence rate for first-order methods to minimize strongly composite nonsmooth convex functions.},
  archive      = {J_SIOPT},
  author       = {J.-F. Aujol and Ch. Dossal and A. Rondepierre},
  doi          = {10.1137/21M1403990},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1817-1842},
  shortjournal = {SIAM J. Optim.},
  title        = {Convergence rates of the heavy ball method for quasi-strongly convex optimization},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Approximating min-mean-cycle for low-diameter graphs in
near-optimal time and memory. <em>SIOPT</em>, <em>32</em>(3), 1791–1816.
(<a href="https://doi.org/10.1137/21M1439390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We revisit Min-Mean-Cycle, the classical problem of finding a cycle in a weighted directed graph with minimum mean weight. Despite an extensive algorithmic literature, previous work failed to achieve a near-linear runtime in the number of edges $m$. We propose an algorithm with near-linear runtime $\tilde{O}(m (W_{\max}/\epsilon)^2)$ for computing an $\epsilon$ additive approximation on graphs with polylogarithmic diameter and weights of magnitude at most $W_{\max}$. In particular, this is the first algorithm whose runtime scales in the number of vertices $n$ as $\tilde{O}(n^2)$ for the complete graph. Moreover---unconditionally on the diameter---the algorithm uses only $O(n)$ memory beyond reading the input, making it “memory-optimal&quot;. Our approach is based on solving a linear programming (LP) relaxation using entropic regularization, which reduces the LP to a Matrix Balancing problem---à la the popular reduction of Optimal Transport to Matrix Scaling. We then round the fractional LP solution using a variant of the classical Cycle-Canceling algorithm that is sped up to near-linear runtime at the expense of being approximate, and implemented in a memory-optimal manner. The algorithm is simple to implement and is competitive with the state-of-the-art methods in practice.},
  archive      = {J_SIOPT},
  author       = {Jason M. Altschuler and Pablo A. Parrilo},
  doi          = {10.1137/21M1439390},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1791-1816},
  shortjournal = {SIAM J. Optim.},
  title        = {Approximating min-mean-cycle for low-diameter graphs in near-optimal time and memory},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). First-order methods for problems with <span
class="math inline"><em>O</em></span>(1) functional constraints can have
almost the same convergence rate as for unconstrained problems.
<em>SIOPT</em>, <em>32</em>(3), 1759–1790. (<a
href="https://doi.org/10.1137/20M1371579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {First-order methods (FOMs) have recently been applied and analyzed for solving problems with complicated functional constraints. Existing works show that FOMs for functional constrained problems have lower-order convergence rates than those for unconstrained problems. In particular, an FOM for a smooth strongly convex problem can have linear convergence, while it can only converge sublinearly for a constrained problem if the projection onto the constraint set is prohibited. In this paper, we point out that the slower convergence is caused by the large number of functional constraints but not the constraints themselves. When there are only $m=O(1)$ functional constraints, we show that an FOM can have almost the same convergence rate as that for solving an unconstrained problem, even without the projection onto the feasible set. In addition, given an $\varepsilon&gt;0$, we show that a complexity result that is better than a lower bound can be obtained if there are only $m=o(\varepsilon^{-\frac{1}{2}})$ functional constraints. Our result is surprising but does not contradict the existing lower complexity bound because we focus on a specific subclass of problems. Experimental results on quadratically constrained quadratic programs demonstrate our theory.},
  archive      = {J_SIOPT},
  author       = {Yangyang Xu},
  doi          = {10.1137/20M1371579},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1759-1790},
  shortjournal = {SIAM J. Optim.},
  title        = {First-order methods for problems with $O$(1) functional constraints can have almost the same convergence rate as for unconstrained problems},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the benefit of width for neural networks: Disappearance
of basins. <em>SIOPT</em>, <em>32</em>(3), 1728–1758. (<a
href="https://doi.org/10.1137/21M1394205">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wide networks are often believed to have a nice optimization landscape, but what rigorous results can we prove? To understand the benefit of width, it is important to identify the difference between wide and narrow networks. In this work, we prove that from narrow to wide networks, there is a phase transition from having suboptimal basins to no suboptimal basins. Specifically, we prove two results: on the positive side, for any continuous activation functions, the loss surface of a class of wide networks has no suboptimal basin, where “basin” is defined as the setwise strict local minimum; on the negative side, for a large class of networks with width below a threshold, we construct strict local minima that are not global. These two results together show the phase transition from narrow to wide networks.},
  archive      = {J_SIOPT},
  author       = {Dawei Li and Tian Ding and Ruoyu Sun},
  doi          = {10.1137/21M1394205},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1728-1758},
  shortjournal = {SIAM J. Optim.},
  title        = {On the benefit of width for neural networks: Disappearance of basins},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Effective scenarios in multistage distributionally robust
optimization with a focus on total variation distance. <em>SIOPT</em>,
<em>32</em>(3), 1698–1727. (<a
href="https://doi.org/10.1137/21M1446484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study multistage distributionally robust optimization (DRO) to hedge against ambiguity in quantifying the underlying uncertainty of a problem. Recognizing that not all the realizations and scenario paths might have an “effect” on the optimal value, we investigate the question of how to define and identify critical scenarios for nested multistage DRO problems. Our analysis extends the work of Rahimian, Bayraksan, and Homem-de-Mello [Math. Program., 173 (2019), pp. 393--430], which was in the context of a static/two-stage setting, to the multistage setting. To this end, we define the notions of effectiveness of scenario paths and the conditional effectiveness of realizations along a scenario path for a general class of multistage DRO problems. We then propose easy-to-check conditions to identify the effectiveness of scenario paths in the multistage setting when the distributional ambiguity is modeled via the total variation distance. Numerical results show that these notions provide useful insight on the underlying uncertainty of the problem.},
  archive      = {J_SIOPT},
  author       = {Hamed Rahimian and Güzin Bayraksan and Tito Homem De-Mello},
  doi          = {10.1137/21M1446484},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1698-1727},
  shortjournal = {SIAM J. Optim.},
  title        = {Effective scenarios in multistage distributionally robust optimization with a focus on total variation distance},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Potential function-based framework for minimizing gradients
in convex and min-max optimization. <em>SIOPT</em>, <em>32</em>(3),
1668–1697. (<a href="https://doi.org/10.1137/21M1395302">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Making the gradients small is a fundamental optimization problem that has eluded unifying and simple convergence arguments in first-order optimization, so far primarily reserved for other convergence criteria, such as reducing the optimality gap. In particular, while many different potential function-based frameworks covering broad classes of algorithms exist for optimality gap-based convergence guarantees, we are not aware of such general frameworks addressing the gradient norm guarantees. To fill this gap, we introduce a novel potential function-based framework to study the convergence of standard methods for making the gradients small in smooth convex optimization and convex-concave min-max optimization. Our framework is intuitive and provides a lens for viewing algorithms that makes the gradients small as being driven by a trade-off between reducing either the gradient norm or a certain notion of an optimality gap. On the lower bounds side, we discuss tightness of the obtained convergence results for the convex setup and provide a new lower bound for minimizing norm of cocoercive operators that allows us to argue about optimality of methods in the min-max setup.},
  archive      = {J_SIOPT},
  author       = {Jelena Diakonikolas and Puqian Wang},
  doi          = {10.1137/21M1395302},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1668-1697},
  shortjournal = {SIAM J. Optim.},
  title        = {Potential function-based framework for minimizing gradients in convex and min-max optimization},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sublinear convergence of a tamed stochastic gradient descent
method in hilbert space. <em>SIOPT</em>, <em>32</em>(3), 1642–1667. (<a
href="https://doi.org/10.1137/21M1427450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce the tamed stochastic gradient descent method (TSGD) for optimization problems. Inspired by the tamed Euler scheme, which is a commonly used method within the context of stochastic differential equations, TSGD is an explicit scheme that exhibits stability properties similar to those of implicit schemes. As its computational cost is essentially equivalent to that of the well-known stochastic gradient descent method (SGD), it constitutes a very competitive alternative to such methods. We rigorously prove (optimal) sublinear convergence of the scheme for strongly convex objective functions on an abstract Hilbert space. The analysis only requires very mild step size restrictions, which illustrates the good stability properties. The analysis is based on a priori estimates more frequently encountered in a time integration context than in optimization, and this alternative approach provides a different perspective also on the convergence of SGD. Finally, we demonstrate the usability of the scheme on a problem arising in a context of supervised learning.},
  archive      = {J_SIOPT},
  author       = {Monika Eisenmann and Tony Stillfjord},
  doi          = {10.1137/21M1427450},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1642-1667},
  shortjournal = {SIAM J. Optim.},
  title        = {Sublinear convergence of a tamed stochastic gradient descent method in hilbert space},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Difference-of-convex algorithms for a class of sparse group
<span class="math inline"><em>ℓ</em><sub>0</sub></span> regularized
optimization problems. <em>SIOPT</em>, <em>32</em>(3), 1614–1641. (<a
href="https://doi.org/10.1137/21M1443455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider a class of sparse group $\ell_0$ regularized optimization problems. First, we give a continuous relaxation model of the considered problem and define a class of stationary points of the relaxation problem. Then, we establish the equivalence of these two problems in the sense of global minimizers, and prove that the defined stationary point is equivalent to the local minimizer of the considered sparse group $\ell_0$ regularized problem with a desirable bound from its global minimizers. Further, based on the difference-of-convex (DC) structure of the relaxation problem, we design two DC algorithms to solve the relaxation problem. We prove that any accumulation point of the iterates generated by them is a local minimizer with a desirable bound for the considered sparse group $\ell_0$ problem. In particular, all accumulation points have a common support set and their zero entries can be attained within finite iterations. Moreover, we give the global convergence analysis of the proposed algorithms. Finally, we perform some numerical experiments to show the efficiency of the proposed algorithms.},
  archive      = {J_SIOPT},
  author       = {Wenjing Li and Wei Bian and Kim-Chuan Toh},
  doi          = {10.1137/21M1443455},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1614-1641},
  shortjournal = {SIAM J. Optim.},
  title        = {Difference-of-convex algorithms for a class of sparse group $\ell_0$ regularized optimization problems},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Golden ratio primal-dual algorithm with linesearch.
<em>SIOPT</em>, <em>32</em>(3), 1584–1613. (<a
href="https://doi.org/10.1137/21M1420319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The golden ratio primal-dual algorithm (GRPDA) is a new variant of the classical Arrow--Hurwicz method for solving structured convex optimization problems, in which the objective function consists of the sum of two closed proper convex functions, one of which involves a composition with a linear transform. The same as the Arrow--Hurwicz method and the popular primal-dual algorithm (PDA) of Chambolle and Pock, GRPDA is full-splitting in the sense that it does not rely on solving any subproblems or linear system of equations iteratively. Compared with PDA, an important feature of GRPDA is that it permits larger primal and dual stepsizes. However, the stepsize condition of GRPDA requires that the spectral norm of the linear transform is known, which can be difficult to obtain in some applications. Furthermore, constant stepsizes are usually overconservative in practice. In this paper, we propose a linesearch strategy for GRPDA, which not only does not require the spectral norm of the linear transform but also allows adaptive and potentially much larger stepsizes. Within each linesearch step, only the dual variable needs to be updated, and it is thus quite cheap and does not require any extra matrix-vector multiplications for many special yet important applications such as a regularized least-squares problem. Global iterate convergence and ${\cal O}(1/N)$ ergodic convergence rate results, measured by the function value gap and constraint violations of an equivalent optimization problem, are established, where $N$ denotes the iteration counter. When one of the component functions is strongly convex, faster ${\cal O}(1/N^2)$ ergodic convergence rate results, quantified by the same measures, are established by adaptively choosing some algorithmic parameters. Moreover, when the subdifferential operators of the component functions are strongly metric subregular, a condition that is much weaker than strong convexity, we show that the iterates converge R-linearly to the unique solution. Numerical experiments on matrix game and LASSO problems illustrate the effectiveness of the proposed linesearch strategy.},
  archive      = {J_SIOPT},
  author       = {Xiao-Kai Chang and Junfeng Yang and Hongchao Zhang},
  doi          = {10.1137/21M1420319},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1584-1613},
  shortjournal = {SIAM J. Optim.},
  title        = {Golden ratio primal-dual algorithm with linesearch},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sketched newton–raphson. <em>SIOPT</em>, <em>32</em>(3),
1555–1583. (<a href="https://doi.org/10.1137/21M139788X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new globally convergent stochastic second-order method. Our starting point is the development of a new sketched Newton--Raphson (SNR) method for solving large scale nonlinear equations of the form $F(x)=0$ with $F:\mathbb{R}^p \rightarrow \mathbb{R}^m$. We then show how to design several stochastic second-order optimization methods by rewriting the optimization problem of interest as a system of nonlinear equations and applying SNR. For instance, by applying SNR to find a stationary point of a generalized linear model, we derive completely new and scalable stochastic second-order methods. We show that the resulting method is very competitive as compared to state-of-the-art variance reduced methods. Furthermore, using a variable splitting trick, we also show that the stochastic Newton method (SNM) is a special case of SNR and use this connection to establish the first global convergence theory of SNM. We establish the global convergence of SNR by showing that it is a variant of the online stochastic gradient descent (SGD) method, and then leveraging proof techniques of \textttSGD. As a special case, our theory also provides a new global convergence theory for the original Newton--Raphson method under strictly weaker assumptions as compared to the classic monotone convergence theory.},
  archive      = {J_SIOPT},
  author       = {Rui Yuan and Alessandro Lazaric and Robert M. Gower},
  doi          = {10.1137/21M139788X},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1555-1583},
  shortjournal = {SIAM J. Optim.},
  title        = {Sketched newton--raphson},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bregman proximal point algorithm revisited: A new inexact
version and its inertial variant. <em>SIOPT</em>, <em>32</em>(3),
1523–1554. (<a href="https://doi.org/10.1137/20M1360748">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a general convex optimization problem, which covers various classic problems in different areas and particularly includes many optimal transport related problems arising in recent years. To solve this problem, we revisit the classic Bregman proximal point algorithm (BPPA) and introduce a new inexact stopping condition for solving the subproblems, which can circumvent the underlying feasibility difficulty often appearing in existing inexact conditions when the problem has a complex feasible set. Our inexact condition also covers several existing inexact conditions as special cases and hence makes our inexact BPPA (iBPPA) more flexible to fit different scenarios in practice. As an application to the standard optimal transport (OT) problem, our iBPPA with the entropic proximal term can bypass some numerical instability issues that usually plague the popular Sinkhorn&#39;s algorithm in the OT community, since our iBPPA does not require the proximal parameter to be very small for obtaining an accurate approximate solution. The iteration complexity of $O(1/k)$ and the convergence of the sequence are also established for our iBPPA under some mild conditions. Moreover, inspired by Nesterov&#39;s acceleration technique, we develop an inertial variant of our iBPPA, denoted by V-iBPPA, and establish the iteration complexity of $O(1/k^{\lambda})$, where $\lambda\geq1$ is a quadrangle scaling exponent of the kernel function. In particular, when the proximal parameter is a constant and the kernel function is strongly convex with Lipschitz continuous gradient (hence $\lambda=2$), our V-iBPPA achieves a faster rate of $O(1/k^2)$ just as existing accelerated inexact proximal point algorithms. Some preliminary numerical experiments for solving the standard OT problem are conducted to show the convergence behaviors of our iBPPA and V-iBPPA under different inexactness settings. The experiments also empirically verify the potential of our V-iBPPA for improving the convergence speed.},
  archive      = {J_SIOPT},
  author       = {Lei Yang and Kim-Chuan Toh},
  doi          = {10.1137/20M1360748},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1523-1554},
  shortjournal = {SIAM J. Optim.},
  title        = {Bregman proximal point algorithm revisited: A new inexact version and its inertial variant},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distributionally robust two-stage stochastic programming.
<em>SIOPT</em>, <em>32</em>(3), 1499–1522. (<a
href="https://doi.org/10.1137/20M1370227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributionally robust optimization is a popular modeling paradigm in which the underlying distribution of the random parameters in a stochastic optimization model is unknown. Therefore, hedging against a range of distributions, properly characterized in an ambiguity set, is of interest. We study two-stage stochastic programs with linear recourse in the context of distributional ambiguity, and formulate several distributionally robust models that vary in how the ambiguity set is built. We focus on the Wasserstein distance under a $p$-norm, and an extension, an optimal quadratic transport distance, as mechanisms to construct the set of probability distributions, allowing the support of the random variables to be a continuous space. We study both unbounded and bounded support sets, and provide guidance regarding which models are meaningful in the sense of yielding robust first-stage decisions. We develop cutting-plane algorithms to solve two classes of problems, and test them on a supply-allocation problem. Our numerical experiments provide further evidence as to what type of problems benefit the most from a distributionally robust solution.},
  archive      = {J_SIOPT},
  author       = {Daniel Duque and Sanjay Mehrotra and David P. Morton},
  doi          = {10.1137/20M1370227},
  journal      = {SIAM Journal on Optimization},
  number       = {3},
  pages        = {1499-1522},
  shortjournal = {SIAM J. Optim.},
  title        = {Distributionally robust two-stage stochastic programming},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). General feasibility bounds for sample average approximation
via vapnik–chervonenkis dimension. <em>SIOPT</em>, <em>32</em>(2),
1471–1497. (<a href="https://doi.org/10.1137/21M140211X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the feasibility of sample average approximation (SAA) for general stochastic optimization problems, including two-stage stochastic programs without relatively complete recourse. We utilize results from the Vapnik--Chervonenkis (VC) dimension and probably approximately correct learning to provide a general framework to construct feasibility bounds for SAA solutions under minimal structural or distributional assumption. We show that, as long as the hypothesis class formed by the feasible region has a finite VC dimension, the infeasibility of SAA solutions decreases exponentially with computable rates and explicitly identifiable accompanying constants. We demonstrate how our bounds apply more generally and competitively compared to existing results.},
  archive      = {J_SIOPT},
  author       = {Henry Lam and Fengpei Li},
  doi          = {10.1137/21M140211X},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1471-1497},
  shortjournal = {SIAM J. Optim.},
  title        = {General feasibility bounds for sample average approximation via vapnik--chervonenkis dimension},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Preference robust optimization for choice functions on the
space of CDFs. <em>SIOPT</em>, <em>32</em>(2), 1446–1470. (<a
href="https://doi.org/10.1137/20M1316524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider decision-making problems where the decision maker&#39;s (DM&#39;s) utility/risk preferences are ambiguous but can be described by a general class of choice functions defined over the space of cumulative distribution functions (CDFs) of random prospects. These choice functions are assumed to satisfy two basic properties: (i) monotonicity w.r.t. the order on CDFs and (ii) quasiconcavity. We propose a maximin preference robust optimization (PRO) model where the optimal decision is based on the robust choice function from a set of choice functions elicited from available information on the DM&#39;s preferences. The current univariate utility PRO models are fundamentally based on Von Neumann--Morgenstein&#39;s (VNM&#39;s) expected utility theory. Our new robust choice function model effectively generalizes them to one which captures common features of VNM&#39;s theory and Yaari&#39;s dual theory of choice. To evaluate our robust choice functions, we characterize the quasiconcave envelope of $L-$Lipschitz functions of a set of points. Subsequently, we propose two numerical methods for the DM&#39;s PRO problem: a projected level function method and a level search method. We apply our PRO model and numerical methods to a portfolio optimization problem and report test results.},
  archive      = {J_SIOPT},
  author       = {William B. Haskell and Huifu Xu and Wenjie Huang},
  doi          = {10.1137/20M1316524},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1446-1470},
  shortjournal = {SIAM J. Optim.},
  title        = {Preference robust optimization for choice functions on the space of CDFs},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimization on the euclidean unit sphere. <em>SIOPT</em>,
<em>32</em>(2), 1430–1445. (<a
href="https://doi.org/10.1137/21M1433150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of minimizing a continuously differentiable function $f$ of $m$ linear forms in $n$ variables on the Euclidean unit sphere. We show that this problem is equivalent to minimizing the same function of related $m$ linear forms (but now in $m$ variables) on the Euclidean unit ball. When the linear forms are known, this results in a drastic reduction in problem size whenever $m\ll n$ and allows us to solve potentially large scale nonconvex such problems. We also provide a test to detect when a polynomial is a polynomial in a fixed number of forms. Finally, we identify two classes of functions with no spurious local minima on the sphere: (i) quasi-convex polynomials of odd degree and (ii) nonnegative and homogeneous functions.},
  archive      = {J_SIOPT},
  author       = {Jean B. Lasserre},
  doi          = {10.1137/21M1433150},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1430-1445},
  shortjournal = {SIAM J. Optim.},
  title        = {Optimization on the euclidean unit sphere},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Global linear convergence of evolution strategies on more
than smooth strongly convex functions. <em>SIOPT</em>, <em>32</em>(2),
1402–1429. (<a href="https://doi.org/10.1137/20M1373815">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolution strategies (ESs) are zeroth-order stochastic black-box optimization heuristics invariant to monotonic transformations of the objective function. They evolve a multivariate normal distribution, from which candidate solutions are generated. Among different variants, CMA-ES is nowadays recognized as one of the state-of-the-art zeroth-order optimizers for difficult problems. Despite ample empirical evidence that ESs with a step-size control mechanism converge linearly, theoretical guarantees of linear convergence of ESs have been established only on limited classes of functions. In particular, theoretical results on convex functions are missing, where zeroth-order and also first-order optimization methods are often analyzed. In this paper, we establish almost sure linear convergence and a bound on the expected hitting time of an ES family, namely, the $(1+1)_\kappa$-ES, which includes the (1+1)-ES with (generalized) one-fifth success rule and an abstract covariance matrix adaptation with bounded condition number, on a broad class of functions. The analysis holds for monotonic transformations of positively homogeneous functions and of quadratically bounded functions, the latter of which particularly includes monotonic transformation of strongly convex functions with Lipschitz continuous gradient. As far as the authors know, this is the first work that proves linear convergence of ES on such a broad class of functions.},
  archive      = {J_SIOPT},
  author       = {Youhei Akimoto and Anne Auger and Tobias Glasmachers and Daiki Morinaga},
  doi          = {10.1137/20M1373815},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1402-1429},
  shortjournal = {SIAM J. Optim.},
  title        = {Global linear convergence of evolution strategies on more than smooth strongly convex functions},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The bregman proximal average. <em>SIOPT</em>,
<em>32</em>(2), 1379–1401. (<a
href="https://doi.org/10.1137/21M1442474">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide a proximal average with respect to a 1-coercive Legendre function. In the sense of Bregman distance, the Bregman envelope of the proximal average is a convex combination of Bregman envelopes of individual functions. The Bregman proximal mapping of the average is a convex combination of convexified proximal mappings of individual functions. Techniques from variational analysis provide the keys for the Bregman proximal average.},
  archive      = {J_SIOPT},
  author       = {Xianfu Wang and Heinz H. Bauschke},
  doi          = {10.1137/21M1442474},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1379-1401},
  shortjournal = {SIAM J. Optim.},
  title        = {The bregman proximal average},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the generalized <span
class="math inline"><em>ϑ</em></span>-number and related problems for
highly symmetric graphs. <em>SIOPT</em>, <em>32</em>(2), 1344–1378. (<a
href="https://doi.org/10.1137/21M1414620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is an in-depth analysis of the generalized $\vartheta$-number of a graph. The generalized $\vartheta$-number, $\vartheta_k(G)$, serves as a bound for both the $k$-multichromatic number of a graph and the maximum $k$-colorable subgraph problem. We present various properties of $\vartheta_k(G)$, such as that the sequence $(\vartheta_k(G))_k$ is increasing and bounded from above by the order of the graph $G$. We study $\vartheta_k(G)$ when $G$ is the strong, disjunction, or Cartesian product of two graphs. We provide closed form expressions for the generalized $\vartheta$-number on several classes of graphs including the Kneser graphs, cycle graphs, strongly regular graphs, and orthogonality graphs. Our paper provides bounds on the product and sum of the $k$-multichromatic number of a graph and its complement graph, as well as lower bounds for the $k$-multichromatic number on several graph classes including the Hamming and Johnson graphs.},
  archive      = {J_SIOPT},
  author       = {Lennart Sinjorgo and Renata Sotirov},
  doi          = {10.1137/21M1414620},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1344-1378},
  shortjournal = {SIAM J. Optim.},
  title        = {On the generalized $\vartheta$-number and related problems for highly symmetric graphs},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cutting plane generation through sparse principal component
analysis. <em>SIOPT</em>, <em>32</em>(2), 1319–1343. (<a
href="https://doi.org/10.1137/21M1399956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quadratically constrained quadratic programs (QCQPs) are optimization models whose remarkable expressiveness have made them a cornerstone of methodological research for nonconvex optimization problems. However, modern methods to solve a general QCQP fail to scale, encountering computational challenges even with just a few hundred variables. Specifically, a semidefinite programming (SDP) relaxation is typically employed, which provides strong dual bounds for QCQPs but relies on memory-intensive algorithms. An appealing alternative is to replace the SDP with an easier-to-solve linear programming relaxation while still achieving strong bounds. In this work, we make advances toward achieving this goal by developing a computationally efficient linear cutting plane algorithm that emulates the SDP-based approximations of nonconvex QCQPs. The cutting planes are required to be sparse, in order to ensure a numerically attractive approximation, and efficiently computable. We present a novel connection between such sparse cut generation and the sparse principal component analysis problem in statistics, which allows us to achieve these two goals. We show extensive computational results advocating for the use of our approach.},
  archive      = {J_SIOPT},
  author       = {Santanu S. Dey and Aleksandr Kazachkov and Andrea Lodi and Gonzalo Munoz},
  doi          = {10.1137/21M1399956},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1319-1343},
  shortjournal = {SIAM J. Optim.},
  title        = {Cutting plane generation through sparse principal component analysis},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the convergence of stochastic primal-dual hybrid
gradient. <em>SIOPT</em>, <em>32</em>(2), 1288–1318. (<a
href="https://doi.org/10.1137/19M1296252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we analyze the recently proposed stochastic primal-dual hybrid gradient (SPDHG) algorithm and provide new theoretical results. In particular, we prove almost sure convergence of the iterates to a solution with convexity and linear convergence with further structure, using standard step sizes independent of strong convexity or other regularity constants. In the general convex case, we also prove the $\mathcal{O}(1/k)$ convergence rate for the ergodic sequence, on expected primal-dual gap function. Our assumption for linear convergence is metric subregularity, which is satisfied for strongly convex-strongly concave problems in addition to many nonsmooth and/or nonstrongly convex problems, such as linear programs, Lasso, and support vector machines. We also provide numerical evidence showing that SPDHG with standard step sizes shows a competitive practical performance against its specialized strongly convex variant SPDHG-$\mu$ and other state-of-the-art algorithms, including variance reduction methods.},
  archive      = {J_SIOPT},
  author       = {Ahmet Alacaoglu and Olivier Fercoq and Volkan Cevher},
  doi          = {10.1137/19M1296252},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1288-1318},
  shortjournal = {SIAM J. Optim.},
  title        = {On the convergence of stochastic primal-dual hybrid gradient},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Newton differentiability of convex functions in normed
spaces and of a class of operators. <em>SIOPT</em>, <em>32</em>(2),
1265–1287. (<a href="https://doi.org/10.1137/21M1449531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Newton differentiability is an important concept for analyzing generalized Newton methods for nonsmooth equations. In this work, for a convex function defined on an infinite-dimensional space, we discuss the relation between Newton and Bouligand differentiability and upper semicontinuity of its subdifferential. We also construct a Newton derivative of an operator of the form $(Fx)(p) = f(x,p)$ for general nonlinear operators $f$ that possess a Newton derivative with respect to $x$ and also for the case where $f$ is convex in $x$.},
  archive      = {J_SIOPT},
  author       = {Martin Brokate and Michael Ulbrich},
  doi          = {10.1137/21M1449531},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1265-1287},
  shortjournal = {SIAM J. Optim.},
  title        = {Newton differentiability of convex functions in normed spaces and of a class of operators},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Constrained, global optimization of unknown functions with
lipschitz continuous gradients. <em>SIOPT</em>, <em>32</em>(2),
1239–1264. (<a href="https://doi.org/10.1137/20M1380879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present two first-order, sequential optimization algorithms to solve constrained optimization problems. We consider a black-box setting with a priori unknown, nonconvex objective and constraint functions that have Lipschitz continuous gradients. The proposed algorithms balance the exploration of the a priori unknown feasible space with the pursuit of global optimality within a prespecified finite number of first-order oracle calls. The first algorithm accommodates an infeasible start and provides either a near-optimal global solution or establishes infeasibility. However, the algorithm may produce infeasible iterates during the search. For a strongly convex constraint function and a feasible initial solution guess, the second algorithm returns a near-optimal global solution without any constraint violation. At each iteration, the algorithms identify the next query point by solving a nonconvex, quadratically constrained, quadratic program, characterized by the Lipschitz continuous gradient property of the functions and the oracle responses. In contrast to existing methods, the algorithms compute global suboptimality bounds at every iteration. They can also satisfy user-specified tolerances in the computed solution with near-optimal complexity in oracle calls for a large class of optimization problems. We implement the proposed algorithms using GUROBI, a commercial off-the-shelf solver.},
  archive      = {J_SIOPT},
  author       = {Abraham P. Vinod and Arie Israel and Ufuk Topcu},
  doi          = {10.1137/20M1380879},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1239-1264},
  shortjournal = {SIAM J. Optim.},
  title        = {Constrained, global optimization of unknown functions with lipschitz continuous gradients},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An accelerated method for derivative-free smooth stochastic
convex optimization. <em>SIOPT</em>, <em>32</em>(2), 1210–1238. (<a
href="https://doi.org/10.1137/19M1259225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider an unconstrained problem of minimizing a smooth convex function which is only available through noisy observations of its values, the noise consisting of two parts. Similar to stochastic optimization problems, the first part is of stochastic nature. The second part is additive noise of unknown nature but bounded in absolute value. In the two-point feedback setting, i.e., when pairs of function values are available, we propose an accelerated derivative-free algorithm together with its complexity analysis. The complexity bound of our derivative-free algorithm is only by a factor of $\sqrt{n}$ larger than the bound for accelerated gradient-based algorithms, where $n$ is the dimension of the decision variable. We also propose a nonaccelerated derivative-free algorithm with a complexity bound similar to the stochastic gradient--based algorithm; that is, our bound does not have any dimension-dependent factor except logarithmic. Notably, if the difference between the starting point and the solution is a sparse vector, for both our algorithms, we obtain a better complexity bound if the algorithm uses an 1-norm proximal setup rather than the Euclidean proximal setup, which is a standard choice for unconstrained problems.},
  archive      = {J_SIOPT},
  author       = {Eduard Gorbunov and Pavel Dvurechensky and Alexander Gasnikov},
  doi          = {10.1137/19M1259225},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1210-1238},
  shortjournal = {SIAM J. Optim.},
  title        = {An accelerated method for derivative-free smooth stochastic convex optimization},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A vectorization scheme for nonconvex set optimization
problems. <em>SIOPT</em>, <em>32</em>(2), 1184–1209. (<a
href="https://doi.org/10.1137/21M143683X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study a solution approach for set optimization problems with respect to the lower set less relation. This approach can serve as a base for numerically solving set optimization problems by using established solvers from multiobjective optimization. Our strategy consists of deriving a parametric family of multiobjective optimization problems whose optimal solution sets approximate, in a specific sense, that of the set-valued problem with arbitrary accuracy. We also examine particular classes of set-valued mappings for which the corresponding set optimization problem is equivalent to a multiobjective optimization problem in the generated family. Surprisingly, this includes set-valued mappings with a convex graph.},
  archive      = {J_SIOPT},
  author       = {Gabriele Eichfelder and Ernest Quintana and Stefan Rocktäschel},
  doi          = {10.1137/21M143683X},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1184-1209},
  shortjournal = {SIAM J. Optim.},
  title        = {A vectorization scheme for nonconvex set optimization problems},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exponential decay of sensitivity in graph-structured
nonlinear programs. <em>SIOPT</em>, <em>32</em>(2), 1156–1183. (<a
href="https://doi.org/10.1137/21M1391079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study solution sensitivity for nonlinear programs (NLPs) whose structures are induced by graphs. These NLPs arise in many applications such as dynamic optimization, stochastic optimization, optimization with partial differential equations, and network optimization. We show that for a given pair of nodes, the sensitivity of the primal-dual solution at one node against a data perturbation at the other node decays exponentially with respect to the distance between these two nodes on the graph. In other words, the solution sensitivity decays as one moves away from the perturbation point. This result, which we call exponential decay of sensitivity, holds under the strong second-order sufficiency condition and the linear independence constraint qualification. We also present conditions under which the decay rate remains uniformly bounded; this allows us to characterize the sensitivity behavior of NLPs defined over subgraphs of infinite graphs. The theoretical developments are illustrated with numerical examples.},
  archive      = {J_SIOPT},
  author       = {Sungho Shin and Mihai Anitescu and Victor M. Zavala},
  doi          = {10.1137/21M1391079},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1156-1183},
  shortjournal = {SIAM J. Optim.},
  title        = {Exponential decay of sensitivity in graph-structured nonlinear programs},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Simple and optimal methods for stochastic variational
inequalities, II: Markovian noise and policy evaluation in reinforcement
learning. <em>SIOPT</em>, <em>32</em>(2), 1120–1155. (<a
href="https://doi.org/10.1137/20M1381691">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The focus of this paper is on stochastic variational inequalities (VI) under Markovian noise. A prominent application of our algorithmic developments is the stochastic policy evaluation problem in reinforcement learning. Prior investigations in the literature focused on temporal difference (TD) learning by employing nonsmooth finite time analysis motivated by stochastic subgradient descent leading to certain limitations. These limitations encompass the requirement of analyzing a modified TD algorithm that involves projection to an a priori defined Euclidean ball, achieving a nonoptimal convergence rate and no clear way of deriving the beneficial effects of parallel implementation. Our approach remedies these shortcomings in the broader context of stochastic VIs and in particular when it comes to stochastic policy evaluation. We developed a variety of simple TD learning type algorithms motivated by its original version that maintain its simplicity, while offering distinct advantages from a nonasymptotic analysis point of view. We first provide an improved analysis of the standard TD algorithm that can benefit from parallel implementation. Then we present versions of a conditional TD algorithm (CTD), that involves periodic updates of the stochastic iterates, which reduce the bias and therefore exhibit improved iteration complexity. This brings us to the fast TD (FTD) algorithm which combines elements of CTD and the stochastic operator extrapolation method of the companion paper. For a novel index resetting step size policy FTD exhibits the best known convergence rate. We also devised a robust version of the algorithm that is particularly suitable for discounting factors close to 1.},
  archive      = {J_SIOPT},
  author       = {Georgios Kotsalis and Guanghui Lan and Tianjiao Li},
  doi          = {10.1137/20M1381691},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1120-1155},
  shortjournal = {SIAM J. Optim.},
  title        = {Simple and optimal methods for stochastic variational inequalities, II: Markovian noise and policy evaluation in reinforcement learning},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Local linear convergence of alternating projections in
metric spaces with bounded curvature. <em>SIOPT</em>, <em>32</em>(2),
1094–1119. (<a href="https://doi.org/10.1137/21M1431576">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the popular and classical method of alternating projections for finding a point in the intersection of two closed sets. By situating the algorithm in a metric space, equipped only with well-behaved geodesics and angles (in the sense of Alexandrov), we are able to highlight the two key geometric ingredients in a standard intuitive analysis of local linear convergence. The first is a transversality-like condition on the intersection; the second is a convexity-like condition on one set: “uniform approximation by geodesics.&quot;},
  archive      = {J_SIOPT},
  author       = {Adrian S. Lewis and Genaro Lopez-Acedo and Adriana Nicolae},
  doi          = {10.1137/21M1431576},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1094-1119},
  shortjournal = {SIAM J. Optim.},
  title        = {Local linear convergence of alternating projections in metric spaces with bounded curvature},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Continuation methods for riemannian optimization.
<em>SIOPT</em>, <em>32</em>(2), 1069–1093. (<a
href="https://doi.org/10.1137/21M1428650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerical continuation in the context of optimization can be used to mitigate convergence issues due to a poor initial guess. In this work, we extend this idea to Riemannian optimization problems, that is, the minimization of a target function on a Riemannian manifold. For this purpose, a suitable homotopy is constructed between the original problem and a problem that admits an easy solution. We develop and analyze a path-following numerical continuation algorithm on manifolds for solving the resulting parameter-dependent equation. To illustrate our developments, we consider two typical classical applications of Riemannian optimization: the computation of the Karcher mean and low-rank matrix completion. We demonstrate that numerical continuation can yield improvements for challenging instances of both problems.},
  archive      = {J_SIOPT},
  author       = {Axel Séguin and Daniel Kressner},
  doi          = {10.1137/21M1428650},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1069-1093},
  shortjournal = {SIAM J. Optim.},
  title        = {Continuation methods for riemannian optimization},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Minimal pairs of convex sets which share a recession cone.
<em>SIOPT</em>, <em>32</em>(2), 1049–1068. (<a
href="https://doi.org/10.1137/21M1410695">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robinson introduced a quotient space of pairs of unbounded convex sets which share their recession cone. In this paper minimal pairs of unbounded convex sets, i.e., minimal representations of elements of Robinson&#39;s quotient spaces, are investigated. The fact that a minimal pair having a property of translation is reduced is proved. In the case of pairs of two-dimensional sets a formula for finding an equivalent minimal pair is given, a criterion of minimality of a pair of sets is presented, reducibility of all minimal pairs is proved, and nontrivial examples are shown. Shephard--Weil--Schneider&#39;s criterion for polytopal summand of a compact convex set is generalized to unbounded convex sets. Finally, minimal pairs of unbounded convex sets are applied to finding Hartman&#39;s minimal representation of differences of convex functions.},
  archive      = {J_SIOPT},
  author       = {Jerzy Grzybowski and Ryszard Urbański},
  doi          = {10.1137/21M1410695},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1049-1068},
  shortjournal = {SIAM J. Optim.},
  title        = {Minimal pairs of convex sets which share a recession cone},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improved performance guarantees for orthogonal group
synchronization via generalized power method. <em>SIOPT</em>,
<em>32</em>(2), 1018–1048. (<a
href="https://doi.org/10.1137/20M1389571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the noisy pairwise measurements among a set of unknown group elements, how does one recover them efficiently and robustly? This problem, known as group synchronization, has drawn tremendous attention in the scientific community. In this work, we focus on orthogonal group synchronization that has found many applications, including computer vision, robotics, and cryo-electron microscopy. One commonly used approach is the least squares estimation that requires solving a highly nonconvex optimization program. The past few years have witnessed considerable advances in tackling this challenging problem by convex relaxation and efficient first order methods. However, one fundamental theoretical question remains to be answered: how does the recovery performance depend on the noise strength? To answer this question, we study a benchmark model: recovering orthogonal group elements from their pairwise measurements corrupted by additive Gaussian noise. We investigate the performance of convex relaxation and the generalized power method (GPM). By applying the novel leave-one-out technique, we prove that the GPM with spectral initialization enjoys linear convergence to the global optima to the convex relaxation that also matches the maximum likelihood estimator. Our result achieves a near-optimal performance bound on the convergence of the GPM and improves the state-of-the-art theoretical guarantees on the tightness of convex relaxation by a large margin.},
  archive      = {J_SIOPT},
  author       = {Shuyang Ling},
  doi          = {10.1137/20M1389571},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {1018-1048},
  shortjournal = {SIAM J. Optim.},
  title        = {Improved performance guarantees for orthogonal group synchronization via generalized power method},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust markov decision processes with data-driven,
distance-based ambiguity sets. <em>SIOPT</em>, <em>32</em>(2), 989–1017.
(<a href="https://doi.org/10.1137/21M1423841">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider finite- and infinite-horizon Markov decision processes (MDPs) with unknown state-transition probabilities. They are assumed to belong to certain ambiguity sets, and the goal is to maximize the worst-case expected total discounted reward over all probabilities from these sets. Specifically, the ambiguity set for any state-action-stage triplet is a ball---it includes all probability mass functions (pmfs) within a certain distance from the empirical pmf constructed using historical, independent observations of state transitions. We prove that optimal values in the resulting robust MDPs (RMDPs) converge to the optimal value of the true MDP if the radii of the ambiguity balls approach zero as the sample-size diverges to infinity. In addition, robust optimal policies for sufficiently large sample-sizes are optimal to the true MDP. These results rely on a sufficient condition that links convergence of pmfs with respect to the distance function with their componentwise convergence in an appropriate space. Further, for finite sample-sizes, the optimal value of the RMDP provides a lower bound on the value of the robust optimal policy in the true MDP, with a high probability. A certain concentration inequality is sufficient for this out-of-sample performance guarantee. Several well-known distances satisfy these conditions. Numerical experiments suggest that one can choose from several distance functions to build computationally tractable RMDPs that exhibit good out-of-sample performance, and balance conservativeness with probabilistic guarantees.},
  archive      = {J_SIOPT},
  author       = {Sivaramakrishnan Ramani and Archis Ghate},
  doi          = {10.1137/21M1423841},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {989-1017},
  shortjournal = {SIAM J. Optim.},
  title        = {Robust markov decision processes with data-driven, distance-based ambiguity sets},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Column <span
class="math inline"><em>ℓ</em><sub>2, 0</sub></span>-norm regularized
factorization model of low-rank matrix recovery and its computation.
<em>SIOPT</em>, <em>32</em>(2), 959–988. (<a
href="https://doi.org/10.1137/20M136205X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the column $\ell_{2,0}$-regularized factorization model of low-rank matrix recovery problems and its computation. The column $\ell_{2,0}$-norm of factor matrices is introduced to promote column sparsity of factors and low-rank solutions. For this nonconvex discontinuous optimization problem, we develop an alternating majorization-minimization (AMM) method with extrapolation and a hybrid AMM in which a majorized alternating proximal method is proposed to seek an initial factor pair with less nonzero columns and the AMM with extrapolation is then employed to minimize a smooth nonconvex loss. We provide the global convergence analysis for the proposed AMM methods and apply them to the matrix completion problem with nonuniform sampling schemes. Numerical experiments are conducted with synthetic and real data examples, and comparison results with the nuclear-norm regularized factorization model and the max-norm regularized convex model show that the column $\ell_{2,0}$-regularized factorization model has an advantage in offering solutions of lower error and rank within less time.},
  archive      = {J_SIOPT},
  author       = {Ting Tao and Yitian Qian and Shaohua Pan},
  doi          = {10.1137/20M136205X},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {959-988},
  shortjournal = {SIAM J. Optim.},
  title        = {Column $\ell_{2,0}$-norm regularized factorization model of low-rank matrix recovery and its computation},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimization under rare chance constraints. <em>SIOPT</em>,
<em>32</em>(2), 930–958. (<a
href="https://doi.org/10.1137/20M1382490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chance constraints provide a principled framework to mitigate the risk of high-impact extreme events by modifying the controllable properties of a system. The low probability and rare occurrence of such events, however, impose severe sampling and computational requirements on classical solution methods that render them impractical. This work proposes a novel sampling-free method for solving rare chance constrained optimization problems affected by uncertainties that follow general Gaussian mixture distributions. By integrating modern developments in large deviation theory with tools from convex analysis and bilevel optimization, we propose tractable formulations that can be solved by off-the-shelf solvers. Our formulations enjoy several advantages compared to classical methods: their size and complexity is independent of event rarity, they do not require linearity or convexity assumptions on system constraints, and under easily verifiable conditions, serve as safe conservative approximations or asymptotically exact reformulations of the true problem. Computational experiments on linear, nonlinear, and PDE-constrained problems from applications in portfolio management, structural engineering, and fluid dynamics illustrate the broad applicability of our method and its advantages over classical sampling-based approaches in terms of both accuracy and efficiency.},
  archive      = {J_SIOPT},
  author       = {Shanyin Tong and Anirudh Subramanyam and Vishwas Rao},
  doi          = {10.1137/20M1382490},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {930-958},
  shortjournal = {SIAM J. Optim.},
  title        = {Optimization under rare chance constraints},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A proximal quasi-newton trust-region method for nonsmooth
regularized optimization. <em>SIOPT</em>, <em>32</em>(2), 900–929. (<a
href="https://doi.org/10.1137/21M1409536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a trust-region method for minimizing the sum of a smooth term (f) and a nonsmooth term (h), both of which can be nonconvex. Each iteration of our method minimizes a possibly nonconvex model of (f + h) in a trust region. The model coincides with (f + h) in value and subdifferential at the center. We establish global convergence to a first-order stationary point when (f) satisfies a smoothness condition that holds, in particular, when it has a Lipschitz-continuous gradient, and (h) is proper and lower semicontinuous. The model of (h) is required to be proper, lower semi-continuous and prox-bounded. Under these weak assumptions, we establish a worst-case (O(1/\epsilon^2)) iteration complexity bound that matches the best known complexity bound of standard trust-region methods for smooth optimization. We detail a special instance, named TR-PG, in which we use a limited-memory quasi-Newton model of (f) and compute a step with the proximal gradient method, resulting in a practical proximal quasi-Newton method. We establish similar convergence properties and complexity bound for a quadratic regularization variant, named R2, and provide an interpretation as a proximal gradient method with adaptive step size for nonconvex problems. R2 may also be used to compute steps inside the trust-region method, resulting in an implementation named TR-R2. We describe our Julia implementations and report numerical results on inverse problems from sparse optimization and signal processing. Both TR-PG and TR-R2 exhibit promising performance and compare favorably with two linesearch proximal quasi-Newton methods based on convex models.},
  archive      = {J_SIOPT},
  author       = {Aleksandr Y. Aravkin and Robert Baraldi and Dominique Orban},
  doi          = {10.1137/21M1409536},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {900-929},
  shortjournal = {SIAM J. Optim.},
  title        = {A proximal quasi-newton trust-region method for nonsmooth regularized optimization},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Convexification with bounded gap for randomly projected
quadratic optimization. <em>SIOPT</em>, <em>32</em>(2), 874–899. (<a
href="https://doi.org/10.1137/21M1433678">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Random projection techniques based on the Johnson--Lindenstrauss lemma are used for randomly aggregating the constraints or variables of optimization problems while approximately preserving their optimal values, which leads to smaller-scale optimization problems. D&#39;Ambrosio et al. [Math. Program., 183 (2020), pp. 619--647] have applied random projection to a quadratic optimization problem so as to decrease the number of decision variables. Although the problem size becomes smaller, the projected problem will also almost surely be nonconvex if the original problem is nonconvex and hence will be hard to solve. In this paper, by focusing on the fact that the level of the nonconvexity of a nonconvex quadratic optimization problem can be alleviated by random projection, we find an approximate global optimal value of the problem by attributing it to a convex problem with smaller size. To the best of our knowledge, our paper is the first to use random projection for convexification of nonconvex optimization problems. We evaluate the approximation error between optimum values of a nonconvex optimization problem and its convexified randomly projected problem.},
  archive      = {J_SIOPT},
  author       = {Terunari Fuji and Pierre-Louis Poirion and Akiko Takeda},
  doi          = {10.1137/21M1433678},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {874-899},
  shortjournal = {SIAM J. Optim.},
  title        = {Convexification with bounded gap for randomly projected quadratic optimization},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fenchel duality and a separation theorem on hadamard
manifolds. <em>SIOPT</em>, <em>32</em>(2), 854–873. (<a
href="https://doi.org/10.1137/21M1400699">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a definition of Fenchel conjugate and Fenchel biconjugate on Hadamard manifolds based on the tangent bundle. Our definition overcomes the inconvenience that the conjugate depends on the choice of a certain point on the manifold, as previous definitions required. On the other hand, this new definition still possesses properties known to hold in the Euclidean case. It even yields a broader interpretation of the Fenchel conjugate in the Euclidean case itself. Most prominently, our definition of the Fenchel conjugate provides a Fenchel--Moreau theorem for geodesically convex, proper, lower semicontinuous functions. In addition, this framework allows us to develop a theory of separation of convex sets on Hadamard manifolds, and a strict separation theorem is obtained.},
  archive      = {J_SIOPT},
  author       = {Maurício Silva Louzeiro and Ronny Bergmann and Roland Herzog},
  doi          = {10.1137/21M1400699},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {854-873},
  shortjournal = {SIAM J. Optim.},
  title        = {Fenchel duality and a separation theorem on hadamard manifolds},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sequential quadratic optimization for nonlinear optimization
problems on riemannian manifolds. <em>SIOPT</em>, <em>32</em>(2),
822–853. (<a href="https://doi.org/10.1137/20M1370173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider optimization problems on Riemannian manifolds with equality and inequality constraints, which we call Riemannian nonlinear optimization (RNLO) problems. Although they have numerous applications, the existing studies on them are limited especially in terms of algorithms. In this paper, we propose Riemannian sequential quadratic optimization (RSQO) that uses a line-search technique with an $\ell_{1}$ penalty function as an extension of the standard SQO algorithm for constrained nonlinear optimization problems in Euclidean spaces to Riemannian manifolds. We prove its global convergence to a Karush--Kuhn--Tucker point of the RNLO problem by means of parallel transport and the exponential mapping. Furthermore, we establish its local quadratic convergence by analyzing the relationship between sequences generated by RSQO and the Riemannian Newton method. Ours is the first algorithm that has both global and local convergence properties for constrained nonlinear optimization on Riemannian manifolds. Empirical results show that RSQO finds solutions more stably and with higher accuracy compared with the existing Riemannian penalty and augmented Lagrangian methods.},
  archive      = {J_SIOPT},
  author       = {Mitsuaki Obara and Takayuki Okuno and Akiko Takeda},
  doi          = {10.1137/20M1370173},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {822-853},
  shortjournal = {SIAM J. Optim.},
  title        = {Sequential quadratic optimization for nonlinear optimization problems on riemannian manifolds},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Differentially private accelerated optimization algorithms.
<em>SIOPT</em>, <em>32</em>(2), 795–821. (<a
href="https://doi.org/10.1137/20M1355847">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present two classes of differentially private optimization algorithms derived from the well-known accelerated first-order methods. The first algorithm is inspired by Polyak&#39;s heavy ball method and employs a smoothing approach to decrease the accumulated noise on the gradient steps required for differential privacy. The second class of algorithms are based on Nesterov&#39;s accelerated gradient method and its recent multistage variant. We propose a noise dividing mechanism for the iterations of Nesterov&#39;s method in order to improve the error behavior of the algorithm. The convergence rate analyses are provided for both the heavy ball and the Nesterov&#39;s accelerated gradient method with the help of the dynamical system analysis techniques. Finally, we conclude with our numerical experiments showing that the presented algorithms have advantages over the well-known differentially private algorithms.},
  archive      = {J_SIOPT},
  author       = {Nurdan Kuru and Ş. İlker Birbil and Mert Gürbüzbalaban and Sinan Yildirim},
  doi          = {10.1137/20M1355847},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {795-821},
  shortjournal = {SIAM J. Optim.},
  title        = {Differentially private accelerated optimization algorithms},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the linear convergence of the multimarginal sinkhorn
algorithm. <em>SIOPT</em>, <em>32</em>(2), 786–794. (<a
href="https://doi.org/10.1137/21M1410634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this note is to give an elementary proof of linear convergence of the Sinkhorn algorithm for the entropic regularization of multimarginal optimal transport in the setting of general probability spaces. The proof simply relies on (i) the fact that Sinkhorn iterates are bounded, (ii) the strong convexity of the exponential on bounded intervals, and (iii) the convergence analysis of the coordinate descent (Gauss--Seidel) method of Beck and Tetruashvili [SIAM J. Optim, 23 (2013), pp. 2037--2060].},
  archive      = {J_SIOPT},
  author       = {Guillaume Carlier},
  doi          = {10.1137/21M1410634},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {786-794},
  shortjournal = {SIAM J. Optim.},
  title        = {On the linear convergence of the multimarginal sinkhorn algorithm},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Symmetry reduction in AM/GM-based optimization.
<em>SIOPT</em>, <em>32</em>(2), 765–785. (<a
href="https://doi.org/10.1137/21M1405691">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The arithmetic mean/geometric mean inequality (AM/GM inequality) facilitates classes of nonnegativity certificates and of relaxation techniques for polynomials and, more generally, for exponential sums. Here, we present a first systematic study of the AM/GM-based techniques in the presence of symmetries under the linear action of a finite group. We prove a symmetry-adapted representation theorem and develop techniques to reduce the size of the resulting relative entropy programs. We study in more detail the complexity gain in the case of the symmetric group. In this setup, we can show in particular certain stabilization results. We exhibit several sequences of examples in growing dimensions where the size of the reduced problem stabilizes. Finally, we provide some numerical results, emphasizing the computational speedup.},
  archive      = {J_SIOPT},
  author       = {Philippe Moustrou and Helen Naumann and Cordian Riener and Thorsten Theobald and Hugues Verdure},
  doi          = {10.1137/21M1405691},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {765-785},
  shortjournal = {SIAM J. Optim.},
  title        = {Symmetry reduction in AM/GM-based optimization},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Active-set identification with complexity guarantees of an
almost cyclic 2-coordinate descent method with armijo line search.
<em>SIOPT</em>, <em>32</em>(2), 739–764. (<a
href="https://doi.org/10.1137/20M1328014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper establishes finite active-set identification of an almost cyclic 2-coordinate descent method for problems with one linear coupling constraint and simple bounds. First, general active-set identification results are stated for nonconvex objective functions. Then, under convexity and a quadratic growth condition (satisfied by any strongly convex function), complexity results on the number of iterations required to identify the active set are given. In our analysis, a simple Armijo line search is used to compute the stepsize, thus not requiring exact minimizations or additional information.},
  archive      = {J_SIOPT},
  author       = {Andrea Cristofari},
  doi          = {10.1137/20M1328014},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {739-764},
  shortjournal = {SIAM J. Optim.},
  title        = {Active-set identification with complexity guarantees of an almost cyclic 2-coordinate descent method with armijo line search},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distributionally robust second-order stochastic dominance
constrained optimization with wasserstein ball. <em>SIOPT</em>,
<em>32</em>(2), 715–738. (<a
href="https://doi.org/10.1137/21M1394412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a distributionally robust second-order stochastic dominance constrained optimization problem. We require the dominance constraints to hold with respect to all probability distributions in a Wasserstein ball centered at the empirical distribution. We adopt the sample approximation approach to develop a linear programming formulation that provides a lower bound. We propose a novel split-and-dual decomposition framework which provides an upper bound. We establish quantitative convergence for both lower and upper approximations given some constraint qualification conditions. To efficiently solve the nonconvex upper bound problem, we use a sequential convex approximation algorithm. Numerical evidence on a portfolio selection problem validates the convergence and effectiveness of the proposed two approximation methods.},
  archive      = {J_SIOPT},
  author       = {Yu Mei and Jia Liu and Zhiping Chen},
  doi          = {10.1137/21M1394412},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {715-738},
  shortjournal = {SIAM J. Optim.},
  title        = {Distributionally robust second-order stochastic dominance constrained optimization with wasserstein ball},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Zeroth-order regularized optimization (ZORO): Approximately
sparse gradients and adaptive sampling. <em>SIOPT</em>, <em>32</em>(2),
687–714. (<a href="https://doi.org/10.1137/21M1392966">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of minimizing a high-dimensional objective function, which may include a regularization term, using only (possibly noisy) evaluations of the function. Such optimization is also called derivative-free, zeroth-order, or black-box optimization. We propose a new zeroth-order regularized optimization method, dubbed ZORO. When the underlying gradient is approximately sparse at an iterate, ZORO needs very few objective function evaluations to obtain a new iterate that decreases the objective function. We achieve this with an adaptive, randomized gradient estimator, followed by an inexact proximal-gradient scheme. Under a novel approximately sparse gradient assumption and various different convex settings, we show that the (theoretical and empirical) convergence rate of ZORO is only logarithmically dependent on the problem dimension. Numerical experiments show that ZORO outperforms existing methods with similar assumptions, on both synthetic and real datasets.},
  archive      = {J_SIOPT},
  author       = {HanQin Cai and Daniel McKenzie and Wotao Yin and Zhenliang Zhang},
  doi          = {10.1137/21M1392966},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {687-714},
  shortjournal = {SIAM J. Optim.},
  title        = {Zeroth-order regularized optimization (ZORO): Approximately sparse gradients and adaptive sampling},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On obtaining the convex hull of quadratic inequalities via
aggregations. <em>SIOPT</em>, <em>32</em>(2), 659–686. (<a
href="https://doi.org/10.1137/21M1428583">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A classical approach for obtaining valid inequalities for a set involves the analysis of relaxations constructed using aggregations of the inequalities that describe such a set. When the set is described by linear inequalities, thanks to the Farkas lemma, we know that every valid inequality can be obtained using aggregations. When the inequalities describing the set are two quadratics, Yildiran [IMA J. Math. Control Inform., 26 (2009), pp. 417--450] showed that the convex hull of the set is given by at most two aggregated inequalities. In this work, we study the case of a set described by three or more quadratic inequalities. We show that, under technical assumptions, the convex hull of a set described by three quadratic inequalities can be obtained via (potentially infinitely many) aggregated inequalities. We also show, through counterexamples, that such as a result does not hold either if the technical conditions are relaxed or if we consider four or more inequalities.},
  archive      = {J_SIOPT},
  author       = {Santanu S. Dey and Gonzalo Mun͂oz and Felipe Serrano},
  doi          = {10.1137/21M1428583},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {659-686},
  shortjournal = {SIAM J. Optim.},
  title        = {On obtaining the convex hull of quadratic inequalities via aggregations},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Condition number minimization in euclidean jordan algebras.
<em>SIOPT</em>, <em>32</em>(2), 635–658. (<a
href="https://doi.org/10.1137/21M1400705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let $b$ be a nonnegative vector in a Euclidean Jordan algebra $\mathbb{E}$. Its condition number $\kappa(b)$ is assumed to be high, possibly infinite. The condition number of a nonnegative vector is defined as the ratio between the largest and the smallest eigenvalue. We wish to perturb $b$ in such a way as to diminish its condition number as much as possible. The problem at hand is that of minimizing $\kappa(b+x)$ with respect to a perturbation vector $x$ taken from a given subset of $\mathbb{E}$. In spite of being nonsmooth and nonconvex, such an optimization problem can be handled with the machinery of Euclidean Jordan algebras and, in particular, with the theory of spectral functions.},
  archive      = {J_SIOPT},
  author       = {Alberto Seeger},
  doi          = {10.1137/21M1400705},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {635-658},
  shortjournal = {SIAM J. Optim.},
  title        = {Condition number minimization in euclidean jordan algebras},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generic property of the partial calmness condition for
bilevel programming problems. <em>SIOPT</em>, <em>32</em>(2), 604–634.
(<a href="https://doi.org/10.1137/20M1371403">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The partial calmness for the bilevel programming problem (BLPP) is an important condition which ensures that a local optimal solution of BLPP is a local optimal solution of a partially penalized problem where the lower-level optimality constraint is moved to the objective function and hence a weaker constraint qualification can be applied. In this paper, we propose a sufficient condition in the form of a partial error bound condition which guarantees the partial calmness condition. We analyze the partial calmness for the combined program based on the Bouligand (B) and the Fritz John (FJ) stationary conditions from a generic point of view. Our main result states that the partial error bound condition for the combined programs based on B and FJ conditions is generic for an important setting with applications in economics, and hence the partial calmness for the combined program is not a particularly stringent assumption. Moreover, we derive optimality conditions for the combined program for the generic case without any extra constraint qualifications and show the exact equivalence between our optimality condition and the one by Jongen and Shikhman [Math. Program., 136 (2012), pp. 65--89] given in implicit form. Our arguments are based on Jongen, Jonker, and Twilt&#39;s [Math. Program., 34 (1986), pp. 333--353] generic (five type) classification of the so-called generalized critical points for one-dimensional parametric optimization problems and Jongen and Shikhman&#39;s generic local reductions of BLPPs.},
  archive      = {J_SIOPT},
  author       = {Rongzhu Ke and Wei Yao and Jane J. Ye and Jin Zhang},
  doi          = {10.1137/20M1371403},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {604-634},
  shortjournal = {SIAM J. Optim.},
  title        = {Generic property of the partial calmness condition for bilevel programming problems},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distributed variable sample-size gradient-response and
best-response schemes for stochastic nash equilibrium problems.
<em>SIOPT</em>, <em>32</em>(2), 573–603. (<a
href="https://doi.org/10.1137/20M1340071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers an $n$-player stochastic Nash equilibrium problem (NEP) in which the $i$th player minimizes a composite objective $f_i( \bullet ,x_{-i}) + r_i( \bullet )$, where $f_i$ is an expectation-valued smooth function, $x_{-i}$ is a tuple of rival decisions, and $r_i$ is a nonsmooth convex function with an efficient prox-evaluation. In this context, we make the following contributions. (I) Under suitable monotonicity assumptions on the \redpseudogradient map, we derive optimal rate statements and oracle complexity bounds for the proposed variable sample-size proximal stochastic gradient-response (VS-PGR) scheme when the sample-size increases at a geometric rate. If the sample-size increases at a polynomial rate with degree $v &gt; 0$, the mean-squared error of the iterates decays at a corresponding polynomial rate; in particular, we prove that the iteration and oracle complexities to obtain an $\epsilon$-Nash equilibrium ($\epsilon$-NE) are $\mathcal{O}(1/\epsilon^{1/v})$ and $\mathcal{O}(1/\epsilon^{1+1/v})$, respectively. \redWhen the sample-size is held constant, the iterates converge geometrically to a neighborhood of the Nash equilibrium in an expected-value sense. (II) We then overlay \bf VS-PGR with a consensus phase with a view towards developing distributed protocols for aggregative stochastic NEPs. In the resulting \bf d-VS-PGR scheme, when the sample-size at each iteration grows at a geometric rate while the communication rounds per iteration grow at the rate of $ k+1 $, computing an $\epsilon$-NE requires similar iteration and oracle complexities to \bf VS-PGR with a communication complexity of $\mathcal{O}(\ln^2(1/\epsilon))$. Notably, (I) and (II) rely on weaker oracle assumptions in that the conditionally unbiasedness assumption is relaxed while the bound on the conditional second moment may be state-dependent. (III) Under a suitable contractive property associated with the proximal best-response (BR) map, we design a variable sample-size proximal BR (VS-PBR) scheme, where each player solves a sample-average BR problem. When the sample-size increases at a suitable geometric rate, the resulting iterates converge at a geometric rate while the iteration and oracle complexity are, respectively, $\mathcal{O}(\ln(1/\epsilon))$ and $\mathcal{O}(1/\epsilon)$. If the sample-size increases at a polynomial rate with degree $v$, the mean-squared error decays at a corresponding polynomial rate while the iteration and oracle complexities are $\mathcal{O}(1/\epsilon^{1/v})$ and $\mathcal{O}(1/\epsilon^{1+1/v})$, respectively. (IV) Akin to (II), the distributed variant \bf d-VS-PBR achieves similar iteration and oracle complexities to the centralized VS-PBR with a communication complexity of $\mathcal{O}(\ln^2(1/\epsilon))$ when the communication rounds per iteration increase at the rate of $ k+1 $. Finally, we present preliminary numerics to provide empirical support for the rate and complexity statements.},
  archive      = {J_SIOPT},
  author       = {Jinlong Lei and Uday V. Shanbhag},
  doi          = {10.1137/20M1340071},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {573-603},
  shortjournal = {SIAM J. Optim.},
  title        = {Distributed variable sample-size gradient-response and best-response schemes for stochastic nash equilibrium problems},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A subspace acceleration method for minimization involving a
group sparsity-inducing regularizer. <em>SIOPT</em>, <em>32</em>(2),
545–572. (<a href="https://doi.org/10.1137/21M1411111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of minimizing an objective function that is the sum of a convex function and a group sparsity-inducing regularizer. Problems that integrate such regularizers arise in modern machine learning applications, often for the purpose of obtaining models that are easier to interpret and that have higher predictive accuracy. We present a new method for solving such problems that utilizes subspace acceleration, domain decomposition, and support identification. Our analysis provides the global iteration complexity of obtaining an $\epsilon$-accurate solution and shows that, under common assumptions, the iterates locally converge superlinearly. Numerical results on regularized logistic and linear regression problems show that our approach is efficient and reliable and outperforms state-of-the-art methods on interesting classes of problems, especially when the number of data points is larger than the number of features. For solving problems when the number of data points is smaller than the number of features, algorithms that focus on solving a dual problem may be more efficient than our approach, which solves the primal problem.},
  archive      = {J_SIOPT},
  author       = {Frank E. Curtis and Yutong Dai and Daniel P. Robinson},
  doi          = {10.1137/21M1411111},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {545-572},
  shortjournal = {SIAM J. Optim.},
  title        = {A subspace acceleration method for minimization involving a group sparsity-inducing regularizer},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stochastic multilevel composition optimization algorithms
with level-independent convergence rates. <em>SIOPT</em>,
<em>32</em>(2), 519–544. (<a
href="https://doi.org/10.1137/21M1406222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study smooth stochastic multilevel composition optimization problems, where the objective function is a nested composition of $T$ functions. We assume access to noisy evaluations of the functions and their gradients, through a stochastic first-order oracle. For solving this class of problems, we propose two algorithms using moving-average stochastic estimates, and analyze their convergence to an $\epsilon$-stationary point of the problem. We show that the first algorithm, which is a generalization of [S. Ghadimi, A. Ruszczynski, and M. Wang, SIAM J. Optim., 30 (2020), pp. 960--979] to the $T$ level case, can achieve a sample complexity of $\mathcal{O}_T(1/\epsilon^6)$ by using minibatches of samples in each iteration, where $\mathcal{O}_T$ hides constants that depend on $T$. By modifying this algorithm using linearized stochastic estimates of the function values, we improve the sample complexity to $\mathcal{O}_T(1/\epsilon^4)$. This modification not only removes the requirement of having a minibatch of samples in each iteration, but also makes the algorithm parameter-free and easy to implement. To the best of our knowledge, this is the first time that such an online algorithm designed for the (un)constrained multilevel setting obtains the same sample complexity of the smooth single-level setting, under standard assumptions (unbiasedness and boundedness of the second moments) on the stochastic first-order oracle.},
  archive      = {J_SIOPT},
  author       = {Krishnakumar Balasubramanian and Saeed Ghadimi and Anthony Nguyen},
  doi          = {10.1137/21M1406222},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {519-544},
  shortjournal = {SIAM J. Optim.},
  title        = {Stochastic multilevel composition optimization algorithms with level-independent convergence rates},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Finite convergence of sum-of-squares hierarchies for the
stability number of a graph. <em>SIOPT</em>, <em>32</em>(2), 491–518.
(<a href="https://doi.org/10.1137/21M140345X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate a hierarchy of semidefinite bounds $\vartheta^{(r)}(G)$ for the stability number $\alpha(G)$ of a graph $G$, based on its copositive programming formulation and introduced by de Klerk and Pasechnik [SIAM J. Optim., 12 (2002), pp. 875--892], who conjectured convergence to $\alpha(G)$ in $r=\alpha(G)-1$ steps. Even the weaker conjecture claiming finite convergence is still open. We establish links between this hierarchy and sum-of-squares hierarchies based on the Motzkin--Straus formulation of $\alpha(G)$, which we use to show finite convergence when $G$ is acritical, i.e., when $\alpha(G\setminus e)=\alpha(G)$ for all edges $e$ of $G$. This relies, in particular, on understanding the structure of the minimizers of the Motzkin--Straus formulation and showing that their number is finite precisely when $G$ is acritical. Moreover we show that these results hold in the general setting of the weighted stable set problem for graphs equipped with positive node weights. In addition, as a byproduct we show that deciding whether a standard quadratic program has finitely many minimizers does not admit a polynomial-time algorithm unless P=NP.},
  archive      = {J_SIOPT},
  author       = {Monique Laurent and Luis Felipe Vargas},
  doi          = {10.1137/21M140345X},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {491-518},
  shortjournal = {SIAM J. Optim.},
  title        = {Finite convergence of sum-of-squares hierarchies for the stability number of a graph},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hyperbolic relaxation of <span
class="math inline"><em>k</em></span>-locally positive semidefinite
matrices. <em>SIOPT</em>, <em>32</em>(2), 470–490. (<a
href="https://doi.org/10.1137/20M1387407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A successful computational approach for solving large-scale positive semidefinite (PSD) programs is to enforce PSD-ness on only a collection of submatrices. For our study, we let $\mathcal{S}^{n,k}$ be the convex cone of $n\times n$ symmetric matrices where all $k\times k$ principal submatrices are PSD. We call a matrix in this $k$-locally PSD. In order to compare $\mathcal{S}^{n,k}$ to the cone of PSD matrices, we study eigenvalues of $k$-locally PSD matrices. The key insight in this paper is that there is a convex cone $H(e_k^n)$ so that if $X \in \mathcal{S}^{n,k}$, then the vector of eigenvalues of $X$ is contained in $H(e_k^n)$. The cone $H(e_k^n)$ is the hyperbolicity cone of the elementary symmetric polynomial $e_k^n$ (where $e_k^n(x) = \sum_{S \subseteq [n] : |S| = k} \prod_{i \in S} x_i$) with respect to the all ones vector. Using this insight, we are able to improve previously known upper bounds on the Frobenius distance between matrices in $\mathcal{S}^{n,k}$ and PSD matrices. We also study the quality of the convex relaxation $H(e^n_k)$. We first show that this relaxation is tight for the case of $k = n -1$, that is, for every vector in $H(e^n_{n -1})$ there exists a matrix in $\mathcal{S}^{n, n -1}$ whose eigenvalues are equal to the components of the vector. We then prove a structure theorem on nonsingular matrices in $\mathcal{S}^{n,k}$ all of whose $k\times k$ principal minors are zero, which we believe is of independent interest. This result shows shows that for $1&lt; k &lt; n -1$ “large parts” of the boundary of $H(e_k^n)$ do not intersect with the eigenvalues of matrices in $\mathcal{S}^{n,k}$.},
  archive      = {J_SIOPT},
  author       = {Grigoriy Blekherman and Santanu S. Dey and Kevin Shu and Shengding Sun},
  doi          = {10.1137/20M1387407},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {470-490},
  shortjournal = {SIAM J. Optim.},
  title        = {Hyperbolic relaxation of $k$-locally positive semidefinite matrices},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tracking and regret bounds for online zeroth-order euclidean
and riemannian optimization. <em>SIOPT</em>, <em>32</em>(2), 445–469.
(<a href="https://doi.org/10.1137/21M1405551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study numerical optimization algorithms that use zeroth-order information to minimize time-varying geodesically convex cost functions on Riemannian manifolds. In the Euclidean setting, zeroth-order algorithms have received a lot of attention in both the time-varying and time-invariant cases. However, the extension to Riemannian manifolds is much less developed. We focus on Hadamard manifolds, which are a special class of Riemannian manifolds with global nonpositive curvature that offer convenient grounds for the generalization of convexity notions. Specifically, we derive bounds on the expected instantaneous tracking error, and we provide algorithm parameter values that minimize the algorithm&#39;s performance. Our results illustrate how the manifold geometry in terms of the sectional curvature affects these bounds. Additionally, we provide dynamic regret bounds for this online optimization setting. To the best of our knowledge, these are the first regret bounds even for the Euclidean version of the problem. Lastly, via numerical simulations, we demonstrate the applicability of our algorithm on an online Karcher mean problem.},
  archive      = {J_SIOPT},
  author       = {Alejandro I. Maass and Chris Manzie and Dragan Nešić and Jonathan H. Manton and Iman Shames},
  doi          = {10.1137/21M1405551},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {445-469},
  shortjournal = {SIAM J. Optim.},
  title        = {Tracking and regret bounds for online zeroth-order euclidean and riemannian optimization},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian optimization with expensive integrands.
<em>SIOPT</em>, <em>32</em>(2), 417–444. (<a
href="https://doi.org/10.1137/19M1303125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonconvex derivative-free time-consuming objectives are often optimized using “black-box” optimization. These approaches assume very little about the objective. While broadly applicable, they typically require more evaluations than methods exploiting more problem structure. Often, such time-consuming objectives are actually the sum or integral of a larger number of functions, each of which consumes significant time when evaluated individually. This arises in designing aircraft, choosing parameters in ride-sharing dispatch systems, and tuning hyperparameters in deep neural networks. We develop a novel Bayesian optimization algorithm that leverages this structure to improve performance. Our algorithm is average-case optimal by construction when a single evaluation of the integrand remains within our evaluation budget. Achieving this one-step optimality requires solving a challenging value of information optimization problem, for which we provide a novel efficient discretization-free computational method. We also prove consistency for our method in both continuum and discrete finite domains for objective functions that are sums. In numerical experiments comparing against previous state-of-the-art methods, including those that also leverage sum or integral structure, our method performs as well or better across a wide range of problems and offers significant improvements when evaluations are noisy or the integrand varies smoothly in the integrated variables.},
  archive      = {J_SIOPT},
  author       = {Saul Toscano-Palmerin and Peter I. Frazier},
  doi          = {10.1137/19M1303125},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {417-444},
  shortjournal = {SIAM J. Optim.},
  title        = {Bayesian optimization with expensive integrands},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Zeroth-order stochastic compositional algorithms for
risk-aware learning. <em>SIOPT</em>, <em>32</em>(2), 386–416. (<a
href="https://doi.org/10.1137/20M1315403">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present ${\it Free-MESSAGE}^{,p}$, the first zeroth-order algorithm for (weakly) convex mean-semideviation-based risk-aware learning, which is also the first-ever three-level zeroth-order compositional stochastic optimization algorithm. Using a nontrivial extension of Nesterov&#39;s classical results on Gaussian smoothing, we develop the ${\it Free-MESSAGE}^{,p}$ algorithm from first principles and show that it essentially solves a smoothed surrogate to the original problem, the former being a uniform approximation of the latter, in a useful, convenient sense. We then present a complete analysis of the ${\it Free-MESSAGE}^{,p}$ algorithm, which establishes convergence in a user-tunable neighborhood of the optimal solutions of the original problem for convex costs, as well as explicit convergence rates for convex, weakly convex, and strongly convex costs, in a unified way. Orderwise, and for fixed problem parameters, our results demonstrate no sacrifice in convergence speed as compared to existing first-order methods, while striking a certain balance among the condition of the problem, its dimensionality, and the accuracy of the obtained results, naturally extending previous results in zeroth-order risk-neutral learning.},
  archive      = {J_SIOPT},
  author       = {Dionysios S. Kalogerias and Warren B. Powell},
  doi          = {10.1137/20M1315403},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {386-416},
  shortjournal = {SIAM J. Optim.},
  title        = {Zeroth-order stochastic compositional algorithms for risk-aware learning},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distributed optimization based on gradient tracking
revisited: Enhancing convergence rate via surrogation. <em>SIOPT</em>,
<em>32</em>(2), 354–385. (<a
href="https://doi.org/10.1137/19M1259973">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study distributed multiagent optimization over graphs. We consider the minimization of $F+G$ subject to convex constraints, where $F$ is the smooth strongly convex sum of the agent&#39;s losses and $G$ is a nonsmooth convex function. We build on the SONATA algorithm: the algorithm employs the use of surrogate objective functions in the agents&#39; subproblems (thus going beyond linearization, such as proximal-gradient) coupled with a perturbed consensus mechanism that aims to locally track the gradient of $F$. SONATA achieves precision $\epsilon&gt;0$ on the objective value in $\mathcal{O}(\kappa_g \log(1/\epsilon))$ gradient computations at each node and $\tilde{\mathcal{O}}\big(\kappa_g (1-\rho)^{-1/2} \log(1/\epsilon)\big)$ communication steps, where $\kappa_g$ is the condition number of $F$ and $\rho$ characterizes the connectivity of the network. This is the first linear rate result for distributed composite optimization; it also improves on existing (nonaccelerated) schemes just minimizing $F$, whose rate depends on much larger quantities than $\kappa_g$. When the loss functions of the agents are similar, due to statistical data similarity or otherwise, SONATA employing high-order surrogates achieves precision $\epsilon&gt;0$ in $\mathcal{O}\big((\beta/\mu) \log(1/\epsilon)\big)$ iterations and $\tilde{\mathcal{O}}\big((\beta/\mu) (1-\rho)^{-1/2} \log(1/\epsilon)\big)$ communication steps, where $\beta$ measures the degree of similarity of agents&#39; losses and $\mu$ is the strong convexity constant of $F$. Therefore, when $\beta/\mu &lt; \kappa_g$, the use of high-order surrogates yields provably faster rates than those achievable by first-order models; this is without exchanging any Hessian matrix over the network.},
  archive      = {J_SIOPT},
  author       = {Ying Sun and Gesualdo Scutari and Amir Daneshmand},
  doi          = {10.1137/19M1259973},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {354-385},
  shortjournal = {SIAM J. Optim.},
  title        = {Distributed optimization based on gradient tracking revisited: Enhancing convergence rate via surrogation},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Finding sparse solutions for packing and covering
semidefinite programs. <em>SIOPT</em>, <em>32</em>(2), 321–353. (<a
href="https://doi.org/10.1137/20M137570X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Packing and covering semidefinite programs (SDPs) appear in natural relaxations of many combinatorial optimization problems as well as a number of other applications. Recently, several techniques were proposed, which utilize the particular structure of this class of problems, to obtain more efficient algorithms than those offered by general SDP solvers. For certain applications, such as those described in this paper, it may be desirable to obtain sparse dual solutions, i.e., those with support size (almost) independent of the number of primal constraints. In this paper, we give an algorithm that finds such solutions, which is an extension of a logarithmic-potential based algorithm of Grigoriadis et al. [SIAM J. Optim. 11 (2001), pp. 1081--1091] for packing/covering linear programs.},
  archive      = {J_SIOPT},
  author       = {Khaled Elbassioni and Kazuhisa Makino and Waleed Najy},
  doi          = {10.1137/20M137570X},
  journal      = {SIAM Journal on Optimization},
  number       = {2},
  pages        = {321-353},
  shortjournal = {SIAM J. Optim.},
  title        = {Finding sparse solutions for packing and covering semidefinite programs},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Corrigendum: Critical cones for sufficient second order
conditions in PDE constrained optimization. <em>SIOPT</em>,
<em>32</em>(1), 319–320. (<a
href="https://doi.org/10.1137/21M1466839">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We correct an error in the proof of Theorem 3.1 in [E. Casas and M. Mateos, Critical cones for sufficient second order conditions in PDE constrained optimization, SIAM J. Optim., 30 (2020), pp. 585--603]. With this correction, all results in that paper remain true.},
  archive      = {J_SIOPT},
  author       = {Eduardo Casas and Mariano Mateos},
  doi          = {10.1137/21M1466839},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {319-320},
  shortjournal = {SIAM J. Optim.},
  title        = {Corrigendum: Critical cones for sufficient second order conditions in PDE constrained optimization},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Uncertainty preferences in robust mixed-integer linear
optimization with endogenous uncertainty. <em>SIOPT</em>,
<em>32</em>(1), 292–318. (<a
href="https://doi.org/10.1137/20M1355422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In robust optimization one seeks to make a decision under uncertainty, where the goal is to find the solution with the best worst-case performance. The set of possible realizations of the uncertain data is described by a so-called uncertainty set. In many scenarios, a decision maker may influence the uncertainty regime they are facing, for example, by investing in market research or in machines which work with higher precision. Recently, this situation was addressed in the literature by introducing decision dependent uncertainty sets (endogenous uncertainty), i.e., uncertainty sets whose structure depends on (typically discrete) decision variables. In this way, one can model the trade-off between reducing the cost of robustness versus the cost of the investment necessary for influencing the uncertainty. However, there is another trade-off to be made here. With different uncertainty regimes, not only do the worst-case optimal solutions vary but also other aspects of those solutions such as max-regret, best-case performance, or predictability of the performance. A decision maker may still be interested in having a performance guarantee but at the same time be willing to forgo superior worst-case performance if those other aspects can be enhanced by switching to a suitable uncertainty regime. We introduce the notion of uncertainty preference in order to capture such stances. We introduce a multiobjective optimization based and a bilevel optimization based model that integrate these preferences in a meaningful way. Further, we present three ways to formalize uncertainty preferences and study the resulting mathematical models. The goal is to have reformulations/approximations of these models which can be solved with standard methods. The workhorse is mixed-integer linear and conic optimization. We apply our framework to the uncertain shortest path problem and conduct numerical experiments for the resulting models. We can demonstrate that our models can be handled very well by standard mixed-integer linear solvers.},
  archive      = {J_SIOPT},
  author       = {Immanuel Bomze and Markus Gabl},
  doi          = {10.1137/20M1355422},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {292-318},
  shortjournal = {SIAM J. Optim.},
  title        = {Uncertainty preferences in robust mixed-integer linear optimization with endogenous uncertainty},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Partial smoothness and constant rank. <em>SIOPT</em>,
<em>32</em>(1), 276–291. (<a
href="https://doi.org/10.1137/19M1237909">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In optimization, the notion of a partly smooth objective function is powerful for applications in algorithmic convergence and postoptimality analysis, and yet is complex to define. A shift in focus to the first-order optimality conditions reduces the concept to a simple constant-rank condition. In this view, partial smoothness extends to more general variational systems, encompassing in particular the saddlepoint operators underlying popular primal-dual splitting algorithms. For a broad class of semi-algebraic generalized equations, partial smoothness holds generically.},
  archive      = {J_SIOPT},
  author       = {A. S. Lewis and Jingwei Liang and Tonghua Tian},
  doi          = {10.1137/19M1237909},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {276-291},
  shortjournal = {SIAM J. Optim.},
  title        = {Partial smoothness and constant rank},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interior point methods can exploit structure of convex
piecewise linear functions with application in radiation therapy.
<em>SIOPT</em>, <em>32</em>(1), 256–275. (<a
href="https://doi.org/10.1137/21M1402364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Auxiliary variables are often used to model a convex piecewise linear function in the framework of linear optimization. This work shows that such variables yield a block diagonal plus low rank structure in the reduced KKT system of the dual problem. We show how the structure can be detected efficiently and derive the linear algebra formulas for an interior point method which exploits such a structure. The structure is detected in 36\% of the cases in Netlib. Numerical results on the inverse planning problem in radiation therapy show an order of magnitude speed-up compared to the state-of-the-art interior point solver CPLEX and considerable improvements in dose distribution compared to current algorithms.},
  archive      = {J_SIOPT},
  author       = {Bram L. Gorissen},
  doi          = {10.1137/21M1402364},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {256-275},
  shortjournal = {SIAM J. Optim.},
  title        = {Interior point methods can exploit structure of convex piecewise linear functions with application in radiation therapy},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). QNG: A quasi-natural gradient method for large-scale
statistical learning. <em>SIOPT</em>, <em>32</em>(1), 228–255. (<a
href="https://doi.org/10.1137/20M1376753">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural gradient method provides a powerful paradigm for training statistical models and offers several appealing theoretic benefits. It constructs the Fisher information matrix to correct the ordinary gradients, and thus, the cost may become prohibitively expensive in the large-scale setting. This paper proposes a quasi-natural gradient method to address this computational issue. It employs a rank-one model to capture the second-order information from the underlying statistical manifold and to iteratively update the Fisher approximations. A three-loop procedure is designed to implement the updating formulas. This procedure resembles the classical two-loop procedure in the limited-memory BFGS method but saves half of the memory usage while it can be made faster. The resulting method retains the convergence rate advantages of existing stochastic optimization methods and has inherent ability in handling nonconvexity. Numerical studies conducted on several machine learning tasks demonstrate the reduction in convergence time and the robustness in tackling nonconvexity relative to stochastic gradient descent and the online limited-memory BFGS method.},
  archive      = {J_SIOPT},
  author       = {Xiaoyu He and Zibin Zheng and Yuren Zhou and Chuan Chen},
  doi          = {10.1137/20M1376753},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {228-255},
  shortjournal = {SIAM J. Optim.},
  title        = {QNG: A quasi-natural gradient method for large-scale statistical learning},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Faster lagrangian-based methods in convex optimization.
<em>SIOPT</em>, <em>32</em>(1), 204–227. (<a
href="https://doi.org/10.1137/20M1375358">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we aim at unifying, simplifying, and improving the convergence rate analysis of Lagrangian-based methods for convex optimization problems. We first introduce the notion of nice primal algorithmic map, which plays a central role in the unification and in the simplification of the analysis of most Lagrangian-based methods. Equipped with a nice primal algorithmic map, we then introduce a versatile generic scheme, which allows for the design and analysis of faster Lagrangian (FLAG) methods with new provably sublinear rate of convergence expressed in terms of function values and feasibility violation of the original (nonergodic) generated sequence. To demonstrate the power and versatility of our approach and results, we show that most well-known iconic Lagrangian-based schemes admit a nice primal algorithmic map and hence share the new faster rate of convergence results within their corresponding FLAG.},
  archive      = {J_SIOPT},
  author       = {Shoham Sabach and Marc Teboulle},
  doi          = {10.1137/20M1375358},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {204-227},
  shortjournal = {SIAM J. Optim.},
  title        = {Faster lagrangian-based methods in convex optimization},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The ratio-cut polytope and k-means clustering.
<em>SIOPT</em>, <em>32</em>(1), 173–203. (<a
href="https://doi.org/10.1137/20M1348601">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the ratio-cut polytope defined as the convex hull of ratio-cut vectors corresponding to all partitions of $n$ points in $\mathbb{R}^m$ into at most $K$ clusters. This polytope is closely related to the convex hull of the feasible region of a number of clustering problems such as K-means clustering and spectral clustering. We study the facial structure of the ratio-cut polytope and derive several types of facet-defining inequalities. We then consider the problem of K-means clustering and introduce a novel linear programming (LP) relaxation for it. Subsequently, we focus on the case of two clusters and derive sufficient condition under which the proposed LP relaxation recovers the underlying clusters exactly. Namely, we consider the stochastic ball model, a popular generative model for K-means clustering, and we show that if the separation distance between cluster centers satisfies $\Delta &gt; 1+\sqrt 3$, then the LP relaxation recovers the planted clusters with high probability. This is a major improvement over the only existing recovery guarantee for an LP relaxation of K-means clustering stating that recovery is possible with high probability if and only if $\Delta &gt; 4$. Our numerical experiments indicate that the proposed LP relaxation significantly outperforms a popular semidefinite programming relaxation in recovering the planted clusters.},
  archive      = {J_SIOPT},
  author       = {Antonio De Rosa and Aida Khajavirad},
  doi          = {10.1137/20M1348601},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {173-203},
  shortjournal = {SIAM J. Optim.},
  title        = {The ratio-cut polytope and K-means clustering},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Affinely adjustable robust linear complementarity problems.
<em>SIOPT</em>, <em>32</em>(1), 152–172. (<a
href="https://doi.org/10.1137/20M1359778">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linear complementarity problems (LCPs) are a powerful tool for modeling many practically relevant situations such as market equilibria. They also connect many subareas of mathematics like game theory, optimization, and matrix theory. Despite their close relation to optimization, the protection of LCPs against uncertainties---especially in the sense of robust optimization---is still in its infancy. During the last years, robust LCPs have only been studied using the notions of strict and $\Gamma$-robustness. Unfortunately, both concepts lead to the problem that the existence of robust solutions cannot be guaranteed. In this paper, we consider affinely adjustable robust LCPs. In the latter, a part of the LCP solution is allowed to adjust via a function that is affine in the uncertainty. We show that this notion of robustness allows us to establish strong characterizations of solutions for the cases of uncertain matrix and vector, separately, from which existence results can be derived. Our main results are valid for the case of an uncertain LCP vector. Here, we additionally provide sufficient conditions on the LCP matrix for the uniqueness of a solution. Moreover, based on characterizations of the affinely adjustable robust solutions, we derive a mixed-integer programming formulation that allows us to solve the corresponding robust counterpart. If, in addition, the certain LCP matrix is positive semidefinite, we prove polynomial-time solvability and uniqueness of robust solutions. If the LCP matrix is uncertain, characterizations of solutions are developed for every nominal matrix; i.e., these characterizations are, in particular, independent of the definiteness of the nominal matrix. Robust solutions are also shown to be unique for a positive definite LCP matrix, but both uniqueness and mixed-integer programming formulations still remain open problems if the nominal LCP matrix is not positive definite.},
  archive      = {J_SIOPT},
  author       = {Christian Biefel and Frauke Liers and Jan Rolfes and Martin Schmidt},
  doi          = {10.1137/20M1359778},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {152-172},
  shortjournal = {SIAM J. Optim.},
  title        = {Affinely adjustable robust linear complementarity problems},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bias reduction in sample-based optimization. <em>SIOPT</em>,
<em>32</em>(1), 130–151. (<a
href="https://doi.org/10.1137/20M1326428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the stochastic optimization problems which use observed data to estimate essential characteristics of the random quantities involved. Sample average approximation (SAA) or empirical (plug-in) estimation are very popular ways to use data in optimization. It is well known that SAA suffers from downward bias. Our proposal is to use smooth estimators rather than empirical ones in the optimization problems. We establish consistency results for the optimal value and the set of optimal solutions of the new problem formulation. The performance of the proposed approach is compared to SAA theoretically and numerically. We analyze the bias of the new problems and identify sufficient conditions for ensuring less biased estimation of the optimal value of the true problem. At the same time, the error of the new estimator remains controlled. Those conditions are satisfied for many popular statistical problems such as regression models, classification problems, and optimization problems with average (conditional) value at risk. We have proved that smoothing the least-squares objective in a regression problem by a normal kernel leads to a ridge regression. Our numerical experience shows that the new estimators also frequently exhibit smaller variance and smaller mean-square error than those of SAA.},
  archive      = {J_SIOPT},
  author       = {Darinka Dentcheva and Yang Lin},
  doi          = {10.1137/20M1326428},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {130-151},
  shortjournal = {SIAM J. Optim.},
  title        = {Bias reduction in sample-based optimization},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). First-order algorithms for a class of fractional
optimization problems. <em>SIOPT</em>, <em>32</em>(1), 100–129. (<a
href="https://doi.org/10.1137/20M1325381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider a class of single-ratio fractional minimization problems, in which the numerator of the objective is the sum of a nonsmooth nonconvex function and a smooth nonconvex function while the denominator is a nonsmooth convex function. In this work, we first derive its first-order necessary optimality condition, by using the first-order operators of the three functions involved. Then we develop first-order algorithms, namely, the proximity-gradient-subgradient algorithm (PGSA), PGSA with monotone line search (PGSA_ML), and PGSA with nonmonotone line search (PGSA_NL). It is shown that any accumulation point of the sequence generated by them is a critical point of the problem under mild assumptions. Moreover, we establish global convergence of the sequence generated by PGSA or PGSA_ML and analyze its convergence rate, by further assuming the local Lipschitz continuity of the nonsmooth function in the numerator, the smoothness of the denominator, and the Kurdyka--Łojasiewicz (KL) property of the objective. The proposed algorithms are applied to the sparse generalized eigenvalue problem associated with a pair of symmetric positive semidefinite matrices, and the corresponding convergence results are obtained according to their general convergence theorems. We perform some preliminary numerical experiments to demonstrate the efficiency of the proposed algorithms.},
  archive      = {J_SIOPT},
  author       = {Na Zhang and Qia Li},
  doi          = {10.1137/20M1325381},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {100-129},
  shortjournal = {SIAM J. Optim.},
  title        = {First-order algorithms for a class of fractional optimization problems},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sequential linearization method for bound-constrained
mathematical programs with complementarity constraints. <em>SIOPT</em>,
<em>32</em>(1), 75–99. (<a
href="https://doi.org/10.1137/20M1370501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an algorithm for solving bound-constrained mathematical programs with complementarity constraints on the variables. Each iteration of the algorithm involves solving a linear program with complementarity constraints in order to obtain an estimate of the active set. The algorithm enforces descent on the objective function to promote global convergence to B-stationary points. We provide a convergence analysis and preliminary numerical results on a range of test problems. We also study the effect of fixing the active constraints in a bound-constrained quadratic program that can be solved on each iteration in order to obtain fast convergence.},
  archive      = {J_SIOPT},
  author       = {Christian Kirches and Jeffrey Larson and Sven Leyffer and Paul Manns},
  doi          = {10.1137/20M1370501},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {75-99},
  shortjournal = {SIAM J. Optim.},
  title        = {Sequential linearization method for bound-constrained mathematical programs with complementarity constraints},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Openness, hölder metric regularity, and hölder continuity
properties of semialgebraic set-valued maps. <em>SIOPT</em>,
<em>32</em>(1), 56–74. (<a
href="https://doi.org/10.1137/20M1331901">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a semialgebraic set-valued map $F \colon \mathbb{R}^n \rightrightarrows \mathbb{R}^m$ with closed graph, we show that the map $F$ is Hölder metrically subregular and that the following conditions are equivalent: (i) $F$ is an open map from its domain into its range, and the range of $F$ is locally closed; (ii) the map $F$ is Hölder metrically regular; (iii) the inverse map $F^{-1}$ is pseudo-Hölder continuous; (iv) the inverse map $F^{-1}$ is lower pseudo-Hölder continuous. An application, via Robinson&#39;s normal map formulation, leads to the following result in the context of semialgebraic variational inequalities: if the solution map (as a map of the parameter vector) is lower semicontinuous, then the solution map is finite and pseudo-Hölder continuous. In particular, we obtain a negative answer to a question mentioned in the paper of Dontchev and Rockafellar SIAM J. Optim., 4 (1996), pp. 1087--1105. As a byproduct, we show that for a (not necessarily semialgebraic) continuous single-valued map from $\mathbb{R}^n$ to $\mathbb{R},$ the openness and the nonextremality are equivalent. This fact improves the main result of Pühl J. Math. Anal. Appl., 227 (1998), pp. 382--395, which requires the convexity of the map in question.},
  archive      = {J_SIOPT},
  author       = {Jae Hyoung Lee and Tien-Son Pham},
  doi          = {10.1137/20M1331901},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {56-74},
  shortjournal = {SIAM J. Optim.},
  title        = {Openness, hölder metric regularity, and hölder continuity properties of semialgebraic set-valued maps},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A noise-tolerant quasi-newton algorithm for unconstrained
optimization. <em>SIOPT</em>, <em>32</em>(1), 29–55. (<a
href="https://doi.org/10.1137/20M1373190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes an extension of the BFGS and L-BFGS methods for the minimization of a nonlinear function subject to errors. This work is motivated by applications that contain computational noise, employ low-precision arithmetic, or are subject to statistical noise. The classical BFGS and L-BFGS methods can fail in such circumstances because the updating procedure can be corrupted and the line search can behave erratically. The proposed method addresses these difficulties and ensures that the BFGS update is stable by employing a lengthening procedure that spaces out the points at which gradient differences are collected. A new line search, designed to tolerate errors, guarantees that the Armijo--Wolfe conditions are satisfied under most reasonable conditions, and works in conjunction with the lengthening procedure. The proposed methods are shown to enjoy convergence guarantees for strongly convex functions. Detailed implementations of the methods are presented, together with encouraging numerical results.},
  archive      = {J_SIOPT},
  author       = {Hao-Jun M. Shi and Yuchen Xie and Richard Byrd and Jorge Nocedal},
  doi          = {10.1137/20M1373190},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {29-55},
  shortjournal = {SIAM J. Optim.},
  title        = {A noise-tolerant quasi-newton algorithm for unconstrained optimization},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast decentralized nonconvex finite-sum optimization with
recursive variance reduction. <em>SIOPT</em>, <em>32</em>(1), 1–28. (<a
href="https://doi.org/10.1137/20M1361158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers decentralized minimization of $N:=nm$ smooth nonconvex cost functions equally divided over a directed network of $n$ nodes. Specifically, we describe a stochastic first-order gradient method, called GT-SARAH, that employs a SARAH-type variance reduction technique and gradient tracking (GT) to address the stochastic and decentralized nature of the problem. We show that GT-SARAH, with appropriate algorithmic parameters, finds an $\epsilon$-accurate first-order stationary point with $\mathcal{O}\big(\max\big{N^{{1}/{2}},n(1-\lambda)^{-2},n^{{2}/{3}}m^{{1}/{3}}(1-\lambda)^{-1}\big}L\epsilon^{-2}\big)$ gradient complexity, where ${(1-\lambda)\in(0,1]}$ is the spectral gap of the network weight matrix and $L$ is the smoothness parameter of the cost functions. This gradient complexity outperforms that of the existing decentralized stochastic gradient methods. In particular, in a big-data regime such that ${n = \mathcal{O}(N^{{1}/{2}}(1-\lambda)^{3})}$, this gradient complexity furthers reduces to ${\mathcal{O}(N^{{1}/{2}}L\epsilon^{-2})}$, independent of the network topology, and matches that of the centralized near-optimal variance-reduced methods. Moreover, in this regime GT-SARAH achieves a nonasymptotic linear speedup in that the total number of gradient computations at each node is reduced by a factor of $1/n$ compared to the centralized near-optimal algorithms that perform all gradient computations at a single node. To the best of our knowledge, GT-SARAH is the first algorithm that achieves this property. In addition, we show that appropriate choices of local minibatch size balance the trade-offs between the gradient and communication complexity of GT-SARAH. Over infinite time horizon, we establish that all nodes in GT-SARAH asymptotically achieve consensus and converge to a first-order stationary point in the almost sure and mean-squared sense.},
  archive      = {J_SIOPT},
  author       = {Ran Xin and Usman A. Khan and Soummya Kar},
  doi          = {10.1137/20M1361158},
  journal      = {SIAM Journal on Optimization},
  number       = {1},
  pages        = {1-28},
  shortjournal = {SIAM J. Optim.},
  title        = {Fast decentralized nonconvex finite-sum optimization with recursive variance reduction},
  volume       = {32},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
