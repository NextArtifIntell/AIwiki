<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AAIL_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aail---9">AAIL - 9</h2>
<ul>
<li><details>
<summary>
(2022). Twin neural network regression. <em>AAIL</em>,
<em>3</em>(4), e78. (<a href="https://doi.org/10.1002/ail2.78">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce twin neural network regression (TNNR). This method predicts differences between the target values of two different data points rather than the targets themselves. The solution of a traditional regression problem is then obtained by averaging over an ensemble of all predicted differences between the targets of an unseen data point and all training data points. Whereas ensembles are normally costly to produce, TNNR intrinsically creates an ensemble of predictions of twice the size of the training set while only training a single neural network. Since ensembles have been shown to be more accurate than single models this property naturally transfers to TNNR. We show that TNNs are able to compete or yield more accurate predictions for different data sets, compared with other state-of-the-art methods. Furthermore, TNNR is constrained by self-consistency conditions. We find that the violation of these conditions provides a signal for the prediction uncertainty.},
  archive      = {J_AAIL},
  author       = {Sebastian Johann Wetzel and Kevin Ryczko and Roger Gordon Melko and Isaac Tamblyn},
  doi          = {10.1002/ail2.78},
  journal      = {Applied AI Letters},
  month        = {12},
  number       = {4},
  pages        = {e78},
  shortjournal = {Appl. AI Lett.},
  title        = {Twin neural network regression},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evaluating perceptual and semantic interpretability of
saliency methods: A case study of melanoma. <em>AAIL</em>,
<em>3</em>(3), e77. (<a href="https://doi.org/10.1002/ail2.77">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to be useful, XAI explanations have to be faithful to the AI system they seek to elucidate and also interpretable to the people that engage with them. There exist multiple algorithmic methods for assessing faithfulness, but this is not so for interpretability, which is typically only assessed through expensive user studies. Here we propose two complementary metrics to algorithmically evaluate the interpretability of saliency map explanations. One metric assesses perceptual interpretability by quantifying the visual coherence of the saliency map. The second metric assesses semantic interpretability by capturing the degree of overlap between the saliency map and textbook features—features human experts use to make a classification. We use a melanoma dataset and a deep-neural network classifier as a case-study to explore how our two interpretability metrics relate to each other and a faithfulness metric. Across six commonly used saliency methods, we find that none achieves high scores across all three metrics for all test images, but that different methods perform well in different regions of the data distribution. This variation between methods can be leveraged to consistently achieve high interpretability and faithfulness by using our metrics to inform saliency mask selection on a case-by-case basis. Our interpretability metrics provide a new way to evaluate saliency-based explanations and allow for the adaptive combination of saliency-based explanation methods.},
  archive      = {J_AAIL},
  author       = {Harshit Bokadia and Scott Cheng-Hsin Yang and Zhaobin Li and Tomas Folke and Patrick Shafto},
  doi          = {10.1002/ail2.77},
  journal      = {Applied AI Letters},
  month        = {9},
  number       = {3},
  pages        = {e77},
  shortjournal = {Appl. AI Lett.},
  title        = {Evaluating perceptual and semantic interpretability of saliency methods: A case study of melanoma},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Applying machine learning for large scale field calibration
of low-cost PM2.5 and PM10 air pollution sensors. <em>AAIL</em>,
<em>3</em>(3), e76. (<a href="https://doi.org/10.1002/ail2.76">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-cost air quality monitoring networks can potentially increase the availability of high-resolution monitoring to inform analytic and evidence-informed approaches to better manage air quality. This is particularly relevant in low and middle-income settings where access to traditional reference-grade monitoring networks remains a challenge. However, low-cost air quality sensors are impacted by ambient conditions which could lead to over- or underestimation of pollution concentrations and thus require field calibration to improve their accuracy and reliability. In this paper, we demonstrate the feasibility of using machine learning methods for large-scale calibration of AirQo sensors, low-cost PM sensors custom-designed for and deployed in Sub-Saharan urban settings. The performance of various machine learning methods is assessed by comparing model corrected PM using k -nearest neighbours, support vector regression, multivariate linear regression, ridge regression, lasso regression, elastic net regression, XGBoost, multilayer perceptron, random forest and gradient boosting with collocated reference PM concentrations from a Beta Attenuation Monitor (BAM). To this end, random forest and lasso regression models were superior for PM 2.5 and PM 10 calibration, respectively. Employing the random forest model decreased RMSE of raw data from 18.6 μg/m 3 to 7.2 μg/m 3 with an average BAM PM 2.5 concentration of 37.8 μg/m 3 while the lasso regression model decreased RMSE from 13.4 μg/m 3 to 7.9 μg/m 3 with an average BAM PM 10 concentration of 51.1 μg/m 3 . We validate our models through cross-unit and cross-site validation, allowing analysis of AirQo devices&#39; consistency. The resulting calibration models were deployed to the entire large-scale air quality monitoring network consisting of over 120 AirQo devices, which demonstrates the use of machine learning systems to address practical challenges in a developing world setting.},
  archive      = {J_AAIL},
  author       = {Priscilla Adong and Engineer Bainomugisha and Deo Okure and Richard Sserunjogi},
  doi          = {10.1002/ail2.76},
  journal      = {Applied AI Letters},
  month        = {9},
  number       = {3},
  pages        = {e76},
  shortjournal = {Appl. AI Lett.},
  title        = {Applying machine learning for large scale field calibration of low-cost PM2.5 and PM10 air pollution sensors},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning to predict power output from respiratory
inductive plethysmography data. <em>AAIL</em>, <em>3</em>(2), e65. (<a
href="https://doi.org/10.1002/ail2.65">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Power output is one of the most accurate methods for measuring exercise intensity during outdoor endurance sports, since it records the actual effect of the work performed by the muscles over time. However, power meters are expensive and are limited to activity forms where it is possible to embed sensors in the propulsion system such as in cycling. We investigate using breathing to estimate power output during exercise, in order to create a portable method for tracking physical effort that is universally applicable in many activity forms. Breathing can be quantified through respiratory inductive plethysmography (RIP), which entails recording the movement of the rib cage and abdomen caused by breathing, and it enables us to have a portable, non-invasive device for measuring breathing. RIP signals, heart rate and power output were recorded during a N-of-1 study of a person performing a set of workouts on a stationary bike. The recorded data were used to build predictive models through deep learning algorithms. A convolutional neural network (CNN) trained on features derived from RIP signals and heart rate obtained a mean absolute percentage error (MAPE) of 0.20 (ie, 20% average error). The model showed promising capability of estimating correct power levels and reactivity to changes in power output, but the accuracy is significantly lower than that of cycling power meters.},
  archive      = {J_AAIL},
  author       = {Erik Johannes B. L. G Husom and Pierre Bernabé and Sagar Sen},
  doi          = {10.1002/ail2.65},
  journal      = {Applied AI Letters},
  month        = {4},
  number       = {2},
  pages        = {e65},
  shortjournal = {Appl. AI Lett.},
  title        = {Deep learning to predict power output from respiratory inductive plethysmography data},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generative model-enhanced human motion prediction.
<em>AAIL</em>, <em>3</em>(2), e63. (<a
href="https://doi.org/10.1002/ail2.63">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of predicting human motion is complicated by the natural heterogeneity and compositionality of actions, necessitating robustness to distributional shifts as far as out-of-distribution (OoD). Here, we formulate a new OoD benchmark based on the Human3.6M and Carnegie Mellon University (CMU) motion capture datasets, and introduce a hybrid framework for hardening discriminative architectures to OoD failure by augmenting them with a generative model. When applied to current state-of-the-art discriminative models, we show that the proposed approach improves OoD robustness without sacrificing in-distribution performance, and can theoretically facilitate model interpretability. We suggest human motion predictors ought to be constructed with OoD challenges in mind, and provide an extensible general framework for hardening diverse discriminative architectures to extreme distributional shift. The code is available at: https://github.com/bouracha/OoDMotion .},
  archive      = {J_AAIL},
  author       = {Anthony Bourached and Ryan-Rhys Griffiths and Robert Gray and Ashwani Jha and Parashkev Nachev},
  doi          = {10.1002/ail2.63},
  journal      = {Applied AI Letters},
  month        = {4},
  number       = {2},
  pages        = {e63},
  shortjournal = {Appl. AI Lett.},
  title        = {Generative model-enhanced human motion prediction},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Explainable artificial intelligence and social science:
Further insights for qualitative investigation. <em>AAIL</em>,
<em>3</em>(1), e64. (<a href="https://doi.org/10.1002/ail2.64">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a scoping review of user studies in explainable artificial intelligence (XAI) entailing qualitative investigation. We draw on social science corpora to suggest ways for improving the rigor of studies where XAI researchers use observations, interviews, focus groups, and/or questionnaire tasks to collect qualitative data. We contextualize the presentation of the XAI papers included in our review according to the components of rigor discussed in the qualitative research literature: (a) underlying theories or frameworks; (b) methodological approaches; (c) data collection methods; and (d) data analysis processes. The results of our review dovetail with calls made by others in the XAI community advocating for collaboration with experts from social disciplines toward bolstering rigor and effectiveness in user studies.},
  archive      = {J_AAIL},
  author       = {Adam J. Johs and Denise E. Agosto and Rosina O. Weber},
  doi          = {10.1002/ail2.64},
  journal      = {Applied AI Letters},
  month        = {2},
  number       = {1},
  pages        = {e64},
  shortjournal = {Appl. AI Lett.},
  title        = {Explainable artificial intelligence and social science: Further insights for qualitative investigation},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning does not replace bayesian modeling: Comparing
research use via citation counting. <em>AAIL</em>, <em>3</em>(1), e62.
(<a href="https://doi.org/10.1002/ail2.62">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One could be excused for assuming that deep learning had or will soon usurp all credible work in reasoning, artificial intelligence, and statistics, but like most “meme” class broad generalizations the concept does not hold up to scrutiny. Memes do not generally matter since the experts will always know better; but in the case of Bayesian software like Stan and PyMC3, even their developers and advocates bemoan the apparent dominance of deep learning as manifested in popular culture, breathtaking performance, and most problematically from funding agency peer review that impacts our ability to further advance the field. The facts, however, do not support the assumed dominance of deep learning in science upon closer examination. This letter simply makes the argument by the crudest of possible metrics, citation count, that once the discipline of Computer Science is subtracted, Bayesian software accounts for nearly a third of research citations. Stan and PyMC3 dominate some fields, PyTorch, Keras, and TensorFlow dominate others with lot of variations in between. Bayesian and deep-learning approaches are related but very different technologies in goals, implementation, and applicability with little actual overlap--so this is not a surprise. For example, deep learning cannot bring the explainability of applied math/statistics and Bayesian methods do not scale to deep-learning data sets. While deep-learning behemoths like Facebook and Google use and support Bayesian efforts, the Bayesian packages scientists actually use are academic/volunteer efforts punching far above their weight class, and they need financial support. It would behoove funders to fully understand the impact and role of Bayesian methods in resource allocation.},
  archive      = {J_AAIL},
  author       = {Breck Baldwin},
  doi          = {10.1002/ail2.62},
  journal      = {Applied AI Letters},
  month        = {2},
  number       = {1},
  pages        = {e62},
  shortjournal = {Appl. AI Lett.},
  title        = {Deep learning does not replace bayesian modeling: Comparing research use via citation counting},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Computer vision and machine-learning techniques for
quantification and predictive modeling of intracellular anticancer drug
delivery by nanocarriers. <em>AAIL</em>, <em>3</em>(1), e50. (<a
href="https://doi.org/10.1002/ail2.50">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of cancer nanomedicine has made significant progress, but its clinical translation is impeded by many challenges, such as the difficulty in analyzing intracellular anticancer drug release by the nanocarriers due to the lack of suitable tools. Here, we propose the development of an image-based strategy involving machine learning (ML) to evaluate anticancer drug such as doxorubicin hydrochloride (DOX) released by a nanocarrier inside the HCT116 colon cancer cells and its subsequent intracellular accumulation. This technique combines fluorescent cell imaging with ML-based image analysis to assess and quantify the delivery of DOX by nanoparticles within them. We show that DOX in HCT116 cells was higher for multifunctional CNT-DOX-Fe 3 O 4 nanocarrier than free DOX, indicating efficient and steady release of DOX as well as superior retentive property of the nanocarrier. Initially (1 and 4 hours), the luminance intensity of DOX in the cell cytoplasm delivered by CNT-DOX-Fe 3 O 4 nanocarrier was ~0.34 and ~0.42 times lesser than that of free DOX delivered normally. However, at 24 and 48 hours posttreatment, the luminance intensity of DOX for CNT-DOX-Fe 3 O 4 nanocarrier was ~1.98 and ~1.92 times higher than that of free DOX. Furthermore, the luminance intensity of DOX for CNT-DOX-Fe 3 O 4 in the whole cell was ~1.35 and ~1.62 times higher than that of free DOX at 24 and 48 hours, respectively. The high-throughput nature of our image analysis workflow allowed us to automate the process of DOX retention analysis and enabled us to devise ML-based modeling to predict the percentage of anticancer drug retention in cells. The development of models to automatically quantify and predict intracellular drug release in cancer cells could benefit personalized treatments by optimizing the design of nanocarriers.},
  archive      = {J_AAIL},
  author       = {Sanjay Goswami and Kshama D. Dhobale and Ravindra D. Wavhale and Barnali Goswami and Shashwat S. Banerjee},
  doi          = {10.1002/ail2.50},
  journal      = {Applied AI Letters},
  month        = {2},
  number       = {1},
  pages        = {e50},
  shortjournal = {Appl. AI Lett.},
  title        = {Computer vision and machine-learning techniques for quantification and predictive modeling of intracellular anticancer drug delivery by nanocarriers},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tiny video networks. <em>AAIL</em>, <em>3</em>(1), e38. (<a
href="https://doi.org/10.1002/ail2.38">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic video understanding is becoming more important for applications where real-time performance is crucial and compute is limited: for example, automated video tagging, robot perception, activity recognition for mobile devices. Yet, accurate solutions so far have been computationally intensive. We propose efficient models for videos—Tiny Video Networks—which are video architectures, automatically designed to comply with fast runtimes and, at the same time are effective at video recognition tasks. The TVNs run at faster-than-real-time speeds and demonstrate strong performance across several video benchmarks. These models not only provide new tools for real-time video applications, but also enable fast research and development in video understanding. Code and models are available.},
  archive      = {J_AAIL},
  author       = {A. J. Piergiovanni and Anelia Angelova and Michael S. Ryoo},
  doi          = {10.1002/ail2.38},
  journal      = {Applied AI Letters},
  month        = {2},
  number       = {1},
  pages        = {e38},
  shortjournal = {Appl. AI Lett.},
  title        = {Tiny video networks},
  volume       = {3},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
