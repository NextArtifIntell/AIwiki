<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>BIMJ_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="bimj---108">BIMJ - 108</h2>
<ul>
<li><details>
<summary>
(2022h). Cover picture: Biometrical journal 8’22. <em>BIMJ</em>,
<em>64</em>(8), NA. (<a
href="https://doi.org/10.1002/bimj.202270081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIMJ},
  doi          = {10.1002/bimj.202270081},
  journal      = {Biometrical Journal},
  month        = {12},
  number       = {8},
  pages        = {NA},
  shortjournal = {Bio. J.},
  title        = {Cover picture: Biometrical journal 8&#39;22},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tree-based methods for statistical learning in r. Brandon m.
Greenwell (2022). Boca raton, FL: CRC press. 404 pp., £59.99. ISBN
978-0-367-53246-8. <em>BIMJ</em>, <em>64</em>(8), 1500–1501. (<a
href="https://doi.org/10.1002/bimj.202200286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIMJ},
  author       = {Jianchang Hu},
  doi          = {10.1002/bimj.202200286},
  journal      = {Biometrical Journal},
  month        = {12},
  number       = {8},
  pages        = {1500-1501},
  shortjournal = {Bio. J.},
  title        = {Tree-based methods for statistical learning in r. brandon m. greenwell (2022). boca raton, FL: CRC press. 404 pp., £59.99. ISBN 978-0-367-53246-8},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Handbook of measurement error models. Grace y. Yi, aurore
delaigle and paul gustafson (eds.). (2021). Boca raton: Chapman &amp;
hall/CRC press. 592 pages. ISBN: 978-1-1381-0640-6. List price: £190
(hardback), £171 (eBook). <em>BIMJ</em>, <em>64</em>(8), 1498–1499. (<a
href="https://doi.org/10.1002/bimj.202200273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIMJ},
  author       = {Helmut Küchenhoff},
  doi          = {10.1002/bimj.202200273},
  journal      = {Biometrical Journal},
  month        = {12},
  number       = {8},
  pages        = {1498-1499},
  shortjournal = {Bio. J.},
  title        = {Handbook of measurement error models. grace y. yi, aurore delaigle and paul gustafson (Eds.). (2021). boca raton: chapman &amp; Hall/CRC press. 592 pages. ISBN: 978-1-1381-0640-6. list price: £190 (Hardback), £171 (eBook)},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DICE: A bayesian model for early dose finding in phase i
trials with multiple treatment courses. <em>BIMJ</em>, <em>64</em>(8),
1486–1497. (<a href="https://doi.org/10.1002/bimj.202000369">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dose-finding clinical trials in oncology aim to determine the maximum tolerated dose (MTD) of a new drug, generally defined by the proportion of patients with short-term dose-limiting toxicities (DLTs). Model-based approaches for such phase I oncology trials have been widely designed and are mostly restricted to the DLTs occurring during the first cycle of treatment, although patients continue to receive treatment for multiple cycles. We aim to estimate the probability of DLTs over sequences of treatment cycles via a Bayesian cumulative modeling approach, where the probability of DLT is modeled taking into account the cumulative effect of the administered drug and the DLT cycle of occurrence. We propose a design, called DICE (Dose-fInding CumulativE), for dose escalation and de-escalation according to previously observed toxicities, which aims at finding the MTD sequence (MTS). We performed an extensive simulation study comparing this approach to the time-to-event continual reassessment method (TITE-CRM) and a benchmark. In general, our approach achieved a better or comparable percentage of correct MTS selection. Moreover, we investigated the DICE prediction ability.},
  archive      = {J_BIMJ},
  author       = {Moreno Ursino and Lucie Biard and Sylvie Chevret},
  doi          = {10.1002/bimj.202000369},
  journal      = {Biometrical Journal},
  month        = {12},
  number       = {8},
  pages        = {1486-1497},
  shortjournal = {Bio. J.},
  title        = {DICE: A bayesian model for early dose finding in phase i trials with multiple treatment courses},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adapting SIMEX to correct for bias due to interval-censored
outcomes in survival analysis with time-varying exposure. <em>BIMJ</em>,
<em>64</em>(8), 1467–1485. (<a
href="https://doi.org/10.1002/bimj.202100013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many clinical and epidemiological applications of survival analysis focus on interval-censored events that can be ascertained only at discrete times of clinic visits. This implies that the values of time-varying covariates are not correctly aligned with the true, unknown event times, inducing a bias in the estimated associations. To address this issue, we adapted the simulation-extrapolation (SIMEX) methodology, based on assessing how the estimates change with the artificially increased time between clinic visits. We propose diagnostics to choose the extrapolating function. In simulations, the SIMEX-corrected estimates reduced considerably the bias to the null and generally yielded a better bias/variance trade-off than conventional estimates. In a real-life pharmacoepidemiological application, the proposed method increased by 27% the excess hazard of the estimated association between a time-varying exposure, representing the 2-year cumulative duration of past use of a hypertensive medication, and the hazard of nonmelanoma skin cancer (interval-censored events). These simulation-based and real-life results suggest that the proposed SIMEX-based correction may help improve the accuracy of estimated associations between time-varying exposures and the hazard of interval-censored events in large cohort studies where the events are recorded only at relatively sparse times of clinic visits/assessments. However, these advantages may be less certain for smaller studies and/or weak associations.},
  archive      = {J_BIMJ},
  author       = {Michal Abrahamowicz and Marie-Eve Beauchamp and Cristiano Soares Moura and Sasha Bernatsky and Steve Ferreira Guerra and Coraline Danieli},
  doi          = {10.1002/bimj.202100013},
  journal      = {Biometrical Journal},
  month        = {12},
  number       = {8},
  pages        = {1467-1485},
  shortjournal = {Bio. J.},
  title        = {Adapting SIMEX to correct for bias due to interval-censored outcomes in survival analysis with time-varying exposure},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiobjective semisupervised learning with a right-censored
endpoint adapted to the multiple imputation framework. <em>BIMJ</em>,
<em>64</em>(8), 1446–1466. (<a
href="https://doi.org/10.1002/bimj.202000365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semisupervised learning aims to use additional knowledge in the search for data structure. In clinical applications, including predictive information in the construction of a data-driven classification is of major importance. This work was motivated by a study that aimed to identify different patterns of immune parameters that would be associated with relapse-free survival in a cohort of breast cancer patients. Supervised and unsupervised objectives can be concomitantly optimized using multiobjective optimization. We propose such a procedure that addresses two challenges in the semisupervised approach, that is, missing data and additional knowledge based on survival time. The former was handled by using multiple imputation and consensus clustering. Survival information was incorporated in the supervised objective through the estimation of a cross-validation error of a Cox regression. A simulation study was performed to assess the performance of the proposed procedure. On complete datasets, the performances were compared to those of an existing modified multiobjective semisupervised learning method. The added value of including the survival data in the learning process was assessed by comparing the procedure to unsupervised learning. The proposed procedure showed better performance than the existing method, notably in the selection of the number of clusters. On incomplete datasets, the procedure showed little sensitivity to most of its parameters, even though a high number of imputations and partition initialization seeds improved the performance. The performance was degraded with a high proportion of missing data (40%) and with more ambiguous data structures. Simulation results and application on real data support the conclusion that our procedure enables the construction of a classification associated with a right-censored endpoint on a possibly incomplete dataset.},
  archive      = {J_BIMJ},
  author       = {Lilith Faucheux and Vassili Soumelis and Sylvie Chevret},
  doi          = {10.1002/bimj.202000365},
  journal      = {Biometrical Journal},
  month        = {12},
  number       = {8},
  pages        = {1446-1466},
  shortjournal = {Bio. J.},
  title        = {Multiobjective semisupervised learning with a right-censored endpoint adapted to the multiple imputation framework},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep dynamic modeling with just two time points: Can we
still allow for individual trajectories? <em>BIMJ</em>, <em>64</em>(8),
1426–1445. (<a href="https://doi.org/10.1002/bimj.202000366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Longitudinal biomedical data are often characterized by a sparse time grid and individual-specific development patterns. Specifically, in epidemiological cohort studies and clinical registries we are facing the question of what can be learned from the data in an early phase of the study, when only a baseline characterization and one follow-up measurement are available. Inspired by recent advances that allow to combine deep learning with dynamic modeling, we investigate whether such approaches can be useful for uncovering complex structure, in particular for an extreme small data setting with only two observations time points for each individual. Irregular spacing in time could then be used to gain more information on individual dynamics by leveraging similarity of individuals. We provide a brief overview of how variational autoencoders (VAEs), as a deep learning approach, can be linked to ordinary differential equations (ODEs) for dynamic modeling, and then specifically investigate the feasibility of such an approach that infers individual-specific latent trajectories by including regularity assumptions and individuals&#39; similarity. We also provide a description of this deep learning approach as a filtering task to give a statistical perspective. Using simulated data, we show to what extent the approach can recover individual trajectories from ODE systems with two and four unknown parameters and infer groups of individuals with similar trajectories, and where it breaks down. The results show that such dynamic deep learning approaches can be useful even in extreme small data settings, but need to be carefully adapted.},
  archive      = {J_BIMJ},
  author       = {Maren Hackenberg and Philipp Harms and Michelle Pfaffenlehner and Astrid Pechmann and Janbernd Kirschner and Thorsten Schmidt and Harald Binder},
  doi          = {10.1002/bimj.202000366},
  journal      = {Biometrical Journal},
  month        = {12},
  number       = {8},
  pages        = {1426-1445},
  shortjournal = {Bio. J.},
  title        = {Deep dynamic modeling with just two time points: Can we still allow for individual trajectories?},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evaluation of approaches for accommodating interactions and
non-linear terms in multiple imputation of incomplete three-level data.
<em>BIMJ</em>, <em>64</em>(8), 1404–1425. (<a
href="https://doi.org/10.1002/bimj.202000343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-level data structures arising from repeated measures on individuals clustered within larger units are common in health research studies. Missing data are prominent in such studies and are often handled via multiple imputation (MI). Although several MI approaches can be used to account for the three-level structure, including adaptations to single- and two-level approaches, when the substantive analysis model includes interactions or quadratic effects, these too need to be accommodated in the imputation model. In such analyses, substantive model compatible (SMC) MI has shown great promise in the context of single-level data. Although there have been recent developments in multilevel SMC MI, to date only one approach that explicitly handles incomplete three-level data is available. Alternatively, researchers can use pragmatic adaptations to single- and two-level MI approaches, or two-level SMC-MI approaches. We describe the available approaches and evaluate them via simulations in the context of three three-level random effects analysis models involving an interaction between the incomplete time-varying exposure and time, an interaction between the time-varying exposure and an incomplete time-fixed confounder, or a quadratic effect of the exposure. Results showed that all approaches considered performed well in terms of bias and precision when the target analysis involved an interaction with time, but the three-level SMC MI approach performed best when the target analysis involved an interaction between the time-varying exposure and an incomplete time-fixed confounder, or a quadratic effect of the exposure. We illustrate the methods using data from the Childhood to Adolescence Transition Study.},
  archive      = {J_BIMJ},
  author       = {Rushani Wijesuriya and Margarita Moreno-Betancur and John B. Carlin and Anurika P. De Silva and Katherine J. Lee},
  doi          = {10.1002/bimj.202000343},
  journal      = {Biometrical Journal},
  month        = {12},
  number       = {8},
  pages        = {1404-1425},
  shortjournal = {Bio. J.},
  title        = {Evaluation of approaches for accommodating interactions and non-linear terms in multiple imputation of incomplete three-level data},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Causal inference in case of near-violation of positivity:
Comparison of methods. <em>BIMJ</em>, <em>64</em>(8), 1389–1403. (<a
href="https://doi.org/10.1002/bimj.202000323">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In causal studies, the near-violation of the positivity may occur by chance, because of sample-to-sample fluctuation despite the theoretical veracity of the positivity assumption in the population. It may mostly happen when the exposure prevalence is low or when the sample size is small. We aimed to compare the robustness of g-computation (GC), inverse probability weighting (IPW), truncated IPW, targeted maximum likelihood estimation (TMLE), and truncated TMLE in this situation, using simulations and one real application. We also tested different extrapolation situations for the sub-group with a positivity violation. The results illustrated that the near-violation of the positivity impacted all methods. We demonstrated the robustness of GC and TMLE-based methods. Truncation helped in limiting the bias in near-violation situations, but at the cost of bias in normal conditions. The application illustrated the variability of the results between the methods and the importance of choosing the most appropriate one. In conclusion, compared to propensity score-based methods, methods based on outcome regression should be preferred when suspecting near-violation of the positivity assumption.},
  archive      = {J_BIMJ},
  author       = {Maxime Léger and Arthur Chatton and Florent Le Borgne and Romain Pirracchio and Sigismond Lasocki and Yohann Foucher},
  doi          = {10.1002/bimj.202000323},
  journal      = {Biometrical Journal},
  month        = {12},
  number       = {8},
  pages        = {1389-1403},
  shortjournal = {Bio. J.},
  title        = {Causal inference in case of near-violation of positivity: Comparison of methods},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Using marginal structural joint models to estimate the
effect of a time-varying treatment on recurrent events and survival: An
application on arrhythmogenic cardiomyopathy. <em>BIMJ</em>,
<em>64</em>(8), 1374–1388. (<a
href="https://doi.org/10.1002/bimj.202100003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many clinical applications to evaluate the effect of a treatment, randomized control trials are difficult to carry out. On the other hand, clinical observational registries are often available and they contain longitudinal data regarding clinical parameters, drug therapies, and outcomes. In the past, much research has addressed causal methods to estimate treatment effects from observational studies. In the context of time-varying treatments, marginal structural models are often used. However, most analyses have focused on binary outcomes or time-to-the-first event analyses. The novelty of our approach is to combine the marginal structural methodology with the case where correlated recurrent events and survival are the outcomes of interest. Our work focuses on solving the nontrivial problem of defining the measures of effect, specifying the model for the time-dependent weights and the model to estimate the outcome, implementing them, and finally estimating the final treatment effects in this life-history setting. Our approach provides a strategy that allows obtaining treatment effect estimates both on the recurrent events and the survival with a clear causal and clinical interpretation. At the same time, the strategy we propose is based on flexible modeling choices such as the use of joint models to capture the correlation within events from the same subject and the specification of time-dependent treatment effects. The clinical problem which motivated our work is the evaluation of the treatment effect of beta-blockers in arrhythmogenic right ventricular cardiomyopathy (ARVC/D), and the dataset comes from the Trieste Heart Muscle Disease Registry.},
  archive      = {J_BIMJ},
  author       = {Caterina Gregorio and Chiara Cappelletto and Simona Romani and Davide Stolfo and Marco Merlo and Giulia Barbati},
  doi          = {10.1002/bimj.202100003},
  journal      = {Biometrical Journal},
  month        = {12},
  number       = {8},
  pages        = {1374-1388},
  shortjournal = {Bio. J.},
  title        = {Using marginal structural joint models to estimate the effect of a time-varying treatment on recurrent events and survival: An application on arrhythmogenic cardiomyopathy},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Clinical biostatistics in the 2020s. <em>BIMJ</em>,
<em>64</em>(8), 1371–1373. (<a
href="https://doi.org/10.1002/bimj.202200303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIMJ},
  author       = {Michal Abrahamowicz},
  doi          = {10.1002/bimj.202200303},
  journal      = {Biometrical Journal},
  month        = {12},
  number       = {8},
  pages        = {1371-1373},
  shortjournal = {Bio. J.},
  title        = {Clinical biostatistics in the 2020s},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022h). Contents: Biometrical journal 8’22. <em>BIMJ</em>,
<em>64</em>(8), 1369–1370. (<a
href="https://doi.org/10.1002/bimj.202270084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIMJ},
  doi          = {10.1002/bimj.202270084},
  journal      = {Biometrical Journal},
  month        = {12},
  number       = {8},
  pages        = {1369-1370},
  shortjournal = {Bio. J.},
  title        = {Contents: Biometrical journal 8&#39;22},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022g). Cover picture: Biometrical journal 7’22. <em>BIMJ</em>,
<em>64</em>(7), NA. (<a
href="https://doi.org/10.1002/bimj.202270071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIMJ},
  doi          = {10.1002/bimj.202270071},
  journal      = {Biometrical Journal},
  month        = {10},
  number       = {7},
  pages        = {NA},
  shortjournal = {Bio. J.},
  title        = {Cover picture: Biometrical journal 7&#39;22},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Single-arm phase II survival trial design. Jianrong wu
(2021). Boca raton: Chapman &amp; hall/CRC press. 273 pages. ISBN:
978-0-3676-5345-3. List price: £130 (hardback), £40.49 (eBook).
<em>BIMJ</em>, <em>64</em>(7), 1363. (<a
href="https://doi.org/10.1002/bimj.202200197">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIMJ},
  author       = {Axel Benner},
  doi          = {10.1002/bimj.202200197},
  journal      = {Biometrical Journal},
  month        = {10},
  number       = {7},
  pages        = {1363},
  shortjournal = {Bio. J.},
  title        = {Single-arm phase II survival trial design. jianrong wu (2021). boca raton: chapman &amp; Hall/CRC press. 273 pages. ISBN: 978-0-3676-5345-3. list price: £130 (Hardback), £40.49 (eBook)},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Statistical thinking in clinical trials, michael a. Proschan
(2021). 264 pages. New york: Chapman and hall/CRC. eBook ISBN
9781315164090. <em>BIMJ</em>, <em>64</em>(7), 1361–1362. (<a
href="https://doi.org/10.1002/bimj.202200192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIMJ},
  author       = {Mark Baillie and Frank Bretz},
  doi          = {10.1002/bimj.202200192},
  journal      = {Biometrical Journal},
  month        = {10},
  number       = {7},
  pages        = {1361-1362},
  shortjournal = {Bio. J.},
  title        = {Statistical thinking in clinical trials, michael a. proschan (2021). 264 pages. new york: Chapman and Hall/CRC. eBook ISBN 9781315164090.},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Jointly pooling aggregated effect sizes and their standard
errors from studies with continuous clinical outcomes. <em>BIMJ</em>,
<em>64</em>(7), 1340–1360. (<a
href="https://doi.org/10.1002/bimj.202100108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The DerSimonian–Laird (DL) weighted average method for aggregated data meta-analysis has been widely used for the estimation of overall effect sizes. It is criticized for its underestimation of the standard error of the overall effect size in the presence of heterogeneous effect sizes. Due to this negative property, many alternative estimation approaches have been proposed in the literature. One of the earliest alternative approaches was developed by Hardy and Thompson (HT), who implemented a profile likelihood instead of the moment-based approach of DL. Others have further extended this likelihood approach and proposed higher-order likelihood inferences (e.g., Bartlett-type corrections). In addition, corrections factors for the estimated DL standard error, like the Hartung–Knapp–Sidik–Jonkman (HKSJ) adjustment, and the restricted maximum likelihood (REML) estimation have been suggested too. Although these improvements address the uncertainty in estimating the between-study variance better than the DL method, they all assume that the true within-study standard errors are known and equal to the observed standard errors of the effect sizes. Here, we will treat the observed standard errors as estimators for the within-study variability and we propose a bivariate likelihood approach that jointly estimates the overall effect size, the between-study variance, and the potentially heteroskedastic within-study variances. We study the performance of the proposed method by means of simulation, and compare it to DL (with and without HKSJ), HT, their higher-order likelihood methods, and REML. Our proposed approach seems to have better or similar coverages compared to the other approaches and it appears to be less biased in the case of heteroskedastic within-study variances when this heteroskedasticty is correlated with the effect size.},
  archive      = {J_BIMJ},
  author       = {Osama Almalik and Zhuozhao Zhan and Edwin R. van den Heuvel},
  doi          = {10.1002/bimj.202100108},
  journal      = {Biometrical Journal},
  month        = {10},
  number       = {7},
  pages        = {1340-1360},
  shortjournal = {Bio. J.},
  title        = {Jointly pooling aggregated effect sizes and their standard errors from studies with continuous clinical outcomes},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multivariate linear mixed models with censored and
nonignorable missing outcomes, with application to AIDS studies.
<em>BIMJ</em>, <em>64</em>(7), 1325–1339. (<a
href="https://doi.org/10.1002/bimj.202100233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The analysis of multivariate longitudinal data could encounter some complications due to censorship induced by detection limits of the assay and nonresponse occurring when participants missed scheduled visits intermittently or discontinued participation. This paper establishes a generalization of the multivariate linear mixed model that can accommodate censored responses and nonignorable missing outcomes simultaneously. To account for the nonignorable missingness, the selection approach which decomposes the joint distribution as a marginal distribution for the primary outcome variables and a model describing the missing process conditional on the hypothetical complete data is used. A computationally feasible Monte Carlo expectation conditional maximization algorithm is developed for parameter estimation with the maximum likelihood (ML) method. Furthermore, a general information-based approach is presented to assess the variability of ML estimators. The techniques for the prediction of censored responses and imputation of missing outcomes are also discussed. The methodology is motivated and exemplified by a real dataset concerning HIV-AIDS clinical trials. A simulation study is conducted to examine the performance of the proposed method compared with other traditional approaches.},
  archive      = {J_BIMJ},
  author       = {Tsung-I Lin and Wan-Lun Wang},
  doi          = {10.1002/bimj.202100233},
  journal      = {Biometrical Journal},
  month        = {10},
  number       = {7},
  pages        = {1325-1339},
  shortjournal = {Bio. J.},
  title        = {Multivariate linear mixed models with censored and nonignorable missing outcomes, with application to AIDS studies},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust probit linear mixed models for longitudinal binary
data. <em>BIMJ</em>, <em>64</em>(7), 1307–1324. (<a
href="https://doi.org/10.1002/bimj.202100246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose Bayesian analysis methods dealing with longitudinal data involving repeated binary outcomes on subjects with dropouts. The proposed Bayesian methods implement probit models with random effects to capture heterogeneity and hypersphere decomposition to model the correlation matrix for serial correlation of repeated responses. We investigate the model robustness against misspecifications of the probit models along with techniques to handle missing data. The parameters of the proposed models are estimated by implementing an Markov chain Monte Carlo (MCMC) algorithm, and simulations were performed to provide a comparison with other models and validate the choice of prior distributions. The simulations show that when suitable correlation structures are specified, the proposed approach improves estimation of the regression parameters in terms of the mean percent relative error and the mean squared error. Finally, two real data examples are provided to illustrate the proposed approach.},
  archive      = {J_BIMJ},
  author       = {Kuo-Jung Lee and Chanmin Kim and Ray-Bing Chen and Keunbaik Lee},
  doi          = {10.1002/bimj.202100246},
  journal      = {Biometrical Journal},
  month        = {10},
  number       = {7},
  pages        = {1307-1324},
  shortjournal = {Bio. J.},
  title        = {Robust probit linear mixed models for longitudinal binary data},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semi-supervised empirical bayes group-regularized factor
regression. <em>BIMJ</em>, <em>64</em>(7), 1289–1306. (<a
href="https://doi.org/10.1002/bimj.202100105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The features in a high-dimensional biomedical prediction problem are often well described by low-dimensional latent variables (or factors). We use this to include unlabeled features and additional information on the features when building a prediction model. Such additional feature information is often available in biomedical applications. Examples are annotation of genes, metabolites, or p -values from a previous study. We employ a Bayesian factor regression model that jointly models the features and the outcome using Gaussian latent variables. We fit the model using a computationally efficient variational Bayes method, which scales to high dimensions. We use the extra information to set up a prior model for the features in terms of hyperparameters, which are then estimated through empirical Bayes. The method is demonstrated in simulations and two applications. One application considers influenza vaccine efficacy prediction based on microarray data. The second application predicts oral cancer metastasis from RNAseq data.},
  archive      = {J_BIMJ},
  author       = {Magnus M. Münch and Mark A. van de Wiel and Aad W. van der Vaart and Carel F. W. Peeters},
  doi          = {10.1002/bimj.202100105},
  journal      = {Biometrical Journal},
  month        = {10},
  number       = {7},
  pages        = {1289-1306},
  shortjournal = {Bio. J.},
  title        = {Semi-supervised empirical bayes group-regularized factor regression},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A gentle tutorial on accelerated parameter and confidence
interval estimation for hidden markov models using template model
builder. <em>BIMJ</em>, <em>64</em>(7), 1260–1288. (<a
href="https://doi.org/10.1002/bimj.202100256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A very common way to estimate the parameters of a hidden Markov model (HMM) is the relatively straightforward computation of maximum likelihood (ML) estimates. For this task, most users rely on user-friendly implementation of the estimation routines via an interpreted programming language such as the statistical software environment R . Such an approach can easily require time-consuming computations, in particular for longer sequences of observations. In addition, selecting a suitable approach for deriving confidence intervals for the estimated parameters is not entirely obvious, and often the computationally intensive bootstrap methods have to be applied. In this tutorial, we illustrate how to speed up the computation of ML estimates significantly via the R package TMB . Moreover, this approach permits simple retrieval of standard errors at the same time. We illustrate the performance of our routines using different data sets: first, two smaller samples from a mobile application for tinnitus patients and a well-known data set of fetal lamb movements with 87 and 240 data points, respectively. Second, we rely on larger data sets of simulated data of sizes 2000 and 5000 for further analysis. This tutorial is accompanied by a collection of scripts, which are all available in the Supporting Information. These scripts allow any user with moderate programming experience to benefit quickly from the computational advantages of TMB .},
  archive      = {J_BIMJ},
  author       = {Timothée Bacri and Geir D. Berentsen and Jan Bulla and Sondre Hølleland},
  doi          = {10.1002/bimj.202100256},
  journal      = {Biometrical Journal},
  month        = {10},
  number       = {7},
  pages        = {1260-1288},
  shortjournal = {Bio. J.},
  title        = {A gentle tutorial on accelerated parameter and confidence interval estimation for hidden markov models using template model builder},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). New weighting methods when cases are only a subset of events
in a nested case-control study. <em>BIMJ</em>, <em>64</em>(7),
1240–1259. (<a href="https://doi.org/10.1002/bimj.202100194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nested case control (NCC) is a sampling method widely used for developing and evaluating risk models with expensive biomarkers on large prospective cohort studies. In a typical NCC design, biomarker values are obtained on a subcohort, where cases consist of all the events (subjects who experience the event during the follow-up). However, when the number of events is not small, due to the cost and limited availability of biospecimen, one may select only a subset of events as cases. We refer to such a variation as the untypical NCC. Unfortunately, existing inverse probability weighted (IPW) estimators for the untypical NCC are biased, and they only focus on relative risk parameters under the proportional hazards (PH) model. In this manuscript, we propose new weighting methods that produce consistent IPW estimators for not only relative risk parameters but also several metrics that evaluate a risk model&#39;s predictive performance. We also provide the inference procedure via perturbation resampling, which captures all the variance and between-subject covariance induced by the sampling processes for both case and control selections. In addition, our methods are not limited to the PH model, and they can be applied to the time-specific generalized linear model. Under the typical NCC design, our new weights are equivalent to the weight proposed by Samuelsen; under the untypical NCC, the IPW estimators using our weights have smaller bias and variance than the existing methods. We will demonstrate this improved performance via both analytical and numerical investigations.},
  archive      = {J_BIMJ},
  author       = {Qian M. Zhou and Xuan Wang and Yingye Zheng and Tianxi Cai},
  doi          = {10.1002/bimj.202100194},
  journal      = {Biometrical Journal},
  month        = {10},
  number       = {7},
  pages        = {1240-1259},
  shortjournal = {Bio. J.},
  title        = {New weighting methods when cases are only a subset of events in a nested case-control study},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A unified framework for weighted parametric group sequential
design. <em>BIMJ</em>, <em>64</em>(7), 1219–1239. (<a
href="https://doi.org/10.1002/bimj.202100085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Group sequential design (GSD) is widely used in clinical trials in which correlated tests of multiple hypotheses are used. Multiple primary objectives resulting in tests with known correlations include evaluating (1) multiple experimental treatment arms, (2) multiple populations, (3) the combination of multiple arms and multiple populations, or (4) any asymptotically multivariate normal tests. In this paper, we focus on the first three of these and extend the framework of the weighted parametric multiple test procedure from fixed designs with a single analysis per objective to a GSD setting where different objectives may be assessed at the same or different times, each in a group sequential fashion. Pragmatic methods for design and analysis of weighted parametric group sequential design under closed testing procedures are proposed to maintain the strong control of the family-wise Type I error rate when correlations between tests are incorporated. This results in the ability to relax testing bounds compared to designs not fully adjusting for known correlations, increasing power, or allowing decreased sample size. We illustrate the proposed methods using clinical trial examples and conduct a simulation study to evaluate the operating characteristics.},
  archive      = {J_BIMJ},
  author       = {Keaven M. Anderson and Zifang Guo and Jing Zhao and Linda Z. Sun},
  doi          = {10.1002/bimj.202100085},
  journal      = {Biometrical Journal},
  month        = {10},
  number       = {7},
  pages        = {1219-1239},
  shortjournal = {Bio. J.},
  title        = {A unified framework for weighted parametric group sequential design},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Two-stage screened selection designs for randomized phase II
trials with time-to-event endpoints. <em>BIMJ</em>, <em>64</em>(7),
1207–1218. (<a href="https://doi.org/10.1002/bimj.202100305">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Phase II exploratory multiarm studies that randomize among new treatments are found to be broadly useful and appear to be of value both scientifically and logistically, especially in the areas of unmet needs, for example, pediatric cancer. This multiarm design also has a faster recruitment rate because it provides patients with more treatment choices than traditional two-arm randomized controlled trials do. In contrast to direct formal comparisons in multiarm multistage designs, for example, umbrella or platform designs, the screened selection design (SSD) recommends using a promising treatment arm by ranking according to the effect size, which often needs lesser sample sizes than the former. In this paper, the usefulness of the phase II SSD design is exemplified by three real trials. However, the existing SSD methods can only deal with binary endpoints. Motivated by the real trials in the authors&#39; respective institutions, we propose using the two-stage SSD and its variant for randomized phase II trials with the time-to-event endpoint. The proposed methods not only provide a high probability of selecting a superior treatment arm but also control the type I error rate for testing the efficacy of each treatment arm versus a common external control. Sample size calculations have been derived and simulation studies demonstrate desirable operating characteristics. The proposed design has been used for designing three real trials. An R package frequentistSSD has been developed and is freely accessible for practitioners.},
  archive      = {J_BIMJ},
  author       = {Jianrong Wu and Haitao Pan and Chia-Wei Hsu},
  doi          = {10.1002/bimj.202100305},
  journal      = {Biometrical Journal},
  month        = {10},
  number       = {7},
  pages        = {1207-1218},
  shortjournal = {Bio. J.},
  title        = {Two-stage screened selection designs for randomized phase II trials with time-to-event endpoints},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian two-stage sequential enrichment design for
biomarker-guided phase II trials for anticancer therapies.
<em>BIMJ</em>, <em>64</em>(7), 1192–1206. (<a
href="https://doi.org/10.1002/bimj.202100297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biomarker-guided phase II trials have become increasingly important for personalized cancer treatment. In this paper, we propose a Bayesian two-stage sequential enrichment design for such biomarker-guided trials. We assumed that all patients were dichotomized as marker positive or marker negative based on their biomarker status; the positive patients were considered more likely to respond to the targeted drug. Early stopping rules and adaptive randomization methods were embedded in the design to control the number of patients receiving inferior treatment. At the same time, a Bayesian hierarchical model was used to borrow information between the positive and negative control arms to improve efficiency. Simulation results showed that the proposed design achieved higher empirical power while controlling the type I error and assigned more patients to the superior treatment arms. The operating characteristics suggested that the design has good performance and may be useful for biomarker-guided phase II trials for evaluating anticancer therapies.},
  archive      = {J_BIMJ},
  author       = {Liwen Su and Xin Chen and Jingyi Zhang and Jun Gao and Fangrong Yan},
  doi          = {10.1002/bimj.202100297},
  journal      = {Biometrical Journal},
  month        = {10},
  number       = {7},
  pages        = {1192-1206},
  shortjournal = {Bio. J.},
  title        = {Bayesian two-stage sequential enrichment design for biomarker-guided phase II trials for anticancer therapies},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GBOIN-ET: The generalized bayesian optimal interval design
for optimal dose-finding accounting for ordinal graded efficacy and
toxicity in early clinical trials. <em>BIMJ</em>, <em>64</em>(7),
1178–1191. (<a href="https://doi.org/10.1002/bimj.202100263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the primary objectives of an oncology dose-finding trial for novel therapies, such as molecular targeted agents and immune-oncology therapies, is to identify an optimal dose (OD) that is tolerable and therapeutically beneficial for subjects in subsequent clinical trials. These new therapeutic agents appear more likely to induce multiple low- or moderate-grade toxicities than dose-limiting toxicities. Besides, efficacy should be evaluated as an overall response and stable disease in solid tumors and the difference between complete remission and partial remission in lymphoma. This paper proposes the generalized Bayesian optimal interval design for dose-finding accounting for efficacy and toxicity grades. The new design, named “gBOIN-ET” design, is model-assisted, simple, and straightforward to implement in actual oncology dose-finding trials than model-based approaches. These characteristics are quite valuable in practice. A simulation study shows that the gBOIN-ET design has advantages compared with the other model-assisted designs in the percentage of correct OD selection and the average number of patients allocated to the ODs across various realistic settings.},
  archive      = {J_BIMJ},
  author       = {Kentaro Takeda and Satoshi Morita and Masataka Taguri},
  doi          = {10.1002/bimj.202100263},
  journal      = {Biometrical Journal},
  month        = {10},
  number       = {7},
  pages        = {1178-1191},
  shortjournal = {Bio. J.},
  title        = {GBOIN-ET: The generalized bayesian optimal interval design for optimal dose-finding accounting for ordinal graded efficacy and toxicity in early clinical trials},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the choice of timescale for other cause mortality in a
competing risk setting using flexible parametric survival models.
<em>BIMJ</em>, <em>64</em>(7), 1161–1177. (<a
href="https://doi.org/10.1002/bimj.202100254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In competing risks settings where the events are death due to cancer and death due to other causes, it is common practice to use time since diagnosis as the timescale for all competing events. However, attained age has been proposed as a more natural choice of timescale for modeling other cause mortality. We examine the choice of using time since diagnosis versus attained age as the timescale when modeling other cause mortality, assuming that the hazard rate is a function of attained age, and how this choice can influence the cumulative incidence functions ( C I F $CIF$ s) derived using flexible parametric survival models. An initial analysis on the colon cancer data from the population-based Swedish Cancer Register indicates such an influence. A simulation study is conducted in order to assess the impact of the choice of timescale for other cause mortality on the bias of the estimated C I F s $CIFs$ and how different factors may influence the bias. We also use regression standardization methods in order to obtain marginal C I F $CIF$ estimates. Using time since diagnosis as the timescale for all competing events leads to a low degree of bias in C I F $CIF$ for cancer mortality ( C I F 1 $CIF_{1}$ ) under all approaches. It also leads to a low degree of bias in C I F $CIF$ for other cause mortality ( C I F 2 $CIF_{2}$ ), provided that the effect of age at diagnosis is included in the model with sufficient flexibility, with higher bias under scenarios where a covariate has a time-varying effect on the hazard rate for other cause mortality on the attained age scale.},
  archive      = {J_BIMJ},
  author       = {Nikolaos Skourlis and Michael J. Crowther and Therese M.-L. Andersson and Paul C. Lambert},
  doi          = {10.1002/bimj.202100254},
  journal      = {Biometrical Journal},
  month        = {10},
  number       = {7},
  pages        = {1161-1177},
  shortjournal = {Bio. J.},
  title        = {On the choice of timescale for other cause mortality in a competing risk setting using flexible parametric survival models},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). In memory of carmen maría cadarso suárez (1960–2022).
<em>BIMJ</em>, <em>64</em>(7), 1159–1160. (<a
href="https://doi.org/10.1002/bimj.202270075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIMJ},
  author       = {Guadalupe Gómez Melis and Thomas Kneib},
  doi          = {10.1002/bimj.202270075},
  journal      = {Biometrical Journal},
  month        = {10},
  number       = {7},
  pages        = {1159-1160},
  shortjournal = {Bio. J.},
  title        = {In memory of carmen maría cadarso suárez (1960–2022)},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022g). Contents: Biometrical journal 7’22. <em>BIMJ</em>,
<em>64</em>(7), 1157–1158. (<a
href="https://doi.org/10.1002/bimj.202270074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIMJ},
  doi          = {10.1002/bimj.202270074},
  journal      = {Biometrical Journal},
  month        = {10},
  number       = {7},
  pages        = {1157-1158},
  shortjournal = {Bio. J.},
  title        = {Contents: Biometrical journal 7&#39;22},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022f). Cover picture: Biometrical journal 6’22. <em>BIMJ</em>,
<em>64</em>(6), NA. (<a
href="https://doi.org/10.1002/bimj.202270061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIMJ},
  doi          = {10.1002/bimj.202270061},
  journal      = {Biometrical Journal},
  month        = {8},
  number       = {6},
  pages        = {NA},
  shortjournal = {Bio. J.},
  title        = {Cover picture: Biometrical journal 6&#39;22},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient testing and effect size estimation for set-based
genetic association inference via semiparametric multilevel mixture
modeling. <em>BIMJ</em>, <em>64</em>(6), 1142–1152. (<a
href="https://doi.org/10.1002/bimj.202100234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In genetic association studies, rare variants with extremely low allele frequencies play a crucial role in complex traits. Therefore, set-based testing methods that jointly assess the effects of groups of single nucleotide polymorphisms (SNPs) were developed to increase the powers of the association tests. However, these powers are still insufficient, and precise estimations of the effect sizes of individual SNPs are largely impossible. In this article, we provide an efficient set-based statistical inference framework that addresses both of these important issues simultaneously using an empirical Bayes method with semiparametric multilevel mixture modeling. We propose to utilize the hierarchical model that incorporates variations in set-specific effects and to apply the optimal discovery procedure (ODP) that achieves the largest overall power in multiple significance testing. In addition, we provide an optimal “set-based” estimator of the empirical distribution of effect sizes. The efficiency of the proposed methods is demonstrated through application to a genome-wide association study of coronary artery disease and through simulation studies. The results demonstrated numerous rare variants with large effect sizes for coronary artery disease, and the number of significant sets detected by the ODP was much greater than those identified by existing methods.},
  archive      = {J_BIMJ},
  author       = {Shonosuke Sugasawa and Hisashi Noma},
  doi          = {10.1002/bimj.202100234},
  journal      = {Biometrical Journal},
  month        = {8},
  number       = {6},
  pages        = {1142-1152},
  shortjournal = {Bio. J.},
  title        = {Efficient testing and effect size estimation for set-based genetic association inference via semiparametric multilevel mixture modeling},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Regression-based heterogeneity analysis to identify
overlapping subgroup structure in high-dimensional data. <em>BIMJ</em>,
<em>64</em>(6), 1109–1141. (<a
href="https://doi.org/10.1002/bimj.202100119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneity is a hallmark of complex diseases. Regression-based heterogeneity analysis, which is directly concerned with outcome–feature relationships, has led to a deeper understanding of disease biology. Such an analysis identifies the underlying subgroup structure and estimates the subgroup-specific regression coefficients. However, most of the existing regression-based heterogeneity analyses can only address disjoint subgroups; that is, each sample is assigned to only one subgroup. In reality, some samples have multiple labels, for example, many genes have several biological functions, and some cells of pure cell types transition into other types over time, which suggest that their outcome–feature relationships (regression coefficients) can be a mixture of relationships in more than one subgroups, and as a result, the disjoint subgrouping results can be unsatisfactory. To this end, we develop a novel approach to regression-based heterogeneity analysis, which takes into account possible overlaps between subgroups and high data dimensions. A subgroup membership vector is introduced for each sample, which is combined with a loss function. Considering the lack of information arising from small sample sizes, an norm penalty is developed for each membership vector to encourage similarity in its elements. A sparse penalization is also applied for regularized estimation and feature selection. Extensive simulations demonstrate its superiority over direct competitors. The analysis of Cancer Cell Line Encyclopedia data and lung cancer data from The Cancer Genome Atlas show that the proposed approach can identify an overlapping subgroup structure with favorable performance in prediction and stability.},
  archive      = {J_BIMJ},
  author       = {Ziye Luo and Xinyue Yao and Yifan Sun and Xinyan Fan},
  doi          = {10.1002/bimj.202100119},
  journal      = {Biometrical Journal},
  month        = {8},
  number       = {6},
  pages        = {1109-1141},
  shortjournal = {Bio. J.},
  title        = {Regression-based heterogeneity analysis to identify overlapping subgroup structure in high-dimensional data},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On optimal two-stage testing of multiple mediators.
<em>BIMJ</em>, <em>64</em>(6), 1090–1108. (<a
href="https://doi.org/10.1002/bimj.202100190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mediation analysis in high-dimensional settings often involves identifying potential mediators among a large number of measured variables. For this purpose, a two-step familywise error rate procedure called ScreenMin has been recently proposed. In ScreenMin, variables are first screened and only those that pass the screening are tested. The proposed data-independent threshold for selection has been shown to guarantee asymptotic familywise error rate. In this work, we investigate the impact of the threshold on the finite-sample familywise error rate. We derive a power maximizing threshold and show that it is well approximated by an adaptive threshold of Wang et al. (2016, arXiv preprint arXiv:1610.03330). We illustrate the investigated procedures on a case-control study examining the effect of fish intake on the risk of colorectal adenoma. We also apply our procedure in the context of replicability analysis to identify single nucleotide polymorphisms (SNP) associated with crop yield in two distinct environments.},
  archive      = {J_BIMJ},
  author       = {Vera Djordjilović and Jesse Hemerik and Magne Thoresen},
  doi          = {10.1002/bimj.202100190},
  journal      = {Biometrical Journal},
  month        = {8},
  number       = {6},
  pages        = {1090-1108},
  shortjournal = {Bio. J.},
  title        = {On optimal two-stage testing of multiple mediators},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Application of gap time analysis with flexible hazards to
pulmonary exacerbations in the EPIC observational study. <em>BIMJ</em>,
<em>64</em>(6), 1075–1089. (<a
href="https://doi.org/10.1002/bimj.201900255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cystic fibrosis and other chronic lung disease clinical trials often use time to first pulmonary exacerbation (PEx) or total PEx count as endpoints. The use of these outcomes may fail to capture patterns or timing of multiple exacerbations and how covariates influence the risk of future exacerbations. Analysis of gap times between PEx provides a useful framework to understand risks of subsequent events, particularly to assess if there is a temporary increase in a hazard of a subsequent PEx following the occurrence of a PEx. This may be useful for estimating the amount of time needed to follow patients after a PEx and predicting which patients are more likely to have multiple PEx. We propose a smoothed hazard for gap times to account for elevated hazards after exacerbations. A simulation study was conducted to explore model performance and was able to appropriately estimate parameters in all situations with an underlying change point with independent or correlated recurrent events. Models with different change-point structures and trends are compared using Early Pseudomonas Infection Control (EPIC) observational study data, using a quasi-likelihood modification of the Akaike information criterion; a model with a change-point provided a better fit than a model without one. The analysis suggests that the change point may be 1.8 years (SE 0.09) after the end of a PEx. Models including covariates in the hazard function revealed that having one or two copies of the F508 mutation, female sex, and higher numbers of previous PEx were significantly associated with increased risk of another PEx.},
  archive      = {J_BIMJ},
  author       = {John D. Rice and Rachel L. Johnson and Elizabeth Juarez-Colunga and Edith T. Zemanick and Margaret Rosenfeld and Brandie D. Wagner},
  doi          = {10.1002/bimj.201900255},
  journal      = {Biometrical Journal},
  month        = {8},
  number       = {6},
  pages        = {1075-1089},
  shortjournal = {Bio. J.},
  title        = {Application of gap time analysis with flexible hazards to pulmonary exacerbations in the EPIC observational study},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Time-dependent ROC curve estimation for interval-censored
data. <em>BIMJ</em>, <em>64</em>(6), 1056–1074. (<a
href="https://doi.org/10.1002/bimj.202000382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The receiver-operating characteristic (ROC) curve is the most popular graphical method for evaluating the classification accuracy of a diagnostic marker. In time-to-event studies, the subject&#39;s event status is time-dependent, and hence, time-dependent extensions of ROC curve have been proposed. However, in practice, the calculation of this curve is not straightforward due to the presence of censoring that may be of different types. Existing methods focus on the more standard and simple case of right-censoring and neglect the general case of mixed interval-censored data that may involve left-, right-, and interval-censored observations. In this context, we propose and study a new time-dependent ROC curve estimator. We also consider some summary measures (area under the ROC curve and Youden index) traditionally associated with ROC as well as the Youden-based cutoff estimation method. The proposed method uses available data very efficiently. To this end, the unknown status (positive or negative) of censored subjects are estimated from the data via the estimation of the conditional survival function given the marker. For that, we investigate both model-based and nonparametric approaches. We also provide variance estimates and confidence intervals using Bootstrap. A simulation study is conducted to investigate the finite sample behavior of the proposed methods and to compare their performance with a competitor. Globally, we observed better finite sample performances for the proposed estimators. Finally, we illustrate the methods using two data sets one from a hypobaric decompression sickness study and the other from an oral health study. The proposed methods are implemented in the R package cenROC .},
  archive      = {J_BIMJ},
  author       = {Kassu Mehari Beyene and Anouar El Ghouch},
  doi          = {10.1002/bimj.202000382},
  journal      = {Biometrical Journal},
  month        = {8},
  number       = {6},
  pages        = {1056-1074},
  shortjournal = {Bio. J.},
  title        = {Time-dependent ROC curve estimation for interval-censored data},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semiparametric empirical likelihood inference for abundance
from one-inflated capture–recapture data. <em>BIMJ</em>, <em>64</em>(6),
1040–1055. (<a href="https://doi.org/10.1002/bimj.202100231">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abundance estimation from capture–recapture data is of great importance in many disciplines. Analysis of capture–recapture data is often complicated by the existence of one-inflation and heterogeneity problems. Simultaneously taking these issues into account, existing abundance estimation methods are usually constructed on the basis of conditional likelihood under one-inflated zero-truncated count models. However, the resulting Horvitz–Thompson-type estimators may be unstable, and the resulting Wald-type confidence intervals may exhibit severe undercoverage. In this paper, we propose a semiparametric empirical likelihood (EL) approach to abundance estimation under one-inflated binomial and Poisson regression models. To facilitate the computation of the EL method, we develop an expectation-maximization algorithm. We also propose a new score test for the existence of one-inflation and prove its asymptotic normality. Our simulation studies indicate that compared with existing estimators, the proposed score test is more powerful and the maximum EL estimator has a smaller mean square error. The advantages of our approaches are further demonstrated by analyses of prinia data from Hong Kong and drug user data from Bangkok.},
  archive      = {J_BIMJ},
  author       = {Yang Liu and Pengfei Li and Yukun Liu and Riquan Zhang},
  doi          = {10.1002/bimj.202100231},
  journal      = {Biometrical Journal},
  month        = {8},
  number       = {6},
  pages        = {1040-1055},
  shortjournal = {Bio. J.},
  title        = {Semiparametric empirical likelihood inference for abundance from one-inflated capture–recapture data},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Construction of joint confidence spaces for the optimal true
class fraction triplet in the ROC space using alternative biomarker
cutoffs. <em>BIMJ</em>, <em>64</em>(6), 1023–1039. (<a
href="https://doi.org/10.1002/bimj.202100132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hepatocellular carcinoma (HCC) is the most common primary cancer of the liver. Finding new biomarkers for its early detection is of high clinical importance. As with many other diseases, cancer has a progressive nature. In cancer biomarker studies, it is often the case that the true disease status of the recruited individuals exhibits more than two classes. The receiver operating characteristic (ROC) surface is a well-known statistical tool for assessing the biomarkers&#39; discriminatory ability in trichotomous settings. The volume under the ROC surface (VUS) is an overall measure of the discriminatory ability of a marker. In practice, clinicians are often in need of cutoffs for decision-making purposes. A popular approach for computing such cutoffs is the Youden index and its recent three-class generalization. A drawback of such a method is that it treats the data in a pairwise fashion rather than consider all the data simultaneously. The use of the minimized Euclidean distance from the perfection corner to the ROC surface (also known as closest to perfection method) is an alternative to the Youden index that may be preferable in some settings. When such a method is employed, there is a need for inferences around the resulting true class rates/fractions that correspond to the optimal operating point. In this paper, we provide an inferential framework for the derivation of marginal confidence intervals (CIs) and joint confidence spaces (CSs) around the corresponding true class fractions, when dealing with trichotomous settings. We explore parametric and nonparametric approaches for the construction of such CIs and CSs. We evaluate our approaches through extensive simulations and apply them to a real data set that refers to HCC patients.},
  archive      = {J_BIMJ},
  author       = {Peng Shi and Leonidas E. Bantis},
  doi          = {10.1002/bimj.202100132},
  journal      = {Biometrical Journal},
  month        = {8},
  number       = {6},
  pages        = {1023-1039},
  shortjournal = {Bio. J.},
  title        = {Construction of joint confidence spaces for the optimal true class fraction triplet in the ROC space using alternative biomarker cutoffs},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A two-way additive model with unknown group-specific
interactions applied to gene expression data. <em>BIMJ</em>,
<em>64</em>(6), 1007–1022. (<a
href="https://doi.org/10.1002/bimj.202100282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a two-way additive model with group-specific interactions, where the group information is unknown. We treat the group membership as latent information and propose an EM algorithm for estimation. With a single observation matrix and under the situation of diverging row and column numbers, we rigorously establish the estimation consistency and asymptotic normality of our estimator. Extensive simulation studies are conducted to demonstrate the finite sample performance. We apply the model to the triple negative breast cancer (TNBC) gene expression data and provide a new way to classify patients into different subtypes. Our analysis detects the potential genes that may be associated with TNBC.},
  archive      = {J_BIMJ},
  author       = {Tianqi Zheng and Jianhua Guo and Yanyuan Ma},
  doi          = {10.1002/bimj.202100282},
  journal      = {Biometrical Journal},
  month        = {8},
  number       = {6},
  pages        = {1007-1022},
  shortjournal = {Bio. J.},
  title        = {A two-way additive model with unknown group-specific interactions applied to gene expression data},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimization of adaptive designs with respect to a
performance score. <em>BIMJ</em>, <em>64</em>(6), 989–1006. (<a
href="https://doi.org/10.1002/bimj.202100166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive designs are an increasingly popular method for the adaptation of design aspects in clinical trials, such as the sample size. Scoring different adaptive designs helps to make an appropriate choice among the numerous existing adaptive design methods. Several scores have been proposed to evaluate adaptive designs. Moreover, it is possible to determine optimal two-stage adaptive designs with respect to a customized objective score by solving a constrained optimization problem. In this paper, we use the conditional performance score by Herrmann et al. (2020) as the optimization criterion to derive optimal adaptive two-stage designs. We investigate variations of the original performance score, for example, by assigning different weights to the score components and by incorporating prior assumptions on the effect size. We further investigate a setting where the optimization framework is extended by a global power constraint, and additional optimization of the critical value function next to the stage-two sample size is performed. Those evaluations with respect to the sample size curves and the resulting design&#39;s performance can contribute to facilitate the score&#39;s usage in practice.},
  archive      = {J_BIMJ},
  author       = {Carolin Herrmann and Meinhard Kieser and Geraldine Rauch and Maximilian Pilz},
  doi          = {10.1002/bimj.202100166},
  journal      = {Biometrical Journal},
  month        = {8},
  number       = {6},
  pages        = {989-1006},
  shortjournal = {Bio. J.},
  title        = {Optimization of adaptive designs with respect to a performance score},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022f). Contents: Biometrical journal 6’22. <em>BIMJ</em>,
<em>64</em>(6), 988. (<a
href="https://doi.org/10.1002/bimj.202270064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIMJ},
  doi          = {10.1002/bimj.202270064},
  journal      = {Biometrical Journal},
  month        = {8},
  number       = {6},
  pages        = {988},
  shortjournal = {Bio. J.},
  title        = {Contents: Biometrical journal 6&#39;22},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022e). Cover picture: Biometrical journal 5’22. <em>BIMJ</em>,
<em>64</em>(5), NA. (<a
href="https://doi.org/10.1002/bimj.202270051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIMJ},
  doi          = {10.1002/bimj.202270051},
  journal      = {Biometrical Journal},
  month        = {6},
  number       = {5},
  pages        = {NA},
  shortjournal = {Bio. J.},
  title        = {Cover picture: Biometrical journal 5&#39;22},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Using independent cross-sectional survey data to predict
post-migration health trajectories among refugees by estimating
transition probabilities and their variances. <em>BIMJ</em>,
<em>64</em>(5), 964–983. (<a
href="https://doi.org/10.1002/bimj.202100045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Health research is often concerned with the transition of health conditions and their relation with given exposures, therefore requiring longitudinal data. However, such data is not always available and resource-intensive to collect. Our aim is to use a pseudo-panel of independent cross-sectional data (e.g., data of T 0 $T_0$ and T 1 $T_1$ ) to extrapolate and approximate longitudinal health trajectories ( T 0 $T_0$ – T 1 $T_1$ ). Methods will be illustrated by examples of studying contextual effects on health among refugees by calculating transition probabilities with associated variances. The data consist of two cross-sectional health surveys among randomly selected refugee samples in reception ( T 0 $T_0$ ) and accommodation centers ( T 1 $T_1$ ) located in Germany&#39;s third-largest federal state. Self-reported measures of physical and mental health, health-related quality of life, health care access, and unmet medical needs of 560 refugees were collected. Missing data were imputed by multiple imputation. For each imputed data set, transition probabilities were calculated based on (i) probabilistic discrete event systems with Moore-Penrose generalized inverse matrix method (PDES-MP) and (ii) propensity score matching (PSM). By application of sampling approaches, exploiting the fact that status membership is multinomially distributed, results of both methods were pooled by Rubin&#39;s Rule, accounting for within and between-imputation variance. Most of the analyzed estimates of the transition probabilities and their variances are comparable between both methods. However, it seems that they handle sparse cells differently: either assigning an average value for the transition probability for all states with high certainty (i) or assigning a more extreme value for the transition probability with large variance estimate (ii).},
  archive      = {J_BIMJ},
  author       = {Stella Erdmann and Louise Biddle and Meinhard Kieser and Kayvan Bozorgmehr},
  doi          = {10.1002/bimj.202100045},
  journal      = {Biometrical Journal},
  month        = {6},
  number       = {5},
  pages        = {964-983},
  shortjournal = {Bio. J.},
  title        = {Using independent cross-sectional survey data to predict post-migration health trajectories among refugees by estimating transition probabilities and their variances},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving adaptive seamless designs through bayesian
optimization. <em>BIMJ</em>, <em>64</em>(5), 948–963. (<a
href="https://doi.org/10.1002/bimj.202000389">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose to use Bayesian optimization (BO) to improve the efficiency of the design selection process in clinical trials. BO is a method to optimize expensive black-box functions, by using a regression as a surrogate to guide the search. In clinical trials, planning test procedures and sample sizes is a crucial task. A common goal is to maximize the test power, given a set of treatments, corresponding effect sizes, and a total number of samples. From a wide range of possible designs, we aim to select the best one in a short time to allow quick decisions. The standard approach to simulate the power for each single design can become too time consuming. When the number of possible designs becomes very large, either large computational resources are required or an exhaustive exploration of all possible designs takes too long. Here, we propose to use BO to quickly find a clinical trial design with high power from a large number of candidate designs. We demonstrate the effectiveness of our approach by optimizing the power of adaptive seamless designs for different sets of treatment effect sizes. Comparing BO with an exhaustive evaluation of all candidate designs shows that BO finds competitive designs in a fraction of the time.},
  archive      = {J_BIMJ},
  author       = {Jakob Richter and Tim Friede and Jörg Rahnenführer},
  doi          = {10.1002/bimj.202000389},
  journal      = {Biometrical Journal},
  month        = {6},
  number       = {5},
  pages        = {948-963},
  shortjournal = {Bio. J.},
  title        = {Improving adaptive seamless designs through bayesian optimization},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Monotonicity conditions for avoiding counterintuitive
decisions in basket trials. <em>BIMJ</em>, <em>64</em>(5), 934–947. (<a
href="https://doi.org/10.1002/bimj.202100287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a basket trial, a new treatment is tested in different subgroups, called the baskets. In oncology, the baskets usually comprise patients with different primary tumor sites but a common biomarker. Most basket trials are uncontrolled phase II trials and investigate a binary endpoint such as tumor response. To combine the data of baskets that show a similar response to the treatment, many basket trial designs use Bayesian borrowing methods. This increases the power compared to a basketwise analysis. However, it can lead to posterior probabilities that are not monotonically increasing in the number of responses. We show that, as a consequence, two types of counterintuitive decisions can arise—one that occurs within a single trial and one that occurs when the results are compared between different trials. We propose two monotonicity conditions for the inference in basket trials. Using a design recently proposed by Fujikawa and colleagues, we investigate the case of a single-stage basket trial with equal sample sizes in all baskets and show that, as the number of baskets increases, these conditions are violated for a wide range of different borrowing strengths. We show that in the investigated scenarios pruning baskets can help to ensure that the monotonicity conditions hold and investigate how this affects type I error rate and power.},
  archive      = {J_BIMJ},
  author       = {Lukas Baumann and Johannes Krisam and Meinhard Kieser},
  doi          = {10.1002/bimj.202100287},
  journal      = {Biometrical Journal},
  month        = {6},
  number       = {5},
  pages        = {934-947},
  shortjournal = {Bio. J.},
  title        = {Monotonicity conditions for avoiding counterintuitive decisions in basket trials},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian analysis of one-inflated models for elusive
population size estimation. <em>BIMJ</em>, <em>64</em>(5), 912–933. (<a
href="https://doi.org/10.1002/bimj.202100187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The identification and treatment of “one-inflation” in estimating the size of an elusive population has received increasing attention in capture–recapture literature in recent years. The phenomenon occurs when the number of units captured exactly once clearly exceeds the expectation under a baseline count distribution. Ignoring one-inflation has serious consequences for estimation of the population size, which can be drastically overestimated. In this paper we propose a Bayesian approach for Poisson, geometric, and negative binomial one-inflated count distributions. Posterior inference for population size will be obtained applying a Gibbs sampler approach. We also provide a Bayesian approach to model selection. We illustrate the proposed methodology with simulated and real data and propose a new application in official statistics to estimate the number of people implicated in the exploitation of prostitution in Italy.},
  archive      = {J_BIMJ},
  author       = {Tiziana Tuoto and Davide Di Cecco and Andrea Tancredi},
  doi          = {10.1002/bimj.202100187},
  journal      = {Biometrical Journal},
  month        = {6},
  number       = {5},
  pages        = {912-933},
  shortjournal = {Bio. J.},
  title        = {Bayesian analysis of one-inflated models for elusive population size estimation},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semiparametric marginal methods for clustered data adjusting
for informative cluster size with nonignorable zeros. <em>BIMJ</em>,
<em>64</em>(5), 898–911. (<a
href="https://doi.org/10.1002/bimj.202100161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustered or longitudinal data are commonly encountered in clinical trials and observational studies. This type of data could be collected through a real-time monitoring scheme associated with some specific event, such as disease recurrence, hospitalization, or emergency room visit. In these contexts, the cluster size could be informative because of its potential correlation with disease status, since more frequency of observations may indicate a worsening health condition. However, for some clusters/subjects, there are no measures or relevant medical records. Under such circumstances, these clusters/subjects may have a considerably lower risk of an event occurrence or may not be susceptible to such events at all, indicating a nonignorable zero cluster size. There is a substantial body of literature using observations from those clusters with a nonzero informative cluster size only, but few works discuss informative nonignorable zero-sized clusters. To utilize the information from both event-free and event-occurring participants, we propose a weighted within-cluster-resampling (WWCR) method and its asymptotically equivalent method, dual-weighted generalized estimating equations (WWGEE) by adopting the inverse probability weighting technique. The asymptotic properties are rigorously presented theoretically. Extensive simulations and an illustrative example of the Assessment, Serial Evaluation, and Subsequent Sequelae of Acute Kidney Injury (ASSESS-AKI) study are performed to analyze the finite-sample behavior of our methods and to show their advantageous performance compared to the existing approaches.},
  archive      = {J_BIMJ},
  author       = {Biyi Shen and Chixiang Chen and Vernon M. Chinchilli and Nasrollah Ghahramani and Lijun Zhang and Ming Wang},
  doi          = {10.1002/bimj.202100161},
  journal      = {Biometrical Journal},
  month        = {6},
  number       = {5},
  pages        = {898-911},
  shortjournal = {Bio. J.},
  title        = {Semiparametric marginal methods for clustered data adjusting for informative cluster size with nonignorable zeros},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Model selection characteristics when using MCP-mod for
dose–response gene expression data. <em>BIMJ</em>, <em>64</em>(5),
883–897. (<a href="https://doi.org/10.1002/bimj.202000250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We extend the scope of application for MCP-Mod (Multiple Comparison Procedure and Modeling) to in vitro gene expression data and assess its characteristics regarding model selection for concentration gene expression curves. Precisely, we apply MCP-Mod on single genes of a high-dimensional gene expression data set, where human embryonic stem cells were exposed to eight concentration levels of the compound valproic acid (VPA). As candidate models we consider the sigmoid (four-parameter log-logistic), linear, quadratic, exponential, and beta model. Through simulations we investigate the impact of omitting one or more models from the candidate model set to uncover possibly superfluous models and to evaluate the precision and recall rates of selected models. Each model is selected according to Akaike information criterion (AIC) for a considerable number of genes. For less noisy cases the popular sigmoid model is frequently selected. For more noisy data, often simpler models like the linear model are selected, but mostly without relevant performance advantage compared to the second best model. Also, the commonly used standard model has an unexpected low performance.},
  archive      = {J_BIMJ},
  author       = {Julia C. Duda and Franziska Kappenberg and Jörg Rahnenführer},
  doi          = {10.1002/bimj.202000250},
  journal      = {Biometrical Journal},
  month        = {6},
  number       = {5},
  pages        = {883-897},
  shortjournal = {Bio. J.},
  title        = {Model selection characteristics when using MCP-mod for dose–response gene expression data},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Missing data imputation in clinical trials using recurrent
neural network facilitated by clustering and oversampling.
<em>BIMJ</em>, <em>64</em>(5), 863–882. (<a
href="https://doi.org/10.1002/bimj.202000393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In clinical practice, the composition of missing data may be complex, for example, a mixture of missing at random (MAR) and missing not at random (MNAR) assumptions. Many methods under the assumption of MAR are available. Under the assumption of MNAR, likelihood-based methods require specification of the joint distribution of the data, and the missingness mechanism has been introduced as sensitivity analysis. These classic models heavily rely on the underlying assumption, and, in many realistic scenarios, they can produce unreliable estimates. In this paper, we develop a machine learning based missing data prediction framework with the aim of handling more realistic missing data scenarios. We use an imbalanced learning technique (i.e., oversampling of minority class) to handle the MNAR data. To implement oversampling in longitudinal continuous variable, we first perform clustering via -mean trajectories. And use the recurrent neural network (RNN) to model the longitudinal data. Further, we apply bootstrap aggregating to improve the accuracy of prediction and also to consider the uncertainty of a single prediction. We evaluate the proposed method using simulated data. The prediction result is evaluated at the individual patient level and the overall population level. We demonstrate the powerful predictive capability of RNN for longitudinal data and its flexibility for nonlinear modeling. Overall, the proposed method provides an accurate individual prediction for both MAR and MNAR data and reduce the bias of missing data in treatment effect estimation when compared to standard methods and classic models. Finally, we implement the proposed method in a real dataset from an antidepressant clinical trial. In summary, this paper offers an opportunity to encourage the integration of machine learning strategies for handling of missing data in the analysis of randomized clinical trials.},
  archive      = {J_BIMJ},
  author       = {Halimu N. Haliduola and Frank Bretz and Ulrich Mansmann},
  doi          = {10.1002/bimj.202000393},
  journal      = {Biometrical Journal},
  month        = {6},
  number       = {5},
  pages        = {863-882},
  shortjournal = {Bio. J.},
  title        = {Missing data imputation in clinical trials using recurrent neural network facilitated by clustering and oversampling},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Correcting conditional mean imputation for censored
covariates and improving usability. <em>BIMJ</em>, <em>64</em>(5),
858–862. (<a href="https://doi.org/10.1002/bimj.202100250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Missing data are often overcome using imputation, which leverages the entire dataset to replace missing values with informed placeholders. This method can be modified for censored data by also incorporating partial information from censored values. One such modification proposed by Atem et al. (2017, 2019a, 2019b) is conditional mean imputation where censored covariates are replaced by their conditional means given other fully observed information. These methods are robust to additional parametric assumptions on the censored covariate and utilize all available data, which is appealing. However, in implementing these methods, we discovered that these three articles provide nonequivalent formulas and, in fact, none is the correct formula for the conditional mean. Herein, we derive the correct form of the conditional mean and discuss the bias incurred when using the incorrect formulas. Furthermore, we note that even the correct formula can perform poorly for log hazard ratios far from . We also provide user-friendly R software, the imputeCensoRd package, to enable future researchers to tackle censored covariates correctly.},
  archive      = {J_BIMJ},
  author       = {Sarah C. Lotspeich and Kyle F. Grosser and Tanya P. Garcia},
  doi          = {10.1002/bimj.202100250},
  journal      = {Biometrical Journal},
  month        = {6},
  number       = {5},
  pages        = {858-862},
  shortjournal = {Bio. J.},
  title        = {Correcting conditional mean imputation for censored covariates and improving usability},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Two-dimensional p-spline smoothing for spatial analysis of
plant breeding trials. <em>BIMJ</em>, <em>64</em>(5), 835–857. (<a
href="https://doi.org/10.1002/bimj.202100212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large agricultural field trials may display irregular spatial trends that cannot be fully captured by a purely randomization-based analysis. For this reason, paralleling the development of analysis-of-variance procedures for randomized field trials, there is a long history of spatial modeling for field trials, starting with the early work of Papadakis on nearest neighbor analysis, which can be cast in terms of first or second differences among neighboring plot values. This kind of spatial modeling is amenable to a natural extension using splines, as has been demonstrated in recent publications in the field. Here, we consider the P-spline framework, focusing on model options that are easy to implement in linear mixed model packages. Two examples serve to illustrate and evaluate the methods. A key conclusion is that first differences are rather competitive with second differences. A further key observation is that second differences require special attention regarding the representation of the null space of the smooth terms for spatial interaction, and that an unstructured variance–covariance structure is required to ensure invariance to translation and rotation of eigenvectors associated with that null space. We develop a strategy that permits fitting this model with ease, but the approach is more demanding than that needed for fitting models using first differences. Hence, even though in other areas, second differences are very commonly used in the application of P-splines, our conclusion is that with field trials, first differences have advantages for routine use.},
  archive      = {J_BIMJ},
  author       = {Hans-Peter Piepho and Martin P. Boer and Emlyn R. Williams},
  doi          = {10.1002/bimj.202100212},
  journal      = {Biometrical Journal},
  month        = {6},
  number       = {5},
  pages        = {835-857},
  shortjournal = {Bio. J.},
  title        = {Two-dimensional P-spline smoothing for spatial analysis of plant breeding trials},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022e). Contents: Biometrical journal 5’22. <em>BIMJ</em>,
<em>64</em>(5), 833–834. (<a
href="https://doi.org/10.1002/bimj.202270054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIMJ},
  doi          = {10.1002/bimj.202270054},
  journal      = {Biometrical Journal},
  month        = {6},
  number       = {5},
  pages        = {833-834},
  shortjournal = {Bio. J.},
  title        = {Contents: Biometrical journal 5&#39;22},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022d). Cover picture: Biometrical journal 4’22. <em>BIMJ</em>,
<em>64</em>(4), NA. (<a
href="https://doi.org/10.1002/bimj.202270041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIMJ},
  doi          = {10.1002/bimj.202270041},
  journal      = {Biometrical Journal},
  month        = {4},
  number       = {4},
  pages        = {NA},
  shortjournal = {Bio. J.},
  title        = {Cover picture: Biometrical journal 4&#39;22},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). List of reviewers for 2021. <em>BIMJ</em>, <em>64</em>(4),
824–827. (<a href="https://doi.org/10.1002/bimj.202270045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIMJ},
  doi          = {10.1002/bimj.202270045},
  journal      = {Biometrical Journal},
  month        = {4},
  number       = {4},
  pages        = {824-827},
  shortjournal = {Bio. J.},
  title        = {List of reviewers for 2021},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine learning for knowledge discovery with r:
Methodologies for modeling, inference and prediction, kao-tai tsai, boca
raton, FL: Chapman and hall/CRC press. 2021. 244 pages. Hardback price
GBP 74.99. ISBN 9781032065366. <em>BIMJ</em>, <em>64</em>(4), 822–823.
(<a href="https://doi.org/10.1002/bimj.202200007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIMJ},
  author       = {Roman Hornung and Anne-Laure Boulesteix},
  doi          = {10.1002/bimj.202200007},
  journal      = {Biometrical Journal},
  month        = {4},
  number       = {4},
  pages        = {822-823},
  shortjournal = {Bio. J.},
  title        = {Machine learning for knowledge discovery with r: methodologies for modeling, inference and prediction, kao-tai tsai, boca raton, FL: chapman and Hall/CRC press. 2021. 244 pages. hardback price GBP 74.99. ISBN 9781032065366.},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Statistical methods for global health and epidemiology:
Principles, methods and applications, edited by xinguang chen and (din)
ding-geng chen, cham: Springer nature switzerland, 2020. ISBN
978-3-030-35259-2. Https://doi.org/10.1007/978-3-030-35260-8.
<em>BIMJ</em>, <em>64</em>(4), 820–821. (<a
href="https://doi.org/10.1002/bimj.202200006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIMJ},
  author       = {Henry Mwambi},
  doi          = {10.1002/bimj.202200006},
  journal      = {Biometrical Journal},
  month        = {4},
  number       = {4},
  pages        = {820-821},
  shortjournal = {Bio. J.},
  title        = {Statistical methods for global health and epidemiology: principles, methods and applications, edited by xinguang chen and (Din) ding-geng chen, cham: springer nature switzerland, 2020. ISBN 978-3-030-35259-2. https://doi.org/10.1007/978-3-030-35260-8.},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Handbook of statistical methods for randomized controlled
trials. KyungMann kim, frank bretz, ying kuen cheung, lisa v. Hampson
boca raton, chapman &amp; hall/CRC press (2021). 654 pages. ISBN:
978-1-4987-1462-4. List price: £ 190. <em>BIMJ</em>, <em>64</em>(4),
818–819. (<a href="https://doi.org/10.1002/bimj.202200005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIMJ},
  author       = {Andreas Ziegler},
  doi          = {10.1002/bimj.202200005},
  journal      = {Biometrical Journal},
  month        = {4},
  number       = {4},
  pages        = {818-819},
  shortjournal = {Bio. J.},
  title        = {Handbook of statistical methods for randomized controlled trials. KyungMann kim, frank bretz, ying kuen cheung, lisa v. hampson boca raton, chapman &amp; Hall/CRC press (2021). 654 pages. ISBN: 978-1-4987-1462-4. list price: £ 190},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimal dynamic treatment regime estimation using
information extraction from unstructured clinical text. <em>BIMJ</em>,
<em>64</em>(4), 805–817. (<a
href="https://doi.org/10.1002/bimj.202100077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The wide-scale adoption of electronic health records (EHRs) provides extensive information to support precision medicine and personalized health care. In addition to structured EHRs, we leverage free-text clinical information extraction (IE) techniques to estimate optimal dynamic treatment regimes (DTRs), a sequence of decision rules that dictate how to individualize treatments to patients based on treatment and covariate history. The proposed IE of patient characteristics closely resembles “The clinical Text Analysis and Knowledge Extraction System” and employs named entity recognition, boundary detection, and negation annotation. It also utilizes regular expressions to extract numerical information. Combining the proposed IE with optimal DTR estimation, we extract derived patient characteristics and use tree-based reinforcement learning (T-RL) to estimate multistage optimal DTRs. IE significantly improved the estimation in counterfactual outcome models compared to using structured EHR data alone, which often include incomplete data, data entry errors, and other potentially unobserved risk factors. Moreover, including IE in optimal DTR estimation provides larger study cohorts and a broader pool of candidate tailoring variables. We demonstrate the performance of our proposed method via simulations and an application using clinical records to guide blood pressure control treatments among critically ill patients with severe acute hypertension. This joint estimation approach improves the accuracy of identifying the optimal treatment sequence by 14–24% compared to traditional inference without using IE, based on our simulations over various scenarios. In the blood pressure control application, we successfully extracted significant blood pressure predictors that are unobserved or partially missing from structured EHR.},
  archive      = {J_BIMJ},
  author       = {Nina Zhou and Robert D. Brook and Ivo D. Dinov and Lu Wang},
  doi          = {10.1002/bimj.202100077},
  journal      = {Biometrical Journal},
  month        = {4},
  number       = {4},
  pages        = {805-817},
  shortjournal = {Bio. J.},
  title        = {Optimal dynamic treatment regime estimation using information extraction from unstructured clinical text},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sample size determination for comparing accuracies between
two diagnostic tests under a paired design. <em>BIMJ</em>,
<em>64</em>(4), 771–804. (<a
href="https://doi.org/10.1002/bimj.202000036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the progressive technology, many medical researches are aimed to develop diagnostic tests that can detect diseases faster and accurately. The assessment of the accuracy of the diagnostic test for classifying two groups is through the receiver operating characteristic (ROC) curve and the area under the ROC curve (AUC). When a paired design is considered, the sample size determination requires the information about two AUC estimates and the corresponding variance and covariance of two AUC estimators. This paper derives the nonparametric estimators of the variance and covariance of two AUC estimators. The result is used to derive the sample size formula when the paired sample is planned. Since most of the results do not have a closed form, numerical results are provided under various scenarios.},
  archive      = {J_BIMJ},
  author       = {Yi-Ting Hwang and Nan-Cheng Su},
  doi          = {10.1002/bimj.202000036},
  journal      = {Biometrical Journal},
  month        = {4},
  number       = {4},
  pages        = {771-804},
  shortjournal = {Bio. J.},
  title        = {Sample size determination for comparing accuracies between two diagnostic tests under a paired design},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A flexible bayesian nonconfounding spatial model for
analysis of dispersed count data. <em>BIMJ</em>, <em>64</em>(4),
758–770. (<a href="https://doi.org/10.1002/bimj.202100157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In employing spatial regression models for counts, we usually meet two issues. First, the possible inherent collinearity between covariates and the spatial effect could lead to misleading inferences. Second, real count data usually reveal over- or under-dispersion where the classical Poisson model is not appropriate to use. We propose a flexible Bayesian hierarchical modeling approach by joining nonconfounding spatial methodology and a newly reconsidered dispersed count modeling from the renewal theory to control the issues. Specifically, we extend the methodology for analyzing spatial count data based on the gamma distribution assumption for waiting times. The model can be formulated as a latent Gaussian model, and consequently, we can carry out the fast computation by using the integrated nested Laplace approximation method. We examine different popular approaches for handling spatial confounding and compare their performances in the presence of dispersion. Two real applications from a crime study against women in India as well as stomach cancer incidences in Slovenia motivate the suggested methods. We also perform a simulation study to understand the proposed approach&#39;s merits better. Supplementary Materials for this article are available.},
  archive      = {J_BIMJ},
  author       = {Mahsa Nadifar and Hossein Baghishani and Afshin Fallah},
  doi          = {10.1002/bimj.202100157},
  journal      = {Biometrical Journal},
  month        = {4},
  number       = {4},
  pages        = {758-770},
  shortjournal = {Bio. J.},
  title        = {A flexible bayesian nonconfounding spatial model for analysis of dispersed count data},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Disease mapping method comparing the spatial distribution of
a disease with a control disease. <em>BIMJ</em>, <em>64</em>(4),
733–757. (<a href="https://doi.org/10.1002/bimj.202000246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small-area methods are being used in spatial epidemiology to understand the effect of location on health and detect areas where the risk of a disease is significantly elevated. Disease mapping models relate the observed number of cases to an expected number of cases per area. Expected numbers are often calculated by internal standardization, which requires both accurate population numbers and disease rates per gender and/or age group. However, confidentiality issues or the absence of high-quality information about the characteristics of a population-at-risk can hamper those calculations. Based on methods in point process analysis for situations without accurate population data, we propose the use of a case-control approach in the context of lattice data, in which an unrelated, spatially unstructured disease is used as a control disease. We correct for the uncertainty in the estimation of the expected values, which arises by using the control-disease&#39;s observed number of cases as a representation of a fraction of the total population. We apply our methods to a Belgian study of mesothelioma risk, where pancreatic cancer serves as the control disease. The analysis results are in close agreement with those coming from traditional disease mapping models based on internally standardized expected counts. The simulation study results confirm our findings for different spatial structures. We show that the proposed method can adequately address the problem of inaccurate or unavailable population data in disease mapping analysis.},
  archive      = {J_BIMJ},
  author       = {Oana Petrof and Thomas Neyens and Maren Vranckx and Valerie Nuyts and Benoit Nemery and Kristiaan Nackaerts and Christel Faes},
  doi          = {10.1002/bimj.202000246},
  journal      = {Biometrical Journal},
  month        = {4},
  number       = {4},
  pages        = {733-757},
  shortjournal = {Bio. J.},
  title        = {Disease mapping method comparing the spatial distribution of a disease with a control disease},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dirichlet composition distribution for compositional data
with zero components: An application to fluorescence in situ
hybridization (FISH) detection of chromosome. <em>BIMJ</em>,
<em>64</em>(4), 714–732. (<a
href="https://doi.org/10.1002/bimj.202000334">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zeros in compositional data are very common and can be classified into rounded and essential zeros. The rounded zero refers to a small proportion or below detection limit value, while the essential zero refers to the complete absence of the component in the composition. In this article, we propose a new framework for analyzing compositional data with zero entries by introducing a stochastic representation. In particular, a new distribution, namely the Dirichlet composition distribution, is developed to accommodate the possible essential-zero feature in compositional data. We derive its distributional properties (e.g., its moments). The calculation of maximum likelihood estimates via the Expectation-Maximization (EM) algorithm will be proposed. The regression model based on the new Dirichlet composition distribution will be considered. Simulation studies are conducted to evaluate the performance of the proposed methodologies. Finally, our method is employed to analyze a dataset of fluorescence in situ hybridization (FISH) for chromosome detection.},
  archive      = {J_BIMJ},
  author       = {Man-Lai Tang and Qin Wu and Sheng Yang and Guo-Liang Tian},
  doi          = {10.1002/bimj.202000334},
  journal      = {Biometrical Journal},
  month        = {4},
  number       = {4},
  pages        = {714-732},
  shortjournal = {Bio. J.},
  title        = {Dirichlet composition distribution for compositional data with zero components: An application to fluorescence in situ hybridization (FISH) detection of chromosome},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Restricted survival benefit with right-censored data.
<em>BIMJ</em>, <em>64</em>(4), 696–713. (<a
href="https://doi.org/10.1002/bimj.202000392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hazard ratio is widely used to quantify treatment effects. However, it may be difficult to interpret for patients and practitioners, especially when the hazard ratio is not constant over time. Alternative measures of the treatment effects have been proposed such as the difference of the restricted mean survival times, the difference in survival proportions at some fixed follow-up time, or the net chance of a longer survival. In this paper, we propose the restricted survival benefit (RSB), a quantity that can incorporate multiple useful measurements of treatment effects. Hence, it provides a framework for a comprehensive assessment of the treatment effects. We provide estimation and inference procedures for the RSB that accommodate censored survival outcomes, using methods of the inverse-probability-censoring-weighted -statistic and the jackknife empirical likelihood. We conduct extensive simulation studies to examine the numerical performance of the proposed method, and we analyze data from a randomized Phase III clinical trial (SWOG S0777) using the proposed method.},
  archive      = {J_BIMJ},
  author       = {Shixiao Zhang and Michael L. LeBlanc and Ying-Qi Zhao},
  doi          = {10.1002/bimj.202000392},
  journal      = {Biometrical Journal},
  month        = {4},
  number       = {4},
  pages        = {696-713},
  shortjournal = {Bio. J.},
  title        = {Restricted survival benefit with right-censored data},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Joint control of consensus and evidence in bayesian design
of clinical trials. <em>BIMJ</em>, <em>64</em>(4), 681–695. (<a
href="https://doi.org/10.1002/bimj.202100035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Bayesian inference, prior distributions formalize preexperimental information and uncertainty on model parameters. Sometimes different sources of knowledge are available, possibly leading to divergent posterior distributions and inferences. Research has been recently devoted to the development of sample size criteria that guarantee agreement of posterior information in terms of credible intervals when multiple priors are available. In these articles, the goals of reaching consensus and evidence are typically kept separated. Adopting a Bayesian performance-based approach, the present article proposes new sample size criteria for superiority trials that jointly control the achievement of both minimal evidence and consensus , measured by appropriate functions of the posterior distributions. We develop both an average criterion and a more stringent criterion that accounts for the entire predictive distributions of the selected measures of minimal evidence and consensus. Methods are developed and illustrated via simulation for trials involving binary outcomes. A real clinical trial example on Covid-19 vaccine data is presented.},
  archive      = {J_BIMJ},
  author       = {Fulvio De Santis and Stefania Gubbiotti},
  doi          = {10.1002/bimj.202100035},
  journal      = {Biometrical Journal},
  month        = {4},
  number       = {4},
  pages        = {681-695},
  shortjournal = {Bio. J.},
  title        = {Joint control of consensus and evidence in bayesian design of clinical trials},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Power considerations for generalized estimating equations
analyses of four-level cluster randomized trials. <em>BIMJ</em>,
<em>64</em>(4), 663–680. (<a
href="https://doi.org/10.1002/bimj.202100081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we develop methods for sample size and power calculations in four-level intervention studies when intervention assignment is carried out at any level, with a particular focus on cluster randomized trials (CRTs). CRTs involving four levels are becoming popular in healthcare research, where the effects are measured, for example, from evaluations (level 1) within participants (level 2) in divisions (level 3) that are nested in clusters (level 4). In such multilevel CRTs, we consider three types of intraclass correlations between different evaluations to account for such clustering: that of the same participant, that of different participants from the same division, and that of different participants from different divisions in the same cluster. Assuming arbitrary link and variance functions, with the proposed correlation structure as the true correlation structure, closed-form sample size formulas for randomization carried out at any level (including individually randomized trials within a four-level clustered structure) are derived based on the generalized estimating equations approach using the model-based variance and using the sandwich variance with an independence working correlation matrix. We demonstrate that empirical power corresponds well with that predicted by the proposed method for as few as eight clusters, when data are analyzed using the matrix-adjusted estimating equations for the correlation parameters with a bias-corrected sandwich variance estimator, under both balanced and unbalanced designs.},
  archive      = {J_BIMJ},
  author       = {Xueqi Wang and Elizabeth L. Turner and John S. Preisser and Fan Li},
  doi          = {10.1002/bimj.202100081},
  journal      = {Biometrical Journal},
  month        = {4},
  number       = {4},
  pages        = {663-680},
  shortjournal = {Bio. J.},
  title        = {Power considerations for generalized estimating equations analyses of four-level cluster randomized trials},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022d). Contents: Biometrical journal 4’22. <em>BIMJ</em>,
<em>64</em>(4), 661–662. (<a
href="https://doi.org/10.1002/bimj.202270044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIMJ},
  doi          = {10.1002/bimj.202270044},
  journal      = {Biometrical Journal},
  month        = {4},
  number       = {4},
  pages        = {661-662},
  shortjournal = {Bio. J.},
  title        = {Contents: Biometrical journal 4&#39;22},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Cover picture: Biometrical journal 3’22. <em>BIMJ</em>,
<em>64</em>(3), NA. (<a
href="https://doi.org/10.1002/bimj.202270031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIMJ},
  doi          = {10.1002/bimj.202270031},
  journal      = {Biometrical Journal},
  month        = {3},
  number       = {3},
  pages        = {NA},
  shortjournal = {Bio. J.},
  title        = {Cover picture: Biometrical journal 3&#39;22},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modified score function for monotone likelihood in the
semiparametric mixture cure model. <em>BIMJ</em>, <em>64</em>(3),
635–654. (<a href="https://doi.org/10.1002/bimj.202000254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cure fraction models are intended to analyze lifetime data from populations where some individuals are immune to the event under study, and allow a joint estimation of the distribution related to the cured and susceptible subjects, as opposed to the usual approach ignoring the cure rate. In situations involving small sample sizes with many censored times, the detection of nonfinite coefficients may arise via maximum likelihood. This phenomenon is commonly known as monotone likelihood (ML), occurring in the Cox and logistic regression models when many categorical and unbalanced covariates are present. An existing solution to prevent the issue is based on the Firth correction, originally developed to reduce the estimation bias. The method ensures finite estimates by penalizing the likelihood function. In the context of mixture cure models, the ML issue is rarely discussed in the literature; therefore, this topic can be seen as the first contribution of our paper. The second major contribution, not well addressed elsewhere, is the study of the ML issue in cure mixture modeling under the flexibility of a semiparametric framework to handle the baseline hazard. We derive the modified score function based on the Firth approach and explore finite sample size properties of the estimators via a Monte Carlo scheme. The simulation results indicate that the performance of coefficients related to the binary covariates are strongly affected to the imbalance degree. A real illustration, in the melanoma dataset, is discussed using a relatively novel data set collected in a Brazilian university hospital.},
  archive      = {J_BIMJ},
  author       = {Frederico M. Almeida and Enrico A. Colosimo and Vinícius D. Mayrink},
  doi          = {10.1002/bimj.202000254},
  journal      = {Biometrical Journal},
  month        = {3},
  number       = {3},
  pages        = {635-654},
  shortjournal = {Bio. J.},
  title        = {Modified score function for monotone likelihood in the semiparametric mixture cure model},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detection of multiple change points in a weibull accelerated
failure time model using sequential testing. <em>BIMJ</em>,
<em>64</em>(3), 617–634. (<a
href="https://doi.org/10.1002/bimj.202000262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With improvements to cancer diagnoses and treatments, incidences and mortality rates have changed. However, the most commonly used analysis methods do not account for such distributional changes. In survival analysis, change point problems can concern a shift in a distribution for a set of time-ordered observations, potentially under censoring or truncation. We propose a sequential testing approach for detecting multiple change points in the Weibull accelerated failure time model, since this is sufficiently flexible to accommodate increasing, decreasing, or constant hazard rates and is also the only continuous distribution for which the accelerated failure time model can be reparameterized as a proportional hazards model. Our sequential testing procedure does not require the number of change points to be known; this information is instead inferred from the data. We conduct a simulation study to show that the method accurately detects change points and estimates the model. The numerical results along with real data applications demonstrate that our proposed method can detect change points in the hazard rate.},
  archive      = {J_BIMJ},
  author       = {Kristine Gierz and Kayoung Park},
  doi          = {10.1002/bimj.202000262},
  journal      = {Biometrical Journal},
  month        = {3},
  number       = {3},
  pages        = {617-634},
  shortjournal = {Bio. J.},
  title        = {Detection of multiple change points in a weibull accelerated failure time model using sequential testing},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Quantifying uncertainty in method of moments estimates of
the heterogeneity variance in random effects meta-analysis.
<em>BIMJ</em>, <em>64</em>(3), 598–616. (<a
href="https://doi.org/10.1002/bimj.202000222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The between-study variance or heterogeneity variance is an important parameter in random effects meta-analysis. This paper uses an M-estimation framework to introduce and discuss variance estimators for quantifying the uncertainty in estimates of the heterogeneity variance using the noniterative generalized method of moments estimator and some related method of moments estimators. An example is used to further illustrate the variance estimators, and simulation results are presented for assessing the empirical properties of the proposed variance estimators.},
  archive      = {J_BIMJ},
  author       = {Kurex Sidik and Jeffrey N. Jonkman},
  doi          = {10.1002/bimj.202000222},
  journal      = {Biometrical Journal},
  month        = {3},
  number       = {3},
  pages        = {598-616},
  shortjournal = {Bio. J.},
  title        = {Quantifying uncertainty in method of moments estimates of the heterogeneity variance in random effects meta-analysis},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Use of multivariate distance measures for high-dimensional
data in tests for difference, superiority, equivalence and
non-inferiority. <em>BIMJ</em>, <em>64</em>(3), 577–597. (<a
href="https://doi.org/10.1002/bimj.202000367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tests based on pairwise distance measures for multivariate sample vectors are common in ecological studies but are usually restricted to two-sided tests for differences. In this paper, we investigate extensions to tests for superiority, equivalence and non-inferiority.},
  archive      = {J_BIMJ},
  author       = {Siegfried Kropf and Kai Antweiler and Ekkehard Glimm},
  doi          = {10.1002/bimj.202000367},
  journal      = {Biometrical Journal},
  month        = {3},
  number       = {3},
  pages        = {577-597},
  shortjournal = {Bio. J.},
  title        = {Use of multivariate distance measures for high-dimensional data in tests for difference, superiority, equivalence and non-inferiority},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hypothesis testing in multivariate normal models with block
circular covariance structures. <em>BIMJ</em>, <em>64</em>(3), 557–576.
(<a href="https://doi.org/10.1002/bimj.202100023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we address the problem of simultaneous testing hypothesis about mean and covariance matrix for repeated measures data when both the mean vector and covariance matrix are patterned. In particular, tests about the mean vector under block circular and doubly exchangeable covariance structures have been considered. The null distributions are established for the corresponding likelihood ratio test statistics, and expressions for the exact or near-exact probability density and cumulative distribution functions are obtained. The application of the results is illustrated by both a simulation study and a real-life data example.},
  archive      = {J_BIMJ},
  author       = {Yuli Liang and Carlos A. Coelho and Tatjana von Rosen},
  doi          = {10.1002/bimj.202100023},
  journal      = {Biometrical Journal},
  month        = {3},
  number       = {3},
  pages        = {557-576},
  shortjournal = {Bio. J.},
  title        = {Hypothesis testing in multivariate normal models with block circular covariance structures},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimation in multivariate linear mixed models for
longitudinal data with multiple outputs: Application to PBCseq data
analysis. <em>BIMJ</em>, <em>64</em>(3), 539–556. (<a
href="https://doi.org/10.1002/bimj.202000015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many biomedical studies or clinical trials, we have data with more than one response variable on the same subject repeatedly measured over time. In analyzing such data, we adopt a multivariate linear mixed-effects longitudinal model. On the other hand, in longitudinal data, we often find features that do not impact modeling the response variable and are eliminated from the study. In this paper, we consider the problem of simultaneous variable selection and estimation in a multivariate t linear mixed-effects model (MtLMM) for analyzing longitudinally measured multioutcome data. This work&#39;s motivation comes from a cohort study of patients with primary biliary cirrhosis. The interest is eliminating insignificant variables using the smoothly clipped and absolute deviation penalty function in the MtLMM. The proposed penalized model offers robustness and flexibility to accommodate fat tails. An expectation conditional maximization algorithm is employed for the computation of maximum likelihood estimates of parameters. The calculation of standard errors is affected by an information-based method. The methodology is illustrated by analyzing Mayo Clinic Primary Biliary Cirrhosis sequential (PBCseq) data and a simulation study. We found drugs and sex can be eliminated from the PBCseq analysis, and over time the disease progresses.},
  archive      = {J_BIMJ},
  author       = {Mozhgan Taavoni and Mohammad Arashi},
  doi          = {10.1002/bimj.202000015},
  journal      = {Biometrical Journal},
  month        = {3},
  number       = {3},
  pages        = {539-556},
  shortjournal = {Bio. J.},
  title        = {Estimation in multivariate linear mixed models for longitudinal data with multiple outputs: Application to PBCseq data analysis},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Misspecified modeling of subsequent waves during COVID-19
outbreak: A change-point growth model. <em>BIMJ</em>, <em>64</em>(3),
523–538. (<a href="https://doi.org/10.1002/bimj.202100129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the analysis of cumulative counts of SARS-CoV-2 infections, such as deaths or cases, common parametric models based on log-logistic growth curves adapt well to describe a single wave at a time. Unfortunately, in Italy, as well as all over the globe, from February 2020 to March 2021 more than one wave has been observed. In this paper, we propose a method to fit more than one wave in the same model. In particular, we discuss an approach based on a change-point model in a pseudo-likelihood framework that takes into account some model misspecification issues, such as those concerning the assumption of Poisson marginals and those relating to overdispersion and autocorrelation. An application to data collected in Italy is discussed.},
  archive      = {J_BIMJ},
  author       = {Paolo Girardi and Luca Greco and Laura Ventura},
  doi          = {10.1002/bimj.202100129},
  journal      = {Biometrical Journal},
  month        = {3},
  number       = {3},
  pages        = {523-538},
  shortjournal = {Bio. J.},
  title        = {Misspecified modeling of subsequent waves during COVID-19 outbreak: A change-point growth model},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Identification of subgroups via partial linear regression
modeling approach. <em>BIMJ</em>, <em>64</em>(3), 506–522. (<a
href="https://doi.org/10.1002/bimj.202000331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In clinical trials, treatment effects often vary from subject to subject. Some subjects may benefit more than others from a specific treatment. One of the aims of subgroup analysis is to identify if there are subgroups of subjects with differential treatment effects. As in standard analysis, we first test if subgroups with differential treatment effects exist; if they do, we classify the subjects into different subgroups based on their covariate profiles; otherwise, we conclude no subgroups have differential treatment effects in this population. Existing methods utilize regression models, particularly linear models, for such analysis. However, in practice, not all effects of covariates on responses are linear. To address this issue, the article proposes a more flexible model, the partial linear model with a nonlinear monotone function to describe some specific effects of covariates and with a linear component to describe the effects of other covariates, develops model-fitting algorithm and derives model asymptotics. We then utilize the Wald statistic to test the existence of subgroups and the Neyman–Pearson rule to classify subjects into the subgroups. Simulation studies are conducted to evaluate the finite sample performance of the proposed method by comparing it with the commonly used linear models. Finally, we apply the methods to analyzing a real clinical trial.},
  archive      = {J_BIMJ},
  author       = {Yizhao Zhou and Ao Yuan and Ming T. Tan},
  doi          = {10.1002/bimj.202000331},
  journal      = {Biometrical Journal},
  month        = {3},
  number       = {3},
  pages        = {506-522},
  shortjournal = {Bio. J.},
  title        = {Identification of subgroups via partial linear regression modeling approach},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Type i multivariate zero-inflated COM–poisson regression
model. <em>BIMJ</em>, <em>64</em>(3), 481–505. (<a
href="https://doi.org/10.1002/bimj.202000249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present the Type I multivariate zero-inflated Conway–Maxwell–Poisson distribution, whose development is based on the extension of the Type I multivariate zero-inflated Poisson distribution. We developed important properties of the distribution and present a regression model. The AIC and BIC criteria are used to select the best fitted model. Two real data sets have been used to illustrate the proposed model. Moreover, we conclude by stating that the Type I multivariate zero-inflated Conway–Maxwell–Poisson distribution produces a better fitted model for multivariate count data with excess of zeros.},
  archive      = {J_BIMJ},
  author       = {Rogério A. Santana and Katiane S. Conceição and Carlos A. R. Diniz and Marinho G. Andrade},
  doi          = {10.1002/bimj.202000249},
  journal      = {Biometrical Journal},
  month        = {3},
  number       = {3},
  pages        = {481-505},
  shortjournal = {Bio. J.},
  title        = {Type i multivariate zero-inflated COM–Poisson regression model},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Gene–environment interaction identification via penalized
robust divergence. <em>BIMJ</em>, <em>64</em>(3), 461–480. (<a
href="https://doi.org/10.1002/bimj.202000157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In high-throughput cancer studies, gene–environment interactions associated with outcomes have important implications. Some commonly adopted identification methods do not respect the “main effect, interaction” hierarchical structure. In addition, they can be challenged by data contamination and/or long-tailed distributions, which are not uncommon. In this article, robust methods based on -divergence and density power divergence are proposed to accommodate contaminated data/long-tailed distributions. A hierarchical sparse group penalty is adopted for regularized estimation and selection and can identify important gene–environment interactions and respect the “main effect, interaction” hierarchical structure. The proposed methods are implemented using an effective group coordinate descent algorithm. Simulation shows that when contamination occurs, the proposed methods can significantly outperform the existing alternatives with more accurate identification. The proposed approach is applied to the analysis of The Cancer Genome Atlas (TCGA) triple-negative breast cancer data and Gene Environment Association Studies (GENEVA) Type 2 Diabetes data.},
  archive      = {J_BIMJ},
  author       = {Mingyang Ren and Sanguo Zhang and Shuangge Ma and Qingzhao Zhang},
  doi          = {10.1002/bimj.202000157},
  journal      = {Biometrical Journal},
  month        = {3},
  number       = {3},
  pages        = {461-480},
  shortjournal = {Bio. J.},
  title        = {Gene–environment interaction identification via penalized robust divergence},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design aspects of COVID-19 treatment trials: Improving
probability and time of favorable events. <em>BIMJ</em>, <em>64</em>(3),
440–460. (<a href="https://doi.org/10.1002/bimj.202000359">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a reaction to the pandemic of the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), a multitude of clinical trials for the treatment of SARS-CoV-2 or the resulting corona disease 2019 (COVID-19) are globally at various stages from planning to completion. Although some attempts were made to standardize study designs, this was hindered by the ferocity of the pandemic and the need to set up clinical trials quickly. We take the view that a successful treatment of COVID-19 patients (i) increases the probability of a recovery or improvement within a certain time interval, say 28 days; (ii) aims to expedite favorable events within this time frame; and (iii) does not increase mortality over this time period. On this background, we discuss the choice of endpoint and its analysis. Furthermore, we consider consequences of this choice for other design aspects including sample size and power and provide some guidance on the application of adaptive designs in this particular context.},
  archive      = {J_BIMJ},
  author       = {Jan Beyersmann and Tim Friede and Claudia Schmoor},
  doi          = {10.1002/bimj.202000359},
  journal      = {Biometrical Journal},
  month        = {3},
  number       = {3},
  pages        = {440-460},
  shortjournal = {Bio. J.},
  title        = {Design aspects of COVID-19 treatment trials: Improving probability and time of favorable events},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Impact of unequal cluster sizes for GEE analyses of stepped
wedge cluster randomized trials with binary outcomes. <em>BIMJ</em>,
<em>64</em>(3), 419–439. (<a
href="https://doi.org/10.1002/bimj.202100112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stepped wedge (SW) design is a type of unidirectional crossover design where cluster units switch from control to intervention condition at different prespecified time points. While a convention in study planning is to assume the cluster-period sizes are identical, SW cluster randomized trials (SW-CRTs) involving repeated cross-sectional designs frequently have unequal cluster-period sizes, which can impact the efficiency of the treatment effect estimator. In this paper, we provide a comprehensive investigation of the efficiency impact of unequal cluster sizes for generalized estimating equation analyses of SW-CRTs, with a focus on binary outcomes as in the Washington State Expedited Partner Therapy trial. Several major distinctions between our work and existing work include the following: (i) we consider multilevel correlation structures in marginal models with binary outcomes; (ii) we study the implications of both the between-cluster and within-cluster imbalances in sizes; and (iii) we provide a comparison between the independence working correlation versus the true working correlation and detail the consequences of ignoring correlation estimation in SW-CRTs with unequal cluster sizes. We conclude that the working independence assumption can lead to substantial efficiency loss and a large sample size regardless of cluster-period size variability in SW-CRTs, and recommend accounting for correlations in the analysis. To improve study planning, we additionally provide a computationally efficient search algorithm to estimate the sample size in SW-CRTs accounting for unequal cluster-period sizes, and conclude by illustrating the proposed approach in the context of the Washington State study.},
  archive      = {J_BIMJ},
  author       = {Zibo Tian and John S. Preisser and Denise Esserman and Elizabeth L. Turner and Paul J. Rathouz and Fan Li},
  doi          = {10.1002/bimj.202100112},
  journal      = {Biometrical Journal},
  month        = {3},
  number       = {3},
  pages        = {419-439},
  shortjournal = {Bio. J.},
  title        = {Impact of unequal cluster sizes for GEE analyses of stepped wedge cluster randomized trials with binary outcomes},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Contents: Biometrical journal 3’22. <em>BIMJ</em>,
<em>64</em>(3), 417–418. (<a
href="https://doi.org/10.1002/bimj.202270034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIMJ},
  doi          = {10.1002/bimj.202270034},
  journal      = {Biometrical Journal},
  month        = {3},
  number       = {3},
  pages        = {417-418},
  shortjournal = {Bio. J.},
  title        = {Contents: Biometrical journal 3&#39;22},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Cover picture: Biometrical journal 2’22. <em>BIMJ</em>,
<em>64</em>(2), NA. (<a
href="https://doi.org/10.1002/bimj.202270021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIMJ},
  doi          = {10.1002/bimj.202270021},
  journal      = {Biometrical Journal},
  month        = {2},
  number       = {2},
  pages        = {NA},
  shortjournal = {Bio. J.},
  title        = {Cover picture: Biometrical journal 2&#39;22},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Randomized -values for multiple testing and their
application in replicability analysis. <em>BIMJ</em>, <em>64</em>(2),
384–409. (<a href="https://doi.org/10.1002/bimj.202000155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We are concerned with testing replicability hypotheses for many endpoints simultaneously. This constitutes a multiple test problem with composite null hypotheses. Traditional -values, which are computed under least favorable parameter configurations (LFCs), are over-conservative in the case of composite null hypotheses. As demonstrated in prior work, this poses severe challenges in the multiple testing context, especially when one goal of the statistical analysis is to estimate the proportion of true null hypotheses. Randomized -values have been proposed to remedy this issue. In the present work, we discuss the application of randomized -values in replicability analysis. In particular, we introduce a general class of statistical models for which valid, randomized -values can be calculated easily. By means of computer simulations, we demonstrate that their usage typically leads to a much more accurate estimation of than the LFC-based approach. Finally, we apply our proposed methodology to a real data example from genomics.},
  archive      = {J_BIMJ},
  author       = {Anh-Tuan Hoang and Thorsten Dickhaus},
  doi          = {10.1002/bimj.202000155},
  journal      = {Biometrical Journal},
  month        = {2},
  number       = {2},
  pages        = {384-409},
  shortjournal = {Bio. J.},
  title        = {Randomized -values for multiple testing and their application in replicability analysis},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Note on a stepwise procedure for rejecting at least k out of
m hypotheses: A simple holm-type formulation and proof. <em>BIMJ</em>,
<em>64</em>(2), 377–383. (<a
href="https://doi.org/10.1002/bimj.202000206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mielke et al. (2021) proposed a stepwise multiple testing procedure (MTP) based on marginal p -values for rejecting at least k out of m null hypotheses. Briefly, the MTP cannot reject less than k hypotheses, but this property improves the power to reject k or more hypotheses relative to the stepdown MTP of Holm (1979). Mielke et al. discussed why such an MTP is of interest in the context of biosimilarity developments. This article describes how a slight modification of Holm&#39;s simple direct arguments can be used as an alternative to the closed-testing arguments of Mielke et al. to show the strong control of the family-wise error rate. This modification is based on a Holm-type formulation of the rejection algorithm where each step involves a single ordered p -value. With k equal to one, the stepwise MTP reduces to Holm&#39;s stepdown MTP. The MTP is valid quite generally. A version of the MTP with weights for hypotheses is also described and discussed. As in the case without weights: (a) a modification of Holm&#39;s arguments can be used; (b) with k equal to one, the MTP reduces to Holm&#39;s MTP with weights; and (c) the MTP is valid quite generally.},
  archive      = {J_BIMJ},
  author       = {Olivier J. M. Guilbaud},
  doi          = {10.1002/bimj.202000206},
  journal      = {Biometrical Journal},
  month        = {2},
  number       = {2},
  pages        = {377-383},
  shortjournal = {Bio. J.},
  title        = {Note on a stepwise procedure for rejecting at least k out of m hypotheses: A simple holm-type formulation and proof},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). One-two dependence and probability inequalities between one-
and two-sided union-intersection tests. <em>BIMJ</em>, <em>64</em>(2),
361–376. (<a href="https://doi.org/10.1002/bimj.202000207">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a paper published in 1939 in The Annals of Mathematical Statistics , Wald and Wolfowitz discussed the possible validity of a probability inequality between one- and two-sided coverage probabilities for the empirical distribution function. Twenty-eight years later, Vandewiele and Noé proved this inequality for Kolmogorov-Smirnov type goodness of fit tests. We refer to this type of inequality as one-two inequality. In this paper, we generalize their result for one- and two-sided union-intersection tests based on positively associated random variables and processes. Thereby, we give a brief review of different notions of positive association and corresponding results. Moreover, we introduce the notion of one-two dependence and discuss relationships with other dependence concepts. While positive association implies one-two dependence, the reverse implication fails. Last but not least, the Bonferroni inequality and the one-two inequality yield lower and upper bounds for two-sided acceptance/rejection probabilities which differ only slightly for significance levels not too large. We discuss several examples where the one-two inequality applies. Finally, we briefly discuss the possible impact of the validity of a one-two inequality on directional error control in multiple testing.},
  archive      = {J_BIMJ},
  author       = {Helmut Finner and Markus Roters},
  doi          = {10.1002/bimj.202000207},
  journal      = {Biometrical Journal},
  month        = {2},
  number       = {2},
  pages        = {361-376},
  shortjournal = {Bio. J.},
  title        = {One-two dependence and probability inequalities between one- and two-sided union-intersection tests},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust group sequential designs for trials with survival
endpoints and delayed response. <em>BIMJ</em>, <em>64</em>(2), 343–360.
(<a href="https://doi.org/10.1002/bimj.202000169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Randomized clinical trials in oncology typically utilize time-to-event endpoints such as progression-free survival or overall survival as their primary efficacy endpoints, and the most commonly used statistical test to analyze these endpoints is the log-rank test. The power of the log-rank test depends on the behavior of the hazard ratio of the treatment arm to the control arm. Under the assumption of proportional hazards, the log-rank test is asymptotically fully efficient. However, this proportionality assumption does not hold true if there is a delayed treatment effect. Cancer immunology has evolved over time and several cancer vaccines are available in the market for treating existing cancers. This includes sipuleucel-T for metastatic hormone-refractory prostate cancer, nivolumab for metastatic melanoma, and pembrolizumab for advanced nonsmall-cell lung cancer. As cancer vaccines require some time to elicit an immune response, a delayed treatment effect is observed, resulting in a violation of the proportional hazards assumption. Thus, the traditional log-rank test may not be optimal for testing immuno-oncology drugs in randomized clinical trials. Moreover, the new immuno-oncology compounds have been shown to be very effective in prolonging overall survival. Therefore, it is desirable to implement a group sequential design with the possibility of early stopping for overwhelming efficacy. In this paper, we investigate the max-combo test, which utilizes the maximum of two weighted log-rank statistics, as a robust alternative to the log-rank test. The new test is implemented for two-stage designs with possible early stopping at the interim analysis time point. Two classes of weights are investigated for the max-combo test: the Fleming and Harrington (1981) weights and the Magirr and Burman (2019) modest weights.},
  archive      = {J_BIMJ},
  author       = {Pranab Ghosh and Robin Ristl and Franz König and Martin Posch and Christopher Jennison and Heiko Götte and Armin Schüler and Cyrus Mehta},
  doi          = {10.1002/bimj.202000169},
  journal      = {Biometrical Journal},
  month        = {2},
  number       = {2},
  pages        = {343-360},
  shortjournal = {Bio. J.},
  title        = {Robust group sequential designs for trials with survival endpoints and delayed response},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Confirmatory adaptive group sequential designs for
single-arm phase II studies with multiple time-to-event endpoints.
<em>BIMJ</em>, <em>64</em>(2), 312–342. (<a
href="https://doi.org/10.1002/bimj.202000205">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing methods concerning the assessment of long-term survival outcomes in one-armed trials are commonly restricted to one primary endpoint. Corresponding adaptive designs suffer from limitations regarding the use of information from other endpoints in interim design changes. Here we provide adaptive group sequential one-sample tests for testing hypotheses on the multivariate survival distribution derived from multi-state models, while making provision for data-dependent design modifications based on all involved time-to-event endpoints. We explicitly elaborate application of the methodology to one-sample tests for the joint distribution of (i) progression-free survival (PFS) and overall survival (OS) in the context of an illness-death model, and (ii) time to toxicity and time to progression while accounting for death as a competing event. Large sample distributions are derived using a counting process approach. Small sample properties are studied by simulation. An already established multi-state model for non-small cell lung cancer is used to illustrate the adaptive procedure.},
  archive      = {J_BIMJ},
  author       = {Moritz Fabian Danzer and Tobias Terzer and Frank Berthold and Andreas Faldum and Rene Schmidt},
  doi          = {10.1002/bimj.202000205},
  journal      = {Biometrical Journal},
  month        = {2},
  number       = {2},
  pages        = {312-342},
  shortjournal = {Bio. J.},
  title        = {Confirmatory adaptive group sequential designs for single-arm phase II studies with multiple time-to-event endpoints},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sample size optimization and initial allocation of the
significance levels in group sequential trials with multiple endpoints.
<em>BIMJ</em>, <em>64</em>(2), 301–311. (<a
href="https://doi.org/10.1002/bimj.202000081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider multistage tests of multiple hypotheses under a flexible setting of calendar time and information fraction, focusing on the case where there are two hypotheses under testing. Explicit expressions of statistical powers are derived. With a proof of existence and uniqueness of solution, we develop a numerical method to search the optimal sample size. The proposed method allows us to find the suitable allocation of initial significance level along with the minimum sample size for group sequential designs, with and without hierarchical structures among different endpoints.},
  archive      = {J_BIMJ},
  author       = {Jiangtao Gou},
  doi          = {10.1002/bimj.202000081},
  journal      = {Biometrical Journal},
  month        = {2},
  number       = {2},
  pages        = {301-311},
  shortjournal = {Bio. J.},
  title        = {Sample size optimization and initial allocation of the significance levels in group sequential trials with multiple endpoints},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Simultaneous confidence tubes for comparing several
multivariate linear regression models. <em>BIMJ</em>, <em>64</em>(2),
290–300. (<a href="https://doi.org/10.1002/bimj.202000148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Much of the research on multiple comparison and simultaneous inference in the past 60 years or so has been for the comparisons of several population means. Spurrier seems to have been the first to investigate multiple comparisons of several simple linear regression lines using simultaneous confidence bands. In this paper, we extend the work of Liu et al. for finite comparisons of several univariate linear regression models using simultaneous confidence bands to finite comparisons of several multivariate linear regression models using simultaneous confidence tubes. We show how simultaneous confidence tubes can be constructed to allow more informative inferences for the comparison of several multivariate linear regression models than the current approach of hypotheses testing. The methods are illustrated with examples.},
  archive      = {J_BIMJ},
  author       = {Jianan Peng and Wei Liu and Frank Bretz and A. J. Hayter},
  doi          = {10.1002/bimj.202000148},
  journal      = {Biometrical Journal},
  month        = {2},
  number       = {2},
  pages        = {290-300},
  shortjournal = {Bio. J.},
  title        = {Simultaneous confidence tubes for comparing several multivariate linear regression models},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exact simultaneous confidence intervals for logical
selection of a biomarker cut-point. <em>BIMJ</em>, <em>64</em>(2),
272–289. (<a href="https://doi.org/10.1002/bimj.202000159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes four new principles for logical biomarker cut-point selection methods to adhere to: subgroup sensibility, sensitivity, specificity, and target monotonicity. At every cut-point value, our method gives confidence intervals not only for the efficacy at that cut-point value, but also efficacies in the marker-positive and marker-negative subgroups defined by that cut-point. These confidence intervals are given simultaneously for all possible cut-point values. Using Alzheimer&#39;s disease (AD) and type 2 diabetes (T2DM) as examples, we show our method achieves the four principles. Our method strongly controls familywise type I error rate (FWER) across both levels of multiplicity: the multiplicity of having marker-positive and marker-negative subgroups at each cut-point, and the multiplicity of searching through infinitely many cut-points. This is in contrast to other available methods. The confidence level of our simultaneous confidence intervals is in fact exact (not conservative). An application (app) is available, which implements the method we propose.},
  archive      = {J_BIMJ},
  author       = {Yang Han and Szu-Yu Tang and Hui-Min Lin and Jason C. Hsu},
  doi          = {10.1002/bimj.202000159},
  journal      = {Biometrical Journal},
  month        = {2},
  number       = {2},
  pages        = {272-289},
  shortjournal = {Bio. J.},
  title        = {Exact simultaneous confidence intervals for logical selection of a biomarker cut-point},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Confident identification of subgroups from SNP testing in
RCTs with binary outcomes. <em>BIMJ</em>, <em>64</em>(2), 256–271. (<a
href="https://doi.org/10.1002/bimj.202000170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern drug development, genotype information becomes more frequently collected in randomized controlled trials (RCTs) for individualized risk prediction and personalized medicine development. Finding single nucleotide polymorphisms (SNPs) that are predictive of differential treatment efficacy, measured by a clinical outcome, is fundamentally different and more challenging than the traditional association test for a quantitative trait. With the objective to confidently identify and infer genetic subgroups with enhanced treatment efficacy from a large RCT for an eye disease, age-related macular degeneration (AMD), where the clinical endpoint is binary (progressed or not), we propose a novel SNP-testing procedure for binary clinical outcomes. Specifically, we formulate four contrasts to simultaneously assess all possible genetic effects on a logic-respecting efficacy measure, the relative risk (between treatment and control). Our method controls both within- and across-SNP multiplicity rigorously. We then use real genotype data to perform chromosome-wide simulations to evaluate our method performance and to provide practical recommendations. Finally, we apply the proposed method to perform a genome-wide SNP testing for the AMD trial and successfully identify multiple gene regions with genetic subgroups exhibiting enhanced efficacy in terms of decreasing the AMD progression rate.},
  archive      = {J_BIMJ},
  author       = {Yue Wei and Xinjun Wang and Emily Y. Chew and Ying Ding},
  doi          = {10.1002/bimj.202000170},
  journal      = {Biometrical Journal},
  month        = {2},
  number       = {2},
  pages        = {256-271},
  shortjournal = {Bio. J.},
  title        = {Confident identification of subgroups from SNP testing in RCTs with binary outcomes},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Rejoinder for discussions on correct and logical causal
inference for binary and time-to-event outcomes in randomized controlled
trials. <em>BIMJ</em>, <em>64</em>(2), 246–255. (<a
href="https://doi.org/10.1002/bimj.202100089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our paper differs from previous literature in two ways:},
  archive      = {J_BIMJ},
  author       = {Yi Liu and Bushi Wang and Hong Tian and Jason C. Hsu},
  doi          = {10.1002/bimj.202100089},
  journal      = {Biometrical Journal},
  month        = {2},
  number       = {2},
  pages        = {246-255},
  shortjournal = {Bio. J.},
  title        = {Rejoinder for discussions on correct and logical causal inference for binary and time-to-event outcomes in randomized controlled trials},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Discussion on ‘correct and logical causal inference for
binary and time-to-event outcomes in randomized controlled trials’.
<em>BIMJ</em>, <em>64</em>(2), 243–245. (<a
href="https://doi.org/10.1002/bimj.202100060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIMJ},
  author       = {Dong Xi and Frank Bretz},
  doi          = {10.1002/bimj.202100060},
  journal      = {Biometrical Journal},
  month        = {2},
  number       = {2},
  pages        = {243-245},
  shortjournal = {Bio. J.},
  title        = {Discussion on ‘Correct and logical causal inference for binary and time-to-event outcomes in randomized controlled trials&#39;},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the logic of collapsibility for causal effect measures.
<em>BIMJ</em>, <em>64</em>(2), 235–242. (<a
href="https://doi.org/10.1002/bimj.202000305">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIMJ},
  author       = {Vanessa Didelez and Mats Julius Stensrud},
  doi          = {10.1002/bimj.202000305},
  journal      = {Biometrical Journal},
  month        = {2},
  number       = {2},
  pages        = {235-242},
  shortjournal = {Bio. J.},
  title        = {On the logic of collapsibility for causal effect measures},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Discussion on “correct and logical causal inference for
binary and time-to-event outcomes in randomized controlled trials” by yi
liu, bushi wang, miao yang, jianan hui, heng xu, siyoen kil, and jason
c. hsu. <em>BIMJ</em>, <em>64</em>(2), 225–234. (<a
href="https://doi.org/10.1002/bimj.202000320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In their paper, Liu et al. (2020) pointed out illogical discrepancies between subgroup and overall causal effects for some efficacy measures, in particular the odds and hazard ratios. As the authors show, the culprit is subgroups having prognostic effects within treatment arms. In response to their provocative findings, we found that the odds and hazard ratios are logic respecting when the subgroups are purely predictive, that is, the distribution of the potential outcome for the control treatment is homogeneous across subgroups. We also found that when we redefined the odds and hazards ratio causal estimands in terms of the joint distribution of the potential outcomes, the discrepancies are resolved under specific models in which the potential outcomes are conditionally independent. In response to other discussion points in the paper, we also provide remarks on association versus causation, confounding, statistical computing software, and dichotomania.},
  archive      = {J_BIMJ},
  author       = {Gene Pennello and Dandan Xu},
  doi          = {10.1002/bimj.202000320},
  journal      = {Biometrical Journal},
  month        = {2},
  number       = {2},
  pages        = {225-234},
  shortjournal = {Bio. J.},
  title        = {Discussion on “Correct and logical causal inference for binary and time-to-event outcomes in randomized controlled trials” by yi liu, bushi wang, miao yang, jianan hui, heng xu, siyoen kil, and jason c. hsu},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Correct and logical causal inference for binary and
time-to-event outcomes in randomized controlled trials. <em>BIMJ</em>,
<em>64</em>(2), 198–224. (<a
href="https://doi.org/10.1002/bimj.202000202">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Targeted therapies tend to have biomarker defined subgroups that derive differential efficacy from treatments. This article corrects three prevailing oversights in stratified analyses comparing treatments in randomized controlled trials (RCTs) with binary and time-to-event outcomes:},
  archive      = {J_BIMJ},
  author       = {Yi Liu and Bushi Wang and Miao Yang and Jianan Hui and Heng Xu and Siyoen Kil and Jason C. Hsu},
  doi          = {10.1002/bimj.202000202},
  journal      = {Biometrical Journal},
  month        = {2},
  number       = {2},
  pages        = {198-224},
  shortjournal = {Bio. J.},
  title        = {Correct and logical causal inference for binary and time-to-event outcomes in randomized controlled trials},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Special issue on multiple comparisons (MCP 2019).
<em>BIMJ</em>, <em>64</em>(2), 197. (<a
href="https://doi.org/10.1002/bimj.202100332">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIMJ},
  author       = {Xinping Cui and Thorsten Dickhaus and Jason C. Hsu},
  doi          = {10.1002/bimj.202100332},
  journal      = {Biometrical Journal},
  month        = {2},
  number       = {2},
  pages        = {197},
  shortjournal = {Bio. J.},
  title        = {Special issue on multiple comparisons (MCP 2019)},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Contents: Biometrical journal 2’22. <em>BIMJ</em>,
<em>64</em>(2), 195–196. (<a
href="https://doi.org/10.1002/bimj.202270024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIMJ},
  doi          = {10.1002/bimj.202270024},
  journal      = {Biometrical Journal},
  month        = {2},
  number       = {2},
  pages        = {195-196},
  shortjournal = {Bio. J.},
  title        = {Contents: Biometrical journal 2&#39;22},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Cover picture: Biometrical journal 1’22. <em>BIMJ</em>,
<em>64</em>(1), NA. (<a
href="https://doi.org/10.1002/bimj.202270011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIMJ},
  doi          = {10.1002/bimj.202270011},
  journal      = {Biometrical Journal},
  month        = {1},
  number       = {1},
  pages        = {NA},
  shortjournal = {Bio. J.},
  title        = {Cover picture: Biometrical journal 1&#39;22},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Heterogeneity in statistical genetics: How to assess,
address, and account for mixtures in association studies, by derek
gordon, stephen j. Finch, wonkuk kim 2020. Cham: Springer (2020).
Springer series statistics for biology and health. 352 pages. ISBN:
978-3-030-61120-0. Https://doi.org/10.1007/978-3-030-61121-7.
<em>BIMJ</em>, <em>64</em>(1), 186–187. (<a
href="https://doi.org/10.1002/bimj.202100336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIMJ},
  author       = {Michael Nothnagel},
  doi          = {10.1002/bimj.202100336},
  journal      = {Biometrical Journal},
  month        = {1},
  number       = {1},
  pages        = {186-187},
  shortjournal = {Bio. J.},
  title        = {Heterogeneity in statistical genetics: how to assess, address, and account for mixtures in association studies, by derek gordon, stephen j. finch, wonkuk kim 2020. cham: springer (2020). springer series statistics for biology and health. 352 pages. ISBN: 978-3-030-61120-0. https://doi.org/10.1007/978-3-030-61121-7},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An optimal multiarmed response adaptive design for survival
outcome with independent censoring. <em>BIMJ</em>, <em>64</em>(1),
165–185. (<a href="https://doi.org/10.1002/bimj.202000089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compromising ethics and precision in the context of a multiarmed clinical trial, an optimal order adjusted response adaptive design is proposed for survival outcomes subject to independent random censoring. The operating characteristics of the proposed design and the follow-up inference are studied both theoretically as well as empirically and are compared with those of the competitors. Applicability of the developed design is further illustrated through redesigning a real clinical trial with survival responses.},
  archive      = {J_BIMJ},
  author       = {Soumyadeep Das and Rahul Bhattacharya},
  doi          = {10.1002/bimj.202000089},
  journal      = {Biometrical Journal},
  month        = {1},
  number       = {1},
  pages        = {165-185},
  shortjournal = {Bio. J.},
  title        = {An optimal multiarmed response adaptive design for survival outcome with independent censoring},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive dose-response studies to establish proof-of-concept
in learning-phase clinical trials. <em>BIMJ</em>, <em>64</em>(1),
146–164. (<a href="https://doi.org/10.1002/bimj.202100044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In learning-phase clinical trials in drug development, adaptive designs can be efficient and highly informative when used appropriately. In this article, we extend the multiple comparison procedures with modeling techniques (MCP-Mod) procedure with generalized multiple contrast tests (GMCTs) to two-stage adaptive designs for establishing proof-of-concept. The results of an interim analysis of first-stage data are used to adapt the candidate dose-response models and the dosages studied in the second stage. GMCTs are used in both stages to obtain stage-wise -values, which are then combined to determine an overall -value. An alternative approach is also considered that combines the -statistics across stages, employing the conditional rejection probability principle to preserve the Type I error probability. Simulation studies demonstrate that the adaptive designs are advantageous compared to the corresponding tests in a nonadaptive design if the selection of the candidate set of dose-response models is not well informed by evidence from preclinical and early-phase studies.},
  archive      = {J_BIMJ},
  author       = {Shiyang Ma and Michael P. McDermott},
  doi          = {10.1002/bimj.202100044},
  journal      = {Biometrical Journal},
  month        = {1},
  number       = {1},
  pages        = {146-164},
  shortjournal = {Bio. J.},
  title        = {Adaptive dose-response studies to establish proof-of-concept in learning-phase clinical trials},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimating the correlation between semi-competing risk
survival endpoints. <em>BIMJ</em>, <em>64</em>(1), 131–145. (<a
href="https://doi.org/10.1002/bimj.202000226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-to-event, bivariate, semi-competing risk data occur when a terminal event can censor a non-terminal event, but not vice versa. There are potential correlations between these endpoints as they are measured on the same individual. However, traditional methods to estimate the correlations cannot be used directly due to the censoring of time-to-event endpoints. We develop methods using a copula-based approach to study the dependence structures between the two survival endpoints. We use a variety of copulas to estimate the correlation between endpoints and to acknowledge different dependence structures. The estimated association parameter in the copula function is transformed into Spearman&#39;s rank correlation coefficient. We conduct a simulation study to evaluate the estimation from the proposed models along with the effects of misspecification of the copula functions and survival distributions. The proposed methods are applied to two real-life data sets.},
  archive      = {J_BIMJ},
  author       = {Lexy Sorrell and Yinghui Wei and Małgorzata Wojtyś and Peter Rowe},
  doi          = {10.1002/bimj.202000226},
  journal      = {Biometrical Journal},
  month        = {1},
  number       = {1},
  pages        = {131-145},
  shortjournal = {Bio. J.},
  title        = {Estimating the correlation between semi-competing risk survival endpoints},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Nonproportional hazards model with a frailty term for
modeling subgroups with evidence of long-term survivors: Application to
a lung cancer dataset. <em>BIMJ</em>, <em>64</em>(1), 105–130. (<a
href="https://doi.org/10.1002/bimj.202000292">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With advancements in medical treatments for cancer, an increase in the life expectancy of patients undergoing new treatments is expected. Consequently, the field of statistics has evolved to present increasingly flexible models to explain such results better. In this paper, we present a lung cancer dataset with some covariates that exhibit nonproportional hazards (NPHs). Besides, the presence of long-term survivors is observed in subgroups. The proposed modeling is based on the generalized time-dependent logistic model with each subgroup&#39;s effect time and a random term effect (frailty). In practice, essential covariates are not observed for several reasons. In this context, frailty models are useful in modeling to quantify the amount of unobservable heterogeneity. The frailty distribution adopted was the weighted Lindley distribution, which has several interesting properties, such as the Laplace transform function on closed form, flexibility in the probability density function, among others. The proposed model allows for NPHs and long-term survivors in subgroups. Parameter estimation was performed using the maximum likelihood method, and Monte Carlo simulation studies were conducted to evaluate the estimators&#39; performance. We exemplify this model&#39;s use by applying data of patients diagnosed with lung cancer in the state of São Paulo, Brazil.},
  archive      = {J_BIMJ},
  author       = {Amanda B. Gazon and Eder A. Milani and Alex L. Mota and Francisco Louzada and Vera L. D. Tomazella and Vinicius F. Calsavara},
  doi          = {10.1002/bimj.202000292},
  journal      = {Biometrical Journal},
  month        = {1},
  number       = {1},
  pages        = {105-130},
  shortjournal = {Bio. J.},
  title        = {Nonproportional hazards model with a frailty term for modeling subgroups with evidence of long-term survivors: Application to a lung cancer dataset},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exposure assessment for cox proportional hazards cure models
with interval-censored survival data. <em>BIMJ</em>, <em>64</em>(1),
91–104. (<a href="https://doi.org/10.1002/bimj.202000271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mixture cure models have been developed as an effective tool to analyze failure time data with a cure fraction. Used in conjunction with the logistic regression model, this model allows covariate-adjusted inference of an exposure effect on the cured probability and the hazard of failure for the uncured subjects. However, the covariate-adjusted inference for the overall exposure effect is not directly provided. In this paper, we describe a Cox proportional hazards cure model to analyze interval-censored survival data in the presence of a cured fraction and then apply a post-estimation approach by using model-predicted estimates difference to assess the overall exposure effect on the restricted mean survival time scale. For baseline hazard/survival function estimation, simple parametric models as fractional polynomials or restricted cubic splines are utilized to approximate the baseline logarithm cumulative hazard function, or, alternatively, the full likelihood is specified through a piecewise linear approximation for the cumulative baseline hazard function. Simulation studies were conducted to demonstrate the unbiasedness of both estimation methods for the overall exposure effect estimates over various baseline hazard distribution shapes. The methods are applied to analyze the interval-censored relapse time data from a smoking cessation study.},
  archive      = {J_BIMJ},
  author       = {Wei Wang and Ning Cong and Aijun Ye and Hui Zhang and Bo Zhang},
  doi          = {10.1002/bimj.202000271},
  journal      = {Biometrical Journal},
  month        = {1},
  number       = {1},
  pages        = {91-104},
  shortjournal = {Bio. J.},
  title        = {Exposure assessment for cox proportional hazards cure models with interval-censored survival data},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A bayesian longitudinal trend analysis of count data with
gaussian processes. <em>BIMJ</em>, <em>64</em>(1), 74–90. (<a
href="https://doi.org/10.1002/bimj.202000298">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The context of comparing two different groups of subjects that are measured repeatedly over time is considered. Our specific focus is on highly variable count data which have a nonnegligible frequency of zeros and have time trends that are difficult to characterize. These challenges are often present when analyzing bacteria or gene expression data sets. Traditional longitudinal data analysis methods, including generalized estimating equations, can be challenged by the features present in these types of data sets. We propose a Bayesian methodology that effectively confronts these challenges. A key feature of the methodology is the use of Gaussian processes to flexibly model the time trends. Inference procedures based on both sharp and interval null hypotheses are discussed, including for the important hypotheses that test for group differences at individual time points. The proposed methodology is illustrated with next-generation sequencing (NGS) data sets corresponding to two different experimental conditions. In particular, the method is applied to a case study containing bacteria counts of mice with chronic and nonchronic wounds to identify potential wound-healing probiotics. The methodology can be applied to similar NGS data sets comparing two groups of subjects.},
  archive      = {J_BIMJ},
  author       = {Samantha VanSchalkwyk and Daniel R. Jeske and Jane H. Kim and Manuela Martins-Green},
  doi          = {10.1002/bimj.202000298},
  journal      = {Biometrical Journal},
  month        = {1},
  number       = {1},
  pages        = {74-90},
  shortjournal = {Bio. J.},
  title        = {A bayesian longitudinal trend analysis of count data with gaussian processes},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Penalized joint generalized estimating equations for
longitudinal binary data. <em>BIMJ</em>, <em>64</em>(1), 57–73. (<a
href="https://doi.org/10.1002/bimj.202000336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In statistical research, variable selection and feature extraction are a typical issue. Variable selection in linear models has been fully developed, while it has received relatively little attention for longitudinal data. Since a longitudinal study involves within-subject correlations, the likelihood function of discrete longitudinal responses generally cannot be expressed in analytically closed form, and standard variable selection methods cannot be directly applied. As an alternative, the penalized generalized estimating equation (PGEE) is helpful but very likely results in incorrect variable selection if the working correlation matrix is misspecified. In many circumstances, the within-subject correlations are of interest and need to be modeled together with the mean. For longitudinal binary data, it becomes more challenging because the within-subject correlation coefficients have the so-called Fréchet–Hoeffding upper bound. In this paper, we proposed smoothly clipped absolute deviation (SCAD)-based and least absolute shrinkage and selection operator (LASSO)-based penalized joint generalized estimating equation (PJGEE) methods to simultaneously model the mean and correlations for longitudinal binary data, together with variable selection in the mean model. The estimated correlation coefficients satisfy the upper bound constraints. Simulation studies under different scenarios are made to assess the performance of the proposed method. Compared to existing PGEE methods that specify a working correlation matrix for longitudinal binary data, the proposed PJGEE method works much better in terms of variable selection consistency and parameter estimation accuracy. A real data set on Clinical Global Impression is analyzed for illustration.},
  archive      = {J_BIMJ},
  author       = {Youjun Huang and Jianxin Pan},
  doi          = {10.1002/bimj.202000336},
  journal      = {Biometrical Journal},
  month        = {1},
  number       = {1},
  pages        = {57-73},
  shortjournal = {Bio. J.},
  title        = {Penalized joint generalized estimating equations for longitudinal binary data},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Variance estimators for weighted and stratified linear
dose–response function estimators using generalized propensity score.
<em>BIMJ</em>, <em>64</em>(1), 33–56. (<a
href="https://doi.org/10.1002/bimj.202000267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Propensity score methods are widely used in observational studies for evaluating marginal treatment effects. The generalized propensity score (GPS) is an extension of the propensity score framework, historically developed in the case of binary exposures, for use with quantitative or continuous exposures. In this paper, we proposed variance estimators for treatment effect estimators on continuous outcomes. Dose–response functions (DRFs) were estimated through weighting on the inverse of the GPS, or using stratification. Variance estimators were evaluated using Monte Carlo simulations. Despite the use of stabilized weights, the variability of the weighted estimator of the DRF was particularly high, and none of the variance estimators (a bootstrap-based estimator, a closed-form estimator especially developed to take into account the estimation step of the GPS, and a sandwich estimator) were able to adequately capture this variability, resulting in coverages below the nominal value, particularly when the proportion of the variation in the quantitative exposure explained by the covariates was large. The stratified estimator was more stable, and variance estimators (a bootstrap-based estimator, a pooled linearized estimator, and a pooled model-based estimator) more efficient at capturing the empirical variability of the parameters of the DRF. The pooled variance estimators tended to overestimate the variance, whereas the bootstrap estimator, which intrinsically takes into account the estimation step of the GPS, resulted in correct variance estimations and coverage rates. These methods were applied to a real data set with the aim of assessing the effect of maternal body mass index on newborn birth weight.},
  archive      = {J_BIMJ},
  author       = {Valérie Garès and Guillaume Chauvet and David Hajage},
  doi          = {10.1002/bimj.202000267},
  journal      = {Biometrical Journal},
  month        = {1},
  number       = {1},
  pages        = {33-56},
  shortjournal = {Bio. J.},
  title        = {Variance estimators for weighted and stratified linear dose–response function estimators using generalized propensity score},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Nonparametric estimation of recursive point processes with
application to mumps in pennsylvania. <em>BIMJ</em>, <em>64</em>(1),
20–32. (<a href="https://doi.org/10.1002/bimj.202000245">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The self-exciting Hawkes point process model (Hawkes, 1971) has been used to describe and forecast communicable diseases. A variant of the Hawkes model, called the recursive model, was proposed by Schoenberg et al. (2019) and has been shown to fit well to various epidemic disease datasets. Unlike the Hawkes model, the recursive model allows the productivity to vary as the overall rate of incidence of the disease varies. Here, we extend the data-driven nonparametric expectation-maximization method of Marsan and Lengliné (2008) in order to fit the recursive model without assuming a particular functional form for the productivity. The nonparametric recursive model is trained to fit to weekly reported cases of mumps in Pennsylvania during the January 1970–September 1990 time frame and then assessed using one week forecasts for the October 1990–December 2001 time period. Both its training and predictive ability are evaluated compared to that of other candidate models, such as Hawkes and SVEILR (susceptible, vaccinated, exposed, infected, lightly infected, recovered) compartmental models.},
  archive      = {J_BIMJ},
  author       = {Andrew Kaplan and Junhyung Park and Conor Kresin and Frederic Schoenberg},
  doi          = {10.1002/bimj.202000245},
  journal      = {Biometrical Journal},
  month        = {1},
  number       = {1},
  pages        = {20-32},
  shortjournal = {Bio. J.},
  title        = {Nonparametric estimation of recursive point processes with application to mumps in pennsylvania},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Simultaneous confidence intervals for contrasts of
quantiles. <em>BIMJ</em>, <em>64</em>(1), 7–19. (<a
href="https://doi.org/10.1002/bimj.202000077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skewed distributions and inferences concerning quantiles are common in the health and social science researches. And most standard simultaneous inference procedures require the normality assumption. For example, few methods exist for comparing the medians of independent samples or quantiles of several distributions in general. To our knowledge, there is no easy-to-use method for constructing simultaneous confidence intervals for multiple contrasts of quantiles in a one-way layout. In this paper, we develop an asymptotic method for constructing such intervals both for differences and ratios of quantiles and extend the idea to that of right-censored time-to-event data in survival analysis. Small-sample performance of the proposed method and a bootstrap method were assessed in terms of coverage probabilities and average widths of the simultaneous confidence intervals. Good coverage probabilities were observed for most of the distributions considered in our simulations. The proposed methods have been implemented in an R package and are used to analyze two motivating datasets.},
  archive      = {J_BIMJ},
  author       = {Lawrence S. Segbehoe and Frank Schaarschmidt and Gemechis D. Djira},
  doi          = {10.1002/bimj.202000077},
  journal      = {Biometrical Journal},
  month        = {1},
  number       = {1},
  pages        = {7-19},
  shortjournal = {Bio. J.},
  title        = {Simultaneous confidence intervals for contrasts of quantiles},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Contents: Biometrical journal 1’22. <em>BIMJ</em>,
<em>64</em>(1), 5–6. (<a
href="https://doi.org/10.1002/bimj.202270014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BIMJ},
  doi          = {10.1002/bimj.202270014},
  journal      = {Biometrical Journal},
  month        = {1},
  number       = {1},
  pages        = {5-6},
  shortjournal = {Bio. J.},
  title        = {Contents: Biometrical journal 1&#39;22},
  volume       = {64},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
