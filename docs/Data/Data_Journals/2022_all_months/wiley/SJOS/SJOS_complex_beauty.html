<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SJOS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="sjos---66">SJOS - 66</h2>
<ul>
<li><details>
<summary>
(2022). Efficient semiparametric estimation of time-censored
intensity-reduction models for repairable systems. <em>SJOS</em>,
<em>49</em>(4), 1860–1888. (<a
href="https://doi.org/10.1111/sjos.12564">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rate reduction models have been widely used to model the recurrent failure data for their capabilities in quantifying the repair effects. Despite the widespread popularity, there have been limited studies on statistical inference of most failure rate reduction models. In view of this fact, this study proposes a semiparametric estimation framework for a general class of such models, called extended geometric failure rate reduction (EGFRR) models. Covariates are considered in our analysis and their effects are modeled as a log-linear factor on the baseline failure rate. Unlike the existing inference methods for the EGFRR models that assume the failure data are censored at a fixed number of failures, our study considers covariates and time-censoring, which are more common in practice. The semiparametric maximum likelihood (ML) estimators are obtained by carefully constructing the likelihood function. Asymptotic properties including consistency and weak convergence of the ML estimators are established by using the properties of the martingale process. In addition, we show that the semiparametric estimators are asymptotically efficient. A real example from the automobile industry illustrates the usefulness of the proposed framework and extensive simulations show its outstanding performance when comparing with the existing methods.},
  archive      = {J_SJOS},
  author       = {Jinyang Wang and Piao Chen and Zhisheng Ye},
  doi          = {10.1111/sjos.12564},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1860-1888},
  shortjournal = {Scand. J. Statist.},
  title        = {Efficient semiparametric estimation of time-censored intensity-reduction models for repairable systems},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Equivalence theorems for c and DA-optimality for linear
mixed effects models with applications to multitreatment group
assignments in health care. <em>SJOS</em>, <em>49</em>(4), 1842–1859.
(<a href="https://doi.org/10.1111/sjos.12584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We constructcandDA-optimal approximate designs for linear mixed models with group-specific treatment for estimating parameters or contrasts in the population parameters. We establish equivalence theorems to confirm optimality of these designs under a linear mixed model and provide illustrative application to findD,DAandc-optimal designs for polynomial and fractional polynomial models with multitreatment group assignments. For more complex models, we briefly review metaheuristics and their potential applications to find various optimal designs, including optimal designs for problems considered here and their extensions.},
  archive      = {J_SJOS},
  author       = {Xin Liu and Rong-Xian Yue and Weng Kee Wong},
  doi          = {10.1111/sjos.12584},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1842-1859},
  shortjournal = {Scand. J. Statist.},
  title        = {Equivalence theorems for c and DA-optimality for linear mixed effects models with applications to multitreatment group assignments in health care},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimation of graphical models for skew continuous data.
<em>SJOS</em>, <em>49</em>(4), 1811–1841. (<a
href="https://doi.org/10.1111/sjos.12569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a new approach for estimating non-Gaussian undirected graphical models. Specifically, we model continuous data from a class of multivariateskeweddistributions, whose conditional dependence structure depends on both a precision matrix and a shape vector. To estimate the graph, we propose a novel estimation method based on nodewise regression: we first fit a linear model, and then fit a one component projection pursuit regression model to the residuals obtained from the linear model, and finally threshold appropriate quantities. Theoretically, we establish error bounds for each nodewise regression and prove the consistency of the estimated graph when the number of variables diverges with the sample size. Simulation results demonstrate the strong finite sample performance of our new method over existing methods for estimating Gaussian and non-Gaussian graphical models. Finally, we demonstrate an application of the proposed method on observations of physicochemical properties of wine.},
  archive      = {J_SJOS},
  author       = {Linh H. Nghiem and Francis K. C. Hui and Samuel Müller and Alan H. Welsh},
  doi          = {10.1111/sjos.12569},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1811-1841},
  shortjournal = {Scand. J. Statist.},
  title        = {Estimation of graphical models for skew continuous data},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pointwise comparison of two multivariate density functions.
<em>SJOS</em>, <em>49</em>(4), 1791–1810. (<a
href="https://doi.org/10.1111/sjos.12565">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Testing the equality of two density functions based on independent samples is a classical problem in statistics. While the focus is often on global equality, it is also of interest to conduct local comparisons of density functions. Typically a type of Wald statistic is employed, where the local difference in densities is standardized by an estimate of the asymptotic standard error of that difference. We study the null distribution of this test statistic. The literature has suggested that this will be asymptotically standard normal, but we show that this is by no means always the case. In particular, when using bandwidth matrices of optimal order (for estimation), we prove that the asymptotic mean of this null distribution is nonzero when either the sample sizes differ, or when the Hessian matrices of the densities differ at the point where the densities are equal. In numerical studies we find the erroneous use of the standard normal null distribution in such cases can severely corrupt the test size. We show that these problems can be managed effectively by using common bandwidths when the Hessian matrices are equal, and applying adjusted undersmoothing bandwidth matrices when they are not.},
  archive      = {J_SJOS},
  author       = {Martin L. Hazelton and Tilman M. Davies},
  doi          = {10.1111/sjos.12565},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1791-1810},
  shortjournal = {Scand. J. Statist.},
  title        = {Pointwise comparison of two multivariate density functions},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Soft maximin estimation for heterogeneous data.
<em>SJOS</em>, <em>49</em>(4), 1761–1790. (<a
href="https://doi.org/10.1111/sjos.12580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting a common robust signal from data divided into heterogeneous groups is challenging when each group—in addition to the signal—contains large, unique variation components. Previously, maximin estimation was proposed as a robust method in the presence of heterogeneous noise. We propose soft maximin estimation as a computationally attractive alternative aimed at striking a balance between pooled estimation and (hard) maximin estimation. The soft maximin method provides a range of estimators, controlled by a parameterζ&gt;0$$ \zeta &gt;0 $$, that interpolates pooled least squares estimation and maximin estimation. By establishing relevant theoretical properties we argue that the soft maximin method is statistically sensible and computationally attractive. We demonstrate, on real and simulated data, that soft maximin estimation can offer improvements over both pooled OLS and hard maximin in terms of predictive performance and computational complexity. A time and memory efficient implementation is provided in the R packageSMMEavailable on CRAN.},
  archive      = {J_SJOS},
  author       = {Adam Lund and Søren Wengel Mogensen and Niels Richard Hansen},
  doi          = {10.1111/sjos.12580},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1761-1790},
  shortjournal = {Scand. J. Statist.},
  title        = {Soft maximin estimation for heterogeneous data},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Convergence of likelihood ratios and estimators for
selection in nonneutral wright–fisher diffusions. <em>SJOS</em>,
<em>49</em>(4), 1728–1760. (<a
href="https://doi.org/10.1111/sjos.12572">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A number of discrete time, finite population size models in genetics describing the dynamics of allele frequencies are known to converge (subject to suitable scaling) to a diffusion process termed the Wright–Fisher diffusion. This diffusion evolves on a bounded interval, such that many standard results in diffusion theory, assuming evolution on the real line, no longer apply. In this article we derive conditions to establishϑ-uniform ergodicity for diffusions on bounded intervals, and use them to prove that the Wright–Fisher diffusion is uniformly in the selection and mutation parameters ergodic, and that the measures induced by the solution to the stochastic differential equation are uniformly locally asymptotically normal. We subsequently use these results to show that the maximum likelihood and Bayesian estimators for the selection parameter are uniformly over compact sets consistent, asymptotically normal, display moment convergence, and are asymptotically efficient for a suitable class of loss functions.},
  archive      = {J_SJOS},
  author       = {Jaromir Sant and Paul A. Jenkins and Jere Koskela and Dario Spanò},
  doi          = {10.1111/sjos.12572},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1728-1760},
  shortjournal = {Scand. J. Statist.},
  title        = {Convergence of likelihood ratios and estimators for selection in nonneutral Wright–Fisher diffusions},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Empirical best prediction of small area bivariate
parameters. <em>SJOS</em>, <em>49</em>(4), 1699–1727. (<a
href="https://doi.org/10.1111/sjos.12618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces empirical best predictors of small area bivariate parameters, like ratios of sums or sums of ratios, by assuming that the target unit-level vector follows a bivariate nested error regression model. The corresponding means squared errors are estimated by parametric bootstrap. Several simulation experiments empirically study the behavior of the introduced statistical methodology. An application to real data from the Spanish household budget survey gives estimators of ratios of food household expenditures by provinces.},
  archive      = {J_SJOS},
  author       = {María Dolores Esteban and María José Lombardía and Esther López-Vizcaíno and Domingo Morales and Agustín Pérez},
  doi          = {10.1111/sjos.12618},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1699-1727},
  shortjournal = {Scand. J. Statist.},
  title        = {Empirical best prediction of small area bivariate parameters},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The kendall and spearman rank correlations of the bivariate
skew normal distribution. <em>SJOS</em>, <em>49</em>(4), 1669–1698. (<a
href="https://doi.org/10.1111/sjos.12587">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We derive the Kendall and Spearman rank correlation coefficients of the bivariate skew normal (SN) distribution. For a given correlation parameter, we provide conditions on the shape parameters, under which the SN is more dependent than the normal in terms of each of the two-rank correlations. We further show how our results can be used for rank-based estimation procedures of the correlation parameter and the equal shape parameter of the SN, whose consistency and asymptotic normality we establish.},
  archive      = {J_SJOS},
  author       = {Andréas Heinen and Alfonso Valdesogo},
  doi          = {10.1111/sjos.12587},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1669-1698},
  shortjournal = {Scand. J. Statist.},
  title        = {The kendall and spearman rank correlations of the bivariate skew normal distribution},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the sign recovery by least absolute shrinkage and
selection operator, thresholded least absolute shrinkage and selection
operator, and thresholded basis pursuit denoising. <em>SJOS</em>,
<em>49</em>(4), 1636–1668. (<a
href="https://doi.org/10.1111/sjos.12568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Basis pursuit (BP), basis pursuit deNoising (BPDN), and least absolute shrinkage and selection operator (LASSO) are popular methods for identifying important predictors in the high-dimensional linear regression modelY=Xβ+ε. By definition, whenε=0, BP uniquely recoversβwhenXβ=Xbandβ≠bimplies‖b‖1&gt;‖β‖1(identifiability condition). Furthermore, LASSO can recover the sign ofβonly under a much stronger irrepresentability condition. Meanwhile, it is known that the model selection properties of LASSO can be improved by hard thresholding its estimates. This article supports these findings by proving that thresholded LASSO, thresholded BPDN, and thresholded BP recover the sign ofβin both the noisy and noiseless cases if and only ifβis identifiable and large enough. In particular, ifXhas iid Gaussian entries and the number of predictors grows linearly with the sample size, then these thresholded estimators can recover the sign ofβwhen the signal sparsity is asymptotically below the Donoho–Tanner transition curve. This is in contrast to the regular LASSO, which asymptotically, recovers the sign ofβonly when the signal sparsity tends to 0. Numerical experiments show that the identifiability condition, unlike the irrepresentability condition, does not seem to be affected by the structure of the correlations in theXmatrix.},
  archive      = {J_SJOS},
  author       = {Patrick J.C. Tardivel and Małgorzata Bogdan},
  doi          = {10.1111/sjos.12568},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1636-1668},
  shortjournal = {Scand. J. Statist.},
  title        = {On the sign recovery by least absolute shrinkage and selection operator, thresholded least absolute shrinkage and selection operator, and thresholded basis pursuit denoising},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust lasso-zero for sparse corruption and model selection
with missing covariates. <em>SJOS</em>, <em>49</em>(4), 1605–1635. (<a
href="https://doi.org/10.1111/sjos.12591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose Robust Lasso-Zero, an extension of the Lasso-Zero methodology, initially introduced for sparse linear models, to the sparse corruptions problem. We give theoretical guarantees on the sign recovery of the parameters for a slightly simplified version of the estimator, called Thresholded Justice Pursuit. The use of Robust Lasso-Zero is showcased for variable selection with missing values in the covariates. In addition to not requiring the specification of a model for the covariates, nor estimating their covariance matrix or the noise variance, the method has the great advantage of handling missing not-at random values without specifying a parametric model. Numerical experiments and a medical application underline the relevance of Robust Lasso-Zero in such a context with few available competitors. The method is easy to use and implemented in the R librarylass0.},
  archive      = {J_SJOS},
  author       = {Pascaline Descloux and Claire Boyer and Julie Josse and Aude Sportisse and Sylvain Sardy},
  doi          = {10.1111/sjos.12591},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1605-1635},
  shortjournal = {Scand. J. Statist.},
  title        = {Robust lasso-zero for sparse corruption and model selection with missing covariates},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multivariate quantiles with both overall and directional
probability interpretation. <em>SJOS</em>, <em>49</em>(4), 1586–1604.
(<a href="https://doi.org/10.1111/sjos.12603">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The article introduces multivariate quantiles (or reference regions) that have both overall and directional probability interpretation and need not be necessarily convex. They are defined by means of univariate conditional quantiles along the rays starting at a suitable central point. Their basic properties are investigated, their sample estimators and regression extensions are proposed, and their use is illustrated with both simulated and real data.},
  archive      = {J_SJOS},
  author       = {Daniel Hlubinka and Lukáš Kotík and Miroslav Šiman},
  doi          = {10.1111/sjos.12603},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1586-1604},
  shortjournal = {Scand. J. Statist.},
  title        = {Multivariate quantiles with both overall and directional probability interpretation},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Envelopes for censored quantile regression. <em>SJOS</em>,
<em>49</em>(4), 1562–1585. (<a
href="https://doi.org/10.1111/sjos.12602">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an efficient estimator for the coefficients in censored quantile regression using the envelope model. The envelope model uses dimension reduction techniques to identify material and immaterial components in the data, and forms the estimator based only on the material component, thus reducing the variability of estimation. We will demonstrate the guaranteed asymptotic efficiency gain of our proposed envelope estimator over the traditional estimator for censored quantile regression. Our analysis begins with the local weighing approach that traditionally relies on semiparametricZ$$ Z $$-estimation involving the conditional Kaplan–Meier estimator. We will instead invoke the independent identically distributed (i.i.d.) representation of the Kaplan–Meier estimator, which eliminates this infinite-dimensional nuisance and transforms our objective function inZ$$ Z $$-estimation into aU$$ U $$-process indexed by only an Euclidean parameter. The modifiedZ$$ Z $$-estimation problem becomes entirely parametric and hence more amenable to analysis. We will also reconsider the i.i.d. representation of the conditional Kaplan–Meier estimator.},
  archive      = {J_SJOS},
  author       = {Yue Zhao and Ingrid Van Keilegom and Shanshan Ding},
  doi          = {10.1111/sjos.12602},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1562-1585},
  shortjournal = {Scand. J. Statist.},
  title        = {Envelopes for censored quantile regression},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Two-part d-vine copula models for longitudinal insurance
claim data. <em>SJOS</em>, <em>49</em>(4), 1534–1561. (<a
href="https://doi.org/10.1111/sjos.12566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In short-term nonlife (e.g., car and homeowner) insurance, policies are renewed yearly. Insurance companies typically keep track of each policyholder&#39;s claims per year, resulting in longitudinal data. Efficient modeling of time dependence in longitudinal claim data will improve the prediction of future claims needed for routine actuarial practice, such as ratemaking. Insurance claim data usually follow a two-part mixed distribution: a probability mass at zero corresponding to no claim and an otherwise positive claim from a skewed and long-tailed distribution. This two-part data structure leads to difficulties in applying established models for longitudinal data. In this paper, we propose a two-part D-vine copula model to study longitudinal mixed claim data. We build two stationary D-vine copulas. One is used to model the time dependence in binary outcomes resulting from whether or not a claim has occurred. The other studies the dependence in the claim size given occurrence. Under the proposed model, the prediction of the probability of making claims and the quantiles of severity given occurrence is straightforward. We use our approach to investigate a dataset from the Local Government Property Insurance Fund in the state of Wisconsin.},
  archive      = {J_SJOS},
  author       = {Lu Yang and Claudia Czado},
  doi          = {10.1111/sjos.12566},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1534-1561},
  shortjournal = {Scand. J. Statist.},
  title        = {Two-part D-vine copula models for longitudinal insurance claim data},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust inference with censored survival data. <em>SJOS</em>,
<em>49</em>(4), 1496–1533. (<a
href="https://doi.org/10.1111/sjos.12570">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Randomly censored survival data appear in a wide variety of applications in which the time until the occurrence of a certain event is not completely observable. In this paper, we assume that the statistician observes a possibly censored survival time along with a censoring indicator. In this setting, we study a class of M-estimators with a bounded influence function, in the spirit of the infinitesimal approach to robustness. We outline the main asymptotic properties of the robust M-estimators and characterize the optimal B-robust estimator according to two possible measures of sensitivity. Building on these results, we define robust testing procedures which are natural counterparts to the classical Wald, score, and likelihood ratio tests. The empirical performance of our robust estimators and tests is assessed in two extensive simulation studies. An application to data from a well-known medical study on head and neck cancer is also presented.},
  archive      = {J_SJOS},
  author       = {Pierre-Yves Deléamont and Elvezio Ronchetti},
  doi          = {10.1111/sjos.12570},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1496-1533},
  shortjournal = {Scand. J. Statist.},
  title        = {Robust inference with censored survival data},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Asymptotic theory for the inference of the latent trawl
model for extreme values. <em>SJOS</em>, <em>49</em>(4), 1448–1495. (<a
href="https://doi.org/10.1111/sjos.12563">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article develops statistical inference methods and their asymptotic theory for the latent trawl model for extremes, which captures serial dependence in the time series of exceedances above a threshold. We review two methods based on pairwise likelihood and show that they underestimate the serial dependence in the extremes. We propose two generalized method of moments procedures based on auto-covariance matching to overcome this shortcoming. Out of those four inference approaches, two are single-stage strategies while the others have two stages, and we provide central limit theorems in the sense of weakly approaching sequences of distributions for all of them. This additional flexibility ensures good behavior between the estimators and estimates of the limiting distribution. In an empirical illustration using London air pollution data, we find that the two-stage auto-covariance matching scheme yields a high-quality inference. It comprises two interpretable steps and correctly captures the serial dependence structure of extremes while performing on par with other methods in terms of marginal fit.},
  archive      = {J_SJOS},
  author       = {Valentin Courgeau and Almut E.D. Veraart},
  doi          = {10.1111/sjos.12563},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1448-1495},
  shortjournal = {Scand. J. Statist.},
  title        = {Asymptotic theory for the inference of the latent trawl model for extreme values},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Large-scale covariate-assisted two-sample inference under
dependence. <em>SJOS</em>, <em>49</em>(4), 1421–1447. (<a
href="https://doi.org/10.1111/sjos.12608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problems of large-scale two-sample inference often arise from the statistical analysis of “high throughput&quot; data. Conventional multiple testing procedures usually suffer from loss of testing efficiency when conducting two-samplet$$ t $$-tests directly. To some extent, this is because of the ignorance of sparsity information. Moreover, the two-sample tests commonly have local correlations, and neglecting the dependence structure may decrease the statistical accuracy. Therefore, it is imperative to develop a procedure that considers both sparsity information and dependence structure among the tests. We start by introducing a novel dependence model to allow for sparsity information and dependence structure. Based on the dependence model, we propose a covariate-assisted local index of significance(COALIS)$$ \left(\mathbf{COALIS}\right) $$procedure and show that it is valid and optimal. Then a data-driven procedure is developed to mimic the oracle procedure. Both simulations and real data analysis show that theCOALISprocedure outperforms its competitors.},
  archive      = {J_SJOS},
  author       = {Pengfei Wang and Wensheng Zhu},
  doi          = {10.1111/sjos.12608},
  journal      = {Scandinavian Journal of Statistics},
  number       = {4},
  pages        = {1421-1447},
  shortjournal = {Scand. J. Statist.},
  title        = {Large-scale covariate-assisted two-sample inference under dependence},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Corrigendum to “on the unification of families of
skew-normal distributions” published in scand. J. Stat. Vol. 33,
pp. 561–574. <em>SJOS</em>, <em>49</em>(3), 1418–1419. (<a
href="https://doi.org/10.1111/sjos.12594">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SJOS},
  author       = {Reinaldo B. Arellano-Valle and Adelchi Azzalini},
  doi          = {10.1111/sjos.12594},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1418-1419},
  shortjournal = {Scand. J. Statist.},
  title        = {Corrigendum to “On the unification of families of skew-normal distributions” published in scand. j. stat. vol. 33, pp. 561–574},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Identification and estimation of threshold matrix-variate
factor models. <em>SJOS</em>, <em>49</em>(3), 1383–1417. (<a
href="https://doi.org/10.1111/sjos.12576">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the growing availability of complex time series observed in real applications, we propose a threshold matrix-variate factor model, which simultaneously addresses the sample-wise and time-wise complexities of a time series. The sample-wise complexity is characterized by modeling matrix-variate observations directly, while the time-wise complexity is modeled by a threshold variable to describe the nonlinearity in time series. The estimators for loading spaces and threshold values are introduced and their asymptotic properties are investigated. Our matrix-variate models compress data more efficiently than traditional vectorization-based models. Furthermore, we greatly extend the scope of current research on threshold factor models by removing several restrictive assumptions, including existence of only one threshold, fixed factor dimensions across different regimes, and stationarity within regime. Under the relaxed assumptions, the proposed estimators are consistent even when the numbers of factors are overestimated. Simulated and real examples are presented to illustrate the proposed methods.},
  archive      = {J_SJOS},
  author       = {Xialu Liu and Elynn Y. Chen},
  doi          = {10.1111/sjos.12576},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1383-1417},
  shortjournal = {Scand. J. Statist.},
  title        = {Identification and estimation of threshold matrix-variate factor models},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Uniform convergence rates for nonparametric estimators
smoothed by the beta kernel. <em>SJOS</em>, <em>49</em>(3), 1353–1382.
(<a href="https://doi.org/10.1111/sjos.12573">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides a set of uniform consistency results with rates for nonparametric density and regression estimators smoothed by the beta kernel having support on the unit interval. Weak and strong uniform convergence is explored on the basis of expanding compact sets and general sequences of smoothing parameters. The results in this paper are useful for asymptotic analysis of two-step semiparametric estimation using a first-step kernel estimate as a plug-in. We provide simulations and a real data example illustrating attractive properties of the estimators.},
  archive      = {J_SJOS},
  author       = {Masayuki Hirukawa and Irina Murtazashvili and Artem Prokhorov},
  doi          = {10.1111/sjos.12573},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1353-1382},
  shortjournal = {Scand. J. Statist.},
  title        = {Uniform convergence rates for nonparametric estimators smoothed by the beta kernel},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian nonparametric estimation in the current status
continuous mark model. <em>SJOS</em>, <em>49</em>(3), 1329–1352. (<a
href="https://doi.org/10.1111/sjos.12562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the current status continuous mark model where, if an event takes place before an inspection timeTa “continuous mark” variable is observed as well. A Bayesian nonparametric method is introduced for estimating the distribution function of the joint distribution of the event time (X) and mark variable (Y). We consider two histogram-type priors on the density of(X,Y). Our main result shows that under appropriate conditions, the posterior distribution function contracts pointwisely at raten/logn−ρ3(ρ+2)if the true density isρ-Hölder continuous. In addition to our theoretical results we provide efficient computational methods for drawing from the posterior relying on a noncentered parameterization and Crank–Nicolson updates. The performance of the proposed methods is illustrated in several numerical experiments.},
  archive      = {J_SJOS},
  author       = {Geurt Jongbloed and Frank H. van der Meulen and Lixue Pang},
  doi          = {10.1111/sjos.12562},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1329-1352},
  shortjournal = {Scand. J. Statist.},
  title        = {Bayesian nonparametric estimation in the current status continuous mark model},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiply robust estimators of causal effects for survival
outcomes. <em>SJOS</em>, <em>49</em>(3), 1304–1328. (<a
href="https://doi.org/10.1111/sjos.12561">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiply robust estimators of the longitudinal g-formula have recently been proposed to protect against model misspecification better than the standard augmented inverse probability weighted estimator (Rotnitzky et al., 2017; Luedtke et al., 2018). These multiply robust estimators ensure consistency if one of the models for the treatment process or outcome process is correctly specified at each time point. We study the multiply robust estimators of Rotnitzky et al. (2017) in the context of a survival outcome. Specifically, we compare various estimators of the g-formula for survival outcomes in order to (1) understand how the estimators may be related to one another, (2) understand each estimator&#39;s robustness to model misspecification, and (3) construct estimators that can be more efficient than others in certain model misspecification scenarios. We propose a modification of the multiply robust estimators to gain efficiency under misspecification of the outcome model by using calibrated propensity scores over non-calibrated propensity scores at each time point. Theoretical results are confirmed via simulation studies, and a practical comparison of these estimators is conducted through an application to the US Veterans Aging Cohort Study.},
  archive      = {J_SJOS},
  author       = {Lan Wen and Miguel A. Hernán and James M. Robins},
  doi          = {10.1111/sjos.12561},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1304-1328},
  shortjournal = {Scand. J. Statist.},
  title        = {Multiply robust estimators of causal effects for survival outcomes},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interactions and computer experiments. <em>SJOS</em>,
<em>49</em>(3), 1274–1303. (<a
href="https://doi.org/10.1111/sjos.12560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying interactions and understanding the underlying generating mechanism is essential for interpreting the response of black-box models. We offer a systematic analysis of interaction types and corresponding sources, merging results of the broad statistical literature with findings developed within the computer experiment literature. Piecewise-definiteness emerges a self-standing interaction mechanism, alternative to the presence of interaction terms. We find that the scale of the analysis is essential for interpretation, and that no single method is capable of providing the correct identification of the underlying interaction generating mechanisms; conversely a combined approach involving indicators at difference scales is required. We propose a graphical tool called Mikado plot that exploits the link between interaction indicators at the finite scale and global scales to ease the regional visualization of two-factor interactions. The findings are illustrated via numerical experiments with three well-known computer models of different dimensionality and structure.},
  archive      = {J_SJOS},
  author       = {Emanuele Borgonovo and Elmar Plischke and Giovanni Rabitti},
  doi          = {10.1111/sjos.12560},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1274-1303},
  shortjournal = {Scand. J. Statist.},
  title        = {Interactions and computer experiments},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A solution to a linear integral equation with an application
to statistics of infinitely divisible moving averages. <em>SJOS</em>,
<em>49</em>(3), 1244–1273. (<a
href="https://doi.org/10.1111/sjos.12553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a stationary moving average random field, a nonparametric low frequency estimator of the Lévy density of its infinitely divisible independently scattered integrator measure is given. The plug-in estimate is based on the solutionwof the linear integral equationv(x)=∫ℝdg(s)w(h(s)x)ds, whereg,h:ℝd→ℝare given measurable functions andvis a (weighted)L2-function onℝ. We investigate conditions for the existence and uniqueness of this solution and giveL2-error bounds for the resulting estimates. An application to pure jump moving averages and a simulation study round off the paper.},
  archive      = {J_SJOS},
  author       = {Jochen Glück and Stefan Roth and Evgeny Spodarev},
  doi          = {10.1111/sjos.12553},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1244-1273},
  shortjournal = {Scand. J. Statist.},
  title        = {A solution to a linear integral equation with an application to statistics of infinitely divisible moving averages},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tests of multivariate copula exchangeability based on lévy
measures. <em>SJOS</em>, <em>49</em>(3), 1215–1243. (<a
href="https://doi.org/10.1111/sjos.12557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces tests for the symmetry of the copula of random vector. The proposed statistics are based on the copula characteristic function and the weight function that appears naturally in their definition are assumed to belong to the general family of Lévy measures. The proposed test statistics are rank-based and expresses as weightedL2-norms computed from a vector of empirical copula characteristic functions. Their nondegenerate asymptotic distributions under the null hypothesis and general alternatives, as well as the validity of a multiplier bootstrap for the computation ofp-values, are derived using nonstandard arguments. Extended Monte–Carlo experiments show that the new tests hold their size well and are powerful against a wide range of alternatives, and appear to be more powerful than a Cramér–von Mises test based on empirical copulas.},
  archive      = {J_SJOS},
  author       = {Tarik Bahraoui and Jean-François Quessy},
  doi          = {10.1111/sjos.12557},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1215-1243},
  shortjournal = {Scand. J. Statist.},
  title        = {Tests of multivariate copula exchangeability based on lévy measures},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sequential change point tests based on u-statistics.
<em>SJOS</em>, <em>49</em>(3), 1184–1214. (<a
href="https://doi.org/10.1111/sjos.12558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a general framework of sequential testing procedures based onU-statistics which contains as an example a sequential CUSUM test based on differences in mean but also includes a robust sequential Wilcoxon change point procedure. Within this framework, we consider several monitoring schemes that take different observations into account to make a decision at a given time point. Unlike the originally proposed scheme that takes all observations of the monitoring period into account, we also consider a modified moving-sum-version as well as a version of a Page-monitoring scheme. The latter behave almost as good for early changes while being advantageous for later changes. For all proposed procedures we provide the limit distribution under the null hypothesis of no change which yields the threshold to control the global false alarm rate asymptotically. Furthermore, we show that the proposed tests have asymptotic power one. In a simulation study we compare the performance of the sequential procedures via their empirical size, power and detection delay, which is further illustrated by means of a temperature data set.},
  archive      = {J_SJOS},
  author       = {Claudia Kirch and Christina Stoehr},
  doi          = {10.1111/sjos.12558},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1184-1214},
  shortjournal = {Scand. J. Statist.},
  title        = {Sequential change point tests based on U-statistics},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Copula measures and sklar’s theorem in arbitrary dimensions.
<em>SJOS</em>, <em>49</em>(3), 1144–1183. (<a
href="https://doi.org/10.1111/sjos.12559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although copulas are used and defined for various infinite-dimensional objects (e.g., Gaussian processes and Markov processes), there is no prevalent notion of a copula that unifies these concepts. We propose a unified functional analytic framework, show how Sklar&#39;s theorem can be applied in certain examples of Banach spaces and provide a semiparametric estimation procedure for second-order stochastic processes with underlying Gaussian copula.},
  archive      = {J_SJOS},
  author       = {Fred Espen Benth and Giulia Di Nunno and Dennis Schroers},
  doi          = {10.1111/sjos.12559},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1144-1183},
  shortjournal = {Scand. J. Statist.},
  title        = {Copula measures and sklar&#39;s theorem in arbitrary dimensions},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Large spatial data modeling and analysis: A krylov subspace
approach. <em>SJOS</em>, <em>49</em>(3), 1115–1143. (<a
href="https://doi.org/10.1111/sjos.12555">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating the parameters of spatial models for large spatial datasets can be computationally challenging, as it involves repeated evaluation of sizable spatial covariance matrices. In this paper, we aim to develop Krylov subspace-based methods that are computationally efficient for large spatial data. Specifically, we approximate the inverse and the log-determinant of the spatial covariance matrix in the log-likelihood function via conjugate gradient and stochastic Lanczos on a Krylov subspace. These methods reduce the computational complexity fromO(N3)toO(N2logN)andO(NlogN)for dense and sparse matrices, respectively. Moreover, we quantify the difference between the approximated log-likelihood function and the original log-likelihood function and establish the consistency of parameter estimates. Simulation studies are conducted to examine the computational efficiency as well as the finite-sample properties. For illustration, our methodology is applied to analyze a large dataset comprising LiDAR estimates of forest canopy height in western Alaska.},
  archive      = {J_SJOS},
  author       = {Jialuo Liu and Tingjin Chu and Jun Zhu and Haonan Wang},
  doi          = {10.1111/sjos.12555},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1115-1143},
  shortjournal = {Scand. J. Statist.},
  title        = {Large spatial data modeling and analysis: A krylov subspace approach},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Approximate maximum likelihood estimation for
one-dimensional diffusions observed on a fine grid. <em>SJOS</em>,
<em>49</em>(3), 1085–1114. (<a
href="https://doi.org/10.1111/sjos.12556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a one-dimensional stochastic differential equation that is observed on a fine grid of equally spaced time points. A novel approach for approximating the transition density of the stochastic differential equation is presented, which is based on an Itô-Taylor expansion of the sample path, combined with an application of the so-calledϵ-expansion. The resulting approximation is economical with respect to the number of terms needed to achieve a given level of accuracy in a high-frequency sampling framework. This method of density approximation leads to a closed-form approximate likelihood function from which an approximate maximum likelihood estimator may be calculated numerically. A detailed theoretical analysis of the proposed estimator is provided and it is shown that it compares favorably to the Gaussian likelihood-based estimator and does an excellent job of approximating the exact, but usually intractable, maximum likelihood estimator. Numerical simulations indicate that the exact and our approximate maximum likelihood estimator tend to be close, and the latter performs very well relative to other approximate methods in the literature in terms of speed, accuracy, and ease of implementation.},
  archive      = {J_SJOS},
  author       = {Kevin W. Lu and Phillip J. Paine and Simon P. Preston and Andrew T. A. Wood},
  doi          = {10.1111/sjos.12556},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1085-1114},
  shortjournal = {Scand. J. Statist.},
  title        = {Approximate maximum likelihood estimation for one-dimensional diffusions observed on a fine grid},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient spatial designs using hausdorff distances and
bayesian optimization. <em>SJOS</em>, <em>49</em>(3), 1060–1084. (<a
href="https://doi.org/10.1111/sjos.12554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An iterative Bayesian optimization technique is presented to find spatial designs of data that carry much information. We use the decision theoretic notion of value of information as the design criterion. Gaussian process surrogate models enable fast calculations of expected improvement for a large number of designs, while the full-scale value of information evaluations are only done for the most promising designs. The Hausdorff distance is used to model the similarity between designs in the surrogate Gaussian process covariance representation, and this allows the suggested algorithm to learn across different designs. We study properties of the Bayesian optimization design algorithm in a synthetic example and real-world examples from forest conservation and petroleum drilling operations. In the synthetic example we consider a model where the exact solution is available and we run the algorithm under different versions of this example and compare it with existing approaches such as sequential selection and an exchange algorithm.},
  archive      = {J_SJOS},
  author       = {Jacopo Paglia and Jo Eidsvik and Juha Karvanen},
  doi          = {10.1111/sjos.12554},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1060-1084},
  shortjournal = {Scand. J. Statist.},
  title        = {Efficient spatial designs using hausdorff distances and bayesian optimization},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Maximum composite likelihood estimation for spatial extremes
models of brown–resnick type with application to precipitation data.
<em>SJOS</em>, <em>49</em>(3), 1023–1059. (<a
href="https://doi.org/10.1111/sjos.12551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we consider the maximum composite likelihood estimator for spatial extremes model class of Brown–Resnick type. The composite likelihood is constructed based on the weighted tail empirical process. It is shown that the proposed estimator is consistent and asymptotically normal under some regularity conditions fulfilled by the model class. We conduct Monte Carlo simulations to evaluate the estimator and apply it to the analysis of a precipitation data set.},
  archive      = {J_SJOS},
  author       = {Moosup Kim and Sangyeol Lee},
  doi          = {10.1111/sjos.12551},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {1023-1059},
  shortjournal = {Scand. J. Statist.},
  title        = {Maximum composite likelihood estimation for spatial extremes models of Brown–Resnick type with application to precipitation data},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Vector-valued generalized ornstein–uhlenbeck processes:
Properties and parameter estimation. <em>SJOS</em>, <em>49</em>(3),
992–1022. (<a href="https://doi.org/10.1111/sjos.12552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalizations of the Ornstein–Uhlenbeck process defined through Langevin equations, such as fractional Ornstein–Uhlenbeck processes, have recently received a lot of attention. However, most of the literature focuses on the one-dimensional case with Gaussian noise. In particular, estimation of the unknown parameter is widely studied under Gaussian stationary increment noise. In this article, we consider estimation of the unknown model parameter in the multidimensional version of the Langevin equation, where the parameter is a matrix and the noise is a general, not necessarily Gaussian, vector-valued process with stationary increments. Based on algebraic Riccati equations, we construct an estimator for the parameter matrix. Moreover, we prove the consistency of the estimator and derive its limiting distribution under natural assumptions. In addition, to motivate our work, we prove that the Langevin equation characterizes essentially all multidimensional stationary processes.},
  archive      = {J_SJOS},
  author       = {Marko Voutilainen and Lauri Viitasaari and Pauliina Ilmonen and Soledad Torres and Ciprian Tudor},
  doi          = {10.1111/sjos.12552},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {992-1022},
  shortjournal = {Scand. J. Statist.},
  title        = {Vector-valued generalized Ornstein–Uhlenbeck processes: Properties and parameter estimation},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improper priors and improper posteriors. <em>SJOS</em>,
<em>49</em>(3), 969–991. (<a
href="https://doi.org/10.1111/sjos.12550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {What is a good prior? Actual prior knowledge should be used, but for complex models this is often not easily available. The knowledge can be in the form of symmetry assumptions, and then the choice will typically be an improper prior. Also more generally, it is quite common to choose improper priors. Motivated by this we consider a theoretical framework for statistics that includes both improper priors and improper posteriors. Knowledge is then represented by a possibly unbounded measure with interpretation as explained by Rényi in 1955. The main mathematical result here is a constructive proof of existence of a transformation from prior to posterior knowledge. The posterior always exists and is uniquely defined by the prior, the observed data, and the statistical model. The transformation is, as it should be, an extension of conventional Bayesian inference as defined by the axioms of Kolmogorov. It is an extension since the novel construction is valid also when replacing the axioms of Kolmogorov by the axioms of Rényi for a conditional probability space. A concrete case based on Markov Chain Monte Carlo simulations and data for different species of tropical butterflies illustrate that an improper posterior may appear naturally and is useful. The theory is also exemplified by more elementary examples.},
  archive      = {J_SJOS},
  author       = {Gunnar Taraldsen and Jarle Tufto and Bo H. Lindqvist},
  doi          = {10.1111/sjos.12550},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {969-991},
  shortjournal = {Scand. J. Statist.},
  title        = {Improper priors and improper posteriors},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Conditional monte carlo revisited. <em>SJOS</em>,
<em>49</em>(3), 943–968. (<a
href="https://doi.org/10.1111/sjos.12549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conditional Monte Carlo refers to sampling from the conditional distribution of a random vectorXgiven the valueT(X)=tfor a functionT(X). Classical conditional Monte Carlo methods were designed for estimating conditional expectations of functionsϕ(X)by sampling from unconditional distributions obtained by certain weighting schemes. The basic ingredients were the use of importance sampling and change of variables. In the present paper we reformulate the problem by introducing an artificial parametric model in whichXis a pivotal quantity, and next representing the conditional distribution ofXgivenT(X)=twithin this new model. The approach is illustrated by several examples, including a short simulation study and an application to goodness-of-fit testing of real data. The connection to a related approach based on sufficient statistics is briefly discussed.},
  archive      = {J_SJOS},
  author       = {Bo H. Lindqvist and Rasmus Erlemann and Gunnar Taraldsen},
  doi          = {10.1111/sjos.12549},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {943-968},
  shortjournal = {Scand. J. Statist.},
  title        = {Conditional monte carlo revisited},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ultrahigh-dimensional generalized additive model: Unified
theory and methods. <em>SJOS</em>, <em>49</em>(3), 917–942. (<a
href="https://doi.org/10.1111/sjos.12548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalized additive model is a powerful statistical learning and predictive modeling tool that has been applied in a wide range of applications. The need of high-dimensional additive modeling is eminent in the context of dealing with high throughput data such as genetics data analysis. In this article, we studied a two-step selection and estimation method for ultrahigh-dimensional generalized additive models. The first step applies group lasso on the expanded bases of the functions. With high probability this selects all nonzero functions without having too much over selection. The second step uses adaptive group lasso with any initial estimators, including the group lasso estimator, that satisfies some regular conditions. The adaptive group lasso estimator is shown to be selection consistent with improved convergence rates. Tuning parameter selection is also discussed and shown to select the true model consistently under generalized information criterion procedure. The theoretical properties are supported by extensive numerical study.},
  archive      = {J_SJOS},
  author       = {Kaixu Yang and Tapabrata Maiti},
  doi          = {10.1111/sjos.12548},
  journal      = {Scandinavian Journal of Statistics},
  number       = {3},
  pages        = {917-942},
  shortjournal = {Scand. J. Statist.},
  title        = {Ultrahigh-dimensional generalized additive model: Unified theory and methods},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bivariate change point detection: Joint detection of changes
in expectation and variance. <em>SJOS</em>, <em>49</em>(2), 886–916. (<a
href="https://doi.org/10.1111/sjos.12547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A method for change point detection is proposed. We consider a univariate sequence of independent random variables with piecewise constant expectation and variance, apart from which the distribution may vary periodically. We aim to detect change points in both expectation and variance. For that, we propose a statistical test for the null hypothesis of no change points and an algorithm for change point detection. Both are based on a bivariate moving sum approach that jointly evaluates the mean and the empirical variance. The joint consideration helps improve inference compared with separate univariate approaches. We infer on the strength and the type of changes with confidence. Nonparametric methodology supports the analysis of diverse data. Additionally, a multiscale approach addresses complex patterns in change points and effects. We demonstrate the performance through theoretical results and simulation studies. A companionR-packagejcp(available on CRAN) is discussed.},
  archive      = {J_SJOS},
  author       = {Michael Messer},
  doi          = {10.1111/sjos.12547},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {886-916},
  shortjournal = {Scand. J. Statist.},
  title        = {Bivariate change point detection: Joint detection of changes in expectation and variance},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multistate analysis of multitype recurrent event and failure
time data with event feedbacks in biomarkers. <em>SJOS</em>,
<em>49</em>(2), 864–885. (<a
href="https://doi.org/10.1111/sjos.12545">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose a class of multistate models for the analysis of multitype recurrent event and failure time data when there are past event feedbacks in longitudinal biomarkers. It can well incorporate various effects, including time-dependent and time-independent effects, of different event paths or the number of occurrences of events of different types. Asymptotic unbiased estimating equations based on polynomial splines approximation are developed. The consistency and asymptotic normality of the proposed estimators are provided. Simulation studies show that the naive estimators which either ignore the past event feedback or the measurement errors are biased. Our method has a better coverage probability of the time-varying/constant coefficients, compared to the naive methods. An application to the dataset from the Atherosclerosis Risk in Communities Study, which is also the motivating example to develop the method, is presented.},
  archive      = {J_SJOS},
  author       = {Chuoxin Ma and Jianxin Pan},
  doi          = {10.1111/sjos.12545},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {864-885},
  shortjournal = {Scand. J. Statist.},
  title        = {Multistate analysis of multitype recurrent event and failure time data with event feedbacks in biomarkers},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving lasso for model selection and prediction.
<em>SJOS</em>, <em>49</em>(2), 831–863. (<a
href="https://doi.org/10.1111/sjos.12546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is known that the Thresholded Lasso (TL), SCAD or MCP correct intrinsic estimation bias of the Lasso. In this paper we propose an alternative method of improving the Lasso for predictive models with general convex loss functions which encompass normal linear models, logistic regression, quantile regression, or support vector machines. For a given penalty we order the absolute values of the Lasso nonzero coefficients and then select the final model from a small nested family by the Generalized Information Criterion. We derive exponential upper bounds on the selection error of the method. These results confirm that, at least for normal linear models, our algorithm seems to be the benchmark for the theory of model selection as it is constructive, computationally efficient and leads to consistent model selection under weak assumptions. Constructivity of the algorithm means that, in contrast to the TL, SCAD or MCP, consistent selection does not rely on the unknown parameters as the cone invertibility factor. Instead, our algorithm only needs the sample size, the number of predictors and an upper bound on the noise parameter. We show in numerical experiments on synthetic and real-world datasets that an implementation of our algorithm is more accurate than implementations of studied concave regularizations. Our procedure is included in the R packageDMRnetand available in the CRAN repository.},
  archive      = {J_SJOS},
  author       = {Piotr Pokarowski and Wojciech Rejchel and Agnieszka Sołtys and Michał Frej and Jan Mielniczuk},
  doi          = {10.1111/sjos.12546},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {831-863},
  shortjournal = {Scand. J. Statist.},
  title        = {Improving lasso for model selection and prediction},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cramér-von mises tests for change points. <em>SJOS</em>,
<em>49</em>(2), 802–830. (<a
href="https://doi.org/10.1111/sjos.12544">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study two nonparametric tests of the hypothesis that a sequence of independent observations is identically distributed against the alternative that at a single change point the distribution changes. The tests are based on the Cramér–von Mises two-sample test computed at every possible change point. One test uses the largest such test statistic over all possible change points; the other averages over all possible change points. Large sample theory for the average statistic is shown to provide usefulp-values much more quickly than bootstrapping, particularly in long sequences. Power is analyzed for contiguous alternatives. The average statistic is shown to have limiting power larger than its level for such alternative sequences. Evidence is presented that this is not true for the maximal statistic. Asymptotic methods and bootstrapping are used for constructing the test distribution. Performance of the tests is checked with a Monte Carlo power study for various alternative distributions.},
  archive      = {J_SJOS},
  author       = {Rasmus Erlemann and Richard Lockhart and Rihan Yao},
  doi          = {10.1111/sjos.12544},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {802-830},
  shortjournal = {Scand. J. Statist.},
  title        = {Cramér-von mises tests for change points},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generalized linear model for subordinated lévy processes.
<em>SJOS</em>, <em>49</em>(2), 772–801. (<a
href="https://doi.org/10.1111/sjos.12538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalized linear models, introduced by Nelder and Wedderburn, allowed to model the regression of normal and nonnormal data. While doing so, the analysis of these models could not be obtained without the explicit form of the variance function. In this paper, we determine the link and variance functions of the natural exponential family generated by the class of subordinated Lévy processes. In this framework, we introduce a class of variance functions that depends on the Lambert function. In this regard, we call it the Lambert class, which covers the variance functions of the natural exponential families generated by the subordinated gamma processes and the subordinated Lévy processes by the Poisson subordinator. Notice that the gamma process subordinated by the Poisson one is excluded from this class. The concept of reciprocity in natural exponential families was given in order to obtain an exponential family from another one. In this context, we get the reciprocal class of the natural exponential family generated by the class of subordinated Lévy processes. It is well known that the variance function represents an essential element for the determination of the quasi-likelihood and deviance functions. Then, we use the expression of our variance function in order to maintain them. This leads us to analyze the proposed generalized linear model. We illustrate some of our models with applications to the daily exchange rate returns of the Tunisian Dinar against the U.S. Dollar and the damage incidents of ships.},
  archive      = {J_SJOS},
  author       = {Farouk Mselmi},
  doi          = {10.1111/sjos.12538},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {772-801},
  shortjournal = {Scand. J. Statist.},
  title        = {Generalized linear model for subordinated lévy processes},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient inference of longitudinal/functional data models
with time-varying additive structure. <em>SJOS</em>, <em>49</em>(2),
744–771. (<a href="https://doi.org/10.1111/sjos.12540">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the analysis of longitudinal or functional data, a time-varying additive model (tvAM) has been introduced that is effective at avoiding the curse of dimensionality and capturing dynamic features. The present article focuses on the unified two-step estimators of a tvAM with sparse or dense longitudinal or functional data. It is proved that the two-step estimators have the same asymptotic distribution as that of oracle estimators. Furthermore, a unified convergence theory is established, based on which a unified inference is proposed without deciding whether the data are sparse or dense. Also, a testing statistic that can adapt to the sparse and dense cases in a unified framework is proposed to check whether the bivariate nonparametric functions are time varying, and the asymptotic distribution of the proposed test statistic is derived. Simulation studies are conducted to assess the finite-sample performance of the proposed model and methods, and two different types of data are considered to illustrate the proposed method.},
  archive      = {J_SJOS},
  author       = {Qian Huang and Jinhong You and Liwen Zhang},
  doi          = {10.1111/sjos.12540},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {744-771},
  shortjournal = {Scand. J. Statist.},
  title        = {Efficient inference of longitudinal/functional data models with time-varying additive structure},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The role of propensity score structure in asymptotic
efficiency of estimated conditional quantile treatment effect.
<em>SJOS</em>, <em>49</em>(2), 718–743. (<a
href="https://doi.org/10.1111/sjos.12539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When a strict subset of covariates is given, we propose conditional quantile treatment effect (CQTE) to offer, compared with the unconditional quantile treatment effect (QTE) and conditional average treatment effect (CATE), a more complete and informative view of the heterogeneity of treatment effects via the quantile sheet that is a function of the given covariates and quantile levels. Even though either one or bothQTEandCATEare not significant,CQTEcould still show some impact of the treatment on the upper and lower tails of subpopulations&#39; (defined by the covariates subset) distribution. To the best of our knowledge, this is the first to consider such a low-dimensional conditional quantile treatment effect in the literature. We focus on deriving the asymptotic normality of propensity score-based estimators under parametric, nonparametric, and semiparametric structure. We make a systematic study on the estimation efficiency to check the importance of propensity score structure and the essential differences from the unconditional counterparts. The derived unique properties can answer: what is the general ranking of these estimators? how does the affiliation of the given covariates to the set of covariates of the propensity score affect the efficiency? how does the convergence rate of the estimated propensity score affect the efficiency? and why would semiparametric estimation be worth of recommendation in practice? The simulation studies are conducted to examine the performances of these estimators. A real data example is analyzed for illustration and some new findings are acquired.},
  archive      = {J_SJOS},
  author       = {Niwen Zhou and Xu Guo and Lixing Zhu},
  doi          = {10.1111/sjos.12539},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {718-743},
  shortjournal = {Scand. J. Statist.},
  title        = {The role of propensity score structure in asymptotic efficiency of estimated conditional quantile treatment effect},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Moment-based estimation for the multivariate COGARCH(1,1)
process. <em>SJOS</em>, <em>49</em>(2), 681–717. (<a
href="https://doi.org/10.1111/sjos.12531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the multivariate COGARCH process, we obtain explicit expressions for the second-order structure of the “squared returns” process observed on an equidistant grid. Based on this, we present a generalized method of moments estimator for its parameters. Under appropriate moment and strong mixing conditions, we show that the resulting estimator is consistent and asymptotically normal. Sufficient conditions for strong mixing, stationarity and identifiability of the model parameters are discussed in detail. We investigate the finite sample behavior of the estimator in a simulation study.},
  archive      = {J_SJOS},
  author       = {Thiago do Rêgo Sousa and Robert Stelzer},
  doi          = {10.1111/sjos.12531},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {681-717},
  shortjournal = {Scand. J. Statist.},
  title        = {Moment-based estimation for the multivariate COGARCH(1,1) process},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An n-dimensional rosenbrock distribution for markov chain
monte carlo testing. <em>SJOS</em>, <em>49</em>(2), 657–680. (<a
href="https://doi.org/10.1111/sjos.12532">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Rosenbrock function is a ubiquitous benchmark problem in numerical optimization, and variants have been proposed to test the performance of Markov chain Monte Carlo algorithms on distributions with a curved and narrow shape. In this work we discuss the Rosenbrock distribution and the advantages and limitations of its currentn-dimensional extensions. We then propose a new extension to arbitrary dimensions called the Hybrid Rosenbrock distribution, which addresses all the limitations that affect the current extensions. The Hybrid Rosenbrock distribution is composed of conditional normal kernels arranged in such a way that preserves the key features of the original Rosenbrock kernel. Moreover, due to its structure, the Hybrid Rosenbrock distribution is analytically tractable, and possesses several desirable properties which make it an excellent test model for computational algorithms. We conclude with numerical experiments that show how commonly used Markov chain Monte Carlo algorithms may fail to explore densities with curved correlation structure, restating the importance of a reliable benchmark problem for this class of densities.},
  archive      = {J_SJOS},
  author       = {Filippo Pagani and Martin Wiegand and Saralees Nadarajah},
  doi          = {10.1111/sjos.12532},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {657-680},
  shortjournal = {Scand. J. Statist.},
  title        = {An n-dimensional rosenbrock distribution for markov chain monte carlo testing},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Combining information across diverse sources: The II-CC-FF
paradigm. <em>SJOS</em>, <em>49</em>(2), 625–656. (<a
href="https://doi.org/10.1111/sjos.12530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce and develop a general paradigm for combining information across diverse data sources. In broad terms, supposeφis a parameter of interest, built up via componentsψ1,…,ψkfrom data sources 1, … ,k. The proposed scheme has three steps. First, the independent inspection (II) step amounts to investigating each separate data source, translating statistical information to a confidence distribution (CD)Cj(ψj)for the relevant focus parameterψjassociated with data sourcej. Second, confidence conversion (CC) techniques are used to translate the CDs to confidence log-likelihood functions. Finally, the focused fusion (FF) step uses relevant and context-driven techniques to construct a confidence distribution for the primary focus parameterφ=φ(ψ1,…,ψk), acting on the combined confidence log-likelihood. In traditional setups, the II-CC-FF strategy amounts to versions of meta-analysis, and turns out to be competitive against state-of-the-art methods. Its potential lies in applications to harder problems, however. Illustrations are presented, related to actual applications.},
  archive      = {J_SJOS},
  author       = {Céline Cunen and Nils Lid Hjort},
  doi          = {10.1111/sjos.12530},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {625-656},
  shortjournal = {Scand. J. Statist.},
  title        = {Combining information across diverse sources: The II-CC-FF paradigm},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multidimensional parameter estimation of heavy-tailed moving
averages. <em>SJOS</em>, <em>49</em>(2), 593–624. (<a
href="https://doi.org/10.1111/sjos.12527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article we present a parametric estimation method for certain multiparameter heavy-tailed Lévy-driven moving averages. The theory relies on recent multivariate central limit theorems obtained via Malliavin calculus on Poisson spaces. Our minimal contrast approach is related to previous papers, which propose to use the marginal empirical characteristic function to estimate the one-dimensional parameter of the kernel function and the stability index of the driving Lévy motion. We extend their work to allow for a multiparametric framework that in particular includes the important examples of the linear fractional stable motion, the stable Ornstein–Uhlenbeck process, certain CARMA(2, 1) models, and Ornstein–Uhlenbeck processes with a periodic component among other models. We present both the consistency and the associated central limit theorem of the minimal contrast estimator. Furthermore, we demonstrate numerical analysis to uncover the finite sample performance of our method.},
  archive      = {J_SJOS},
  author       = {Mathias Mørck Ljungdahl and Mark Podolskij},
  doi          = {10.1111/sjos.12527},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {593-624},
  shortjournal = {Scand. J. Statist.},
  title        = {Multidimensional parameter estimation of heavy-tailed moving averages},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The negative binomial process: A tractable model with
composite likelihood-based inference. <em>SJOS</em>, <em>49</em>(2),
568–592. (<a href="https://doi.org/10.1111/sjos.12528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a log-linear Poisson regression model driven by a stationary latent gamma autoregression. This process has negative binomial (NB) marginals to analyze overdispersed count time series data. Estimation and statistical inference are performed using a composite (CL) likelihood function. We establish theoretical properties of the proposed count model, in particular, the strong consistency and asymptotic normality of the maximum CL estimator. A procedure for calculating the standard error of the parameter estimator and confidence intervals is derived based on the parametric bootstrap. Monte Carlo experiments were conducted to study and compare the finite-sample properties of the proposed estimators. The simulations demonstrate that, compared with the approach that combines generalized linear models with the ordinary least squares method, the proposed composite likelihood approach provides satisfactory results for estimating the parameters related to the correlation structure of the process, even under model misspecification. An empirical illustration of the NB process is presented for the monthly number of viral hepatitis cases in Goiânia (capital and largest city of the Brazilian state of Goiás) from January 2001 to December 2018.},
  archive      = {J_SJOS},
  author       = {Wagner Barreto-Souza and Hernando Ombao},
  doi          = {10.1111/sjos.12528},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {568-592},
  shortjournal = {Scand. J. Statist.},
  title        = {The negative binomial process: A tractable model with composite likelihood-based inference},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Factorized estimation of high-dimensional nonparametric
covariance models. <em>SJOS</em>, <em>49</em>(2), 542–567. (<a
href="https://doi.org/10.1111/sjos.12529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimation of covariate-dependent conditional covariance matrix in a high-dimensional space poses a challenge to contemporary statistical research. The existing kernel estimators may not be locally adaptive due to using a single bandwidth to explore the smoothness of all entries of the target matrix function. In this paper, we propose a novel framework to address this issue, where we factorize the target matrix into factors and estimate these factors in turn by the kernel approach. The resulting estimator is further regularized by thresholding and optimal shrinkage. Under certain mixing and sparsity conditions, we show that the proposed estimator is well-conditioned and uniformly consistent with the underlying matrix function even when the sample is dependent. Simulation studies suggest that the proposed estimator significantly outperforms its competitors in terms of integrated root-squared estimation error. We present an application to financial return data.},
  archive      = {J_SJOS},
  author       = {Jian Zhang and Jie Li},
  doi          = {10.1111/sjos.12529},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {542-567},
  shortjournal = {Scand. J. Statist.},
  title        = {Factorized estimation of high-dimensional nonparametric covariance models},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficiency of naive estimators for accelerated failure time
models under length-biased sampling. <em>SJOS</em>, <em>49</em>(2),
525–541. (<a href="https://doi.org/10.1111/sjos.12526">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In prevalent cohort studies where subjects are recruited at a cross-section, the time to an event may be subject to length-biased sampling, with the observed data being either the forward recurrence time, or the backward recurrence time, or their sum. In the regression setting, assuming a semiparametric accelerated failure time model for the underlying event time, where the intercept parameter is absorbed into the nuisance parameter, it has been shown that the model remains invariant under these observed data setups and can be fitted using standard methodology for accelerated failure time model estimation, ignoring the length bias. However, the efficiency of these estimators is unclear, owing to the fact that the observed covariate distribution, which is also length biased, may contain information about the regression parameter in the accelerated life model. We demonstrate that if the true covariate distribution is completely unspecified, then the naive estimator based on the conditional likelihood given the covariates is fully efficient for the slope.},
  archive      = {J_SJOS},
  author       = {Pourab Roy and Jason P. Fine and Michael R. Kosorok},
  doi          = {10.1111/sjos.12526},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {525-541},
  shortjournal = {Scand. J. Statist.},
  title        = {Efficiency of naive estimators for accelerated failure time models under length-biased sampling},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Conditional distribution regression for functional
responses. <em>SJOS</em>, <em>49</em>(2), 502–524. (<a
href="https://doi.org/10.1111/sjos.12525">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling conditional distributions for functional data extends the concept of a mean response in functional regression settings, where vector predictors are paired with functional responses. This extension is challenging because of the nonexistence of well-defined densities, cumulative distributions, or quantile functions in the Hilbert space where the response functions are located. To address this challenge, we simplify the problem by assuming that the response functions are Gaussian processes, which means that the conditional distribution of the responses is determined by conditional mean and conditional covariance. We demonstrate that these quantities can be obtained by applying global and local Fréchet regression, where the local version is more flexible and applicable when the covariate dimension is low and covariates are continuous, while the global version is not subject to these restrictions but is based on the assumption of a more restrictive regression relation. Convergence rates for the proposed estimates are obtained under the framework of M-estimation. The corresponding estimation of conditional distributions is illustrated with simulations and an application to bike-sharing data, where predictors include weather characteristics and responses are bike rental profiles. We also show that our methods are applicable to the challenging problem to study functional fragments. Such data are observed in accelerated longitudinal studies and correspond to functional data observed over short domain segments. We demonstrate the utility of conditional distributions in this context by using the time (age) at which a subject enters the domain of a fragment in addition to other covariates as predictor and the function observed over the domain of the fragment as response.},
  archive      = {J_SJOS},
  author       = {Jianing Fan and Hans-Georg Müller},
  doi          = {10.1111/sjos.12525},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {502-524},
  shortjournal = {Scand. J. Statist.},
  title        = {Conditional distribution regression for functional responses},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient estimation via envelope chain in magnetic
resonance imaging-based studies. <em>SJOS</em>, <em>49</em>(2), 481–501.
(<a href="https://doi.org/10.1111/sjos.12522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic resonance imaging (MRI) is a technique that scans the anatomical structure of the brain, whereas functional magnetic resonance imaging (fMRI) uses the same basic principles of atomic physics as MRI scans but image metabolic function. A major goal of MRI and fMRI study is to precisely delineate various types of tissues, anatomical structure, pathologies, and detect the brain regions that react to outer stimuli (e.g., viewing an image). As a key feature of these MRI-based neuroimaging data, voxels (cubic pixels of the brain volume) are highly correlated. However, the associations between voxels are often overlooked in the statistical analysis. We adapt a recently proposed dimension reduction method called the envelope method to analyze neuoimaging data taking into account correlation among voxels. We refer to the modified procedure the envelope chain procedure. Because the envelope chain procedure has not been employed before, we demonstrate in simulations the empirical performance of estimator, and examine its sensitivity when our assumptions are violated. We use the estimator to analyze the MRI data from ADHD-200 study. Data analyses demonstrate that leveraging the correlations among voxels can significantly increase the efficiency of the regression analysis, thus achieving higher detection power with small sample sizes.},
  archive      = {J_SJOS},
  author       = {Lan Liu and Wei Li and Zhihua Su and Dennis Cook and Luca Vizioli and Essa Yacoub},
  doi          = {10.1111/sjos.12522},
  journal      = {Scandinavian Journal of Statistics},
  number       = {2},
  pages        = {481-501},
  shortjournal = {Scand. J. Statist.},
  title        = {Efficient estimation via envelope chain in magnetic resonance imaging-based studies},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Emulation-based inference for spatial infectious disease
transmission models incorporating event time uncertainty. <em>SJOS</em>,
<em>49</em>(1), 455–479. (<a
href="https://doi.org/10.1111/sjos.12523">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mechanistic models of infectious disease spread are key to inferring spatiotemporal infectious disease transmission dynamics. Ideally, covariate data and the infection status of individuals over time would be used to parameterize such models. However, in reality, complete data are rarely available; for example, infection times are almost never observed. Bayesian data-augmented Markov chain Monte Carlo (MCMC) methods are commonly used to allow us to infer such missing or censored data. However, for large disease systems, these methods can be highly computationally expensive. In this paper, we propose two methods of approximate inference for such situations based on so-called emulation techniques. Here, both methods are set in a Bayesian MCMC framework but replace the computationally expensive likelihood function by a Gaussian process-based likelihood approximation. In the first method, we build an emulator of the discrepancy between summary statistics of simulated and observed epidemic data. In the second method, we develop an emulator of an importance sampling-based likelihood approximation. We show how both methods offer substantial computational efficiency gains over standard Bayesian MCMC-based method, and can be used to infer the transmission of complex infectious disease systems. We also show that importance sampling-based methods tend to perform more satisfactorily.},
  archive      = {J_SJOS},
  author       = {Gyanendra Pokharel and Rob Deardon},
  doi          = {10.1111/sjos.12523},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {455-479},
  shortjournal = {Scand. J. Statist.},
  title        = {Emulation-based inference for spatial infectious disease transmission models incorporating event time uncertainty},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Functional central limit theorems for persistent betti
numbers on cylindrical networks. <em>SJOS</em>, <em>49</em>(1), 427–454.
(<a href="https://doi.org/10.1111/sjos.12524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study functional central limit theorems for persistent Betti numbers obtained from networks defined on a Poisson point process. The limit is formed in large volumes of cylindrical shape stretching only in one dimension. The results cover a directed sublevel-filtration for stabilizing networks and the Čech and Vietoris–Rips complex on the random geometric graph. The presented functional central limit theorems open the door to a variety of statistical applications in topological data analysis and we consider goodness-of-fit tests in a simulation study.},
  archive      = {J_SJOS},
  author       = {Johannes Krebs and Christian Hirsch},
  doi          = {10.1111/sjos.12524},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {427-454},
  shortjournal = {Scand. J. Statist.},
  title        = {Functional central limit theorems for persistent betti numbers on cylindrical networks},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multivariate boundary regression models. <em>SJOS</em>,
<em>49</em>(1), 400–426. (<a
href="https://doi.org/10.1111/sjos.12519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we consider a multivariate regression model with one-sided errors. We assume for the regression function to lie in a general Hölder class and estimate it via a nonparametric local polynomial approach that consists of minimization of the local integral of a polynomial approximation lying above the data points. While the consideration of multivariate covariates offers an undeniable opportunity from an application-oriented standpoint, it requires a new method of proof to replace the established ones for the univariate case. The main purpose of this paper is to show the uniform consistency and to provide the rates of convergence of the considered nonparametric estimator for both multivariate random covariates and multivariate deterministic design points. To demonstrate the performance of the estimators, the small sample behavior is investigated in a simulation study in dimension two and three.},
  archive      = {J_SJOS},
  author       = {Leonie Selk and Charles Tillier and Orlando Marigliano},
  doi          = {10.1111/sjos.12519},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {400-426},
  shortjournal = {Scand. J. Statist.},
  title        = {Multivariate boundary regression models},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Expectile-based measures of skewness. <em>SJOS</em>,
<em>49</em>(1), 373–399. (<a
href="https://doi.org/10.1111/sjos.12518">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the literature, quite a few measures have been proposed for quantifying the deviation of a probability distribution from symmetry. The most popular of these skewness measures are based on the third centralized moment and on quantiles. However, there are major drawbacks in using these quantities. These include a strong emphasis on the distributional tails and a poor asymptotic behavior for the (empirical) moment-based measure as well as difficult statistical inference and strange behaviour for discrete distributions for quantile-based measures. Therefore, in this paper, we introduce skewness measures based on or connected with expectiles. Since expectiles can be seen as smoothed versions of quantiles, they preserve the advantages over the moment-based measure while not exhibiting most of the disadvantages of quantile-based measures. We introduce corresponding empirical counterparts and derive asymptotic properties. Finally, we conduct a simulation study, comparing the newly introduced measures with established ones, and evaluating the performance of the respective estimators.},
  archive      = {J_SJOS},
  author       = {Andreas Eberl and Bernhard Klar},
  doi          = {10.1111/sjos.12518},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {373-399},
  shortjournal = {Scand. J. Statist.},
  title        = {Expectile-based measures of skewness},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Projection-based and cross-validated estimation in
high-dimensional cox model. <em>SJOS</em>, <em>49</em>(1), 353–372. (<a
href="https://doi.org/10.1111/sjos.12515">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a projection-based cross-validation method for estimating a low-dimensional parameter in the presence of a high-dimensional nuisance parameter in the Cox regression model. We show that the proposed estimator is asymptotically normal, which enables us to conduct hypothesis test for the parameter of interest with high-dimensional nuisance parameters. Three decision rules are presented to avoid the influence of random splitting of samples. Simulation studies indicate that our method is more powerful than that of Fang et al. (2017,JRSSB) when the coefficients of predictors are high-dimensional and not very sparse. As an illustrative example, we apply our procedure to a breast cancer study.},
  archive      = {J_SJOS},
  author       = {Haixiang Zhang and Jian Huang and Liuquan Sun},
  doi          = {10.1111/sjos.12515},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {353-372},
  shortjournal = {Scand. J. Statist.},
  title        = {Projection-based and cross-validated estimation in high-dimensional cox model},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The greenwood statistic, stochastic dominance, clustering
and heavy tails. <em>SJOS</em>, <em>49</em>(1), 331–352. (<a
href="https://doi.org/10.1111/sjos.12520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Greenwood statisticTnand its functions, including sample coefficient of variation, often arise in testing exponentiality or detecting clustering or heterogeneity. We provide a general result describing stochastic behavior ofTnin response to stochastic behavior of the sample data. Our result provides a rigorous base for constructing tests and assuring that confidence regions are actually intervals for the tail parameter of many power-tail distributions. We also present a result explaining the connection between clustering and heaviness of tail for several classes of distributions and its extension to general heavy tailed families. Our results provide theoretical justification forTnbeing an effective and commonly used statistic discriminating between regularity/uniformity and clustering in presence of heavy tails in applied sciences. We also note that the use of Greenwood statistic as a measure of heterogeneity or clustering is limited to data with large outliers, as opposed to those close to zero.},
  archive      = {J_SJOS},
  author       = {Marek Arendarczyk and Tomasz J. Kozubowski and Anna K. Panorska},
  doi          = {10.1111/sjos.12520},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {331-352},
  shortjournal = {Scand. J. Statist.},
  title        = {The greenwood statistic, stochastic dominance, clustering and heavy tails},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semiparametric estimation and model selection for
conditional mixture copula models. <em>SJOS</em>, <em>49</em>(1),
287–330. (<a href="https://doi.org/10.1111/sjos.12514">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conditional copula models allow the dependence structure among variables to vary with covariates, and thus can describe the evolution of the dependence structure with those factors. This paper proposes a conditional mixture copula which is a weighted average of several individual conditional copulas. We allow both the weights and copula parameters to vary with a covariate so that the conditional mixture copula offers additional flexibility and accuracy in describing the dependence structure. We propose a two-step semi-parametric estimation method and develop asymptotic properties of the estimators. Moreover, we introduce model selection procedures to select the component copulas of the conditional mixture copula model. Simulation results suggest that the proposed procedures have a good performance in estimating and selecting conditional mixture copulas with different model specifications. The proposed model is then applied to investigate how the dependence structures among international equity markets evolve with the volatility in the exchange rate markets.},
  archive      = {J_SJOS},
  author       = {Guannan Liu and Wei Long and Bingduo Yang and Zongwu Cai},
  doi          = {10.1111/sjos.12514},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {287-330},
  shortjournal = {Scand. J. Statist.},
  title        = {Semiparametric estimation and model selection for conditional mixture copula models},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On estimation in the nested case-control design under
nonproportional hazards. <em>SJOS</em>, <em>49</em>(1), 265–286. (<a
href="https://doi.org/10.1111/sjos.12510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analysis of time-to-event data using Cox&#39;s proportional hazards (PH) model is ubiquitous in scientific research. A sample is taken from the population of interest and covariate information is collected on everyone. If the event of interest is rare and covariate information is difficult to collect, the nested case-control (NCC) design reduces costs with minimal impact on inferential precision. Under PH, application of the Cox model to data from a NCC sample provides consistent estimation of the hazard ratio. However, under non-PH, the finite-sample estimates corresponding to the Cox estimator depend on the number of controls sampled and the censoring distribution. We propose two estimators based on a binary predictor of interest: one recovers the estimand corresponding to the Cox model under a simple random sample, while the other recovers an estimand that does not depend on the censoring distribution. We derive the asymptotic distribution and provide finite-sample variance estimators.},
  archive      = {J_SJOS},
  author       = {Michelle M. Nuño and Daniel L. Gillen},
  doi          = {10.1111/sjos.12510},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {265-286},
  shortjournal = {Scand. J. Statist.},
  title        = {On estimation in the nested case-control design under nonproportional hazards},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semiparametric analysis of interval-censored failure time
data with outcome-dependent observation schemes. <em>SJOS</em>,
<em>49</em>(1), 236–264. (<a
href="https://doi.org/10.1111/sjos.12511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Disease progression is often monitored by intermittent follow-up “visits” in longitudinal cohort studies, resulting in interval-censored failure time outcomes. Furthermore, the timing and frequency of visits is often found related to a person&#39;s history of disease-related variables in practice. This article develops a semiparametric estimation approach using weighted binomial regression and a kernel smoother to analyze interval-censored failure time data. Visit times are allowed to be subject-specific and outcome-dependent. We consider a collection of widely used semiparametric regression models, including additive hazards and linear transformation models. For additive hazards models, the nonparametric component has a closed-form estimator and the estimators of regression coefficients are shown to be asymptotically multivariate normal with sandwich-type covariance matrices. Simulations are conducted to examine the finite sample performance of the proposed estimators. A data set from the Toronto Psoriatic Arthritis (PsA) Cohort Study is used to illustrate the proposed methodology.},
  archive      = {J_SJOS},
  author       = {Yayuan Zhu and Ziqi Chen and Jerald F. Lawless},
  doi          = {10.1111/sjos.12511},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {236-264},
  shortjournal = {Scand. J. Statist.},
  title        = {Semiparametric analysis of interval-censored failure time data with outcome-dependent observation schemes},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Nonstationary space–time covariance functions induced by
dynamical systems. <em>SJOS</em>, <em>49</em>(1), 211–235. (<a
href="https://doi.org/10.1111/sjos.12513">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article provides a novel approach to nonstationarity by considering a bridge between differential equations and spatial fields. We consider the dynamical transformation of a given spatial process undergoing the action of a temporal flow of space diffeomorphisms. Such dynamical deformations are shown to be connected to certain classes of ordinary and partial differential equations. The natural question arises of how such dynamical diffeomorphisms convert the original spatial covariance function, specifically if the original covariance is spatially stationary or isotropic. We first challenge this question from a general perspective, and then turn into the special cases of bothd-dimensional Euclidean spaces, and hyperspheres. Several examples of dynamical diffeomorphisms defined in these spaces are given and some emphasis has been put on the stationary reducibility problem. We provide a simple illustration to show the performance of the maximum likelihood estimation of the parameters of a family of dynamically deformed covariance functions.},
  archive      = {J_SJOS},
  author       = {Rachid Senoussi and Emilio Porcu},
  doi          = {10.1111/sjos.12513},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {211-235},
  shortjournal = {Scand. J. Statist.},
  title        = {Nonstationary space–time covariance functions induced by dynamical systems},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Approximate bayesian inference for a spatial point process
model exhibiting regularity and random aggregation. <em>SJOS</em>,
<em>49</em>(1), 185–210. (<a
href="https://doi.org/10.1111/sjos.12509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a doubly stochastic spatial point process model with both aggregation and repulsion. This model combines the ideas behind Strauss processes and log Gaussian Cox processes. The likelihood for this model is not expressible in closed form but it is easy to simulate realizations under the model. We therefore explain how to use approximate Bayesian computation (ABC) to carry out statistical inference for this model. We suggest a method for model validation based on posterior predictions and global envelopes. We illustrate the ABC procedure and model validation approach using both simulated point patterns and a real data example.},
  archive      = {J_SJOS},
  author       = {Ninna Vihrs and Jesper Møller and Alan E. Gelfand},
  doi          = {10.1111/sjos.12509},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {185-210},
  shortjournal = {Scand. J. Statist.},
  title        = {Approximate bayesian inference for a spatial point process model exhibiting regularity and random aggregation},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Statistics for gaussian random fields with unknown location
and scale using lipschitz-killing curvatures. <em>SJOS</em>,
<em>49</em>(1), 143–184. (<a
href="https://doi.org/10.1111/sjos.12500">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present article we study the average of Lipschitz-Killing (LK) curvatures of the excursion set of a stationary isotropic Gaussian fieldXonℝ2. The novelty is that the field can be nonstandard, that is, with unknown mean and variance, which is more realistic from an applied viewpoint. To cope with the unknown location and scale parameters ofX, we introduce novel fundamental quantities calledeffective levelandeffective spectral moment. We propose unbiased and asymptotically normal estimators of these parameters. From these asymptotic results, we build a test to determine if two images of excursion sets can be compared. This test is applied on both synthesized and real mammograms. Meanwhile, we establish the consistency of the empirical variance estimators of the third LK curvature under a weak condition on the correlation function ofX.},
  archive      = {J_SJOS},
  author       = {Elena Di Bernardino and Céline Duval},
  doi          = {10.1111/sjos.12500},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {143-184},
  shortjournal = {Scand. J. Statist.},
  title        = {Statistics for gaussian random fields with unknown location and scale using lipschitz-killing curvatures},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multivariate conditional transformation models.
<em>SJOS</em>, <em>49</em>(1), 116–142. (<a
href="https://doi.org/10.1111/sjos.12501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regression models describing the joint distribution of multivariate responses conditional on covariate information have become an important aspect of contemporary regression analysis. However, a limitation of such models are the rather simplistic assumptions often made, for example, a constant dependence structure not varying with covariates or the restriction to linear dependence between the responses. We propose a general framework for multivariate conditional transformation models that overcomes these limitations and describes the entire distribution in a tractable and interpretable yet flexible way conditional on nonlinear effects of covariates. The framework can be embedded into likelihood-based inference, including results on asymptotic normality, and allows the dependence structure to vary with covariates. In addition, it scales well-beyond bivariate response situations, which were the main focus of most earlier investigations. We illustrate the benefits in a trivariate analysis of childhood undernutrition and demonstrate empirically that complex truly multivariate data-generating processes can be inferred from observations.},
  archive      = {J_SJOS},
  author       = {Nadja Klein and Torsten Hothorn and Luisa Barbanti and Thomas Kneib},
  doi          = {10.1111/sjos.12501},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {116-142},
  shortjournal = {Scand. J. Statist.},
  title        = {Multivariate conditional transformation models},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Nonparametric extreme conditional expectile estimation.
<em>SJOS</em>, <em>49</em>(1), 78–115. (<a
href="https://doi.org/10.1111/sjos.12502">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Expectiles and quantiles can both be defined as the solution of minimization problems. Contrary to quantiles though, expectiles are determined by tail expectations rather than tail probabilities, and define a coherent risk measure. For these two reasons in particular, expectiles have recently started to be considered as serious candidates to become standard tools in actuarial and financial risk management. However, expectiles and their sample versions do not benefit from a simple explicit form, making their analysis significantly harder than that of quantiles and order statistics. This difficulty is compounded when one wishes to integrate auxiliary information about the phenomenon of interest through a finite-dimensional covariate, in which case the problem becomes the estimation of conditional expectiles. In this paper, we exploit the fact that the expectiles of a distributionFare in fact the quantiles of another distributionEexplicitly linked toF, in order to construct nonparametric kernel estimators of extreme conditional expectiles. We analyze the asymptotic properties of our estimators in the context of conditional heavy-tailed distributions. Applications to simulated data and real insurance data are provided.},
  archive      = {J_SJOS},
  author       = {Stéphane Girard and Gilles Stupfler and Antoine Usseglio-Carleve},
  doi          = {10.1111/sjos.12502},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {78-115},
  shortjournal = {Scand. J. Statist.},
  title        = {Nonparametric extreme conditional expectile estimation},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fitting inhomogeneous phase-type distributions to data: The
univariate and the multivariate case. <em>SJOS</em>, <em>49</em>(1),
44–77. (<a href="https://doi.org/10.1111/sjos.12505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The class of inhomogeneous phase-type distributions (IPH) was recently introduced in Albrecher &amp; Bladt (2019) as an extension of the classical phase-type (PH) distributions. Like PH distributions, the class of IPH is dense in the class of distributions on the positive halfline, but leads to more parsimonious models in the presence of heavy tails. In this paper we propose a fitting procedure for this class to given data. We furthermore consider an analogous extension of Kulkarni&#39;s multivariate PH class (Kulkarni, 1989) to the inhomogeneous framework and study parameter estimation for the resulting new and flexible class of multivariate distributions. As a by-product, we amend a previously suggested fitting procedure for the homogeneous multivariate PH case and provide appropriate adaptations for censored data. The performance of the algorithms is illustrated in several numerical examples, both for simulated and real-life insurance data.},
  archive      = {J_SJOS},
  author       = {Hansjörg Albrecher and Mogens Bladt and Jorge Yslas},
  doi          = {10.1111/sjos.12505},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {44-77},
  shortjournal = {Scand. J. Statist.},
  title        = {Fitting inhomogeneous phase-type distributions to data: The univariate and the multivariate case},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Nonparametric estimation of the fragmentation kernel based
on a partial differential equation stationary distribution
approximation. <em>SJOS</em>, <em>49</em>(1), 4–43. (<a
href="https://doi.org/10.1111/sjos.12504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a stochastic individual-based model in continuous time to describe a size-structured population for cell divisions. This model is motivated by the detection of cellular aging in biology. We here address the problem of nonparametric estimation of the kernel ruling the divisions based on the eigenvalue problem related to the asymptotic behavior in large population. This inverse problem involves a multiplicative deconvolution operator. Using Fourier techniques we derive a nonparametric estimator whose consistency is studied. The main difficulty comes from the nonstandard equations connecting the Fourier transforms of the kernel and the parameters of the model. A numerical study is carried out and we pay special attention to the derivation of bandwidths by using resampling.},
  archive      = {J_SJOS},
  author       = {Van Ha Hoang and Thanh Mai Pham Ngoc and Vincent Rivoirard and Viet Chi Tran},
  doi          = {10.1111/sjos.12504},
  journal      = {Scandinavian Journal of Statistics},
  number       = {1},
  pages        = {4-43},
  shortjournal = {Scand. J. Statist.},
  title        = {Nonparametric estimation of the fragmentation kernel based on a partial differential equation stationary distribution approximation},
  volume       = {49},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
