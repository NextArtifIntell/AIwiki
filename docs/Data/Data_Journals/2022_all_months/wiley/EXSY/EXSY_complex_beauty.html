<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>EXSY_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="exsy---257">EXSY - 257</h2>
<ul>
<li><details>
<summary>
(2022). Special issue on international conference on computing and
communication networks. <em>EXSY</em>, <em>39</em>(10), e13167. (<a
href="https://doi.org/10.1111/exsy.13167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EXSY},
  author       = {Deepak Gupta},
  doi          = {10.1111/exsy.13167},
  journal      = {Expert Systems},
  month        = {12},
  number       = {10},
  pages        = {e13167},
  shortjournal = {Expert Syst.},
  title        = {Special issue on international conference on computing and communication networks},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intelligent metaheuristics with optimal machine learning
approach for malware detection on IoT-enabled maritime transportation
systems. <em>EXSY</em>, <em>39</em>(10), e13155. (<a
href="https://doi.org/10.1111/exsy.13155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The latest advancements in Internet of Things (IoT) have revolutionized the productivity of global shipping industry in the recent years. It also led to the emergence of IoT-enabled Maritime Transportation Systems (MTS). These approaches detect the malware in network before the execution process. Various machine learning (ML) models have been proposed and designed in literature for effective malware detection. However, the existence of numerous features in the data bring dimensionality problem which can be only resolved by the use of feature selection approaches. Therefore, the current research work presents Intelligent Metaheuristics-based Feature Selection model with Optimal ML approach for Malware Detection (IMFSOML-MD) on IoT-enabled MTS. Primarily, IMFSOML-MD technique involves the design of Quantum Invasive Weed Optimization Algorithm-based Feature Selection technique to optimally choose a subset of features. Moreover, an Optimal Wavelet Neural Network (OWNN) model is employed to perform classification process. The initial parameters of WNN model are optimally tuned with the help of Colliding Bodies Optimization algorithm thereby improving the detection performance. The proposed IMFSOML-MD technique was experimentally validated using publicly-available CICMalDroid2020 dataset. The results from extensive comparative analysis demonstrated the superiority of the proposed IMFSOML-MD technique over other compared methods in terms of detection performance with maximum accuracy of 98.96%.},
  archive      = {J_EXSY},
  author       = {Mohammed Maray and Mohammed Alghamdi and Fatma S. Alrayes and Saud S. Alotaibi and Sana Alazwari and Rana Alabdan and Mesfer Al Duhayyim},
  doi          = {10.1111/exsy.13155},
  journal      = {Expert Systems},
  month        = {12},
  number       = {10},
  pages        = {e13155},
  shortjournal = {Expert Syst.},
  title        = {Intelligent metaheuristics with optimal machine learning approach for malware detection on IoT-enabled maritime transportation systems},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Drugs–protein affinity-score prediction using deep
convolutional neural network. <em>EXSY</em>, <em>39</em>(10), e13154.
(<a href="https://doi.org/10.1111/exsy.13154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug discovery involves identifying novel drug–target (DT) interactions. Most proposed computer models for predicting drug–target interactions have emphasized binary classification, but the aim is to determine whether two drug targets interact. However, it is more practical but more challenging to anticipate the binding affinity, which evaluates the strength of a DT pair&#39;s association. The drug may not work if the binding affinity is not strong enough. Due to this reason, we need an expert system for predicting the affinity score between the drug and target protein. Advanced deep learning techniques can predict binding affinities because there are more new public affinity data in databases related to DT. This paper uses a comparative analysis of different drug and protein-encoding techniques to predict DT binding affinities based on similarities between drugs and proteins. The validation results on the standard dataset show that the proposed model is an excellent way to predict how well DT binds and can be very helpful in the process of new drugs. Hence, the model on the DAVIS dataset achieved a higher concordance index, that is, 0.897, and the lowest mean square error, that is, 0.226; for the KIBA dataset, the concordance index score achieved is 0.867, and the mean square error is 0.191. The findings are compared to baseline methods using some evaluation parameters, including the mean squared error and the concordance index.},
  archive      = {J_EXSY},
  author       = {Moolchand Sharma and Suman Deswal},
  doi          = {10.1111/exsy.13154},
  journal      = {Expert Systems},
  month        = {12},
  number       = {10},
  pages        = {e13154},
  shortjournal = {Expert Syst.},
  title        = {Drugs–Protein affinity-score prediction using deep convolutional neural network},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-criteria approach for handling sophisticated data
transmission over gateways in blockchain and internet of things (IoT)
federated networks. <em>EXSY</em>, <em>39</em>(10), e13127. (<a
href="https://doi.org/10.1111/exsy.13127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the real-world scenario, the Internet of Things (IoT) and blockchain federated networks implicate smart devices for gathering the data and then directing the data to the destined nodes through gateway devices. A gateway usually supports a number of wireless sensor networks (WSNs) irrespective of their underlying communication technologies. Furthermore, a gateway usually supports a number of WSNs with blockchain master nodes, which employ diverse communication technologies. As a result, gateways are meant to play a versatile role without worrying about the underlying architecture, hardware, and software details of the connecting nodes in blockchain federated networks. This paper proposes a two-phased methodology for blockchain and IoT federated networks where efficient link selection based on a multi-criteria-based approach is performed. The dynamic gateway scheduling strategy is capable enough to support blockchain-based transactions as well as communication in IoT devices. Furthermore, the proposed methodology enhances data transfer fairness for each gateway, resulting in efficient data transmission. Machine learning (ML) methods are also devised to analyze the status of the communication channels before employing the link selection mechanism. Then the selection of links is performed based on multi-criteria statistical techniques. Finally, the scheduling is performed for selecting the appropriate gateway for channelizing the blockchain data speedily. The selection of links is made based on the dynamic status of the links. The usage of time series ML methods such as LSTM is made to predict the upcoming traffic on the links. Multiple criteria-based statistical approaches are utilized for the selection of the link optimally. Finally, the scheduling is performed to fulfil the criteria of 6G networks, where network users are rewarded with seamless connectivity and uninterrupted services. The efficacy of the proposed two-phased mechanism is demonstrated through simulation results. The results are demonstrated with respect to the total data conveyed, packet delivery ratio (PDR), energy consumed by the links, and throughput of the network. The PDR obtained by the proposed work for the high volume of data is 93% and for the low volume of data is 97%. The packet delay is reduced by 21% for low volume data and 19% for high volume data by the proposed methods. The data transmission is also optimized remarkably by the proposed method. The proposed fairness-driven mechanism (FDM) is compared with the state-of-the-art methods to prove the viability and robustness of the two-phased proposed mechanism of link selection for data transmission over blockchain and IoT federated networks.},
  archive      = {J_EXSY},
  author       = {Suvarna Patil and Prasad Gokhale},
  doi          = {10.1111/exsy.13127},
  journal      = {Expert Systems},
  month        = {12},
  number       = {10},
  pages        = {e13127},
  shortjournal = {Expert Syst.},
  title        = {Multi-criteria approach for handling sophisticated data transmission over gateways in blockchain and internet of things (IoT) federated networks},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial neural network and symmetric key cryptography
based verification protocol for 5G enabled internet of things.
<em>EXSY</em>, <em>39</em>(10), e13126. (<a
href="https://doi.org/10.1111/exsy.13126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by the requirements for entirely low communication latencies, high bandwidths, reliability and capacities, the Fifth Generation (5G) networks has been deployed in a number of countries. One of the most prevalent application scenarios of 5G networks is the Internet of Things (IoT) that can potentially boost convenience and energy savings. However, the information exchanged over the open wireless 5G networks is susceptible to numerous attacks such as malicious modifications. Although many protocols have been developed to protect against these attacks, the provision of optimum security and privacy issues in 5G networks is still an open challenge. This is attributed to the high device density, frequent handovers and resource constrained nature the 5G IoT nodes. In this article, a network selection and authentication protocol that securely verifies the authenticity of all the communicating entities is presented. The network selection is accomplished using Artificial Neural Network (ANN) for increased efficiency. In addition, all the security tokens are independently derived at the end devices without the involvement of any central authority. Formal security analysis based on the Burrows–Abadi–Needham (BAN) logic shows that all the terminals securely authenticate each other before the onset of packet exchanges. In addition, it is shown that this protocol thwarts majority of the conventional 5G attack vectors and is robust under the Dolev–Yao (DY) threat model. Moreover, a comparison with other related schemes shows that the proposed protocol offers many adorable security features at relatively low communication and computation costs. The simulation results show that the deployed ANN yields low packet loss ratio and latency variations.},
  archive      = {J_EXSY},
  author       = {Vincent Omollo Nyangaresi and Musheer Ahmad and Ahmed Alkhayyat and Wei Feng},
  doi          = {10.1111/exsy.13126},
  journal      = {Expert Systems},
  month        = {12},
  number       = {10},
  pages        = {e13126},
  shortjournal = {Expert Syst.},
  title        = {Artificial neural network and symmetric key cryptography based verification protocol for 5G enabled internet of things},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Quasi-oppositional wild horse optimization based multi-agent
path finding scheme for real time IoT systems. <em>EXSY</em>,
<em>39</em>(10), e13112. (<a
href="https://doi.org/10.1111/exsy.13112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Agent System (MAS) gained significant interest amongst researchers since it provides multiple benefits through several application areas. MAS involves a network of socially-cooperative smart agents that is conscious about the drastic modifications that occur in the platform at the time of task execution. On the other hand, energy efficiency is a major issue in real-time IoT systems, since most of the sensor nodes experience energy constraints. Though several works have been conducted earlier, there is a need exists to design an effective solution for simultaneous processing in real-time environments using multiple agents. The aim of Multi-Agent Pathfinding (MAPF) process is to provide collision-free routes so as to divert the agents from original path to the destination. In this view, the current study designs a Quasi-Oppositional Wild Horse Optimization-based Multi-Agent Path Finding (QOWHO-MAPF) scheme for real-time IoT systems. The aim of the proposed QOWHO-MAPF scheme is to determine the optimal set of paths to reach the destination in real-time IoT networks. QOWHO algorithm is created by integrating the concepts of Quasi-Oppositional Based Learning (QOBL) and conventional WHO algorithm. In addition, the proposed QOWHO-MAPF model derives a fitness function that involves two input parameters such as residual energy and distance-to-destination. The proposed QOWHO-MAPF model was experimentally analysed and the results were inspected under several aspects. The simulation results established that QOWHO-MAPF model is a superior model compared to other state-of-the-art models.},
  archive      = {J_EXSY},
  author       = {Radwa Marzouk and Jaber S. Alzahrani and Fadwa Alrowais and Fahd N. Al-Wesabi and Manar Ahmed Hamza},
  doi          = {10.1111/exsy.13112},
  journal      = {Expert Systems},
  month        = {12},
  number       = {10},
  pages        = {e13112},
  shortjournal = {Expert Syst.},
  title        = {Quasi-oppositional wild horse optimization based multi-agent path finding scheme for real time IoT systems},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Extractive summarization using concept-space and keyword
phrase. <em>EXSY</em>, <em>39</em>(10), e13110. (<a
href="https://doi.org/10.1111/exsy.13110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EXSY},
  author       = {Parminder Pal Singh Bedi and Manju Bala and Kapil Sharma},
  doi          = {10.1111/exsy.13110},
  journal      = {Expert Systems},
  month        = {12},
  number       = {10},
  pages        = {e13110},
  shortjournal = {Expert Syst.},
  title        = {Extractive summarization using concept-space and keyword phrase},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automated sarcasm detection and classification using
hyperparameter tuned deep learning model for social networks.
<em>EXSY</em>, <em>39</em>(10), e13107. (<a
href="https://doi.org/10.1111/exsy.13107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent digital era, social media sites have been commonly used by majority of people to generate massive quantities of textual data. Sarcasm can be treated as a kind of sentiment, which generally expresses the opposite of what has been anticipated. Since sarcasm detection is mainly based on the context of utterances or sentences, it is hard to design a model to proficiently detect sarcasm in the domain of natural language processing (NLP). The recent advancements of deep learning (DL) models influence neural networks (NN) in learning the lexical as well as contextual features, eradicating the necessity of hand-crafted features for sarcasm detection. With this motivation, this article designs an automated sarcasm detection and classification tool using hyperparameter tuned deep learning (ASDC-HPTDL) model for social media. The proposed ASDC-HPTDL technique primarily involves pre-processing stage to transform the data into useful format. At the next stage of pre-processing, the pre-processed data is converted into the feature vector by Glove Embedding&#39;s technique. Followed by, attention bidirectional gated recurrent unit (ABiGRU) technique is utilized to detect and classify sarcasm. In order to boost the detection outcomes of the ABiGRU technique, a hyperparameter tuning process using improved artificial flora algorithm (IAFO) is employed, shows the novelty of the work. The proposed model is validated using the benchmark dataset and the results are examined interms of precision, recall, accuracy, and F1-score.},
  archive      = {J_EXSY},
  author       = {Dakshnamoorthy Vinoth and Panneer Prabhavathy},
  doi          = {10.1111/exsy.13107},
  journal      = {Expert Systems},
  month        = {12},
  number       = {10},
  pages        = {e13107},
  shortjournal = {Expert Syst.},
  title        = {Automated sarcasm detection and classification using hyperparameter tuned deep learning model for social networks},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). S-shaped and v-shaped binary african vulture optimization
algorithm for feature selection. <em>EXSY</em>, <em>39</em>(10), e13079.
(<a href="https://doi.org/10.1111/exsy.13079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The African vulture optimization algorithm (AVOA) is a recently developed metaheuristic algorithm that imitates the eating and movement patterns of authentic African vultures. AVOA is developed to address the continuous optimization problem. However, AVOA is unable to solve the discrete search space, this inspires us to develop the binary AVOA for feature selection problems in classification tasks. The suggested BAVOA incorporates an eight-transfer function (S-shaped and V-shaped) for transforming a continuous variable to a binary one. Using 14 benchmark data sets, the proposed technique is compared against 15 conventional binary metaheuristics algorithms in terms of classification accuracy, fitness function, number of selected features and converging ability. Furthermore, the results are statistically analysed using Wilcoxon test. The comparative findings of S-Shaped and V-shaped transfer functions indicate the superior performance of BAVOA methods, particularly S2-BAVOA, in contrast to other transfer function. Based on results, it turns out that the suggested technique converges to the global minimum in several iterations based on the selection of optimal characteristics, fitness values and higher classification accuracy as compared to the classical binary metaheuristic algorithms.},
  archive      = {J_EXSY},
  author       = {Kulandaivel Balakrishnan and Ramasamy Dhanalakshmi and Gopalakrishnan Seetharaman},
  doi          = {10.1111/exsy.13079},
  journal      = {Expert Systems},
  month        = {12},
  number       = {10},
  pages        = {e13079},
  shortjournal = {Expert Syst.},
  title        = {S-shaped and V-shaped binary african vulture optimization algorithm for feature selection},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Novel graphical family tree representation to develop an
interactive expert system. <em>EXSY</em>, <em>39</em>(10), e13077. (<a
href="https://doi.org/10.1111/exsy.13077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Family inheritance distribution is an interesting and challenging problem. When a person dies, all of their wealth is passed on to their heirs. Heirs are family members of the deceased with specific relationships. The distribution process of wealth in Islam has many rules that make it difficult to understand and require an expert to solve. Many interrelated rules make it difficult to teach and learn. Therefore, there have been multiple attempts to develop an expert system to help solve the family inheritance problem. The existing solutions have some limitations in terms of the completeness of rules, and user-system interactions, which make these systems unreliable. In this study, we developed an expert system to calculate family inheritance. The two main contributions of this work are the development of a complete set of inheritance rules and the design of intelligent user-system interaction. We innovate the design of the family tree, which plays the role of an interaction layer with the user. The results of our proposed system demonstrate an accuracy of approximately 93%.},
  archive      = {J_EXSY},
  author       = {Mohamed A. Mostafa and Muhammad Al-Qurishi and Atif Al-Amri and Mehmet S. Aksoy and Ahmed Emam},
  doi          = {10.1111/exsy.13077},
  journal      = {Expert Systems},
  month        = {12},
  number       = {10},
  pages        = {e13077},
  shortjournal = {Expert Syst.},
  title        = {Novel graphical family tree representation to develop an interactive expert system},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An intelligent optimization algorithm with a deep
learning-enabled block-based motion estimation model. <em>EXSY</em>,
<em>39</em>(10), e13074. (<a
href="https://doi.org/10.1111/exsy.13074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The motion estimation process has gained significant attention in several video applications such as video compression, global motion estimation, and so on. The deep learning (DL) models that perform effectively in computer vision tasks can be employed for motion estimation. Yet, they have high computational complexity and model parameters since motion estimation in the pixel domain is not effective in practical applications. Instead, a block-based motion estimation process has been developed where the blocks of sequential images are compared. To that end, this paper presents the Anas platyrhynchos optimizer with deep learning-enabled block-based motion estimation (APODL-BBME) model. The proposed model estimates motion using block-based concepts and DL approaches. To accomplish this, the training and testing frames are separated into non-overlapping block categories, and the blocks are filtered via the bilateral filtering (BF) approach. In addition, a histogram of gradients (HOG) and densely connected network (DenseNet) model are employed to extract features, which are then fed into the bidirectional long short-term memory (BiLSTM) model to classify the input features. Finally, the APO algorithm is applied to optimally tune the hyperparameters of the BiLSTM model, which helps to improve the overall motion estimation efficacy, showing the novelty of the work. To demonstrate the enhanced performance of the APODL-BBME model, a comprehensive analysis is carried out, and when we compare the results, the APODL-BBME model outperforms recent motion estimation approaches.},
  archive      = {J_EXSY},
  author       = {Awanish Kumar Mishra and Narendra Kohli},
  doi          = {10.1111/exsy.13074},
  journal      = {Expert Systems},
  month        = {12},
  number       = {10},
  pages        = {e13074},
  shortjournal = {Expert Syst.},
  title        = {An intelligent optimization algorithm with a deep learning-enabled block-based motion estimation model},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Trend analysis and forecasting of publication activities by
indian computer science researchers during the period of 2010–23.
<em>EXSY</em>, <em>39</em>(10), e13070. (<a
href="https://doi.org/10.1111/exsy.13070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Huge collections of published research documents are available in various repositories in Indian universities and research organizations. The efficient retrieval, estimation of research trends, and identification of research gaps with the global trend in different research areas, can be a great guiding tool for regulating research in the appropriate direction. This research attempts to analyse the trend of research activities carried out by Indian researchers in the discipline of Computer Science from 2010 to 19 and forecast the upcoming research trend for the years 2020–23. A repository of the abstracts based on domains given in the Computer Science Ontology (CSO) published by the Indian researchers is developed from the Scopus database. Document Index Graph document representation model is used to store the repository, shared phrases across the documents are extracted and phrase-based similarity is computed. Combining the Single-term and Phrase-based similarity, the hybrid similarity is generated and similar documents are clustered using the DBSCAN clustering technique. Topics are identified for each cluster using the Latent Dirichlet Allocation algorithm and are automatically labelled using CSO. For each topic, the trend analysis and forecasting have been done using the Auto-Regressive Integrated Moving Average. For the assessment of the forecasting performance, the dataset from 2010 to 17 is used as a training dataset and 2018–19 as a testing dataset. The average forecasting for the year 2018 for all CSO domains belongs to the Good forecasting category with Mean Absolute Percentage Error (MAPE) 18.34, and 2019 shows reasonable forecasting with MAPE 30.20 as per the MAPE interpretation given by Lewis. For each topic the average forecasting for years 2018–19 shows either Highly accurate, Good or Reasonable forecasting. As a result, the top four domains for the years 2020–23 are also identified which can help initial researchers in the identification of a relevant topic for research and exploration.},
  archive      = {J_EXSY},
  author       = {Preeti Kathiria and Harshal Arolkar},
  doi          = {10.1111/exsy.13070},
  journal      = {Expert Systems},
  month        = {12},
  number       = {10},
  pages        = {e13070},
  shortjournal = {Expert Syst.},
  title        = {Trend analysis and forecasting of publication activities by indian computer science researchers during the period of 2010–23},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel hybrid robust architecture for automatic screening
of glaucoma using fundus photos, built on feature selection and machine
learning-nature driven computing. <em>EXSY</em>, <em>39</em>(10),
e13069. (<a href="https://doi.org/10.1111/exsy.13069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Glaucoma is a leading cause of permanent vision loss. Early detection and treatment of this infection is critical for recovery and slowing the progression of vision loss. An efficient novel system focused on customized particle swarm optimization (CPSO) and four state-of-the-art machine-learning classifiers is proposed to boost prediction performance. This interconnected architecture detects glaucoma through five main phases: (1) pre-processing, (2) segmentation, (3) feature extraction, (4) finding the best scored features, and (5) classification using the proposed CPSO-machine learning dependent classifier. The subject images belong to the publically available benchmark Digital Retinal Images for Optic Nerve Segmentation retinal fundus data set. Rather than focusing on the initial 20 extracted features of the retinal fundus, half of the critical features are chosen to form a feature vector based on scores provided by the univariate method and the feature importance method separately. These features are fed into this system for training, testing, and multiple sets of results are created as a result of multiple combinations of CPSO and supervised machine-learning classifiers. These result sets are evaluated using six efficiency metrics. According to the simulation results, the best output is recorded when a univariate selected feature vector is fed into the CPSO—K-nearest neighbour dependent hybrid method. This model outperformed other models with a maximum accuracy of 0.99, a specificity of 0.96, a sensitivity of 0.97, a precision of 0.97, an F1-score of 0.97, and a Kappa of 0.94. A fivefold cross-validation method is used to derive the values. This research would help to achieve good levels of glaucoma care since the proposed system is excellent at distinguishing between stable and glaucomatous eyes. For ophthalmologists, this new technique can be used as second opinion for improving diagnostic accuracy for glaucoma.},
  archive      = {J_EXSY},
  author       = {Law Kumar Singh and Munish Khanna and Shankar Thawkar},
  doi          = {10.1111/exsy.13069},
  journal      = {Expert Systems},
  month        = {12},
  number       = {10},
  pages        = {e13069},
  shortjournal = {Expert Syst.},
  title        = {A novel hybrid robust architecture for automatic screening of glaucoma using fundus photos, built on feature selection and machine learning-nature driven computing},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhanced hybrid neural network for automated essay scoring.
<em>EXSY</em>, <em>39</em>(10), e13068. (<a
href="https://doi.org/10.1111/exsy.13068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an online learning system, the automatic scoring of an essay is key to providing immediate feedback on essays submitted by students. To the best of our knowledge, existing approaches ignore the multidimensional and heterogeneous characteristics of essays or rely too heavily on the manual creation of features; therefore, a more comprehensive method of scoring essays is required. To address this issue, this paper proposes an enhanced hybrid neural network for automated essay scoring that extracts and fuses the linguistic, semantic, and structural attributes of an essay to achieve a comprehensive representation. Specifically, linguistic attributes include not only lexical features extracted from the words of an essay but also syntactic features obtained from sentences and syntax trees. Semantic attributes include the dynamic textual semantic representation and topic similarity obtained by the text encoder. We also considered the structural attributes. The text encoder provides the overall structural representation, while the sentence similarity matrix provides the two spatial features of connectivity and aggregation. Finally, we fused the three attributes and six features to achieve a more objective and comprehensive automatic scoring. We found that our model improves the Kappa index by an average of 1.4% over the current best model when tested against four state-of-the-art models using eight public data sets.},
  archive      = {J_EXSY},
  author       = {Xia Li and Huali Yang and Shengze Hu and Jing Geng and Keke Lin and Yuhai Li},
  doi          = {10.1111/exsy.13068},
  journal      = {Expert Systems},
  month        = {12},
  number       = {10},
  pages        = {e13068},
  shortjournal = {Expert Syst.},
  title        = {Enhanced hybrid neural network for automated essay scoring},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A genetic algorithm-based on-orbit self-repair
implementation for SRAM FPGAs. <em>EXSY</em>, <em>39</em>(10), e13039.
(<a href="https://doi.org/10.1111/exsy.13039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The reconfigurable capability of static random-access memory (SRAM) field programmable gate array (FPGA) can be used for its fault self-repair method. As a machine learning method, the genetic algorithm (GA) is an FPGA fault repair method that can be automatically executed on-orbit without any ground support. However, the GA-based fault repair method has disadvantages, such as the dependency on processors, the knowledge requirement for user designs in FPGAs, and the small size of repaired circuits. To address these issues, this paper presents a comprehensive analysis of the FPGA bitstream in the aerospace industry. An accurate on-orbit fault location can be identified by bitstream copying and exhaustive test and the executed area of the GA can be reduced to one tile. In addition, the probability function of the algorithm is optimized, which converts floating-point operations into integer arithmetic operations that are easily implemented in FPGAs without processors. The method is outstanding compared with existing ones, considering: (1) The size of repaired circuits is hundreds of times larger than those from other methods. (2) Its implementations are totally up to FPGAs&#39; own logic, with no requirement for processors. (3) There is no knowledge requirement for user design. (4) It reaches the leading level with a success rate of 81%–93%. The method has been verified by various applications in XC7VX330T, which demonstrates its engineering practicability.},
  archive      = {J_EXSY},
  author       = {Fan Zhang and Chenguang Guo and Shifeng Zhang and Qinqin Zeng and Tri Gia Nguyen},
  doi          = {10.1111/exsy.13039},
  journal      = {Expert Systems},
  month        = {12},
  number       = {10},
  pages        = {e13039},
  shortjournal = {Expert Syst.},
  title        = {A genetic algorithm-based on-orbit self-repair implementation for SRAM FPGAs},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artifical intelligence with optimal deep learning enabled
automated retinal fundus image classification model. <em>EXSY</em>,
<em>39</em>(10), e13028. (<a
href="https://doi.org/10.1111/exsy.13028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic retinopathy (DR) and age related macular degeneration (AMD) becomes widespread microvascular illness among diabetic patients. Traditional retinal fundus image classification requires visual inspection by the professionals, which is time consuming and requires expert&#39;s knowledge. Earlier identification of retinal diseases is essential to delay or avoid vision deterioration and vision loss. The recently developed artificial intelligence (AI) and deep learning (DL) models can be employed for accurate retinal image classification. With this motivation, this study designs a new artificial intelligence with optimal deep convolutional neural network (AI-ODCNN) technique for retinal fundus image classification. Primarily, the proposed model uses the Gaussian Blur based noise removal and contrast enhancement technique (CLAHE) based contrast enhancement technique to pre-process the retinal fundus image. In addition, morphology and contour based image segmentation is performed. Moreover, the deep CNN with RMSProp Optimizer is employed for retinal fundus image classification. A wide range of simulations was performed on the automated retinal image analysis and structured analysis of the retina and the outcomes are examined with respect to various measures. The simulation outcomes ensured the better performance of the proposed approach related to other recent algorithms with maximum accuracy of 96.47%.},
  archive      = {J_EXSY},
  author       = {Indresh Kumar Gupta and Abha Choubey and Siddhartha Choubey},
  doi          = {10.1111/exsy.13028},
  journal      = {Expert Systems},
  month        = {12},
  number       = {10},
  pages        = {e13028},
  shortjournal = {Expert Syst.},
  title        = {Artifical intelligence with optimal deep learning enabled automated retinal fundus image classification model},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Effective hybrid deep learning model for COVID-19 patterns
identification using CT images. <em>EXSY</em>, <em>39</em>(10), e13010.
(<a href="https://doi.org/10.1111/exsy.13010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coronavirus disease 2019 (COVID-19) has attracted significant attention of researchers from various disciplines since the end of 2019. Although the global epidemic situation is stabilizing due to vaccination, new COVID-19 cases are constantly being discovered around the world. As a result, lung computed tomography (CT) examination, an aggregated identification technique, has been used to ameliorate diagnosis. It helps reveal missed diagnoses due to the ambiguity of nucleic acid polymerase chain reaction. Therefore, this study investigated how quickly and accurately hybrid deep learning (DL) methods can identify infected individuals with COVID-19 on the basis of their lung CT images. In addition, this study proposed a developed system to create a reliable COVID-19 prediction network using various layers starting with the segmentation of the lung CT scan image and ending with disease prediction. The initial step of the system starts with a proposed technique for lung segmentation that relies on a no-threshold histogram-based image segmentation method. Afterward, the GrabCut method was used as a post-segmentation method to enhance segmentation outcomes and avoid over-and under-segmentation problems. Then, three pre-trained models of standard DL methods, including Visual Geometry Group Network, convolutional deep belief network, and high-resolution network, were utilized to extract the most affective features from the segmented images that can help to identify COVID-19. These three described pre-trained models were combined as a new mechanism to increase the system&#39;s overall prediction capabilities. A publicly available dataset, namely, COVID-19 CT, was used to test the performance of the proposed model, which obtained a 95% accuracy rate. On the basis of comparison, the proposed model outperformed several state-of-the-art studies. Because of its effectiveness in accurately screening COVID-19 CT images, the developed model will potentially be valuable as an additional diagnostic tool for leading clinical professionals.},
  archive      = {J_EXSY},
  author       = {Dheyaa Ahmed Ibrahim and Dilovan Asaad Zebari and Hussam J. Mohammed and Mazin Abed Mohammed},
  doi          = {10.1111/exsy.13010},
  journal      = {Expert Systems},
  month        = {12},
  number       = {10},
  pages        = {e13010},
  shortjournal = {Expert Syst.},
  title        = {Effective hybrid deep learning model for COVID-19 patterns identification using CT images},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An intelligent robust cascaded control scheme for renewable
energy based microgrid. <em>EXSY</em>, <em>39</em>(10), e12980. (<a
href="https://doi.org/10.1111/exsy.12980">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handling the uncertainties in the utility grid and uncertainties in renewable energy sources is a main challenge to accomplish the modern grid code requirements. This article proposes a new control strategy based on interval type-2 fuzzy sets for controlling the grid-connected dispersed generation (DG) system tied to the distorted electric grid. The proposed control technique can easily model and handle the uncertainties in the system parameters and renewable energy sources. The existence of three-dimensional membership functions of type-2 fuzzy sets offers an additional degree of freedom to counter the uncertainties in the system. The proposed strategy is effective in improving the dynamic response during system uncertainties such as distortions in grid voltage, variations in grid frequency, variations in renewable energy sources and due to presence of non-linear and unbalanced loads. Also, it improves the quality of the current being injected to the grid during uncertainties. The proposed control strategy is applied to control the dc side capacitor voltage as well as to control the current loop of the grid connected inverter. The proposed system is simulated in MATLAB Simulink environment and the performance is compared with traditional controllers to show the effectiveness of the proposed control strategy during system abnormalities.},
  archive      = {J_EXSY},
  author       = {Vigneysh T and Suresh Velamuri and MVV Prasad Kantipudi and Wattana Viriyasitavat},
  doi          = {10.1111/exsy.12980},
  journal      = {Expert Systems},
  month        = {12},
  number       = {10},
  pages        = {e12980},
  shortjournal = {Expert Syst.},
  title        = {An intelligent robust cascaded control scheme for renewable energy based microgrid},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modified lamport merkle digital signature blockchain
framework for authentication of internet of things healthcare data.
<em>EXSY</em>, <em>39</em>(10), e12978. (<a
href="https://doi.org/10.1111/exsy.12978">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical internet of things (IoT) includes various devices, sensor, machines, equipment which exchange data over wide network. Industry 5.0 and 5G technology have ramped mIoT data and cost-effective sensors. There is sudden upsurge in the medical IoT for enhancing the medical care. Integration of cloud server for data storage and cloud computing has led to the emergence of time and cost-effective management of medical resources and improved patient lifestyle. However, cloud data is always at risk of data leak and malicious attack by unwanted users for their personal gains and agenda. With the increase of data exchange in the medical field, there is an urgency of keeping all the transaction safe and secure. There is a growing malicious data attacks and vulnerability. Therefore, to overcome such situations, the proposed model is a step towards sustainable technology. Keeping the focus on cost effective data security, the present work has developed a framework of modified Lamport Merkle Digital Signature method for signature generation and verification. It makes use of central healthcare controller (CHC) which determine the root of generated signature along with verification and authentication. For verification, the validation hash public key with generate key is required to validate the signature. This led to the efficient, cost effective and faster security when compared to the existing methods.},
  archive      = {J_EXSY},
  author       = {Abolfazl Mehbodniya and Julian L. Webber and Rahul Neware and Farrukh Arslan and Raja Varma Pamba and Mohammad Shabaz},
  doi          = {10.1111/exsy.12978},
  journal      = {Expert Systems},
  month        = {12},
  number       = {10},
  pages        = {e12978},
  shortjournal = {Expert Syst.},
  title        = {Modified lamport merkle digital signature blockchain framework for authentication of internet of things healthcare data},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A distributed identity-based authentication scheme for
internet of things devices using permissioned blockchain system.
<em>EXSY</em>, <em>39</em>(10), e12941. (<a
href="https://doi.org/10.1111/exsy.12941">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) has become a significant technology on the internet with its widespread adoption in almost every place we could think of, like homes, hospitals, industries, companies, and so on. This adoption in virtually every device had made them smart, thereby reducing the human intervention to handle them. These devices become smart by gathering the sensed information and communicating with other devices or servers to take the appropriate decisions based on acquired data. However, these devices are deployed in batches with default usernames and passwords, making them vulnerable to attacks as seen in recent pasts like the Mirai botnet attack. Most of the attacks could have been avoided if these devices were equipped with a decent lightweight secure authentication scheme. One of the most common authentication procedures is using traditional public key infrastructure (PKI), which suffers from a single point of failure. Moreover, the complex procedures of PKI make them unfit for low-powered IoT devices. Identity-based cryptography (IBC), a lightweight cryptosystem, could be a good fit for these devices. But, even IBC suffers from a single point of failure and key escrow problem because of the private key generator (PKG). Blockchain has proved its mettle in eliminating a single point of failure with its robust distributed ledger technology. This article presents a novel authentication scheme for IoT devices based on identity-based cryptography using a blockchain network. Blockchain is used as a distributed PKG, eliminating a single point of failure and key escrow problem of PKGs. Further, the proposed work is implemented in Hyperledger Fabric, which is an open-source blockchain platform that efficiently performs the addition, updating, and deletions operation for effective authentication and communication of IoT devices.},
  archive      = {J_EXSY},
  author       = {Erukala Suresh Babu and Ajay Kumar Dadi and Krishna Kant Singh and Soumya Ranjan Nayak and Akash Kumar Bhoi and Akansha Singh},
  doi          = {10.1111/exsy.12941},
  journal      = {Expert Systems},
  month        = {12},
  number       = {10},
  pages        = {e12941},
  shortjournal = {Expert Syst.},
  title        = {A distributed identity-based authentication scheme for internet of things devices using permissioned blockchain system},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Boost-defence for resilient IoT networks: A head-to-toe
approach. <em>EXSY</em>, <em>39</em>(10), e12934. (<a
href="https://doi.org/10.1111/exsy.12934">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) is an emerging technology that is considered a key enabler for next-generation smart cities, industries, security services and economies. IoT networks allow connected devices to communicate with each other automatically without human intervention which empowers innovative solutions for pressing challenges and limitations of current technologies required to materialize smart environments. Due to the concrete involvement of IoT networks in critical infrastructures and cyber-physical systems, defending them against cyber-attacks has led to extensive research efforts to propose effective countermeasures against such attacks. In this work, we present Boost-Defence: a framework to secure IoT networks from a large vector of cyber-attacks at different IoT layers. We employ the AdaBoost machine learning technique combined with Decision Trees and extensive data engineering techniques to construct a robust classifier for detecting and classifying several cyber-attacks in IoT networks. We evaluate our system on the TON_IoT_2020 datasets, a collection of datasets compiled specifically for 3-layered IoT systems comprising: physical, network and application layers. We contrast the performance of our system against existing state-of-the-art solutions. Our experimental analysis demonstrates the capability of our framework in providing superior classification accuracy and lower types 1 and 2 errors for constructing more resilient IoT infrastructures.},
  archive      = {J_EXSY},
  author       = {Qasem Abu Al-Haija and Ahmad Al Badawi and Giridhar Reddy Bojja},
  doi          = {10.1111/exsy.12934},
  journal      = {Expert Systems},
  month        = {12},
  number       = {10},
  pages        = {e12934},
  shortjournal = {Expert Syst.},
  title        = {Boost-defence for resilient IoT networks: A head-to-toe approach},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Blockchain-based IoT architecture to secure healthcare
system using identity-based encryption. <em>EXSY</em>, <em>39</em>(10),
e12915. (<a href="https://doi.org/10.1111/exsy.12915">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, blockchain and Internet of Things (IoT) are two emerging areas of the Information Technology (IT) sector. These two emerging areas are used in various fields, such as supply chain, logistics and automotive industry. Due to the low processing power and storage space of IoT devices, users&#39; medical information is usually saved in a centralized third party like a clinical repository or a cloud computing environment. Thus, in many cases, users lose control of their medical information, which can result in security disclosure and a single-point impediment. So, an advanced solution is required to improve the data sharing process, while restricting it in terms of security. Blockchain technology with IoT can significantly affect the healthcare industry by improving its efficiency, security and transparency, as well as can provide more business opportunities. The efficient sharing of Electronic Health Record (EHR) can improve the treatment process, diagnosis accuracy, security and privacy. This article proposes a blockchain-based IoT architecture to provide enhanced security of healthcare data by using Identity-Based Encryption (IBE) algorithm. Here, the smart contract defines all the basic operations of the healthcare system, which can be beneficial to all stakeholders. Many experiments are executed to evaluate the efficiency of the proposed scheme. The results show that the proposed scheme is better than the existing renowned schemes.},
  archive      = {J_EXSY},
  author       = {Pratima Sharma and Nageswara Rao Moparthi and Suyel Namasudra and Vimal Shanmuganathan and Ching-Hsien Hsu},
  doi          = {10.1111/exsy.12915},
  journal      = {Expert Systems},
  month        = {12},
  number       = {10},
  pages        = {e12915},
  shortjournal = {Expert Syst.},
  title        = {Blockchain-based IoT architecture to secure healthcare system using identity-based encryption},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analysing terrorist networks – an entropy-driven method.
<em>EXSY</em>, <em>39</em>(10), e12720. (<a
href="https://doi.org/10.1111/exsy.12720">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Terrorism is a scourge of humanity. Thousands of people were killed by terrorists in the last years. To understand the structure, information flow and leadership in terrorist cells is a must for all societies to prevent future attacks. Network theory can help to model such cells and to identify leading members therein. This contribution uses the graph theoretical approach as a basis and enriches it by an entropy-driven knowledge processing. After presenting the theoretical concept two terrorist cells, the one of the Bali attack and the one of the 9/11 attack, are analysed. The results are compared to those of other methods. A preview on the application of weighted networks and multi-nets complements the new findings.},
  archive      = {J_EXSY},
  author       = {Wilhelm Rödder and Andreas Dellnitz and Sebastian Litzinger},
  doi          = {10.1111/exsy.12720},
  journal      = {Expert Systems},
  month        = {12},
  number       = {10},
  pages        = {e12720},
  shortjournal = {Expert Syst.},
  title        = {Analysing terrorist networks – an entropy-driven method},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Convolutional neural network for diagnosis of viral
pneumonia and COVID-19 alike diseases. <em>EXSY</em>, <em>39</em>(10),
e12705. (<a href="https://doi.org/10.1111/exsy.12705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reverse-Transcription Polymerase Chain Reaction (RT-PCR) method is currently the gold standard method for detection of viral strains in human samples, but this technique is very expensive, take time and often leads to misdiagnosis. The recent outbreak of COVID-19 has led scientists to explore other options such as the use of artificial intelligence driven tools as an alternative or a confirmatory approach for detection of viral pneumonia. In this paper, we utilized a Convolutional Neural Network (CNN) approach to detect viral pneumonia in x-ray images using a pretrained AlexNet model thereby adopting a transfer learning approach. The dataset used for the study was obtained in the form of optical Coherence Tomography and chest X-ray images made available by Kermany et al. (2018, https://doi.org/10.17632/rscbjbr9sj.3) with a total number of 5853 pneumonia (positive) and normal (negative) images. To evaluate the average efficiency of the model, the dataset was split into on 50:50, 60:40, 70:30, 80:20 and 90:10 for training and testing respectively. To evaluate the performance of the model, 10 K Cross-validation was carried out. The performance of the model using overall dataset was compared with the means of cross-validation and the currents state of arts. The classification model has shown high performance in terms of accuracy, sensitivity and specificity. 70:30 split performed better compare to other splits with accuracy of 98.73%, sensitivity of 98.59% and specificity of 99.84%.},
  archive      = {J_EXSY},
  author       = {Abdullahi Umar Ibrahim and Mehmet Ozsoz and Sertan Serte and Fadi Al-Turjman and Salahudeen Habeeb Kolapo},
  doi          = {10.1111/exsy.12705},
  journal      = {Expert Systems},
  month        = {12},
  number       = {10},
  pages        = {e12705},
  shortjournal = {Expert Syst.},
  title        = {Convolutional neural network for diagnosis of viral pneumonia and COVID-19 alike diseases},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Computational intelligence applied to cybersecurity.
<em>EXSY</em>, <em>39</em>(9), e13120. (<a
href="https://doi.org/10.1111/exsy.13120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EXSY},
  author       = {Álvaro Herrero and Daniel Urda and Javier Sedano and Héctor Quintián and Emilio Corchado},
  doi          = {10.1111/exsy.13120},
  journal      = {Expert Systems},
  month        = {11},
  number       = {9},
  pages        = {e13120},
  shortjournal = {Expert Syst.},
  title        = {Computational intelligence applied to cybersecurity},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GRU-GBM: A combined intrusion detection model using LightGBM
and gated recurrent unit. <em>EXSY</em>, <em>39</em>(9), e13067. (<a
href="https://doi.org/10.1111/exsy.13067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the increasing sophistication of cyber-attacks, intrusion detection systems need to be improved constantly. Each machine learning classifier has different advantages against intrusion detection and combining the advantages of different classifiers increases detection rates. In this study, we combine a machine learning classifier with a deep learning model to propose a new approach called GRU-GBM. The LightGBM gradient boosting machine framework is used for feature selection, and each feature in the dataset is evaluated by a second LightGBM classifier to determine the optimal feature set using a novel threshold-based approach. After the selection of the feature set, a gated recurrent unit is used for attack detection by a recurrent neural network model. Besides, different training/testing ratios (60/40–70/30) are chosen for comparison of GRU-GBM accuracy. The proposed combined model achieved 76.61% and 93.65% overall accuracy in multi-class experiments conducted with the UNSW-NB15 and LITNET-2020 datasets, respectively. Lastly, the GRU-GBM model is compared to other machine learning models. The overall accuracy result is tested with a non-parametric Friedman test to determine the significance of the results. The test result shows that there is enough evidence that the accuracy of the GRU-GBM classifier is statistically significant.},
  archive      = {J_EXSY},
  author       = {Alper Sarıkaya and Banu Günel Kılıç and Mehmet Demirci},
  doi          = {10.1111/exsy.13067},
  journal      = {Expert Systems},
  month        = {11},
  number       = {9},
  pages        = {e13067},
  shortjournal = {Expert Syst.},
  title        = {GRU-GBM: A combined intrusion detection model using LightGBM and gated recurrent unit},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Network intrusion detection system: A survey on artificial
intelligence-based techniques. <em>EXSY</em>, <em>39</em>(9), e13066.
(<a href="https://doi.org/10.1111/exsy.13066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High data rate requirements in recent years have resulted in the massive expansion of communication systems, network size and the amount of data generated and processed. This has eventually caused many threats to the communication networks as well due to a more frequent generation of security attacks that are either novel or the mutation of the existing attacks. To secure the networks against such threats, an intrusion detection system (IDS) is considered as one of the promising solutions. The main problem with the IDS is its increased false alarm rate (FAR) in detecting the zero-day attacks. To improve the detection accuracy and minimizing the FAR, the researchers proposed IDS solutions using artificial intelligence (AI) approaches. In this research, we have systematically reviewed the recent AI-based network IDS (NIDS) solutions proposed during the period 2016–2021 by the research community. We systematically analysed the proposed NIDS solutions based on their strengths, shortcomings, AI methodology adopted, datasets, and the evaluation metrics used for evaluation purposes. From the review, we observed that the hybrid approach is mostly adopted by the researchers to propose AI-based NIDS solutions, with a trend shifting to deep learning-based approaches over the last 2 years. Also, most of the proposed solutions are evaluated using a very old dataset with only a few studies opting for the latest datasets. Finally based on our observations, we highlighted the research challenges and the future research directions to help young researchers to contribute to this field.},
  archive      = {J_EXSY},
  author       = {Mohammed Sayeeduddin Habeeb and T. Ranga Babu},
  doi          = {10.1111/exsy.13066},
  journal      = {Expert Systems},
  month        = {11},
  number       = {9},
  pages        = {e13066},
  shortjournal = {Expert Syst.},
  title        = {Network intrusion detection system: A survey on artificial intelligence-based techniques},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey of visual analytics in urban area. <em>EXSY</em>,
<em>39</em>(9), e13065. (<a
href="https://doi.org/10.1111/exsy.13065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, the population has been overgrowing due to urbanization, yielding many severe problems in the urban area, including traffic congestion, unbalanced distribution of urban hotspots, air pollution and so on. Due to the uncertainty of the urban environment, it always needs to integrate experts&#39; domain knowledge into solving these issues. In recent years, the visual analytics method has been widely used to assist domain experts in solving urban problems with its intuitiveness, interactivity and interpretability. In this survey, we first introduce the background of urban computing, present the motivation of visual analytics in the urban area and point out the characteristics of visual analytics methods. Second, we introduce the most frequently used urban data, analyse the main properties and provide an overview on how to use these data. Thereafter, we propose our taxonomy for visual analytics in the urban area and illustrate the taxonomy. The taxonomy provides four levels for visual analytics on urban data from a new perspective based on the four stages in data mining. Four levels from our taxonomy include: descriptive analytics, diagnostic analytics, predictive analytics and prescriptive analytics. Finally, we conclude this survey by discussing the limitations of the existing related works and the challenges to visual analytics in the urban area.},
  archive      = {J_EXSY},
  author       = {Zezheng Feng and Huamin Qu and Shuang-Hua Yang and Yulong Ding and Jie Song},
  doi          = {10.1111/exsy.13065},
  journal      = {Expert Systems},
  month        = {11},
  number       = {9},
  pages        = {e13065},
  shortjournal = {Expert Syst.},
  title        = {A survey of visual analytics in urban area},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cardiovascular disease prediction using recursive feature
elimination and gradient boosting classification techniques.
<em>EXSY</em>, <em>39</em>(9), e13064. (<a
href="https://doi.org/10.1111/exsy.13064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiovascular diseases are one of the most common chronic illnesses that affect people&#39;s health. Early detection of cardiovascular diseases&#39;s can reduce mortality rates by preventing or reducing the severity of the disease. Machine learning algorithms are a promising method for identifying risk factors. This article proposes a recursive feature elimination-based gradient boosting algorithm in order to obtain accurate heart disease prediction. The patients&#39; health record with important cardiovascular disease features has been analysed for the evaluation of the results. Several other machine learning methods were also used to build the prediction model, and the results were compared with the proposed model. The results of this proposed model infer that the combined recursive feature elimination and gradient boosting algorithm achieves the highest accuracy (89.7%). Further, with an area under the curve of 0.84, the proposed algorithm was found superior and had obtained a substantial gain over other techniques. Thus, the proposed gradient boosting algorithm will serve as a prominent cardiovascular disease estimation and treatment model.},
  archive      = {J_EXSY},
  author       = {Prasannavenkatesan Theerthagiri and Jyothiprakash Vidya},
  doi          = {10.1111/exsy.13064},
  journal      = {Expert Systems},
  month        = {11},
  number       = {9},
  pages        = {e13064},
  shortjournal = {Expert Syst.},
  title        = {Cardiovascular disease prediction using recursive feature elimination and gradient boosting classification techniques},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Social network analysis for cross-evaluation in data
envelopment analysis. <em>EXSY</em>, <em>39</em>(9), e13063. (<a
href="https://doi.org/10.1111/exsy.13063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the important extensions of data envelopment analysis (DEA) methodology, cross-evaluation combines self-evaluation and peer-evaluation processes for each decision making unit (DMU) to effectively eliminate unrealistic weight schemes and differentiate all the units for ranking. Differing from previous research, which mainly pays attention to either secondary goals for generating weights for peer evaluation or aggregation of self and peer-evaluation efficiencies, our study focuses on evaluating the relationships among all DMUs. If we view each unit as a node to be evaluated, then peer-evaluation among pairs of DMUs forms a bidirectional network among all the DMUs. Based on this idea, we introduce a data-driven tool combining social network analysis and cross-evaluation to examine self-evaluated and peer-evaluated scores in the network. Using the hyperlink-induced topic search algorithm, we develop the concepts of self-evaluation and peer-evaluation objectivity coefficients based on how well DMUs accept the analysis results. The rankings based on our self-evaluation and peer-evaluation scores adjusted with objectivity coefficients are shown to be consistent. Our study provides a novel perspective for cross-evaluation and DEA research. An application case study illustrates our new method.},
  archive      = {J_EXSY},
  author       = {Sheng Ang and Hui Wu and Menghan Chen and Feng Yang},
  doi          = {10.1111/exsy.13063},
  journal      = {Expert Systems},
  month        = {11},
  number       = {9},
  pages        = {e13063},
  shortjournal = {Expert Syst.},
  title        = {Social network analysis for cross-evaluation in data envelopment analysis},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improved k-means algorithm for clustering non-spherical
data. <em>EXSY</em>, <em>39</em>(9), e13062. (<a
href="https://doi.org/10.1111/exsy.13062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the commonly used data mining algorithms, K-means has the advantage of fast clustering speed, but the disadvantage is that it is less effective for clustering non-spherical data. An improved K-means algorithm (IK-means) is proposed to enhance clustering efficiency for non-spherical data. The original dataset is clustered into a relatively larger number of high-density sub-clusters, and the final result is obtained by merging connected sub-clusters respectively. The connectivity among sub-clusters is evaluated by the sub-clusters density and the nearest distance class between sub-clusters. By testing on University of California, Irvine(UCI) datasets and several other artificial simulation datasets, the comparison of proposed IK-means algorithm against DBSCAN, KGFCM shows its clustering capability for data of arbitrary shape. The clustering Adjusted Rand Index (ARI) value for 72,000 sizes data is 24% higher than DBSCAN, and 95.2% higher than KGFCM. For larger datasets, the IK-means algorithm is faster than DBSCAN and KGFCM.},
  archive      = {J_EXSY},
  author       = {Honglei He and Yuxuan He and Fang Wang and Wenming Zhu},
  doi          = {10.1111/exsy.13062},
  journal      = {Expert Systems},
  month        = {11},
  number       = {9},
  pages        = {e13062},
  shortjournal = {Expert Syst.},
  title        = {Improved K-means algorithm for clustering non-spherical data},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RFFS: Recursive random forest feature selection based
ensemble algorithm for chronic kidney disease prediction. <em>EXSY</em>,
<em>39</em>(9), e13048. (<a
href="https://doi.org/10.1111/exsy.13048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chronic kidney disease is a global health issue that affects millions of people worldwide and causes significant social, economic, and medical issues. Several automated detection systems can diagnose chronic kidney disease. This paper proposes the recursive random forest feature selection (RFFS) based ensemble learning algorithm to diagnose chronic kidney diseases (CKD). In the decision point, decision tree-based classifiers are used. The accuracy and kappa scores are used to determine the classification results. According to the results of the proposed algorithm&#39;s performance analyses, the ensemble learning classifiers outperform other classifiers for classifying CKD. The proposed RFFS algorithm achieves 6%–40% improved prediction accuracy using the feature selection algorithm. Further, it attains 15%–39% of reduced mean square error. The performance metrics, precision, sensitivity, specificity, f1 score, and Jaccard scores, have been analysed and show greater results for the RFFS algorithm. Thus, the proposed RFE-GB algorithm results prove it as a prominent model for CKD estimation and treatment.},
  archive      = {J_EXSY},
  author       = {Prasannavenkatesan Theerthagiri and A. Usha Ruby},
  doi          = {10.1111/exsy.13048},
  journal      = {Expert Systems},
  month        = {11},
  number       = {9},
  pages        = {e13048},
  shortjournal = {Expert Syst.},
  title        = {RFFS: Recursive random forest feature selection based ensemble algorithm for chronic kidney disease prediction},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-task learning based approach for efficient breast
cancer detection and classification. <em>EXSY</em>, <em>39</em>(9),
e13047. (<a href="https://doi.org/10.1111/exsy.13047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic segmentation and classification of breast tumours in ultrasound images using deep learning approaches can help early detect breast cancer. Such predictive modelling can potentially significantly improve the survival chances of the involved patients. Most of the typical deep convolutional neural network (CNN) based approaches consider segmentation and classification tasks separately. But this loses important supervisory information to help achieve better model training. This work proposes the integrated learning of both of these tasks in an end-to-end manner, using a multi-task learning based approach. More specifically, a convolutional encoder-decoder based architecture is coupled with a residual CNN for performing segmentation and classification together. The level-wise feature maps from both the encoder and decoder parts of the segmentation network are utilized for classification in the proposed approach. From experimental analysis on a publicly available breast ultrasound image (BUSI) dataset, it has been observed that the proposed approach can achieve impressive performances, both with respect to tumour segmentation and classification. A mean test set AUC of 0.97 and a mean dice score of 0.74 is achieved, establishing a new state-of-the-art performance on the BUSI dataset. From the impressive experimental observations, it can be concluded that learning to perform both segmentation and classification simultaneously can have a very high positive impact on the overall quality of the predictive model. Such observations suggest that the proposed approach can be beneficial in providing real-time decision support to the involved diagnostic radiologists, which can help improve the survival chances of the corresponding patients.},
  archive      = {J_EXSY},
  author       = {Arnab Kumar Mishra and Pinki Roy and Sivaji Bandyopadhyay and Sujit Kumar Das},
  doi          = {10.1111/exsy.13047},
  journal      = {Expert Systems},
  month        = {11},
  number       = {9},
  pages        = {e13047},
  shortjournal = {Expert Syst.},
  title        = {A multi-task learning based approach for efficient breast cancer detection and classification},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Effect of vocal tract dynamics on neural network-based
speech recognition: A bengali language-based study. <em>EXSY</em>,
<em>39</em>(9), e13045. (<a
href="https://doi.org/10.1111/exsy.13045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although speech recognition has achieved significant success using integrated and efficient models, still some series of challenges remain as linguistic-acoustic patterns are perturbed by speakers&#39; individual articulation gestures and environmental noises. Due to dynamic changes in the vocal tract cavity, word utterances yield temporal and perturbed linguistic-acoustic features, whereas vowel utterances yield less-perturbed quasi-stationary features. To recognize patterns as in vowels and words, the basic feedforward neural network (NN), among other methods, responds to these vocal tract-induced variabilities and has shown promising results because of its simple yet effective modelling of nonlinear data. We, therefore, present a comprehensive study on how these variabilities of acoustical features affect the speech token classification performances using NNs. We chose vocal tract resonance (formant frequency) as linguistic-acoustic feature. Our statistical evaluation of vocal tract-induced variabilities in seven Bengali vowels and words revealed that words have more variations than vowels. We used four-fold cross-validation in an NN with Adam optimizer to compute classification performances using five different metrics. Our experiments found that formant transitions and dispersions do not contribute to classification, and five-hidden-layered NN is optimum. In all different test cases, we justified our hypothesis—word classification falls behind vowel classification due to the variability induced by vocal tract dynamics. The optimum NN with 28,263 trainable parameters achieved the highest accuracy and AUC scores: 0.89 and 0.99 in vowels, and 0.64 and 0.91 in words.},
  archive      = {J_EXSY},
  author       = {Md Rakibul Hasan and Md Mahbub Hasan and Md Zakir Hossain},
  doi          = {10.1111/exsy.13045},
  journal      = {Expert Systems},
  month        = {11},
  number       = {9},
  pages        = {e13045},
  shortjournal = {Expert Syst.},
  title        = {Effect of vocal tract dynamics on neural network-based speech recognition: A bengali language-based study},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Research on corporate financial performance prediction based
on self-organizing and convolutional neural networks. <em>EXSY</em>,
<em>39</em>(9), e13042. (<a
href="https://doi.org/10.1111/exsy.13042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Economic risks faced by manufacturing enterprises are gradually increasing and risk reduction whilst maintaining high financial performance has become key to their survival and development of enterprises. Enterprise performance affects not only enterprise development but also does the interests of investors and creditors. Therefore, a well-performing model for financial performance prediction is particularly important. In this paper, we combine unsupervised and supervised learning, fusing self-organizing mapping neural networks and convolutional neural networks, and apply deep learning to financial analysis to construct a new financial performance prediction model, called SNN-CNN. This paper uses crawler technology to obtain financial data of listed manufacturing enterprises and classifies their financial performance into five levels. It finds that enterprises with high financial performance tend to have balanced financial indicators, strong corporate vitality and stable development of various capabilities, while enterprises with low financial performance have poor repayment and profitability, significant risks in corporate operation and limited growth and development. Compared with traditional risk prediction models, the SOM-CNN model has a higher accuracy rate, up to 95.69%.},
  archive      = {J_EXSY},
  author       = {Maoze Zhou and Hongjiu Liu and Yanrong Hu},
  doi          = {10.1111/exsy.13042},
  journal      = {Expert Systems},
  month        = {11},
  number       = {9},
  pages        = {e13042},
  shortjournal = {Expert Syst.},
  title        = {Research on corporate financial performance prediction based on self-organizing and convolutional neural networks},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feedback artificial tree-anti corona virus optimization
enabled deep learning for detecting autism spectrum disorder.
<em>EXSY</em>, <em>39</em>(9), e13040. (<a
href="https://doi.org/10.1111/exsy.13040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autism spectrum disorder (ASD) is an umbrella term for a number of neurodevelopmental conditions with many heterogeneous behavioural indications. Recent medical imaging approaches use functional Magnetic Resonance Imaging (fMRI) for human recognition of the various neurological syndromes. However, these traditional techniques are time consuming and expensive. Thus, in this research, an optimization assisted deep learning technique, named Feedback Artificial Virus Optimization (FAVO)-based deep residual network (DRN), is developed. FAVO-based DRN is designed to incorporate the Feedback Artificial Tree (FAT) algorithm with Anti Corona Virus Optimization (ACVO). First, Region-Of-Interest extraction is carried out using thresholding techniques with nub region extraction completed using the proposed FAVO algorithm. ASD classification is then carried out using a DRN classifier. Evaluation of the proposal uses the ABIDE-1 and ABIDE-2 datasets. The developed FAVO algorithm attains better accuracy, sensitivity, and specificity of 0.9214, 0.9365, and 0.9142, respectively, by considering ABIDE-2 dataset.},
  archive      = {J_EXSY},
  author       = {Arunkumar Arumugam and Pitchandi Velrajkumar and Gopalsamy Venkadakrishnan Sriramakrishnan and Satish Muppidi},
  doi          = {10.1111/exsy.13040},
  journal      = {Expert Systems},
  month        = {11},
  number       = {9},
  pages        = {e13040},
  shortjournal = {Expert Syst.},
  title        = {Feedback artificial tree-anti corona virus optimization enabled deep learning for detecting autism spectrum disorder},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Classification of brain tumours in MRI images using
convolutional neural network through cat swarm optimization.
<em>EXSY</em>, <em>39</em>(9), e13021. (<a
href="https://doi.org/10.1111/exsy.13021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In humans, a brain abnormality is a serious illness. Cancer which is the greatest cause of mortality can develop from the tumour. Magnetic resonance imaging (MRI) is among a more extensively utilized medical imaging modalities in brain tumours, then it has become the primary diagnosing mechanism for the treatment and evaluation of brain tumours. Computer-assisted diagnosis has become a requirement due to the exponential expansion in the quantity of MRIs acquired because of these programmes. Computer-assisted diagnosis strategies created to increase detection without many systematized readings failed to produce significant improvements in performance measurements. In this regard, the usage of deep learning-based automatic image processing algorithms appears to be a viable route for identifying brain cancer. In this research, introduce a Cat Swarm Optimization (CSO) algorithm based upon a convolutional neural network (CNN) model utilized to segmentation in a classification of brain tumour. Results of experiments on MRI images using the BRATS dataset show that the CSO algorithm-CNN model achieved high-performance in term of 98% of accuracy, precision, specificity, sensitivity and F-score in the proposed classification task when compared to other classification approaches like support vector machines (SVM) as well as back propagation neural networks (BPNN).},
  archive      = {J_EXSY},
  author       = {Deepak V. K. and Sarath R},
  doi          = {10.1111/exsy.13021},
  journal      = {Expert Systems},
  month        = {11},
  number       = {9},
  pages        = {e13021},
  shortjournal = {Expert Syst.},
  title        = {Classification of brain tumours in MRI images using convolutional neural network through cat swarm optimization},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Special issue “role of artificial intelligence in medical
imaging.” <em>EXSY</em>, <em>39</em>(9), e13019. (<a
href="https://doi.org/10.1111/exsy.13019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EXSY},
  author       = {Syed Hassan Ahmed and Murad Khan and Wael Guibene},
  doi          = {10.1111/exsy.13019},
  journal      = {Expert Systems},
  month        = {11},
  number       = {9},
  pages        = {e13019},
  shortjournal = {Expert Syst.},
  title        = {Special issue ‘role of artificial intelligence in medical imaging’},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards explainability in robotics: A performance analysis
of a cloud accountability system. <em>EXSY</em>, <em>39</em>(9), e13004.
(<a href="https://doi.org/10.1111/exsy.13004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding why a robot&#39;s behaviour was triggered is a growing concern to get human-acceptable social robots. Every action, expected and unexpected, should be able to be explained and audited. The formal model proposed here deals with different information levels, from low-level data, such as sensors&#39; data logging; to high-level data that provide an explanation of the robot&#39;s behaviour. This study examines the impact on the robot system of a custom log engine based on a custom ROS logging node and investigates pros and cons when used together with a NoSQL database locally and in a cloud environment. Results allow to characterize these alternatives and explore the best strategy for offering a fully log-based accountability engine that maximizes the mapping between robot behaviour and robot logs.},
  archive      = {J_EXSY},
  author       = {Francisco Javier Rodríguez-Lera and Miguel Ángel González-Santamarta and Ángel Manuel Guerrero-Higueras and Francisco Martín-Rico and Vicente Matellán-Olivera},
  doi          = {10.1111/exsy.13004},
  journal      = {Expert Systems},
  month        = {11},
  number       = {9},
  pages        = {e13004},
  shortjournal = {Expert Syst.},
  title        = {Towards explainability in robotics: A performance analysis of a cloud accountability system},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Health care intelligent system: A neural network based
method for early diagnosis of alzheimer’s disease using MRI images.
<em>EXSY</em>, <em>39</em>(9), e13003. (<a
href="https://doi.org/10.1111/exsy.13003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer&#39;s disease (AD) is a neurodegenerative disease that causes memory loss and is considered the most common type of dementia. In many countries, AD is commonly affecting senior citizens having an aged more than 65 years. Machine learning-based approaches have some limitations due to data pre-processing issues. We propose a health care intelligent system based on a deep convolutional neural network (DCNN) in this research work. It classifies normal control (NC), mild cognitive impairment (MCI), and AD. The proposed model is employed on white matter (WM), and grey matter (GM) tissues with more cognitive decline features. In the experimental process, we used 375 Magnetic Resonance Image (MRI) subjects collected from Alzheimer&#39;s disease neuroimaging initiative (ADNI), including 130 NC people, 120 MCI patients, and 125 AD patients. We extract three major regions during pre-processing, that is, WM, GM and cerebrospinal fluid (CSF). This study shows promising classification results for NC versus AD 97.94%, MCI versus AD 92.84%, and NC versus MCI 88.15% on GM images. Furthermore, our proposed model attained 95.97%, 90.82%, and 86.87% on the same three binary classes on WM tissue, respectively. When comparing existing studies in terms of accuracy and other evaluation parameters, we found that our proposed approach shows better results than those approaches based on the CNN method.},
  archive      = {J_EXSY},
  author       = {Ahed Abugabah and Atif Mehmood and Sultan Almotairi and Ahmad A. L. Smadi},
  doi          = {10.1111/exsy.13003},
  journal      = {Expert Systems},
  month        = {11},
  number       = {9},
  pages        = {e13003},
  shortjournal = {Expert Syst.},
  title        = {Health care intelligent system: A neural network based method for early diagnosis of alzheimer&#39;s disease using MRI images},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid one-class approach for detecting anomalies in
industrial systems. <em>EXSY</em>, <em>39</em>(9), e12990. (<a
href="https://doi.org/10.1111/exsy.12990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The significant advance of Internet of Things in industrial environments has provided the possibility of monitoring the different variables that come into play in an industrial process. This circumstance allows the supervision of the current state of an industrial plant and the consequent decision making possibilities. Then, the use of anomaly detection techniques are presented as a powerful tool to determine unexpected situations. The present research is based on the implementation of one-class classifiers to detect anomalies in two industrial systems. The proposal is validated using two real datasets registered during different operating points of two industrial plants. To ensure a better performance, a clustering process is developed prior the classifier implementation. Then, local classifiers are trained over each cluster, leading to successful results when they are tested with both real and artificial anomalies. Validation results present in all cases, AUC values above 90%.},
  archive      = {J_EXSY},
  author       = {Francisco Zayas-Gato and Esteban Jove and José-Luis Casteleiro-Roca and Héctor Quintián and Andrés Piñón-Pazos and Dragan Simić and José Luis Calvo-Rolle},
  doi          = {10.1111/exsy.12990},
  journal      = {Expert Systems},
  month        = {11},
  number       = {9},
  pages        = {e12990},
  shortjournal = {Expert Syst.},
  title        = {A hybrid one-class approach for detecting anomalies in industrial systems},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feature optimization and identification of ovarian cancer
using internet of medical things. <em>EXSY</em>, <em>39</em>(9), e12987.
(<a href="https://doi.org/10.1111/exsy.12987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ovarian cancer (OC) is one kind of tumour that impacts women&#39;s ovaries and is hard to diagnose in the initial phase as a primary cause of cancer death. The ovarian cancer information generated by the Clinical Network has been used, and the Self Organizing Map (SOM) and Optimized Neural Networks have suggested a new method for the distinction between ovarian cancer and remaining cancer. Feature optimization and identification of the ovarian cancer (FOI-OV) framework are proposed in this research. The SOM algorithm has also been used separately to improve the functional subset, with understandable and intriguing information from participants&#39; health information steps. The SOM-based collection appears to be tolerable in guided learning strategies due to the lack of different classifiers, which would direct the quest for knowledge specific to the classification algorithm. The classification technique will classify data from ovarian cancer as benign/malignant. By optimizing Neural Network configuration, Advanced Harmony Searching Optimization (AHSO) can enhance the ovarian cancer detection method compared with other methods. This research&#39;s suggested model can also diagnose cancer with high precision, and low root means square error (RMSE) early. With 94% precision and 0.029%, RMSE, SOM, and NN techniques have shown identification and precision in ovarian cancer. Optimization (AHSO) has provided an efficient classification approach with a better failure rate.},
  archive      = {J_EXSY},
  author       = {Taher M. Ghazal and Nasser Taleb},
  doi          = {10.1111/exsy.12987},
  journal      = {Expert Systems},
  month        = {11},
  number       = {9},
  pages        = {e12987},
  shortjournal = {Expert Syst.},
  title        = {Feature optimization and identification of ovarian cancer using internet of medical things},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). 3D brain image-based alzheimer’s disease detection
techniques using fish swarm optimizer’s deep convolution siamese neural
network. <em>EXSY</em>, <em>39</em>(9), e12963. (<a
href="https://doi.org/10.1111/exsy.12963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer&#39;s disease (AD), a chronic syndrome that impacts the brain, is the most prevalent form of dementia. Dementia is a brain disease that severely affects an individual&#39;s ability to perform daily activities. It starts slowly affects the brain and creates a loss of memory, language, problem-solving and other thinking abilities. Hence, early detection is essential to avoid the severity of this illness. Neuroimaging techniques are widely recommended diagnosing approaches by medicos for early AD detection. However, detecting AD using imaging is a challenging and time-consuming task for human expertise. Many machine learning techniques already exist in automatic AD stages detection, but these techniques are failed to handle main issues in AD detection systems such, as preserving and identifying precise biomarker regions certainty handling and; in this research, a new convolution-based AD stages detection framework is introduced to resolve the earlier detection system&#39;s challenges and issues. The first two convolution layers contain resizing, adaptive filtering, and adaptive histogram equalization techniques to enhance the image quality, preserving biomarker features. The third layer contains the Voxel-based Morphometry (VBM) technique to segment the exact biomarker regions of AD stages from brain MRI images. The segmented biomarker feature is extracted and selected in the fourth and fifth layers to identify exact significant biomarker features to reduce the overfitting problem during the model training. Finally, the new food source direction investigation feature of the fish swarm optimizer (FSO) is incorporated in the deep Siamese neural network (DSNN) classification phase, which reduces the uncertainty issue during model training. The efficiency is evaluated using ADNI, AIBL, and OASIS database MRI images with various accuracy metrics. The evolution results show that the new framework is obtained a higher accuracy rate of 99.89% in AD stages detection than the comparison classifiers.},
  archive      = {J_EXSY},
  author       = {Rajaram Sampath and Manickam Baskar},
  doi          = {10.1111/exsy.12963},
  journal      = {Expert Systems},
  month        = {11},
  number       = {9},
  pages        = {e12963},
  shortjournal = {Expert Syst.},
  title        = {3D brain image-based alzheimer&#39;s disease detection techniques using fish swarm optimizer&#39;s deep convolution siamese neural network},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detecting pulmonary oedema in lung resection patient through
point-of-care lung ultrasonography. <em>EXSY</em>, <em>39</em>(9),
e12962. (<a href="https://doi.org/10.1111/exsy.12962">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EXSY},
  author       = {Xiaoning Zhao and Yong Liu and Mingyan Sun and Yingying Wang and Bailing Qian},
  doi          = {10.1111/exsy.12962},
  journal      = {Expert Systems},
  month        = {11},
  number       = {9},
  pages        = {e12962},
  shortjournal = {Expert Syst.},
  title        = {Detecting pulmonary oedema in lung resection patient through point-of-care lung ultrasonography},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detecting breast cancer using novel mask r-CNN techniques.
<em>EXSY</em>, <em>39</em>(9), e12954. (<a
href="https://doi.org/10.1111/exsy.12954">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is more common in women and the mortality rate also increases in recent days. Early detection of breast cancer is reduces the severity of the disease to some extent. Various image processing and classification techniques imposed on a particular image to detect and diagnose the breast cancer clearly. For early detection, an efficient methodology is needed. To reduce death rate, accurate discovery of the disease should be efficiently implemented. The mask R-CNN is used for segmentation to identify abnormalities and ensemble CNN is used to classify the benign and malignant tumour from the given mammographic breast cancer image. The input is fed into the enhanced fuzzy based median filter which is used to remove speckle noises which in turn increases the clarity of images. The noise-free images are fed into the proposed mask R-CNN for segmentation. It is an effective framework for segmentation of medical images. The classification process is then given into ensemble based CNN classifier for prediction of mammogram images. The ensemble based CNN is proposed for the classification of mammograms as benign and malignant. The proposed method focus on the optimization which is performed to minimize the memory requirements and running time while maintaining the high performance of the classifier. The performance metrics such as accuracy, precision, f-measure, and recall is evaluated to measure the efficacy of the proposed design. Using MIAS and DDSM dataset the performance metrics has been evaluated and compared with existing approaches. The results shows that the performance of the proposed method shows higher efficiency.},
  archive      = {J_EXSY},
  author       = {Gul Shaira Banu Jahangeer and Dhiliphan Rajkumar Thambidurai},
  doi          = {10.1111/exsy.12954},
  journal      = {Expert Systems},
  month        = {11},
  number       = {9},
  pages        = {e12954},
  shortjournal = {Expert Syst.},
  title        = {Detecting breast cancer using novel mask R-CNN techniques},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Secure protocols for smart contract based insurance
services. <em>EXSY</em>, <em>39</em>(9), e12950. (<a
href="https://doi.org/10.1111/exsy.12950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cryptocurrency-based transactions are exposed to serious security risks, usually higher than risks related to traditional online transactions. The threats range from unintentional credential leaks, through fraudulent cryptocurrency exchanges and poorly implemented protocols, to broken private keys. Therefore, there is a business need for insurance services dedicated to cryptocurrencies that would be technologically as well as economically secure for both insuring and insured party. In this paper an architecture for cryptocurrency insurance framework along with a set of corresponding communication protocols and a smart contract template that jointly reduce various security risks are proposed. The detailed description of the solution is followed by the security analysis section. Also, the description of the presented solution is preceded by a general risk analysis related to cryptocurrency unit security and countermeasures analysis related to those risks. The authors believe that the presented technological solution can potentially enable new business models based on crypto-insurance services.},
  archive      = {J_EXSY},
  author       = {Daniel Wilusz and Adam Wójtowicz},
  doi          = {10.1111/exsy.12950},
  journal      = {Expert Systems},
  month        = {11},
  number       = {9},
  pages        = {e12950},
  shortjournal = {Expert Syst.},
  title        = {Secure protocols for smart contract based insurance services},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SLDCNet: Skin lesion detection and classification using full
resolution convolutional network-based deep learning CNN with transfer
learning. <em>EXSY</em>, <em>39</em>(9), e12944. (<a
href="https://doi.org/10.1111/exsy.12944">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EXSY},
  author       = {P. Bharat Siva Varma and Siddartha Paturu and Suman Mishra and B. Srinivasa Rao and Pala Mahesh Kumar and Namani Vamshi Krishna},
  doi          = {10.1111/exsy.12944},
  journal      = {Expert Systems},
  month        = {11},
  number       = {9},
  pages        = {e12944},
  shortjournal = {Expert Syst.},
  title        = {SLDCNet: Skin lesion detection and classification using full resolution convolutional network-based deep learning CNN with transfer learning},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). BLSNet: Skin lesion detection and classification using broad
learning system with incremental learning algorithm. <em>EXSY</em>,
<em>39</em>(9), e12938. (<a
href="https://doi.org/10.1111/exsy.12938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EXSY},
  author       = {V. S. S. P. Raju Gottumukkala and N. Kumaran and V. Chandra Sekhar},
  doi          = {10.1111/exsy.12938},
  journal      = {Expert Systems},
  month        = {11},
  number       = {9},
  pages        = {e12938},
  shortjournal = {Expert Syst.},
  title        = {BLSNet: Skin lesion detection and classification using broad learning system with incremental learning algorithm},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fuzzy expert system for road type identification and risk
assessment of conventional two-lane roads. <em>EXSY</em>,
<em>39</em>(9), e12837. (<a
href="https://doi.org/10.1111/exsy.12837">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper first presents a fuzzy expert system to identify and classify conventional two-lane roads based on geometric characteristics. Both fuzzy and neuro-fuzzy techniques have been used. Fuzzy logic has proved suitable to address this problem, since in this case, there is a variability of input information, and classical rules are not suitable to be used due to the uncertainty introduced by some combinations of the variables. Each road&#39;s geometric features were measured by sensors in an equipped vehicle, and are subsequently used to classify the roads according to their real condition. The conventional two-lane roads used for this research are located in the Madrid Region, in Spain. This intelligent system may be used to update the road database regarding the assigned type to each conventional road, according to their present features and state. Also, a risk identification system has been developed to assess whether a vehicle is driving on a two-lane road with an inappropriate speed, combining variables such as the former identification model, vehicle type, road longitudinal gradient, the angle covered by each horizontal curve, and the existence or not of an additional traffic lane. A fuzzy risk index is proposed for this approach. This fuzzy model may be useful to detect road sections where safety must be enhanced by revising the speed limit, since less safe situations may arise from travelling at unappropriated speeds.},
  archive      = {J_EXSY},
  author       = {Felipe Barreno and Manuel G. Romana and Matilde Santos},
  doi          = {10.1111/exsy.12837},
  journal      = {Expert Systems},
  month        = {11},
  number       = {9},
  pages        = {e12837},
  shortjournal = {Expert Syst.},
  title        = {Fuzzy expert system for road type identification and risk assessment of conventional two-lane roads},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep neural network for multi-class classification of
medicinal plant leaves. <em>EXSY</em>, <em>39</em>(8), e13041. (<a
href="https://doi.org/10.1111/exsy.13041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Plant diseases are a critical issue in the farming industry, and early identification is essential for plant monitoring. The leaves of plants represent the majority of disease symptoms, however, leaf analysis by specialists in laboratories is expensive and time-consuming. Hence, there is a necessity for automated and more accurate plant disease detection techniques which can help in diagnosing early symptoms to turn down the economic loss. A deep-learning-based technique for detecting and classifying plant diseases from leaf images is provided in this research. A diversified image dataset of plant leaves with 12 distinct crops in 22 different categories was used for this work. Several intra-class and inter-class variations in the training dataset make it more complex and challenging to train a deep-learning model. An exhaustive analysis of different deep neural networks has been done with different combinations of optimizers and learning rates. Additionally, five-fold cross-validation and testing on separate test images have been done for a detailed investigation of the trained model in different statistical parameters. The proposed approach extended the results to an average cross-validation accuracy of 98.68%, and average test accuracy of 97.69% is obtained on unseen images having intra-class and inter-class variations.},
  archive      = {J_EXSY},
  author       = {Vaibhav Tiwari and Rakesh Chandra Joshi and Malay Kishore Dutta},
  doi          = {10.1111/exsy.13041},
  journal      = {Expert Systems},
  month        = {9},
  number       = {8},
  pages        = {e13041},
  shortjournal = {Expert Syst.},
  title        = {Deep neural network for multi-class classification of medicinal plant leaves},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An efficient feature selection method based on improved
elephant herding optimization to classify high-dimensional biomedical
data. <em>EXSY</em>, <em>39</em>(8), e13038. (<a
href="https://doi.org/10.1111/exsy.13038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning algorithms are widely applied to biomedical data to classify the samples of patients and healthy persons. The high-dimensional biomedical datasets contain a large number of features to represent a sample. However, such datasets may have redundant, noisy and irrelevant features, influencing machine learning algorithms&#39; classification performance and increasing computation overhead. Therefore, data normalization and feature selection techniques are introduced to reduce the impact of noisy features and accurately identify the patterns in features to improve the predictive accuracy of diagnosis. This work proposes an efficient feature selection and parameter optimization method to classify high-dimensional biomedical datasets. In the proposed method, a binary version of the improved elephant herding optimization (IEHO) algorithm is introduced to select features and optimize the C and γ parameters of the support vector machine classifier. Further, four variants of the proposed method are presented based on data normalization techniques: Z -score normalization (ZN), Pareto-scaling (PS), tan h -based normalization (TN), and variant of tan h -based normalization (VTN). The proposed variants reduce the dominance of noisy features and explore the feature space to obtain the optimal feature set that maximizes the classification accuracy and minimizes the time complexity. The performance of the proposed variants is evaluated on 15 high-dimensional biomedical datasets. Friedman&#39;s mean rank test is applied to check the statistical difference between proposed variants. Results show that the proposed Z -score normalization-IEHO (ZN-IEHO) variant performed significantly better than the other proposed variants for classification accuracy, false-positive rate and f -score metrics. Moreover, the performance of the proposed ZN-IEHO variant is compared with 18 state-of-the-art feature selection methods. The experimental results expressed the effectiveness of the proposed ZN-IEHO variant in finding the best combination of features and parameters to classify the biomedical datasets accurately.},
  archive      = {J_EXSY},
  author       = {Harpreet Singh and Birmohan Singh and Manpreet Kaur},
  doi          = {10.1111/exsy.13038},
  journal      = {Expert Systems},
  month        = {9},
  number       = {8},
  pages        = {e13038},
  shortjournal = {Expert Syst.},
  title        = {An efficient feature selection method based on improved elephant herding optimization to classify high-dimensional biomedical data},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Document forgery detection using source printer
identification: A comparative study of text-dependent versus
text-independent analysis. <em>EXSY</em>, <em>39</em>(8), e13020. (<a
href="https://doi.org/10.1111/exsy.13020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Source printer identification represents an interesting modality for document forgery detection. Establishing the identity of the printer that was employed to print a questioned document allows concluding its authenticity. This paper investigates the effectiveness of deep visual features (learned using convolutional neural networks) in characterization of the source printer. Images of printed documents are divided into small patches as well as characters for extraction of features. An off-the-shelf recognition engine is also integrated, allowing experiments in text-dependent as well as text-independent modes. Experiments are carried out on a standard data set of documents from 20 different printers and identification rates of 95.52% and 98.06% are reported using patches and characters, respectively. Furthermore, the discriminating power of different characters, as well as their combinations, is also being studied. Unlike many existing techniques, which rely on pre-segmented characters and report results by comparing same characters only, the proposed technique works on complete images of printed documents and reports high identification rates.},
  archive      = {J_EXSY},
  author       = {Maryam Bibi and Anmol Hamid and Momina Moetesum and Imran Siddiqi},
  doi          = {10.1111/exsy.13020},
  journal      = {Expert Systems},
  month        = {9},
  number       = {8},
  pages        = {e13020},
  shortjournal = {Expert Syst.},
  title        = {Document forgery detection using source printer identification: A comparative study of text-dependent versus text-independent analysis},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analysis of breast cancer classification robustness with
radiomics feature extraction and deep learning techniques.
<em>EXSY</em>, <em>39</em>(8), e13018. (<a
href="https://doi.org/10.1111/exsy.13018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer and breast imaging diagnostic procedures are typically carried out using a variety of imaging modalities, including mammography, MRI, and ultrasound. However, ultrasound and mammography have limitations and MRI is recognized as better than other procedures. Recent computational approaches, such as radiomics, applied to image analysis have shown remarkable progress in lowering diagnostic difficulties. This research analysed the robustness of breast tumour classification with feature extraction (radiomics) and a featureless method (deep learning). The proposal consists of two stages: the first stage introduced and explored radiomics-based steps. A total of 111 tumour lesions were used to derive 74 radiomic features consisting of shape, and three separate second-order metrics. Associations of these features were used to classify tumour lesions with four different kernels from support vector machine algorithm. In the confusion matrix analysis, the SVM-RBF kernel developed optimal diagnostic efficiency with a maximum test accuracy of 97.06% on the combination of feature analysis. The second stage developed with deep learning techniques (InceptionV3 and CNN-SVM). A total of 2998 images were used to create the models. In this portion, the CNN-SVM model achieved the highest accuracy, 95.28%, with an AUC of 0.974, where the pre-trained InceptionV3 achieved an AUC of only 0.932. Finally, the obtained result in both stages was discussed together and other related studies.},
  archive      = {J_EXSY},
  author       = {Harun Ur Rashid and Turgay Ibrikci and Semra Paydaş and Figen Binokay and Ulus Çevik},
  doi          = {10.1111/exsy.13018},
  journal      = {Expert Systems},
  month        = {9},
  number       = {8},
  pages        = {e13018},
  shortjournal = {Expert Syst.},
  title        = {Analysis of breast cancer classification robustness with radiomics feature extraction and deep learning techniques},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-criteria probabilistic dual hesitant fuzzy group
decision making for supply chain finance credit risk assessments.
<em>EXSY</em>, <em>39</em>(8), e13015. (<a
href="https://doi.org/10.1111/exsy.13015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supply chain finance is important for resolving small and medium-sized enterprise financing difficulties and optimizing supply chain capital flows. Therefore, supply chain finance credit risk assessments are key financing indicators for decision makers. However, most current supply chain finance credit risk assessment research has been based on traditional and subjective methods and has focused less on the actual decision-making requirements. The TODIM method in a fuzzy environment has proven to be a useful tool for multi-criteria decision-making as it can better reflect the DMs&#39; psychological characteristics. As probabilistic dual hesitant fuzzy sets can contain more original evaluation information and more comprehensively reflect the DM uncertainties, this paper first proposes a Hamming distance measure in a probabilistic dual hesitant fuzzy environment to compare the relationships between two probabilistic dual hesitant fuzzy elements and prove some of the properties. Then, to fully consider the DMs&#39; risk preferences, a model is proposed to evaluate supply chain finance credit risk that extends the TODIM method to a probabilistic dual hesitant fuzzy environment based on cumulative prospect theory and the proposed Hamming distance. Finally, using improved credit risk assessment criteria, a practical case from Ping An Bank is given to demonstrate the proposed model&#39;s practicality, and a comparison given with the classical TODIM and the probabilistic hesitant fuzzy TODIM method to illustrate the effectiveness of the extended method.},
  archive      = {J_EXSY},
  author       = {Ziyang Li and Xingyu Zhang and Wenju Wang and Zhi Li},
  doi          = {10.1111/exsy.13015},
  journal      = {Expert Systems},
  month        = {9},
  number       = {8},
  pages        = {e13015},
  shortjournal = {Expert Syst.},
  title        = {Multi-criteria probabilistic dual hesitant fuzzy group decision making for supply chain finance credit risk assessments},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). EfficientUNet: Modified encoder-decoder architecture for the
lung segmentation in chest x-ray images. <em>EXSY</em>, <em>39</em>(8),
e13012. (<a href="https://doi.org/10.1111/exsy.13012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chest x-rays are a widely used medical imaging technique for the early detection of pulmonary diseases. However, the increasing workload and shortage of radiologists have motivated the research community to explore the possibilities in automated diagnosis. Segmentation is the most critical and essential procedure to improve the automatic diagnosis. Irregular lung shape and size with the overlapped lung regions make the identification of lung boundaries difficult. Further, the dense abnormalities often have high-intensity values that can be interpreted as lung boundaries. UNet is the most popular segmentation architecture among the deep learning community. Despite its high performance, there is scope for improvement. Most of the proposed segmentation models for lung segmentation in chest x-rays are trained and tested on a same dataset. It is reported that the model trained on one dataset fails when tested on another dataset. The aim of this study is to develop an efficient architecture for accurate lung segmentation in chest x-rays. The proposed model uses the pre-trained encoder, and the decoder uses residual learning and batch normalization to improve the performance. The publicly available Shenzhen, Montgomery County, and the NIH datasets are used for the evaluation of the proposed model. It is also validated by cross-dataset generalization. The proposed model obtained the 96.14% DSC and 92.67% JI value on the Shenzhen dataset, while 98.48% DSC and 97.01% JI value on the MC dataset. For cross-dataset evaluation, the EfficientUNet reported the DSC value of 95.97% and JI value of 92.34% for the MC dataset. While the DSC value of 94.02% and JI value of 88.86% on the NIH dataset. The obtained results across the different metrics show the efficiency of the proposed model. Unlike, the other state-of-the-art models, the proposed model is evaluated on the lungs that are highly irregular in shape and size due to different pulmonary abnormalities.},
  archive      = {J_EXSY},
  author       = {Tarun Agrawal and Prakash Choudhary},
  doi          = {10.1111/exsy.13012},
  journal      = {Expert Systems},
  month        = {9},
  number       = {8},
  pages        = {e13012},
  shortjournal = {Expert Syst.},
  title        = {EfficientUNet: Modified encoder-decoder architecture for the lung segmentation in chest x-ray images},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pulse plethysmograph signal analysis method for
classification of heart diseases using novel local spectral ternary
patterns. <em>EXSY</em>, <em>39</em>(8), e13011. (<a
href="https://doi.org/10.1111/exsy.13011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiac disorders are one of the prime reasons for an increasing global death rate. Reliable and efficient diagnosis procedures are imperative to minimize the risk posed by heart disorders. Computer-aided diagnosis, based on machine learning and biomedical signal analysis, has recently been adopted by researchers to accurately predict cardiac ailments. Multi-channel Electrocardiogram signals are mostly used in scientific literature as an indicator to diagnose cardiac disorders. Recently pulse plethysmograph (PuPG) signal got attention as an evolving biosignal and promising diagnostic tool to detect heart disorders since it has a simple sensor with low cost, non-invasive, reliable, and easy to handle technology. This article proposes a computer-aided diagnosis system to detect Myocardial Infarction, Dilated Cardiomyopathy, and Hypertension from PuPG signals. Raw PuPG signal is first preprocessed through empirical mode decomposition (EMD) by removing the redundant and useless information content. Then, highly discriminative features are extracted from preprocessed PuPG signal through novel local spectral ternary patterns (LSTP). Extracted LSTPs are input to a variety of classification methods such as support vector machines (SVM), K-nearest neighbours, decision tree, and so on. SVM with cubic kernel yielded the best classification performance of 98.4% accuracy, 96.7% sensitivity, and 99.6% specificity with 10-fold cross-validation. The proposed framework was trained and tested on a self-collected PuPG signals database of heart disorders. A comparison with previous studies and other feature descriptors shows the superiority of the proposed system. This research provides better insights into the contributions of PuPG signals towards reliable detection of heart disorder through low-cost and non-invasive means.},
  archive      = {J_EXSY},
  author       = {Sumair Aziz and Muhammad Umar Khan and Khushbakht Iqtidar and Sadaqat Ali and Ancuta Nicoleta Remete and Muhammad Arshad Javid},
  doi          = {10.1111/exsy.13011},
  journal      = {Expert Systems},
  month        = {9},
  number       = {8},
  pages        = {e13011},
  shortjournal = {Expert Syst.},
  title        = {Pulse plethysmograph signal analysis method for classification of heart diseases using novel local spectral ternary patterns},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep transfer learning for COVID-19 fake news detection in
persian. <em>EXSY</em>, <em>39</em>(8), e13008. (<a
href="https://doi.org/10.1111/exsy.13008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spread of fake news on social media has increased dramatically in recent years. Hence, fake news detection systems have received researchers&#39; attention globally. During the COVID-19 outbreak in 2019 and the worldwide epidemic, the importance of this issue becomes more apparent. Due to the importance of the issue, a large number of researchers have begun to collect English datasets and to study COVID-19 fake news detection. However, there are a large number of low-resource languages, including Persian, that cannot develop accurate tools for automatic COVID-19 fake news detection due to the lack of annotated data for the task. In this article, we aim to develop a corpus for Persian in the domain of COVID-19 where the fake news is annotated and to provide a model for detecting Persian COVID-19 fake news. With the impressive advancement of multilingual pre-trained language models, the idea of cross-lingual transfer learning can be proposed to improve the generalization of models trained with low-resource language datasets. Accordingly, we use the state-of-the-art deep cross-lingual contextualized language model, XLM-RoBERTa, and the parallel convolutional neural networks to detect Persian COVID-19 fake news. Moreover, we use the idea of knowledge transferring across-domains to improve the results by using both the English COVID-19 dataset and the general domain Persian fake news dataset. The combination of both cross-lingual and cross-domain transfer learning has outperformed the models and it has beaten the baseline by 2.39% significantly.},
  archive      = {J_EXSY},
  author       = {Masood Ghayoomi and Maryam Mousavian},
  doi          = {10.1111/exsy.13008},
  journal      = {Expert Systems},
  month        = {9},
  number       = {8},
  pages        = {e13008},
  shortjournal = {Expert Syst.},
  title        = {Deep transfer learning for COVID-19 fake news detection in persian},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Models for MAGDM with dual hesitant q-rung orthopair fuzzy
2-tuple linguistic MSM operators and their application to COVID-19
pandemic. <em>EXSY</em>, <em>39</em>(8), e13005. (<a
href="https://doi.org/10.1111/exsy.13005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we introduce dual hesitant q -rung orthopair fuzzy 2-tuple linguistic set (DH q -ROFTLS), a new strategy for dealing with uncertainty that incorporates a 2-tuple linguistic term into dual hesitant q -rung orthopair fuzzy set (DH q -ROFS). DH q -ROFTLS is a better way to deal with uncertain and imprecise information in the decision-making environment. We elaborate the operational rules, based on which, the DH q -ROFTL weighted averaging (DH q -ROFTLWA) operator and the DH q -ROFTL weighted geometric (DH q -ROFTLWG) operator are presented to fuse the DH q -ROFTL numbers (DH q -ROFTLNs). As Maclaurin symmetric mean (MSM) aggregation operator is a useful tool to model the interrelationship between multi-input arguments, we generalize the traditional MSM to aggregate DH q -ROFTL information. Firstly, the DH q -ROFTL Maclaurin symmetric mean (DH q -ROFTLMSM) and the DH q -ROFTL weighted Maclaurin symmetric mean (DH q -ROFTLWMSM) operators are proposed along with some of their desirable properties and some special cases. Further, the DH q -ROFTL dual Maclaurin symmetric mean (DH q -ROFTLDMSM) and weighted dual Maclaurin symmetric mean (DH q -ROFTLWDMSM) operators with some properties and cases are presented. Moreover, the assessment and prioritizing of the most important aspects in multiple attribute group decision-making (MAGDM) problems is analysed by an extended novel approach based on the proposed aggregation operators under DH q -ROFTL framework. At long last, a numerical model is provided for the selection of adequate medication to control COVID-19 outbreaks to demonstrate the use of the generated technique and exhibit its adequacy. Finally, to analyse the advantages of the proposed method, a comparison analysis is conducted and the superiorities are illustrated.},
  archive      = {J_EXSY},
  author       = {Sumera Naz and Muhammad Akram and Arsham Borumand Saeid and Aniqa Saadat},
  doi          = {10.1111/exsy.13005},
  journal      = {Expert Systems},
  month        = {9},
  number       = {8},
  pages        = {e13005},
  shortjournal = {Expert Syst.},
  title        = {Models for MAGDM with dual hesitant q-rung orthopair fuzzy 2-tuple linguistic MSM operators and their application to COVID-19 pandemic},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). EBPSO: Enhanced binary particle swarm optimization for
cardiac disease classification with feature selection. <em>EXSY</em>,
<em>39</em>(8), e13002. (<a
href="https://doi.org/10.1111/exsy.13002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiac disease is one of the leading causes of death worldwide, and its early detection and diagnosis can considerably increase the lifespan of patients. An automated expert system for early and accurate diagnosis that offsets human error can be designed using machine intelligence and appropriate pre-processing of data to ensure accuracy. To that end, enhanced binary particle swarm optimization (EBPSO) has been investigated in this paper to enable the definitive classification of cardiac disease with the aid of feature selection. The primary objective of this study is to improve the accuracy of the classification and the convergence speed while employing a lesser number of features. In order to achieve this, a new adaptive inertia weight was introduced to balance the exploitation and exploration capability of binary particle swarm optimization (BPSO). In addition, a novel idea called ‘neighbourhood best’ is introduced in the velocity update equation to improve the convergence speed. The proposed EBPSO approach was tested over well-known datasets of heart disease, that is, the Cleveland dataset, Hungarian dataset, Switzerland dataset, and Long-Beach-Va datasets. For classification purposes, two well-known classifiers, k-nearest neighbour, and support vector machine were used with the EBPSO. Furthermore, the performance of EBPSO was compared with the traditional BPSO, as well as with BPSO with proposed inertia weight (W a -BPSO) and other PSO variants. It has been observed that the proposed approach EBPSO with KNN shows remarkable efficiency in terms of average classification accuracy and convergence rate. The average classification accuracy for Cleveland dataset is 92.814%, for the Hungarian dataset is 91.97%, for the Switzerland dataset is 91.626% with EBPSO+KNN and for the Long-Beach-Va dataset is 85.253% with EBPSO + SVM. Additionally, the performance of W a -BPSO was compared with other commonly used inertia weights. The results of this study demonstrated that the proposed approach produces better results in terms of both the accuracy of classification as well as the convergence rate with a reduced feature set.},
  archive      = {J_EXSY},
  author       = {Savita Wadhawan and Raman Maini},
  doi          = {10.1111/exsy.13002},
  journal      = {Expert Systems},
  month        = {9},
  number       = {8},
  pages        = {e13002},
  shortjournal = {Expert Syst.},
  title        = {EBPSO: Enhanced binary particle swarm optimization for cardiac disease classification with feature selection},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Internet use behaviour model for predicting students’
performance. <em>EXSY</em>, <em>39</em>(8), e12999. (<a
href="https://doi.org/10.1111/exsy.12999">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet technology is vital in education as it is an enabler tool used by students for information exchange, communication and creation of knowledge. However, issues related to Internet use behaviour (IUB) and effects on students&#39; performance are still being debated due to inconsistent results. Thus, the main aim of this paper is to propose a specific IUB classification model to discover comprehensive prediction models on students&#39; performance by using educational data mining (EDM). Data related to the students&#39; CGPA and their internet usage activities were collected from 469 undergraduate students. Primarily, in this study several techniques were ensembled to predict students&#39; performance based on IUB. An EDM approach comprising of clustering, classification, correlation, and regression was used. The base classifiers including decision tree (j48) ensembled with EM clustering technique were exploited to develop a high accuracy of prediction results. At first, the usage of clustering technique was to cluster the dataset into smaller variable and applied classification technique to solve the complexity of the variables. Correlation come across to measure the degree of IUB and students&#39; performance and later regression was applied to produce predictive results. Based on 11 IUB categories, the results indicate that online gaming has a negative significant effect on the students&#39; performance. Additionally, the prediction model revealed a high correlation, which generates good predictions of 92%. The prediction model would enable higher learning institutions to detect as early as possible those students who are at risk. This will then help them in taking timely and proactive measures to improve their performance.},
  archive      = {J_EXSY},
  author       = {Shakiroh Khamis and Mazida Ahmad and Azizah Ahmad and Mohammad Nazir Ahmad},
  doi          = {10.1111/exsy.12999},
  journal      = {Expert Systems},
  month        = {9},
  number       = {8},
  pages        = {e12999},
  shortjournal = {Expert Syst.},
  title        = {Internet use behaviour model for predicting students&#39; performance},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ensemble methods for meningitis aetiology diagnosis.
<em>EXSY</em>, <em>39</em>(8), e12996. (<a
href="https://doi.org/10.1111/exsy.12996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we explore data-driven techniques for the fast and early diagnosis concerning the etiological origin of meningitis, more specifically with regard to differentiating between viral and bacterial meningitis. We study how machine learning can be used to predict meningitis aetiology once a patient has been diagnosed with this disease. We have a dataset of 26,228 patients described by 19 attributes, mainly about the patient&#39;s observable symptoms and the early results of the cerebrospinal fluid analysis. Using this dataset, we have explored several techniques of dataset sampling, feature selection and classification models based both on ensemble methods and on simple techniques (mainly, decision trees). Experiments with 27 classification models (19 of them involving ensemble methods) have been conducted for this paper. Our main finding is that the combination of ensemble methods with decision trees leads to the best meningitis aetiology classifiers. The best performance indicator values (precision, recall and f -measure of 89% and an AUC value of 95%) have been achieved by the synergy between bagging and NBTrees. Nonetheless, our results also suggest that the combination of ensemble methods with certain decision tree clearly improves the performance of diagnosis in comparison with those obtained with only the corresponding decision tree.},
  archive      = {J_EXSY},
  author       = {Eduardo Guzmán and María-Victoria Belmonte and Viviane M. Lelis},
  doi          = {10.1111/exsy.12996},
  journal      = {Expert Systems},
  month        = {9},
  number       = {8},
  pages        = {e12996},
  shortjournal = {Expert Syst.},
  title        = {Ensemble methods for meningitis aetiology diagnosis},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new chaotic lévy flight distribution optimization
algorithm for solving constrained engineering problems. <em>EXSY</em>,
<em>39</em>(8), e12992. (<a
href="https://doi.org/10.1111/exsy.12992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposed a new metaheuristic dubbed as Chaotic Lévy flight distribution (CLFD) algorithm, to address physical world engineering optimization problems that incorporate the chaotic maps in the elementary Lévy flight distribution (LFD). Hybridization aims to increase the LFD rate of convergence while also providing a problem-free optimization approach. The proposed methodology is investigated for five case studies of constrained optimization issues followed by shape optimization of structural design. The outcomes from the CFLD algorithm are further contrasted with its fundamental version and other distinguished recently introduced algorithms. The computational analysis illustrates the dominance of CLFD over other considered optimizers. Moreover, the present investigation shows that CLFD is a robust technique that can efficiently find optimal mechanical design problems with a proper chaotic map selection.},
  archive      = {J_EXSY},
  author       = {Betül Sultan Yıldız and Sumit Kumar and Nantiwat Pholdee and Sujin Bureerat and Sadiq M. Sait and Ali Riza Yildiz},
  doi          = {10.1111/exsy.12992},
  journal      = {Expert Systems},
  month        = {9},
  number       = {8},
  pages        = {e12992},
  shortjournal = {Expert Syst.},
  title        = {A new chaotic lévy flight distribution optimization algorithm for solving constrained engineering problems},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A user study with aspect-based sentiment analysis for
similarity of items in content-based recommendations. <em>EXSY</em>,
<em>39</em>(8), e12991. (<a
href="https://doi.org/10.1111/exsy.12991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most studies on recommender systems focus on collaborative algorithm approaches over content-based recommendation due to their better accuracy results. However, the advantage of the latter is that it is more effective and more transparent with user applications. This article proposes WordRecommender, an explainable content-based algorithm that calculates similarity by semantic proximity. Its preprocessing step involves analyses of movie reviews to obtain aspects, defined as relevant words of high sentimental value. Recommendations are generated by a neighbourhood algorithm that calculates the similarity of films based on the semantic proximity of the aspects ordered by their emotional score. It can also consider a semantic comparison of metadata using the most related aspects from the recommended movie and one enjoyed by the user for the production of textual explanations. The accuracy of the algorithm was competitive with those of other baseline neighbourhood methods, and the semantic data of items can be the source of both representative information and reasoning in recommender systems.},
  archive      = {J_EXSY},
  author       = {André Levi Zanon and Luan Souza and Diany Pressato and Marcelo Garcia Manzato},
  doi          = {10.1111/exsy.12991},
  journal      = {Expert Systems},
  month        = {9},
  number       = {8},
  pages        = {e12991},
  shortjournal = {Expert Syst.},
  title        = {A user study with aspect-based sentiment analysis for similarity of items in content-based recommendations},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Human activity recognition by wireless body area networks
through multi-objective feature selection with deep learning.
<em>EXSY</em>, <em>39</em>(8), e12988. (<a
href="https://doi.org/10.1111/exsy.12988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless body area network (WBAN) is a novel technology with the incorporation of numerous types of devices, which is also employed in health monitoring applications. Human activity recognition (HAR) receives more interest in recent times along with wearable sensors. HAR system provides information about a person&#39;s identity, personality, and psychological state. In the present scenario, it becomes important to model the active learning paradigms with the help of wearable sensors for analysing human activities. Although various deep learning models and existing algorithms secure better outcomes through the sensor data analysis regarding HAR, the decision-making evaluation seems to be a complex one. The main intent of this paper is to implement the WBAN-based HAR system using the improved deep learning model. By connecting the wearable sensors, the signals are gathered regarding human activity from diverse benchmark sources. After collecting the required signals, the pre-processing of the input signals is done using artefact removal and median filtering. Further, the feature extraction is performed, which intends to extract a set of features by utilizing short-time Fourier transform (STFT) and statistical features. For reducing the feature-length, a multi-objective-based optimal feature selection is adopted. Human activities such as ‘walking, walking upstairs, walking downstairs, sitting, standing, lying, and jogging’ are recognized with help of selected optimal features. The optimized probabilistic neural network (PNN) and convolutional neural network (CNN) are combined and named as adaptive probabilistic-based CNN (AP-CNN). The effective performance of optimal feature selection and recognition is accomplished by incorporating the developed backward updating position-based sea lion optimization algorithm (BU-SLnO). Finally, the performance of the BU-SLnO-AP-CNN-based suggested model is analysed, which shows 1.001%, 1.237%, 0.811%, and 0.859% advanced than SLnO-AP-CNN, feed-forward-AP-CNN (FF-AP-CNN), grey wolf optimization-AP-CNN (GWO-AP-CNN), particle swarm optimization-AP-CNN (PSO-AP-CNN) when observing the dataset 1. The experimental outcomes from comparison with various classification techniques demonstrate the efficiency of the developed technique.},
  archive      = {J_EXSY},
  author       = {Jayaram Boga and V. Dhilip Kumar},
  doi          = {10.1111/exsy.12988},
  journal      = {Expert Systems},
  month        = {9},
  number       = {8},
  pages        = {e12988},
  shortjournal = {Expert Syst.},
  title        = {Human activity recognition by wireless body area networks through multi-objective feature selection with deep learning},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Special issue: Recent advances in deep learning, biometrics,
health informatics and data science. <em>EXSY</em>, <em>39</em>(7),
e13060. (<a href="https://doi.org/10.1111/exsy.13060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EXSY},
  author       = {Steven Lawrence Fernandes and Roshan Joy Martis and Hong Lin and Bahman Javadi and Urcun John Tanik and Muhammad Sharif},
  doi          = {10.1111/exsy.13060},
  journal      = {Expert Systems},
  month        = {8},
  number       = {7},
  pages        = {e13060},
  shortjournal = {Expert Syst.},
  title        = {Special issue: Recent advances in deep learning, biometrics, health informatics and data science},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel multi-view ordinal classification approach for
software bug prediction. <em>EXSY</em>, <em>39</em>(7), e13044. (<a
href="https://doi.org/10.1111/exsy.13044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software bug prediction aims to enhance software quality and testing efficiency by constructing predictive classification models using code properties. This enables the prompt detection of fault-prone modules. There are several machine learning-based software bug prediction studies, which mainly focus on single view data by disregarding the natural ordering relation among the class labels in the literature. Thus, these studies cause losing each view&#39;s own intrinsic structure and the inherent order of the labels that positively affect the prediction performance. To overcome this drawback, this study focuses on integrating ordering information and a multi-view learning strategy. This paper proposes a novel approach multi-view ordinal classification (MVOC), which learns from different views (complexity, coupling, cohesion, inheritance and scale) of the software dataset separately and predicts software bugs taking the inherent order of class labels (non-buggy, less buggy and more buggy) into consideration. To demonstrate its prediction performance, the MVOC approach was executed on the 40 different real-world software datasets using six different classification algorithms as base learners. In the experiments, the MVOC approach was compared with traditional classifiers and their multi-view implementations in terms of precision, recall, f -measure and accuracy rate metrics. The results indicate that the MVOC approach presents better prediction performance on average than the multi-view-based and traditional classifiers. It is also observed from the results that the MVOC.RF model achieved the highest classification performance with an average accuracy rate of 85.65%.},
  archive      = {J_EXSY},
  author       = {Pelin Yildirim Taser},
  doi          = {10.1111/exsy.13044},
  journal      = {Expert Systems},
  month        = {8},
  number       = {7},
  pages        = {e13044},
  shortjournal = {Expert Syst.},
  title        = {A novel multi-view ordinal classification approach for software bug prediction},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Algorithm for generating negative cases for collaborative
filtering recommender. <em>EXSY</em>, <em>39</em>(7), e12986. (<a
href="https://doi.org/10.1111/exsy.12986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most collaborative filtering recommenders based on deep learning utilize implicit feedback information such as likes and bookmarks to infer user preferences rather than explicit feedback such as ratings provided by users. However, collaborative filtering models utilizing implicit feedback pose a chronic problem, that is, the “one-class” problem (also known as the one-class collaborative filtering problem), which causes trivial solutions due to lack of negative examples. A one-class problem free-boosting (OCF-B) algorithm is proposed in this study to solve the one-class problem by considering a user&#39;s preference pattern when generating negative cases and training the model with both positive and negative cases. More specifically, the OCF-B algorithm iteratively selects negative cases that exacerbate the loss value of the object function and replace them with other negative cases when extracting negative cases from unknown cells of the user–item interaction matrix. In an experiment using four datasets, the results show that negative cases selected meticulously via the OCF-B algorithm improve the prediction performance not only for negative cases, but also for positive cases. In addition, the prediction performance was better than that of the existing zero-injection method.},
  archive      = {J_EXSY},
  author       = {Gil Jae Song and Hee Seok Song},
  doi          = {10.1111/exsy.12986},
  journal      = {Expert Systems},
  month        = {8},
  number       = {7},
  pages        = {e12986},
  shortjournal = {Expert Syst.},
  title        = {Algorithm for generating negative cases for collaborative filtering recommender},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-adaptive-deer hunting optimization-based optimal
weighted features and hybrid classifier for automated disease detection
in plant leaves. <em>EXSY</em>, <em>39</em>(7), e12982. (<a
href="https://doi.org/10.1111/exsy.12982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This main intention of this paper is to adopt a new disease detection model for plant leaves. The proposed model involves several steps such as pre-processing, leaf segmentation, abnormality segmentation, feature extraction and detection. Image scaling and contrast enhancement are performed during the pre-processing phase. Once the pre-processing is done, the segmentation phase starts with leaf segmentation by binary thresholding method and abnormality segmentation by K-means clustering. Further, the local binary pattern and grey-level co-occurrence matrix features are extracted and a dimensionality reduced technique called principle component analysis is determined. As the main novelty, the weighted feature extraction is performed, in which the weight functions are optimized by the self-adaptive deer hunting optimization (SA-DHOA). Another contribution of this paper is to implement a hybrid classifier for disease detection. Here, the extracted weighted features are subjected to a support vector machine, and the abnormality segmented image is subjected to convolutional neural network (CNN), which is a deep learning algorithm that can learn the features automatically. Here, the same SA-DHOA is used to improve the performance of CNN, which is termed as SA-DHOA-SCNN. Finally, the performance analysis confirms the maximum success rate of the proposed model over other conventional methods.},
  archive      = {J_EXSY},
  author       = {Kalicharan Sahu and Sonajharia Minz},
  doi          = {10.1111/exsy.12982},
  journal      = {Expert Systems},
  month        = {8},
  number       = {7},
  pages        = {e12982},
  shortjournal = {Expert Syst.},
  title        = {Self-adaptive-deer hunting optimization-based optimal weighted features and hybrid classifier for automated disease detection in plant leaves},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A knowledge-based system for electric motors compliance
verification in a multinational-level company. <em>EXSY</em>,
<em>39</em>(7), e12979. (<a
href="https://doi.org/10.1111/exsy.12979">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electric motors are highly customizable products that have to meticulously comply with the client&#39;s needs, commercial and legal requirements of each market. In this context, the configure-to-order (CTO) approach allows the user to define the product configuration at the time of the order and the supplier to develop a product that meets the customer&#39;s needs. This paper presents an object-oriented knowledge-based system (OOKBS) that integrates rule- and case-based reasoning to verify the compliance of a variant-rich and complex product—electric motors—in a multinational-level company. The system adopts a modular structure to evaluate distinct compliance aspects, such as technical constraints and commercial requirements, and to improve the compliance assessment based on the designs of motors previously sold. The work targeted a product line with significant market share in North America, and is the result of a collaboration among the following teams: product compliance, international sales, engineering systems, and product engineering. In total, the system development involved nine experts from these areas. This study has the originality of presenting a product configuration system (PCS) that integrates rule-based and case-based approaches to verify the compliance of a modular product. The results indicate a reduction of 73% of internal technical queries within the prototype scope. Moreover, the system usability tests highlight the completeness of outcomes, quick access to information, and easy integration of automatic product compliance verification into the company&#39;s design flow. Furthermore, we discussed how the system was effectively implemented in a design routine based on both concurrent engineering and CTO scenarios.},
  archive      = {J_EXSY},
  author       = {Bruno Ziegler Haselein and Jonny Carlos da Silva},
  doi          = {10.1111/exsy.12979},
  journal      = {Expert Systems},
  month        = {8},
  number       = {7},
  pages        = {e12979},
  shortjournal = {Expert Syst.},
  title        = {A knowledge-based system for electric motors compliance verification in a multinational-level company},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An accurate soft diagnosis method of breast cancer using the
operative fusion of derived features and classification approaches.
<em>EXSY</em>, <em>39</em>(7), e12976. (<a
href="https://doi.org/10.1111/exsy.12976">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is one of the most common types of cancer around the world. The early-stage recognition of breast cancer is favourable for the diagnosis and treatment of the affecting patient. Data mining approaches can ease the diagnosis of breast cancer by analysis of the associated dataset for real-time decision-making. The present study proposes an effective transformation approach of experimental attributes of a breast cancer dataset using the latent semantic analysis and the fusion of derived features with classification methods for accurate recognition of breast cancer. The proposed approach is validated using the most widely used benchmark and open-access breast cancer dataset. The transformed features of the original dataset result in 100% recognition efficiency using a multilayer perceptron, support vector machine, multi-class classifier and functional tree classifiers. Other classifiers, like naïve Bayes, rotation forest, simple linear logistic regression and logistic model tree result in recognition accuracy between 96.85% and 99.30% using a similar feature subset. Besides, the optimal subset of derived features has been affirmed based on the evaluation metrics of classification approaches.},
  archive      = {J_EXSY},
  author       = {Sunil Kumar Jha and Jinwei Wang and Raju Shanmugam},
  doi          = {10.1111/exsy.12976},
  journal      = {Expert Systems},
  month        = {8},
  number       = {7},
  pages        = {e12976},
  shortjournal = {Expert Syst.},
  title        = {An accurate soft diagnosis method of breast cancer using the operative fusion of derived features and classification approaches},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deriving the minimum staff number requirement for
intelligent staff scheduling: An efficient constructive method and
application. <em>EXSY</em>, <em>39</em>(7), e12975. (<a
href="https://doi.org/10.1111/exsy.12975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective staff scheduling is a critical activity of successful software development management. Due to its difficulty and broad applications in many service delivery scenarios, staff scheduling has been studied for several decades. However, most existing work focus on constructing the working schedules based on a given workforce size. This paper tries to solve a prerequisite issue before performing staff scheduling, i.e., testing whether the already existed manpower can meet the scheduling requirements. Though it is possible to use network flow theory or artificial intelligence (AI) methods like genetic algorithms to solve this problem, their time complexities could be too high to be used for large problem sizes. This paper proposes a constructive method that can derive the minimum staff number for three scheduling problem variants in a linear running time, and in the meantime a corresponding working schedule that can satisfy all the problem constraints can be produced. We not only theoretically show the lower bound for the computation time complexity of our proposed method but also prove its correctness. Moreover, based on the derived minimum staff number, we further explore the genetic algorithm for generating the schedule and compare its performance with our method. The experiments show that our method outperforms the baselines in terms of both effectiveness and efficiency.},
  archive      = {J_EXSY},
  author       = {Bin Cao and Hao Chen and Zijie Wang and Ting Wang and Jing Fan},
  doi          = {10.1111/exsy.12975},
  journal      = {Expert Systems},
  month        = {8},
  number       = {7},
  pages        = {e12975},
  shortjournal = {Expert Syst.},
  title        = {Deriving the minimum staff number requirement for intelligent staff scheduling: An efficient constructive method and application},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design and development of a vision-based system for
detection, tracking and recognition of isolated dynamic bare hand
gesticulated characters. <em>EXSY</em>, <em>39</em>(7), e12970. (<a
href="https://doi.org/10.1111/exsy.12970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detection and tracking are the vital stages to form the gesture trajectory in gesture recognition. It becomes more challenging when the variations in illumination, pose, position, occlusion, scale, speed, blurring effect and complex environment are introduced. Additionally, the background feature domination effect affects the existing deep learning models. A semantic segmentation model is implemented in this work to detect the bare hand to overcome these challenges. A pre-trained network VGG-16 is utilized by training with the proposed NITS S-Net database. Evaluation of the SegNet model is done on EgoHands, Oxford and OUHands databases. To track the bare hand, a SegNet-based detection and tracking approach is proposed using Kalman filter and point-tracker. This model achieves 97.01% accuracy (a relative improvement of ~8% from the baseline models) at 0.068 s per frame computational time on NITS hand gesture database VIIIB. The gesticulated characters, that is, alphabets, numbers, operators, special characters, are gesticulated without any constraints on the pattern/strokes. To recognize these 95 multi-stroke gestures, a deep convolutional neural network (DCNN) is presented using AlexNet. The DCNN model achieves 97.60% (a relative improvement of ~14% from the baseline models) accuracy on the NITS hand gesture database VIIIB merged. Evaluation of the handwritten EMNIST merged (balanced) database resulted in average recognition accuracy of 91.60%.},
  archive      = {J_EXSY},
  author       = {Kuldeep Singh Yadav and Anish Monsley Kirupakaran and Rabul Hussain Laskar and Manas Kamal Bhuyan and Taimoor Khan},
  doi          = {10.1111/exsy.12970},
  journal      = {Expert Systems},
  month        = {8},
  number       = {7},
  pages        = {e12970},
  shortjournal = {Expert Syst.},
  title        = {Design and development of a vision-based system for detection, tracking and recognition of isolated dynamic bare hand gesticulated characters},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A cost-sensitive deep learning-based meta-classifier for
pediatric pneumonia classification using chest x-rays. <em>EXSY</em>,
<em>39</em>(7), e12966. (<a
href="https://doi.org/10.1111/exsy.12966">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Literature survey shows that convolutional neural network (CNN)-based pretrained models have been successfully employed to diagnose and detect childhood pneumonia using chest X-rays (CXR). However, most of the existing methods are prone to imbalance problems, which become even more significant in medical image classification for example most importantly childhood pneumonia classification using CXR. This is due to the fact that some classes in childhood pneumonia have a very little support in the training dataset. Additionally, though the existing methods have reported better performances for training and testing, in most of the test cases the existing models will not be effective on variants of the childhood pneumonia CXR images or CXR samples from a new pediatric patient. In addition, the models may be effective in detecting latent stage pediatric pneumonia but not show better performances for CXR samples from pediatric patients who are early stage, sick but not pneumonia, sick with other lung diseases, and so on. Generalization is an important term to be considered while designing a pneumonia classifier that can perform well on completely unseen pneumonia CXR datasets. This article presents a cost-sensitive large-scale learning with stacked ensemble meta-classifier and transfer learning-based deep feature fusion approach for pediatric pneumonia classification using CXR. With the aim to identify the importance among the classes of pneumonia, the larger cost items are introduced based on the class-imbalance degree during the backpropogation learning methodology in transfer learning models such as Xception, InceptionResNetV2, DenseNet201, and NASNetMobile. Next, the features from the penultimate layer (global average pooling) of Xception, InceptionResNetV2, DenseNet201, and NASNetMobile were extracted and dimensionality of the extracted features were reduced using kernel principal component analysis (KPCA). The reduced features were fused together and passed into a stacked ensemble meta-classifier for classifying the CXR into either pneumonia or normal. A stacked ensemble meta-classifier is a two stage approach in which the first stage employs random forest and support vector machine (SVM) for prediction and followed by logistic regression for classification. Experiments of the proposed model were done on publicly available benchmark pediatric pneumonia classification CXR dataset. In addition, the experiments for existing methods as well as various cost-insensitive models were conducted. In all the experiments, the proposed method has achieved better performances compared to the existing methods as well as various cost-insensitive models. In particular, the proposed method showed 6% improvement in precision, 10% improvement in recall, 9% improvement in F1 score with less misclassification costs (0.0321) and accuracy (96.8%). Most importantly, the proposed method is insensitive to the imbalance data and more effective to handle variants of the childhood pneumonia CXR images. Thus, the proposed approach can be used as a tool for point-of-care diagnosis by healthcare professionals.},
  archive      = {J_EXSY},
  author       = {Vinayakumar Ravi and Harini Narasimhan and Tuan D. Pham},
  doi          = {10.1111/exsy.12966},
  journal      = {Expert Systems},
  month        = {8},
  number       = {7},
  pages        = {e12966},
  shortjournal = {Expert Syst.},
  title        = {A cost-sensitive deep learning-based meta-classifier for pediatric pneumonia classification using chest X-rays},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modelling of biosignal based decision making model for
intracranial haemorrhage diagnosis in IoT environment. <em>EXSY</em>,
<em>39</em>(7), e12964. (<a
href="https://doi.org/10.1111/exsy.12964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, the Internet of Things (IoT) in healthcare is a novel and promising emerging area that offers a number of benefits to users and healthcare professionals, enabling real time monitoring of diseases, convenience, and ease of use. With respect to aid the patients by the use of IoT with biosignals enabled solutions, recent researches make use of machine learning (ML) techniques for decision making, particularly haemorrhage diagnosis. In this view, this paper presents an intelligent intracranial haemorrhage (ICH) diagnosis using biosignals (IICHD-BS) in IoT environment. The IICHD-BS technique performs data acquisition process using two sensors namely complementary metal oxide semiconductor sensor and ESP8266 Wi-Fi module. They are employed to collect CT images of the CT scanner and transforms them into electrical signals for storing them in the server. Besides, the IICHD-BS technique employs optimal region growing based segmentation approach for detecting the infected brain regions in the CT images. In addition, EfficientNet based feature extraction and functional link neural network (FLNN) based classification approach is used for detecting and classifying the existence of ICH. For experimental validation, a set of two benchmark dataset ICH datasets are used and the experimental outcomes are evaluated with respect to different measures. The simulation outcomes demonstrated the improved performances of the proposed algorithm over the current state of art techniques.},
  archive      = {J_EXSY},
  author       = {Anwer Mustafa Hilal and Rana Alabdan and Mohamed Tahar Ben Othman and Siwar Ben Haj Hassine and Fahd N. Al-Wesabi and Mohammed Rizwanullah and Ishfaq Yaseen and Abdelwahed Motwakel},
  doi          = {10.1111/exsy.12964},
  journal      = {Expert Systems},
  month        = {8},
  number       = {7},
  pages        = {e12964},
  shortjournal = {Expert Syst.},
  title        = {Modelling of biosignal based decision making model for intracranial haemorrhage diagnosis in IoT environment},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Training with growing sets: A comparative study.
<em>EXSY</em>, <em>39</em>(7), e12961. (<a
href="https://doi.org/10.1111/exsy.12961">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Being similar to and inspired from the process of human education, curriculum learning methods -or CL methods-sort the input examples from easy to difficult, then add them to the training set in that order. Considering the fact that CL research is most concerned with determining the direction (from easy to difficult vs. from difficult to easy) and the criteria of this sorting, vast and various studies have emerged in the literature addressing both types of sorting. However, this results in a contradiction that demands finding a common aspect of ordering in both directions. This study argues that this required common aspect lies in the gradual enlargement of training. In other words, it is claimed that the success of CL methods does not depend on which criteria or in which direction the ordering is made. Extensive experiments have been conducted on various datasets using different deep learning models in order to test this claim. It was observed that random ordering had achieved competitive results with CL methods. Moreover, random ordering proved to be faster than other CL methods as it eliminates the cost of sorting computation. Based on these results, using random ordered growing sets as a baseline in future CL studies is recommended. Moreover, the possibly to improve the optimization performance via training with growing sets in theoretical perspective is also explained.},
  archive      = {J_EXSY},
  author       = {Melike Nur Yeğin and Ömer Kurttekin and Serkan Kaan Bahşi and Mehmet Fatih Amasyali},
  doi          = {10.1111/exsy.12961},
  journal      = {Expert Systems},
  month        = {8},
  number       = {7},
  pages        = {e12961},
  shortjournal = {Expert Syst.},
  title        = {Training with growing sets: A comparative study},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MOSQUITO-NET: A deep learning based CADx system for malaria
diagnosis along with model interpretation using GradCam and class
activation maps. <em>EXSY</em>, <em>39</em>(7), e12695. (<a
href="https://doi.org/10.1111/exsy.12695">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malaria is considered one of the deadliest diseases in today&#39;s world, which causes thousands of deaths per year. The parasites responsible for malaria are scientifically known as Plasmodium, which infects the red blood cells in human beings. Diagnosis of malaria requires identification and manual counting of parasitized cells in microscopic blood smears by medical practitioners. Its diagnostic accuracy is primarily affected by extensive scale screening due to the unavailability of resources. State of the art Computer-Aided Diagnostic techniques based on deep learning algorithms such as CNNs, which perform an end to end feature extraction and classification, have widely contributed to various image recognition tasks. In this paper, we evaluate the performance of Mosquito-Net, a custom made convnet to classify the infected and uninfected blood smears for malaria diagnosis. The CADx system can be deployed on IoT and mobile devices due to its fewer parameters and computation power, making it wildly preferable for diagnosis in remote and rural areas that lack medical facilities. Statistical analysis demonstrates that the proposed model achieves greater accuracy than the previous SOTA architectures for malaria diagnosis despite being 10 times lighter in parameters and inference time. Mosquito-Net achieves an AUC of 99.009% and an F-1 score of 96.7% on the validation set.},
  archive      = {J_EXSY},
  author       = {Aayush Kumar and Sanat B. Singh and Suresh Chandra Satapathy and Minakhi Rout},
  doi          = {10.1111/exsy.12695},
  journal      = {Expert Systems},
  month        = {8},
  number       = {7},
  pages        = {e12695},
  shortjournal = {Expert Syst.},
  title        = {MOSQUITO-NET: A deep learning based CADx system for malaria diagnosis along with model interpretation using GradCam and class activation maps},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Computational approach for content-based image retrieval of
k-similar images from brain MR image database. <em>EXSY</em>,
<em>39</em>(7), e12652. (<a
href="https://doi.org/10.1111/exsy.12652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Content-based medical image retrieval (CBMIR) is a mechanism to handle a huge quantity of image data generated in various medical imaging modalities. In recent years, due to the evolution of computer vision and digital imaging modalities, a large number of medical images are generated. Consequently, the task of retrieving medical images from a large image database becomes more tedious due to variation in the size and shape of the images. Hence, it is necessary to design an appropriate system for medical image retrieval. In this paper a methodology for CBMIR using features of an image such as colour, shape, and texture is proposed to represent and retrieve the images from a large database that are relevant to a given query image. This methodology is evaluated for the application of retrieving the brain MRI images of different planes (coronal, sagittal, and transverse) from a dataset of normal and demented subjects. The features are determined in terms of Grey level co-occurrence based Haralik&#39;s features and histogram based cumulative distribution function (CDF). The image retrieval mechanism is designed using the K-Nearest Neighbour algorithm by finding the minimum distance between query and database images. The performance parameters such as precision and recall are calculated. The average accuracy of 95.5% are obtained. The results provided ensures the capability to use it as assistive framework for radiologists in radiology image retrieval and classification.},
  archive      = {J_EXSY},
  author       = {Niranjana Sampathila and Pavithra and Roshan Joy Martis},
  doi          = {10.1111/exsy.12652},
  journal      = {Expert Systems},
  month        = {8},
  number       = {7},
  pages        = {e12652},
  shortjournal = {Expert Syst.},
  title        = {Computational approach for content-based image retrieval of K-similar images from brain MR image database},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybrid genetic-discretized algorithm to handle data
uncertainty in diagnosing stenosis of coronary arteries. <em>EXSY</em>,
<em>39</em>(7), e12573. (<a
href="https://doi.org/10.1111/exsy.12573">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coronary artery disease (CAD) is the leading cause of morbidity and death worldwide. Invasive coronary angiography is the most accurate technique for diagnosing CAD, but is invasive and costly. Hence, analytical methods such as machine learning and data mining techniques are becoming increasingly more popular. Although physicians need to know which arteries are stenotic, most of the researchers focus only on CAD detection and few studies have investigated stenosis of the right coronary artery (RCA), left circumflex (LCX) artery and left anterior descending (LAD) artery separately. Meanwhile, most of the datasets in this field are noisy (data uncertainty). However, to the best of our knowledge, there is no study conducted to address this important problem. This study uses the extension of the Z-Alizadeh Sani dataset, containing 303 records with 54 features. A new feature selection algorithm is proposed in this work. Meanwhile, by discretization of data, we also handle the uncertainty in CAD prediction. To the best of our knowledge, this is the first study attempted to handle uncertainty in CAD prediction. Finally, the genetic algorithm (GA) is used to determine the hyper-parameters of the support vector machine (SVM) kernels. We have achieved high accuracy for the stenosis diagnosis of each main coronary artery. The results of this study can aid the clinicians to validate their manual stenosis diagnosis of RCA, LCX and LAD coronary arteries.},
  archive      = {J_EXSY},
  author       = {Roohallah Alizadehsani and Mohamad Roshanzamir and Moloud Abdar and Adham Beykikhoshk and Abbas Khosravi and Saeid Nahavandi and Pawel Plawiak and Ru San Tan and U Rajendra Acharya},
  doi          = {10.1111/exsy.12573},
  journal      = {Expert Systems},
  month        = {8},
  number       = {7},
  pages        = {e12573},
  shortjournal = {Expert Syst.},
  title        = {Hybrid genetic-discretized algorithm to handle data uncertainty in diagnosing stenosis of coronary arteries},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Entropy-controlled deep features selection framework for
grape leaf diseases recognition. <em>EXSY</em>, <em>39</em>(7), e12569.
(<a href="https://doi.org/10.1111/exsy.12569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several countries are most reliant on agriculture either in terms of employment opportunities, national income, availability of a raw material, food production, to name but a few. However, it faces a big challenge such as climate changes, diseases, pets, weeds etc. Therefore, last decade has provided a machine learning-based solution to the agricultural community, which helped farmers to identify the diseases at the early stages. In this article, our focus is on grape diseases, and proposes a novel framework to identify and classify the selected diseases at the early stages. A deep learning-based solution is embedded into a conventional architecture for optimal performance. Three primary steps are involved; (a) feature extraction after applying transfer learning on pre-trained deep models, AlexNet and ResNet101, (b) selection of best features using proposed Yager Entropy along with Kurtosis (YEaK) technique, (c) fusion of strong features using proposed parallel approach and later subject to classification step using least squared support vector machine (LS-SVM). The simulations are performed on infected grape leaves obtained from the plant village dataset to achieving an accuracy of 99%. From the simulation results, we sincerely believe that our proposed approach performed exceptionally compared to several existing methods.},
  archive      = {J_EXSY},
  author       = {Alishba Adeel and Muhammad Attique Khan and Tallha Akram and Abida Sharif and Mussarat Yasmin and Tanzila Saba and Kashif Javed},
  doi          = {10.1111/exsy.12569},
  journal      = {Expert Systems},
  month        = {8},
  number       = {7},
  pages        = {e12569},
  shortjournal = {Expert Syst.},
  title        = {Entropy-controlled deep features selection framework for grape leaf diseases recognition},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multilevel paradigm for deep convolutional neural network
features selection with an application to human gait recognition.
<em>EXSY</em>, <em>39</em>(7), e12541. (<a
href="https://doi.org/10.1111/exsy.12541">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human gait recognition (HGR) shows high importance in the area of video surveillance due to remote access and security threats. HGR is a technique commonly used for the identification of human style in daily life. However, many typical situations like change of clothes condition and variation in view angles degrade the system performance. Lately, different machine learning (ML) techniques have been introduced for video surveillance which gives promising results among which deep learning (DL) shows best performance in complex scenarios. In this article, an integrated framework is proposed for HGR using deep neural network and fuzzy entropy controlled skewness (FEcS) approach. The proposed technique works in two phases: In the first phase, deep convolutional neural network (DCNN) features are extracted by pre-trained CNN models (VGG19 and AlexNet) and their information is mixed by parallel fusion approach. In the second phase, entropy and skewness vectors are calculated from fused feature vector (FV) to select best subsets of features by suggested FEcS approach. The best subsets of picked features are finally fed to multiple classifiers and finest one is chosen on the basis of accuracy value. The experiments were carried out on four well-known datasets, namely, AVAMVG gait, CASIA A, B and C. The achieved accuracy of each dataset was 99.8, 99.7, 93.3 and 92.2%, respectively. Therefore, the obtained overall recognition results lead to conclude that the proposed system is very promising.},
  archive      = {J_EXSY},
  author       = {Habiba Arshad and Muhammad Attique Khan and Muhammad Irfan Sharif and Mussarat Yasmin and João Manuel R. S. Tavares and Yu-Dong Zhang and Suresh Chandra Satapathy},
  doi          = {10.1111/exsy.12541},
  journal      = {Expert Systems},
  month        = {8},
  number       = {7},
  pages        = {e12541},
  shortjournal = {Expert Syst.},
  title        = {A multilevel paradigm for deep convolutional neural network features selection with an application to human gait recognition},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Proximity-based cloud resource provisioning for deep
learning applications in smart healthcare. <em>EXSY</em>,
<em>39</em>(7), e12524. (<a
href="https://doi.org/10.1111/exsy.12524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning is a powerful technology that enables intelligent data processing in the smart healthcare domain. Inspired by the tremendous processing power of cloud computing, the training process and the model repository of deep learning are moved to the cloud. Cloud-assisted deep learning applications enable smart mobile users to experience quick predictive results. Health professionals use smart mobile devices to convey recordings of the patient and to receive the best inference results. The mobility of these devices causes severe performance degradation as it increases the distance between its current location and the edge cloud where the virtual machines are provisioned. Therefore, mobility-based resource provisioning to identify a suitable server based on deadline constraints, available resources, and cost metrics is crucial. This paper proposes a proximity-based resource provisioning technique that guarantees minimal delay in obtaining inference results with a local mobile cloud system. The proposed technique comprises two algorithms (a) deadline-based initial resource provisioning and (b) resource migration and provisioning at suitable cloudlet during location change. The proposed technique is implemented in a mobile cloud platform running the inference method of a smart mobile healthcare application. The performance results show that the proposed technique outperforms the state-of-the-art techniques in terms of the response time, deadline meeting percentage, and system utilization.},
  archive      = {J_EXSY},
  author       = {Durga Sivan and Mohan Sellappa and Dinesh Peter J},
  doi          = {10.1111/exsy.12524},
  journal      = {Expert Systems},
  month        = {8},
  number       = {7},
  pages        = {e12524},
  shortjournal = {Expert Syst.},
  title        = {Proximity-based cloud resource provisioning for deep learning applications in smart healthcare},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Skin lesion segmentation and classification: A unified
framework of deep neural network features fusion and selection.
<em>EXSY</em>, <em>39</em>(7), e12497. (<a
href="https://doi.org/10.1111/exsy.12497">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated skin lesion diagnosis from dermoscopic images is a difficult process due to several notable problems such as artefacts (hairs), irregularity, lesion shape, and irrelevant features extraction. These problems make the segmentation and classification process difficult. In this research, we proposed an optimized colour feature (OCF) of lesion segmentation and deep convolutional neural network (DCNN)-based skin lesion classification. A hybrid technique is proposed to remove the artefacts and improve the lesion contrast. Then, colour segmentation technique is presented known as OCFs. The OCF approach is further improved by an existing saliency approach, which is fused by a novel pixel-based method. A DCNN-9 model is implemented to extract deep features and fused with OCFs by a novel parallel fusion approach. After this, a normal distribution-based high-ranking feature selection technique is utilized to select the most robust features for classification. The suggested method is evaluated on ISBI series (2016, 2017, and 2018) datasets. The experiments are performed in two steps and achieved average segmentation accuracy of more than 90% on selected datasets. Moreover, the achieve classification accuracy of 92.1%, 96.5%, and 85.1%, respectively, on all three datasets shows that the presented method has remarkable performance.},
  archive      = {J_EXSY},
  author       = {Muhammad Attique Khan and Muhammad Imran Sharif and Mudassar Raza and Almas Anjum and Tanzila Saba and Shafqat Ali Shad},
  doi          = {10.1111/exsy.12497},
  journal      = {Expert Systems},
  month        = {8},
  number       = {7},
  pages        = {e12497},
  shortjournal = {Expert Syst.},
  title        = {Skin lesion segmentation and classification: A unified framework of deep neural network features fusion and selection},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Electromagnetic optimization-based clustering algorithm.
<em>EXSY</em>, <em>39</em>(7), e12491. (<a
href="https://doi.org/10.1111/exsy.12491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the electromagnetic clustering algorithm (ELMC), an enhanced variant of electromagnetic field optimization (EFO), for clustering. The motivation behind ELMC is to overcome the shortcomings of traditional k -means clustering algorithm. The performance of k -means primarily depends upon the initial choice of centroids, which can lead the algorithm towards an undesirable local optimum, if chosen incorrectly or inefficiently. The ELMC utilizes the attraction–repulsion concept of the EFO algorithm to maintain the diversity of the population, making it less vulnerable towards the initial choice of centroids. The performance of ELMC is validated on a set of benchmark problems, and the results are compared with other state-of-the-art algorithms. Numerical and graphical results indicate the competence of the proposed ELMC algorithm.},
  archive      = {J_EXSY},
  author       = {Neetu Kushwaha and Millie Pant and Sugam Sharma},
  doi          = {10.1111/exsy.12491},
  journal      = {Expert Systems},
  month        = {8},
  number       = {7},
  pages        = {e12491},
  shortjournal = {Expert Syst.},
  title        = {Electromagnetic optimization-based clustering algorithm},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Diagnosis of parkinson’s disease from electroencephalography
signals using linear and self-similarity features. <em>EXSY</em>,
<em>39</em>(7), e12472. (<a
href="https://doi.org/10.1111/exsy.12472">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An early stage detection of Parkinson&#39;s disease (PD) is crucial for its appropriate treatment. The quality of life degrades with the advancement of the disease. In this paper, we propose a natural (time) domain technique for the diagnosis of PD. The proposed technique eliminates the need for transformation of the signal to other domains by extracting the feature of electroencephalography signals in the time domain. We hypothesize that two inter-channel similarity features, correlation coefficients and linear predictive coefficients, are able to detect the PD signals automatically using support vector machines classifier with third degree polynomial kernel. A progressive feature addition analysis is employed using selected features obtained based on the feature ranking and principal component analysis techniques. The proposed approach is able to achieve a maximum accuracy of 99.1±0.1 % . The presented computer-aided diagnosis system can act as an assistive tool to confirm the finding of PD by the clinicians.},
  archive      = {J_EXSY},
  author       = {Ankit A. Bhurane and Shivani Dhok and Manish Sharma and Rajamanickam Yuvaraj and Murugappan Murugappan and U. Rajendra Acharya},
  doi          = {10.1111/exsy.12472},
  journal      = {Expert Systems},
  month        = {8},
  number       = {7},
  pages        = {e12472},
  shortjournal = {Expert Syst.},
  title        = {Diagnosis of parkinson&#39;s disease from electroencephalography signals using linear and self-similarity features},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Suggesting method names based on graph neural network with
salient information modelling. <em>EXSY</em>, <em>39</em>(6), e13030.
(<a href="https://doi.org/10.1111/exsy.13030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Descriptive method names have a great impact on improving program readability and facilitating software maintenance. Recently, due to high similarity between the task of method naming and text summarization, large amount of research based on natural language processing has been conducted to generate method names. However, method names are much shorter compared to long source code sequences. The salient information of the whole code snippet account for an relatively small part. Additionally, unlike natural language, source code has complicated structure information. Thus, modelling the salient information from highly structured input presents a great challenge. To tackle this problem, we propose a graph neural network (GNN)-based model with a novel salient information selection layer. Specifically, to comprehensively encode the tokens of the source code, we employ a GNN-based encoder, which can be directly applied to the code graph to ensure that the syntactic information of code structure and semantic information of code sequence can be modelled sufficiently. To effectively discriminate the salient information, we introduce an information selection layer which contains two parts: a global filter gate used to filter irrelevant information, and a semantic-aware convolutional layer used to focus on the semantic information contained in code sequence. To improve the precision of the copy mechanism when decoding, we introduce a salient feature enhanced attention mechanism to facilitate the accuracy of copying tokens from input. Experimental results on an open source dataset indicate that our proposed model, equipped with the salient information selection layer, can effectively improve method naming performance compared to other state-of-the-art models.},
  archive      = {J_EXSY},
  author       = {Li Kuang and Fan Ge and Lingyan Zhang},
  doi          = {10.1111/exsy.13030},
  journal      = {Expert Systems},
  month        = {7},
  number       = {6},
  pages        = {e13030},
  shortjournal = {Expert Syst.},
  title        = {Suggesting method names based on graph neural network with salient information modelling},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Special issue on intelligent software engineering.
<em>EXSY</em>, <em>39</em>(6), e13013. (<a
href="https://doi.org/10.1111/exsy.13013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EXSY},
  author       = {Honghao Gao and Yudong Zhang and Walayat Hussain},
  doi          = {10.1111/exsy.13013},
  journal      = {Expert Systems},
  month        = {7},
  number       = {6},
  pages        = {e13013},
  shortjournal = {Expert Syst.},
  title        = {Special issue on intelligent software engineering},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Advances in robotics for healthcare. <em>EXSY</em>,
<em>39</em>(6), e12998. (<a
href="https://doi.org/10.1111/exsy.12998">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EXSY},
  author       = {Carlos Enrique Montenegro-Marin and Paulo Alonso Gaona-Garcia and Edward Rolando Nuñez Valdez},
  doi          = {10.1111/exsy.12998},
  journal      = {Expert Systems},
  month        = {7},
  number       = {6},
  pages        = {e12998},
  shortjournal = {Expert Syst.},
  title        = {Advances in robotics for healthcare},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). IFGAN: Information fusion generative adversarial network for
knowledge base completion. <em>EXSY</em>, <em>39</em>(6), e12984. (<a
href="https://doi.org/10.1111/exsy.12984">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge base completion (KBC) aims to predict missing information in a knowledge base. From a data governance perspective, KBC is an important task not only in knowledge management but also in downstream knowledge base applications. The prosperity of mobile applications and online systems enables devices to generate an enormous volume of data containing valuable knowledge. However, these data are vast and contain noise, so utilizing them in KBC requires particular skill. In this paper, we propose information fusion generative adversarial network (IFGAN) to handle heterogeneous data. We design a bidirectional learning architecture including a graph convolutional neural network and graph attention network to learn contextual embeddings that fuse knowledge from a knowledge base and data generated by an application. For efficient negative sampling, we employ different kinds of convolution structures, such as depthwise separable convolution and involution in the generator of the network. The convolution structure is known to be suitable for collaborative computing and promises great potential with the progress of technology since the structure is extensible. We demonstrate the effectiveness of the proposed model on KB4Rec dataset, the evaluation metrics MRR and H@10 were improved compared with previous models; the code is available at https://github.com/Tianchen627/IFGAN .},
  archive      = {J_EXSY},
  author       = {Tianchen Zhang and Zhongqin Bi and Meijing Shan and Yongbin Li},
  doi          = {10.1111/exsy.12984},
  journal      = {Expert Systems},
  month        = {7},
  number       = {6},
  pages        = {e12984},
  shortjournal = {Expert Syst.},
  title        = {IFGAN: Information fusion generative adversarial network for knowledge base completion},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Eliminating the high false-positive rate in defect
prediction through BayesNet with adjustable weight. <em>EXSY</em>,
<em>39</em>(6), e12977. (<a
href="https://doi.org/10.1111/exsy.12977">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In defect prediction, a high false-positive rate (FPR) caused by class imbalance not only increases the workload of testing and development but also consumes unnecessary costs. Many defect models against class imbalance have been proposed to improve the accuracy of defect prediction, but their ability to reduce FPR is unclear. To solve these problems, we first proposed a BayesNet with adjustable weights, called WBN, to reduce the FPR in software defect prediction, which is an algorithm independent of data preprocessing techniques. The mechanism of our WBN is to change the sampling probability of the misclassified instances when training the defect model, making the BayesNet model focus more on false alarm instances. And then, we investigate the FPR of five mainstream defect models for solving class imbalance and select them as comparison models to test the validity of our methods. The experimental result on eight open-source projects shows that a) our WBN, in in-version defect prediction (IVDP) and cross-version defect prediction (CVDP), effectively reduces FPR with means of 0.384 and 0.322, respectively; b) compared with improved subclass discriminant analysis (ISDA) that is the lowest FPR in all control models, our WBN not only reduced the FPR but maintained recall whose mean value was 0.797, whereas ISDA did not, with an average recall of only 0.397; c) our WBN, in CVDP, not only reduces FPR, but also has significant superiority over five control defect models and baseline. Besides, we also found that the class imbalance difference between the test set and the training set has an impact on CVDP performance, recommending that practitioners choose the best dataset for CVDP from the defect data of the historical version through special technology.},
  archive      = {J_EXSY},
  author       = {Yanyang Zhao and Yawen Wang and Dalin Zhang and Yunzhan Gong},
  doi          = {10.1111/exsy.12977},
  journal      = {Expert Systems},
  month        = {7},
  number       = {6},
  pages        = {e12977},
  shortjournal = {Expert Syst.},
  title        = {Eliminating the high false-positive rate in defect prediction through BayesNet with adjustable weight},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A fusion of variants of sentence scoring methods and
collaborative word rankings for document summarization. <em>EXSY</em>,
<em>39</em>(6), e12960. (<a
href="https://doi.org/10.1111/exsy.12960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document summarization is an important task in natural language processing that helps deal with the problem of information overload occurring due to the existence of redundant content. Summary generation with highly relevant contents and maximum coverage is particularly challenging which can only be achieved when redundancy is minimized. This article introduces a novel approach for automatic text summarization based on sentence scoring and collaborative ranking to produce summaries with minimal redundancy and improved overall performance of summarization. The proposed model is a fusion of weighted and unweighted features-based sentence scoring methods. To learn optimal weights of text features, it has been modelled as an optimization problem. Moreover, the proposed model exploits the strength of collaborative ranking to generate the summary of a given document. Three similarity factors (proximity, significance and singularity)-based models have been employed to find the similarity between weighted and unweighted sentence scores. The results of the comparison experiment demonstrate that the proposed (PS + Jac) method generates a closer summary to the reference summary with minimal redundant contents. On average, the proposed (PS + Jac) method generates the summaries with 61% accurate contents with greater improved rates up to 40%. The statistical testing also confirms that the performance improvement is significant at a 5% level of significance.},
  archive      = {J_EXSY},
  author       = {Pradeepika Verma and Anshul Verma and Sukomal Pal},
  doi          = {10.1111/exsy.12960},
  journal      = {Expert Systems},
  month        = {7},
  number       = {6},
  pages        = {e12960},
  shortjournal = {Expert Syst.},
  title        = {A fusion of variants of sentence scoring methods and collaborative word rankings for document summarization},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Chirplet transform-based machine-learning approach towards
classification of cognitive state change using galvanic skin response
and photoplethysmography signals. <em>EXSY</em>, <em>39</em>(6), e12958.
(<a href="https://doi.org/10.1111/exsy.12958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in the field of cognitive sciences have provided evidence to classify activities with different cognitive engagement levels. High cognitive load and sustained attention may predispose an individual to psychological and physical stress and may result in a lack of performance. Cognitive load monitoring of professionals in high precision fields has gathered significant attention in the current research scenario. The proposed work in continuity has tried to demonstrate the use of two non-invasive physiological sensing modalities viz. galvanic skin response (GSR) and photoplethysmography (PPG) to elucidate effectiveness in picking up differences of two induced cognitive state categories based on machine learning and statistical methods. This paper demonstrates how GSR and PPG signals data can be effectively utilized to examine the shift in cognitive load. The present work proposes the use of general linear chirplet transform (GLCT) to evaluate the time-frequency characteristic of GSR and PPG signals and utilize the statistical features in classification. Random Forest, Decision Tree, and k-Nearest Neighbours demonstrated an accuracy of 92.13%, 88.0%, and 86.13% respectively on a dataset of 20 subjects against an optimized feature set, thus demonstrating the effectiveness of the proposed methodology for differentiating pre-defined categories of cognitive load. The study shows the potential of GSR and PPG signals attributes and time-frequency representation using GLCT to monitor cognitive load in real-life conditions. The proposed work also indicates the possibility to extend the same to attention-demanding fields such as aviation, medicine, and manufacturing for effective remediation of fatigue periods with increased cognitive demand, which, if sustained, may lead to cognitive decline in the long run.},
  archive      = {J_EXSY},
  author       = {Shuvodeep Saha and Komal Jindal and Divya Shakti and Suman Tewary and Viren Sardana},
  doi          = {10.1111/exsy.12958},
  journal      = {Expert Systems},
  month        = {7},
  number       = {6},
  pages        = {e12958},
  shortjournal = {Expert Syst.},
  title        = {Chirplet transform-based machine-learning approach towards classification of cognitive state change using galvanic skin response and photoplethysmography signals},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Plant competition optimization: A novel metaheuristic
algorithm. <em>EXSY</em>, <em>39</em>(6), e12956. (<a
href="https://doi.org/10.1111/exsy.12956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Plant competition is a fundamental process in plant communities. In one neighbourhood, different plants compete with each other to access shared resources. This paper presents a novel evolutionary algorithm, plant competition optimization (PCO) algorithm, inspired by plant competition processes. In this algorithm, each feasible solution to an optimization problem is assumed to be a plant, with the underlying assumption that each plant grows in competition with its neighbours. In contrast to other techniques inspired by natural phenomena, we attempted to fit the formulation with a known plant growth model, Richards&#39; growth model, and simulate what happens in nature. As the number of plants in a specific area increases, the available resources are decreased, and competition occurs in smaller areas. So, to use this aspect of competition, we develop some mathematical formulation to simulate the decrease of neighbouring area for each plant related to its size to compete on the share resources with the other neighbouring plants. This competition will conduct a smart local search around the most fitted solutions in the optimization context. Furthermore, the reproduction is simulated by producing some seeds in their neighbouring area, which a few of them can migrate to far distances as well. Summing up together, the most powerful plants can grow more. Under competition pressure, their neighbouring area will decrease more than the others, producing more seeds in the next generation. Just as happened in nature, the losers of this competition will die. Our algorithm&#39;s efficiency is shown by performing numerical tests on well-known optimization problems and comparing the results with the other evolutionary algorithms. The results confirm that PCO is effective and efficient in finding sub-optimal solutions and gives better results than genetic algorithm (GA), particle swarm optimization (PSO), simulated annealing (SA), grasshopper optimisation algorithm (GOA), dragonfly algorithm (DA), salp swarm Algorithm (SSA), and comparable results with whale optimization algorithm (WOA) and marine predators algorithm (MPA) on multimodal optimization functions because it efficiently explores the entire search space efficiently and intelligently.},
  archive      = {J_EXSY},
  author       = {Amir Masoud Rahmani and Iman AliAbdi},
  doi          = {10.1111/exsy.12956},
  journal      = {Expert Systems},
  month        = {7},
  number       = {6},
  pages        = {e12956},
  shortjournal = {Expert Syst.},
  title        = {Plant competition optimization: A novel metaheuristic algorithm},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A vision-based clinical analysis for classification of knee
osteoarthritis, parkinson’s disease and normal gait with severity based
on k-nearest neighbour. <em>EXSY</em>, <em>39</em>(6), e12955. (<a
href="https://doi.org/10.1111/exsy.12955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prevalence of musculoskeletal and neurological diseases such as knee osteoarthritis (KOA) and Parkinson&#39;s disease (PD) has grown speedily in recent years. The direct impact of these disorders on a person&#39;s gait has evoked many researchers to perform their analysis using gait because of its greater feasibility. In this paper, we proposed a framework to accurately classify abnormal considering KOA and PD and normal (NM) gait using a vision-based (VB) approach. The aim of this study is four-fold: firstly, a novel VB gait dataset is created and presented; secondly, the segmentation of the region of interest (ROIs) is performed using an improved technique; thirdly gait parameters, that is, spatiotemporal (SPT), linear kinematic (KNM) and additional body motion features are evaluated using statistical methods; fourthly, the classification of KOA, PD and NM subjects has been done based on artificial intelligence or a machine learning technique (MLT), that is, k-nearest neighbour (KNN) at three severity levels and a comparison is performed with other methods namely support vector machine (SVM), random forest (RF) and linear regression (LR). The results reveal the relevance of considered gait features in this investigation. For classification purposes, the highest results are obtained by our proposed method in classifying the subjects with severity also, achieving an overall accuracy = 0.9006, sensitivity = 0.8554, specificity = 0.9044, and precision = 0.8966 respectively. This study thus successfully presents KOA, PD, and NM gait classification method based on the MLT which may be beneficial for clinicians to perform early diagnosis of such disorders objectively.},
  archive      = {J_EXSY},
  author       = {Navleen Kour and Sunanda Gupta and Sakshi Arora},
  doi          = {10.1111/exsy.12955},
  journal      = {Expert Systems},
  month        = {7},
  number       = {6},
  pages        = {e12955},
  shortjournal = {Expert Syst.},
  title        = {A vision-based clinical analysis for classification of knee osteoarthritis, parkinson&#39;s disease and normal gait with severity based on k-nearest neighbour},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enterprise credit risk prediction using supply chain
information: A decision tree ensemble model based on the differential
sampling rate, synthetic minority oversampling technique and AdaBoost.
<em>EXSY</em>, <em>39</em>(6), e12953. (<a
href="https://doi.org/10.1111/exsy.12953">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spread of enterprise credit risk in the supply chain may lead to large-scale bankruptcy and credit crises, which are related to national economic and social stability and financial system security. Therefore, enterprise credit risk in the supply chain context is not only a concern for banking financial institutions, credit rating agencies and enterprise managers but also the focus of governments. This article develops a DTE-DSA (decision tree [DT] ensemble model using the differential sampling rate, Synthetic Minority Oversampling Technique [SMOTE] and AdaBoost) prediction framework integrating supply chain information to predict enterprise credit risk. The empirical test shows that using supply chain information can significantly improve the prediction score. The DTE-DSA model has the best prediction effect in dealing with class imbalance problems. Compared with single classifier models—such as logistic regression, k-nearest neighbours, support vector machine, DT and DT using the SMOTE—as well as ensemble models—such as extremely randomized trees, random forest, rotation forest, extreme gradient boosting, gradient boosting DT and DT ensemble model using AdaBoost—the DTE-DSA model not only has the best prediction score but also has a more stable performance. The comprehensive use of supply chain information and the DTE-DSA model can result in the highest prediction score, with an area under the curve of 0.9016 and a Kolmogorov–Smirnov statistic of 0.7369. Further analysis of the variables of importance enhances the interpretability of the model and obtains relevant management insights.},
  archive      = {J_EXSY},
  author       = {Gang Yao and Xiaojian Hu and Taiyun Zhou and Yue Zhang},
  doi          = {10.1111/exsy.12953},
  journal      = {Expert Systems},
  month        = {7},
  number       = {6},
  pages        = {e12953},
  shortjournal = {Expert Syst.},
  title        = {Enterprise credit risk prediction using supply chain information: A decision tree ensemble model based on the differential sampling rate, synthetic minority oversampling technique and AdaBoost},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improved grey-level correlation feature and neural network
model for medical resource requirement prediction. <em>EXSY</em>,
<em>39</em>(6), e12927. (<a
href="https://doi.org/10.1111/exsy.12927">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the country&#39;s general practitioner training system is constantly improving, problems such as large requirement gaps, low specialization, unfair resource allocation, and uneven regional distribution still exist. In order to promote the improvement of the general practitioner system, to solve the problems of low accuracy and poor robustness of the existing models for medical resource requirement prediction, this paper proposes a combination of grey-scale prediction features and back propogation algorithm (BP) neural network medical resource requirement prediction algorithm. The algorithm first uses the principal component analysis algorithm to solve the principal components of the medical resource requirement influencing factors, then extracts the equal-dimensional dynamic grey-level optimization model grey prediction features of the principal component score, and finally inputs the features into the BP neural network to complete the medical resource requirement prediction. Subsequently, a large number of comparative experiments were carried out on the algorithm proposed in this paper using the medical resource requirement of a certain province as a data set. The experimental results have shown that the comprehensive improvement model proposed in this paper has the best effect in predicting the requirement of medical resources, which contains strong robustness and stability. The algorithm is suitable for the needs of medical resources at this stage. Predicting on the above has strong practical significance in many scenarios by using the proposed algorithm.},
  archive      = {J_EXSY},
  author       = {Hui Teng},
  doi          = {10.1111/exsy.12927},
  journal      = {Expert Systems},
  month        = {7},
  number       = {6},
  pages        = {e12927},
  shortjournal = {Expert Syst.},
  title        = {Improved grey-level correlation feature and neural network model for medical resource requirement prediction},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modelling and analysing the reliability for
microservice-based cloud application based on predicate petri net.
<em>EXSY</em>, <em>39</em>(6), e12924. (<a
href="https://doi.org/10.1111/exsy.12924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microservice design is a new paradigm of cloud application development. Different from monolithic design, microservice enjoys merits of fine-grained and loosely coupled services, and it is becoming more and more popular. The application developed with microservice has a good advantage in independent development and flexible deployment, especially for complex distributed systems. However, there is a big gap between the reliability requirements and microservice-based cloud applications. This article proposes a reliability model of microservice-based cloud application by using predicate Petri net. First, a microservice reliability requirement is given, some basic concepts of predicate Petri net are defined with syntax and semantics. Second, a microservice reliability strategy is proposed, which uses microservice instances and circuit breaker to improve the reliability of the system. Based on the constructed microservice reliability model, the correctness of predicate Petri net modelling and the effectiveness of the strategies are proven theoretically. Finally, an example is given to illustrate the establishment and analysis process of the model, and several groups of experiments are carried out to verify the effectiveness and feasibility of the method. Experimental results show that the proposed microservice reliability strategy is effective.},
  archive      = {J_EXSY},
  author       = {Zheng Liu and Guisheng Fan and Huiqun Yu and Liqiong Chen},
  doi          = {10.1111/exsy.12924},
  journal      = {Expert Systems},
  month        = {7},
  number       = {6},
  pages        = {e12924},
  shortjournal = {Expert Syst.},
  title        = {Modelling and analysing the reliability for microservice-based cloud application based on predicate petri net},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Syntax-based metamorphic relation prediction via the bagging
framework. <em>EXSY</em>, <em>39</em>(6), e12902. (<a
href="https://doi.org/10.1111/exsy.12902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software testing is an indispensable part of the software engineering industry, which guarantees product reliability and safety. Traditional testing approaches face the testing Oracle problem, they are difficult to construct the expected outputs with the increasing of program complexity. As a result, metamorphic testing, which tests the program by examining the relationship between the execution results, is proposed. However, existing manual metamorphic relation construction requires huge effects of domain experts, and automatic methods are unstable and inefficient due to the insufficient software feature mining. Hence, we proposed a multi-dimensional program structure-based metamorphic relation prediction approach, which is composed of feature extraction and prediction model building. In the feature extraction stage, the testing program is converted to multiple intermediate structures (such as control flow graphs and abstract syntax trees) to explore its features. In the prediction model building stage, the extracted feature set is used as the training set, and a novel semi-supervised support vector machine-bagging-K-nearest neighbors algorithm is designed to train the prediction model. Besides, a two-phase hybrid granularity search algorithm is proposed to improve the prediction performance by selecting the optimal number of weak classifiers. Compared with existing approaches, our proposed model can improve the accuracy by around 14%.},
  archive      = {J_EXSY},
  author       = {Yuyu Yin and Jiajie Ruan and Youhuizi Li and Yu Li and Zhijin Pan},
  doi          = {10.1111/exsy.12902},
  journal      = {Expert Systems},
  month        = {7},
  number       = {6},
  pages        = {e12902},
  shortjournal = {Expert Syst.},
  title        = {Syntax-based metamorphic relation prediction via the bagging framework},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fetal health classification from cardiotocographic data
using machine learning. <em>EXSY</em>, <em>39</em>(6), e12899. (<a
href="https://doi.org/10.1111/exsy.12899">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Health complications during the gestation period have evolved as a global issue. These complications sometimes result in the mortality of the fetus, which is more prevalent in developing and underdeveloped countries. The genesis of machine learning (ML) algorithms in the healthcare domain have brought remarkable progress in disease diagnosis, treatment, and prognosis. This research deploys various ML algorithms to predict fetal health from the cardiotocographic (CTG) data by labelling the health state into normal, needs guarantee, and pathology. This work assesses the influence of various factors measured through CTG to predict the health state of the fetus through algorithms like support vector machine, random forest (RF), multi-layer perceptron, and K-nearest neighbours. In addition to this, the regression analysis and correlation analysis revealed the influence of the attributes on fetal health. The results of the algorithms show that RF performs better than its peers in terms of accuracy, precision, recall, F1-score, and support. This work can further enhance more promising results by performing suitable feature engineering in the CTG data.},
  archive      = {J_EXSY},
  author       = {Abolfazl Mehbodniya and Arokia Jesu Prabhu Lazar and Julian Webber and Dilip Kumar Sharma and Santhosh Jayagopalan and Kousalya K and Pallavi Singh and Regin Rajan and Sharnil Pandya and Sudhakar Sengan},
  doi          = {10.1111/exsy.12899},
  journal      = {Expert Systems},
  month        = {7},
  number       = {6},
  pages        = {e12899},
  shortjournal = {Expert Syst.},
  title        = {Fetal health classification from cardiotocographic data using machine learning},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-tenancy and robust workflow management system.
<em>EXSY</em>, <em>39</em>(6), e12878. (<a
href="https://doi.org/10.1111/exsy.12878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Workflow management system (WfMS) in cloud always works as platform as a service to manage customized business processes for massive enterprises. In big data era, non-functional guarantees of such systems are significant when facing a large number of users and concurrent requests. It is not trivial to support multi-tenancy and hold high-availability, because traditional architecture cannot simultaneously satisfy requirements about data isolation and runtime efficiency. In this paper, a modularized distributed workflow management system is proposed, which considers both multi-tenancy and high-availability in storage and engine parts of the system. A multiple-worker-with-separate-schema mechanism is defined to jointly manage the data for tenants, and a proactive strategy is presented to intelligently dispatch large concurrent requests from users to engine workers. After extensive case studies and experiments in practical scenes, our system deployed on modest machines is proved to support tens of thousands of tenants, second-level response time for 10 K concurrency, and no-human-intervened failure recovery for a fail-stop system node.},
  archive      = {J_EXSY},
  author       = {Weilong Ding and Ji Liu and Zhongguo Yang and Bo Lv and Han Li and Hanchuan Xu},
  doi          = {10.1111/exsy.12878},
  journal      = {Expert Systems},
  month        = {7},
  number       = {6},
  pages        = {e12878},
  shortjournal = {Expert Syst.},
  title        = {A multi-tenancy and robust workflow management system},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An english teaching quality evaluation model based on
gaussian process machine learning. <em>EXSY</em>, <em>39</em>(6),
e12861. (<a href="https://doi.org/10.1111/exsy.12861">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EXSY},
  author       = {Shi Qi and Lei Liu and B. Santhosh Kumar and A. Prathik},
  doi          = {10.1111/exsy.12861},
  journal      = {Expert Systems},
  month        = {7},
  number       = {6},
  pages        = {e12861},
  shortjournal = {Expert Syst.},
  title        = {An english teaching quality evaluation model based on gaussian process machine learning},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Study on the effect of mental health nursing intervention
after gynecological tumour operation based on clustering model.
<em>EXSY</em>, <em>39</em>(6), e12844. (<a
href="https://doi.org/10.1111/exsy.12844">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to explore scientific and effective mental health nursing intervention methods after gynecological tumour surgery, this paper combines the clustering algorithm to process the nursing method data. Aiming at the type of comprehensive design structure matrix, this paper compares and analyzes the pros and cons of current intelligent clustering algorithms and selects a high-fit density algorithm as the clustering algorithm of the module division method. Moreover, this paper explains the relative meaning of module cohesion and coupling and uses the smallest ratio of cohesion and coupling as the criterion of the module division method to select the best results from the clustering. In addition, this paper combines the actual situation of mental health nursing intervention after gynecological tumour surgery to set the nursing intervention effect and analyzes the effectiveness of the centralized nursing intervention method through the contrast method. From the test results, it can be seen that the joint intervention nursing method has the best effect on the mental health nursing intervention after gynecological tumour surgery, which provides theoretical guidance for the subsequent mental health intervention after gynecological tumour surgery.},
  archive      = {J_EXSY},
  author       = {Li Li and Yi Lu and Hongmei Li and Ai Lan Liu},
  doi          = {10.1111/exsy.12844},
  journal      = {Expert Systems},
  month        = {7},
  number       = {6},
  pages        = {e12844},
  shortjournal = {Expert Syst.},
  title        = {Study on the effect of mental health nursing intervention after gynecological tumour operation based on clustering model},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The role of contemporary digital tools and technologies in
COVID-19 crisis: An exploratory analysis. <em>EXSY</em>, <em>39</em>(6),
e12834. (<a href="https://doi.org/10.1111/exsy.12834">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Following the COVID-19 pandemic, there has been an increase in interest in using digital resources to contain pandemics. To avoid, detect, monitor, regulate, track, and manage diseases, predict outbreaks and conduct data analysis and decision-making processes, a variety of digital technologies are used, ranging from artificial intelligence (AI)-powered machine learning (ML) or deep learning (DL) focused applications to blockchain technology and big data analytics enabled by cloud computing and the internet of things (IoT). In this paper, we look at how emerging technologies such as the IoT and sensors, AI, ML, DL, blockchain, augmented reality, virtual reality, cloud computing, big data, robots and drones, intelligent mobile apps, and 5G are advancing health care and paving the way to combat the COVID-19 pandemic. The aim of this research is to look at possible technologies, processes, and tools for addressing COVID-19 issues such as pre-screening, early detection, monitoring infected/quarantined individuals, forecasting future infection rates, and more. We also look at the research possibilities that have arisen as a result of the use of emerging technology to handle the COVID-19 crisis.},
  archive      = {J_EXSY},
  author       = {Malliga Subramanian and Kogilavani Shanmuga Vadivel and Wesam Atef Hatamleh and Abeer Ali Alnuaim and Mohamed Abdelhady and Sathishkumar V E},
  doi          = {10.1111/exsy.12834},
  journal      = {Expert Systems},
  month        = {7},
  number       = {6},
  pages        = {e12834},
  shortjournal = {Expert Syst.},
  title        = {The role of contemporary digital tools and technologies in COVID-19 crisis: An exploratory analysis},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Human muscle rigidity identification by human-robot
approximation characteristics framework on internet of things platform.
<em>EXSY</em>, <em>39</em>(6), e12824. (<a
href="https://doi.org/10.1111/exsy.12824">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the health care system and Internet of Things (IoT) platform, medical care robotics is becoming one of the quickest expanding areas of robot technology. The integration of robotics and human knowledge identifies human muscle rigidity from the healthcare data obtained from the wearable sensor. In an IoT platform, Electromyography is a method used for evaluating and tracking the electrical activity of muscles. The transferring of human muscle rigidity to a robot facilitates the robot to obtain resistive management initiatives in a useful and effective way while carrying out physical interaction activities in unstructured surroundings. The major challenges to overcome the unpredictability during physical interaction allow a robot to realize the individual behaviour with adaptability and versatility of muscles. Therefore, in this article, Human-Robot Approximation Characteristics Framework (HRACF) has been proposed for developing physiological communication between humans and robots. HRACF permits robots to understand differential resistive abilities of muscles from human presentations. The pulses collected from Electromyography are used to retrieve human arm muscle rigidity during activity presentation. The characteristics of motion and rigidity are concurrently modelled using an estimation and approximation model with a logistic regression obtained by IoT devices. The analysed human arm muscle rigidity is then connected to the robot impedance regulator. HR model uses an optimized resistive approximator to measure the creative variables of the robot and continue driving to monitor the quoted pathways at the time of interaction. The relationship between motion data and rigidity data is systematically coded in the HR model. HRACF makes it possible to detect uncertainties through space and time that facilitates the robot to meet rigidity specification to 98[Nm/Rad] and error rate to 0.15% during physical interaction.},
  archive      = {J_EXSY},
  author       = {Rajalakshmi Selvaraj and Venu Madhav Kuthadi and S. Baskar},
  doi          = {10.1111/exsy.12824},
  journal      = {Expert Systems},
  month        = {7},
  number       = {6},
  pages        = {e12824},
  shortjournal = {Expert Syst.},
  title        = {Human muscle rigidity identification by human-robot approximation characteristics framework on internet of things platform},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detection of neurodegenerative disease in brain using region
splitting based segmentation with deep unsupervised neural networks.
<em>EXSY</em>, <em>39</em>(6), e12775. (<a
href="https://doi.org/10.1111/exsy.12775">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised segmentation is a significant pre-processing task in various computer visualization processes. However, recently used unsupervised segmentation methods are very sensitive to few of the parameters like number of segmentation or numerous training and more inference complication. Neurodegenerative disorders namely Parkinson&#39;s and Alzheimer&#39;s, add up to main aspects to longer disability and has grown to be a more serious concept in the developed nations. At present, there does not exist efficient therapies. Earlier diagnosis along with avoiding misdiagnosis significantly assists in ensuring a good quality for patient&#39;s life. Hence, adopting computer-aided-diagnosis tools provides clinical assistance. This paper focus on detecting neurodegenerative disease from CT brain images by segmentation through region splitting based segmentation with deep unsupervised neural networks (RSS-DUNN).Auto encoder deep neural network is constructed with reconstruction process of input image, which further improves the accuracy. The performance of the proposed model is evaluated by comparing it with two standard methods in terms of accuracy, precision, recall, Jaccard similarity index (JSI) and dice similarity coefficient (DSC). As a result, it achieves 70.4% of accuracy, 70.8% of precision, 75.8% of recall, 73.6% of JSI and 81% of DSC.},
  archive      = {J_EXSY},
  author       = {C. Rajive Gandhi and V. Murugesh},
  doi          = {10.1111/exsy.12775},
  journal      = {Expert Systems},
  month        = {7},
  number       = {6},
  pages        = {e12775},
  shortjournal = {Expert Syst.},
  title        = {Detection of neurodegenerative disease in brain using region splitting based segmentation with deep unsupervised neural networks},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep ensemble learning approach for lower extremity
activities recognition using wearable sensors. <em>EXSY</em>,
<em>39</em>(6), e12743. (<a
href="https://doi.org/10.1111/exsy.12743">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human walking is a very challenging task and always requires rigorous practice. It is a learning process that involves the complex coordination of the brain and lower limbs. The bipedal robots that mimic the human morphological structure to produce human similar walking, are not capable of producing an efficient walk. Due to walking challenges and structural differences, a robot cannot walk like a human being. In this research, to achieve the aforementioned objective to produce a human similar walk, human lower extremity activities are considered to understand walking behaviour. The experiment involves different walking styles on different terrains. To capture the learning process of bipedal robot locomotion, a deep learning-based ensemble classifier is introduced for human lower activities recognition. To understand the learning process seven different walking activities are considered for analysis purposes. An Inertial measurement unit (IMU) is used as a wearable device due to its small form factor and unobtrusive nature to capture the walking movement of different lower limbs joints. Three public datasets viz. mHealth, OU-ISIR similar action and HAPT inertial sensor data sets are considered for this study. To classify the activities, 2 different deep learning models namely convolutional neural network (CNN) and long short-term memory (LSTM) are used. To generalize the results, an ensemble of different classifiers is implemented. The Classifier has reported accuracy of 99.25%, 88.48% and 97.44%, respectively, on the aforementioned data sets. This work can be utilized for elderly subjects&#39; postural stability, rehabilitation of patients post-stroke and trauma, generation of robot walk trajectories in cluttered environment and reconstruction of impaired walking.},
  archive      = {J_EXSY},
  author       = {Rahul Jain and Vijay Bhaskar Semwal and Praveen Kaushik},
  doi          = {10.1111/exsy.12743},
  journal      = {Expert Systems},
  month        = {7},
  number       = {6},
  pages        = {e12743},
  shortjournal = {Expert Syst.},
  title        = {Deep ensemble learning approach for lower extremity activities recognition using wearable sensors},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A deep learning semantic segmentation architecture for
COVID-19 lesions discovery in limited chest CT datasets. <em>EXSY</em>,
<em>39</em>(6), e12742. (<a
href="https://doi.org/10.1111/exsy.12742">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the epidemic of COVID-19, Computed Tomography (CT) is used to help in the diagnosis of patients. Most current studies on this subject appear to be focused on broad and private annotated data which are impractical to access from an organization, particularly while radiologists are fighting the coronavirus disease. It is challenging to equate these techniques since they were built on separate datasets, educated on various training sets, and tested using different metrics. In this research, a deep learning semantic segmentation architecture for COVID-19 lesions detection in limited chest CT datasets will be presented. The proposed model architecture consists of the encoder and the decoder components. The encoder component contains three layers of convolution and pooling, while the decoder contains three layers of deconvolutional and upsampling. The dataset consists of 20 CT scans of lungs belongs to 20 patients from two sources of data. The total number of images in the dataset is 3520 CT scans with its labelled images. The dataset is split into 70% for the training phase and 30% for the testing phase. Images of the dataset are passed through the pre-processing phase to be resized and normalized. Five experimental trials are conducted through the research with different images selected for the training and the testing phases for every trial. The proposed model achieves 0.993 in the global accuracy, and 0.987, 0.799, 0.874 for weighted IoU, mean IoU and mean BF score accordingly. The performance metrics such as precision, sensitivity, specificity and F1 score strengthens the obtained results. The proposed model outperforms the related works which use the same dataset in terms of performance and IoU metrics.},
  archive      = {J_EXSY},
  author       = {Nour Eldeen M. Khalifa and Gunasekaran Manogaran and Mohamed Hamed N. Taha and Mohamed Loey},
  doi          = {10.1111/exsy.12742},
  journal      = {Expert Systems},
  month        = {7},
  number       = {6},
  pages        = {e12742},
  shortjournal = {Expert Syst.},
  title        = {A deep learning semantic segmentation architecture for COVID-19 lesions discovery in limited chest CT datasets},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybrid intelligent framework for automated medical learning.
<em>EXSY</em>, <em>39</em>(6), e12737. (<a
href="https://doi.org/10.1111/exsy.12737">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the automated medical learning and proposes hybrid intelligent framework, called Hybrid Automated Medical Learning (HAML). The goal is the efficient combination of several intelligent components in order to automatically learn the medical data. Multi agents system is proposed by using distributed deep learning, and knowledge graph for learning medical data. The distributed deep learning is used for efficient learning of the different agents in the system, where the knowledge graph is used for dealing with heterogeneous medical data. To demonstrate the usefulness and accuracy of the HAML framework, intensive simulations on medical data were conducted. A wide range of experiments were conducted to verify the efficiency of the proposed system. Three case studies are discussed in this research, the first case study is related to process mining, and more precisely on the ability of HAML to detect relevant patterns from event medical data. The second case study is related to smart building, and the ability of HAML to recognize the different activities of the patients. The third one is related to medical image retrieval, and the ability of HAML to find the most relevant medical images according to the image query. The results show that the developed HAML achieves good performance compared to the most up-to-date medical learning models regarding both the computational and cost the quality of returned solutions.},
  archive      = {J_EXSY},
  author       = {Asma Belhadi and Youcef Djenouri and Vicente Garcia Diaz and Essam H. Houssein and Jerry Chun-Wei Lin},
  doi          = {10.1111/exsy.12737},
  journal      = {Expert Systems},
  month        = {7},
  number       = {6},
  pages        = {e12737},
  shortjournal = {Expert Syst.},
  title        = {Hybrid intelligent framework for automated medical learning},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimizing demand-driven null dereference verification via
merging branches. <em>EXSY</em>, <em>39</em>(6), e12707. (<a
href="https://doi.org/10.1111/exsy.12707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Null dereference is a common type of runtime failure in Java programs, and it is necessary to verify whether a dereference in the program is safe. However, previous works often have redundant path exploration and high false positive rate. In this paper, we propose a merged null dereference verification (MNDV) approach. MNDV employs a backward, path-sensitive inter-procedural analysis technique to verify a given dereference as safe or potentially unsafe. It uses a branch merging strategy to remove redundant paths, and a method call&#39;s relevance to the null references is checked to determine whether it is necessary to explore the internal codes of the method. We have evaluated the approach in some standard benchmark programs. Compared with some existing approaches, our approach reduces false alarm rate and effectively reduce time and memory consumption.},
  archive      = {J_EXSY},
  author       = {Cheng Huihui and Zeng Hongwei},
  doi          = {10.1111/exsy.12707},
  journal      = {Expert Systems},
  month        = {7},
  number       = {6},
  pages        = {e12707},
  shortjournal = {Expert Syst.},
  title        = {Optimizing demand-driven null dereference verification via merging branches},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Heterogeneous computing model for post-injury walking
pattern restoration and postural stability rehabilitation exercise
recognition. <em>EXSY</em>, <em>39</em>(6), e12706. (<a
href="https://doi.org/10.1111/exsy.12706">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The research paper presents the heterogeneous computing model for analysis &amp; restoration of human walking deformity and posture instability. Gait-related walking activities are very important for the analysis of postural instability, repairment of gait abnormality, diagnosis of cognitive declination, enhance the cognitive ability of human-centered humanoid robot system, and many clinical diagnoses, for example, Parkinson, pathological gait, freezing of gait, etc. at an early stage. For experiment analysis, 10 different lower limb activities are being considered of healthy and crouch walking subjects. A total of 25 healthy and 10 crouch walk subjects are considered for experiment purposes of different age groups, sex, and mental status. To achieve this objective the pattern of 10 different rehabilitation activities are captured using RGB-Depth (RGB-D) camera and classified using heterogeneous deep learning models. Different deep learning models Convolutional Neural Network (CNN) and CNN-LSTM (CNN-Long Short Term Memory) are used for the classification of these rehabilitation exercises. The RGB-D data is obtained using a Microsoft Kinect v2 sensor on a 100 Hz sampling frequency. Experimental results have shown significant activity recognition accuracy with 96% and 98% for CNN and CNN-LSTM models respectively.},
  archive      = {J_EXSY},
  author       = {Vishwanath Bijalwan and Vijay Bhaskar Semwal and Ghanapriya Singh and Ruben Gonzalez Crespo},
  doi          = {10.1111/exsy.12706},
  journal      = {Expert Systems},
  month        = {7},
  number       = {6},
  pages        = {e12706},
  shortjournal = {Expert Syst.},
  title        = {Heterogeneous computing model for post-injury walking pattern restoration and postural stability rehabilitation exercise recognition},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cognitive smart cities: Challenges and trending solutions.
<em>EXSY</em>, <em>39</em>(5), e12981. (<a
href="https://doi.org/10.1111/exsy.12981">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EXSY},
  author       = {Varun G. Menon and Reza Khosravi and Alireza Jolfaei and Akshi Kumar and Vinod P},
  doi          = {10.1111/exsy.12981},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12981},
  shortjournal = {Expert Syst.},
  title        = {Cognitive smart cities: Challenges and trending solutions},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Introduction to the special issue on big data analytics with
internet of things-oriented infrastructures for future smart cities.
<em>EXSY</em>, <em>39</em>(5), e12969. (<a
href="https://doi.org/10.1111/exsy.12969">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EXSY},
  author       = {Rohit Sharma and Deepak Gupta and Andino Maseleno and Sheng-Lung Peng},
  doi          = {10.1111/exsy.12969},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12969},
  shortjournal = {Expert Syst.},
  title        = {Introduction to the special issue on big data analytics with internet of things-oriented infrastructures for future smart cities},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-scale event causality extraction via simultaneous
knowledge-attention and convolutional neural network. <em>EXSY</em>,
<em>39</em>(5), e12952. (<a
href="https://doi.org/10.1111/exsy.12952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event causality extraction is a challenging task in natural language processing (NLP), which plays an important role in event prediction, scene generation, question answering and textual entailment. Most existing methods focus on extracting single-scale (such as phrase) event causality, while fails to extract multi-scale (such as word, phrase, sentence) event causality. To fill the gap, we propose multi-scale event causality extraction via simultaneous knowledge-attention and convolutional neural network (KA-CNN). First, knowledge-attention takes N-gram embedding as input and takes semantic features, fused with prior knowledge through causal associative link network (CALN), as output. Second, multi-scale CNN is designed with word embedding as input and semantic feature of corpus as output. Third, bidirectional long short-term memory with conditional random field (BiLSTM + CRF) is conducted after concatenation of features from knowledge-attention and multi-scale CNN. Finally, we compare our results with other baselines. The experimental results show that our proposed method shows promising result in extracting multi-scale event causality.},
  archive      = {J_EXSY},
  author       = {Xiaoxiao Yu and Xinzhi Wang and Xiangfeng Luo and Jianqi Gao},
  doi          = {10.1111/exsy.12952},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12952},
  shortjournal = {Expert Syst.},
  title        = {Multi-scale event causality extraction via simultaneous knowledge-attention and convolutional neural network},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predicting the severity of COVID-19 patients using a
multi-threaded evolutionary feature selection algorithm. <em>EXSY</em>,
<em>39</em>(5), e12949. (<a
href="https://doi.org/10.1111/exsy.12949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic has huge effects on the global community and an extreme burden on health systems. There are more than 185 million confirmed cases and 4 million deaths as of July 2021. Besides, the exponential rise in COVID-19 cases requires a quick prediction of the patients&#39; severity for better treatment. In this study, we propose a Multi-threaded Genetic feature selection algorithm combined with Extreme Learning Machines (MG-ELM) to predict the severity level of the COVID-19 patients. We conduct a set of experiments on a recently published real-world dataset. We reprocess the dataset via feature construction to improve the learning performance of the algorithm. Upon comprehensive experiments, we report the most impactful features and symptoms for predicting the patients&#39; severity level. Moreover, we investigate the effects of multi-threaded implementation with statistical analysis. In order to verify the efficiency of MG-ELM, we compare our results with traditional and state-of-the-art techniques. The proposed algorithm outperforms other algorithms in terms of prediction accuracy.},
  archive      = {J_EXSY},
  author       = {Ayça Deniz and Hakan Ezgi Kiziloz and Ender Sevinc and Tansel Dokeroglu},
  doi          = {10.1111/exsy.12949},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12949},
  shortjournal = {Expert Syst.},
  title        = {Predicting the severity of COVID-19 patients using a multi-threaded evolutionary feature selection algorithm},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fusion of b-mode and shear wave elastography ultrasound
features for automated detection of axillary lymph node metastasis in
breast carcinoma. <em>EXSY</em>, <em>39</em>(5), e12947. (<a
href="https://doi.org/10.1111/exsy.12947">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we evaluate and compare the diagnostic performance of ultrasound for non-invasive axillary lymph node (ALN) metastasis detection. The study was based on fusing shear wave elastography (SWE) and B-mode ultrasonography (USG) images. These images were subjected to pre-processing and feature extraction, based on bi-dimensional empirical mode decomposition and higher order spectra methods. The resulting nonlinear features were ranked according to their p -value, which was established with Student&#39;s t -test. The ranked features were used to train and test six classification algorithms with 10-fold cross-validation. Initially, we considered B-mode USG images in isolation. A probabilistic neural network (PNN) classifier was able to discriminate positive from negative cases with an accuracy of 74.77% using 15 features. Subsequently, only SWE images were used and as before, the PNN classifier delivered the best result with an accuracy of 87.85% based on 47 features. Finally, we combined SWE and B-mode USG images. Again, the PNN classifier delivered the best result with an accuracy of 89.72% based on 71 features. These three tests indicate that SWE images contain more diagnostically relevant information when compared with B-mode USG. Furthermore, there is scope in fusing SWE and B-mode USG to improve non-invasive ALN metastasis detection.},
  archive      = {J_EXSY},
  author       = {The-Hanh Pham and Oliver Faust and Joel En Wei Koh and Edward J. Ciaccio and Prabal D. Barua and Norlia Omar and Wei Lin Ng and Nazimah Ab Mumin and Kartini Rahmat and U. Rajendra Acharya},
  doi          = {10.1111/exsy.12947},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12947},
  shortjournal = {Expert Syst.},
  title        = {Fusion of B-mode and shear wave elastography ultrasound features for automated detection of axillary lymph node metastasis in breast carcinoma},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sequential multi-headed attention for entity-based
relational neural networks. <em>EXSY</em>, <em>39</em>(5), e12945. (<a
href="https://doi.org/10.1111/exsy.12945">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The capacity of relational interaction between high-level information and reason is the defining characteristic of human intelligence. Regardless of the remarkable progress in artificial intelligence, recent machine reading comprehension models still heavily rely on high-dimensional word-based distributed representations. Since these models employ statistical means to answer questions of complex textual corpus and employ an accuracy-based metric system, their learning capacity of the required skills is not guaranteed. To ensure the capacity of MRC models to learn the desired skills, explainability has become an emerging requirement. In this paper, we propose an end-to-end natural language reasoning model that is based on sets of high-level aggregated representations which promote operational explainability. To this end, sequential multi-head attention, and a loss regularization function is proposed. We show analysis of the proposed approach on two natural language reasoning oriented question and answering datasets (bAbI and NewsQA).},
  archive      = {J_EXSY},
  author       = {Dagmawi Moges and Jiaxu Zhao and Hong Qu},
  doi          = {10.1111/exsy.12945},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12945},
  shortjournal = {Expert Syst.},
  title        = {Sequential multi-headed attention for entity-based relational neural networks},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modelling uncertainties with TOPSIS and GRA based on q-rung
orthopair m-polar fuzzy soft information in COVID-19. <em>EXSY</em>,
<em>39</em>(5), e12940. (<a
href="https://doi.org/10.1111/exsy.12940">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy hybrid models are strong mathematical tools to address vague and uncertain information in real-life circumstances. The aim of this article is to introduce a new fuzzy hybrid model named as of q-rung orthopair m-polar fuzzy soft set (q-RO-m-PFSS) as a robust fusion of soft set (SS), m-polar fuzzy set (m-PFS) and q-rung orthopair fuzzy set (q-ROFS). A q-RO-m-PFSS is a new approach towards modelling uncertainties in the multi-criteria decision making (MCDM) problems. Some fundamental operations on q-RO-m-PFSSs, their key properties, and related significant results are introduced. Additionally, the complexity of logistics and supply chain management during COVID-19 is analysed using TOPSIS (technique for ordering preference through the ideal solution) and GRA (grey relational analysis) with the help of q-RO-m-PFS information. The linguistic terms are used to express q-RO-m-PFS information in terms of numeric values. The proposed approaches are worthy efficient in the selection of ventilator&#39;s manufacturers for the patients suffering from epidemic disease named as COVID-19. A practical application of proposed MCDM techniques is demonstrated by respective numerical examples. The comparison analysis of the final ranking computed by proposed techniques is also given to justify the feasibility, applicability and reliability of these techniques.},
  archive      = {J_EXSY},
  author       = {Muhammad Riaz and Harish Garg and Muhammad Tahir Hamid and Deeba Afzal},
  doi          = {10.1111/exsy.12940},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12940},
  shortjournal = {Expert Syst.},
  title        = {Modelling uncertainties with TOPSIS and GRA based on q-rung orthopair m-polar fuzzy soft information in COVID-19},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving hand gestures recognition capabilities by
ensembling convolutional networks. <em>EXSY</em>, <em>39</em>(5),
e12937. (<a href="https://doi.org/10.1111/exsy.12937">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hand gestures provide humans a convenient way to interact with computers and many applications. However, factors such as the complexity of hand gesture models, differences in hand size and position, and other factors can affect the performance of the recognition and classification algorithms. Some developments of deep learning such as convolutional neural networks (CNNs) and capsule networks (CapsNets) have been proposed to improve the performance of image recognition systems in this particular field. While CNNs are undoubtedly the most widely used networks for object detection and image classification, CapsNets emerged to solve part of the limitations of the former. For this reason, in this work a particular ensemble of both networks is proposed to solve the American Sign Language recognition problem very effectively. The method is based on increasing diversity in both the model and the dataset. The results obtained show that the proposed ensemble model together with a simple data augmentation process produces a very competitive accuracy performance with the all considered datasets.},
  archive      = {J_EXSY},
  author       = {Khalil Bousbai and Juan Morales-Sánchez and Mostefa Merah and José-Luis Sancho-Gómez},
  doi          = {10.1111/exsy.12937},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12937},
  shortjournal = {Expert Syst.},
  title        = {Improving hand gestures recognition capabilities by ensembling convolutional networks},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Personalization of the collaborator recommendation system in
multi-layer scientific social networks: A case study of ResearchGate.
<em>EXSY</em>, <em>39</em>(5), e12932. (<a
href="https://doi.org/10.1111/exsy.12932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of knowledge sharing platforms, like scientific social networks encourages researchers to establish international collaboration in scientific projects. After reviewing the previous methods for collaborator detection in social networks, gaps in the earlier models are investigated, and the present study aims at filling the gaps by introducing a new scientific collaborator recommendation system. Accordingly, in the present paper, an integrated model is presented based on multilayer networks that can personalize the proposing scientific collaborators. Our proposed model involves various types of collaboration features based on researchers&#39; needs. In our method a scientific social network is modelled as a multi-relational network (MRN), in which collaborators are determined by a community detection algorithm. It provides us with an approach to integrate the personalized features into the collaborator detection model that is due to the essence of semi-supervisory learning of our community detection algorithm. This MRN helps us prevent information loss in the network. We considered two techniques for examining the models. The first one was General Collaborator Recommendation, and the second one was a Collaborator with Personalization Ability. The proposed method is applied to the data of the ResearchGate (RG) social network and is evaluated by criteria, such as F index and NMI .},
  archive      = {J_EXSY},
  author       = {Zahra Roozbahani and Jalal Rezaeenour and Ali Katanforoush and Amir Jalaly Bidgoly},
  doi          = {10.1111/exsy.12932},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12932},
  shortjournal = {Expert Syst.},
  title        = {Personalization of the collaborator recommendation system in multi-layer scientific social networks: A case study of ResearchGate},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Peri-ictal and non-seizure EEG event detection using
generated metadata. <em>EXSY</em>, <em>39</em>(5), e12929. (<a
href="https://doi.org/10.1111/exsy.12929">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lack of open access, seizure specific database has hindered the development of Automated Seizure Detection System (ASDS) along with state-of-the-art feature selection and classification methods. Available databases contain noise, artefacts, different length &amp; time EEG segments, associated comorbidities, clinical settings, and epilepsy/seizure types etc. Pre-processing of such continuous EEG segments requires significant amount of time and may feed redundant information (with reference to a seizure event) to the classification model leading to inaccurate, real-time seizure event detection systems. Hence, this paper proposes a metadata generation of large EEG databases (here, CHB-MIT EEG scalp database v.1.0.0) for ASDS. We elucidate the need to generate seizure sensitive data through peri-ictal and non-seizure EEG segments. This paper performs multi-variate analysis and two class (non-seizure and seizure event) classification between these fixed length and time EEG segments from support vector machine (SVM) and k-NN classifier. We thoroughly analysed the variation and dependence of different kernels, cost function, gamma, and degree for SVM based pipeline. The proposed pipeline has been compared with state-of-the-art pipelines and has achieved good classification score. Such methods will help in development of generalised approach toward handling large EEG databases and machine learning applications for seizure detection and prediction.},
  archive      = {J_EXSY},
  author       = {Palak Handa and Nidhi Goel},
  doi          = {10.1111/exsy.12929},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12929},
  shortjournal = {Expert Syst.},
  title        = {Peri-ictal and non-seizure EEG event detection using generated metadata},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A superpixel powered autoencoder technique for detecting
dementia. <em>EXSY</em>, <em>39</em>(5), e12926. (<a
href="https://doi.org/10.1111/exsy.12926">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dementia is a neurocognitive disorder responsible for decreasing the overall quality of life for patients. The disease has emerged as a worldwide health challenge in adults in the age group of 65 years or above. Deep learning has been successfully applied for the prediction of dementia using magnetic resonance imaging. In this paper, a superpixel-powered autoencoder technique has been proposed using a histogram of oriented gradients for extracting the relevant features. The proposed technique is capable of predicting and classifying three categories of dementia—normal, mild cognitive impairment and dementia subjects. The viability of the proposed method is established by comparing it with the other state of art models and the popular pre-trained networks including Squeezenet, Resnet50, Resnet18, Inceptionv3, Googlenet, VGG19 and Alexnet. The experimental results establish that the proposed model has performed significantly better than the state of art models and has outperformed the popular pre-trained networks.},
  archive      = {J_EXSY},
  author       = {Deepika Bansal and Kavita Khanna and Rita Chhikara and Rakesh Kumar Dua and Rajeev Malhotra},
  doi          = {10.1111/exsy.12926},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12926},
  shortjournal = {Expert Syst.},
  title        = {A superpixel powered autoencoder technique for detecting dementia},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analysis of risk factors for blood transfusion in preterm
infants based on statistical analyses. <em>EXSY</em>, <em>39</em>(5),
e12925. (<a href="https://doi.org/10.1111/exsy.12925">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve the analysis effect of risk factors for blood transfusion in preterm infants, this paper studies the natural gradient algorithm based on statistical analysis methods and analyzes the data processing effect of the algorithm. Moreover, this paper combines the analysis of risk factors for blood transfusion in preterm infants to build a factor analysis system based on statistical analysis algorithms and intelligent algorithms, and combines back propagation (BP) neural networks to build the statistical intelligence model. In addition, this paper designs experiments to verify the performance of the statistical intelligence model constructed in this paper, combines statistical methods to perform data processing, and analyzes experimental results through control experiments. From the experimental research results, it can be known that the statistical processing method of risk factors proposed in this paper has a certain effect. Simultaneously, through a large amount of data training research and analysis, it is confirmed that the system constructed in this paper has good data processing effects and can be applied to practice.},
  archive      = {J_EXSY},
  author       = {Jianhui Liu and Jiao Wang and Panpan Ma and Juanjing Geng and Wenyan Chen and Zhiping Sun},
  doi          = {10.1111/exsy.12925},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12925},
  shortjournal = {Expert Syst.},
  title        = {Analysis of risk factors for blood transfusion in preterm infants based on statistical analyses},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). EEG-based automatic multi-class classification of epileptic
seizure types using recurrence plots. <em>EXSY</em>, <em>39</em>(5),
e12923. (<a href="https://doi.org/10.1111/exsy.12923">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is an urgent need to develop an efficient system for accurate recognition of epileptic seizure type that could play a significant role in reducing the adversial effects of the disease. A lot of work is available for EEG based automatic seizure detection but very less attempts have been made towards the classification of variants of seizures. Moreover, none of the authors have included the EEG signals for myoclonic seizure type in their classification studies. Our study aims to propose the automatic machine learning based multi-class classification system for classifying six types of epileptic seizures (such as absence, focal non-specific, complex-partial, generalized, tonic–clonic and including myoclonic too) through the use of recurrence plots (RPs). In our study, we have collected 19-channel EEG data from a huge database of Temple University Hospital. Two classification modalities have been proposed depending upon the feature extraction approach followed for RPs- (a) Traditional approach using the recurrence quantification analysis (RQA) method; (b) Texture based approach using the hybrid method named as Unthresholded Recurrence Plot with Fractal Weighted Local Binary Pattern (URP-FWLBP), that has been proposed in our work using a combination of Unthresholded RPs (URPs) and Fractal Weighted Local Binary Pattern (FWLBP) method. Thereby, an indirect variant of support vector machine (one-vs-rest approach) has been used as the multi-class classifier in both the approaches. The performance of the proposed modalities has been validated using five-fold cross-validation method in the light of seven metrics- accuracy, sensitivity, specificity, Matthews correlation coefficient, geometric-mean, precision and f1-score. The experimental results show the effectiveness of the proposed system following hybrid URP-FWLBP method in performing multi-class epileptic seizure type classification with 100% efficiency, thereby outperforming the traditional RQA method based system as well the existing state-of-the-art systems.},
  archive      = {J_EXSY},
  author       = {Ashima Khosla and Padmavati Khandnor and Trilok Chand},
  doi          = {10.1111/exsy.12923},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12923},
  shortjournal = {Expert Syst.},
  title        = {EEG-based automatic multi-class classification of epileptic seizure types using recurrence plots},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Overlapping community detection in complex networks using
fuzzy theory, balanced link density, and label propagation.
<em>EXSY</em>, <em>39</em>(5), e12921. (<a
href="https://doi.org/10.1111/exsy.12921">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex networks represent various real-world systems. Overlapping community detection is one of the critical tasks in studying these networks and has significance to a wide variety of applications, including the exploration of online social networks because of the natural attitude of persons to participate in multiple communities at the same time. Despite a large number of existing community detection algorithms for detecting disjoint communities, the efficient and fast uncovering of overlapping communities has remained a challenging problem. To provide an efficient solution, on the one hand, the balanced link density label propagation (BLDLP) algorithm, proposed by the authors of the current study, is a fast, stable, and efficient method for disjoint community detection. On the other hand, the fuzzy theory is a worthwhile approach for overlapping community detection since it provides the membership rate of the overlapping nodes as well as the detection of overlapping communities. Hence, in this paper, based on the synergy of the BLDLP algorithm and the fuzzy theory, a novel method, called fuzzy BLDLP, for overlapping community detection is proposed. Fuzzy BLDLP is fast and efficient. The proposed method needs no prior information about the number of network communities to discover them. The experiments on both synthetic and real-world known networks, including Zachary, Dolphins, and COVID-19 Co-authorship, have revealed that the proposed method successfully detects the overlapping nodes and communities and hence is comparable with the state-of-the-art overlapping community detection algorithms in terms of recall, precision, F -score and overlapping normalized mutual information.},
  archive      = {J_EXSY},
  author       = {Ehsan Jokar and Mohammad Mosleh and Mohammad Kheyrandish},
  doi          = {10.1111/exsy.12921},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12921},
  shortjournal = {Expert Syst.},
  title        = {Overlapping community detection in complex networks using fuzzy theory, balanced link density, and label propagation},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Computer-aided diagnosis of COVID-19 disease from chest
x-ray images integrating deep feature extraction. <em>EXSY</em>,
<em>39</em>(5), e12919. (<a
href="https://doi.org/10.1111/exsy.12919">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The novel coronavirus (COVID-19) has an enormous impact on the daily lives and health of people residing in more than 200 nations. This article proposes a deep learning-based system for the rapid diagnosis of COVID-19. Chest x-ray radiograph images were used because recent findings revealed that these images contain salient features about COVID-19 disease. Transfer learning was performed using different pre-trained convolutional neural networks models for binary (normal and COVID-19) and triple (normal, COVID-19 and viral pneumonia) class problems. Deep features were extracted from a fully connected layer of the ResNET50v2 model and feature dimension was reduced through feature reduction methods. Feature fusion of feature sets reduced through analysis of variance (ANOVA) and mutual information feature selection (MIFS) was fed to Fine K-nearest neighbour to perform binary classification. Similarly, serial feature fusion of MIFS and chi-square features were utilized to train Medium Gaussian Support Vector Machines to distinguish normal, COVID-19 and viral pneumonia cases. The proposed framework yielded accuracies of 99.5% for binary and 95.5% for triple class experiments. The proposed model shows better performance than the existing methods, and this research has the potential to assist medical professionals to enhance the diagnostic ability to detect coronavirus disease.},
  archive      = {J_EXSY},
  author       = {Sumair Aziz and Muhammad Umar Khan and Abdul Rehman and Zain Tariq and Khushbakht Iqtidar},
  doi          = {10.1111/exsy.12919},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12919},
  shortjournal = {Expert Syst.},
  title        = {Computer-aided diagnosis of COVID-19 disease from chest X-ray images integrating deep feature extraction},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A lightweight intelligent intrusion detection system for
industrial internet of things using deep learning algorithms.
<em>EXSY</em>, <em>39</em>(5), e12917. (<a
href="https://doi.org/10.1111/exsy.12917">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the substantial industrial growth, the industrial internet of things (IIoT) and many IoT avenues have emerged. However, the existing industrial architectures are still inefficient to deal with advanced security issues due to the distributed and distensible nature of the network IIoT communication networks. Therefore, solutions for improving intelligent decision-making actions to the IIoT are sorely necessary. Thus, in this paper, the main cybersecurity attacks are predicted by applying a deep learning model. The various security and integrity features such as the DoS, malevolent operation, data type probing, spying, scanning, intrusion detection, brute force, web attacks, and wrong setup is analysed and detected by a novel sparse evolutionary training (SET) based prediction model. To scrutinize the conduct of the proposed SET-based prediction model, evaluation parameters, such as, precision, accuracy, recall, and F1 score are measured and compared to other state-of-the-art algorithms, in which the proposed SET-based model achieved an average accuracy of 0.99% for an average testing time of 2.29 ms. Results reveal that the proposed model improved the attack detection accuracy by an average of 6.25% when compared with the other state-of-the-art machine learning models in a real scenario of IoT security in Industry 4.0.},
  archive      = {J_EXSY},
  author       = {Robson V. Mendonça and Juan C. Silva and Renata L. Rosa and Muhammad Saadi and Demostenes Z. Rodriguez and Ahmed Farouk},
  doi          = {10.1111/exsy.12917},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12917},
  shortjournal = {Expert Syst.},
  title        = {A lightweight intelligent intrusion detection system for industrial internet of things using deep learning algorithms},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DFT: A deep feature-based semi-supervised collaborative
training for vehicle recognition in smart cities. <em>EXSY</em>,
<em>39</em>(5), e12916. (<a
href="https://doi.org/10.1111/exsy.12916">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent transport systems (ITS) is a popular field of research in smart city. Image-based vehicle recognition is one of the most promising new techniques. The traditional appearance-based method has some limitations in feature view. The machine learning algorithm can satisfy multiple feature views, but it mainly adopts an improved supervised learning method, which needs manual annotation and has low efficiency. The semi-supervised collaborative training method is widely used in the image recognition process to improve machine learning algorithms&#39; accuracy and generalization performance. This paper proposes DFT (deep feature-based training) method for vehicle recognition in smart cities. DFT is also a semi-supervised collaborative training method on basis of two base learners. DFT adjusts data pre-processing and training process, optimizes the constructing a disagreement encoding network, and expands the recognition disagreement of pseudo-labelled samples-based training set. Compared with the typical collaborative training methods, DFT greatly accelerates the model&#39;s training process by reducing the convergence time, and improves the efficiency of vehicle recognition, while remaining the recognition accuracy unchanged.},
  archive      = {J_EXSY},
  author       = {Yichuan Zhang and Yadi Liu and Guangming Yang and Jie Song},
  doi          = {10.1111/exsy.12916},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12916},
  shortjournal = {Expert Syst.},
  title        = {DFT: A deep feature-based semi-supervised collaborative training for vehicle recognition in smart cities},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Knowledge acquisition for 3D coordinates of target in
wireless sensor networks for smart city application. <em>EXSY</em>,
<em>39</em>(5), e12910. (<a
href="https://doi.org/10.1111/exsy.12910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In wireless sensor networks, non-linear distance information characterized by uncertainty and randomness creates the deviation and significantly target nodes position is affected. Non-linearity effect among distance and received signal strength (RSS) of target nodes is minimized by modelling edge weights using knowledge base in fuzzy logic system. Further, optimum membership functions bases&#39; of RSS and edge weights using application of butterfly optimization algorithm are evolved to minimize the node position error. Here, a single anchor node is used to estimate target nodes 3D coordinates in anisotropic environment using range free localization methods. The anchor node has been deployed at top layer and over beneath layers target nodes are distributed equally. In This paper, simulation results of the proposed method attain substantial performance improvement in target node 3D position accuracy than the earlier proposed range-free methods. Proposed technique is useful for mapping of several instances like, fire hazards in forests, tracking of workers at different installation sites, solar plant tracking in smart cities and so forth.},
  archive      = {J_EXSY},
  author       = {Himanshu and Rajesh Khanna and Anil Kumar},
  doi          = {10.1111/exsy.12910},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12910},
  shortjournal = {Expert Syst.},
  title        = {Knowledge acquisition for 3D coordinates of target in wireless sensor networks for smart city application},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CPP: A content-aware privacy protection method for
location-based service. <em>EXSY</em>, <em>39</em>(5), e12907. (<a
href="https://doi.org/10.1111/exsy.12907">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generally, a location-based service (LBS) often contains the location attribute, content attribute, time-stamp, and range. From the perspective of privacy protection, the location attribute and the content attribute are the key attributes and need to be protected. However, existing privacy protection methods focus excessively on the location attribute and ignore the content attribute contained in the LBS, which discloses the user&#39;s private information. In view of this challenge, a content-aware privacy protection method, called the CPP method that considers the content attribute is proposed. Specifically, the CPP method is based on using k-anonymity to generate dummy content attributes to protect the private content. As is shown in an experiment constructed on real-world data, the CPP method can indeed improve the effect of privacy protection.},
  archive      = {J_EXSY},
  author       = {Jiabang Liu and Xutong Jiang and Song Zhang and Bowen Liu and Wanchun Dou},
  doi          = {10.1111/exsy.12907},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12907},
  shortjournal = {Expert Syst.},
  title        = {CPP: A content-aware privacy protection method for location-based service},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Energy-efficient routing paradigm for resource-constrained
internet of things-based cognitive smart city. <em>EXSY</em>,
<em>39</em>(5), e12905. (<a
href="https://doi.org/10.1111/exsy.12905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential growth in the smart cities and the massive deployment of wireless sensor network-based Internet of Things (IoT) has resulted in generating the humongous data, which needs to be orchestrated. Further, it is observed that the resource-constrained IoT devices act as stumbling block in the successful realization of cognitive smart cities. Hence, there is a high need to manage the data transmission from massive IoT devices and also to enhance the productivity of such devices. To address this issue, in this article, we present energy-efficient routing paradigm for resource-constrained IoT-based cognitive smart city (EI-CSC). We adapt Sooty tern optimization algorithm (STOA) due to its faster convergence and high ‘exploration and exploitation’ capabilities to perform energy efficient cluster-based routing. We focus primarily on rendering the optimized solution to the cluster head selection problem through STOA. The outcomes of simulation analysis of EI-CSC promises enhanced performance in the context of stability period and network lifetime by 83.4% and 107.7%, ‘respectively’ as compared to recently proposed ‘genetic algorithm and PSO based hybrid clustering algorithm’.},
  archive      = {J_EXSY},
  author       = {Sandeep Verma},
  doi          = {10.1111/exsy.12905},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12905},
  shortjournal = {Expert Syst.},
  title        = {Energy-efficient routing paradigm for resource-constrained internet of things-based cognitive smart city},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Internet of things-based deeply proficient monitoring and
protection system for crop field. <em>EXSY</em>, <em>39</em>(5), e12876.
(<a href="https://doi.org/10.1111/exsy.12876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The production rate of crops is significantly declining due to natural disasters, animal interventions and plant diseases. Internet of things (IoT) and wireless sensor networks are widely applied in crop field monitoring systems to observe the quality of each plant and the field. This work proposes IoT based crop field protection system (ICFPS) that monitors and protects the crop fields from animal intrusions. This proposed system uses ultrasonic sensors, hyperspectral cameras, voice recorded buzzers and other agriculture sensors to protect the entire crop field. This system uses numerous sensor nodes and cameras for gathering field objects (images and environmental objects). The proposed ICFPS creates deep learning techniques such as recurrent convolutional neural networks (RCNN) and recurrent generative adversarial neural networks (RGAN) for feature extraction, disease detection and field data monitoring practices. This proposed work develops a smart city-based agriculture system using cognitive learning approaches. This proposed system analyses crop field data and provide automatic alerts regarding animal interferences and crop diseases. Moreover, the cognitive smart crop field system observes various field conditions which support for good production rate. In this system, sensors and camera-enabled agriculture drones are coordinated with each other to collect the field data regularly. At the same time, the proposed work trains the RCNN and RGAN units using effective crop field datasets to attain realistic decisions within minimal time intervals. The experiment details and results show the proposed ICFPS works with 8%–10% of more classification accuracy than existing systems.},
  archive      = {J_EXSY},
  author       = {A. V. Prabu and G. Sateesh Kumar and Soundararajan Rajasoundaran and Prince Priya Malla and Sidheswar Routray and Amrit Mukherjee},
  doi          = {10.1111/exsy.12876},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12876},
  shortjournal = {Expert Syst.},
  title        = {Internet of things-based deeply proficient monitoring and protection system for crop field},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sensor data fusion for the industrial artificial
intelligence of things. <em>EXSY</em>, <em>39</em>(5), e12875. (<a
href="https://doi.org/10.1111/exsy.12875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of smart sensors, artificial intelligence, and deep learning technologies yield artificial intelligence of things, also known as the AIoT. Sophisticated cooperation of these technologies is vital for the effective processing of industrial sensor data. This paper introduces a new framework for addressing the different challenges of the AIoT applications. The proposed framework is an intelligent combination of multi-agent systems, knowledge graphs and deep learning. Deep learning architectures are used to create models from different sensor-based data. Multi-agent systems can be used for simulating the collective behaviours of the smart sensors using IoT settings. The communication among different agents is realized by integrating knowledge graphs. Different optimizations based on constraint satisfaction as well as evolutionary computation are also investigated. Experimental analysis is undertaken to compare the methodology presented to state-of-the-art AIoT technologies. We show through experimentation that our designed framework achieves good performance compared to baseline solutions.},
  archive      = {J_EXSY},
  author       = {Youcef Djenouri and Asma Belhadi and Gautam Srivastava and Essam H. Houssein and Jerry Chun-Wei Lin},
  doi          = {10.1111/exsy.12875},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12875},
  shortjournal = {Expert Syst.},
  title        = {Sensor data fusion for the industrial artificial intelligence of things},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Internet of things and machine learning-based approaches in
the urban solid waste management: Trends, challenges, and future
directions. <em>EXSY</em>, <em>39</em>(5), e12865. (<a
href="https://doi.org/10.1111/exsy.12865">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solid waste management (SWM) is a crucial management entity in urban cities to handle the waste from its generation to disposal to accomplish a clean environment. The waste management operation mainly encompasses various climatic, demographic, environmental, legislative, technological, and socioeconomic dimensions. The traditional approaches deliver limitations in the process of predict and optimizing such composite non-linear operations. The integration of the internet of things (IoT) and artificial intelligence (AI) methods have progressively gained attention by delivering potential alternatives for resolving the difficulties in SWM. This article presents a review of the significance of the amalgamation of IoT and machine learning (ML) in the SWM to predict waste generation, waste classification, route optimization, estimation of methane emissions, and so forth. The article covers the application of each ML model for the activities, including SWM, compositing, incineration, pyrolysis, gasification, landfill, and anaerobic digestion. Moreover, it is concluded that the decision tree and random forest (DT-RF) algorithm is minor implemented, and artificial neural network (ANN) is implemented majorly in the SWM. The large number of data sets covered in the publication are secured and hidden; it limits replicating the AI models; this is also one key constraint of the non-implementation of AI models in SWM. Scarcity of data, accurate data, rare availability of customized AI models for tackling the activities in SWM are the limitations identified from the previous studies. Implementation of low-power ML processors, edge and fog computing-based devices is the future direction for overcoming SWM limitations.},
  archive      = {J_EXSY},
  author       = {Lalit Mohan Joshi and Rajendra Kumar Bharti and Rajesh Singh},
  doi          = {10.1111/exsy.12865},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12865},
  shortjournal = {Expert Syst.},
  title        = {Internet of things and machine learning-based approaches in the urban solid waste management: Trends, challenges, and future directions},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A formal method for privacy-preservation in cognitive smart
cities. <em>EXSY</em>, <em>39</em>(5), e12855. (<a
href="https://doi.org/10.1111/exsy.12855">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of things (IoT) and communication technologies are enabling the consumer to use the smart devices. The explosion of smart devices is shifting the IoT into a framework, which we call the cognitive IoT. The cognitive IoT can enhance many sectors such as smart cities, healthcare, industry 4.0, transportation, just to name a few. Most of the data produced in smart cities are wasted because the important information is not extracted due to lack of standard mechanism for knowledge extraction and archiving methods. This has attracted the attention of researcher to design new approaches of machine and cognitive learning that can handle vast amount of dynamic data. The cognitive smart city is the integration of IoT, smart city technology, real-time big data analytics and artificial intelligence (AI) strategies for proactive actions. The services in smart cities relies on the collection and analysis of the data which are provided by the use themselves or accessed by the services providers. The citizen engagement is the key for success of smart city; however, the engagement may get reduced due to privacy concerns arising from data collection. Therefore, privacy-preservation shall be achieved in a manner where valuable data is exchanged with service provider, and other third party while protecting the citizens&#39; privacy, upholding data laws and enforcement. Therefore, there is a need to control the anonymization and mix some more techniques to preserve the quality of the data. The proposed formal method for privacy-preservation in smart cities is based on pseudonymization, clustering, anonymization and differential privacy methods. The modified clustering algorithm selects the initial cluster based on the concept of dissimilarity between the data sequences. We have assessed the functional correctness and preformation of the proposed model for privacy-preservation in smart cities. The proposed method has lower discriminating rate as compared to other existing methods.},
  archive      = {J_EXSY},
  author       = {Mohammad Ayoub Khan},
  doi          = {10.1111/exsy.12855},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12855},
  shortjournal = {Expert Syst.},
  title        = {A formal method for privacy-preservation in cognitive smart cities},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine learning-based model for prediction of power
consumption in smart grid- smart way towards smart city. <em>EXSY</em>,
<em>39</em>(5), e12832. (<a
href="https://doi.org/10.1111/exsy.12832">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A smart city is an idea that is realized by the computing of a large amount of data collected through sensors, cameras, and other electronic methods to provide services, manage resources and solve daily life problems. The transformation of the conventional grid to a smart grid is one step in the direction towards smart city realization. An electric grid is composed of control stations, generation centres, transformers, communication lines, and distributors, which helps in transferring power from the power station to domestic and commercial consumers. Present electric grids are not smart enough that they can estimate the varying power requirement of the consumer. Also, these conventional grids are not enough robust and scalable. This has become the motivation for shifting from a conventional grid to a smart grid. The smart grid is a kind of power grid, which is robust and adapts itself to the varying needs of the consumer and self-healing in nature. In this way, the transformation from a conventional grid to a smart grid will help the government to make a smart city. The emergence of machine learning has helped in the prediction of the stability of the grid under the dynamically changing requirement of the consumer. Also, the usage of a variety of sensors will help in the collection of real-time consumption data. Through machine learning algorithms, we can gain an insight view of the collected data. This has helped the smart grid to convert into a robust smart grid, as this will help in avoiding the situation of failure. In this work, the authors have applied logistic regression, decision tree, support vector machine, linear discriminant analysis, quadratic discriminant analysis, naïve Bayes, random forest, and k-nearest neighbour algorithms to predict the stability of the grid. The authors have used the smart grid stability dataset freely available on Kaggle to train and test the models. It has been found that a model designed using the support vector machine algorithm has given the most accurate result.},
  archive      = {J_EXSY},
  author       = {Shamik Tiwari and Anurag Jain and Nada Mohamed Osman Sid Ahmed and Charu and Lulwah M. Alkwai and Alaa Kamal Yousif Dafhalla and Sawsan Ali Saad Hamad},
  doi          = {10.1111/exsy.12832},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12832},
  shortjournal = {Expert Syst.},
  title        = {Machine learning-based model for prediction of power consumption in smart grid- smart way towards smart city},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). IVQFIoT: An intelligent vulnerability quantification
framework for scoring internet of things vulnerabilities. <em>EXSY</em>,
<em>39</em>(5), e12829. (<a
href="https://doi.org/10.1111/exsy.12829">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With time smart services have become more domineering than ever before however, the pertinent security considerations fade to correspond with growing heterogeneity in the internet of things (IoT) devices and new technologies coupled with resource constraints, crafting IoT-based systems more susceptible to cyber-attacks. To ensure a secure IoT environment, pro-active security mechanisms, like scanning vulnerabilities and prioritizing to remediate them timely, should be embedded in the system. Motivated by the facts, we in this paper, highlight the state of the art of several works trading with a common vulnerability scoring system (CVSS), its limitations, and the emendations recommended to conclude its maturity. CVSS is an industry standard that has been adopted worldwide to quantify the vulnerabilities in organizations for IT and IoT-based systems. The vulnerabilities mathematical score coalesces with environmental knowledge for finding attack paths and apt score for prioritization. The specific functionality and exclusive dynamics of IoT and cyber-physical systems in comparison to traditional computer networks, make the legacy cyber-security exemplars unfit for these advanced networks. This paper studies the relevance of CVSS for smart systems and present an intelligent vulnerability quantification framework for IoT systems grounded on the CVSS v3.1 framework with threat intelligence and machine learning models. Further by applying blockchain technology in the proposed framework, the issues concerning security, lack of trust, and privacy possibly will resolve by hiring a smart contract.},
  archive      = {J_EXSY},
  author       = {Pooja Anand and Yashwant Singh and Arvind Selwal and Pradeep Kumar Singh and Kayhan Zrar Ghafoor},
  doi          = {10.1111/exsy.12829},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12829},
  shortjournal = {Expert Syst.},
  title        = {IVQFIoT: An intelligent vulnerability quantification framework for scoring internet of things vulnerabilities},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Seamless connectivity with 5G enabled unmanned aerial
vehicles base stations using machine programming approach.
<em>EXSY</em>, <em>39</em>(5), e12828. (<a
href="https://doi.org/10.1111/exsy.12828">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deployment of a small unmanned aerial vehicle (UAV) mounted 5G base station is a promising solution for providing seamless network connectivity to users in a modern, data-centric thrust areas. The key challenge is to find the location, the height and the optimum number of mounts. A machine programming based approach is proposed here for optimal placement of UAV-mounted base station. The location of the deployment is determined using three clustering algorithms such as K -means, K -medoids, and fuzzy cluster means. Different sets of UAV-mounted base stations have been deployed with variable user density at different heights. The impact on the network performance has been quantified through measurements of received power, signal to interference plus noise ratio (SINR), and path loss per active user equipment (UEs). To gain further insights, a scenario where UEs are connected only to the terrestrial base station, that is, the network is devoid of any sort of UAV mounted base station is evaluated. Numerical computations reaffirm that the proposed technique reduces the average path loss of the active UEs. Moreover, the use of height-mounted base station also alleviates the issues arising due to low SINR values. The said technique shows immense potential in terms of seamless connectivity to end users in events of emergency and remote deployment scenarios, where ground-based base station is not possible. The big transition of on- demand connectivity for 5G networks shall be benefitted from purpose-built UAV infrastructure with specific locations or areas in mind.},
  archive      = {J_EXSY},
  author       = {Dilip Mandloi and Rajeev Arya},
  doi          = {10.1111/exsy.12828},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12828},
  shortjournal = {Expert Syst.},
  title        = {Seamless connectivity with 5G enabled unmanned aerial vehicles base stations using machine programming approach},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning-influenced joint vehicle-to-infrastructure and
vehicle-to-vehicle communication approach for internet of vehicles.
<em>EXSY</em>, <em>39</em>(5), e12815. (<a
href="https://doi.org/10.1111/exsy.12815">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The internet of vehicle (IoV) orchestration is an emerging technology in heterogeneous vehicles to contrivance diverse intelligent transportation applications. The roadside unit (RSU) plays a vital role during service provisioning. Vehicle-to-vehicle and vehicle-to-infrastructure communications have consistently accomplished the services in a vehicular network. However, persisting the increased vehicles&#39; quality of experience and network vendors&#39; utilities and which RSUs have to select for effective, reliable service are critical open research challenges to consolidate RSU services to enhance network service utility rate. In this article, we design a deep learning-inspired RSU Service Consolidation Approach based on two-models to enhance the service reliability by formulating the RSU coverage issue with the RSU Migration model and content delivery issue with Linear Programming-based Multicast model. Adaptive Packet-Error measurement system to optimize service reliability rate at the edge of cooperative vehicular network based on content correlation. The performance and efficiency are examined based on MATLAB. The simulation outcome shows RSC approach has low execution cost by 39%, service reliability rate by 71% than the state-of-art approaches.},
  archive      = {J_EXSY},
  author       = {M. S. Mekala and Gaurav Dhiman and Rizwan Patan and Suresh Kallam and Kadiyala Ramana and Kusum Yadav and Ali O. Alharbi},
  doi          = {10.1111/exsy.12815},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12815},
  shortjournal = {Expert Syst.},
  title        = {Deep learning-influenced joint vehicle-to-infrastructure and vehicle-to-vehicle communication approach for internet of vehicles},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Smart user experience medical app interface design based on
mobile devices. <em>EXSY</em>, <em>39</em>(5), e12808. (<a
href="https://doi.org/10.1111/exsy.12808">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the improvement of people&#39;s living standards, the characteristics of people&#39;s consumption needs changing from material to spiritual are very obvious, and the focus is now on the importance of health awareness. However, current medical resources are limited and scattered, and medical needs cannot be met. In order to solve these problems, the research of medical application (APP) for mobile devices is of great significance. In order to improve the usability of medical apps and reduce the difficulty of operation, this article mainly introduces the interface design of the smart user experience medical apps based on mobile devices. This article conducts APP page management through technical analysis of mobile devices and user experience-oriented design. The framework design of the browser and the construction of the interface Model-View-Controller (MVC) design mode, and then through the questionnaire survey method to the user experience needs and expectations of the medical APP to design the main key of the page function. Finally, a smart user experience medical APP interface was designed. The practicability is as high as 90%, and the operation simplification is as high as 80%.},
  archive      = {J_EXSY},
  author       = {Qi Zhang and Yishu Liu},
  doi          = {10.1111/exsy.12808},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12808},
  shortjournal = {Expert Syst.},
  title        = {Smart user experience medical app interface design based on mobile devices},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Environmental sound classification using convolution neural
networks with different integrated loss functions. <em>EXSY</em>,
<em>39</em>(5), e12804. (<a
href="https://doi.org/10.1111/exsy.12804">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hike in the demand for smart cities has gathered the interest of researchers to work on environmental sound classification. Most researchers&#39; goal is to reach the Bayesian optimal error in the field of audio classification. Nonetheless, it is very baffling to interpret meaning from a three-dimensional audio and this is where different types of spectrograms become effective. Using benchmark spectral features such as mel frequency cepstral coefficients (MFCCs), chromagram, log-mel spectrogram (LM), and so on audio can be converted into meaningful 2D spectrograms. In this paper, we propose a convolutional neural network (CNN) model, which is fabricated with additive angular margin loss (AAML), large margin cosine loss (LMCL) and a-softmax loss. These loss functions proposed for face recognition, hold their value in the other fields of study if they are implemented in a systematic manner. The mentioned loss functions are more dominant than conventional softmax loss when it comes to classification task because of its capability to increase intra-class compactness and inter-class discrepancy. Thus, with MCAAM-Net, MCAS-Net and MCLCM-Net models, a classification accuracy of 99.60%, 99.43% and 99.37% is achieved on UrbanSound8K dataset respectively without any augmentation. This paper also demonstrates the benefit of stacking features together and the above-mentioned validation accuracies are achieved after stacking MFCCs and chromagram on the x -axis. We also visualized the clusters formed by the embedded vectors of test data for further acknowledgement of our results, after passing it through different proposed models. Finally, we show that the MCAAM-Net model achieved an accuracy of 99.60% on UrbanSound8K dataset, which outperforms the benchmark models like TSCNN-DS, ADCNN-5, ESResNet-Attention, and so on that are introduced over the recent years.},
  archive      = {J_EXSY},
  author       = {Joy Krishan Das and Amitabha Chakrabarty and Md. Jalil Piran},
  doi          = {10.1111/exsy.12804},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12804},
  shortjournal = {Expert Syst.},
  title        = {Environmental sound classification using convolution neural networks with different integrated loss functions},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LEOBAT: Lightweight encryption and OTP based authentication
technique for securing IoT networks. <em>EXSY</em>, <em>39</em>(5),
e12788. (<a href="https://doi.org/10.1111/exsy.12788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Authentication is one of the foremost pillars in the Internet of Things (IoT) security that authenticates the identity of a device or a person with the help of a unique identification number. If authentication is compromised then an intruder can gain access and launch a variety of attacks on the network. The world of IoT devices is benefiting us in many ways, but the vulnerability of becoming a victim of cybercrime is also increasing at a rapid pace. This research paper proposes an authentication-based solution for designing a secure communication network to ensure safe access to data and stop attackers from any unauthorized access to various IoT applications using cryptography and cloud computing. The proposed work is then compared with other popular cryptosystems such as Secure Internet of Things (SIT), Data Encryption Standard (DES) and Blowfish. LEOBAT is simulated using MATLAB and proves to be a fast and efficient authentication technique.},
  archive      = {J_EXSY},
  author       = {Aarti Goel and Deepak Kumar Sharma and Koyel Datta Gupta},
  doi          = {10.1111/exsy.12788},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12788},
  shortjournal = {Expert Syst.},
  title        = {LEOBAT: Lightweight encryption and OTP based authentication technique for securing IoT networks},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Effective implementation of machine learning algorithms
using 3D colour texture feature for traffic sign detection for smart
cities. <em>EXSY</em>, <em>39</em>(5), e12781. (<a
href="https://doi.org/10.1111/exsy.12781">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent past, emerging technology, such as AI has revolutionized progress and advancement of traffic management solutions in context of smart cities. This paper describes a novel approach of using 3D colour-texture based feature for image detection on public datasets of Chinese traffic sign research database (TSRD) and Mapillary image database. The implementation of 3D colour texture feature for traffic sign detection is evaluated using artificial neural network and multiple other machine learning algorithms as classifier for image detection purposes. Both datasets used in our experiments are considered among most diverse traffic signage datasets globally with annotations of almost all classes. Image datasets have been publicly made available to researchers for academic purposes. For classification of traffic sign images on Chinese TSRD and Mapillary datasets, the result outcome from back-propagation neural network (NN) classifier outperforms all other and produced best results and under multiple ML algorithms, support vector machines (SVM) cubic has best results. For classification of traffic sign images on Mapillary dataset, the result outcome from rational quadratic Gaussian process regression has best results. Also, the comparisons of results with other similar novel works have also been discussed. The proposed approach outperformed the previous experiments as observed through comparative analysis performed on both datasets. The conclusion of the research work highlights that the image detection performance is noticeably improved by using the combined 3D colour-texture feature based proposed approach.},
  archive      = {J_EXSY},
  author       = {Manisha Vashisht and Brijesh Kumar},
  doi          = {10.1111/exsy.12781},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12781},
  shortjournal = {Expert Syst.},
  title        = {Effective implementation of machine learning algorithms using 3D colour texture feature for traffic sign detection for smart cities},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A supervised learning model to identify the star potential
of a basketball player. <em>EXSY</em>, <em>39</em>(5), e12772. (<a
href="https://doi.org/10.1111/exsy.12772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Basketball is a mathematical game with many abstract data interpretations. An average fan ceases to witness the revolution in sports, which is influenced using data science and analytics unless someone brings it to light. Nowadays, teams look at data and tend to make decisions on scouting the player for the team. The decision making for the coaches can be made easier using machine learning algorithms to identify the star potential of players. The paper provides a novel algorithm by building a machine learning model on all players to predict whether the player is a star or not. Besides, an interactive user interface is developed for coaches to input the player&#39;s data and to make an informed decision based on the prediction.},
  archive      = {J_EXSY},
  author       = {Ram Srinivasan and Venki Balasubramanian and Abhishek Vidyasagar},
  doi          = {10.1111/exsy.12772},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12772},
  shortjournal = {Expert Syst.},
  title        = {A supervised learning model to identify the star potential of a basketball player},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Diagnosis of infectious factors in patients with chronic
glomerular disease using deep learning-based health information data.
<em>EXSY</em>, <em>39</em>(5), e12771. (<a
href="https://doi.org/10.1111/exsy.12771">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study was aimed to explore the effect of information health data based on deep learning of neural network to diagnose the infectious factors of patients with chronic glomerular disease (CGD) and evaluate its diagnostic effect. Ninety patients with CGD were selected and randomly rolled into control group A, control group B, and observation group, with 30 cases in each group. Big data scientific research analysis platform was used for data integration, convolutional neural network (CNN) was employed for feature analysis, correlation analysis, and screening of disease-related biomarkers. The patients were diagnosed by observation of symptoms and signs, combined diagnosis of blood test and urine test, and information health data diagnosis based on deep learning CNN. As a result, the specificity, sensitivity, and accuracy of information health data diagnosis based on deep learning CNN were 78.9%, 87.6%, and 92.1%, respectively. The main sources of infections in patients were lung infections, bloodstream infections, urinary system infections, skin and soft tissue infections, and upper respiratory tract infections. Amongst them, lung infection accounted for the highest proportion, reaching 65.4%, followed by blood infection (11.2%) and skin tissue infection (9.6%). The pathogens of infection were mainly bacteria, viruses, fungi, tuberculosis, and pneumocystis pneumonia (PCP), amongst which bacterial infections accounted for the highest proportion (31.5%), followed by PCP (25.6%). In short, the information health data based on deep learning CNN had high specificity, sensitivity, and accuracy for the diagnosis of CGD. The main infectious factors of CGD were pulmonary infection and blood infection, and the pathogens were mainly bacteria and viruses.},
  archive      = {J_EXSY},
  author       = {Canxin Zhou and Siqi Chen and Xinhan Li and Xuxia Ying},
  doi          = {10.1111/exsy.12771},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12771},
  shortjournal = {Expert Syst.},
  title        = {Diagnosis of infectious factors in patients with chronic glomerular disease using deep learning-based health information data},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A fully homomorphic encryption based on magic number
fragmentation and el-gamal encryption: Smart healthcare use case.
<em>EXSY</em>, <em>39</em>(5), e12767. (<a
href="https://doi.org/10.1111/exsy.12767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, cloud computing offers a digital infrastructure for smart city development. Cognitive cities are steadily automating daily urban processes. The ever expanding objective-driven communities gather and share sensitive data that must be stored securely. Cloud computing offers a suitable platform that allows cognitive smart cities to access and re-access data to learn from their past to adapt its current behaviour. However, the cloud is an untrusted entity that may expose data when decrypted for processing by systems. In this paper, we treat the issue of encrypted data processing. Often, the data is encrypted prior to transferring it to the cloud, where the cloud must have the data in clear to be able to make calculations which raises security and privacy threats if the cloud is considered untrusted. The scenario of asking users to make the calculations after decrypting the received cloud data and encrypting the obtained results before sending them back to the cloud is not a practical solution in distributed multi-tenant architectures. Homomorphic encryption allows offers a solution for processing encrypted data. Many existing homomorphic encryption schemes suffer from limitations that hinder their usability. This paper presents an efficient fully homomorphic encryption scheme using twin key encryption and magic number fragmentation. The details of the scheme are presented along with cryptanalytic attacks to assess its effectiveness. The proposed scheme exhibits strong resilience against brute-force attacks compared to its rivals from the literature. Finally, we illustrate the applicability of the proposed scheme using a cognitive smart city application.},
  archive      = {J_EXSY},
  author       = {Mostefa Kara and Abdelkader Laouid and Mohammed Amine Yagoub and Reinhardt Euler and Saci Medileh and Mohammad Hammoudeh and Amna Eleyan and Ahcène Bounceur},
  doi          = {10.1111/exsy.12767},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12767},
  shortjournal = {Expert Syst.},
  title        = {A fully homomorphic encryption based on magic number fragmentation and el-gamal encryption: Smart healthcare use case},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Soft computing for abuse detection using cyber-physical and
social big data in cognitive smart cities. <em>EXSY</em>,
<em>39</em>(5), e12766. (<a
href="https://doi.org/10.1111/exsy.12766">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The internet of things (IoT) and the smart city crusade has seen an exponential increase in the number of data points we collect. Cities can use this data for an exceedingly heterogeneous range of purposes such as traffic, parking and public safety. Quite evidently, public safety is an essential pillar of these interconnected, instrumented and intelligent cities. The big data from cyber-physical systems and social media platforms can be used for predictive policing to identify potential criminal activities, abuse, offenders, and victims of abuse. This study offers a systematic literature review on the use of soft computing techniques for abuse detection in the complex cyber–physical–social big data systems in cognitive smart cities. The objective is to define and identify the diverse concept of abuse and systematize techniques for automatic abuse detection for cyber abuse detection on social media and real-time abuse detection using IoT. The cyber abuse studies on social media platforms have further been categorized as cyber-hate and cyberbullying whereas the real-time abuse includes studies using Internet of cyber-physical systems. As in a cognitive smart city, citizens expect more from their urban environments with minimal intervention, this study helps to establish the need to capture situational context and awareness in real-time and foster the need to develop a proactive as well as reactive safety mechanism to mitigate the risks of online abuse. The need of the hour is to entrench self-learning, thinking and understanding capabilities into the physical and social world for reinforcing intelligent mechanisms which can detect assaults and disorderly conduct.},
  archive      = {J_EXSY},
  author       = {Saurabh Raj Sangwan and Mohinder Pal Singh Bhatia},
  doi          = {10.1111/exsy.12766},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12766},
  shortjournal = {Expert Syst.},
  title        = {Soft computing for abuse detection using cyber-physical and social big data in cognitive smart cities},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Anomaly detection in autonomous electric vehicles using AI
techniques: A comprehensive survey. <em>EXSY</em>, <em>39</em>(5),
e12754. (<a href="https://doi.org/10.1111/exsy.12754">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The next wave in smart transportation is directed towards the design of renewable energy sources that can fuel automobile sector to shift towards the autonomous electric vehicles (AEVs). AEVs are sensor-driven and driverless that uses artificial intelligence (AI)-based interactions in Internet-of-vehicles (IoV) ecosystems. AEVs can reduce carbon footprints and trade energy with peer AEVs, smart grids (SG), and roadside units (RSUs). It supports green transportation vision. However, the sensor information, energy units, and user data are exchanged through open channels, and thus, are susceptible to various security and privacy attacks. Thus, AEVs can be remotely operated and directed by malicious entities that can propagate false updates to the peer nodes in IoV environment. This can cause the failure of components, congestion, as well as the entire disruption of IoV network. Globally researchers and security analysts have addressed solutions that pertain to specific security requirements, but still, the detection and classification of malicious AEVs is a widely studied topic. Malicious AEVs exhibit an anomaly behavior that differentiates them from normal AEVs, and thereby, the detection of anomalous AEVs and classification of anomaly type is required. Motivated from the aforementioned facts, the survey presents a systematic outlook of AI techniques in anomaly detection of AEVs. A solution taxonomy is proposed based on research gaps in the existing surveys, and the evaluation metrics for AI-based anomaly detection are discussed. The open challenges and issues in AI deployments are discussed and a case study is presented on anomaly classification through a weighted ensemble technique. Thus, the proposed survey is designed to guide the manufacturing industry, AI practitioners, and researchers worldwide to formulate and design accurate and precise mechanisms to detect anomalies.},
  archive      = {J_EXSY},
  author       = {Palak Dixit and Pronaya Bhattacharya and Sudeep Tanwar and Rajesh Gupta},
  doi          = {10.1111/exsy.12754},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12754},
  shortjournal = {Expert Syst.},
  title        = {Anomaly detection in autonomous electric vehicles using AI techniques: A comprehensive survey},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Conceptualizing smart city applications: Requirements,
architecture, security issues, and emerging trends. <em>EXSY</em>,
<em>39</em>(5), e12753. (<a
href="https://doi.org/10.1111/exsy.12753">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of smart cities and sustainable development has become a globally accepted form of urbanization. The epitome of smart city development has become possible due to the latest innovative integration of information and communication technology. Citizens of smart cities can enjoy the benefits of a smart living environment, ubiquitous connectivity, seamless access to services, intelligent decision making through smart governance, and optimized resource management. The widespread acceptance of smart cities has raised data security issues, authentication, unauthorized access, device-level vulnerability, and sustainability. This article focuses on the holistic overview and conceptual development of smart city. Initially, the work discusses the smart city idea and fundamentals explored in various pieces of literature. Further various smart city applications along with notable implementations, are put forth to understand the quality of living standards. Finally, the article depicts a solid understanding of different security and privacy issues, including some crucial future research directions.},
  archive      = {J_EXSY},
  author       = {A. K. M. Bahalul Haque and Bharat Bhushan and Gaurav Dhiman},
  doi          = {10.1111/exsy.12753},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12753},
  shortjournal = {Expert Syst.},
  title        = {Conceptualizing smart city applications: Requirements, architecture, security issues, and emerging trends},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Big data analytics with oppositional moth flame optimization
based vehicular routing protocol for future smart cities. <em>EXSY</em>,
<em>39</em>(5), e12718. (<a
href="https://doi.org/10.1111/exsy.12718">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presently, smart city is designed to enhance the quality of life in city, fulfil the safety of the people, safe travelling, etc. Besides, big data has attracted significant attention among researchers in different fields as a large amount of data is being produced with diverse day-to-day applications. Besides, Vehicular adhoc network (VANET) is a kind of mobile adhoc network (MANET) that considers the vehicles as the nodes in a network. Since the VANET generates large amount of data, big data analytics can be used to gain meaningful understanding for improving the traffic management process such as planning, engineering, and operations. This paper designs a Big Data Analytics with Oppositional Moth Flame Optimization based Vehicular Routing Protocol for Future Smart Cities. The presented model maps the features of VANET with the attributes of the big data. In addition, oppositional moth flame optimization based vehicular routing (OMFOVR) technique is developed for VANET over the Hadoop Map Reduce standalone distributed framework. For validating the effectual performance of the proposed OMFOVR technique, a series of experiments were performed and the results are compared with the conventional NetBeans IDE platform. The experimental values showcased the betterment of the OMFOVR technique on the selection of routes over the compared methods.},
  archive      = {J_EXSY},
  author       = {Nojood O. Aljehane and Romany F. Mansour},
  doi          = {10.1111/exsy.12718},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12718},
  shortjournal = {Expert Syst.},
  title        = {Big data analytics with oppositional moth flame optimization based vehicular routing protocol for future smart cities},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A taxonomy of energy optimization techniques for smart
cities: Architecture and future directions. <em>EXSY</em>,
<em>39</em>(5), e12703. (<a
href="https://doi.org/10.1111/exsy.12703">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a drastic increase in urbanization over the past few years, which requires energy-efficient and optimized solutions for transportation, governance, quality of life in a smart city among all the citizens. The Internet-of-Energy (IoE) ecosystem offers many sophisticated and ubiquitous applications for smart cities. The energy demand of IoE applications is increased while IoE devices continue to grow. Therefore, smart city solutions must have the ability to utilize energy and handle the associated challenges efficiently. Moreover, energy Optimization (EO) techniques can be used to reduce energy consumption to meet the sustainability goals in IoE. Different techniques have been proposed for EO in various fields by researchers worldwide. Computing systems also need energy optimization. The energy consumption in the data center, clouds, and blockchain (BC)-based architectures are a point of concern at the current time. Due to the enormous energy demands of these systems, we cannot take advantage of the latest technologies to their fullest. Due to the emergence of new technologies and some limitations of proposed techniques, we can still not optimize energy usage more than some extent. There is minimal exploration done in energy optimization in BC-based systems. In this paper, we have proposed a survey on the energy optimization techniques in various systems, including the optimization techniques in BC-based systems. We have proposed a taxonomy that classifies energy optimization techniques. We have also proposed an energy-efficient consensus mechanism, Proof-of-High Performance optimization (named as PoHPo ), for High-Performance Computing (HPC) based ecosystems. The open issues and challenges are then discussed in EO. The survey intends to propose future directions for industry professionals, green-energy stakeholders, and researchers worldwide to explore this topic further.},
  archive      = {J_EXSY},
  author       = {Sudeep Tanwar and Aarti Popat and Pronaya Bhattacharya and Rajesh Gupta and Neeraj Kumar},
  doi          = {10.1111/exsy.12703},
  journal      = {Expert Systems},
  month        = {6},
  number       = {5},
  pages        = {e12703},
  shortjournal = {Expert Syst.},
  title        = {A taxonomy of energy optimization techniques for smart cities: Architecture and future directions},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). IWINAC’2019: Intelligent systems for cognitive training and
assessment. <em>EXSY</em>, <em>39</em>(4), e12965. (<a
href="https://doi.org/10.1111/exsy.12965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EXSY},
  author       = {Mariano Rincón Zamorano and Rafael Martínez Tomás and José Manuel Ferrández Vicente},
  doi          = {10.1111/exsy.12965},
  journal      = {Expert Systems},
  month        = {5},
  number       = {4},
  pages        = {e12965},
  shortjournal = {Expert Syst.},
  title        = {IWINAC&#39;2019: Intelligent systems for cognitive training and assessment},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automated test design using swarm and evolutionary
intelligence algorithms. <em>EXSY</em>, <em>39</em>(4), e12918. (<a
href="https://doi.org/10.1111/exsy.12918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The world&#39;s increasing dependence on computer-assisted education systems has raised significant challenges about student assessment methods, such as automated test design. The exam questions should test the students&#39; potential from various aspects, such as their intellectual and cognitive levels, which can be defined as attributes of the questions to assess student knowledge. Test design is challenging when various question attributes, such as category, learning outcomes, difficulty, and so forth, are considered with the exam constraints, such as exam difficulty and duration. In this paper, four contributions are provided to overcome test design challenges for the student assessment. First, a tool is developed to generate a synthetic question pool. Second, an objective function is designed based on the considered attributes. Third, the popular swarm and evolutionary optimization methods, namely particle swarm optimization, genetic algorithm, artificial bee colony, differential search algorithm are comparatively studied with novel methodologies applied to them. Finally, as the state of the art methods, artificial bee colony, and differential search algorithm are further modified to improve the solution of the test design. To perform the proposed algorithms, a dataset of 1000 questions is built with the proposed question attributes of the test design. Algorithms are evaluated in terms of their successes in both minimizing the objective function and running time. Additionally, Friedman&#39;s test and Wilcoxon rank-sum statistical tests are applied to statistically compare the algorithms&#39; performances. The results show that the improved artificial bee colony and the improved differential search provide better results than others in terms of optimization error and running time.},
  archive      = {J_EXSY},
  author       = {Muhammet Aktaş and Zeki Yetgin and Fatih Kılıç and Önder Sünbül},
  doi          = {10.1111/exsy.12918},
  journal      = {Expert Systems},
  month        = {5},
  number       = {4},
  pages        = {e12918},
  shortjournal = {Expert Syst.},
  title        = {Automated test design using swarm and evolutionary intelligence algorithms},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An efficient cardiovascular disease detection model based on
multilayer perceptron and moth-flame optimization. <em>EXSY</em>,
<em>39</em>(4), e12914. (<a
href="https://doi.org/10.1111/exsy.12914">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiovascular diseases are the leading cause of death in recent decades, which are increasing due to changes in people&#39;s lifestyles. Their treatment has high costs and a long treatment process. Therefore, predicting such diseases can provide care, and prevention services and treatment programs can be very useful to increase the quality of life and reduce the cost of treatment and the risk of death for patients. Various artificial neural network (ANN) techniques and machine learning (ML) algorithms can be used as efficient and reliable methods to automatically analyze and detect the hidden patterns of patient medical records data collected through medical examinations related to cardiovascular diseases. In this paper, the multilayer perceptron (MLP) neural network is employed as a supervised learning approach to detect cardiovascular diseases. Moreover, we propose a modified version of moth-flame optimization algorithm named as MMFO which is used to achieve the optimal values of weights and biases in the MLP to speed-up the training process and provide more accurate predictions. The effectiveness of the proposed method is assessed according to performing extensive experiments on three cardiovascular disease datasets from the UCI repository, and its performance is compared with different state-of-the-art classification approaches. The results reveal that the proposed method performs better than other models in terms of all medical datasets.},
  archive      = {J_EXSY},
  author       = {Sajad Ahmadian and Seyed Mohammad Jafar Jalali and Saeid Raziani and Abdolah Chalechale},
  doi          = {10.1111/exsy.12914},
  journal      = {Expert Systems},
  month        = {5},
  number       = {4},
  pages        = {e12914},
  shortjournal = {Expert Syst.},
  title        = {An efficient cardiovascular disease detection model based on multilayer perceptron and moth-flame optimization},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An improved chaotic ideal gas molecular movement algorithm
for engineering optimization problems. <em>EXSY</em>, <em>39</em>(4),
e12913. (<a href="https://doi.org/10.1111/exsy.12913">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the ideal gas molecular movement (IGMM) optimization algorithm was introduced by the authors. It is inspired by the movement and collision behaviour of the ideal gas molecules in an isolated medium. Although the IGMM could perform a high potential in determining the global optimum, improving its convergence behaviour came to the attention of the present investigation to deal with any type of especially highly nonlinear optimization problems. For that purpose, two actions took place hybridly. One was the simulation of the vibrational motion of gas molecules, especially at the early stages of the optimization process. The second simultaneous move concerned the non-repetitive nature of chaotic maps which could diversify the molecules, reduce the threat of premature convergence and improve the convergence speed of the IGMM algorithm. Therefore, this article investigates 10 different chaotic map functions and a random number generator along with four different Vibrational-based Chaotic IGMM (VCIGMM) strategies to still improve the speed of convergence. The results of applying the proposed algorithm to various numerical and engineering benchmark problems, intensely show that the chaotic maps, merged with vibrational motion of gas molecules, significantly improved the performance of the IGMM. It could considerably outperform some of the well-known meta-heuristic optimization algorithms in the literature.},
  archive      = {J_EXSY},
  author       = {Hesam Varaee and Mohammad Reza Ghasemi},
  doi          = {10.1111/exsy.12913},
  journal      = {Expert Systems},
  month        = {5},
  number       = {4},
  pages        = {e12913},
  shortjournal = {Expert Syst.},
  title        = {An improved chaotic ideal gas molecular movement algorithm for engineering optimization problems},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Balanced hierarchical max margin matrix factorization for
recommendation system. <em>EXSY</em>, <em>39</em>(4), e12911. (<a
href="https://doi.org/10.1111/exsy.12911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Matrix factorization (MF) is one of the most important regression analysis methods used in recommendation systems. Max margin matrix factorization (MMMF) is a variant of MF which transforms the regression analysis problem into a single multi-class classification problem, and then learns a multi-class max margin classifier to achieve to a better error rate. One drawback of multi-class MMMF is its bias towards class with small sample size. Therefore, hierarchical MMMF (HMF) which uses some two-class MMMF problems in a hierarchical manner for multi-class classification was proposed. Each two-class MMMF of HMF is learned on the basis of thresholded training data which is too imbalanced for some two-class MMMFs. Meanwhile, all training data is used in each two-class MMMF. In the test phase of HMF, an imbalanced tree is used to estimate rating. Each node of this tree is a learned two-class MMMF. In this paper, we propose a balanced HMF, which constructs a balanced tree with minimum depth. Each node of this tree is a learned two-class MMMF on the basis of a part of data which is selected such that to be more balanced than that of the traditional HMF. Moreover, each part of data in our proposed balanced HMF does not have overlap with all previous parts of data. Therefore, the overall training data used in each step of balanced HMF is smaller than that of in the traditional HMF. Experimental results on real datasets show that training time, test time and error rate of our proposed balanced HMF is better than those of the traditional HMF.},
  archive      = {J_EXSY},
  author       = {Mahdi Ravakhah and Mehrdad Jalali and Yahya Forghani and Reza Sheibani},
  doi          = {10.1111/exsy.12911},
  journal      = {Expert Systems},
  month        = {5},
  number       = {4},
  pages        = {e12911},
  shortjournal = {Expert Syst.},
  title        = {Balanced hierarchical max margin matrix factorization for recommendation system},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A semi-supervised network based on feature embeddings for
image classification. <em>EXSY</em>, <em>39</em>(4), e12908. (<a
href="https://doi.org/10.1111/exsy.12908">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning approaches, including convolutional neural networks, are suitable for image classification tasks with well-labelled data. Unfortunately, we do not always have sufficiently labelled data. Recent methods attempt to leverage labelled and unlabelled data using fine-tuning or transfer learning. However, these methods rely on low-level image features. This article departs from recent works and proposes a new semi-supervised learning network that constitutes a convolutional branch and a neighbour cluster branch. Also, we introduce a new loss function that carefully optimizes the network according to the labelled/unlabelled data. In this way, we reduce any tendency to rely on low-level features, which is the case in current methods. We use datasets from three different domains (hand-written digits, natural images, and objects) to analyse the performance of our method. Experimental analysis shows that the network performs better by learning inherent discrimination features when integrating unlabelled data into the model&#39;s training process. Our proposed approach also provides strong generalization in the context of transfer learning. Finally, this study shows that the proposed loss function optimizes the network to produce more efficient feature embeddings for domain adaptation.},
  archive      = {J_EXSY},
  author       = {Raphael Elimeli Nuhoho and Chen Wenyu and Adu Asare Baffour},
  doi          = {10.1111/exsy.12908},
  journal      = {Expert Systems},
  month        = {5},
  number       = {4},
  pages        = {e12908},
  shortjournal = {Expert Syst.},
  title        = {A semi-supervised network based on feature embeddings for image classification},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An ensemble artificial intelligence-enabled MIoT for
automated diagnosis of malaria parasite. <em>EXSY</em>, <em>39</em>(4),
e12906. (<a href="https://doi.org/10.1111/exsy.12906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid advancements in Information and Communication Technologies (ICT) and artificial intelligence (AI) applications permeating to all spheres of life, including medical prognosis, have led modern clinical systems to tread the path of advanced Internet of Medical Things (IoMT) by infusing advanced learning technologies, particularly deep learning. Automated diagnosis of malarial infection using AI-enabled IoMT holds the promise of sustainable prognosis by reducing diagnosis error significantly with improved recognition accuracy. Existing automated diagnostic systems usually employ classical deep learning models wherein setting parameter values such as automatic learning rate selection, weight management etc. are a major concern. To address these issues, this paper proposes a collaborative ensemble AI-enabled IoMT automated diagnosis model to classify malaria parasitized from microscopic images. The proposed model consists of two main stages. In the first stage, a Snapshot ensemble learning model is conjured upon by a combination of three distinct layers of Convolutional, Batch Normalization, and Relu networks; that alters the learning rate aggressively during training phase thus providing different network weights that gives multiple models by training a single model. In the second stage, an ensemble of three transfer learning models is constructed, and finally the average ensemble result is obtained. The learning rates at both these stages are empirically selected through Cosine Annealing. Experiment on the malaria parasite image dataset demonstrates the superiority of the proposed model with respect to a baseline algorithm.},
  archive      = {J_EXSY},
  author       = {Soumya Ranjan Nayak and Janmenjoy Nayak and S. Vimal and Vaibhav Arora and Utkarsh Sinha},
  doi          = {10.1111/exsy.12906},
  journal      = {Expert Systems},
  month        = {5},
  number       = {4},
  pages        = {e12906},
  shortjournal = {Expert Syst.},
  title        = {An ensemble artificial intelligence-enabled MIoT for automated diagnosis of malaria parasite},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). New entropy propositions for interval-valued spherical fuzzy
sets and their usage in an extension of ARAS (ARAS-IVSFS).
<em>EXSY</em>, <em>39</em>(4), e12898. (<a
href="https://doi.org/10.1111/exsy.12898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spherical fuzzy set (SFS) concept and its interval-valued version (IVSFS) are among the recent developments aiming at handling the hesitancy representation issue in multiple attribute decision-making problems. In SFS, decision-makers can assign independent membership, non-membership, and hesitancy degrees. IVSFS extends this feature by assigning intervals to these three degrees. In this manner, the uncertainty, vagueness, and ambiguity hidden in human judgements can be quantified and processed more comprehensively. In multiple attribute decision-making problems, the attribute weights are not commonly known. To determine these weights, there are two families of methods: subjective and objective ones. While subjective methods need expert judgements in weighting, objective methods can reveal the weights from the current dataset. Entropy-based weighting technique is one of the well-known objective methods. In the study, two IVSFS entropy expressions are introduced, and their practicality is presented in obtaining objective weights. Then, an IVSFS extension of Additive Ratio Assessment Method is proposed and integrated with the entropy-based weighting schema. The proposition is applied in solving a 3D printer selection problem and a comparative analysis is conducted to check its robustness and validity.},
  archive      = {J_EXSY},
  author       = {Ali Aydoğdu and Sait Gül},
  doi          = {10.1111/exsy.12898},
  journal      = {Expert Systems},
  month        = {5},
  number       = {4},
  pages        = {e12898},
  shortjournal = {Expert Syst.},
  title        = {New entropy propositions for interval-valued spherical fuzzy sets and their usage in an extension of ARAS (ARAS-IVSFS)},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ESIMD: Epileptic seizure identification using metaheuristic
deep learning technique. <em>EXSY</em>, <em>39</em>(4), e12897. (<a
href="https://doi.org/10.1111/exsy.12897">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The identification of epileptic seizure from electroencephalogram (EEG) segments is significant for seizure identification and classification. In epilepsy, the patients develop epileptic seizures. These lead to neurological disorders and abnormal brain activities. The manual identification of seizures is not very efficient. As the manual analysis of EEG data requires expert neurologists it is prone to inaccuracies. Therefore, automated methods for seizure identification are required. Deep learning methods have shown efficiency in the seizure classification problem. Many challenges are faced by the existing methods owing to the properties of the EEG signals like transiency, non-stationary behaviour and presence of noise. Therefore, to overcome these challenges and design a highly efficient method an automated method based on deep learning and spotted hyena optimization (SHO) algorithm is proposed. The SHO algorithm is used to initialize the network as it avoids the local minima problem. Epileptic seizure identification using metaheuristic deep learning (ESIMD) is proposed in this paper which is a hybridization of spotted hyena and deep convolution network. The convolutional neural network used has two blocks, the first block is used for feature extraction and the second block for seizure classification. ESIMD is used for seizure detection and classification. The proposed algorithm can handle the complex and large number of features in EEG signals. The performance of the proposed is evaluated by applying it on EEG Bonn Dataset. The results are compared with 13 other conventional methods. The comparative study shows that ESIMD gives higher accuracy than the existing methods.},
  archive      = {J_EXSY},
  author       = {Satyender and Sanjeev Dhull and Krishna Kant Singh},
  doi          = {10.1111/exsy.12897},
  journal      = {Expert Systems},
  month        = {5},
  number       = {4},
  pages        = {e12897},
  shortjournal = {Expert Syst.},
  title        = {ESIMD: Epileptic seizure identification using metaheuristic deep learning technique},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic contrast enhanced-magnetic resonance imaging
radiomics combined with a hybrid adaptive neuro-fuzzy inference
system-particle swarm optimization approach for breast tumour
classification. <em>EXSY</em>, <em>39</em>(4), e12895. (<a
href="https://doi.org/10.1111/exsy.12895">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The authors propose a method for breast dynamic contrast enhanced-magnetic resonance imaging classification by combining radiomic texture analysis with a hybrid adaptive neuro-fuzzy inference system (ANFIS)-particle swarm optimization (PSO) classifier. The fast discrete curvelet transform is utilized as a decomposition scheme in multiple scales. The mean and entropy features extracted from the produced scheme are used as texture descriptors. Principal component analysis (PCA) involves reduction of the dimensionality of the initial feature set. The transformed feature vector is subsequently introduced to a hybrid ANFIS-PSO classifier. The average overall classification power of the proposed hybrid ANFIS-PSO classifier is comparatively assessed to that obtained using several classifiers (ANFIS, linear discriminant analysis, Naïve Bayes, artificial neural networks, random forest and support vector machine) by using the 70 training-30 testing data ratio. The comparison performed highlights the superiority of the proposed methodology, thus underlying the potential of ANFIS-PSO for the breast cancer diagnosis with a classification accuracy of 94%.},
  archive      = {J_EXSY},
  author       = {Alexia G. Tzalavra and Ioannis Andreadis and Kalliopi V. Dalakleidi and Fotios Constantinidis and Evangelia I. Zacharaki and Konstantina S. Nikita},
  doi          = {10.1111/exsy.12895},
  journal      = {Expert Systems},
  month        = {5},
  number       = {4},
  pages        = {e12895},
  shortjournal = {Expert Syst.},
  title        = {Dynamic contrast enhanced-magnetic resonance imaging radiomics combined with a hybrid adaptive neuro-fuzzy inference system-particle swarm optimization approach for breast tumour classification},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Computer-aided deep learning model for identification of
lymphoblast cell using microscopic leukocyte images. <em>EXSY</em>,
<em>39</em>(4), e12894. (<a
href="https://doi.org/10.1111/exsy.12894">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conventional technique of leukocyte cell classification involves segmenting the required portion of cells from input image, extracting features of the segmented nuclei, reducing and optimizing these features and then implements the classifier. Thus, designing a good classifier by using such techniques increases the time complexity of the system. In order to resolve such issues, the proposed work implements the deep convolutional neural network (DCNN)-based models for classifying malignant versus normal WBCs. The proposed system is validated on 108 images of ALL-IDB 1. Due to limited number of training samples, data augmentation is used to create a similar type of virtual image. In this work, experimentation is carried out for discrimination between normal and infected WBC using DCNN with four different activation functions. By using this method, a set of 6000 samples are generated and used for proper training of the DL model for all activation functions. The performance of each trained model is evaluated in terms of accuracy, recall, precision and F-measure with the maximum values of 98.1%, 98.3%, 98.3% and 98.3% are achieved, respectively. Finally, it has been concluded that the defined DCNN model and ReLu activation function yield outstanding performance for lymphoblast characterization using microscopic blood images.},
  archive      = {J_EXSY},
  author       = {Abhishek Kumar and Jyoti Rawat and Indrajeet Kumar and Mamoon Rashid and Kamred Udham Singh and Yasser D. Al-Otaibi and Usman Tariq},
  doi          = {10.1111/exsy.12894},
  journal      = {Expert Systems},
  month        = {5},
  number       = {4},
  pages        = {e12894},
  shortjournal = {Expert Syst.},
  title        = {Computer-aided deep learning model for identification of lymphoblast cell using microscopic leukocyte images},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimization of fuzzy similarity by genetic algorithm in
user-based collaborative filtering recommender systems. <em>EXSY</em>,
<em>39</em>(4), e12893. (<a
href="https://doi.org/10.1111/exsy.12893">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The most important subjects in the memory-based collaborative filtering recommender system (RS) are to accurately calculate the similarities between users and finally finding interesting recommendations for active users. The main purpose of this research is to provide a list of the best items for recommending in less time. The fuzzy-genetic collaborative filtering (FGCF) approach recommends items by optimizing fuzzy similarities in the continuous genetic algorithm (CGA). In this method, first, the crisp values of user ratings are converted to fuzzy ratings, and then the fuzzy similarities are calculated. Similarity values are placed into the genes of the genetic algorithm, optimized, and finally, they are used in fuzzy prediction. Therefore, the fuzzy system is used twice in this process. Experimental results on RecSys, Movielens 100 K, and Movielens 1 M datasets show that FGCF improves the collaborative filtering RS performance in terms of quality and accuracy of recommendations, time and space complexities. The FGCF method is robust against the sparsity of data due to the correct choice of neighbours and avoids the users&#39; different rating scales problem but it not able to solve the cold-start challenge.},
  archive      = {J_EXSY},
  author       = {Farimah Houshmand-Nanehkaran and Seyed Mohammadreza Lajevardi and Mahmoud Mahlouji-Bidgholi},
  doi          = {10.1111/exsy.12893},
  journal      = {Expert Systems},
  month        = {5},
  number       = {4},
  pages        = {e12893},
  shortjournal = {Expert Syst.},
  title        = {Optimization of fuzzy similarity by genetic algorithm in user-based collaborative filtering recommender systems},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neighbour-based bag-of-samplings for person identification
through handwritten dynamics and convolutional neural networks.
<em>EXSY</em>, <em>39</em>(4), e12891. (<a
href="https://doi.org/10.1111/exsy.12891">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biometric recognition provides straightforward methods to deal with the problem of identifying people under certain circumstances. Additionally, a well-calibrated biometric system enhances security policies and prevents malicious attempts, such as fraud or identity theft. Deep learning has arisen to foster the problem by extracting high-level features that compose the so-called ‘user fingerprint’, that is, digital identification of a particular individual. Nevertheless, personal identification is not a trivial task, as many traits might define an individual, varying according to the task&#39;s domain. An exciting way to overcome such a problem is to employ handwritten dynamics, which are hand- and motor-based signals from an individual&#39;s writing style and obtained through a biometric smartpen. In this work, we propose using such signals to identify an individual through convolutional neural networks. Essentially, the proposed work uses a neighbour-based bag-of-samplings procedure to sample the signals to a fixed size and feeds them into a neural network responsible for extracting their features and further classifying them. The experiments were conducted over two handwritten dynamic datasets, NewHandPD and SignRec, and established new fruitful state-of-the-art concerning these particular datasets and the corresponding context.},
  archive      = {J_EXSY},
  author       = {Gustavo H. de Rosa and Mateus Roder and João P. Papa},
  doi          = {10.1111/exsy.12891},
  journal      = {Expert Systems},
  month        = {5},
  number       = {4},
  pages        = {e12891},
  shortjournal = {Expert Syst.},
  title        = {Neighbour-based bag-of-samplings for person identification through handwritten dynamics and convolutional neural networks},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Handling multiple objectives using k-means clustering guided
multiobjective evolutionary algorithm. <em>EXSY</em>, <em>39</em>(4),
e12890. (<a href="https://doi.org/10.1111/exsy.12890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiobjective optimization problems (MOPs) are very popular these days and have gained continuous research attention. These problems involve a minimum of two conflicting objectives that need to be optimized simultaneously. Multiobjective evolutionary algorithms (MOEAs) optimize these objectives by targeting solutions on the Pareto front. To judge the performance of different MOEAs, the convergence rate and population diversity are used. In order to create a good algorithm with a high convergence rate and diversity, the k-means clustering algorithm is combined with a real parameter version of the improved environmental adaptation method (IEAM-RP) in this paper. This is done as IEAM-RP converges very fast and the k-means clustering algorithm is used to provide diversity in decision search space. To check the performance of the proposed algorithm, it has been compared with nine state-of-the-art multiobjective algorithms (MOPSOtridist, MOEA/D-STM, MOEA/D, MOPSO, NSGA-II, MOPSOses, MOGOA, MODA, MOALO) using standard multiobjective benchmark functions. Further, the performance of the proposed algorithm is compared against IBEA and SMS-EMOA using walking fish group (WFG) test suit. The experimental results prove the effectiveness of the proposed algorithm.},
  archive      = {J_EXSY},
  author       = {Tribhuvan Singh},
  doi          = {10.1111/exsy.12890},
  journal      = {Expert Systems},
  month        = {5},
  number       = {4},
  pages        = {e12890},
  shortjournal = {Expert Syst.},
  title        = {Handling multiple objectives using k-means clustering guided multiobjective evolutionary algorithm},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feature-weighted AdaBoost classifier for punctuation
prediction in tamil and hindi NLP systems. <em>EXSY</em>,
<em>39</em>(4), e12889. (<a
href="https://doi.org/10.1111/exsy.12889">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Punctuation marks play a vital role in text representation and interpretation, and are useful in enhancing the performance of modern Natural Language Processing (NLP) systems such as voice input typing aids, machine translation, and speech synthesis systems. Punctuation marks, except period, are inherently not available in Indian languages such as Tamil and Hindi. However, some modern forms of writing such as news articles, blogs, stories, and so forth, incorporate user-defined punctuation marks in these languages. The current work proposes an automatic punctuation prediction system for texts in Tamil and Hindi using classification approach, where punctuation prediction is considered as a multi-class classification problem. Word-level text features are chosen and are analysed to validate their language-dependency and significance towards punctuation prediction. A Feature-weighted AdaBoost (FAda) classifier is proposed that defines a novel boosting factor to adjust the hypothesis weight of the weak classifiers, hence reducing the number of false classifications. It is observed that the proposed classifier outperforms the other classification techniques such as, AdaBoost, SVM, CART, CRF, and Bi-LSTM by a maximum difference of 50% and 16% in the macro F1-scores for Tamil and Hindi texts, respectively. The proposed classifier performs on par with the attention-based classifier for both Tamil and Hindi texts. Further, as a proof of concept, the proposed punctuation prediction system is applied to voice keyboard, machine translation, and speech synthesis systems, to validate the effect of the punctuation marks on the performance of these Natural Language Processing (NLP) systems.},
  archive      = {J_EXSY},
  author       = {Mrinalini K and Vijayalakshmi P and Nagarajan T},
  doi          = {10.1111/exsy.12889},
  journal      = {Expert Systems},
  month        = {5},
  number       = {4},
  pages        = {e12889},
  shortjournal = {Expert Syst.},
  title        = {Feature-weighted AdaBoost classifier for punctuation prediction in tamil and hindi NLP systems},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MIFAS: Multi-source heterogeneous information fusion with
adaptive importance sampling for link prediction. <em>EXSY</em>,
<em>39</em>(4), e12888. (<a
href="https://doi.org/10.1111/exsy.12888">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction plays an important role in constructing knowledge graph. Recently, graph representation learning models yield state-of-the-art results. However, existing models concentrate merely on triples or graph structures and mostly ignore textual descriptions, resulting in incomplete or partial information. In this paper, we propose a novel graph representation learning model to address this challenge, namely multi-source heterogeneous information fusion with adaptive importance sampling. Our model leverages multiple sources, such triple, graph structure and textual description, and generate rich-attribute embeddings for entities, encapsulating relations simultaneously. We also propose an adaptive importance sampling algorithm to boost aggregation of useful features from local neighbours. Additionally, we also boost node aggregation of useful features from local neighbours by adaptive importance sampling algorithm in our model. Experimental results on two benchmark datasets show that our proposed model significantly outperforms state-of-the-art methods.},
  archive      = {J_EXSY},
  author       = {Tingting Jiang and Hao Wang and Xiangfeng Luo and Shaorong Xie and Jingchao Wang},
  doi          = {10.1111/exsy.12888},
  journal      = {Expert Systems},
  month        = {5},
  number       = {4},
  pages        = {e12888},
  shortjournal = {Expert Syst.},
  title        = {MIFAS: Multi-source heterogeneous information fusion with adaptive importance sampling for link prediction},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Convolution network model based leaf disease detection using
augmentation techniques. <em>EXSY</em>, <em>39</em>(4), e12885. (<a
href="https://doi.org/10.1111/exsy.12885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agriculture plays a vital role in a country&#39;s economy. Thus, better yields of crops are required for growth of agriculture-based industries. Deep Learning (DL) techniques have led to remarkable achievements in image classification and recognition. However, DL networks rely heavily on large data sets to prevent overfitting. Image augmentation is one of the DL techniques gaining attention in avoiding the risk of overfitting. The most common Image augmentation techniques like rotation, zoom, and shift used in the existing research allow to generate new images from the original set and increases the images quantity but cannot minimize the misclassification error. The present research can provide a better solution to provide sufficient quantity of training images to a convolutional neural network model to handle the overfitting and classification problems. Therefore, two learning algorithms image preprocessing and transformation algorithm (IPTA) and image masking and REC-based hybrid segmentation algorithm (IMHSA) are proposed to address the problem of limited dataset and convolutional neural network model overfitting during classification. IPTA is an adaptive supervised learning approach to transform the original images into augmented ones and IMHSA is an unsupervised approach for Red, Green, Blue (RGB) image segmentation. Later, the Histogram threshold technique is applied to form all the possible regions used to split the diseased leaf into comparable regions. A novel convolutional neural network model is also proposed to evaluate the performance of the IPTA approach. The model is trained on two independent datasets, one generated before and one generated after IPTA was applied. Plots of precision and loss functions are used to assess the acquired results. The experimental results demonstrated that before using IPTA, the training accuracy was 83%, while the validation accuracy was 65%. After using IPTA, the proposed model attained a training accuracy of 74% and a validation accuracy of 73%, thereby solving the overfitting problem. The experimental results proved that the proposed model outperforms while classifying the RGB images with the support of image augmentation.},
  archive      = {J_EXSY},
  author       = {Mamillapally Nagaraju and Priyanka Chawla and Shuchi Upadhyay and Rajeev Tiwari},
  doi          = {10.1111/exsy.12885},
  journal      = {Expert Systems},
  month        = {5},
  number       = {4},
  pages        = {e12885},
  shortjournal = {Expert Syst.},
  title        = {Convolution network model based leaf disease detection using augmentation techniques},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid learning approach for the stage-wise classification
and prediction of COVID-19 x-ray images. <em>EXSY</em>, <em>39</em>(4),
e12884. (<a href="https://doi.org/10.1111/exsy.12884">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EXSY},
  author       = {Adimoolam M. and Karthi Govindharaju and John A. and Senthilkumar Mohan and Ali Ahmadian and Tiziana Ciano},
  doi          = {10.1111/exsy.12884},
  journal      = {Expert Systems},
  month        = {5},
  number       = {4},
  pages        = {e12884},
  shortjournal = {Expert Syst.},
  title        = {A hybrid learning approach for the stage-wise classification and prediction of COVID-19 X-ray images},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Assessment of the comparative efficiency of software-based
boolean, electronic, software-based fractional value and simplified
quantum principal expert systems. <em>EXSY</em>, <em>39</em>(4), e12880.
(<a href="https://doi.org/10.1111/exsy.12880">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software-based expert systems typically use an iterative algorithm for rule-fact network processing. However, other approaches to expert system implementation also exist. This paper proposes simplified quantum principle expert systems and compares the computational efficiency and comparative efficacy of four types of expert systems: software-based Boolean expert systems, electronic (gate-based) expert systems, software-based fractional value (SBFV) expert systems and simplified quantum principal expert systems (SQPES). For two expert system types, software-based Boolean and SBFV, back chaining and mixed changing techniques, respectively, are also evaluated. The performance of these systems approaches is compared quantitatively, and the efficacy of the different systems types are compared both qualitatively and quantitatively.},
  archive      = {J_EXSY},
  author       = {Jeremy Straub},
  doi          = {10.1111/exsy.12880},
  journal      = {Expert Systems},
  month        = {5},
  number       = {4},
  pages        = {e12880},
  shortjournal = {Expert Syst.},
  title        = {Assessment of the comparative efficiency of software-based boolean, electronic, software-based fractional value and simplified quantum principal expert systems},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimal multiple key-based homomorphic encryption with deep
neural networks to secure medical data transmission and diagnosis.
<em>EXSY</em>, <em>39</em>(4), e12879. (<a
href="https://doi.org/10.1111/exsy.12879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical database classification problems can be considered as complex optimization problems to assure the diagnosis support precisely. In healthcare, several computer researchers have employed different deep learning (DL) approaches to enhance the classification performance. Besides, encryption is an effective way to offer secure transmission of medical data over public network. With this motivation, this paper presents new privacy-preserving encryption with DL based medical data transmission and classification (PPEDL-MDTC) model. The presented model derives multiple key-based homomorphic encryption (MHE) technique with sailfish optimization (SFO), called MHE-SFO algorithm-based encryption process. In addition, the cross-entropy based artificial butterfly optimization-based feature selection technique and optimal deep neural network (ODNN) based classification is carried out. In ODNN model, the hyperparameter optimization of the DNN model is carried out utilizing the use of chemical reaction optimization (CRO) algorithm. The proposed method has been simulated utilizing Python 3.6.5 tool, which is tested using activity recognition and sleep stage dataset. A detailed comparative outcomes analysis makes sure the higher efficiency of the PPEDL-MDTC on the state of art techniques with the detection accuracy of 0.9813 and 0.9650 on the applied activity recognition and University College Dublin Sleep Stage dataset.},
  archive      = {J_EXSY},
  author       = {Jafar A. Alzubi and Omar A. Alzubi and Majdi Beseiso and Anil Kumar Budati and K. Shankar},
  doi          = {10.1111/exsy.12879},
  journal      = {Expert Systems},
  month        = {5},
  number       = {4},
  pages        = {e12879},
  shortjournal = {Expert Syst.},
  title        = {Optimal multiple key-based homomorphic encryption with deep neural networks to secure medical data transmission and diagnosis},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Embedded electronic medical record text data mining using
neural network association classification algorithm. <em>EXSY</em>,
<em>39</em>(4), e12874. (<a
href="https://doi.org/10.1111/exsy.12874">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The embedded electronic medical record (EMR) information is analysed through a neural network algorithm in the field of deep learning to mine the main sentence of EMR text. The pure convolutional neural network model (PCNN) based on pooled and non-pooled analysis is constructed based on deep learning CNN to mine EMR text. An association classification algorithm based on neural network is proposed, which integrates classification rules into the neural network and realizes the rapid establishment of neural network structure and parameter setting. Character embedding is imported and combined with a sliding window. Then, CNN is adopted to classify the Chinese character tags of the neural network model. Finally, the model is applied to the word segmentation of the actual pregnant women&#39;s EMR text. The results show that the scores of the Biomedical Engineering Society and Bioelectronics in Peking University and Microsoft Reserved Partition datasets are between 0.9516 and 0.9684 and the performance is basically the same, which shows that the model has strong stability. The performance of the max-pooling, n-max pooling, and mean-pooling are all between 0.8004 and 0.8634, but the above results are not as good as the model without pooling layer. For this new fast method to obtain neural network parameters, once the classification rules are given, the parameters in PCNN can be set quickly, and provide a practical basis for the development of deep learning in the medical field.},
  archive      = {J_EXSY},
  author       = {Xiuli Mu and Hongyan Zhang},
  doi          = {10.1111/exsy.12874},
  journal      = {Expert Systems},
  month        = {5},
  number       = {4},
  pages        = {e12874},
  shortjournal = {Expert Syst.},
  title        = {Embedded electronic medical record text data mining using neural network association classification algorithm},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A replication study on implicit feedback recommender systems
with application to the data visualization recommendation.
<em>EXSY</em>, <em>39</em>(4), e12871. (<a
href="https://doi.org/10.1111/exsy.12871">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we compare the Bayesian personalized ranking (BPR) algorithms with two recent state-of-the-art algorithms, namely, noisy-label robust Bayesian point-wise optimization (NBPO) and Light Graph Convolution Network (LightGCN) algorithms, to validate and generalize their performance by using six publicly available datasets and one proprietary dataset containing web-based data visualization usage records. We follow the guidelines explained in the original studies to pre-process the input data and evaluate these algorithms using various evaluation metrics. We also perform hyperparameter tuning for the recommendation algorithms to determine the optimal configuration resulting in the best recommendation quality. We observe that the best hyperparameter configuration varies based on the algorithms and the datasets. The results of our analysis show some similarities with the results of the original studies while differing in certain respects. We observe that adaptive oversampling BPR (AOBPR) and LightGCN algorithms generate higher quality recommendations than the other algorithms. However, algorithm convergence rates vary significantly for each dataset. We note that the AOBPR approach is particularly useful for data visualization recommendation task, and can contribute to the improved recommendations in practice.},
  archive      = {J_EXSY},
  author       = {Parisa Lak and Aysun Bozanta and Can Kavaklioglu and Mucahit Cevik and Ayse Basar and Martin Petitclerc and Graham Wills},
  doi          = {10.1111/exsy.12871},
  journal      = {Expert Systems},
  month        = {5},
  number       = {4},
  pages        = {e12871},
  shortjournal = {Expert Syst.},
  title        = {A replication study on implicit feedback recommender systems with application to the data visualization recommendation},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Topic modelling in precision medicine with its applications
in personalized diabetes management. <em>EXSY</em>, <em>39</em>(4),
e12774. (<a href="https://doi.org/10.1111/exsy.12774">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in Internet of Things (IoT) and analytic-based systems in the past decade have found several applications in medical informatics, and have significantly facilitated healthcare decision making. Patients&#39; data are collected through a variety of means, including IoT sensory systems, and require efficient, and accurate processing. Topic Modelling is an unsupervised machine learning algorithm for Natural Language Processing (NLP) that identifies relationships and associations within textual data. The application of Topic Modelling has been widely used on raw text data, where meaningful clusters (topics) are generated by the model. The purpose of this paper is to explore the varying methods of Topic Modelling, mostly the Latent Dirichlet allocation (LDA) model, and its applicability on personalized diabetes management. The proposed study evaluates the possibility of applying topic modelling methods on diabetes literature and genomic data in order to achieve precision medicine.},
  archive      = {J_EXSY},
  author       = {Chong Ni Ki and Amin Hosseinian-Far and Alireza Daneshkhah and Nader Salari},
  doi          = {10.1111/exsy.12774},
  journal      = {Expert Systems},
  month        = {5},
  number       = {4},
  pages        = {e12774},
  shortjournal = {Expert Syst.},
  title        = {Topic modelling in precision medicine with its applications in personalized diabetes management},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design of a secured telehealth system based on multiple
biosignals diagnosis and classification for IoT application.
<em>EXSY</em>, <em>39</em>(4), e12765. (<a
href="https://doi.org/10.1111/exsy.12765">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this article is to design a new telehealth system with secured wireless transmission and classification of multiple biosignals using e-Health sensors platform and Xbee modules with Arduino Uno and Raspberry Pi as acquisition and processing units, respectively. The collected data, such as temperature, airflow, position, Galvanic skin response and oxygen in the blood can be evaluated in order to monitor patient health state using threshold detection. The prediction of the cardiac state based on automatic identification of arrhythmias is validated by the classification of ElectroCardioGram (ECG) signals using Artificial Intelligence (AI) by exploiting TensorFlow and Keras tools. Different AI algorithms and a combination with different Machine Learning (ML) basing to transfer learning approach are tested. These algorithms include Artificial Neural Network (ANN), Convolutional Neural Network (CNN), Support Vector Machine (SVM), K-Nearest Neighbour (KNN) and Random Forest (RF). At first, ANN and CNN are used to classify ECG-scalogram images using softmax, then the used CNN model (VGG16) is employed to extract features and pass them to other traditional classifiers (SVM, KNN and RF) allowing to evaluate and select the best classifier, such that the ECG signal can be classified into four categories namely Normal Sinus Rhythm (NSR), Atrial Fibrillation (AF), Congestive Heart Failure (CHF) and other cardiac arrhythmia (ARR). The proposed method has been evaluated using real recorded signals and four PhysioNet databases. A Graphical User Interface (GUI) has been designed with C# under Visual Studio IDE allowing to display the results using personal computer (PC) or a network linked phone, which makes it possible to transfer the diagnosis with the prediction results to a remote clinic control room as Internet of Things (IoT) system application. The best classification accuracy of 99.56% is attained, confirming that the designed system allows a good trade-off between low cost and performances in addition, it is easy to use with quick access to multiple biosignals. It has improved vital characteristics monitoring and diagnosis services quality under a robust secured wireless transmission using lightweight chaos-based algorithm, thus preventing loss of life during critical health situations.},
  archive      = {J_EXSY},
  author       = {Hocine Hamil and Zahia Zidelmal and Mohamed Salah Azzaz and Samir Sakhi and Redouane Kaibou and Salem Djilali and Djaffar Ould Abdeslam},
  doi          = {10.1111/exsy.12765},
  journal      = {Expert Systems},
  month        = {5},
  number       = {4},
  pages        = {e12765},
  shortjournal = {Expert Syst.},
  title        = {Design of a secured telehealth system based on multiple biosignals diagnosis and classification for IoT application},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Variational autoencoders for anomaly detection in the
behaviour of the elderly using electricity consumption data.
<em>EXSY</em>, <em>39</em>(4), e12744. (<a
href="https://doi.org/10.1111/exsy.12744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to the World Health Organization, between and , the proportion of the world&#39;s population over will double, from to . In absolute numbers, this age group will increase from million to billion in the course of half a century. It is a reality that most of them prefer to live alone, so it is necessary to look for mechanisms and tools that will help them to improve their autonomy. Although in recent years, we have been living in a veritable explosion of domotic systems that facilitate people&#39;s daily lives, it is also true that there are not many tools specifically aimed at this sector of the population. The aim of this paper is to present a potential solution to the monitoring of activity of daily living in the least intrusive way for people. In this case, anomalous patterns of daily activities will be detected by analysing the daily consumption of household appliances. People who live alone usually have a pattern of daily behaviour in the use of household appliances (coffee machine, microwave, television, etc.). A neuronal model is proposed for the detection of abnormal behaviour based on an autoencoder architecture. This solution will be compared with a variational autoencoder to analyse the improvements that can be obtained. The well-known dataset called UK-DALE will be used to validate the proposal.},
  archive      = {J_EXSY},
  author       = {Daniel Gonzalez and Miguel A. Patricio and Antonio Berlanga and Jose M. Molina},
  doi          = {10.1111/exsy.12744},
  journal      = {Expert Systems},
  month        = {5},
  number       = {4},
  pages        = {e12744},
  shortjournal = {Expert Syst.},
  title        = {Variational autoencoders for anomaly detection in the behaviour of the elderly using electricity consumption data},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A proactive model to predict osteoporosis: An artificial
immune system approach. <em>EXSY</em>, <em>39</em>(4), e12708. (<a
href="https://doi.org/10.1111/exsy.12708">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Osteoporosis disease is caused by hormonal changes, vitamin D, and calcium deficiency. With current technologies, the identification of osteoporosis requires many tests with the support of medications. Bone mineral density is a typical measure implemented using a DEXA scan which can be very costly. Such high technology equipment is usually not accessible for remote people, and thus a low-cost screening system is very appealing. This article proposes an osteoporosis prediction system that effectively determines its possibility of occurrence based on essential factors such as smoking habits and calcium level so that the people at high risk can be referred to access the DEXA scanner. Our proposed system is implemented by an improved version of the artificial immune system, enabling care providers to take precautionary measures at the right time to avoid the early development of osteoporosis. The experiments demonstrated a promising result of 94% prediction accuracy that proved its usefulness in identifying people with potential osteoporosis in the future.},
  archive      = {J_EXSY},
  author       = {Keerthika Periasamy and Suresh Periasamy and Sathiyamoorthi Velayutham and Zuopeng Zhang and Syed Thouheed Ahmed and Anitha Jayapalan},
  doi          = {10.1111/exsy.12708},
  journal      = {Expert Systems},
  month        = {5},
  number       = {4},
  pages        = {e12708},
  shortjournal = {Expert Syst.},
  title        = {A proactive model to predict osteoporosis: An artificial immune system approach},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fog-assisted virtual reality-based learning framework to
control panic. <em>EXSY</em>, <em>39</em>(4), e12700. (<a
href="https://doi.org/10.1111/exsy.12700">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The biggest challenges for several universities and educational institutions throughout the COVID-19 pandemic are online and e-learning infrastructure availability. The incorporation of Information and Communication Technologies in the domain of disaster management is one such dimension, which focuses on the sustainability of human beings regarding the handling of unexpected pandemics. Therefore, it is important to evaluate the panic well-being of the student in this situation. Moreover, virtual reality technology provides a virtual classroom environment that improves the skill and knowledge of the students at remote sites. In this paper, a fog-assisted cyber physical system is proposed that deals with the various aspects of the panic well-being of the student, including the virtual reality platform for remote learning. The proposed system utilizes the concepts of physical and cyberspace. The physical space facilitates real-time data acquisition, and cyberspace determines and predicts the panic well-being of the student. The performance assessment of the proposed model acknowledges the efficiency of the virtual learning system and panic well-being determination and prediction. The proposed system also discussed a virtual learning system that provides a virtual classroom environment to the students at remote sites and reduces the panic due to stressful times during the COVID-19 pandemic.},
  archive      = {J_EXSY},
  author       = {Sandeep Kumar Sood and Keshav Singh Rawat},
  doi          = {10.1111/exsy.12700},
  journal      = {Expert Systems},
  month        = {5},
  number       = {4},
  pages        = {e12700},
  shortjournal = {Expert Syst.},
  title        = {Fog-assisted virtual reality-based learning framework to control panic},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Risk factors for prediction of delirium at hospital
admittance. <em>EXSY</em>, <em>39</em>(4), e12698. (<a
href="https://doi.org/10.1111/exsy.12698">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aging population in many developed countries, moves the issue of healthy aging at the forefront of the political, scientific and technological concerns. Delirium is a multifactorial disorder that is highly prevalent in hospitalized elderly people that causes complications in the patient care and increases mortality at the hospital and soon after discharge. Early diagnostics would allow improved treatment and prevention for a syndrome that requires very personalized treatment. This paper deals with machine learning based prediction of delirium at hospital admittance as a computer aided diagnostic tool, as well as with the identification of risk factors by means of the variable importance computed by the classifier model building approaches. We achieve almost 0.80 classification accuracy, which is encourages further exploration of improved classifier models. Exploration of variable importance shows that frailty, dementia and some pharmacological factors are relevant risk factors for delirium at hospital admittance.},
  archive      = {J_EXSY},
  author       = {Guillermo Cano-Escalera and Manuel Graña and Jon Irazusta and Idoia Labayen and Ariadna Besga},
  doi          = {10.1111/exsy.12698},
  journal      = {Expert Systems},
  month        = {5},
  number       = {4},
  pages        = {e12698},
  shortjournal = {Expert Syst.},
  title        = {Risk factors for prediction of delirium at hospital admittance},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deming least square regressed feature selection and gaussian
neuro-fuzzy multi-layered data classifier for early COVID prediction.
<em>EXSY</em>, <em>39</em>(4), e12694. (<a
href="https://doi.org/10.1111/exsy.12694">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coronavirus disease (COVID-19) is a harmful disease caused by the new SARS-CoV-2 virus. COVID-19 disease comprises symptoms such as cold, cough, fever, and difficulty in breathing. COVID-19 has affected many countries and their spread in the world has put humanity at risk. Due to the increasing number of cases and their stress on administration as well as health professionals, different prediction techniques were introduced to predict the coronavirus disease existence in patients. However, the accuracy was not improved, and time consumption was not minimized during the disease prediction. To address these problems, least square regressive Gaussian neuro-fuzzy multi-layered data classification (LSRGNFM-LDC) technique is introduced in this article. LSRGNFM-LDC technique performs efficient COVID prediction with better accuracy and lesser time consumption through feature selection and classification. The preprocessing is used to eliminate the unwanted data in input features. Preprocessing is applied to reduce the time complexity. Next, Deming Least Square Regressive Feature Selection process is carried out for selecting the most relevant features through identifying the line of best fit. After the feature selection process, Gaussian neuro-fuzzy classifier in LSRGNFM-LDC technique performs the data classification process with help of fuzzy if-then rules for performing prediction process. Finally, the fuzzy if-then rule classifies the patient data as lower risk level, medium risk level and higher risk level with higher accuracy and lesser time consumption. Experimental evaluation is performed by Novel Corona Virus 2019 Dataset using different metrics like prediction accuracy, prediction time, and error rate. The result shows that LSRGNFM-LDC technique improves the accuracy and minimizes the time consumption as well as error rate than existing works during COVID prediction.},
  archive      = {J_EXSY},
  author       = {Rathnamma V Mydukuri and Suresh Kallam and Rizwan Patan and Fadi Al-Turjman and Manikandan Ramachandran},
  doi          = {10.1111/exsy.12694},
  journal      = {Expert Systems},
  month        = {5},
  number       = {4},
  pages        = {e12694},
  shortjournal = {Expert Syst.},
  title        = {Deming least square regressed feature selection and gaussian neuro-fuzzy multi-layered data classifier for early COVID prediction},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). COVID-19 special issue: Intelligent solutions for computer
communication-assisted infectious disease diagnosis. <em>EXSY</em>,
<em>39</em>(3), e12946. (<a
href="https://doi.org/10.1111/exsy.12946">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EXSY},
  author       = {Fadi Al-Turjman},
  doi          = {10.1111/exsy.12946},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12946},
  shortjournal = {Expert Syst.},
  title        = {COVID-19 special issue: Intelligent solutions for computer communication-assisted infectious disease diagnosis},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Special issue on deep neural networks for biomedical data
and imaging. <em>EXSY</em>, <em>39</em>(3), e12943. (<a
href="https://doi.org/10.1111/exsy.12943">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EXSY},
  author       = {Deepak Gupta and Utku Kose and Oscar Castillo},
  doi          = {10.1111/exsy.12943},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12943},
  shortjournal = {Expert Syst.},
  title        = {Special issue on deep neural networks for biomedical data and imaging},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-source BERT stack ensemble for cross-domain author
profiling. <em>EXSY</em>, <em>39</em>(3), e12869. (<a
href="https://doi.org/10.1111/exsy.12869">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Author profiling is the computational task of inferring an author&#39;s demographics (e.g., gender, age etc.) based on text samples written by them. As in other text classification tasks, optimal results are usually obtained by using training data taken from the same text genre as the target application, in so-called in-domain settings. On the other hand, when training data in the required text genre is unavailable, a possible alternative is to perform cross-domain author profiling, that is, building a model from a source domain (e.g., Facebook posts), and then using it to classify text in a different target domain (e.g., e-mails.) Methods of this kind may however suffer from cross-domain vocabulary discrepancies and other difficulties. As a means to ameliorate these, the present work discusses a particular strategy for cross-domain author profiling in which multiple source domains are combined in a stack ensemble architecture of pre-trained language models. Results from this approach are shown to compare favourably against standard single-source cross-domain author profiling, and are found to reduce overall accuracy loss in comparison with optimal in-domain gender and age classification.},
  archive      = {J_EXSY},
  author       = {José Pereira Delmondes Neto and Ivandré Paraboni},
  doi          = {10.1111/exsy.12869},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12869},
  shortjournal = {Expert Syst.},
  title        = {Multi-source BERT stack ensemble for cross-domain author profiling},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intelligent grey forecasting model based on periodic
aggregation generating operator and its application in forecasting clean
energy. <em>EXSY</em>, <em>39</em>(3), e12868. (<a
href="https://doi.org/10.1111/exsy.12868">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of long-term and short-term clean energy production is the basis for understanding short-term clean energy supply capacity, long-term clean energy development trend and evaluating the effect of energy policies. However, under the circumstances of the large time span, the insufficient data samples and the periodic characteristics of seasonal clean energy production make the traditional grey prediction model prone to produce forecasting deviations. Given this situation, a novel seasonal fractional-order full-order time power discrete grey prediction model is initially proposed to deal with long-term clean energy production sequences featured with nonlinearity and periodicity. Based on the proposed model, we also propose a data-based algorithm to select the model structure adaptively. To prove the practicability of the new model for nonlinear long-term development trend, monthly periodic time series and quarterly periodic time series, this article uses the new model to predict annual hydropower capacity in North America, monthly natural gas production in China and quarterly solar power generation in China. And the prediction results are compared with the existing grey models and non-grey prediction models. Different methods including GM (1,1), DGM (1,1), NGM (1,1), ARGM (1,1), ENGM (1,1), Verhulst, CCRGM (1,1), FOTP-DGM r (1,1), PFSM (1,1), Holt-winters model, SARIMA model, SGM, HP-GM and DGGM are used as benchmarks. In experiments, the MAPE of the proposed model is 2.92%, 2.43%, and 7.87%, respectively. The results of empirical analysis indicate that the proposed model generally outperform the benchmark model as it can well capture nonlinear long-term development trend and seasonal characteristics.},
  archive      = {J_EXSY},
  author       = {Aodi Sui and Wuyong Qian},
  doi          = {10.1111/exsy.12868},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12868},
  shortjournal = {Expert Syst.},
  title        = {Intelligent grey forecasting model based on periodic aggregation generating operator and its application in forecasting clean energy},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predictive effect of computed tomography imaging omics
features under deep learning on metastatic lymph nodes of nasopharyngeal
carcinoma. <em>EXSY</em>, <em>39</em>(3), e12860. (<a
href="https://doi.org/10.1111/exsy.12860">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article was to explore the adoption value of deep learning combined with computed tomography (CT) imaging omics in the prediction of metastatic lymph nodes of nasopharyngeal carcinoma (NPC). An end-to-end neural network architecture was designed based on the fully convolutional neural network (FCNN), which was applied to the CT image analysis of 52 patients with lymphatic metastasis and 36 patients without lymphatic metastasis. Patient&#39;s lymph node volume (V), the largest cross-sectional shortest diameter (d-value), and other macro characteristics were recorded. The microscopic features of its CT imaging omics were extracted. Moreover, receiver operating characteristic (ROC) curve was utilized to analyse the prediction performance (accuracy, area under the curve [AUC], and Youden index) of each feature for lymphatic metastasis. The results showed that the lymph node volume (4.37 ± 0.67) and the shortest diameter of the largest cross section (12.35 ± 2.31) of patients with lymph node metastasis were greatly larger than those without lymph node metastasis (1.84 ± 0.65, 7.98 ± 2.04) ( P &lt; 0.05). There were five features that met the conditions of AUC &gt; 0.7 and Yoden index&gt;0.5, including lymph node volume (AUC area 0.945, Youden index 0.597), the shortest diameter of the largest cross section (AUC area 0.746, Youden index 0.539), Surface Area Density (AUC area 0.809, Youden index 0.552), Compactness1 (AUC area 0.751, Youden index 0.537), and Convex Hull Volume (AUC area 0.751, Youden index 0.537). The AUC of V+ Surface Area Density + Compactness1 + Convex Hull Volume was 0.876, and the prediction accuracy was 92.11%. In short, the prediction model composed of the macroscopic features of CT images and some imaging omics features based on deep learning showed high accuracy and AUC for the prediction of NPC metastatic lymph nodes. Moreover, V + Surface Area Density + Compactness1 + Convex Hull Volume can be used as the optimal feature combination model for predicting NPC lymphatic metastasis.},
  archive      = {J_EXSY},
  author       = {Jianpeng Yuan and Wensheng Huang and Yongshun Wu and Long Liu and Chao Bu and Shuqiang Wang and Weidong Zhang},
  doi          = {10.1111/exsy.12860},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12860},
  shortjournal = {Expert Syst.},
  title        = {Predictive effect of computed tomography imaging omics features under deep learning on metastatic lymph nodes of nasopharyngeal carcinoma},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Internet of healthcare things security vulnerabilities and
jamming attack analysis. <em>EXSY</em>, <em>39</em>(3), e12853. (<a
href="https://doi.org/10.1111/exsy.12853">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of the internet in the recent past, communication and transferring data are no longer challenging. The internet of things (IoT) and many other mobile devices are another paradigm that has evolved lately and plays a significant role in communications. Smart healthcare has been a field of incredible change and growth in the age of smart houses, smart communities and the digital era. Technological expertise and electronics devices have fused, resulting in the internet of healthcare things (IoHT). It is considered to be one of the most required technological progress. However, the IoHT devices, wireless transmission of sensitive patient data poses some obvious security concerns. In addition, with the widespread use of IoHT devices, the foremost challenge is to manage and ensuring security while using IoHT for clinical applications. In this paper, the security and privacy challenges and associated threats in the domain of IoHT are thoroughly reviewed. A real-time collaborative jamming detection algorithm is proposed, which caters to all the significant challenges being faced. A jamming attack is a sub-type of denial of service (DoS) attack due to free Wi-Fi access points (APs) that executes on both mobile devices and Wi-Fi AP. The proposed algorithm investigates the strength of the received signal and the ratio of packet loss in the mobile devices, whereas the number of connected clients disrupted by the jammer is considered Wi-Fi AP. The approach aims to mitigate the causes of false alarms by connecting the originator present in the network, interfering with communication between the mobile devices and the Wi-Fi AP. This approach can be used to detect the presence of a jammer, which may hamper mobile device communication and prevent confidential information, that can be acquired via fake Wi-Fi AP.},
  archive      = {J_EXSY},
  author       = {Kavita Sharma},
  doi          = {10.1111/exsy.12853},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12853},
  shortjournal = {Expert Syst.},
  title        = {Internet of healthcare things security vulnerabilities and jamming attack analysis},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Clinical study of serum procalcitonin in the early diagnosis
of burns and sepsis under the background of healthy clouds.
<em>EXSY</em>, <em>39</em>(3), e12850. (<a
href="https://doi.org/10.1111/exsy.12850">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {‘Health Cloud’ refers to the provision of hospital management and residents&#39; health file management application services to all hospitals and related medical institutions in the area where the cloud computing industry base is located in the form of SaaS (software as a service). In the process of treating burn sepsis, it is particularly important to prevent burn sepsis. The purpose of this study is to diagnose burn sepsis early, after adding serum procalcitonin clinical research. First, use PCT during the experiment to observe the efficacy of antibiotics according to the situation and prognosis. In order to reduce the inappropriate use of antibiotics, it can be used as a reliable indicator to guide antibiotic management and allow patients with sepsis to receive accurate treatment. Second, according to the main observation indicators of burn sepsis, analyse the degree of injury of the patient. Finally, identifying burn sepsis as early as possible, and early intervention and prevention based on related technologies is a problem that needs to be solved by the research institute. The clinical symptoms and vital signs of burn sepsis are not particularly abnormal, and imaging examination may cause the focus of infection to be incorrect. As a result, the positive rate of positive results is low, which seriously affects the timely diagnosis and treatment of patients. Experimental data show that serum PCT of non-septic patients is obvious during the six groups of experiments 1–5 days, 6–10 days, 11–15 days, 16–20 days, 21–25 days, 26–30 days after treatment serum PCT levels below sepsis. The data recorded during the experiment are in accordance with the relevant principles of statistics to ensure that the experiment is true and effective. The experimental results show that the PCT of burn sepsis group is higher than that of the cured group without burns, and the serum PCT level is crucial for the diagnosis of burn sepsis.},
  archive      = {J_EXSY},
  author       = {Chonggen Huang and Zaiqiu Gu and Zhigang Jia and Jiong Yan},
  doi          = {10.1111/exsy.12850},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12850},
  shortjournal = {Expert Syst.},
  title        = {Clinical study of serum procalcitonin in the early diagnosis of burns and sepsis under the background of healthy clouds},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Local binary pattern and deep learning feature extraction
fusion for COVID-19 detection on computed tomography images.
<em>EXSY</em>, <em>39</em>(3), e12842. (<a
href="https://doi.org/10.1111/exsy.12842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The deadly coronavirus virus (COVID-19) was confirmed as a pandemic by the World Health Organization (WHO) in December 2019. It is important to identify suspected patients as early as possible in order to control the spread of the virus, improve the efficacy of medical treatment, and, as a result, lower the mortality rate. The adopted method of detecting COVID-19 is the reverse-transcription polymerase chain reaction (RT-PCR), the process is affected by a scarcity of RT-PCR kits as well as its complexities. Medical imaging using machine learning and deep learning has proved to be one of the most efficient methods of detecting respiratory diseases, but to train machine learning features needs to be extracted manually, and in deep learning, efficiency is affected by deep learning architecture and low data. In this study, handcrafted local binary pattern (LBP) and automatic seven deep learning models extracted features were used to train support vector machines (SVM) and K-nearest neighbour (KNN) classifiers, to improve the performance of the classifier, a concatenated LBP and deep learning feature was proposed to train the KNN and SVM, based on the performance criteria, the models VGG-19 + LBP achieved the highest accuracy of 99.4%. The SVM and KNN classifiers trained on the hybrid feature outperform the state of the art model. This shows that the proposed feature can improve the performance of the classifiers in detecting COVID-19.},
  archive      = {J_EXSY},
  author       = {Auwalu Saleh Mubarak and Sertan Serte and Fadi Al-Turjman and Zubaida Sa&#39;id Ameen and Mehmet Ozsoz},
  doi          = {10.1111/exsy.12842},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12842},
  shortjournal = {Expert Syst.},
  title        = {Local binary pattern and deep learning feature extraction fusion for COVID-19 detection on computed tomography images},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DC-GAN-based synthetic x-ray images augmentation for
increasing the performance of EfficientNet for COVID-19 detection.
<em>EXSY</em>, <em>39</em>(3), e12823. (<a
href="https://doi.org/10.1111/exsy.12823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, many deep learning models are being used to classify COVID-19 and normal cases from chest X-rays. However, the available data (X-rays) for COVID-19 is limited to train a robust deep-learning model. Researchers have used data augmentation techniques to tackle this issue by increasing the numbers of samples through flipping, translation, and rotation. However, by adopting this strategy, the model compromises for the learning of high-dimensional features for a given problem. Hence, there are high chances of overfitting. In this paper, we used deep-convolutional generative adversarial networks algorithm to address this issue, which generates synthetic images for all the classes (Normal, Pneumonia, and COVID-19). To validate whether the generated images are accurate, we used the k-mean clustering technique with three clusters (Normal, Pneumonia, and COVID-19). We only selected the X-ray images classified in the correct clusters for training. In this way, we formed a synthetic dataset with three classes. The generated dataset was then fed to The EfficientNetB4 for training. The experiments achieved promising results of 95% in terms of area under the curve (AUC). To validate that our network has learned discriminated features associated with lung in the X-rays, we used the Grad-CAM technique to visualize the underlying pattern, which leads the network to its final decision.},
  archive      = {J_EXSY},
  author       = {Pir Masoom Shah and Hamid Ullah and Rahim Ullah and Dilawar Shah and Yulin Wang and Saif ul Islam and Abdullah Gani and Joel J. P. C. Rodrigues},
  doi          = {10.1111/exsy.12823},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12823},
  shortjournal = {Expert Syst.},
  title        = {DC-GAN-based synthetic X-ray images augmentation for increasing the performance of EfficientNet for COVID-19 detection},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Image segmentation algorithm of lung cancer based on neural
network model. <em>EXSY</em>, <em>39</em>(3), e12822. (<a
href="https://doi.org/10.1111/exsy.12822">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To explore the application of neural network algorithm model in lung cancer imaging, and provide reference for the application and development of artificial neural network (ANN) algorithm model in lung cancer medical mirroring, so as to promote the development of ANN in this field. Meanwhile, it is hoped that the application of neural network algorithms in medical imaging can improve the survival rate and cure rate of lung cancer. In this study, an ANN algorithm model was selected to establish a lung cancer recognition model. After determining the lung cancer lesion area, the image segmentation algorithm was used to separately display the lung cancer lesion area, and a comparison experiment was designed to verify the accuracy of the model. ANNs were used to identify lung cancer, which can be concluded that the accuracy is 94.6%, the sensitivity is 95.7%, and the specificity is 93.5%. By combining image retrieval methods with lung cancer image segmentation algorithms, the lesion area of lung cancer can be clearly displayed. Therefore, the lung cancer image segmentation algorithm based on the neural network model has good recognition performance. This research can provide reference for the application of neural network algorithm model in the field of cancer diagnosis and treatment.},
  archive      = {J_EXSY},
  author       = {Binjun He and Wenbin Hu and Kang Zhang and Shunda Yuan and Xiaoliang Han and Chao Su and Jiaming Zhao and Guzong Wang and Guoxia Wang and Liuya Zhang},
  doi          = {10.1111/exsy.12822},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12822},
  shortjournal = {Expert Syst.},
  title        = {Image segmentation algorithm of lung cancer based on neural network model},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel quantum-inspired binary bat algorithm for leukocytes
classification in blood smear. <em>EXSY</em>, <em>39</em>(3), e12813.
(<a href="https://doi.org/10.1111/exsy.12813">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of medical sciences, day-to-day procedure is followed for identification of bone marrow and immune system related diseases, which is most of the time carried out manually. The notion is to perform differential and qualitative analysis of leukocytes for the timely diagnosis of these diseases. In this article, a systematized solution is offered for the classification of leukocytes in blood smear. The proposed model incorporates the optimistic aspects of nature-inspired and quantum-inspired algorithms; this model tends to be perfect blend of both the techniques. For reducing the dimensionality, that is, irrelevant features; the quantum-inspired binary bat algorithm (QBBA) has been used in the proposed model. The optimality of features selected has been computed with the help of accuracy measure using various machine learning classifiers like Logistic Regression, KNN, Random Forest, Decision Tree. The performance of QBBA and its customary algorithms has been compared and the results depict that QBBA outperforms binary bat algorithm for the same set of population. QBBA comes out as an influential algorithm with an average accuracy of 98.31% and also possess enhanced noise invulnerability. The proposed QBBA can also find its usage in thorough haematological analysis.},
  archive      = {J_EXSY},
  author       = {Prerna Sharma and Kapil Sharma},
  doi          = {10.1111/exsy.12813},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12813},
  shortjournal = {Expert Syst.},
  title        = {A novel quantum-inspired binary bat algorithm for leukocytes classification in blood smear},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Medical image analysis of multiple myeloma based on
convolutional neural network. <em>EXSY</em>, <em>39</em>(3), e12810. (<a
href="https://doi.org/10.1111/exsy.12810">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The staging diagnosis of multiple myeloma is conducive to the treatment of patients and can improve the survival rate of patients. In particular, the early diagnosis of multiple myeloma is more helpful to the cure of patients. However, multiple myeloma has a slow onset. Due to no obvious symptoms in the early stage, it is easily misdiagnosed. Recently, convolutional neural networks (CNNs) have been used in medical image detection to improve diagnosis efficiency. However, because of the slow onset of multiple myeloma in the early stage, how to segment diagnosis is a difficult point, which leads to less studies on the application of CNN algorithm in multiple myeloma. In order to fill this gap, a large number of existing multiple myeloma imaging data was used to construct a CNN model, and input the retained case image data into the constructed CNN to verify the accuracy of the neural network. The results showed that the accuracy rate of the neural network model constructed in this study was 0.87, which was higher than the accuracy rate of manual detection of 0.77. Therefore, it can be proved that the CNN model established in this paper is effective. At the same time, it is found that the use of magnetic resonance imaging (MRI) to classify and classify multiple myeloma has a high accuracy rate. Our results prove that the neural network algorithm can be applied to MRI analysis, which helps to improve the efficiency of multiple myeloma diagnosis.},
  archive      = {J_EXSY},
  author       = {Jinxia He and Kaifeng Zhang},
  doi          = {10.1111/exsy.12810},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12810},
  shortjournal = {Expert Syst.},
  title        = {Medical image analysis of multiple myeloma based on convolutional neural network},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PTXNet: An extended UNet model based segmentation of
pneumothorax from chest radiography images. <em>EXSY</em>,
<em>39</em>(3), e12807. (<a
href="https://doi.org/10.1111/exsy.12807">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the respiratory analysis of human beings, lungs play an important role and can be used to find several associated diseases. One of such conditions is called pneumothorax which occurs due to leaking of air into pleural space and results in lungs collapse. The traditional methodology uses chest radiography with the manual intervention of radiologists for the detection and segmentation of the affected areas. This paper introduces a deep neural network based methodology for the automatic localization and segmentation of the proper region-of-interest (RoI). The proposed approach is based on transfer learning where the existing UNet model is extended and redesigned to a new architecture named PTXNet for RoI segmentation. In PTXNet, the traditional encoder is redesigned with the use of EfficientNet, SE-ResNeXt50 and Xception convolutional neural network (CNN) architectures. Furthermore, residual blocks are introduced in the decoder phase and concatenation of the previous decoder stage feature maps in addition to standard global skip connections is performed. The PTXNet is trained on a dataset of more than 15,000 chest radiography and resulted in the mean dice coefficient of 84.89%. It is found that the proposed approach provides superior results than the UNet model with an increase in the mean dice coefficient of 18.76%.},
  archive      = {J_EXSY},
  author       = {Aarya Patel and Ankit Vidyarthi},
  doi          = {10.1111/exsy.12807},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12807},
  shortjournal = {Expert Syst.},
  title        = {PTXNet: An extended UNet model based segmentation of pneumothorax from chest radiography images},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Autism diagnosis via correlation between vectors of direct
quadrature instantaneous frequency of EEG analytic normalized intrinsic
mode functions. <em>EXSY</em>, <em>39</em>(3), e12801. (<a
href="https://doi.org/10.1111/exsy.12801">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autism spectrum disorder (ASD) is a neurological and developmental disorder that commences usually in the early years of age. It impacts the social interaction, communication and learning. It is believed that it is mainly caused by an abnormal connectivity between brain zones. The presented work applies an EEG-based nonlinear method for the classification of ASD and neuro-typical groups. The suggested procedure does not require pre-assumptions and is completely data-driven. Also, the main advantage is the accurate tracking of the pace of EEG activity without the effect of amplitude modulation on the spectral information. In addition, the tracking is conducted point-by-point to avoid shortcomings of inexact global features. First, for every (ASD or neuro-typical) volunteer, the recorded EEG channels (64 channels) are decomposed by empirical mode decomposition (EMD) in order to get the underlying components (intrinsic mode functions—IMFs). Second, the direct quadrature (DQ) method is used to normalize the IMFs, and to dissociate between amplitude and frequency contents of the resulted components, as well as to help extract then the point-by-point spectral information from the analytic normalized IMFs by Hilbert transform. Third, the correlation coefficients between the instantaneous frequency vectors of the counterpart components will be computed over all channels (i.e., between components number ‘i’ of channels ‘x’ and ‘y’, 1 &lt; i &lt; number of components, 1 &lt; x &lt; 64, 1 &lt; y &lt; 64). Fourth, correlation coefficients array is constructed. Fifth, the dimension of the feature array is reduced without loss of significant information. Sixth, classification of reduced features is achieved via neural network. Finally, the statistical assessment of the classification outcome is conducted. The proposed method yields a test accuracy of 94.1%–100%.},
  archive      = {J_EXSY},
  author       = {Enas Abdulhay and Maha Alafeef and Hikmat Hadoush and Arunkumar N},
  doi          = {10.1111/exsy.12801},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12801},
  shortjournal = {Expert Syst.},
  title        = {Autism diagnosis via correlation between vectors of direct quadrature instantaneous frequency of EEG analytic normalized intrinsic mode functions},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Traditional and deep-based techniques for end-to-end
automated karyotyping: A review. <em>EXSY</em>, <em>39</em>(3), e12799.
(<a href="https://doi.org/10.1111/exsy.12799">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of cytogenetics, chromosome image analysis or karyotyping from metaphase images plays an imperative role in the diagnosis, prognosis and treatment assessment of different genetic disorders and cancers. This paper is a comprehensive review on different traditional and deep-based techniques, which are utilized in the design of automated karyotyping systems (AKSs). By this review, a detailed methodology is suggested for the design of end-to-end automated karyotyping system (EEAKS) which portrays a sequential multi stage approach. Methods related to all the stages in EEAKS are systematically surveyed by exploring the state of the art literature. Datasets and performance measures incorporated in the past studies are explored. Even though numerous methods were proposed throughout the past three decades, a completely automated framework has not yet been acknowledged. Inferences from this study show that, while various traditional image processing strategies are utilized for pre-processing and segmentation, machine learning techniques are used only for the classification purpose. In conventional classifiers, artificial neural networks are generally utilized even when the peak performance is given by support vector machines. However, owing to the recent prodigious breakthrough in computer vision, deep neural networks are progressively utilized for developing automated systems. It is seen that deep neural networks are not yet explored in the realm of pre-processing stage of EEAKS. However, limited number of methods based on convolutional neural networks (CNN) are utilized in all other stages. This review recommends a hybrid CNN for the design of EEAKS, in which all the stages can be automated by sub CNNs. Methodology for generating sufficient datasets is also discussed here which is, indeed, required for further research in this area. This paper concludes with future research directions for the development of a fully automated end-to-end karyotyping system.},
  archive      = {J_EXSY},
  author       = {Remya Remani Sathyan and Gopakumar Chandrasekhara Menon and Hariharan S and Rakhi Thampi and Jude Hemanth Duraisamy},
  doi          = {10.1111/exsy.12799},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12799},
  shortjournal = {Expert Syst.},
  title        = {Traditional and deep-based techniques for end-to-end automated karyotyping: A review},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Early prediction and monitoring of sepsis using sequential
long short term memory model. <em>EXSY</em>, <em>39</em>(3), e12798. (<a
href="https://doi.org/10.1111/exsy.12798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sepsis is a severe life-threatening disease, which is the body&#39;s extreme reverberation to any virus leading to failed organs, damaged tissue, or death. It requires accurate and efficient real-time detection. Continuous and potent monitoring of patient health data can be useful in predicting the potential risks the patient might be exposed to, based on their recent history of medical records. Machine learning models have proven to be a significant approach in performing accurate and precise predictions, especially in the medical field. In this paper, a smart network with a long short term memory (LSTM) based model at its heart is proposed for early prediction of Sepsis for patients admitted in the ICU. The network operates on time series data and predicts the probability of a patient developing sepsis based on the historical medical data of the patient. It comprises Internet of Things based devices which have proven to be impactful in the areas of acquiring continuous and real-time data in the healthcare field. In this paper, an architecture for early prediction and monitoring Sepsis with minimized latency through LSTM network is proposed by designing a decentralized prediction model in a fog-based environment. The model had an accuracy of 95.1% after the last epoch with validation accuracy as 95%. The receiver operating characteristic curve area was reported as 0.864 for testing data with an accuracy of 95.1%. The model was not over-fitted since the validation accuracy was significantly close to the training accuracy of the model.},
  archive      = {J_EXSY},
  author       = {Deepak Kumar Sharma and Parul Lakhotia and Paras Sain and Shikha Brahmachari},
  doi          = {10.1111/exsy.12798},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12798},
  shortjournal = {Expert Syst.},
  title        = {Early prediction and monitoring of sepsis using sequential long short term memory model},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A study on specific learning algorithms pertaining to
classify lung cancer disease. <em>EXSY</em>, <em>39</em>(3), e12797. (<a
href="https://doi.org/10.1111/exsy.12797">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lung cancer is a worldwide precarious disease and it is encouraged by the abnormal growth of cells in bronchi. Spotting the cancer cells is unknown until it leads to respiration issues and the muddling of organs working. Due to problems, limited or incorrect selection of hypothesis space, and dropping into local minima, single learners often give erratic output in an existing approach. The ensemble method accomplished a dataset that is free and composed of computed tomography (CT) images. The annotation process reveals observed lung lesions and provides a degree of malignancy for each lesion. Detection of benign and malignant nodules is recognized using deep convolutional frameworks AlexNet, SqueezeNet, GoogleNet, ResNet, and Inception ResNet, achieves higher accuracy (93%) than other convolutional neural networks (CNNs). Eight machine learning methods are involved for achieving better performance. The prediction probability obtained from CNN is applied as input to support vector machines (SVM), K-nearest neighbours (KNN), naive Bayes (NB), multi-layer perceptron (MLP), decision trees (DT), gradient boosted regression trees (GBRT), and adaptive boosting. The composition of GoogleNet model and AdaBoost classifier reached the most coherent classification accuracy as 99%. This is one of the best ways to analyse early detection and it increases the survival rate. Therefore, the result from the proposed deep CNN and ML technique achieves better precision than sputum cytology, X-Ray process, and earlier detection of lung cancer.},
  archive      = {J_EXSY},
  author       = {Malavika Saminathan and Manikandan Ramachandran and Ambeshwar Kumar and Kulandaivel Rajkumar and Ashish Khanna and Prakashkumar Singh},
  doi          = {10.1111/exsy.12797},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12797},
  shortjournal = {Expert Syst.},
  title        = {A study on specific learning algorithms pertaining to classify lung cancer disease},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fully-automatic identification of gynaecological abnormality
using a new adaptive frequency filter and histogram of oriented
gradients (HOG). <em>EXSY</em>, <em>39</em>(3), e12789. (<a
href="https://doi.org/10.1111/exsy.12789">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultrasound imaging (US) is one of the most common diagnostic imaging tools for producing images of the human body in clinical practice. This work is devoted to studying ultrasound images collected from gynaecological tests for medical purposes regarding ovarian and breast defects. The study revolves around (i) Enhancing the texture of the image by applying a new effective framework that can help in reducing the speckle noise from the image while preserving the most important information; (ii) Extracting the most prominent features using the histogram of oriented gradients (HOG) and; (iii) Fusing the features that are produced by the edge operators and using them as an input to the ANN classifier to generate three trained classifiers. The fusion technique has been used to get an effective decision by using the whole features. The experimental results of the proposed method for the breast cancer and ovarian tumour using the second experiment achieved 97.96% accuracy, 96.05% sensitivity, and 99.17% specificity by utilizing the breast cancer information set. Overall, 95.87% precision, 97.01% sensitivity, and 93.33% specificity have been achieved for the ovarian tumour data collection. Consequently, the proposed method has been improved to validate the output of modern computerized and automated technologies. This method analyzes the gynaecological ultrasound images to identify suspicious objects or cases with health consequences for women.},
  archive      = {J_EXSY},
  author       = {Ihsan Jasim Hussein and Mohd Aboobaider Burhanuddin and Mazin Abed Mohammed and Narjes Benameur and Marwah Suliman Maashi and Mashael S. Maashi},
  doi          = {10.1111/exsy.12789},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12789},
  shortjournal = {Expert Syst.},
  title        = {Fully-automatic identification of gynaecological abnormality using a new adaptive frequency filter and histogram of oriented gradients (HOG)},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient detection of parkinson’s disease using deep
learning techniques over medical data. <em>EXSY</em>, <em>39</em>(3),
e12787. (<a href="https://doi.org/10.1111/exsy.12787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson&#39;s disease is a degenerative disease that leads to brain disorder and nonfunctioning of different body parts. Deep learning tools like artificial neural network (ANN), convolution neural network (CNN), regression Analysis (RA), and so on, has been considered to a great extent in recent days. Several data sets based on the motor and nonmotor symptoms are applied to different classifier for correct identification of Parkinson&#39;s patient from healthy people. In this paper, hybridization of two deep learning tools such as, RA and ANN are done for effective diagnosis of the disease by probability estimation. The communal merits of individual approaches of the existing approaches are realized in this context for accurate probability estimation. Data preprocessing and probability estimation of preprocessed data is done in RA. The second existing approach is used to identify the PD patient by comparing with a predefined threshold value of a neuron. The estimation is performed on the data set of speech recognition, iron content, and pulse rate among a group of people. The proposed approach is compared with the existing approaches like, SVM and k-NN classifier. The computed result reveals the superiority of the proposed algorithm with 93.46% accuracy.},
  archive      = {J_EXSY},
  author       = {Lipsita Sahu and Rohit Sharma and Ipsita Sahu and Manoja Das and Bandita Sahu and Raghvendra Kumar},
  doi          = {10.1111/exsy.12787},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12787},
  shortjournal = {Expert Syst.},
  title        = {Efficient detection of parkinson&#39;s disease using deep learning techniques over medical data},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid feature selection model based on butterfly
optimization algorithm: COVID-19 as a case study. <em>EXSY</em>,
<em>39</em>(3), e12786. (<a
href="https://doi.org/10.1111/exsy.12786">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The need to evolve a novel feature selection (FS) approach was motivated by the persistence necessary for a robust FS system, the time-consuming exhaustive search in traditional methods, and the favourable swarming manner in various optimization techniques. Most of the datasets have a high dimension in many issues since all features are not crucial to the problem, which reduces the algorithm&#39;s accuracy and efficiency. This article presents a hybrid feature selection approach to solve the low precision and tardy convergence of the butterfly optimization algorithm (BOA). The proposed method is dependent on combining the algorithm of BOA and the particle swarm optimization (PSO) as a search methodology using a wrapper framework. BOA is started with a one-dimensional cubic map in the proposed approach, and a non-linear parameter control technique is also implemented. To boost the basic BOA for global optimization, PSO algorithm is mixed with the butterfly optimization algorithm (BOAPSO). A 25 dataset evaluates the proposed BOAPSO to determine its efficiency with three metrics: classification precision, the selected features, and the computational time. A COVID-19 dataset has been used to evaluate the proposed approach. Compared to the previous approaches, the findings show the supremacy of BOAPSO for enhancing performance precision and minimizing the number of chosen features. Concerning the accuracy, the experimental outcomes demonstrate that the proposed model converges rapidly and performs better than with the PSO, BOA, and GWO with improvement percentages: 91.07%, 87.2%, 87.8%, 87.3%, respectively. Moreover, the proposed model&#39;s average selected features are 5.7 compared to the PSO, BOA, and GWO, with average features 22.5, 18.05, and 23.1, respectively.},
  archive      = {J_EXSY},
  author       = {Ibrahim M. EL-Hasnony and Mohamed Elhoseny and Zahraa Tarek},
  doi          = {10.1111/exsy.12786},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12786},
  shortjournal = {Expert Syst.},
  title        = {A hybrid feature selection model based on butterfly optimization algorithm: COVID-19 as a case study},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybrid diabetes disease prediction framework based on data
imputation and outlier detection techniques. <em>EXSY</em>,
<em>39</em>(3), e12785. (<a
href="https://doi.org/10.1111/exsy.12785">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of medical science, accurate prediction is a difficult and challenging task. But, the presence of missing values and outliers can make the prediction task more complicated. Many researchers address the issue of missing value in medical data, either detect the missing value and delete the respective data instances from the dataset or adopt some default methods such as mean, median, neighbour etc., for filling the missing value. However, both methods are lacking to produce optimal results. Furthermore, outliers are also presented in data and degraded the performance of classifier. Few researchers also focus on the outlier detection in medical dataset, but it is not fully explored till date. This work considers the two well-known problems of data that is, (i) missing value imputation, and (ii) outlier. The missing value imputation issue is addressed through K-Mean ++ based data imputation technique. This technique also validates the data through clustering and also compute the values for missing data. The outlier can be detected through an ABC based outlier detection technique. Further, the final outcome is determined using LS-SVM classifiers. Hence, this work presents a hybrid disease diagnosis framework for diabetes prediction, called hybrid diabetes prediction framework. The reason behind to choose the diabetes dataset for implementation as it contains 763 missing values and several outliers. The simulation results showed that proposed hybrid framework effectively determines the missing values and outliers in diabetes dataset. Further, the performance of proposed hybrid diabetes prediction framework is evaluated using accuracy, sensitivity, specificity, kappa and AUC parameters and compared with 34 state of art techniques. Results confirmed that proposed hybrid framework obtains 96.57%, 93.37%, 98.12%, 98.17%, and 95.43% accuracy, sensitivity, specificity, kappa and AUC rate respectively.},
  archive      = {J_EXSY},
  author       = {Anand Kumar Srivastava and Yugal Kumar and Pradeep Kumar Singh},
  doi          = {10.1111/exsy.12785},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12785},
  shortjournal = {Expert Syst.},
  title        = {Hybrid diabetes disease prediction framework based on data imputation and outlier detection techniques},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Medical informatization of management system for admission
office under convolutional neural network. <em>EXSY</em>,
<em>39</em>(3), e12780. (<a
href="https://doi.org/10.1111/exsy.12780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study aims to construct a client/server model of a three-tier architecture based on the convolutional neural network (CNN), which is responsible for information management in admission office, including eight aspects of the registration management, admission management, prepayment management, inpatient charge management, settlement management, report statistics management, information query management, and help management. The test results of the system show that the management system constructed can run 48 h trouble-free for registration services, no-fee discharge services, inpatient charge services, and settlement services, and the average response time of the system is less than 10 s. The management system constructed for the admission office realizes the medical informatization, and heightens the work efficiency of relevant workers.},
  archive      = {J_EXSY},
  author       = {Guan Wang and Dandan Li and Jinling Ge and Tao Wang},
  doi          = {10.1111/exsy.12780},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12780},
  shortjournal = {Expert Syst.},
  title        = {Medical informatization of management system for admission office under convolutional neural network},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Blockchain technology: A DNN token-based approach in
healthcare and COVID-19 to generate extracted data. <em>EXSY</em>,
<em>39</em>(3), e12778. (<a
href="https://doi.org/10.1111/exsy.12778">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The healthcare technologies in COVID-19 pandemic had grown immensely in various domains. Blockchain technology is one such turnkey technology, which is transforming the data securely; to store electronic health records (EHRs), develop deep learning algorithms, access the data, process the data between physicians and patients to access the EHRs in the form of distributed ledgers. Blockchain technology is also made to supply the data in the cloud and contact the huge amount of healthcare data, which is difficult and complex to process. As the complexity in the analysis of data is increasing day by day, it has become essential to minimize the risk of data complexity. This paper supports deep neural network (DNN) analysis in healthcare and COVID-19 pandemic and gives the smart contract procedure, to identify the feature extracted data (FED) from the existing data. At the same time, the innovation will be useful to analyse future diseases. The proposed method also analyze the existing diseases which had been reported and it is extremely useful to guide physicians in providing appropriate treatment and save lives. To achieve this, the massive data is integrated using Python scripting language under various libraries to perform a wide range of medical and healthcare functions to infer knowledge that assists in the diagnosis of major diseases such as heart disease, blood cancer, gastric and COVID-19.},
  archive      = {J_EXSY},
  author       = {Basetty Mallikarjuna and Gulshan Shrivastava and Meenakshi Sharma},
  doi          = {10.1111/exsy.12778},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12778},
  shortjournal = {Expert Syst.},
  title        = {Blockchain technology: A DNN token-based approach in healthcare and COVID-19 to generate extracted data},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). COVID-19 diagnosis system by deep learning approaches.
<em>EXSY</em>, <em>39</em>(3), e12776. (<a
href="https://doi.org/10.1111/exsy.12776">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The novel coronavirus disease 2019 (COVID-19) has been a severe health issue affecting the respiratory system and spreads very fast from one human to other overall countries. For controlling such disease, limited diagnostics techniques are utilized to identify COVID-19 patients, which are not effective. The above complex circumstances need to detect suspected COVID-19 patients based on routine techniques like chest X-Rays or CT scan analysis immediately through computerized diagnosis systems such as mass detection, segmentation, and classification. In this paper, regional deep learning approaches are used to detect infected areas by the lungs&#39; coronavirus. For mass segmentation of the infected region, a deep Convolutional Neural Network (CNN) is used to identify the specific infected area and classify it into COVID-19 or Non-COVID-19 patients with a full-resolution convolutional network (FrCN). The proposed model is experimented with based on detection, segmentation, and classification using a trained and tested COVID-19 patient dataset. The evaluation results are generated using a fourfold cross-validation test with several technical terms such as Sensitivity, Specificity, Jaccard (Jac.), Dice (F1-score), Matthews correlation coefficient (MCC), Overall accuracy, etc. The comparative performance of classification accuracy is evaluated on both with and without mass segmentation validated test dataset.},
  archive      = {J_EXSY},
  author       = {Hemanta Kumar Bhuyan and Chinmay Chakraborty and Yogesh Shelke and Subhendu Kumar Pani},
  doi          = {10.1111/exsy.12776},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12776},
  shortjournal = {Expert Syst.},
  title        = {COVID-19 diagnosis system by deep learning approaches},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Decision support system for major depression detection using
spectrogram and convolution neural network with EEG signals.
<em>EXSY</em>, <em>39</em>(3), e12773. (<a
href="https://doi.org/10.1111/exsy.12773">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The number of Major Depressive Disorder (MDD) patients is rising rapidly these days following the incidence of COVID-19 pandemic. It is challenging to detect MDD through personal interviews and by observing electroencephalogram (EEG) signals. Hence, an automated MDD detection system developed using deep learning techniques can help reduce the workload of clinicians by diagnosing MDD accurately. In this study, we have proposed a novel deep learning model based on Convolutional Neural Network (CNN) and spectrogram images. In this work, Short-Time Fourier Transform (STFT) is first applied to the EEG signals to obtain spectrogram images of MDD patients and healthy subjects. These spectrogram images are then fed to the CNN model for automated detection of MDD patients and healthy subjects. The EEG signals used in this study were obtained from public database with 34 MDD patients and 30 healthy subjects. The highest classification accuracy, precision, sensitivity, specificity, and F1-score of 99.58%, 99.40%, 99.70%, 99.48%, and 99.55% respectively were obtained with hold-out validation. Our MDD detection model is highly accurate and needs to be validated with more diverse MDD database before it can be used in clinical settings. Also, we plan to use our developed prototype to detect depression using other physiological signals like electrocardiogram (ECG) and speech signals for accurate and faster diagnosis.},
  archive      = {J_EXSY},
  author       = {Hui Wen Loh and Chui Ping Ooi and Emrah Aydemir and Turker Tuncer and Sengul Dogan and U. Rajendra Acharya},
  doi          = {10.1111/exsy.12773},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12773},
  shortjournal = {Expert Syst.},
  title        = {Decision support system for major depression detection using spectrogram and convolution neural network with EEG signals},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimal deep learning based fusion model for biomedical
image classification. <em>EXSY</em>, <em>39</em>(3), e12764. (<a
href="https://doi.org/10.1111/exsy.12764">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated examination of biomedical signals plays a vital role to diagnose diseases and offers useful data to several applications in the areas of physiology, sports medicine, and human–computer interface. The latest advancements in Artificial Intelligence (AI) have the ability to manage and analyse enormous biomedical datasets resulting in clinical decision making and real time applications. At the same time, Colorectal cancer (CRC) is the third most deadly disease affecting people over the globe. The utilization of AI techniques for the earlier identification of CRC has gained significant interest among the research communities. Therefore, this paper presents a novel AI based fusion model for CRC disease diagnosis and classification, named AIFM-CRC. The presented AIFM-CRC model primarily undergoes Gaussian filtering based noise removal and contrast enhancement as a preprocessing stage. In addition, a fusion based feature extraction process takes place where the SIFT based handcrafted features and Inception v4 based deep features are fused together. Besides, whale optimization algorithm tuned deep support vector machine model is employed as a classification technique to determine the existence of CRC. In order to highlight the proficient results analysis of the AIFM-CRC model, a comprehensive simulation analysis takes place. The resultant experimental values pointed out the betterment of the AIFM-CRC model by accomplishing a maximum accuracy of 96.18%.},
  archive      = {J_EXSY},
  author       = {Romany F. Mansour and Nada M. Alfar and Sayed Abdel-Khalek and Maha Abdelhaq and Rashid A. Saeed and Raed Alsaqour},
  doi          = {10.1111/exsy.12764},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12764},
  shortjournal = {Expert Syst.},
  title        = {Optimal deep learning based fusion model for biomedical image classification},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fuzzy logic control theory in clinical anesthesia.
<em>EXSY</em>, <em>39</em>(3), e12761. (<a
href="https://doi.org/10.1111/exsy.12761">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of big data, the application of fuzzy logic control theory to clinical anesthesia will produce more research directions and new technologies. This article mainly studies the application of fuzzy logic control theory in clinical anesthesia. First, after introducing the basic content of fuzzy logic control theory, the determination method of commonly used membership functions, the relevant knowledge of clinical anesthesia, and the fuzzy logic code rate control model, this article describes in detail the basic principle diagram of the clinical anesthesia control system and the clinical anesthesia process Mechanism model. The mathematical model of clinical anesthesia control system is constructed based on the data fusion technology of the parameters of anesthesia depth monitoring. The parameters in the model are adjusted by the time domain analysis method to measure the dynamic characteristics, and the stability of the system is analyzed by root locus method. The heart rate does not change significantly when it is lower than 1 MAC, and the heart rate increases when it reaches 1.5–2 MAC. Experimental results show that the application of fuzzy logic control theory to clinical anesthesia can reduce the risk of clinical anesthesia.},
  archive      = {J_EXSY},
  author       = {Ye Tian and Zheng Chu and Gang Ma},
  doi          = {10.1111/exsy.12761},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12761},
  shortjournal = {Expert Syst.},
  title        = {Fuzzy logic control theory in clinical anesthesia},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). HSV model-based segmentation driven facial acne detection
using deep learning. <em>EXSY</em>, <em>39</em>(3), e12760. (<a
href="https://doi.org/10.1111/exsy.12760">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acne is a skin disease mainly caused by bacteria, the hair follicles exposed to oil, and dying skin cells. These sometimes trigger whiteheads, blackheads or pimples, usually on the neck, arms, arm and back of shoulders. Acne in adolescents is the most severe, even though it affects people of any generation. Doctors can easily detect acne by seeing a patient&#39;s skin, but automatic acne detection is not easy for machines. Deep learning (DL) approaches have been quite successful for various aspects like classification and detection of objects in real life. This paper proposes an enhanced DL CNN model with the Leaky ReLU activation function. DermNet NZ&#39;s facial acne images dataset is used for the experiments. Three different techniques- K-Means, Texture Analysis and HSV Model-Based Segmentation, are applied for image segmentation to extract the acne region from skin images. After applying all the above image segmentation methods five times for each method, output images from K-Means and HSV (5 + 5 images) are collected and combined with the dataset. Using that dataset, one SVM model using Scikit-learn and two CNN models- one with the ReLU activation function and another with the LeakyReLU activation function, is trained. Out of these three models, the proposed CNN (LeakyReLU) model achieved a 97.54% accuracy.},
  archive      = {J_EXSY},
  author       = {Neha Yadav and Sk Md Alfayeed and Aditya Khamparia and Babita Pandey and Dang N. H. Thanh and Sagar Pande},
  doi          = {10.1111/exsy.12760},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12760},
  shortjournal = {Expert Syst.},
  title        = {HSV model-based segmentation driven facial acne detection using deep learning},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Review on COVID-19 diagnosis models based on machine
learning and deep learning approaches. <em>EXSY</em>, <em>39</em>(3),
e12759. (<a href="https://doi.org/10.1111/exsy.12759">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 is the disease evoked by a new breed of coronavirus called the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). Recently, COVID-19 has become a pandemic by infecting more than 152 million people in over 216 countries and territories. The exponential increase in the number of infections has rendered traditional diagnosis techniques inefficient. Therefore, many researchers have developed several intelligent techniques, such as deep learning (DL) and machine learning (ML), which can assist the healthcare sector in providing quick and precise COVID-19 diagnosis. Therefore, this paper provides a comprehensive review of the most recent DL and ML techniques for COVID-19 diagnosis. The studies are published from December 2019 until April 2021. In general, this paper includes more than 200 studies that have been carefully selected from several publishers, such as IEEE, Springer and Elsevier. We classify the research tracks into two categories: DL and ML and present COVID-19 public datasets established and extracted from different countries. The measures used to evaluate diagnosis methods are comparatively analysed and proper discussion is provided. In conclusion, for COVID-19 diagnosing and outbreak prediction, SVM is the most widely used machine learning mechanism, and CNN is the most widely used deep learning mechanism. Accuracy, sensitivity, and specificity are the most widely used measurements in previous studies. Finally, this review paper will guide the research community on the upcoming development of machine learning for COVID-19 and inspire their works for future development. This review paper will guide the research community on the upcoming development of ML and DL for COVID-19 and inspire their works for future development.},
  archive      = {J_EXSY},
  author       = {Zaid Abdi Alkareem Alyasseri and Mohammed Azmi Al-Betar and Iyad Abu Doush and Mohammed A. Awadallah and Ammar Kamal Abasi and Sharif Naser Makhadmeh and Osama Ahmad Alomari and Karrar Hameed Abdulkareem and Afzan Adam and Robertas Damasevicius and Mazin Abed Mohammed and Raed Abu Zitar},
  doi          = {10.1111/exsy.12759},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12759},
  shortjournal = {Expert Syst.},
  title        = {Review on COVID-19 diagnosis models based on machine learning and deep learning approaches},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Endoscopic image recognition method of gastric cancer based
on deep learning model. <em>EXSY</em>, <em>39</em>(3), e12758. (<a
href="https://doi.org/10.1111/exsy.12758">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The combination of computer algorithms to diagnose clinical images has attracted more and more attention. This research aims to improve the efficiency of gastric cancer (GC) diagnosis, so deep learning (DL) algorithms are tentatively used to assist doctors in the diagnosis of gastric cancer. In the experiment, the collected 3591 gastroscopic images were divided into network training set and experimental verification test set. The lesion samples in the image are all marked by many endoscopists with many years of clinical experience. In order to improve the experimental effect, 5261 endoscopic images were obtained by expanding the training set. Then the obtained training set is input into the convolutional neural network (CNN) for training, and finally get the algorithm model DLU-Net. By inputting 598 test set samples into the CNN constructed in this paper, five results such as advanced GC, early GC, precancerous lesions, normal and benign lesions can be identified and output, with a total accuracy of 94.1%. It can be concluded that the DL algorithm model constructed in this paper can effectively identify the staging characteristics of cancer as well as gastroscopic images, greatly improve efficiency, and effectively assist physicians in the diagnosis of GC under gastroscopy.},
  archive      = {J_EXSY},
  author       = {Wengang Qiu and Jun Xie and Yi Shen and Jiang Xu and Jun Liang},
  doi          = {10.1111/exsy.12758},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12758},
  shortjournal = {Expert Syst.},
  title        = {Endoscopic image recognition method of gastric cancer based on deep learning model},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automated COVID-19 detection in chest x-ray images using
fine-tuned deep learning architectures. <em>EXSY</em>, <em>39</em>(3),
e12749. (<a href="https://doi.org/10.1111/exsy.12749">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic has a significant impact on human health globally. The illness is due to the presence of a virus manifesting itself in a widespread disease resulting in a high mortality rate in the whole world. According to the study, infected patients have distinct radiographic visual characteristics as well as dry cough, breathlessness, fever, and other symptoms. Although, the reverse transcription polymerase-chain reaction (RT-PCR) test has been used for COVID-19 testing its reliability is very low. Therefore, computed tomography and X-ray images have been widely used. Artificial intelligence coupled with X-ray technologies has recently shown to be more effective in the diagnosis of this disease. With this motivation, a comparative analysis of fine-tuned deep learning architectures has been made to speed up the detection and classification of COVID-19 patients from other pneumonia groups. The models used for this analysis are MobileNetV2, ResNet50, InceptionV3, NASNetMobile, VGG16, Xception, InceptionResNetV2 DenseNet121, which have been fine-tuned using a new set of layers replaced with the head of the network. This research work has carried out an analysis on two datasets. Dataset-1 includes the images of three classes: Normal, COVID, and Pneumonia. Dataset-2, in contrast, contains the same classes with more focus on two prominent pneumonia categories: bacterial pneumonia and viral pneumonia. The research was conducted on 959 X-ray images (250 of Bacterial Pneumonia, 250 of Viral Pneumonia, 209 of COVID, and 250 of Normal cases). Using the confusion matrix, the required results of different models have been computed. For the first dataset, DenseNet121 has obtained a 97% accuracy, while for the second dataset, MobileNetV2 has performed best with an accuracy of 81%.},
  archive      = {J_EXSY},
  author       = {Sonam Aggarwal and Sheifali Gupta and Adi Alhudhaif and Deepika Koundal and Rupesh Gupta and Kemal Polat},
  doi          = {10.1111/exsy.12749},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12749},
  shortjournal = {Expert Syst.},
  title        = {Automated COVID-19 detection in chest X-ray images using fine-tuned deep learning architectures},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Value of medical imaging artificial intelligence in the
diagnosis and treatment of new coronavirus pneumonia. <em>EXSY</em>,
<em>39</em>(3), e12740. (<a
href="https://doi.org/10.1111/exsy.12740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of computer technology is becoming more and more mature. The application of artificial intelligence to the medical field has made important contributions to medical diagnosis and auxiliary detection. Using the powerful computing power of computers to replace humans in the automatic diagnosis of complex diseases has been enthusiastic by the majority of scientific researchers. In the current medical imaging diagnosis system, the location of the lesion is mainly found by observing the two-dimensional medical image sequence, and the signs of biological information cannot be accurately displayed. Through medical image analysis technology, two-dimensional images will be divided into three-dimensional models after image segmentation, image recognition, and three-dimensional imaging. In this way, it seems that the doctor can “hold the image volume data,” which can greatly improve the scientific and accurate diagnosis. Sex—this article applies artificial intelligence to medical imaging, combined with embedded technology, RFID technology and signal processing technology, and applies the new coronavirus pneumonia image to the artificial intelligence environment after processing, assisting doctors in diagnosis of the disease, and providing relevant information about patients record and manage the diagnosis and diagnosis, save and accumulate the experience and knowledge of famous doctors through the expert system, and then perform corresponding operations and analysis. Through the medical image intelligent analysis system, the safety risk of medical imaging artificial intelligence diagnosis is reduced from 81% to 11%, which greatly reduces the hidden safety hazards for doctors and patients, reduces the workload of doctors, and also reduces the cost of medical care by 79% It is reduced to 20%, which reduces the waiting time of patients and achieves the purpose of improving the accuracy of diagnosis.},
  archive      = {J_EXSY},
  author       = {Shouqin Jia and Ying Wang and Wuzhang Wang and Qiang Zhang and Xu Zhang},
  doi          = {10.1111/exsy.12740},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12740},
  shortjournal = {Expert Syst.},
  title        = {Value of medical imaging artificial intelligence in the diagnosis and treatment of new coronavirus pneumonia},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning-based scheme to diagnose parkinson’s disease.
<em>EXSY</em>, <em>39</em>(3), e12739. (<a
href="https://doi.org/10.1111/exsy.12739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson&#39;s disease (PD) is a neurological disorder of the central nervous system that causes difficulty in movement, often including tremors and rigidity. Early detection of PD can prevent symptoms up to a certain age and increase life expectancy. For this purpose, we have used brain images from magnetic resonance imaging (MRI) technique. A deeper level of feature detection in MRI can identify biomarkers that can be used to know how the disease spreads, leading to a cure in the future. With these motives, we have presented two novel approaches using deep learning (DL) techniques. 2D and 3D convolution neural networks (CNN) are used, which are trained on MRI scans in the axial plane. The dataset was constructed using images from Parkinson&#39;s progression markers initiative (PPMI). The four pre-processing techniques used in this article are bias field correction, histogram matching, Z -score normalization, and image resizing. Pre-processing techniques were essential inaccurate training models. Every class prediction done by the model would have taken multiple features into account across multiple layers of the brain and not relied on a single or few important features, making DL a powerful concept. A total of 318 MRI scans were used to train and test a 2D CNN and a 3D CNN model. We have compared the models&#39; results using different evaluation parameters such as accuracy, loss, confusion matrix, receiver operating characteristic (ROC) curve, and precision-recall (PR) curve. The 3D model learned key features from the data and was able to classify the test data with 88.9% accuracy with 0.86 area under curve (AUC). In contrast, the 2D model achieved a mediocre accuracy of 72.22% with 0.50 AUC. This shows that the 3D model is more accurate and reliable than the 2D model.},
  archive      = {J_EXSY},
  author       = {Tarjni Vyas and Raj Yadav and Chitra Solanki and Rutvi Darji and Shivani Desai and Sudeep Tanwar},
  doi          = {10.1111/exsy.12739},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12739},
  shortjournal = {Expert Syst.},
  title        = {Deep learning-based scheme to diagnose parkinson&#39;s disease},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A knowledge-based self-pre-diagnosis system to predict
covid-19 in smartphone users using personal data and observed symptoms.
<em>EXSY</em>, <em>39</em>(3), e12716. (<a
href="https://doi.org/10.1111/exsy.12716">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Covid-19 is an acute respiratory infection and presents various clinical features ranging from no symptoms to severe pneumonia and death. Medical expert systems, especially in diagnosis and monitoring stages, can give positive consequences in the struggle against Covid-19. In this study, a rule-based expert system is designed as a predictive tool in self-pre-diagnosis of Covid-19. The potential users are smartphone users, healthcare experts and government health authorities. The system does not only share the data gathered from the users with experts, but also analyzes the symptom data as a diagnostic assistant to predict possible Covid-19 risk. To do this, a user needs to fill out a patient examination card that conducts an online Covid-19 diagnostic test, to receive an unconfirmed online test prediction result and a set of precautionary and supportive action suggestions. The system was tested for 169 positive cases. The results produced by the system were compared with the real PCR test results for the same cases. For patients with certain symptomatic findings, there was no significant difference found between the results of the system and the confirmed test results with PCR test. Furthermore, a set of suitable suggestions produced by the system were compared with the written suggestions of a collaborated health expert. The suggestions deduced and the written suggestions of the health expert were similar and the system suggestions in line with suggestions of the expert. The system can be suitable for diagnosing and monitoring of positive cases in the areas other than clinics and hospitals during the Covid-19 pandemic. The results of the case studies are promising, and it demonstrates the applicability, effectiveness, and efficiency of the proposed approach in all communities.},
  archive      = {J_EXSY},
  author       = {Duygu Çelik Ertuğrul and Demet Çelik Ulusoy},
  doi          = {10.1111/exsy.12716},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12716},
  shortjournal = {Expert Syst.},
  title        = {A knowledge-based self-pre-diagnosis system to predict covid-19 in smartphone users using personal data and observed symptoms},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pandemic coronavirus disease (covid-19): World effects
analysis and prediction using machine-learning techniques.
<em>EXSY</em>, <em>39</em>(3), e12714. (<a
href="https://doi.org/10.1111/exsy.12714">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pandemic novel Coronavirus (Covid-19) is an infectious disease that primarily spreads by droplets of nose discharge when sneezing and saliva from the mouth when coughing, that had first been reported in Wuhan, China in December 2019. Covid-19 became a global pandemic, which led to a harmful impact on the world. Many predictive models of Covid-19 are being proposed by academic researchers around the world to take the foremost decisions and enforce the appropriate control measures. Due to the lack of accurate Covid-19 records and uncertainty, the standard techniques are being failed to correctly predict the epidemic global effects. To address this issue, we present an Artificial Intelligence (AI)-based meta-analysis to predict the trend of epidemic Covid-19 over the world. The powerful machine learning algorithms namely Naïve Bayes, Support Vector Machine (SVM) and Linear Regression were applied on real time-series dataset, which holds the global record of confirmed, recovered, deaths and active cases of Covid-19 outbreak. Statistical analysis has also been conducted to present various facts regarding Covid-19 observed symptoms, a list of Top-20 Coronavirus affected countries and a number of coactive cases over the world. Among the three machine learning techniques investigated, Naïve Bayes produced promising results to predict Covid-19 future trends with less Mean Absolute Error (MAE) and Mean Squared Error (MSE). The less value of MAE and MSE strongly represent the effectiveness of the Naïve Bayes regression technique. Although, the global footprint of this pandemic is still uncertain. This study demonstrates the various trends and future growth of the global pandemic for a proactive response from the citizens and governments of countries. This paper sets the initial benchmark to demonstrate the capability of machine learning for outbreak prediction.},
  archive      = {J_EXSY},
  author       = {Dimple Tiwari and Bhoopesh Singh Bhati and Fadi Al-Turjman and Bharti Nagpal},
  doi          = {10.1111/exsy.12714},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12714},
  shortjournal = {Expert Syst.},
  title        = {Pandemic coronavirus disease (Covid-19): World effects analysis and prediction using machine-learning techniques},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A scalable framework for smart COVID surveillance in the
workplace using deep neural networks and cloud computing. <em>EXSY</em>,
<em>39</em>(3), e12704. (<a
href="https://doi.org/10.1111/exsy.12704">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A smart and scalable system is required to schedule various machine learning applications to control pandemics like COVID-19 using computing infrastructure provided by cloud and fog computing. This paper proposes a framework that considers the use case of smart office surveillance to monitor workplaces for detecting possible violations of COVID effectively. The proposed framework uses deep neural networks, fog computing and cloud computing to develop a scalable and time-sensitive infrastructure that can detect two major violations: wearing a mask and maintaining a minimum distance of 6 feet between employees in the office environment. The proposed framework is developed with the vision to integrate multiple machine learning applications and handle the computing infrastructures for pandemic applications. The proposed framework can be used by application developers for the rapid development of new applications based on the requirements and do not worry about scheduling. The proposed framework is tested for two independent applications and performed better than the traditional cloud environment in terms of latency and response time. The work done in this paper tries to bridge the gap between machine learning applications and their computing infrastructure for COVID-19.},
  archive      = {J_EXSY},
  author       = {Ajay Singh and Vaibhav Jindal and Rajinder Sandhu and Victor Chang},
  doi          = {10.1111/exsy.12704},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12704},
  shortjournal = {Expert Syst.},
  title        = {A scalable framework for smart COVID surveillance in the workplace using deep neural networks and cloud computing},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fruit category classification by fractional fourier entropy
with rotation angle vector grid and stacked sparse autoencoder.
<em>EXSY</em>, <em>39</em>(3), e12701. (<a
href="https://doi.org/10.1111/exsy.12701">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EXSY},
  author       = {Yu-Dong Zhang and Suresh Chandra Satapathy and Shui-Hua Wang},
  doi          = {10.1111/exsy.12701},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12701},
  shortjournal = {Expert Syst.},
  title        = {Fruit category classification by fractional fourier entropy with rotation angle vector grid and stacked sparse autoencoder},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). P-SCADA - a novel area and energy efficient FPGA
architectures for LSTM prediction of heart arrthymias in biot
applications. <em>EXSY</em>, <em>39</em>(3), e12687. (<a
href="https://doi.org/10.1111/exsy.12687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recurrent neural networks (RNN) are extensively used to determine the optimal solutions to the various class recognition problems such as image processing, prediction of biomedical data and speech recognition. With the gradient problems, RNN is slowing losing its shade which is replaced by the Long short term memory (LSTM). However the hardware implementation of the LSTM requires more challenge due to its complexity and high power consumption which makes it unsuitable for implementing in Biological Internet of things networks for prediction of heart diseases. Several algorithms were proposed for an effective implementation of LSTM, but hand-offs between the performance and utilization still needs improvisation. The paper proposes the novel energy efficient and high performance architecture Pipelined Stochastic Adaptive Distributed Architectures (P-SCADA) for LSTM networks. In this architecture, hybrid structure has been developed with the help of new distributed arithmetic stochastic computing (DSC) along with the binary circuits to advance the performance of the FPGA such as energy, area and accuracy. The proposed system has been implemented in ARTIX-7 FPGA with special purpose software has been designed and evaluated with different ECG datasets. For the different series data, area utilization is about 40%–44% and power consumption is about 20%–25% with the prediction of accuracy of 98%. Moreover the proposed architecture has been compared with the other existing architecture such as SPARSE architectures, normal stochastic architectures in which the proposed architecture excels in terms area, power and efficiency.},
  archive      = {J_EXSY},
  author       = {Senthil Kumaran Varadharajan and Viswanathan Nallasamy},
  doi          = {10.1111/exsy.12687},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12687},
  shortjournal = {Expert Syst.},
  title        = {P-SCADA - a novel area and energy efficient FPGA architectures for LSTM prediction of heart arrthymias in biot applications},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An impact study of COVID-19 on six different industries:
Automobile, energy and power, agriculture, education, travel and tourism
and consumer electronics. <em>EXSY</em>, <em>39</em>(3), e12677. (<a
href="https://doi.org/10.1111/exsy.12677">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent outbreak of a novel coronavirus, named COVID-19 by the World Health Organization (WHO) has pushed the global economy and humanity into a disaster. In their attempt to control this pandemic, the governments of all the countries have imposed a nationwide lockdown. Although the lockdown may have assisted in limiting the spread of the disease, it has brutally affected the country, unsettling complete value-chains of most important industries. The impact of the COVID-19 is devastating on the economy. Therefore, this study has reported about the impact of COVID-19 epidemic on various industrial sectors. In this regard, the authors have chosen six different industrial sectors such as automobile, energy and power, agriculture, education, travel and tourism and consumer electronics, and so on. This study will be helpful for the policymakers and government authorities to take necessary measures, strategies and economic policies to overcome the challenges encountered in different sectors due to the present pandemic.},
  archive      = {J_EXSY},
  author       = {Janmenjoy Nayak and Manohar Mishra and Bighnaraj Naik and Hanumanthu Swapnarekha and Korhan Cengiz and Vimal Shanmuganathan},
  doi          = {10.1111/exsy.12677},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12677},
  shortjournal = {Expert Syst.},
  title        = {An impact study of COVID-19 on six different industries: Automobile, energy and power, agriculture, education, travel and tourism and consumer electronics},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Prediction of COVID-19 active cases using exponential and
non-linear growth models. <em>EXSY</em>, <em>39</em>(3), e12648. (<a
href="https://doi.org/10.1111/exsy.12648">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {World Health Organization recognized COVID-19 as a pandemic on March 11, 2020. A total of 213 countries and territories around the world have reported a total of 27,948,441 confirmed cases as on September 9, 2020. This article adopted two non-linear growth models (Gompertz, Verhulst) and exponential model (SIR) to analyse the coronavirus pandemic across the world. All the models have been used for active COVID-19 patients predictions based on the data collected from John Hopkins University repository in the time period of January 30, 2020 to June 4, 2020. Outbreak of COVID-19 disease has been analysed for India, Pakistan, Myanmar (Burma), Brazil, Italy and Germany till June 4, 2020 and predictions have been made for the number of positive cases for the next 28 days. Verhulst model fitting effect is better than Gompertz and SIR model with R -score 0.9973. The proposed model perform better as compare to other three existing models with R -score 0.9981.These above models can be adapted to forecast in long term intervals, based on the predictions for a short interval as of June 5, 2020 and June 30, 2020, active COVID-19 patients for India, Pakistan, Italy, Germany, Brazil and Myanmar predicted as (236,170, 88,998, 234,066, 184,922, 645,057 and 235) and (486,357, 218,864, 240,545, 193,727, 1,211,567 and 309).},
  archive      = {J_EXSY},
  author       = {Chandrakanta Mahanty and Raghvendra Kumar and Brojo Kishore Mishra and D. Jude Hemanth and Deepak Gupta and Ashish Khanna},
  doi          = {10.1111/exsy.12648},
  journal      = {Expert Systems},
  month        = {3},
  number       = {3},
  pages        = {e12648},
  shortjournal = {Expert Syst.},
  title        = {Prediction of COVID-19 active cases using exponential and non-linear growth models},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Special issue on big data in transportation. <em>EXSY</em>,
<em>39</em>(2), e12931. (<a
href="https://doi.org/10.1111/exsy.12931">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EXSY},
  author       = {Baloka Belezamo and Süleyman Eken and Cafer Avcı},
  doi          = {10.1111/exsy.12931},
  journal      = {Expert Systems},
  month        = {2},
  number       = {2},
  pages        = {e12931},
  shortjournal = {Expert Syst.},
  title        = {Special issue on big data in transportation},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improved detection of small objects in road network
sequences using CNN and super resolution. <em>EXSY</em>, <em>39</em>(2),
e12930. (<a href="https://doi.org/10.1111/exsy.12930">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of small objects is one of the problems present in deep learning due to the context of the scene or the low number of pixels of the objects to be detected. According to these problems, current pre-trained models based on convolutional neural networks usually give a poor average precision, highlighting some as CenterNet HourGlass104 with a mean average precision of 25.6%, or SSD-512 with 9%. This work focuses on the detection of small objects. In particular, our proposal aims to vehicle detection from images captured by video surveillance cameras with pre-trained models without modifying their structures, so it does not require retraining the network to improve the detection rate of the elements. For better performance, a technique has been developed which, starting from certain initial regions, detects a higher number of objects and improves their class inference without modifying or retraining the network. The neural network is integrated with processes that are in charge of increasing the resolution of the images to improve the object detection performance. This solution has been tested for a set of traffic images containing elements of different scales to check the efficiency depending on the detections obtained by the model. Our proposal achieves good results in a wide range of situations, obtaining, for example, an average score of 45.1% with the EfficientDet-D4 model for the first video sequence, compared to the 24.3% accuracy initially provided by the pre-trained model.},
  archive      = {J_EXSY},
  author       = {Iván García-Aguilar and Rafael Marcos Luque-Baena and Ezequiel López-Rubio},
  doi          = {10.1111/exsy.12930},
  journal      = {Expert Systems},
  month        = {2},
  number       = {2},
  pages        = {e12930},
  shortjournal = {Expert Syst.},
  title        = {Improved detection of small objects in road network sequences using CNN and super resolution},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Expert systems and risk analytics in service engineering.
<em>EXSY</em>, <em>39</em>(2), e12909. (<a
href="https://doi.org/10.1111/exsy.12909">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EXSY},
  author       = {Desheng Dash Wu and Jon Hall},
  doi          = {10.1111/exsy.12909},
  journal      = {Expert Systems},
  month        = {2},
  number       = {2},
  pages        = {e12909},
  shortjournal = {Expert Syst.},
  title        = {Expert systems and risk analytics in service engineering},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spherical fuzzy extension of AHP-ARAS methods integrated
with modified k-means clustering for logistics hub location problem.
<em>EXSY</em>, <em>39</em>(2), e12886. (<a
href="https://doi.org/10.1111/exsy.12886">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Like most other industries, logistics services are currently encountering enormous transformation. Many companies worldwide are applying big data analytics to implement operational strategies and facilitate location selection. Logistics companies need to focus on now and explore some futures of logistics hub location problems. Creating a profitable logistic network is a crucial task for airline and postal services. To establish a cost-effective network, transportation expenses should be decreased, and networks should be simplified. Hub location problem is born out of these needs. The concept of hub cumulates the flows and makes networks more reliable. In this article, a novel hub location selection approach is introduced in a group decision making (GDM) environment with uncertainty by integrating a modified weighted k-means clustering algorithm with multi-criteria decision-making (MCDM) tools. The combined MCDM method integrates analytic hierarchy process (AHP) to measure criteria weights and Additive Ratio Assessment technique to measure the performance of hub location alternatives in a spherical fuzzy set (SFS) environment. The SFS has shown definite advantages in handling vagueness and uncertainty over crisp, fuzzy, or intuitionistic fuzzy sets to depict experts&#39; evaluations with a richer structure, allowing for more representative decision making. Using Turkish logistics data, big data algorithm facilitates 15 possible locations, and these sites are ranked in order by the integrated GDM methodology. The validation of the proposed evaluation model is illustrated in an application of the network structure in Turkey. Finally, sensitivity and comparison evaluations are introduced to demonstrate the feasibility and effectiveness of the proposed approach.},
  archive      = {J_EXSY},
  author       = {Fethullah Gocer and Nazmi Sener},
  doi          = {10.1111/exsy.12886},
  journal      = {Expert Systems},
  month        = {2},
  number       = {2},
  pages        = {e12886},
  shortjournal = {Expert Syst.},
  title        = {Spherical fuzzy extension of AHP-ARAS methods integrated with modified k-means clustering for logistics hub location problem},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Regional-based multi-module spatial–temporal networks
predicting city-wide taxi pickup/dropoff demand from origin to
destination. <em>EXSY</em>, <em>39</em>(2), e12883. (<a
href="https://doi.org/10.1111/exsy.12883">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Taxi demand forecasting from origin to destination (OD) is an important component in managing public transportation needs on a city-wide scale. Accurate taxi demand forecasting may provide several benefits, including economic and traffic flow optimization. However, due to complicated spatial–temporal connections and irregular distant locations, predicting taxi demand becomes difficult. To address these issues, we proposed a novel architecture of multi-module spatial–temporal networks to collectively predict city-wide OD taxi demand. In our work to deal with adjacent areas in a city, we employed the 3D convolutional neural networks to extract the spatial–temporal dependencies and learn the OD taxi demand pattern. To handle remote areas, we created an attention-based auto encoder-decoder, in which the input of the set of convolutional layers creates a feature matrix. The feature matrix embeds the spatial–temporal correlation jointly and passing through the encoder layer. We encode the spatial–temporal features with the help of pooling layer, then flatten layer used the back-propagation method to decode the weight matrix. We apply the normalization function to determine the demand pattern influences. The influence vector we compute with the Euclidean distance formula to determine the similarity of all distant regions. Finally, we use the attention mechanism to calculate the attention weight score for each region that its neighbour impacted. Then we used long short-term memory, we captured the significant relationship of spatial–temporal dependencies with external factors. We train our model simultaneously to forecast city-wide taxi services OD. We have performed comprehensive experiments and large-scale dataset comparisons that reveal the taxi demand prediction problem.},
  archive      = {J_EXSY},
  author       = {Zain Ul Abideen and Heli Sun and Zhou Yang and Hamza Fahim},
  doi          = {10.1111/exsy.12883},
  journal      = {Expert Systems},
  month        = {2},
  number       = {2},
  pages        = {e12883},
  shortjournal = {Expert Syst.},
  title        = {Regional-based multi-module spatial–temporal networks predicting city-wide taxi pickup/dropoff demand from origin to destination},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A horizontal partitioning-based method for frequent pattern
mining in transport timetable. <em>EXSY</em>, <em>39</em>(2), e12881.
(<a href="https://doi.org/10.1111/exsy.12881">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analysing transport timetables is an important task, as it brings the opportunity to discover which routes commonly lead to delays. Frequent pattern mining is a technique used to support such type of discovery. However, functional dependencies are intrinsic properties present in timetables, particularly related to attributes derived from the origin–destination matrix. Such functional dependencies compromise the search for patterns in timetables in both the number of association rules (ARs) generated and the computational cost. Several of these ARs refer to the same information. Redundancy removal techniques can reduce the number of ARs. However, these techniques are designed to be used after mining finishes, which increases the computational cost of finding useful ARs. This work presents timetable pattern mining (T-mine), a novel method for frequent pattern mining that improves knowledge discovery in timetables. We evaluated T-mine using Brazilian Flight Data and compared T-mine with the direct application of frequent pattern mining approaches with and without functional dependencies. Our experiments indicate that T-mine is about one order magnitude faster than other methods with functional dependencies.},
  archive      = {J_EXSY},
  author       = {Claudio Teixeira and Luana Fragoso and Marta Mattoso and Diego Carvalho and Eduardo Bezerra and Jorge Soares and Glauco Amorim and Eduardo Ogasawara},
  doi          = {10.1111/exsy.12881},
  journal      = {Expert Systems},
  month        = {2},
  number       = {2},
  pages        = {e12881},
  shortjournal = {Expert Syst.},
  title        = {A horizontal partitioning-based method for frequent pattern mining in transport timetable},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improved multi-criteria group decision-making method
considering hesitant fuzzy preference relations with self-confidence
behaviours for environmental pollution emergency response process
evaluation. <em>EXSY</em>, <em>39</em>(2), e12866. (<a
href="https://doi.org/10.1111/exsy.12866">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Environmental pollution is one of the major challenges in China, which seriously affects people&#39;s life, economy and society. This paper proposes a multi-criteria group decision-making method based on hesitant fuzzy preference relations with self-confidence (HFPRs-SC) behaviours and applies it to the evaluation of the environmental pollution emergency response process. Firstly, a comprehensive evaluation system is proposed that covers the environmental pollution emergency response process. Moreover, is utilized to obtain the normalized hesitant fuzzy preference relationship, and an algorithm that considers both the hesitant fuzzy preference value and the self-confidence level is proposed to improve the consistency of HFPRs-SC. In addition, combined with subjective and objective weights of experts, a weighted average operator based on the confidence level is applied to aggregate individual HFPR-SC. Furthermore, the score function of HFPRs-SC is designed to get the best ranking. Finally, a case study on an explosion accident in Fujian Province of China is conducted to verify the practicability and effectiveness of the proposed method with comparative analysis and sensitivity analysis. Based on the analysis, some suggestions are put forward for improving environmental pollution emergency response.},
  archive      = {J_EXSY},
  author       = {Jun Liu and Shengkai Zhang and Yan Tu and Liang Li and Zongmin Li},
  doi          = {10.1111/exsy.12866},
  journal      = {Expert Systems},
  month        = {2},
  number       = {2},
  pages        = {e12866},
  shortjournal = {Expert Syst.},
  title        = {Improved multi-criteria group decision-making method considering hesitant fuzzy preference relations with self-confidence behaviours for environmental pollution emergency response process evaluation},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Attention deep learning-based large-scale learning
classifier for cassava leaf disease classification. <em>EXSY</em>,
<em>39</em>(2), e12862. (<a
href="https://doi.org/10.1111/exsy.12862">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cassava is a rich source of carbohydrates, and it is vulnerable to virus diseases. Literature survey shows that the image recognition and integrated deep learning approach is successfully employed for Cassava leaf disease classification. Mostly, transfer learning based on a convolutional neural network (CNN) models were successfully applied for Cassava leaf disease classification. However, existing approaches are not effective in identifying the tiny portion of the disease in the overall leaf area. Identifying and focussing on regions affected by the disease is vital to achieving a good classification accuracy. An attention-based approach is integrated into pretrained CNN-based EfficientNet models to locate and identify the tiny infected regions in Cassava leaf. Penultimate layer features of attention-based EfficientNet models such as A_EfficientNetB4, A_EfficientNetB5, and A_EfficientNetB6 were extracted. Next, the dimensionality of the extracted features was reduced using kernel principal component analysis. The reduced features were fused and passed into a stacked ensemble meta-classifier for Cassava leaf disease classification. A stacked ensemble meta-classifier is a two-stage approach in which the first stage employs random forest and support vector machine (SVM) for prediction followed by logistic regression for classification. Detailed investigation and analysis of the proposed method, attention, and non-attention-based approaches with CNN pretrained models were tested using a publicly available benchmark dataset of Cassava leaf disease images. The proposed method achieved better performances in all experiments than several existing methods as well as various attention and non-attention-based CNN pretrained models. The proposed approach can be used as a deployable tool for Cassava leaf disease classification in agricultural field.},
  archive      = {J_EXSY},
  author       = {Vinayakumar Ravi and Vasundhara Acharya and Tuan D. Pham},
  doi          = {10.1111/exsy.12862},
  journal      = {Expert Systems},
  month        = {2},
  number       = {2},
  pages        = {e12862},
  shortjournal = {Expert Syst.},
  title        = {Attention deep learning-based large-scale learning classifier for cassava leaf disease classification},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RDOF: An outlier detection algorithm based on relative
density. <em>EXSY</em>, <em>39</em>(2), e12859. (<a
href="https://doi.org/10.1111/exsy.12859">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An outlier has a significant impact on data quality and the efficiency of data mining. The outlier identification algorithm observes only data points that do not follow clearly defined meanings of projected behaviour in a data set. Several techniques for identifying outliers have been presented in recent years, but if outliers are located in areas where neighbourhood density varies substantially, it can result in an imprecise estimate. To address this problem, we provide a ‘Relative Density-based Outlier Factor (RDOF)’ algorithm based on the concept of mutual proximity between a data point and its neighbours. The proposed approach is divided into two stages: an influential space is created at a test point in the first stage. In the later stage, a test point is assigned an outlier-ness score. We have conducted experiments on three real-world data sets, namely the Johns Hopkins University Ionosphere, the Iris Plant, and Wisconsin Breast Cancer data sets. We have investigated three performance metrics for comparison: precision, recall, and rank power. In addition, we have compared our proposed method against a set of relevant baseline methods. The experimental results reveal that our proposed method detected all (i.e., 100%) outlier class objects with higher rank power than baseline approaches over these experimental data sets.},
  archive      = {J_EXSY},
  author       = {Abdul Wahid and Annavarapu Chandra Sekhara Rao},
  doi          = {10.1111/exsy.12859},
  journal      = {Expert Systems},
  month        = {2},
  number       = {2},
  pages        = {e12859},
  shortjournal = {Expert Syst.},
  title        = {RDOF: An outlier detection algorithm based on relative density},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-view rank-based random forest: A new algorithm for
prediction in eSports. <em>EXSY</em>, <em>39</em>(2), e12857. (<a
href="https://doi.org/10.1111/exsy.12857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main problem associated with the random forest (RF) algorithm is its application of random feature subset selection technique over a single vector. In this technique, the irrelevant or redundant features in a single-view data have equal chances with the important features to be selected for training a classifier, leading to misclassification. To overcome this problem, this article proposes a novel algorithm, called multi-view rank-based random forest (MVRRF). The proposed algorithm builds a set of decision trees from multi-view data by using a rank-based feature selection strategy. The main advantages of our method are that (i) it extends the RF algorithm for multi-view learning, and (ii) it reduces the chances of irrelevant and redundant feature selection, and thus it usually improves the accuracy, generalizability and robustness of the classification models. The aim of our study is to predict the match result of the game League of Legends in electronic sports (eSports). Thus, the eSports teams can define trustworthy strategies through important features. The proposed method can be successfully used in other fields as well as eSports. The experiments that were conducted on a publicly available eSports dataset show that the proposed MVRRF algorithm (93.32%) outperforms the standard RF algorithm (86.38%) on multi-view data in terms of accuracy. Furthermore, the experimental results also show that our method achieved higher performance than the methods tested in the state of the art studies on the same dataset.},
  archive      = {J_EXSY},
  author       = {Kokten Ulas Birant},
  doi          = {10.1111/exsy.12857},
  journal      = {Expert Systems},
  month        = {2},
  number       = {2},
  pages        = {e12857},
  shortjournal = {Expert Syst.},
  title        = {Multi-view rank-based random forest: A new algorithm for prediction in eSports},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Golden sine cosine SALP swarm algorithm for shape matching
using atomic potential function. <em>EXSY</em>, <em>39</em>(2), e12854.
(<a href="https://doi.org/10.1111/exsy.12854">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Salp swarm algorithm (SSA) is one of the efficient recent meta-heuristic optimization algorithms, where it has been successfully utilized in a wide range of optimization problems in different fields. In the research process, it is found that it is very difficult to maintain the balance between the exploration and exploitation capabilities of a certain algorithm. Therefore, one of the main purposes of this article is to provide an algorithm that can intelligently balance between exploration and exploitation, so that it can balance exploration and exploitation capabilities. Later, in the research process, it was found that the sine and cosine function and the salp foraging trajectory have a high mathematical similarity, which greatly improves the optimization ability of the algorithm. In addition, the variable neighbourhood strategy can appropriately expand the optimization range of the algorithm. So in this paper, a novel golden sine cosine salp swarm algorithm with variable neighbourhood search scheme (GSCSSA-VNS) is proposed, the another objective of proposing this algorithm is as a new optimization method for shape matching. As a relatively new branch, atomic potential matching (APM) model is inspired by potential field attractions. Compared to the conventional edge potential function (EPF) model, APM has been verified to be less sensitive to intricate backgrounds in the test image and far more cost effective in the computation process. Experimental results of four realistic examples show that GSCSSA-VNS is able to provide very competitive results and outperforms the other algorithms.},
  archive      = {J_EXSY},
  author       = {Zhehong Xiang and Guo Zhou and Yongquan Zhou and Qifang Luo},
  doi          = {10.1111/exsy.12854},
  journal      = {Expert Systems},
  month        = {2},
  number       = {2},
  pages        = {e12854},
  shortjournal = {Expert Syst.},
  title        = {Golden sine cosine SALP swarm algorithm for shape matching using atomic potential function},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Development methodologies for ontology-based knowledge
management systems: A review. <em>EXSY</em>, <em>39</em>(2), e12851. (<a
href="https://doi.org/10.1111/exsy.12851">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge management systems (KMS) are computer-based systems highly valued in business organizations because they support knowledge management (KM) processes. Most KMS have been developed using non-intelligent computer technology—that is, DMS, CMS, DBMS, and CIS—, and thus, they cannot provide advanced capabilities. Consequently, enhanced KMS using intelligent technologies of ontologies with inference engines—called ontology-based knowledge management systems (OKMS)—have been proposed in the last three decades. Nowadays, however, the implementation of OKMS in real-world settings is still scarce. Lack of comprehensive and systematic development methodologies including Project Management and Technical Systems Engineering processes—as the Systems and Software Systems Engineering standards propose—have been suggested as a factor that inhibits OKMS implementations. In this study, we review the OKMS literature (1990–2021 period)—from six seminal studies located using a research search engine—to assess OKMS development methodologies that can be considered comprehensive and systematic. Five methodologies were identified and assessed using an evaluation subset from the ISO/IEC/IEEE 15288:2015 Systems and Software Engineering standard. Two of them—CommonKADS and NeON—were found with a high comprehensive and systematic level and both are suggested for organizations interested in OKMS implementations, but none of them qualified as agile, which is a current development approach for systems and software systems. Hence, further empirical research toward the realization of comprehensive and systematic OKMSs development methodologies, including agile versions, is suggested for fostering the implementation of OKMS in real-world settings.},
  archive      = {J_EXSY},
  author       = {Manuel Mora and Fen Wang and Jorge Marx Gómez and Gloria Phillips-Wren},
  doi          = {10.1111/exsy.12851},
  journal      = {Expert Systems},
  month        = {2},
  number       = {2},
  pages        = {e12851},
  shortjournal = {Expert Syst.},
  title        = {Development methodologies for ontology-based knowledge management systems: A review},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The demand effect analysis of head books and tail books in
book recommendation networks. <em>EXSY</em>, <em>39</em>(2), e12847. (<a
href="https://doi.org/10.1111/exsy.12847">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many existing studies related to recommendation systems have made great efforts to increase performance-oriented evaluation metrics such as accuracy, recall, F1 value, MAE, diversity, and so on. However, these metrics for measuring performance do not provide any explanation of how such recommendation systems contribute to a product provider&#39;s sales. Recently, to investigate the factors affecting product sales, researchers have started to use the product recommendation network, which is a graphical presentation of the relationship between products that are purchased simultaneously. In this research, we are going to identify factors that influence the demand for head books (top sales books) and tail books (non-top sales books) in academic and technology books, because the characteristics of specialized books are different from those of general books. To test the model, online sales data of medicine and science books of G Publishing, the leading medical book publishing and distribution company in Korea, are used. We employ social network analysis and multiple regression analysis to investigate demand effect of the book recommendation network. The former is used to measure centralities of the book recommendation network, while the latter is used to measure the demand effect. Furthermore, we inspect whether there are different attributes between head books and tail books that are related to the book demand in recommendation networks. This study is the first attempt to examine the demand effect of the recommendation network of academic and technology books. The following results are obtained general book sales of an online bookstore follow a long-tail law, while sales of academic and technology books follow Pareto&#39;s law distribution. This study investigated attributes that might be linked to demand effect of head books and tail books in the recommendation network of academic and technology books. How to increase book sales using attributes that are differently associated with the demand of head books and tail books in the recommendation network is also presented.},
  archive      = {J_EXSY},
  author       = {Jae Kyeong Kim and Chang Geun Jeong and Qinglong Li and Il Young Choi},
  doi          = {10.1111/exsy.12847},
  journal      = {Expert Systems},
  month        = {2},
  number       = {2},
  pages        = {e12847},
  shortjournal = {Expert Syst.},
  title        = {The demand effect analysis of head books and tail books in book recommendation networks},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel equilibrium optimizer based on levy flight and
iterative cosine operator for engineering optimization problems.
<em>EXSY</em>, <em>39</em>(2), e12843. (<a
href="https://doi.org/10.1111/exsy.12843">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Equilibrium optimizer (EO) is a novel optimization algorithm with high exploration and exploitation capabilities. The capabilities of EO are impacted by the generation rate, exponential term, and equilibrium pool, wherein the initial two depend on the turnover rate. The performance of the EO on different optimization functions can be improved by updating these factors. This paper designs a modified equilibrium optimizer (MEO) by incorporating three changes in the EO: (i) replacement of the equilibrium pool with an iterative cosine operator (ICO) that gradually reduces diversification to intensification as the iterations progress; (ii) implementation of levy flight to update the concentration of particle that improves exploration capabilities; and (iii) the random vector with uniform distribution of turnover rate is replaced by heavy-tailed non-uniform levy distribution to improve exploration capability of the algorithm. Here, the other parameters on which MEO depends are selected by performing the sensitivity analysis. The capabilities of MEO have been analysed by comparing it with 19 algorithms, including the EO algorithm, 12 state-of-art algorithms, and 6 hybrid/improved algorithms on 62 functions, that is, 23 benchmark functions, 10 CEC-06-2019, 29 CEC-2017 functions. The non-parametric Friedman test and Kruskal–Wallis test validate that MEO outperforms the other algorithms due to its balanced exploration and exploitation abilities. MEO robustness has been validated by the diversity analysis along with the scalability test. MEO is also evaluated on five practical engineering problems to showcase its significance.},
  archive      = {J_EXSY},
  author       = {Sachin Minocha and Birmohan Singh},
  doi          = {10.1111/exsy.12843},
  journal      = {Expert Systems},
  month        = {2},
  number       = {2},
  pages        = {e12843},
  shortjournal = {Expert Syst.},
  title        = {A novel equilibrium optimizer based on levy flight and iterative cosine operator for engineering optimization problems},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Goal programming and multiple criteria data envelopment
analysis combined with optimization and monte carlo simulation: An
application in railway components. <em>EXSY</em>, <em>39</em>(2),
e12840. (<a href="https://doi.org/10.1111/exsy.12840">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work has been developed in a large steel industry in Brazil, which produces railway and industrial components, and whose aim was to reduce casting defects. Usually, in industrial processes, identifying the causes of defects and their control are relatively complex activities, due to the many variables involved. In this context, the production processes of seven products, involving 38 process variables (inputs and outputs), have been evaluated adopting a new and innovative procedure. Initially, using a Weighted Goal Programming - Multiple Criteria Data Envelopment Analysis (WGP-MCDEA) model, we identified the most relevant input and output variables, and the studied company validated the results. Next, using the multiple regression technique, empirical functions were constructed for two response variables chosen by the company – number of external cracks and number of internal cracks. Then, to model the real processes adequately, we introduced the occurrence of uncertainty on the coefficients of these functions, considering them as random variables, according to triangular probability functions. Finally, applying the optimizer Optquest, optimization via Monte Carlo simulation (OvMCS) was performed, and with the Ordinary Least Square technique, we obtained the best fit for the two response variables. Specialists from the company validated the proposed procedure. They found that the values of input and output variables obtained by OvMSC, as well as the values of the response variables, belonged to the database available in the ERP system of the company. These results showed that the procedure proposed herein provided feasible and useful solutions to improve the industrial processes under study.},
  archive      = {J_EXSY},
  author       = {Aneirson Francisco da Silva and Fernando Augusto Silva Marins and Erica Ximenes Dias and Rafael de Carvalho Miranda},
  doi          = {10.1111/exsy.12840},
  journal      = {Expert Systems},
  month        = {2},
  number       = {2},
  pages        = {e12840},
  shortjournal = {Expert Syst.},
  title        = {Goal programming and multiple criteria data envelopment analysis combined with optimization and monte carlo simulation: An application in railway components},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An efficient adaptive genetic algorithm for energy saving in
the hybrid flow shop scheduling with batch production at last stage.
<em>EXSY</em>, <em>39</em>(2), e12678. (<a
href="https://doi.org/10.1111/exsy.12678">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article deals with energy saving in the hybrid flow shop scheduling problem with batch production at last stage, which has important application in energy-intensive steelmaking-continuous casting (SCC) process. We first establish a mixed integer programming model to reduce extra energy consumption, and then adopt genetic algorithm to solving the scheduling problem. Based on traditional genetic algorithm (TGA), the calculation of the fitness function as well as adaptive crossover and mutation are designed. Due to the complexity of the problem in this article, we then propose an efficient adaptive genetic algorithm (EAGA) to improve the search ability of TGA. The EAGA has new features including layered strategies and enhanced adaptive adjustment method. To evaluate the proposed model and algorithm, we conduct computational experiments under practical background and compare the EAGA with the several algorithms presented previously. The results illustrate that scheduling with our model can greatly reduce the extra energy consumption. Meanwhile, the proposed EAGA is very efficient in comparison.},
  archive      = {J_EXSY},
  author       = {Hong Lu and Fei Qiao},
  doi          = {10.1111/exsy.12678},
  journal      = {Expert Systems},
  month        = {2},
  number       = {2},
  pages        = {e12678},
  shortjournal = {Expert Syst.},
  title        = {An efficient adaptive genetic algorithm for energy saving in the hybrid flow shop scheduling with batch production at last stage},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-objective optimization for stochastic failure-prone
job shop scheduling problem via hybrid of NSGA-II and simulation method.
<em>EXSY</em>, <em>39</em>(2), e12455. (<a
href="https://doi.org/10.1111/exsy.12455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Production scheduling and reliability of machinery are prominent issues in flexible manufacturing systems that are led to decreasing of production costs and increasing of system efficiency. In this paper, multiobjective optimization of stochastic failure-prone job shop scheduling problem is sought wherein that job processing time seems to be controllable. It endeavours to determine the best sequence of jobs, optimal production rate, and optimum preventive maintenance period for simultaneous optimization of three criteria of sum of earliness and tardiness, system reliability, and energy consumption. First, a new mixed integer programming model is proposed to formulate the problem. Then, by combining of simulation and NSGA-II algorithm, a new algorithm is put forward for solving the problem. A set of Pareto optimal solutions is achieved through this algorithm. The stochastic failure-prone job shop with controllable processing times has not been investigated in the earlier research, and for the first time, a new hedging point policy is presented. The computational results reveal that the proposed metaheuristic algorithm converges into optimal or near-optimal solution. To end, results and managerial insights for the problem are presented.},
  archive      = {J_EXSY},
  author       = {Sayed Shahab Amelian and Seyed Mojtaba Sajadi and Mehrzad Navabakhsh and Majid Esmaelian},
  doi          = {10.1111/exsy.12455},
  journal      = {Expert Systems},
  month        = {2},
  number       = {2},
  pages        = {e12455},
  shortjournal = {Expert Syst.},
  title        = {Multi-objective optimization for stochastic failure-prone job shop scheduling problem via hybrid of NSGA-II and simulation method},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). China’s high-tech industry efficiency measurement with
virtual frontier data envelopment analysis and malmquist productivity
index. <em>EXSY</em>, <em>39</em>(2), e12450. (<a
href="https://doi.org/10.1111/exsy.12450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data envelopment analysis (DEA) is a widely used non-parametric method in efficiency measurement with multiinputs and multioutputs. Malmquist productivity measures the efficiency change in different periods and decomposes the general efficiency change into technical efficiency change and frontier shift. In this paper, we choose a driving industry in social development, the high-tech industry, as an example to illustrate a new method, virtual frontier DEA model, in the aspect of improvement of the traditional DEA model. Additionally, we decompose the Malmquist productivity index with virtual frontier DEA model to find out the driving force of high-tech efficiency change.},
  archive      = {J_EXSY},
  author       = {Xin Liu and Jingkai Huang},
  doi          = {10.1111/exsy.12450},
  journal      = {Expert Systems},
  month        = {2},
  number       = {2},
  pages        = {e12450},
  shortjournal = {Expert Syst.},
  title        = {China&#39;s high-tech industry efficiency measurement with virtual frontier data envelopment analysis and malmquist productivity index},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comparison analysis for credit scoring using bagging
ensembles. <em>EXSY</em>, <em>39</em>(2), e12297. (<a
href="https://doi.org/10.1111/exsy.12297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a hybrid approach for credit scoring, and the classification performance of this approach is compared with 4 base learners in machine learning. A large credit default swap dataset covering the period from 2006 to 2016 is used to build classifiers and test their performances. The results from this empirical study indicate that the bagging ensemble method can substantially improve individual base learners such as decision tree, multilayer perceptron, and k -nearest neighbours. The performance of support vector machine does not change after applying bagging ensemble. The overall results demonstrate that k -nearest neighbour is more suitable than any other method when dealing with large unbalanced datasets in credit scoring.},
  archive      = {J_EXSY},
  author       = {Cuicui Luo},
  doi          = {10.1111/exsy.12297},
  journal      = {Expert Systems},
  month        = {2},
  number       = {2},
  pages        = {e12297},
  shortjournal = {Expert Syst.},
  title        = {A comparison analysis for credit scoring using bagging ensembles},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Productivity measurement of industrial sector in china
regarding air pollution. <em>EXSY</em>, <em>39</em>(2), e12267. (<a
href="https://doi.org/10.1111/exsy.12267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important sector of national economy, the industrial sector accounts for 33.4% of gross domestic product while consuming 70% of energy and causing serious air pollution in China. It is meaningful to measure the productivity of industrial sector in China with air pollution consideration. The range-adjusted measure of the nonradial data envelopment analysis, as with natural disposability and managerial disposability, is adopted in order to measure the productivity of provincial industrial sector in China during 2011–2014. The results explain that the unified efficiency under managerial disposability is lower than the unified efficiency under natural disposability and the unified efficiency under natural and managerial disposability, which means that management improvement and technology innovation should be obtained more attention from the government. As modernization of economic restructuring, there is not a trend of unified efficiency under natural disposability. Eastern China has highest unified efficiency under managerial disposability, whereas unified efficiency under natural and managerial disposability are improving in eastern China and western China in period of 2013–2014. The results also describe that more than 20 provinces and nearly half of provinces are suitable for the industrial pollution control investment and research and development investment, respectively. On the basis of the results of the truncated regression model, we can identify the influencing factors of unified efficiency. According to above results, suggestions are proposed in order to improve the productivity.},
  archive      = {J_EXSY},
  author       = {Meisheng Liu and Desheng Wu},
  doi          = {10.1111/exsy.12267},
  journal      = {Expert Systems},
  month        = {2},
  number       = {2},
  pages        = {e12267},
  shortjournal = {Expert Syst.},
  title        = {Productivity measurement of industrial sector in china regarding air pollution},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An intelligent system for monitoring students’ engagement in
large classroom teaching through facial expression recognition.
<em>EXSY</em>, <em>39</em>(1), e12839. (<a
href="https://doi.org/10.1111/exsy.12839">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Students&#39; disengagement problem has become critical in the modern scenario due to various distractions and lack of student-teacher interactions. This problem is exacerbated with large offline classrooms, where it becomes challenging for teachers to monitor students&#39; engagement and maintain the right-level of interactions. Traditional ways of monitoring students&#39; engagement rely on self-reporting or using physical devices, which have limitations for offline classroom use. Student&#39;s academic affective states (e.g., moods and emotions) analysis has potential for creating intelligent classrooms, which can autonomously monitor and analyse students&#39; engagement and behaviours in real-time. In recent literature, a few computer vision based methods have been proposed, but they either work only in the e-learning domain or have limitations in real-time processing and scalability for large offline classes. This paper presents a real-time system for student group engagement monitoring by analysing their facial expressions and recognizing academic affective states: ‘boredom,’ ‘confuse,’ ‘focus,’ ‘frustrated,’ ‘yawning,’ and ‘sleepy,’ which are pertinent in the learning environment. The methodology includes certain pre-processing steps like face detection, a convolutional neural network (CNN) based facial expression recognition model, and post-processing steps like frame-wise group engagement estimation. For training the CNN model, we created a dataset of the aforementioned facial expressions from classroom lecture videos and added related samples from three publicly available datasets, BAUM-1, DAiSEE, and YawDD, to generalize the model predictions. The trained model has achieved train and test accuracy of 78.70% and 76.90%, respectively. The proposed methodology gave promising results when compared with self-reported engagement levels by students.},
  archive      = {J_EXSY},
  author       = {Chakradhar Pabba and Praveen Kumar},
  doi          = {10.1111/exsy.12839},
  journal      = {Expert Systems},
  month        = {1},
  number       = {1},
  pages        = {e12839},
  shortjournal = {Expert Syst.},
  title        = {An intelligent system for monitoring students&#39; engagement in large classroom teaching through facial expression recognition},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). HTE 3.0: Knowledge-based systems in cascade for familial
hypercholesterolemia detection and dyslipidemia treatment.
<em>EXSY</em>, <em>39</em>(1), e12835. (<a
href="https://doi.org/10.1111/exsy.12835">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {HTE 3.0 aims to support clinicians in the detection of patients with dyslipidemia, especially patients with familial hypercholesterolemia (FH), and in the recommendation of personalized lipid-lowering treatments. The core of HTE 3.0 is a clinical decision support system in which several knowledge-based systems are serialized: patient detection, therapeutic target setting, personalized treatment assessment, and treatment combination and prioritization, according to different criteria. The experimental evaluation of HTE 3.0 shows that the use of HTE 3.0 would mean increasing the capacity to detect FH by 5.7 times compared with usual clinical practice. Regarding the lipid-lowering treatment, a comparison of 18 cases among seven lipidologists shows that the differences between treatments provided by HTE 3.0 and human lipidologists are smaller than the differences between human experts.},
  archive      = {J_EXSY},
  author       = {Beatriz López and Ferran Torrent-Fontbona and Luis Masana Marín and Alberto Zamora},
  doi          = {10.1111/exsy.12835},
  journal      = {Expert Systems},
  month        = {1},
  number       = {1},
  pages        = {e12835},
  shortjournal = {Expert Syst.},
  title        = {HTE 3.0: Knowledge-based systems in cascade for familial hypercholesterolemia detection and dyslipidemia treatment},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Weight attention layer-based document classification
incorporating information gain. <em>EXSY</em>, <em>39</em>(1), e12833.
(<a href="https://doi.org/10.1111/exsy.12833">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of document classifiers largely depends on their internal representations of text data. Recent studies have been conducted to identify areas of focus and find latent data spaces to increase the representativeness and the performance of classifiers. In this study, we propose a weight attention layer (WAL) that uses an additional feature of words when computing their attention weights for deep learning models based on attention mechanisms. In the WAL, the attention distribution is calculated through the dot product of the attention weight matrix and a word weight matrix. We utilized information gain, which is one of the feature selection algorithms for the additional feature. To evaluate the proposed method, datasets of helpful reviews, sentiment reviews, and fake reviews were used. These datasets were applied to two deep learning models based on attention mechanisms, including an attention-based bidirectional long short-term memory (LSTM) and a hierarchical attention network. As a result of 10-fold cross validation, the improved performance of the models in terms of accuracy and F1-score when using WAL is demonstrated.},
  archive      = {J_EXSY},
  author       = {Min Seok Lee and Seok Woo Yang and Hong Joo Lee},
  doi          = {10.1111/exsy.12833},
  journal      = {Expert Systems},
  month        = {1},
  number       = {1},
  pages        = {e12833},
  shortjournal = {Expert Syst.},
  title        = {Weight attention layer-based document classification incorporating information gain},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). High performance accelerators for deep neural networks: A
review. <em>EXSY</em>, <em>39</em>(1), e12831. (<a
href="https://doi.org/10.1111/exsy.12831">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The availability of huge structured and unstructured data, advanced highly dense memory and high performance computing machines have provided a strong push for the development in artificial intelligence (AI) and machine learning (ML) domains. AI and machine learning has rekindled the hope of efficiently solving complex problems which was not possible in the recent past. The generation and availability of big-data is a strong driving force for the development of AI/ML applications, however, several challenges need to be addressed, like processing speed, memory requirement, high bandwidth, low latency memory access, and highly conductive and flexible connections between processing units and memory blocks. The conventional computing platforms are unable to address these issues with machine learning and AI. Deep neural networks (DNNs) are widely employed for machine learning and AI applications, like speech recognition, computer vison, robotics, and so forth, efficiently and accurately. However, accuracy is achieved at the cost of high computational complexity, sacrificing energy efficiency and throughput like performance measuring parameters along with high latency. To address the problems of latency, energy efficiency, complexity, power consumption, and so forth, a lot of state of the art DNN accelerators have been designed and implemented in the form of application specific integrated circuits (ASICs) and field programmable gate arrays (FPGAs). This work provides the state of the art of all these DNN accelerators which have been developed recently. Various DNN architectures, their computing units, emerging technologies used in improving the performance of DNN accelerators will be discussed. Finally, we will try to explore the scope for further improvement in these accelerator designs, various opportunities and challenges for the future research.},
  archive      = {J_EXSY},
  author       = {Mohd Saqib Akhoon and Shahrel A. Suandi and Abdullah Alshahrani and Abdul-Malik H. Y. Saad and Fahad R. Albogamy and Mohd Zaid Bin Abdullah and Sajad A. Loan},
  doi          = {10.1111/exsy.12831},
  journal      = {Expert Systems},
  month        = {1},
  number       = {1},
  pages        = {e12831},
  shortjournal = {Expert Syst.},
  title        = {High performance accelerators for deep neural networks: A review},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-start iterated local search metaheuristic for the
multi-mode resource-constrained project scheduling problem.
<em>EXSY</em>, <em>39</em>(1), e12830. (<a
href="https://doi.org/10.1111/exsy.12830">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper a multi-start iterated local search (MS-ILS) algorithm is presented as a new and effective approach to solve the multi-mode resource-constrained project scheduling problem (MRCPSP). The MRCPSP is a well-known project scheduling NP-Hard optimization problem, in which there is a trade-off between the duration of each project activity and the amount of resources they require to be completed. The proposed algorithm generates an initial solution, performs a local search to obtain a local optimum, subsequently, for a certain number of iterations, makes a perturbation to that local optimum and performs a new local search on the perturbed solution. This whole process then restarts with a different initial solution for a certain number of restarts. The algorithm was tested on benchmark instances of projects with 30, 50 and 100 activities from well-known libraries. The obtained results were compared to recent benchmark results from the literature. The proposed algorithm outperforms other solution methods found in related literature for the largest tested instances (100 activities), while for smaller instances it shows to be quite competitive, in terms of the average deviation against known lower bounds.},
  archive      = {J_EXSY},
  author       = {Alfredo S. Ramos and Elias Olivares-Benitez and Pablo A. Miranda-Gonzalez},
  doi          = {10.1111/exsy.12830},
  journal      = {Expert Systems},
  month        = {1},
  number       = {1},
  pages        = {e12830},
  shortjournal = {Expert Syst.},
  title        = {Multi-start iterated local search metaheuristic for the multi-mode resource-constrained project scheduling problem},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MapReduce paradigm: DNA sequence clustering based on repeats
as features. <em>EXSY</em>, <em>39</em>(1), e12827. (<a
href="https://doi.org/10.1111/exsy.12827">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is one of the major operations to analyse genome sequence data. Sophisticated sequencing technologies generate huge DNA sequence data; consequently, the complexity of analysing sequences is also increased. So, there is an enormous need for faster sequence analysis algorithms. Most of the existing tools focused on alignment-based approaches, which are slow-paced for sequence comparison. Alignment-free approaches are more successful for fast clustering. The state-of-the-art methods have been applied to cluster small genome sequences of various species; however, they are sensitive to large size sequences. To subdue this limitation, we propose a novel alignment-free method called DNA sequence clustering with map-reduce (DCMR). Initially, MapReduce paradigm is used to speed up the process of extracting eight different types of repeats. Then, the frequency of each type of repeat in a sequence is considered as a feature for clustering. Finally, K-means (DCMR-Kmeans) and K-median (DCMR-Kmedian) algorithms are used to cluster large DNA sequences by using extracted features. The two variants of proposed method are evaluated to cluster large genome sequences of 21 different species and the results show that sequences are very well clustered. Our method is tested for different benchmark data sets like viral genome, influenza A virus, mtDNA, and COXI data sets. Proposed method is compared with MeshClust, UCLUST, STARS, and ClustalW. DCMR-Kmeans outperforms MeshClust, UCLUST, and DCMR-Kmedian with respect to purity and NMI on virus data sets. The computational time of DCMR-Kmeans is less than STARS, DCMR-Kmedian, and much less than UCLUST on COXI data set.},
  archive      = {J_EXSY},
  author       = {Chandra Mohan Dasari and Raju Bhukya},
  doi          = {10.1111/exsy.12827},
  journal      = {Expert Systems},
  month        = {1},
  number       = {1},
  pages        = {e12827},
  shortjournal = {Expert Syst.},
  title        = {MapReduce paradigm: DNA sequence clustering based on repeats as features},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Segmentation of malignant tumours in mammogram images: A
hybrid approach using convolutional neural networks and connected
component analysis. <em>EXSY</em>, <em>39</em>(1), e12826. (<a
href="https://doi.org/10.1111/exsy.12826">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The segmentation of breast lesions is an important step in the computer-aided analysis of the mammogram. The presence of noise in mammograms makes lesion detection challenging particularly for complex malignant lesions. Pre-processing techniques can deal with the noise issue but distorts the important shape features. This motivates us to propose a novel hybrid approach by combining a convolution neural network (CNN) with connected component analysis (CCA) to segment malignant breast lesions without any pre-processing to avoid any distortion in image sharpness at the initial stages. Two well-known segmentation techniques namely, K-means (KM) and Fuzzy c-means (FCM) are also used to compare the results. From a pool of 1045 mammographic cancer images acquired from the Digital Database for Screening Mammography (DDSM), 1016 are used for training and validation, and 29 are used for testing. All three results (Hybrid, KM and FCM) are compared against the results by the expert Radiologist. The results indicate that, among various segmentation techniques, the proposed hybrid approach achieves the highest accuracy (90%), Matthew&#39;s correlation coefficient (0.79), Jaccard index (0.73) and the Dice similarity coefficient (0.84). Other performance evaluation techniques such as; precision, sensitivity, specificity, false-positive rate, false discovery rate, negative predictive value and false-negative rate also show the superior performance of the proposed hybrid approach. Statistical analysis (Mann–Whitney U test, T -test, Chi-square test, Kolmogorov–Smirnov test and Wilcoxon test), graphical analysis (Regression and Bland–Altman plots) and receiver operating characteristic curve further demonstrate the stability and consistency of the results.},
  archive      = {J_EXSY},
  author       = {Abhijit Roy and Bikesh Kumar Singh and Sumit K. Banchhor and Kesari Verma},
  doi          = {10.1111/exsy.12826},
  journal      = {Expert Systems},
  month        = {1},
  number       = {1},
  pages        = {e12826},
  shortjournal = {Expert Syst.},
  title        = {Segmentation of malignant tumours in mammogram images: A hybrid approach using convolutional neural networks and connected component analysis},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Eliciting symptom-diagnosis knowledge from online medical
q&amp;a. <em>EXSY</em>, <em>39</em>(1), e12821. (<a
href="https://doi.org/10.1111/exsy.12821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the objective to automatically detect diseases from symptoms in free-text data, a methodology to extract symptom-diagnosis knowledge from online medical textual data in Q&amp;A domain is proposed in this paper: (1) a term frequency-inverse document frequency and PRECISION method is adopted to retrieve symptom words from unstructured text; (2) a variable precision rough set based genetic algorithm is applied to reduce redundant symptom words, and a rough set based rule is utilized for adding discriminative symptom words assisting to discriminate diseases sharing similar symptoms; (3) by employing fuzzy linguistic variables to express the risk level of disease or severity level of symptoms, a knowledge base with fuzzy belief structure is generated. Using data extracted from a Chinese medical Q&amp;A forum for training and testing, some classical gastrointestinal diseases serve as a case study to evaluate the efficiency of the proposed methodology. Subsequently performance comparisons are made between the proposed methodology and some other classifiers, such as the decision tree algorithms including ID3 and J45, and the Bayesian network classifier. The comparative results demonstrate that the proposed methodology outperforms the decision tree algorithms and the Bayesian network classifier.},
  archive      = {J_EXSY},
  author       = {Ying Yu and Hao Huang},
  doi          = {10.1111/exsy.12821},
  journal      = {Expert Systems},
  month        = {1},
  number       = {1},
  pages        = {e12821},
  shortjournal = {Expert Syst.},
  title        = {Eliciting symptom-diagnosis knowledge from online medical Q&amp;A},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Training and assessing numerical abilities across the
lifespan with intelligent systems: The example of baldo. <em>EXSY</em>,
<em>39</em>(1), e12817. (<a
href="https://doi.org/10.1111/exsy.12817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Baldo is an intelligent system that can be used to assess and train numerical abilities across the lifespan, especially for children and elderly. Baldo includes digital and tangible materials to propose activities, built on the game-based learning approach, strongly grounded on well-known and experimentally supported theories about numerical and mathematical cognition. Moreover, Baldo has a special module devoted to motivational and affective dimensions related to mathematic cognition and a tutoring system to select specific activities that are adequate to the actual and potential level of the people involved in the training pathway.},
  archive      = {J_EXSY},
  author       = {Michela Ponticorvo and Massimiliano Schembri and Orazio Miglino},
  doi          = {10.1111/exsy.12817},
  journal      = {Expert Systems},
  month        = {1},
  number       = {1},
  pages        = {e12817},
  shortjournal = {Expert Syst.},
  title        = {Training and assessing numerical abilities across the lifespan with intelligent systems: The example of baldo},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analysing stable feature selection through an augmented
marine predator algorithm based on opposition-based learning.
<em>EXSY</em>, <em>39</em>(1), e12816. (<a
href="https://doi.org/10.1111/exsy.12816">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retrieving the relevant information from the high-dimensional dataset enhances the classification accuracy of a predictive model. This research critique has devised an improved marine predator algorithm based on opposition learning for stable feature selection to overcome the problem of high-dimensionality. Marine predator algorithm is a population-based meta-heuristics optimization algorithm that works on the ‘survival-of-the-fittest’ theory. Classical marine predator algorithm explores the search space merely in one direction, affecting its converging capacity while being responsible for stagnation at local minima. The proposed opposition-based learning nuances enhance the exploration capacity of marine predator algorithm and productively converges the model to global optima. The proposed OBL-based marine predator algorithm selects stable, substantial elements from six different high-dimensional microarray datasets. The performance of the proposed method is investigated using five predominantly used classifiers. From the result, it is understood that the proposed approach outperforms other conventional feature selection techniques in terms of converging capability, classification accuracy, and stable feature selection.},
  archive      = {J_EXSY},
  author       = {Kulanthaivel Balakrishnan and Ramasamy Dhanalakshmi and Utkarsh Mahadeo Khaire},
  doi          = {10.1111/exsy.12816},
  journal      = {Expert Systems},
  month        = {1},
  number       = {1},
  pages        = {e12816},
  shortjournal = {Expert Syst.},
  title        = {Analysing stable feature selection through an augmented marine predator algorithm based on opposition-based learning},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evolutionary state-based novel multi-objective periodic
bacterial foraging optimization algorithm for data clustering.
<em>EXSY</em>, <em>39</em>(1), e12812. (<a
href="https://doi.org/10.1111/exsy.12812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering divides objects into groups based on similarity. However, traditional clustering approaches are plagued by their difficulty in dealing with data with complex structure and high dimensionality, as well as their inability in solving multi-objective data clustering problems. To address these issues, an evolutionary state-based novel multi-objective periodic bacterial foraging optimization algorithm (ES-NMPBFO) is proposed in this article. The algorithm is designed to alleviate the high-computing complexity of the standard bacterial foraging optimization (BFO) algorithm by introducing periodic BFO. Moreover, two learning strategies, global best individual ( gbest ) and personal historical best individual ( pbest ), are used in the chemotaxis operation to enhance the convergence speed and guide the bacteria to the optimum position. Two elimination-dispersal operations are also proposed to prevent falling into local optima and improve the diversity of solutions. The proposed algorithm is compared with five other algorithms on six validity indexes in two data clustering cases comprising nine general benchmark datasets and four credit risk assessment datasets. The experimental results suggest that the proposed algorithm significantly outperforms the competing approaches. To further examine the effectiveness of the proposed strategies, two variants of ES-NMPBFO were designed, and all three forms of ES-NMPBFO were tested. The experimental results show that all of the proposed strategies are conducive to the improvement of solution quality, diversity and convergence.},
  archive      = {J_EXSY},
  author       = {Chen Guo and Heng Tang and Ben Niu},
  doi          = {10.1111/exsy.12812},
  journal      = {Expert Systems},
  month        = {1},
  number       = {1},
  pages        = {e12812},
  shortjournal = {Expert Syst.},
  title        = {Evolutionary state-based novel multi-objective periodic bacterial foraging optimization algorithm for data clustering},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid optimization algorithm-based feature selection for
thyroid disease classifier with rough type-2 fuzzy support vector
machine. <em>EXSY</em>, <em>39</em>(1), e12811. (<a
href="https://doi.org/10.1111/exsy.12811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thyroid hormones are essential for all the metabolic and reproductive activities with significance to growth, and neuron development in the human body. The thyroid hormone dysfunction has many ill consequences, affecting the human population; thereby being a global epidemic. It is noticed that every one in 10 persons suffer from different thyroid disorders in India. In recent years, many researchers have implemented various disease predictive models based on Information and Communications Technology (ICT). Increasing the accuracy of disease classification is a critical and challenging task. To increase the accuracy of classification, in this paper, we propose a hybrid optimization algorithm-based feature selection design for thyroid disease classifier with rough type-2 fuzzy support vector machine. This work uses the hybrid optimization algorithm, which combines the firefly algorithm (FA) and butterfly optimization algorithm (BOA) to select the top-n features. The proposed hybrid firefly butterfly optimization-rough type-2 fuzzy support vector machine (HFBO-RT2FSVM) is evaluated with several key metrics such as specificity, accuracy, and sensitivity. We compare our approach with well-known benchmark methods such as improved grey wolf optimization linear support vector machine (IGWO Linear SVM) and mixed-kernel support vector machine (MKSVM) methods. From the experimental evaluations, we justify that our technique improves the accuracy by large thereby precise in identifying the thyroid disease. HFBO-RT2FSVM model attained an accuracy of 99.28%, having specificity and sensitivity of 98 and 99.2%, respectively.},
  archive      = {J_EXSY},
  author       = {Vidhushavarshini Sureshkumar and Sathiyabhama Balasubramaniam and Vinayakumar Ravi and Ajay Arunachalam},
  doi          = {10.1111/exsy.12811},
  journal      = {Expert Systems},
  month        = {1},
  number       = {1},
  pages        = {e12811},
  shortjournal = {Expert Syst.},
  title        = {A hybrid optimization algorithm-based feature selection for thyroid disease classifier with rough type-2 fuzzy support vector machine},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A sparse coded composite descriptor for human activity
recognition. <em>EXSY</em>, <em>39</em>(1), e12805. (<a
href="https://doi.org/10.1111/exsy.12805">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel algorithm for computing discriminative descriptors named as a sparse coded composite descriptor (SCCD) for robust human activity recognition. The proposed method blends the state-of-the-art handcrafted features and the discriminative nature of the sparse representation of visual information. The human activity is firstly modelled using any handcrafted feature, and then the sparse codes computed on a discriminative sparse dictionary of these features are embedded to provide discrimination in the feature set. Finally, a support vector machine (SVM) is trained using the proposed SCCDs to perform classification of different human activities. A new feature named as differential motion descriptor (DMD) is also proposed to extract the motion as well as spatial information from an activity video. The simulation results reveal that in comparison with the handcrafted feature, the corresponding SCCD improves the recognition accuracy significantly. The proposed method is compared with state-of-the-art methods on KTH, Ballet, UCF50, and HMDB51 datasets and the proposed methodology of composite features outperforms these methods in terms of recognition accuracy.},
  archive      = {J_EXSY},
  author       = {Kuldeep Singh and Chhavi Dhiman and Dinesh Kumar Vishwakarma and Himanshu Makhija and Gurjit S. Walia},
  doi          = {10.1111/exsy.12805},
  journal      = {Expert Systems},
  month        = {1},
  number       = {1},
  pages        = {e12805},
  shortjournal = {Expert Syst.},
  title        = {A sparse coded composite descriptor for human activity recognition},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-criteria decision making approach for strategy
formulation using pythagorean fuzzy logic. <em>EXSY</em>,
<em>39</em>(1), e12802. (<a
href="https://doi.org/10.1111/exsy.12802">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of this paper is to develop Pythagorean fuzzy (PF) multi-objective optimization by ratio analysis (PF-MOORA) plus full MULTIplicative form (PF-MULTIMOORA) method for solving multicriteria decision making (MCDM) problems with completely unknown information of criteria weights. In the model formulation process, a new distance measure is defined to quantify the difference between PF sets by combining Hamming distance and Hausdorff metric. This distance measure is, subsequently, implemented in entropy weight model for determining unknown weights of criteria, and also in reference point approach for obtaining preference indices of alternatives. To overcome the deficiencies occurred in existing MULTIMOORA method, like multiple comparisons, circular reasoning, and so on, an aggregation-based approach is recommended in the proposed PF-MULTIMOORA. To demonstrate the feasibility and practicality of the proposed method, an example concerning strategy prioritization of a tiles manufacturing company is presented. In the strategy evaluation process, at first, the judgement values provided by the decision maker are expressed in linguistic terms, and then those are converted into PF numbers through a PF weighting scale. The sensitivity of the proposed model is validated by changing of weights of criteria which impact on the ranks of the strategies. To show robustness of the developed method, the result attained by applying PF-MULTIMOORA is compared with existing techniques, not only in crisp and fuzzy quantitative strategic planning matrix context, but also using four other MCDM methods, namely, modified PF-MOORA, as a particular case of the proposed PF-MULTIMOORA technique, PF weighted sum, PF-TOPSIS and PF-VIKOR.},
  archive      = {J_EXSY},
  author       = {Biswajit Sarkar and Animesh Biswas},
  doi          = {10.1111/exsy.12802},
  journal      = {Expert Systems},
  month        = {1},
  number       = {1},
  pages        = {e12802},
  shortjournal = {Expert Syst.},
  title        = {A multi-criteria decision making approach for strategy formulation using pythagorean fuzzy logic},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An end-to-end framework for the detection of mathematical
expressions in scientific document images. <em>EXSY</em>,
<em>39</em>(1), e12800. (<a
href="https://doi.org/10.1111/exsy.12800">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of mathematical expressions is a prerequisite step for the digitisation of scientific documents. Many different multistage approaches have been proposed for the detection of expressions in document images, that is, page segmentation and expression detection. However, the detection accuracy of such methods still needs improvement owing to errors in the page segmentation of complex documents. This paper presents an end-to-end framework for mathematical expression detection in scientific document images without requiring optical character recognition (OCR) or document analysis techniques applied in conventional methods. The novelty of this paper is twofold. First, because document images are usually in binary form, the direct use of these images, which lack texture information as input for detection networks, may lead to an incorrect detection. Therefore, we propose the application of a distance transform to obtain a discriminating and meaningful representation of mathematical expressions in document images. Second, the transformed images are fed into the faster region with a convolutional neural network (Faster R-CNN) optimized to improve the accuracy of the detection. The proposed framework was tested on two benchmark data sets (Marmot and GTDB). Compared with the original Faster R-CNN, the proposed network improves the accuracies of detection of isolated and inline expressions by 5.09% and 3.40%, respectfully, on the Marmot data set, whereas those on the GTDB data set are improved by 4.04% and 4.55%. A performance comparison with conventional methods shows the effectiveness of the proposed method.},
  archive      = {J_EXSY},
  author       = {Bui Hai Phong and Thang Manh Hoang and Thi-Lan Le},
  doi          = {10.1111/exsy.12800},
  journal      = {Expert Systems},
  month        = {1},
  number       = {1},
  pages        = {e12800},
  shortjournal = {Expert Syst.},
  title        = {An end-to-end framework for the detection of mathematical expressions in scientific document images},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). VIRDOCD: A VIRtual DOCtor to predict dengue fatality.
<em>EXSY</em>, <em>39</em>(1), e12796. (<a
href="https://doi.org/10.1111/exsy.12796">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clinicians make routine diagnosis by scrutinizing patients&#39; medical signs and symptoms, a skill popularly referred to as ‘Clinical Eye’. This skill evolves through trial-and-error and improves with time. The success of the therapeutic regime relies largely on the accuracy of interpretation of such sign-symptoms, analysing which a clinician assesses the severity of the illness. The present study is an attempt to propose a complementary medical front by mathematically modelling the ‘Clinical Eye’ of a VIR tual DOC tor, using statistical and machine intelligence tools (SMI), to analyse D engue epidemic infected patients ( 100 case studies with 11 weighted sign-symptoms ). The SMI in VIRDOCD reads medical data and translates these into a vector comprising multiple linear regression (MLR) coefficients to predict infection severity grades of dengue patients that clone the clinician&#39;s experience-based assessment. Risk managed through ANOVA, the dengue severity grade prediction accuracy from VIRDOCD is found higher (ca 75%) than conventional clinical practice (ca 71.4%, mean accuracy profile assessed by a team of 10 senior consultants). Free of human errors and capable of deciphering even minute differences from almost identical symptoms (to the Clinical eye), VIRDOCD is uniquely individualized in its decision-making ability. The algorithm has been validated against Random Forest classification (RF, ca 63%), another regression-based classifier similar to MLR that can be trained through supervised learning. We find that MLR-based VIRDOCD is superior to RF in predicting the grade of Dengue morbidity. VIRDOCD can be further extended to analyse other epidemic infections, such as COVID-19.},
  archive      = {J_EXSY},
  author       = {Amit K Chattopadhyay and Subhagata Chattopadhyay},
  doi          = {10.1111/exsy.12796},
  journal      = {Expert Systems},
  month        = {1},
  number       = {1},
  pages        = {e12796},
  shortjournal = {Expert Syst.},
  title        = {VIRDOCD: A VIRtual DOCtor to predict dengue fatality},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sequential credit card fraud detection: A joint deep neural
network and probabilistic graphical model approach. <em>EXSY</em>,
<em>39</em>(1), e12795. (<a
href="https://doi.org/10.1111/exsy.12795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the wide usage of e-banking in recent years, and by increased opportunities for fraudsters subsequently, we are witnessing a loss of billions of Euros worldwide due to credit card fraud every year. Therefore, credit card fraud detection has become a critical necessity for financial institutions. Several studies have used machine learning techniques for proposing a method to address the problem. However, most of them did not take into account the sequential nature of transactional data. In this paper, we proposed a novel credit card fraud detection model using sequence labelling based on both deep neural networks and probabilistic graphical models (PGM). Then by using two real-world datasets, we compared our model with the baseline model and examined how considering hidden sequential dependencies among transactions and also among predicted labels can improve the results. Moreover, we introduce a novel undersampling algorithm, which helps to maintain the sequential patterns of data during the random undersampling process. Our experiments demonstrate that this algorithm achieves promising results compared to the state-of-the-art methods in oversampling and undersampling.},
  archive      = {J_EXSY},
  author       = {Javad Forough and Saeedeh Momtazi},
  doi          = {10.1111/exsy.12795},
  journal      = {Expert Systems},
  month        = {1},
  number       = {1},
  pages        = {e12795},
  shortjournal = {Expert Syst.},
  title        = {Sequential credit card fraud detection: A joint deep neural network and probabilistic graphical model approach},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sparsity-aware support vector data description reinforced by
expectation maximization. <em>EXSY</em>, <em>39</em>(1), e12794. (<a
href="https://doi.org/10.1111/exsy.12794">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support vector data description (SVDD) characterizes a dataset by a spherically shaped boundary around it. Since the complexity of SVDD training is O(N 3 ), its performance decreases for large-scale datasets. In this paper, we propose an improved SVDD algorithm, called EM-SVDD, which combines the expectation maximization (EM) algorithm and SVDD to reduce the complexity and accelerate the training phase, while the accuracy of the classifier remains unchanged. First, the dataset is clustered to obtain smaller subsets, and then the boundary of each subset is identified by SVDD. After that, to construct the dataset boundary and get the optimal weighted combination of SVDDs, the EM algorithm is utilized to estimate the parameters and weights of SVDDs. The time complexity of the proposed method is N/i times lower than SVDD, where i is the number of EM iterations. In addition to EM-SVDD, Sparse EM-SVDD is proposed to guarantee the sparsity of the iteratively estimated parameters. EM-SVDD is well compared with several similar methods. Simulation results indicate higher speed and performance of the proposed method in the training and testing phases. Furthermore, the capability of the proposed method is tested on a large image dataset acquired from social networks and our method identifies in-class and outlier images with 0.71 accuracy rate.},
  archive      = {J_EXSY},
  author       = {Mahdie Eghdami and Hadi Sadoghi Yazdi and Neshat Salehi},
  doi          = {10.1111/exsy.12794},
  journal      = {Expert Systems},
  month        = {1},
  number       = {1},
  pages        = {e12794},
  shortjournal = {Expert Syst.},
  title        = {Sparsity-aware support vector data description reinforced by expectation maximization},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Image super resolution model enabled by wavelet lifting with
optimized deep convolutional neural network. <em>EXSY</em>,
<em>39</em>(1), e12793. (<a
href="https://doi.org/10.1111/exsy.12793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper plans to develop an intelligent super resolution model with the linkage of Wavelet lifting scheme and Deep learning algorithm. Before initiating the resolution procedure, the entire HR images are converted into Low Resolution (LR) images using bicubic interpolation-based downsampling and upsampling. Further, the Wavelet lifting scheme helps to generate the four subbands of each image like LR wavelet Sub-Bands for LR images, and High Resolution (HR) wavelet Sub-Bands for HR images. The residual image is generated by taking the difference between the LR wavelet Sub-Bands and HR wavelet Sub-Bands images. The proposed model involves two main phases: Training phase and Testing. The training phase trains the residual image of all images by Deep Convolutional Neural Network with LR wavelet Sub-Bands as input and residual image as target. On the other hand, in testing phase, the LR wavelet Sub-Bands query image is subjected to Deep Convolutional Neural Network, which outputs the concerned residual image. This generated residual image is summed with LR wavelet Sub-Bands image, followed by inverse wavelet lifting scheme to obtain the final super resolution image. The main contribution of this paper is to improve the conventional Deep Convolutional Neural Network by optimizing the number of hidden layer, and hidden neurons using modified Whale Optimization Algorithm called Average Fitness Enabled Whale Optimization Algorithm by considering the objective of maximizing the Peak Signal-to-Noise Ratio. Finally, the proposed method achieves an improved quality of the results which is comparable the existing models.},
  archive      = {J_EXSY},
  author       = {Achukatla Valli Bhasha and Balam Diguvathattu Venkatramana Reddy},
  doi          = {10.1111/exsy.12793},
  journal      = {Expert Systems},
  month        = {1},
  number       = {1},
  pages        = {e12793},
  shortjournal = {Expert Syst.},
  title        = {Image super resolution model enabled by wavelet lifting with optimized deep convolutional neural network},
  volume       = {39},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
