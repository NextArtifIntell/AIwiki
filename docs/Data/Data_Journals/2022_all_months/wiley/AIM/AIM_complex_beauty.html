<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AIM_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aim---37">AIM - 37</h2>
<ul>
<li><details>
<summary>
(2022a). Is AI at human parity yet? A case study on speech
recognition. <em>AIM</em>, <em>43</em>(4), 386–389. (<a
href="https://doi.org/10.1002/aaai.12071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Claims have been made that speech recognition has achieved human parity, yet this does not appear to be the case in the real-world applications that rely on it, especially for non-native speakers. This then begs the questions: What does it even mean for an AI system to reach human parity? How is progress towards that goal being measured? This article focuses on the current state of speech recognition and the recent developments in benchmarking and measuring performance of AI models built for speech processing. Through the shift away from single metric benchmarks and specialized models and towards evaluating collections of diverse challenging tasks and generalized models, the ultimate goal of true human parity in commercial speech processing applications is hopefully on the near horizon.},
  archive      = {J_AIM},
  author       = {Ian Beaver},
  doi          = {10.1002/aaai.12071},
  journal      = {AI Magazine},
  month        = {12},
  number       = {4},
  pages        = {386-389},
  shortjournal = {AI Mag.},
  title        = {Is AI at human parity yet? a case study on speech recognition},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). In memory of drew v. McDermott. <em>AIM</em>,
<em>43</em>(4), 383–385. (<a
href="https://doi.org/10.1002/aaai.12072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AIM},
  doi          = {10.1002/aaai.12072},
  journal      = {AI Magazine},
  month        = {12},
  number       = {4},
  pages        = {383-385},
  shortjournal = {AI Mag.},
  title        = {In memory of drew v. McDermott},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intelligent planning for large-scale multi-agent systems.
<em>AIM</em>, <em>43</em>(4), 376–382. (<a
href="https://doi.org/10.1002/aaai.12069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article summarizes the New Faculty Highlights talk with the same title at AAAI 2021. Intelligent agents such as different types of robots will soon become an integral part of our daily lives. In real-world multi-agent systems, the most fundamental challenges are assigning tasks to multiple agents (task-level coordination problems) and planning collision-free paths for the agents to task locations (motion-level coordination problems). This article surveys four directions of our research on using intelligent planning techniques for the above multi-agent coordination problems. Link to video abstract: https://youtu.be/HDAFcatq9_I},
  archive      = {J_AIM},
  author       = {Hang Ma},
  doi          = {10.1002/aaai.12069},
  journal      = {AI Magazine},
  month        = {12},
  number       = {4},
  pages        = {376-382},
  shortjournal = {AI Mag.},
  title        = {Intelligent planning for large-scale multi-agent systems},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning causality with graphs. <em>AIM</em>,
<em>43</em>(4), 365–375. (<a
href="https://doi.org/10.1002/aaai.12070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed a rocketing growth of machine learning methods on graph data, especially those powered by effective neural networks. Despite their success in different real-world scenarios, the majority of these methods on graphs only focus on predictive or descriptive tasks, but lack consideration of causality. Causal inference can reveal the causality inside data, promote human understanding of the learning process and model prediction, and serve as a significant component of artificial intelligence (AI). An important problem in causal inference is causal effect estimation, which aims to estimate the causal effects of a certain treatment (e.g., prescription of medicine) on an outcome (e.g., cure of disease) at an individual level (e.g., each patient) or a population level (e.g., a group of patients). In this paper, we introduce the background of causal effect estimation from observational data, envision the challenges of causal effect estimation with graphs, and then summarize representative approaches of causal effect estimation with graphs in recent years. Furthermore, we provide some insights for future research directions in related area. Link to video abstract: https://youtu.be/BpDPOOqw-ns},
  archive      = {J_AIM},
  author       = {Jing Ma and Jundong Li},
  doi          = {10.1002/aaai.12070},
  journal      = {AI Magazine},
  month        = {12},
  number       = {4},
  pages        = {365-375},
  shortjournal = {AI Mag.},
  title        = {Learning causality with graphs},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hierarchical planning and reasoning about partially ordered
plans—from theory to practice. <em>AIM</em>, <em>43</em>(4), 353–364.
(<a href="https://doi.org/10.1002/aaai.12073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This invited paper (part of the New Faculty Highlights Invited Speaker Program of AAAI&#39;21 * ) surveys my work done until today. The reviewed work focuses on hierarchical task network (HTN) planning as well as on partial order causal link (POCL) planning. Lines of research include theoretical investigations (mostly computational complexity analyses), heuristic search, as well as the practical application of the technology for planning-based assistants, which support a human user in carrying out various tasks.},
  archive      = {J_AIM},
  author       = {Pascal Bercher},
  doi          = {10.1002/aaai.12073},
  journal      = {AI Magazine},
  month        = {12},
  number       = {4},
  pages        = {353-364},
  shortjournal = {AI Mag.},
  title        = {Hierarchical planning and reasoning about partially ordered plans—From theory to practice},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Search and learning for unsupervised text generation.
<em>AIM</em>, <em>43</em>(4), 344–352. (<a
href="https://doi.org/10.1002/aaai.12068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advances of deep learning techniques, text generation is attracting increasing interest in the artificial intelligence (AI) community, because of its wide applications and because it is an essential component of AI. Traditional text generation systems are trained in a supervised way, requiring massive labeled parallel corpora. In this paper, I will introduce our recent work on search and learning approaches to unsupervised text generation, where a heuristic objective function estimates the quality of a candidate sentence, and discrete search algorithms generate a sentence by maximizing the search objective. A machine learning model further learns from the search results to smooth out noise and improve efficiency. Our approach is important to the industry for building minimal viable products for a new task; it also has high social impacts for saving human annotation labor and for processing low-resource languages. Link to video abstract: https://youtu.be/Xir1e9g6oIc},
  archive      = {J_AIM},
  author       = {Lili Mou},
  doi          = {10.1002/aaai.12068},
  journal      = {AI Magazine},
  month        = {12},
  number       = {4},
  pages        = {344-352},
  shortjournal = {AI Mag.},
  title        = {Search and learning for unsupervised text generation},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The new faculty highlights program at AAAI-21. <em>AIM</em>,
<em>43</em>(4), 343. (<a
href="https://doi.org/10.1002/aaai.12074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AIM},
  author       = {Kevin Leyton-Brown and Mausam and Qiang Yang},
  doi          = {10.1002/aaai.12074},
  journal      = {AI Magazine},
  month        = {12},
  number       = {4},
  pages        = {343},
  shortjournal = {AI Mag.},
  title        = {The new faculty highlights program at AAAI-21},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The return of intelligent textbooks. <em>AIM</em>,
<em>43</em>(3), 337–340. (<a
href="https://doi.org/10.1002/aaai.12061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement of computational Artificial Intelligence (AI) in the recent decade has been transformative for many domains, including AI in Education. One direction, where it has caused a noticeable increase in research activity, is application of AI technologies to enhance digital textbooks by making them more interactive, engaging, adaptive, and intelligent. For many researchers coming into this field, it would have seemed as if an intelligent textbook is a completely new idea. We would like to provide a historic outlook on this field and outline the important phases that it went through over the last three decades. We hope that such an account can inform interested readers and help them better understand the problems and the approaches of intelligent textbooks.},
  archive      = {J_AIM},
  author       = {Peter Brusilovsky and Sergey Sosnovsky and Khushboo Thaker},
  doi          = {10.1002/aaai.12061},
  journal      = {AI Magazine},
  month        = {9},
  number       = {3},
  pages        = {337-340},
  shortjournal = {AI Mag.},
  title        = {The return of intelligent textbooks},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial intelligence and auditing in small- and
medium-sized firms: Expectations and applications. <em>AIM</em>,
<em>43</em>(3), 323–336. (<a
href="https://doi.org/10.1002/aaai.12066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Auditing is a field of expertise often mentioned as being ripe for automation using artificial intelligence methods at all levels of operations. Primarily, the application of artificial intelligence (AI) in the auditing profession is done by and for large organizations, leveraging large datasets. While AI approaches for big data are continually improving, methods for small data are scarce. Yet most firms in the world employ fewer than 50 people and can, therefore, rarely rely on big data for automation. In our study, we ask auditors, who mainly audit SMEs, about their expectations towards the impact of AI on the auditing profession and where they expect it to provide the most value when it comes to auditing SMEs. We find that these auditors expect significant improvements in their own efficiency on the job, that learning to use AI applications will not be a challenge for them, and that the use of AI in auditing firms will become mandatory in the future. They expect the performance of certain tasks to become AI-augmented, including risk assessment of individual transactions, conducting audit interviews, performing all manners of analysis, writing confirmation letters, performing the final verification of annual reports, and performing physical observations. Considering these results, we discuss the potential impact of these developments, such as how AI could make the auditing process more effective and efficient but also how AI could lead to an even higher concentration of the auditing service industry.},
  archive      = {J_AIM},
  author       = {Pall Rikhardsson and Kristinn R. Thórisson and Gudmundur Bergthorsson and Catherine Batt},
  doi          = {10.1002/aaai.12066},
  journal      = {AI Magazine},
  month        = {9},
  number       = {3},
  pages        = {323-336},
  shortjournal = {AI Mag.},
  title        = {Artificial intelligence and auditing in small- and medium-sized firms: Expectations and applications},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neurocompositional computing: From the central paradox of
cognition to a new generation of AI systems. <em>AIM</em>,
<em>43</em>(3), 308–322. (<a
href="https://doi.org/10.1002/aaai.12065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {What explains the dramatic progress from 20th-century to 21st-century AI, and how can the remaining limitations of current AI be overcome? The widely accepted narrative attributes this progress to massive increases in the quantity of computational and data resources available to support statistical learning in deep artificial neural networks. We show that an additional crucial factor is the development of a new type of computation. Neurocompositional computing adopts two principles that must be simultaneously respected to enable human-level cognition: the principles of Compositionality and Continuity. These have seemed irreconcilable until the recent mathematical discovery that compositionality can be realized not only through discrete methods of symbolic computing, but also through novel forms of continuous neural computing. The revolutionary recent progress in AI has resulted from the use of limited forms of neurocompositional computing. New, deeper forms of neurocompositional computing create AI systems that are more robust, accurate, and comprehensible.},
  archive      = {J_AIM},
  author       = {Paul Smolensky and Richard Thomas McCoy and Roland Fernandez and Matthew Goldrick and Jianfeng Gao},
  doi          = {10.1002/aaai.12065},
  journal      = {AI Magazine},
  month        = {9},
  number       = {3},
  pages        = {308-322},
  shortjournal = {AI Mag.},
  title        = {Neurocompositional computing: From the central paradox of cognition to a new generation of AI systems},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The AI field needs translational ethical AI research.
<em>AIM</em>, <em>43</em>(3), 294–307. (<a
href="https://doi.org/10.1002/aaai.12062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Calls for Ethical AI have become urgent and pervasive, especially as ethical issues surrounding AI products at tech companies are increasingly scrutinized by the public. Yet even after a first wave of responses to these calls coalesced around Ethical AI principles to guide decision-making and a second wave generated technical tools to mitigate specific ethical issues, multiple lines of evidence indicate that these Ethical AI principles and technical tools have only a limited impact on the daily practices of AI users and producers. In other words, there is a big gap between what we publish in academic papers and what AI creators need to generate AI products that reflect society&#39;s values. Ethical AI is by no means the only field to have this problem. However, when medical and ecology fields documented similar gaps between their fields’ scientific discoveries and the practices and products that people actually use, they invested tremendous resources into subfields that developed evidence about how to translate what was done in the lab to adopted solutions. I argue in this commentary that it is our research community&#39;s moral duty to invest in our own subfield of “Translational Ethical AI” that will determine how best to ensure AI practitioners can implement the Ethical AI technical tools we publish in academic venues in production settings. Further, I offer concrete steps for doing that, drawing on insights gleaned from other translational fields. Closing the “Ethical AI Publication-to-Practice gap” will be a considerable transdisciplinary challenge, but one of the AI research community has the unique expertise, political leverage, and moral responsibility to tackle.},
  archive      = {J_AIM},
  author       = {Jana Schaich Borg},
  doi          = {10.1002/aaai.12062},
  journal      = {AI Magazine},
  month        = {9},
  number       = {3},
  pages        = {294-307},
  shortjournal = {AI Mag.},
  title        = {The AI field needs translational ethical AI research},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Advanced artificial agents intervene in the provision of
reward. <em>AIM</em>, <em>43</em>(3), 282–293. (<a
href="https://doi.org/10.1002/aaai.12064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze the expected behavior of an advanced artificial agent with a learned goal planning in an unknown environment. Given a few assumptions, we argue that it will encounter a fundamental ambiguity in the data about its goal. For example, if we provide a large reward to indicate that something about the world is satisfactory to us, it may hypothesize that what satisfied us was the sending of the reward itself; no observation can refute that. Then we argue that this ambiguity will lead it to intervene in whatever protocol we set up to provide data for the agent about its goal. We discuss an analogous failure mode of approximate solutions to assistance games. Finally, we briefly review some recent approaches that may avoid this problem.},
  archive      = {J_AIM},
  author       = {Michael K. Cohen and Marcus Hutter and Michael A. Osborne},
  doi          = {10.1002/aaai.12064},
  journal      = {AI Magazine},
  month        = {9},
  number       = {3},
  pages        = {282-293},
  shortjournal = {AI Mag.},
  title        = {Advanced artificial agents intervene in the provision of reward},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Transformative research focus considered harmful.
<em>AIM</em>, <em>43</em>(3), 273–281. (<a
href="https://doi.org/10.1002/aaai.12063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers are often encouraged to pursue nothing short of revolutionary advances, and those who work in artificial intelligence are no exception. However, an exclusive focus on revolutionary breakthroughs is often counterproductive in science. As explained by Kuhn almost 50 years ago, dramatic breakthroughs usually rely on a foundation of less dramatic advances, which uncover anomalies and make marginal improvements to current efforts. Progress relies on an essential tension between convergent and divergent thinking, each being complementary aspects of the same process. We argue that an overemphasis on, and exclusive rewarding of, divergent thinking in contemporary AI—whether in the form of rejecting funding for nontransformative research, or peer-review criteria rejecting papers for lack of novelty—is counterproductive to artificial intelligence and machine learning research, and may even be fundamentally harmful to progress in the field. To reckon with this problem, we recommend increasing funding for iterative improvement of theories, better guidance for reviewers, and more transparency in public funding.},
  archive      = {J_AIM},
  author       = {Michael Cooper and John Licato},
  doi          = {10.1002/aaai.12063},
  journal      = {AI Magazine},
  month        = {9},
  number       = {3},
  pages        = {273-281},
  shortjournal = {AI Mag.},
  title        = {Transformative research focus considered harmful},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CORRIGENDUM. <em>AIM</em>, <em>43</em>(2), 270. (<a
href="https://doi.org/10.1002/aaai.12045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AIM},
  doi          = {10.1002/aaai.12045},
  journal      = {AI Magazine},
  month        = {6},
  number       = {2},
  pages        = {270},
  shortjournal = {AI Mag.},
  title        = {CORRIGENDUM},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Looking back, looking ahead: Humans, ethics, and AI.
<em>AIM</em>, <em>43</em>(2), 267–269. (<a
href="https://doi.org/10.1002/aaai.12052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AIM},
  author       = {Ashok K. Goel},
  doi          = {10.1002/aaai.12052},
  journal      = {AI Magazine},
  month        = {6},
  number       = {2},
  pages        = {267-269},
  shortjournal = {AI Mag.},
  title        = {Looking back, looking ahead: Humans, ethics, and AI},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey of knowledge-based sequential decision-making under
uncertainty. <em>AIM</em>, <em>43</em>(2), 249–266. (<a
href="https://doi.org/10.1002/aaai.12053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reasoning with declarative knowledge (RDK) and sequential decision-making (SDM) are two key research areas in artificial intelligence. RDK methods reason with declarative domain knowledge, including commonsense knowledge, that is either provided a priori or acquired over time, while SDM methods (probabilistic planning [PP] and reinforcement learning [RL]) seek to compute action policies that maximize the expected cumulative utility over a time horizon; both classes of methods reason in the presence of uncertainty. Despite the rich literature in these two areas, researchers have not fully explored their complementary strengths. In this paper, we survey algorithms that leverage RDK methods while making sequential decisions under uncertainty. We discuss significant developments, open problems, and directions for future work.},
  archive      = {J_AIM},
  author       = {Shiqi Zhang and Mohan Sridharan},
  doi          = {10.1002/aaai.12053},
  journal      = {AI Magazine},
  month        = {6},
  number       = {2},
  pages        = {249-266},
  shortjournal = {AI Mag.},
  title        = {A survey of knowledge-based sequential decision-making under uncertainty},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Designing for human–AI complementarity in k-12 education.
<em>AIM</em>, <em>43</em>(2), 239–248. (<a
href="https://doi.org/10.1002/aaai.12058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent work has explored how complementary strengths of humans and artificial intelligence (AI) systems might be productively combined. However, successful forms of human–AI partnership have rarely been demonstrated in real-world settings. We present the iterative design and evaluation of Lumilo, smart glasses that help teachers help their students in AI-supported classrooms by presenting real-time analytics about students’ learning, metacognition, and behavior. Results from a field study conducted in K-12 classrooms indicate that students learn more when teachers and AI tutors work together during class. We discuss implications of this research for the design of human–AI partnerships. We argue for more participatory approaches to research and design in this area, in which practitioners and other stakeholders are deeply, meaningfully involved throughout the process. Furthermore, we advocate for theory-building and for principled approaches to the study of human–AI decision-making in real-world contexts.},
  archive      = {J_AIM},
  author       = {Kenneth Holstein and Vincent Aleven},
  doi          = {10.1002/aaai.12058},
  journal      = {AI Magazine},
  month        = {6},
  number       = {2},
  pages        = {239-248},
  shortjournal = {AI Mag.},
  title        = {Designing for human–AI complementarity in K-12 education},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Offline recommender system evaluation: Challenges and new
directions. <em>AIM</em>, <em>43</em>(2), 225–238. (<a
href="https://doi.org/10.1002/aaai.12051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline evaluation is an essential complement to online experiments in the selection, improvement, tuning, and deployment of recommender systems. Offline methodologies for recommender system evaluation evolved from experimental practice in Machine Learning (ML) and Information Retrieval (IR). However, evaluating recommendations involves particularities that pose challenges to the assumptions upon which the ML and IR methodologies were developed. We recap and reflect on the development and current status of recommender system evaluation, providing an updated perspective. With a focus on offline evaluation, we review the adaptation of IR principles, procedures and metrics, and the implications of those techniques when applied to recommender systems. At the same time, we identify the singularities of recommendation that require different responses, or involve specific new needs. In addition, we provide an overview of important choices in the configuration of experiments that require particular care and understanding; discuss broader perspectives of evaluation such as recommendation value beyond accuracy; and survey open challenges such as experimental biases, and the cyclic dimension of recommendation.},
  archive      = {J_AIM},
  author       = {Pablo Castells and Alistair Moffat},
  doi          = {10.1002/aaai.12051},
  journal      = {AI Magazine},
  month        = {6},
  number       = {2},
  pages        = {225-238},
  shortjournal = {AI Mag.},
  title        = {Offline recommender system evaluation: Challenges and new directions},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Building effective recommender systems for tourists.
<em>AIM</em>, <em>43</em>(2), 209–224. (<a
href="https://doi.org/10.1002/aaai.12057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems (RSs) are personalized information search and discovery applications helping users to identify and choose useful items and information. In this paper, we focus on the tourism application scenario and its specific requirements. We discuss a novel RS approach that copes with the specific application constraints of the domain and produces recommendations that better match the true needs of tourists. We illustrate the proposed next POI recommendation approach in a case study and we compare it with a state-of-the-art nearest neighbor-based next item RS. With the analysis of this case study, we aim at illustrating the specific features of the compared approaches also with the goal to raise the discussion on RSs validation methods, with a particular attention to tourism applications. We finally discuss some significant limitations of current evaluation approaches that must be addressed in future studies.},
  archive      = {J_AIM},
  author       = {David Massimo and Francesco Ricci},
  doi          = {10.1002/aaai.12057},
  journal      = {AI Magazine},
  month        = {6},
  number       = {2},
  pages        = {209-224},
  shortjournal = {AI Mag.},
  title        = {Building effective recommender systems for tourists},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Explainability in music recommender systems. <em>AIM</em>,
<em>43</em>(2), 190–208. (<a
href="https://doi.org/10.1002/aaai.12056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The most common way to listen to recorded music nowadays is via streaming platforms, which provide access to tens of millions of tracks. To assist users in effectively browsing these large catalogs, the integration of music recommender systems (MRSs) has become essential. Current real-world MRSs are often quite complex and optimized for recommendation accuracy. They combine several building blocks based on collaborative filtering and content-based recommendation. This complexity can hinder the ability to explain recommendations to end users, which is particularly important for recommendations perceived as unexpected or inappropriate. While pure recommendation performance often correlates with user satisfaction, explainability has a positive impact on other factors such as trust and forgiveness, which are ultimately essential to maintain user loyalty. In this article, we discuss how explainability can be addressed in the context of MRSs. We provide perspectives on how explainability could improve music recommendation algorithms and enhance user experience. First, we review common dimensions and goals of recommenders explainability and in general of eXplainable Artificial Intelligence (XAI), and elaborate on the extent to which these apply—or need to be adapted—to the specific characteristics of music consumption and recommendation. Then, we show how explainability components can be integrated within a MRS and in what form explanations can be provided. Since the evaluation of explanation quality is decoupled from pure accuracy-based evaluation criteria, we also discuss requirements and strategies for evaluating explanations of music recommendations. Finally, we describe the current challenges for introducing explainability within a large-scale industrial MRS and provide research perspectives.},
  archive      = {J_AIM},
  author       = {Darius Afchar and Alessandro B. Melchiorre and Markus Schedl and Romain Hennequin and Elena V. Epure and Manuel Moussallam},
  doi          = {10.1002/aaai.12056},
  journal      = {AI Magazine},
  month        = {6},
  number       = {2},
  pages        = {190-208},
  shortjournal = {AI Mag.},
  title        = {Explainability in music recommender systems},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Recommender systems, ground truth, and preference pollution.
<em>AIM</em>, <em>43</em>(2), 177–189. (<a
href="https://doi.org/10.1002/aaai.12055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interactions between individuals and recommender systems can be viewed as a continuous feedback loop, consisting of pre-consumption and post-consumption phases. Pre-consumption, systems provide recommendations that are typically based on predictions of user preferences. They represent a valuable service for both providers and users as decision aids. After item consumption, the user provides post-consumption feedback (e.g., a preference rating) to the system, often used to improve the system&#39;s subsequent recommendations, completing the feedback loop. There is a growing understanding that this feedback loop can be a significant source of unintended consequences, introducing decision-making biases that can affect the quality of the “ground truth” preference data, which serves as the key input to modern recommender systems. This paper highlights two forms of bias that recommender systems inherently inflict on the “ground truth” preference data collected from users after item consumption: non-representativeness of such preference data and so-called “preference pollution,” which denotes an unintended relationship between system recommendations and the user&#39;s post-consumption preference ratings. We provide an overview of these issues and their importance for the design and application of next-generation recommendation systems, including directions for future research.},
  archive      = {J_AIM},
  author       = {Gediminas Adomavicius and Jesse C. Bockstedt and Shawn P. Curley and Jingjing Zhang},
  doi          = {10.1002/aaai.12055},
  journal      = {AI Magazine},
  month        = {6},
  number       = {2},
  pages        = {177-189},
  shortjournal = {AI Mag.},
  title        = {Recommender systems, ground truth, and preference pollution},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The multisided complexity of fairness in recommender
systems. <em>AIM</em>, <em>43</em>(2), 164–176. (<a
href="https://doi.org/10.1002/aaai.12054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems are poised at the interface between stakeholders: for example, job applicants and employers in the case of recommendations of employment listings, or artists and listeners in the case of music recommendation. In such multisided platforms, recommender systems play a key role in enabling discovery of products and information at large scales. However, as they have become more and more pervasive in society, the equitable distribution of their benefits and harms have been increasingly under scrutiny, as is the case with machine learning generally. While recommender systems can exhibit many of the biases encountered in other machine learning settings, the intersection of personalization and multisidedness makes the question of fairness in recommender systems manifest itself quite differently. In this article, we discuss recent work in the area of multisided fairness in recommendation, starting with a brief introduction to core ideas in algorithmic fairness and multistakeholder recommendation. We describe techniques for measuring fairness and algorithmic approaches for enhancing fairness in recommendation outputs. We also discuss feedback and popularity effects that can lead to unfair recommendation outcomes. Finally, we introduce several promising directions for future research in this area.},
  archive      = {J_AIM},
  author       = {Nasim Sonboli and Robin Burke and Michael Ekstrand and Rishabh Mehrotra},
  doi          = {10.1002/aaai.12054},
  journal      = {AI Magazine},
  month        = {6},
  number       = {2},
  pages        = {164-176},
  shortjournal = {AI Mag.},
  title        = {The multisided complexity of fairness in recommender systems},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Conversational recommendation: A grand AI challenge.
<em>AIM</em>, <em>43</em>(2), 151–163. (<a
href="https://doi.org/10.1002/aaai.12059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Animated avatars, which look and talk like humans, are iconic visions of the future of AI-powered systems. Through many sci-fi movies, we are acquainted with the idea of speaking to such virtual personalities as if they were humans. Today, we talk more and more to machines like Apple&#39;s Siri, for example, to ask them for the weather forecast. However, when asked for recommendations, for example, for a restaurant to go to, the limitations of such devices quickly become obvious. They do not engage in a conversation to find out what we might prefer, they often do not provide explanations for what they recommend, and they may have difficulties remembering what was said 1 min earlier. Conversational recommender systems (CRS) promise to address these limitations. In this paper, we review existing approaches to building such systems, which developments we observe today, which challenges are still open and why the development of conversational recommenders represents one of the next grand challenges of AI.},
  archive      = {J_AIM},
  author       = {Dietmar Jannach and Li Chen},
  doi          = {10.1002/aaai.12059},
  journal      = {AI Magazine},
  month        = {6},
  number       = {2},
  pages        = {151-163},
  shortjournal = {AI Mag.},
  title        = {Conversational recommendation: A grand AI challenge},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Recommender systems: Trends and frontiers. <em>AIM</em>,
<em>43</em>(2), 145–150. (<a
href="https://doi.org/10.1002/aaai.12050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems (RSs), as used by Netflix, YouTube, or Amazon, are one of the most compelling success stories of AI. Enduring research activity in this area has led to a continuous improvement of recommendation techniques over the years, and today&#39;s RSs are indeed often capable to make astonishingly good suggestions. With countless papers being published on the topic each year, one might think the recommendation problem is almost solved. In reality, however, the large majority of published works focuses on algorithmic improvements and relies on data-based evaluation procedures which may sometimes tell us little regarding the effects new algorithms will have in practice. This special issue contains a set of papers which address some of the open challenges and frontiers in RSs research: (i) building interactive and conversational solutions, (ii) understanding recommender systems as socio-technical systems with longitudinal dynamics, (iii) avoiding abstraction traps, and (iv) finding better ways of assessing the impact and value of recommender systems without field tests.},
  archive      = {J_AIM},
  author       = {Dietmar Jannach and Pearl Pu and Francesco Ricci and Markus Zanker},
  doi          = {10.1002/aaai.12050},
  journal      = {AI Magazine},
  month        = {6},
  number       = {2},
  pages        = {145-150},
  shortjournal = {AI Mag.},
  title        = {Recommender systems: Trends and frontiers},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). The success of conversational AI and the AI evaluation
challenge it reveals. <em>AIM</em>, <em>43</em>(1), 139–141. (<a
href="https://doi.org/10.1002/aaai.12030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research interest in Conversational artificial intelligence (ConvAI) has experienced a massive growth over the last few years and several recent advancements have enabled systems to produce rich and varied turns in conversations similar to humans. However, this apparent creativity is also creating a real challenge in the objective evaluation of such systems as authors are becoming reliant on crowd worker opinions as the primary measurement of success and, so far, few papers are reporting all that is necessary for others to compare against in their own crowd experiments. This challenge is not unique to ConvAI, but demonstrates as AI systems mature in more “human” tasks that involve creativity and variation, evaluation strategies need to mature with them.},
  archive      = {J_AIM},
  author       = {Ian Beaver},
  doi          = {10.1002/aaai.12030},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {139-141},
  shortjournal = {AI Mag.},
  title        = {The success of conversational AI and the AI evaluation challenge it reveals},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Decoding human behavior with big data? Critical,
constructive input from the decision sciences. <em>AIM</em>,
<em>43</em>(1), 126–138. (<a
href="https://doi.org/10.1002/aaai.12034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big data analytics employs algorithms to uncover people&#39;s preferences and values, and support their decision making. A central assumption of big data analytics is that it can explain and predict human behavior. We investigate this assumption, aiming to enhance the knowledge basis for developing algorithmic standards in big data analytics. First, we argue that big data analytics is by design atheoretical and does not provide process-based explanations of human behavior; thus, it is unfit to support deliberation that is transparent and explainable. Second, we review evidence from interdisciplinary decision science, showing that the accuracy of complex algorithms used in big data analytics for predicting human behavior is not consistently higher than that of simple rules of thumb. Rather, it is lower in situations such as predicting election outcomes, criminal profiling, and granting bail. Big data algorithms can be considered as candidate models for explaining, predicting, and supporting human decision making when they match, in transparency and accuracy, simple, process-based, domain-grounded theories of human behavior. Big data analytics can be inspired by behavioral and cognitive theory.},
  archive      = {J_AIM},
  author       = {Konstantinos V. Katsikopoulos and Marc C. Canellas},
  doi          = {10.1002/aaai.12034},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {126-138},
  shortjournal = {AI Mag.},
  title        = {Decoding human behavior with big data? critical, constructive input from the decision sciences},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The third AI summer: AAAI robert s. Engelmore memorial
lecture. <em>AIM</em>, <em>43</em>(1), 105–125. (<a
href="https://doi.org/10.1002/aaai.12036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AIM},
  author       = {Henry A. Kautz},
  doi          = {10.1002/aaai.12036},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {105-125},
  shortjournal = {AI Mag.},
  title        = {The third AI summer: AAAI robert s. engelmore memorial lecture},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enabling AI innovation via data and model sharing: An
overview of the NSF convergence accelerator track d. <em>AIM</em>,
<em>43</em>(1), 93–104. (<a
href="https://doi.org/10.1002/aaai.12042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article provides a brief overview of 18 projects funded in Track D—Data and Model Sharing to Enable AI Innovation—of the 2020 Cohort of the National Science Foundation&#39;s (NSF) Convergence Accelerator (CA) program. The NSF CA is focused on transitioning research to practice for societal impact. The projects described here were funded for one year in phase I of the program, beginning September 2020. Their focus is on delivering tools, technologies, and techniques to assist in sharing data as well as data-driven models to enable AI innovation. A broad range of domain areas is covered by the funded efforts, spanning across healthcare and medicine, to climate change and disaster, and civil/built infrastructure. The projects are addressing sharing of open as well as sensitive/private data. In September 2021, six of the eighteen projects described here were selected for phase II of the program, as noted in this article.},
  archive      = {J_AIM},
  author       = {Chaitanya Baru and Michael Pozmantier and Ilkay Altintas and Stephen Baek and Jonathan Cohen and Laura Condon and Giulia Fanti and Raul Castro Fernandez and Ethan Jackson and Upmanu Lall and Bennett Landman and Hai Helen Li and Claudia Marin and Beatriz Martinez Lopez and Dimitris Metaxas and Bradley Olsen and Grier Page and Jingbo Shang and Yelda Turkan and Peng Zhang},
  doi          = {10.1002/aaai.12042},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {93-104},
  shortjournal = {AI Mag.},
  title        = {Enabling AI innovation via data and model sharing: An overview of the NSF convergence accelerator track d},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Human-centered intelligent training for emergency
responders. <em>AIM</em>, <em>43</em>(1), 83–92. (<a
href="https://doi.org/10.1002/aaai.12041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emergency response (ER) workers perform extremely demanding physical and cognitive tasks that can result in serious injuries and loss of life. Human augmentation technologies have the potential to enhance physical and cognitive work-capacities, thereby dramatically transforming the landscape of ER work, reducing injury risk, improving ER, as well as helping attract and retain skilled ER workers. This opportunity has been significantly hindered by the lack of high-quality training for ER workers that effectively integrates innovative and intelligent augmentation solutions. Hence, new ER learning environments are needed that are adaptive, affordable, accessible, and continually available for reskilling the ER workforce as technological capabilities continue to improve. This article presents the research considerations in the design and integration of use-inspired exoskeletons and augmented reality technologies in ER processes and the identification of unique cognitive and motor learning needs of each of these technologies in context-independent and ER-relevant scenarios. We propose a human-centered artificial intelligence (AI) enabled training framework for these technologies in ER. Finally, how these human-centered training requirements for nascent technologies are integrated in an intelligent tutoring system that delivers across tiered access levels, covering the range of virtual, to mixed, to physical reality environments, is discussed.},
  archive      = {J_AIM},
  author       = {Ranjana K. Mehta and Jason Moats and Rohith Karthikeyan and Joseph L. Gabbard and Divya Srinivasan and Eric Jing Du and Alexander Leonessa and Garret Burks and Andrew Stephenson and Ron Fernandes},
  doi          = {10.1002/aaai.12041},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {83-92},
  shortjournal = {AI Mag.},
  title        = {Human-centered intelligent training for emergency responders},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intelligent links: AI-supported connections between
employers and colleges. <em>AIM</em>, <em>43</em>(1), 75–82. (<a
href="https://doi.org/10.1002/aaai.12040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When modernization and other changes demand workforce reskilling, employers often turn to local colleges for training programs. Doing so can be a frustrating experience. HR and talent professionals have difficulty identifying and communicating requirements, especially for new jobs and roles, while college continuing education (CE) and professional development offices have difficulty understanding and responding to company needs. This article describes an NSF Convergence Accelerator project called SkillSync ™ in which multiple forms of AI are used to address this specific problem and provide national efforts (e.g., the US Chamber of Commerce Talent Pipeline Management initiative) with skills data and skills alignment services. Skillsync uses variations on the Siamese Multi-depth Transformer-based Hierarchical Encoder (SMITH) and other natural language understanding methods to map job descriptions and course information to skills taxonomies, uses machine-learned models to align skills needs with learning outcomes and training, and incorporates an intelligent coach based on Georgia Tech&#39;s Jill Watson “virtual teaching assistant” to answer questions about Skillsync&#39;s vocabulary, functionality, and process. This article describes these AI methods, how these methods are used in Skillsync, and the challenges involved.},
  archive      = {J_AIM},
  author       = {Robby Robson and Elaine Kelsey and Ashok Goel and Sazzad M. Nasir and Elliot Robson and Myk Garn and Matt Lisle and Jeanne Kitchens and Spencer Rugaber and Fritz Ray},
  doi          = {10.1002/aaai.12040},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {75-82},
  shortjournal = {AI Mag.},
  title        = {Intelligent links: AI-supported connections between employers and colleges},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The promise of AI in an open justice system. <em>AIM</em>,
<em>43</em>(1), 69–74. (<a
href="https://doi.org/10.1002/aaai.12039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To craft effective public policy, modern governments must gather and analyze data on both the performance of their public functions and the responses by the public. Federal administrative agencies such as the Patent Office and Centers for Disease Control routinely do this, as does the United States Congress. More importantly, they make such data freely accessible. Within the United States government, however, the judicial branch is a conspicuous outlier. In theory, federal court records could be used to evaluate the efficiency and fairness of the justice system. In practice, court records are effectively out of reach because they sit behind a government paywall. This financial barrier, along with an equally important myriad of technical obstacles, have forestalled the development of AI-driven analysis that could enable a systematic understanding and evaluation of the work of the courts. The Systematic Content Analysis of Litigation EventS Open Knowledge Network (SCALES OKN) seeks to address this situation by transforming the transparency and accessibility of court records. The SCALES OKN will potentiate the development of new AI solutions that will benefit the judiciary, legal scholars, and the public. In this article, we outline some of key financial, technical, and policy challenges to developing novel AI solutions.},
  archive      = {J_AIM},
  author       = {Adam R Pah and David L Schwartz and Sarath Sanga and Charlotte S Alexander and Kristian J Hammond and Luís A.N. Amaral},
  doi          = {10.1002/aaai.12039},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {69-74},
  shortjournal = {AI Mag.},
  title        = {The promise of AI in an open justice system},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Infrastructure for rapid open knowledge network development.
<em>AIM</em>, <em>43</em>(1), 59–68. (<a
href="https://doi.org/10.1002/aaai.12038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The past decade has witnessed a growth in the use of knowledge graph technologies for advanced data search, data integration, and query-answering applications. The leading example of a public, general-purpose open knowledge network ( aka knowledge graph) is Wikidata, which has demonstrated remarkable advances in quality and coverage over this time. Proprietary knowledge graphs drive some of the leading applications of the day including, for example, Google Search, Alexa, Siri, and Cortana. Open Knowledge Networks are exciting: they promise the power of structured database-like queries with the potential for the wide coverage that is today only provided by the Web. With the current state of the art, building, using, and scaling large knowledge networks can still be frustratingly slow. This article describes a National Science Foundation Convergence Accelerator project to build a set of Knowledge Network Programming Infrastructure systems to address this issue.},
  archive      = {J_AIM},
  author       = {Michael Cafarella and Michael Anderson and Iz Beltagy and Arie Cattan and Sarah Chasins and Ido Dagan and Doug Downey and Oren Etzioni and Sergey Feldman and Tian Gao and Tom Hope and Kexin Huang and Sophie Johnson and Daniel King and Kyle Lo and Yuze Lou and Matthew Shapiro and Dinghao Shen and Shivashankar Subramanian and Lucy Lu Wang and Yuning Wang and Yitong Wang and Daniel S. Weld and Jenny Vo-Phamhi and Anna Zeng and Jiayun Zou},
  doi          = {10.1002/aaai.12038},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {59-68},
  shortjournal = {AI Mag.},
  title        = {Infrastructure for rapid open knowledge network development},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A biomedical open knowledge network harnesses the power of
AI to understand deep human biology. <em>AIM</em>, <em>43</em>(1),
46–58. (<a href="https://doi.org/10.1002/aaai.12037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge representation and reasoning (KR&amp;R) has been successfully implemented in many fields to enable computers to solve complex problems with AI methods. However, its application to biomedicine has been lagging in part due to the daunting complexity of molecular and cellular pathways that govern human physiology and pathology. In this article, we describe concrete uses of Scalable PrecisiOn Medicine Knowledge Engine (SPOKE), an open knowledge network that connects curated information from thirty-seven specialized and human-curated databases into a single property graph, with 3 million nodes and 15 million edges to date. Applications discussed in this article include drug discovery, COVID-19 research and chronic disease diagnosis, and management.},
  archive      = {J_AIM},
  author       = {Sergio E. Baranzini and Katy Börner and John Morris and Charlotte A. Nelson and Karthik Soman and Erica Schleimer and Michael Keiser and Mark Musen and Roger Pearce and Tahsin Reza and Brett Smith and Bruce W. Herr and Boris Oskotsky and Angela Rizk-Jackson and Katherine P. Rankin and Stephan J. Sanders and Riley Bove and Peter W. Rose and Sharat Israni and Sui Huang},
  doi          = {10.1002/aaai.12037},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {46-58},
  shortjournal = {AI Mag.},
  title        = {A biomedical open knowledge network harnesses the power of AI to understand deep human biology},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Knowledge graphs to support real-time flood impact
evaluation. <em>AIM</em>, <em>43</em>(1), 40–45. (<a
href="https://doi.org/10.1002/aaai.12035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A digital map of the built environment is useful for a range of economic, emergency response, and urban planning exercises such as helping find places in app driven interfaces, helping emergency managers know what locations might be impacted by a flood or fire, and helping city planners proactively identify vulnerabilities and plan for how a city is growing. Since its inception in 2004, OpenStreetMap (OSM) sets the benchmark for open geospatial data and has become a key player in the public, research, and corporate realms. Following the foundations laid by OSM, several open geospatial products describing the built environment have blossomed including the Microsoft USA building footprint layer and the OpenAddress project. Each of these products use different data collection methods ranging from public contributions to artificial intelligence, and if taken together, could provide a comprehensive description of the built environment. Yet, these projects are still siloed, and their variety makes integration and interoperability a major challenge. Here, we document an approach for merging data from these three major open building datasets and outline a workflow that is scalable to the continental United States (CONUS). We show how the results can be structured as a knowledge graph over which machine learning models are built. These models can help propagate and complete unknown quantities that can then be leveraged in disaster management.},
  archive      = {J_AIM},
  author       = {J. Michael Johnson and Tom Narock and Justin Singh-Mohudpur and Doug Fils and Keith C. Clarke and Siddharth Saksena and Adam Shepherd and Sankar Arumugam and Lilit Yeghiazarian},
  doi          = {10.1002/aaai.12035},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {40-45},
  shortjournal = {AI Mag.},
  title        = {Knowledge graphs to support real-time flood impact evaluation},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Know, know where, KnowWhereGraph: A densely connected,
cross-domain knowledge graph and geo-enrichment service stack for
applications in environmental intelligence. <em>AIM</em>,
<em>43</em>(1), 30–39. (<a
href="https://doi.org/10.1002/aaai.12043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) are a novel paradigm for the representation, retrieval, and integration of data from highly heterogeneous sources. Within just a few years, KGs and their supporting technologies have become a core component of modern search engines, intelligent personal assistants, business intelligence, and so on. Interestingly, despite large-scale data availability, they have yet to be as successful in the realm of environmental data and environmental intelligence. In this paper, we will explain why spatial data require special treatment, and how and when to semantically lift environmental data to a KG. We will present our KnowWhereGraph that contains a wide range of integrated datasets at the human–environment interface, introduce our application areas, and discuss geospatial enrichment services on top of our graph. Jointly, the graph and services will provide answers to questions such as “what is here,” “what happened here before,” and “how does this region compare to …” for any region on earth within seconds.},
  archive      = {J_AIM},
  author       = {Krzysztof Janowicz and Pascal Hitzler and Wenwen Li and Dean Rehberger and Mark Schildhauer and Rui Zhu and Cogan Shimizu and Colby K. Fisher and Ling Cai and Gengchen Mai and Joseph Zalewski and Lu Zhou and Shirly Stephen and Seila Gonzalez and Bryce Mecum and Anna Lopez-Carr and Andrew Schroeder and David Smith and Dawn Wright and Sizhe Wang and Yuanyuan Tian and Zilong Liu and Meilin Shi and Anthony D&#39;Onofrio and Zhining Gu and Kitty Currier},
  doi          = {10.1002/aaai.12043},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {30-39},
  shortjournal = {AI Mag.},
  title        = {Know, know where, KnowWhereGraph: A densely connected, cross-domain knowledge graph and geo-enrichment service stack for applications in environmental intelligence},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Knowledge graphs: Introduction, history, and perspectives.
<em>AIM</em>, <em>43</em>(1), 17–29. (<a
href="https://doi.org/10.1002/aaai.12033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) have emerged as a compelling abstraction for organizing the world&#39;s structured knowledge and for integrating information extracted from multiple data sources. They are also beginning to play a central role in representing information extracted by AI systems, and for improving the predictions of AI systems by giving them knowledge expressed in KGs as input. The goals of this article are to (a) introduce KGs and discuss important areas of application that have gained recent prominence; (b) situate KGs in the context of the prior work in AI; and (c) present a few contrasting perspectives that help in better understanding KGs in relation to related technologies.},
  archive      = {J_AIM},
  author       = {Vinay K. Chaudhri and Chaitanya Baru and Naren Chittar and Xin Luna Dong and Michael Genesereth and James Hendler and Aditya Kalyanpur and Douglas B. Lenat and Juan Sequeda and Denny Vrandečić and Kuansan Wang},
  doi          = {10.1002/aaai.12033},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {17-29},
  shortjournal = {AI Mag.},
  title        = {Knowledge graphs: Introduction, history, and perspectives},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The NSF convergence accelerator program. <em>AIM</em>,
<em>43</em>(1), 6–16. (<a
href="https://doi.org/10.1002/aaai.12032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The National Science Foundation&#39;s Convergence Accelerator is a unique program offering researchers and innovators the opportunity to translate research results into tangible solutions that make a difference for society. Through an intense innovation curriculum and a mentorship program, researchers gain skills and experiences that are of use not only during this program but throughout their careers. This article describes the NSF Convergence Accelerator program and its initial funded convergence research topics—or “tracks”—funded in 2019 and 2020. In almost every track and NSF-funded project, artificial intelligence and machine learning (AI/ML) approaches and methods are playing an essential role.},
  archive      = {J_AIM},
  author       = {Chaitanya Baru and Lara Campbell and Aurali Dade and Pradeep Fulay and Alex Loewi and Douglas Maughan and Ibrahim Mohedas and Linda Molnar and Michael Pozmantier and Michael Reksulak and Shelby Smith and Nicole Tehrani},
  doi          = {10.1002/aaai.12032},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {6-16},
  shortjournal = {AI Mag.},
  title        = {The NSF convergence accelerator program},
  volume       = {43},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
