<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SII_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="sii---45">SII - 45</h2>
<ul>
<li><details>
<summary>
(2022). Multivariate bernstein fréchet copulas. <em>SII</em>,
<em>15</em>(4), 527–547. (<a
href="https://doi.org/10.4310/22-SII722">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding joint copulas based on given bivariate margins is an interesting problem. It involves in obtaining the copula from the information of its bivariate marginal distributions. In this paper, we present a multivariate copula family called multivariate Bernstein Fréchet (BF) copulas. Each copula in the family is uniquely determined by its bivariate margins, the bivariate BF copulas. For this purpose, we first discuss properties of the bivariate BF copulas, including supermigrativity and $\mathrm{TP}_2$ properties. The advantages of bivariate BF copula are identified by comparing it with the bivariate Gaussian copula and the bivariate Fréchet copula. We show that a multivariate BF copula is uniquely determined by its marginal bivariate BF copulas, and methods to construct the multivariate BF copula are discussed. Numerical studies are carried out for displaying the advantages of multivariate BF copulas.},
  archive      = {J_SII},
  author       = {Xie, Zongkai and Wang, Fang and Yang, Jingping and Guo, Nan},
  doi          = {10.4310/22-SII722},
  journal      = {Statistics and Its Interface},
  number       = {4},
  pages        = {527-547},
  shortjournal = {Stat. Interface},
  title        = {Multivariate bernstein fréchet copulas},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The more data, the better? Demystifying deletion-based
methods in linear regression with missing data. <em>SII</em>,
<em>15</em>(4), 515–526. (<a
href="https://doi.org/10.4310/21-SII717">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We compare two deletion-based methods for dealing with the problem of missing observations in linear regression analysis. One is the complete-case analysis (CC, or listwise deletion) that discards all incomplete observations and only uses common samples for ordinary least-squares estimation. The other is the available-case analysis (AC, or pairwise deletion) that utilizes all available data to estimate the covariance matrices and applies these matrices to construct the normal equation. We show that the estimates from both methods are asymptotically unbiased under missing completely at random (MCAR) and further compare their asymptotic variances in some typical situations. Surprisingly, using more data (i.e., AC) does not necessarily lead to better asymptotic efficiency in many scenarios. Missing patterns, covariance structure and true regression coefficient values all play a role in determining which is better. We further conduct simulation studies to corroborate the findings and demystify what has been missed or misinterpreted in the literature. Some detailed proofs and simulation results are available in the online supplemental materials.},
  archive      = {J_SII},
  author       = {Xu, Tianchen and Chen, Kun and Li, Gen},
  doi          = {10.4310/21-SII717},
  journal      = {Statistics and Its Interface},
  number       = {4},
  pages        = {515-526},
  shortjournal = {Stat. Interface},
  title        = {The more data, the better? demystifying deletion-based methods in linear regression with missing data},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). When to initiate cancer screening exam? <em>SII</em>,
<em>15</em>(4), 503–514. (<a
href="https://doi.org/10.4310/21-SII716">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A probability method is developed to decide when to initiate cancer screening for asymptomatic individuals. The probability of incidence is a function of screening sensitivity, time duration in the disease-free state and sojourn time in the preclinical state; and it is monotonically increasing as time increases, given a person’s current age. So a unique solution of the first screening time can be found by limiting this probability to a small value, such as 10% or 20%. That is, with 90% or 80% probability, one will not be a clinical incident case before the first exam. After this age is found, we can further estimate the lead time distribution and probability of over-diagnosis if one would be diagnosed with cancer at the first exam. Simulations were carried out under different scenarios; and the method was applied to two heavy smoker cohorts in the National Lung Screening Trial using low-dose computerized tomography. The method is applicable to other kinds of cancer screening. The predictive information can be used by physicians or individuals at risk to make informed decisions on when to initiate screening.},
  archive      = {J_SII},
  author       = {Wu, Dongfeng},
  doi          = {10.4310/21-SII716},
  journal      = {Statistics and Its Interface},
  number       = {4},
  pages        = {503-514},
  shortjournal = {Stat. Interface},
  title        = {When to initiate cancer screening exam?},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semiparametric transformation models of
survival-out-of-hospital. <em>SII</em>, <em>15</em>(4), 487–501. (<a
href="https://doi.org/10.4310/21-SII713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recurrent event data with a terminal event commonly arise in biomedical studies, and the survival-out-of-hospital process is a useful alternative framework for the analysis of recurrent/terminal event data with non-negligible event duration. In this article, we propose a class of semiparametric transformation models for the survival-out-of-hospital process, and the proposed models offer great flexibility in formulating covariate effects on the probability of survival-out-of-hospital. Estimating equation approaches are developed for the model parameters, and the asymptotic properties of the resulting estimators are established. The finite sample performance of the proposed estimators is examined through simulation studies. An application to a Centers for Medicare and Medicaid Services study is provided.},
  archive      = {J_SII},
  author       = {Sun, Xiaowei and Zeng, Cheng and Sun, Liuquan},
  doi          = {10.4310/21-SII713},
  journal      = {Statistics and Its Interface},
  number       = {4},
  pages        = {487-501},
  shortjournal = {Stat. Interface},
  title        = {Semiparametric transformation models of survival-out-of-hospital},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multivariate skew laplace normal distribution for modeling
skewness and heavy-tailedness in multivariate data sets. <em>SII</em>,
<em>15</em>(4), 475–485. (<a
href="https://doi.org/10.4310/21-SII711">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling both skewness and heavy-tailedness in multivariate data sets is a challenging problem. The main goal of this paper is to introduce a multivariate skew Laplace normal (MSLN) distribution to deal with the issue by providing a flexible model for modeling skewness and heavy-tailedness simultaneously. This distribution will be an alternative to some multivariate skew distributions including the multivariate skew-t-normal (MSTN) distribution introduced by [ 28 ]. This is due to the fact that the MSLN distribution has fewer parameters than most of these distributions, which causes computationally advantageous for the MSLN distribution over these distributions. The definition, some distributional properties of this distribution are studied. The maximum likelihood (ML) estimators for the parameters of the MSLN distribution are obtained via the expectation-maximization (EM) algorithm. A simulation study and a real data example are also provided to illustrate the capability of the MSLN distribution for modeling data sets in multivariate settings.},
  archive      = {J_SII},
  author       = {Doğru, Fatma Zehra and Arslan, Olcay},
  doi          = {10.4310/21-SII711},
  journal      = {Statistics and Its Interface},
  number       = {4},
  pages        = {475-485},
  shortjournal = {Stat. Interface},
  title        = {Multivariate skew laplace normal distribution for modeling skewness and heavy-tailedness in multivariate data sets},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A gibbs sampler for estimating the graded item response
model with likert-scale data via the pólya–gamma distribution: A
calculationally efficient data-augmentation scheme. <em>SII</em>,
<em>15</em>(4), 463–474. (<a
href="https://doi.org/10.4310/21-SII710">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper reports the use of a highly effective Pólya–Gamma Gibbs sampling algorithm [ 32 ] based on auxiliary variables to estimate the parameters of the graded response model (GRM; [ 34 ]) that has been used widely in educational and psychological assessments. As its name suggests, the algorithm can be viewed as an extension of the traditional Gibbs sampling algorithm, overcoming the defect that the latter is ineffective for Bayesian non-conjugate models. By introducing auxiliary variables, non-conjugate models are transformed into conjugate ones, and posterior sampling is easier to implement with the help of the traditional Gibbs sampling algorithm. Also, the algorithm avoids the Metropolis–Hastings sampling algorithm’s tedious adjustment of tuning parameters to achieve an appropriate acceptance probability. Two simulation studies are conducted, and data from the Sexual Compulsivity Scale are subjected to detailed analysis to further illustrate the proposed methodology.},
  archive      = {J_SII},
  author       = {Zhang, Zhaoyuan and Zhang, Jiwei and Lu, Jing},
  doi          = {10.4310/21-SII710},
  journal      = {Statistics and Its Interface},
  number       = {4},
  pages        = {463-474},
  shortjournal = {Stat. Interface},
  title        = {A gibbs sampler for estimating the graded item response model with likert-scale data via the Pólya–Gamma distribution: A calculationally efficient data-augmentation scheme},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Testing high-dimensional covariance matrices with random
projections and corrected likelihood ratio. <em>SII</em>,
<em>15</em>(4), 449–461. (<a
href="https://doi.org/10.4310/21-SII708">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Testing the equality between two high-dimensional covariance matrices is challenging. As the efficient way to measure evidential discrepancy from observed data, the likelihood ratio test is expected to be powerful when the null hypothesis is violated. However, when the data dimensionality becomes large and may substantially exceed the sample size, likelihood ratio based approaches are encountering both practical and theoretical difficulties. To solve the problem, we propose in this study to first randomly project the original high-dimensional data to some lower-dimensional space, and then to apply the corrected likelihood ratio tests developed with the random matrix theory. We show that our test is consistent under the null hypothesis. Through evaluating the power function which is a challenging objective in this context, we show evidence that our test based on random projection matrix with reasonable column size is more powerful when the two covariance matrices are unequal but component-wise discrepancy could be small—a weak and dense signal setting. Numerical studies with simulations and a real data analysis confirm the merits of our test.},
  archive      = {J_SII},
  author       = {Sun, Nan and Tang, Cheng Yong},
  doi          = {10.4310/21-SII708},
  journal      = {Statistics and Its Interface},
  number       = {4},
  pages        = {449-461},
  shortjournal = {Stat. Interface},
  title        = {Testing high-dimensional covariance matrices with random projections and corrected likelihood ratio},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Partial profile score feature selection in high-dimensional
generalized linear interaction models. <em>SII</em>, <em>15</em>(4),
433–447. (<a href="https://doi.org/10.4310/21-SII706">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential method is promising for feature selection in high-dimensional models. In this paper, we propose a sequential approach based on partial profile score dubbed as PPSFS to feature selection for a broad class of high-dimensional models, including high-dimensional generalized linear interaction models. The PPSFS approach has a prominent performance in feature selection while it keeps highly scalable for ultra-high-dimensional models. The selection consistency of the PPSFS approach is established under mild conditions. Comprehensive numerical studies demonstrating the performance of PPSFS are reported. A real data analysis for gene expression cancer RNA-Seq data is also presented.},
  archive      = {J_SII},
  author       = {Xu, Zengchao and Luo, Shan and Chen, Zehua},
  doi          = {10.4310/21-SII706},
  journal      = {Statistics and Its Interface},
  number       = {4},
  pages        = {433-447},
  shortjournal = {Stat. Interface},
  title        = {Partial profile score feature selection in high-dimensional generalized linear interaction models},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sufficient dimension reduction for spatial point processes
using weighted principal support vector machines. <em>SII</em>,
<em>15</em>(4), 415–431. (<a
href="https://doi.org/10.4310/21-SII705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider sufficient dimension reduction (SDR) for spatial point processes. SDR methods aim to identify a lower dimensional sufficient subspace of a data set, in a model-free manner. Most SDR results are based on independent data, and also often do not work well with binary data. [ 13 ] introduced a SDR framework for spatial point processes by characterizing point processes as a binary process, and applied several popular SDR methods to spatial point data. On the other hand, [ 29 ] proposed Weighted Principal Support Vector Machines (WPSVM) for SDR and showed that it performed better than other methods with binary data. We combine these two works and examine WPSVM for spatial point processes. We show consistency and asymptotic normality of the WPSVM estimated sufficient subspace under some conditions on the spatial process, and compare it with other SDR methods via a simulation study and an application to real data.},
  archive      = {J_SII},
  author       = {Datta, Subha and Loh, Ji Meng},
  doi          = {10.4310/21-SII705},
  journal      = {Statistics and Its Interface},
  number       = {4},
  pages        = {415-431},
  shortjournal = {Stat. Interface},
  title        = {Sufficient dimension reduction for spatial point processes using weighted principal support vector machines},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Causal measures using generalized difference-in-difference
approach with nonlinear models. <em>SII</em>, <em>15</em>(4), 399–413.
(<a href="https://doi.org/10.4310/21-SII704">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To assess the impact of interventions on observational studies, several approaches have been proposed for identification of causal effects. They include propensity score matching, regression discontinuity, instrumental variables and causal graphs. In this paper, we focus on the Differences-in-Differences. We review the subject, discuss its scope and limitations, and extend it to a class of nonlinear models, inducing more appropriate causal measures in relation to the type of response variable and the corresponding statistical model. More specifically, we extend the usual causal effect identification procedure for more general setups, particularly Generalized Linear Models, presenting the necessary assumptions. We call such methodology Generalized Difference-in-Difference method. To illustrate, we analyze novel data from three relevant health issues in Brazil: the demographic impact of the Zika virus outbreak on birth rates, and the impact of two distinct interventions in primary health care, namely the Family Health Program and the More Doctors Program, on hospitalizations rate. Such analyzes, besides original and referring to important topics, complement and extend previous studies. Finally, we argue, in the methodological and application sections, that the use of the Generalized Difference-in-Difference will help us to avoid errors and fallacies arising from the misapplication of the usual Difference-in-Difference method at different scales.},
  archive      = {J_SII},
  author       = {Taddeo, Marcelo M. and Amorim, Leila D. and Aquino, Rosana},
  doi          = {10.4310/21-SII704},
  journal      = {Statistics and Its Interface},
  number       = {4},
  pages        = {399-413},
  shortjournal = {Stat. Interface},
  title        = {Causal measures using generalized difference-in-difference approach with nonlinear models},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Asymptotic in a class of network models with a difference
private degree sequence. <em>SII</em>, <em>15</em>(3), 383–397. (<a
href="https://doi.org/10.4310/21-SII702">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The asymptotic properties of parameter estimators with a difference private degree sequence have been derived in $\beta$‑model with common binary values, but the general asymptotic properties in network models are lacking. Therefore, we will establish the unified asymptotic result including the consistency and asymptotical normality of the parameter estimator in a class of network models with a difference private degree sequence. Simulations are provided to illustrate asymptotic results.},
  archive      = {J_SII},
  author       = {Luo, Jing and Qin, Hong},
  doi          = {10.4310/21-SII702},
  journal      = {Statistics and Its Interface},
  number       = {3},
  pages        = {383-397},
  shortjournal = {Stat. Interface},
  title        = {Asymptotic in a class of network models with a difference private degree sequence},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiple penalized regularization for clusters with varying
correlation levels. <em>SII</em>, <em>15</em>(3), 373–382. (<a
href="https://doi.org/10.4310/21-SII701">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the high-dimensional correlated data with multi-level correlations. These data appear frequently in many fields, e.g., genes in gene pathways or stock in industry groups. It motivates us not only to exploit these clusters but also to distinguish the correlation levels. Besides, we analyze the data without pre-specified clustering information to covariates. A two-step method is proposed to address the above problems. The first step focuses on distinguishing the levels and clustering. We aim to divide covariates into sub-vectors, considering both grouping effect and varying correlation. In the second step, we propose a joint estimation and a modified coordinate descent algorithm. The proposed procedure estimates different correlated groups with different penalties. We provide the theoretical guarantees of this method. Numerical comparisons show that the method works effectively on the multi-level correlation structures. We also apply the proposed method to financial data and get interpretable results.},
  archive      = {J_SII},
  author       = {Cao, Wenjun and Wang, Lisu and Yang, Yuehan},
  doi          = {10.4310/21-SII701},
  journal      = {Statistics and Its Interface},
  number       = {3},
  pages        = {373-382},
  shortjournal = {Stat. Interface},
  title        = {Multiple penalized regularization for clusters with varying correlation levels},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Depth-invariant beamforming for functional connectivity with
MEG data. <em>SII</em>, <em>15</em>(3), 359–371. (<a
href="https://doi.org/10.4310/21-SII700">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conventional beamformers that reconstruct the cerebral origin of brain activity measured outside the head via electro- and magneto-encephalography (EEG/MEG) suffer from depth bias and smearing of nearby sources. Here, to meet these methodological challenges, we propose a depth-invariant and forward beamformer for magneto-encephalography (MEG) data. Based on the new proposal, we further develop a two-step approach for inferring functional connectivity in the brain. The proposed methodology is invariant with respect to source depths in the brain. It nulls smearing of nearby sources and allows for time-varying source orientations. We illustrate the new approach with MEG data derived from a face-perception experiment, revealing patterns of functional connectivity for face perception. We identify a set of brain regions where their responses and connectivity are significantly varying when stimuli alter between faces and scrambled faces. By simulation studies, we show that the proposed forward beamformer can outperform the forward methods based on conventional beamformers in terms of localization bias.},
  archive      = {J_SII},
  author       = {Zhang, Jian},
  doi          = {10.4310/21-SII700},
  journal      = {Statistics and Its Interface},
  number       = {3},
  pages        = {359-371},
  shortjournal = {Stat. Interface},
  title        = {Depth-invariant beamforming for functional connectivity with MEG data},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimation of preclinical state onset age and sojourn time
for heavy smokers in lung cancer. <em>SII</em>, <em>15</em>(3), 349–358.
(<a href="https://doi.org/10.4310/21-SII696">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimation of the three key parameters: onset age of the preclinical state, sojourn time and screening sensitivity is critical in cancer screening, since all other terms are functions of the three. A novel link function to connect sensitivity with time in the preclinical state and the likelihood method were used in this project; since sensitivity depends on how long one has entered the preclinical state relative to the total sojourn time. Simulations using Markov Chain Monte Carlo and maximum likelihood estimate were carried out to estimate the key parameters for male and female heavy smokers separately in the low-dose computed tomography group of the National Lung Screening Trial. Sensitivity for male and female heavy smokers were 0.883 and 0.915 respectively at the onset of the preclinical state, and increased to 0.972 and 0.981 at the end. The mean age to make the transition into the preclinical state was 70.94 or 71.15 for male and female heavy smokers respectively, and 90% of heavy smokers at risk for lung cancer would enter the preclinical state in age interval (55.7, 85.8) for males and (54.2, 87.7) for females, and the transition peaked around age 69 for both genders. The mean sojourn time in the preclinical state was 1.43 and 1.49 years, and the 99% credible intervals for the sojourn time were (0.21, 2.96) and (0.37, 2.69) years for male and female heavy smokers correspondingly. Based on the result, low-dose CT should be started at age 55 and ended before 85 for heavy smokers. This provided important information to policy makers.},
  archive      = {J_SII},
  author       = {Wu, Dongfeng and Rai, Shesh N. and Seow, Albert},
  doi          = {10.4310/21-SII696},
  journal      = {Statistics and Its Interface},
  number       = {3},
  pages        = {349-358},
  shortjournal = {Stat. Interface},
  title        = {Estimation of preclinical state onset age and sojourn time for heavy smokers in lung cancer},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Paired-sample tests for homogeneity with/without confounding
variables. <em>SII</em>, <em>15</em>(3), 335–348. (<a
href="https://doi.org/10.4310/21-SII695">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we are concerned about testing the homogeneity on paired samples with or without confounding variables. These problems usually arise in clinical trials, psychological or sociological studies. We introduce new nonparametric tests for equality of two distributions or two conditional distributions of random vectors on paired samples. We show that their test statistics are consistent but have different asymptotic distributions under the null hypothesis, depending on whether confounding variables exist. The limit distribution of the test statistic is a mixed $\chi^2$ distribution when testing the equality of two paired distributions, while it is a normal distribution when testing the equality of two conditional distributions of paired samples. We conduct several simulation studies to evaluate the finite-sample performance of our tests. Finally, we apply our tests on real data to illustrate their usefulness in the applications.},
  archive      = {J_SII},
  author       = {Chen, Minqiong and Tian, Ting and Zhu, Jin and Pan, Wenliang and Wang, Xueqin},
  doi          = {10.4310/21-SII695},
  journal      = {Statistics and Its Interface},
  number       = {3},
  pages        = {335-348},
  shortjournal = {Stat. Interface},
  title        = {Paired-sample tests for homogeneity with/without confounding variables},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Local neighborhood-based approach of link prediction in
networks. <em>SII</em>, <em>15</em>(3), 323–334. (<a
href="https://doi.org/10.4310/21-SII690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network structure has been widely studied in recent decades. One particular usage of the network is to represent the relationship among nodes. Therefore, link prediction plays a crucial role in network analysis. A key issue of link prediction is to estimate the likelihood of potential links between nodes in the network. However, the complex network structure makes such estimation very challenging. In this paper, we propose a link prediction method based on nodes’ local neighborhood (LN), which constructs a local neighborhood for each node and calculates the likelihood of connection between nodes based on their neighbors. Further, we extend the LN method to solve the link prediction problems in a network with node covariates and community structure. Experimental studies on synthetic and real networks demonstrate that the performance of our methods is competitive.},
  archive      = {J_SII},
  author       = {Wang, Chunning and Jing, Bingyi},
  doi          = {10.4310/21-SII690},
  journal      = {Statistics and Its Interface},
  number       = {3},
  pages        = {323-334},
  shortjournal = {Stat. Interface},
  title        = {Local neighborhood-based approach of link prediction in networks},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimation of conditional average treatment effect by
covariates balance methods. <em>SII</em>, <em>15</em>(3), 312–322. (<a
href="https://doi.org/10.4310/21-SII689">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conditional average treatment effects estimation is one of the crucial mainstays in observational studies. The conditional average treatment effect is defined as a functional parameter which is used to describe the variation of average treatment effect condition on some covariates. Based on the unconfoundedness assumption, we propose the covariates balance method to estimate the propensity score, and the estimated propensity score is applied to the non-parametric method to estimate the conditional average treatment effect. The proposed method is robust and superior to the parametric approach. The proposed method has a smaller RMSE than the true method when the propensity score model is correct specified. Meanwhile, compared with the kernel method, the proposed method is much more computationally efficient. The proposed estimator is consistent and asymptotic under some regularity conditions. Finally, we apply the proposed method to estimate the effect of maternal smoking on low birth weight infants given the age of mothers.},
  archive      = {J_SII},
  author       = {Wang, Jun and Liu, Changbiao},
  doi          = {10.4310/21-SII689},
  journal      = {Statistics and Its Interface},
  number       = {3},
  pages        = {312-322},
  shortjournal = {Stat. Interface},
  title        = {Estimation of conditional average treatment effect by covariates balance methods},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Variable selection for time-varying effects based on
interval-censored failure time data. <em>SII</em>, <em>15</em>(3),
303–311. (<a href="https://doi.org/10.4310/21-SII687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variable selection has recently attracted a great deal of attention and correspondingly, many methods have been proposed. In this paper, we discuss the topic when one faces interval-censored failure time data arising from a model with time-varying coefficients, for which there does not seem to exist a method. For the situation, in addition to identifying important variables or covariates, a desired feature of a variable selection method is to distinguish time-varying coefficients from time-independent ones, which also presents an additional challenge. To address these, a penalized maximum likelihood procedure is presented and in the proposed method, the adaptive group Lasso penalty function and B‑spline functions are used. The approach can simultaneously select between time-dependent and time-independent covariate effects. To implement the proposed procedure, an EM algorithm is developed, and a simulation study is conducted and suggests that the proposed method works well in practical situations. Finally it is applied a set of real data on Alzheimer’s disease that motivated this study.},
  archive      = {J_SII},
  author       = {Chen, Kaiyi and Sun, Jianguo},
  doi          = {10.4310/21-SII687},
  journal      = {Statistics and Its Interface},
  number       = {3},
  pages        = {303-311},
  shortjournal = {Stat. Interface},
  title        = {Variable selection for time-varying effects based on interval-censored failure time data},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Empirical likelihood-based estimation and inference in
randomized controlled trials with high-dimensional covariates.
<em>SII</em>, <em>15</em>(3), 283–301. (<a
href="https://doi.org/10.4310/21-SII686">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a data-adaptive empirical likelihood-based approach for treatment effect estimation and inference, which overcomes the obstacle of the traditional empirical likelihood-based approaches in the high-dimensional setting by adopting penalized regression and machine learning methods to model the covariate-outcome relationship. In particular, we show that our procedure successfully recovers the true variance of Zhang’s treatment effect estimator [ 30 ] by utilizing a data-splitting technique. Our proposed estimator is proved to be asymptotically normal and semiparametric efficient under mild regularity conditions. Simulation studies indicate that our estimator is more efficient than the estimator proposed by Wager et al . [ 26 ] when random forest is employed to model the covariate-outcome relationship. Moreover, when multiple machine learning models are imposed, our estimator is at least as efficient as any regular estimator with a single machine learning model. We compare our method to existing ones using the ACTG175 data and the GSE118657 data, and confirm the outstanding performance of our approach.},
  archive      = {J_SII},
  author       = {Liang, Wei and Yan, Ying},
  doi          = {10.4310/21-SII686},
  journal      = {Statistics and Its Interface},
  number       = {3},
  pages        = {283-301},
  shortjournal = {Stat. Interface},
  title        = {Empirical likelihood-based estimation and inference in randomized controlled trials with high-dimensional covariates},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Link prediction via latent space logistic regression model.
<em>SII</em>, <em>15</em>(3), 267–282. (<a
href="https://doi.org/10.4310/21-SII684">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, link prediction is of vital importance in the operation of social network platforms. One typical application is to make accurate recommendation to enhance users’ activeness. In this article, we propose a latent space logistic regression model for link prediction. The model takes both the users’ attributes and the latent social space into consideration. Two pseudo maximum likelihood estimators are proposed for parameter estimation. They correspond to the concepts of reciprocity and transitivity, respectively, and are computationally efficient for large-scale social networks. Extensive simulation studies are provided to evaluate the finite sample performance of the newly proposed methodology. At last, a real data set of Sina Weibo is presented for illustration purposes.},
  archive      = {J_SII},
  author       = {Pan, Rui and Chang, Xiangyu and Zhu, Xuening and Wang, Hansheng},
  doi          = {10.4310/21-SII684},
  journal      = {Statistics and Its Interface},
  number       = {3},
  pages        = {267-282},
  shortjournal = {Stat. Interface},
  title        = {Link prediction via latent space logistic regression model},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Rejoinder of “estimation of hilbertian varying coefficient
models.” <em>SII</em>, <em>15</em>(2), 261–265. (<a
href="https://doi.org/10.4310/21-SII685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We thank all discussants for their insightful comments on our paper. They highlight some important points of the paper that need more detailed discussion and clarification, and also make valuable suggestions for future study. We categorize the issues raised by the discussants into three groups: extensions to other models and data types; statistical inference; real data example. Below, we briefly address them.},
  archive      = {J_SII},
  author       = {Lee, Young Kyung and Park, Byeong U. and Hong, Hyerim and Kim, Dongwoo},
  doi          = {10.4310/21-SII685},
  journal      = {Statistics and Its Interface},
  number       = {2},
  pages        = {261-265},
  shortjournal = {Stat. Interface},
  title        = {Rejoinder of “Estimation of hilbertian varying coefficient models”},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new <span class="math inline"><em>k</em></span>-nearest
neighbors classifier for functional data. <em>SII</em>, <em>15</em>(2),
247–260. (<a href="https://doi.org/10.4310/20-SII650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For supervised classification of functional data, several classifiers have been proposed in the literature, including the well-known classic $k$-nearest neighbors (kNN) classifier. The classic kNN classifier selects $k$ nearest neighbors around a new observation and determines its class-membership according to a majority vote. A difficulty arises when there are two classes having the same largest number of votes. To overcome this difficulty, we propose a new kNN classifier which selects $k$ nearest neighbors around a new observation from each class. The class-membership of the new observation is determined by the minimum average distance or semi-distance between the $k$ nearest neighbors and the new observation. Good performance of the new kNN classifier is demonstrated by three simulation studies and two real data examples.},
  archive      = {J_SII},
  author       = {Zhang, Jin-Ting and Zhu, Tianming},
  doi          = {10.4310/20-SII650},
  journal      = {Statistics and Its Interface},
  number       = {2},
  pages        = {247-260},
  shortjournal = {Stat. Interface},
  title        = {A new $k$-nearest neighbors classifier for functional data},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Average treatment effect estimation in observational studies
with functional covariates. <em>SII</em>, <em>15</em>(2), 237–246. (<a
href="https://doi.org/10.4310/20-SII632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Functional data analysis is an important area in modern statistics and has been successfully applied in many fields. Although many scientific studies aim to find causations, a predominant majority of functional data analysis approaches can only reveal correlations. In this paper, average treatment effect estimation is studied for observational data with functional covariates. This paper generalizes various state-of-art propensity score estimation methods for multivariate data to functional data. The resulting average treatment effect estimators via propensity score weighting are numerically evaluated by a simulation study and applied to a real-world dataset to study the causal effect of duloxitine on the pain relief of chronic knee osteoarthritis patients.},
  archive      = {J_SII},
  author       = {Miao, Rui and Xue, Wu and Zhang, Xiaoke},
  doi          = {10.4310/20-SII632},
  journal      = {Statistics and Its Interface},
  number       = {2},
  pages        = {237-246},
  shortjournal = {Stat. Interface},
  title        = {Average treatment effect estimation in observational studies with functional covariates},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Principal wave analysis for high-dimensional structured data
with applications to epigenomics and neuroimaging studies. <em>SII</em>,
<em>15</em>(2), 225–236. (<a
href="https://doi.org/10.4310/20-SII658">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional structured data are emerging and accumulating in biomedical research fields. Examples include epigenomics and neuroimaging studies. In these studies, it is often required to extract biologically meaningful patterns and identify relevant biological features from highdimensional structured data. Motivated by this problem, we propose a new statistical learning method named Principal Wave Analysis (PWA). The practical merits of PWA are shown through simulation studies incorporating diverse types of signal patterns as well as its applications to epigenomic and neuroimaging data.},
  archive      = {J_SII},
  author       = {Zhang, Yuping},
  doi          = {10.4310/20-SII658},
  journal      = {Statistics and Its Interface},
  number       = {2},
  pages        = {225-236},
  shortjournal = {Stat. Interface},
  title        = {Principal wave analysis for high-dimensional structured data with applications to epigenomics and neuroimaging studies},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Covariate-adjusted hybrid principal components analysis for
region-referenced functional EEG data. <em>SII</em>, <em>15</em>(2),
209–223. (<a href="https://doi.org/10.4310/21-SII712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalography (EEG) studies produce regionreferenced functional data via EEG signals recorded across scalp electrodes. The high-dimensional data can be used to contrast neurodevelopmental trajectories between diagnostic groups, for example between typically developing (TD) children and children with autism spectrum disorder (ASD). Valid inference requires characterization of the complex EEG dependency structure as well as covariate-dependent heteroscedasticity, such as changes in variation over developmental age. In our motivating study, EEG data is collected on TD and ASD children aged two to twelve years old. The peak alpha frequency, a prominent peak in the alpha spectrum, is a biomarker linked to neurodevelopment that shifts as children age. To retain information, we model patterns of alpha spectral variation, rather than just the peak location, regionally across the scalp and chronologically across development. We propose a covariate-adjusted hybrid principal components analysis (CA-HPCA) for EEG data, which utilizes both vector and functional principal components analysis while simultaneously adjusting for covariate-dependent heteroscedasticity. CA-HPCA assumes the covariance process is weakly separable conditional on observed covariates, allowing for covariate-adjustments to be made on the marginal covariances rather than the full covariance leading to stable and computationally efficient estimation. The proposed methodology provides novel insights into neurodevelopmental differences between TD and ASD children.},
  archive      = {J_SII},
  author       = {Dickinson, Abigail and DiStefano, Charlotte and Jeste, Shafali and Scheffler, Aaron and Şenturk, Damla},
  doi          = {10.4310/21-SII712},
  journal      = {Statistics and Its Interface},
  number       = {2},
  pages        = {209-223},
  shortjournal = {Stat. Interface},
  title        = {Covariate-adjusted hybrid principal components analysis for region-referenced functional EEG data},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A sequential monte carlo gibbs coupled with stochastically
approximated expectation-maximization algorithm for functional data.
<em>SII</em>, <em>15</em>(2), 197–208. (<a
href="https://doi.org/10.4310/20-SII657">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop an algorithm to overcome the curse of dimensionality in sequential Monte Carlo (SMC) for functional data. In the inner iterations of the algorithm for given parameter values, the conditional SMC is extended to obtain draws of the underlying state vectors. These draws in turn are used in the outer iterations to update the parameter values in the framework of stochastically approximated expectation-maximization to obtain maximum likelihood estimates of the parameters. Standard errors of the parameters are calculated using a stochastic approximation of Louis formula. Three numeric examples are used for illustration. They show that although the computational burden remains high, the algorithm produces reasonable results without exponentially increasing the particle numbers.},
  archive      = {J_SII},
  author       = {Liu, Ziyue},
  doi          = {10.4310/20-SII657},
  journal      = {Statistics and Its Interface},
  number       = {2},
  pages        = {197-208},
  shortjournal = {Stat. Interface},
  title        = {A sequential monte carlo gibbs coupled with stochastically approximated expectation-maximization algorithm for functional data},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stochastic functional linear models for gene-based
association analysis of quantitative traits in longitudinal studies.
<em>SII</em>, <em>15</em>(2), 181–196. (<a
href="https://doi.org/10.4310/SII.2022.v15.n2.a9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Longitudinally measured phenotypes are important for exploring genetic and environmental factors that affect complex traits over time. Genetic analysis of multiple measures in longitudinal studies provides a valuable opportunity to understand genetic architecture and biological variations of complex diseases. In this paper, stochastic functional linear models are developed for temporal association analysis at gene levels to analyze sequence data and longitudinally measured quantitative traits. Functional data analysis techniques are utilized to reduce high dimensionality of sequence data and draw useful information. A variance-covariance structure is constructed to model the measurement variation and correlations of the traits based on the theory of stochastic processes. Spline models are used to estimate the time-dependent trajectory mean function. By intensive simulation studies, it is shown that the proposed stochastic models control type I errors well, and have higher power levels than those of the perturbation tests. In addition, the proposed methods are robust when the correlation function is mis-specified. We test and refine the models and related software using real data sets of Framingham Heart Study.},
  archive      = {J_SII},
  author       = {Zhang, Bingsong and Wang, Shuqi and Mei, Xiaohan and Han, Yue and Wang, Runqiu and Fang, Hong-Bin and Chiu, Chi-Yang and Ding, Jun and Wang, Zuoheng and Wilson, Alexander F.},
  doi          = {10.4310/SII.2022.v15.n2.a9},
  journal      = {Statistics and Its Interface},
  number       = {2},
  pages        = {181-196},
  shortjournal = {Stat. Interface},
  title        = {Stochastic functional linear models for gene-based association analysis of quantitative traits in longitudinal studies},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sparse logistic regression on functional data. <em>SII</em>,
<em>15</em>(2), 171–179. (<a
href="https://doi.org/10.4310/21-SII688">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by a hemodialysis monitoring study, we propose a logistic model with a functional predictor, called the Sparse Functional Logistic Regression (SFLR), where the corresponding coefficient function is locally sparse , that is, it is completely zero on some subregions of its domain. The coefficient function, together with the intercept parameter, are estimated through a doubly-penalized likelihood approach with a B-splines expansion. One penalty is for controlling the roughness of the coefficient function estimate and the other penalty, in the form of the $L_1$ norm, enforces the local sparsity. A Newton–Raphson procedure is designed for the optimization of the penalized likelihood. Our simulations show that SFLR is capable of generating a smooth and reasonably good estimate of the coefficient function on the non-null region(s) while recognizing the null region(s). Application of the method to the Raman spectral data generated from the hemodialysis study pinpoint the wavenumber regions for identifying key chemicals contributing to the dialysis progress.},
  archive      = {J_SII},
  author       = {Du, Pang and Xu, Yunnan and Robertson, John and Senger, Ryan},
  doi          = {10.4310/21-SII688},
  journal      = {Statistics and Its Interface},
  number       = {2},
  pages        = {171-179},
  shortjournal = {Stat. Interface},
  title        = {Sparse logistic regression on functional data},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distribution free prediction intervals for multiple
functional regression. <em>SII</em>, <em>15</em>(2), 161–170. (<a
href="https://doi.org/10.4310/20-SII646">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper applies conformal prediction techniques to the problem of constructing prediction intervals in a multiple functional regression setting. After a short introduction to the Signature expansion and its favorable properties, a method utilizing this feature set is developed with great modeling flexibility. With minimal assumptions, the resulting algorithm produces a closed form solution for a prediction set with guaranteed coverage. The good performance of the proposed method is illustrated using simulations and data examples.},
  archive      = {J_SII},
  author       = {Chen, Kehui and Kelly, Ryan},
  doi          = {10.4310/20-SII646},
  journal      = {Statistics and Its Interface},
  number       = {2},
  pages        = {161-170},
  shortjournal = {Stat. Interface},
  title        = {Distribution free prediction intervals for multiple functional regression},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Discussion of “estimation of hilbertian varying coefficient
models.” <em>SII</em>, <em>15</em>(2), 159–160. (<a
href="https://doi.org/10.4310/21-SII680">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SII},
  author       = {Huang, Jianhua and Wang, Jiangli and Zhou, Huiya},
  doi          = {10.4310/21-SII680},
  journal      = {Statistics and Its Interface},
  number       = {2},
  pages        = {159-160},
  shortjournal = {Stat. Interface},
  title        = {Discussion of “Estimation of hilbertian varying coefficient models”},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Discussion of “estimation of hilbertian varying coefficient
models.” <em>SII</em>, <em>15</em>(2), 157–158. (<a
href="https://doi.org/10.4310/21-SII679">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The suggested model covers a broad range of settings in functional data analysis and the proposed smooth backfitting method is advantageous. Here I discuss its relationship with several alternative approaches.},
  archive      = {J_SII},
  author       = {Cheng, Ming-Yen},
  doi          = {10.4310/21-SII679},
  journal      = {Statistics and Its Interface},
  number       = {2},
  pages        = {157-158},
  shortjournal = {Stat. Interface},
  title        = {Discussion of “Estimation of hilbertian varying coefficient models”},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Discussion of “estimation of hilbertian varying coefficient
models.” <em>SII</em>, <em>15</em>(2), 155. (<a
href="https://doi.org/10.4310/21-SII678">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SII},
  author       = {Dai, Xiongtao},
  doi          = {10.4310/21-SII678},
  journal      = {Statistics and Its Interface},
  number       = {2},
  pages        = {155},
  shortjournal = {Stat. Interface},
  title        = {Discussion of “Estimation of hilbertian varying coefficient models”},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Discussion of “estimation of hilbertian varying coefficient
models.” <em>SII</em>, <em>15</em>(2), 153–154. (<a
href="https://doi.org/10.4310/21-SII677">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SII},
  author       = {Guo, Jia and Zhang, Jin-Ting and Zhou, Bu},
  doi          = {10.4310/21-SII677},
  journal      = {Statistics and Its Interface},
  number       = {2},
  pages        = {153-154},
  shortjournal = {Stat. Interface},
  title        = {Discussion of “Estimation of hilbertian varying coefficient models”},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Discussion of “estimation of hilbertian varying coefficient
models.” <em>SII</em>, <em>15</em>(2), 151. (<a
href="https://doi.org/10.4310/21-SII671">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SII},
  author       = {Du, Pang},
  doi          = {10.4310/21-SII671},
  journal      = {Statistics and Its Interface},
  number       = {2},
  pages        = {151},
  shortjournal = {Stat. Interface},
  title        = {Discussion of “Estimation of hilbertian varying coefficient models”},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimation of hilbertian varying coefficient models.
<em>SII</em>, <em>15</em>(2), 129–149. (<a
href="https://doi.org/10.4310/20-SII651">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we discuss the estimation of a fairly general type of varying coefficient model. The model is for a response variable that takes values in a general Hilbert space and allows for various types of additive interaction terms in representing the effects of predictors. It also accommodates both continuous and discrete predictors. We develop a powerful technique of estimating the very general model. Our approach may be used in a variety of situations where one needs to analyze the relation between a set of predictors and a Hilbertian response. We prove the existence of the estimators of the model itself and of its components, and also the convergence of a backfitting algorithm that realizes the estimators. We derive the rates of convergence of the estimators and their asymptotic distributions. We also demonstrate via simulation study that our approach works efficiently, and illustrate its usefulness through a real data application.},
  archive      = {J_SII},
  author       = {Hong, Hyerim and Kim, Dongwoo and Lee, Young Kyung and Park, Byeong U.},
  doi          = {10.4310/20-SII651},
  journal      = {Statistics and Its Interface},
  number       = {2},
  pages        = {129-149},
  shortjournal = {Stat. Interface},
  title        = {Estimation of hilbertian varying coefficient models},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Further study on testing the equality of response rates
under dallal’s model. <em>SII</em>, <em>15</em>(1), 115–126. (<a
href="https://doi.org/10.4310/21-SII683">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Paired binary data naturally arises when paired body parts are investigated in clinical trials. In this paper, we will further study whether the response rates of $g (g \geq 2)$ groups are equal under Dallal’s model and propose eight test statistics ($T^a_L$, $T^a_W$, $T^a_{SC}$, $T^a_R$, $T^b_L$, $T^b_W$, $T^b_{SC}$ and $T^b_R$). Some expressions of these tests are derived. The simulation results show that likelihood ratio and Wald-type tests are not robust with respect to empirical type I error rates (TIEs). The score and Ronser-type tests can produce satisfactory TIEs and power, and therefore are recommended. A real example is given to illustrate the proposed methods.},
  archive      = {J_SII},
  author       = {Chen, Yafei and Li, Zhiming and Ma, Changxing},
  doi          = {10.4310/21-SII683},
  journal      = {Statistics and Its Interface},
  number       = {1},
  pages        = {115-126},
  shortjournal = {Stat. Interface},
  title        = {Further study on testing the equality of response rates under dallal’s model},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian estimation for partially linear varying coefficient
spatial autoregressive models. <em>SII</em>, <em>15</em>(1), 105–113.
(<a href="https://doi.org/10.4310/21-SII682">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a fully Bayesian estimation approach for partially linear varying coefficient spatial autoregressive models on the basis of B-spline approximations of nonparametric components. A computational efficient MCMC method that combines the Gibbs sampler with Metropolis–Hastings algorithm is implemented to simultaneously obtain the Bayesian estimates of unknown parameters, as well as their standard error estimates. Monte Carlo simulations are used to investigate the finite sample performance of the proposed method. Finally, a real data analysis of Boston housing data is used to illustrate the usefulness of the proposed methodology.},
  archive      = {J_SII},
  author       = {Tian, Ruiqin and Xu, Dengke and Du, Jiang and Zhang, Junfei},
  doi          = {10.4310/21-SII682},
  journal      = {Statistics and Its Interface},
  number       = {1},
  pages        = {105-113},
  shortjournal = {Stat. Interface},
  title        = {Bayesian estimation for partially linear varying coefficient spatial autoregressive models},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A generalized semi-parametric model for jointly analyzing
response times and accuracy in computerized testing. <em>SII</em>,
<em>15</em>(1), 91–104. (<a
href="https://doi.org/10.4310/21-SII681">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Cox proportional hazards model has been widely used for modeling response-time data in educational and psychological research. However, based on the Kaplan-Meier (KM) plots in an empirical example, we find that the proportionality of the hazard ratios does not seem to be an appropriate assumption, and there are considerable differences in survival rates among different items. To overcome such a problem, we consider a class of flexible nonproportional hazards models known as the generalized odds-rate hazards class of regression models. This class is general enough to include several commonly used models, including the proportional hazards model and the proportional odds model, as special cases. A fully Bayesian method is developed for parameter estimation and the deviance information criterion (DIC) and the logarithm of the pseudomarginal likelihood (LPML) are employed for model comparison. Simulation studies are conducted and a detailed analysis of the Programme for International Student Assessment (PISA) science data is carried out to further illustrate the proposed methodology.},
  archive      = {J_SII},
  author       = {Liu, Fang and Zhang, Jiwei and Shi, Ningzhong and Chen, Ming-Hui},
  doi          = {10.4310/21-SII681},
  journal      = {Statistics and Its Interface},
  number       = {1},
  pages        = {91-104},
  shortjournal = {Stat. Interface},
  title        = {A generalized semi-parametric model for jointly analyzing response times and accuracy in computerized testing},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Rate-efficient asymptotic normality for the fourier
estimator of the leverage process. <em>SII</em>, <em>15</em>(1), 73–89.
(<a href="https://doi.org/10.4310/21-SII676">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove a Central Limit Theorem for two estimators of the leverage process based on the Fourier method of Malliavin and Mancino [26], showing that they reach the optimal rate $1/4$ and a smaller variance compared to different estimators based on a pre-estimation of the instantaneous volatility. The obtained limiting distributions of the estimators are supported by simulation results. Further, we exploit the availability of efficient leverage estimates to show, using S&amp;P500 prices, that adding an extra term which accounts for the leverage effect to the Heterogeneous Auto-Regressive volatility model by Corsi [13] increases the explanatory power of the latter.},
  archive      = {J_SII},
  author       = {Mancino, Maria Elvira and Toscano, Giacomo},
  doi          = {10.4310/21-SII676},
  journal      = {Statistics and Its Interface},
  number       = {1},
  pages        = {73-89},
  shortjournal = {Stat. Interface},
  title        = {Rate-efficient asymptotic normality for the fourier estimator of the leverage process},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stochastic diffusion process based on goel–okumoto curve:
Statistical inference and application to real data. <em>SII</em>,
<em>15</em>(1), 63–71. (<a
href="https://doi.org/10.4310/21-SII675">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we study a new stochastic diffusion process based on the Goel-Okumoto curve. Such a process can be considered as an extension of the nonhomogeneous lognormal diffusion process. From the corresponding Itô’s stochastic differential equation (SDE), firstly we establish the probabilistic characteristics of the studied process, such as the solution to the SDE, the probability transition density function and their distribution, the moments function, in particular the conditional and non-conditional trend functions. Secondly, we treat the parameters estimation problem by using the maximum likelihood method in basis of the discrete sampling, thus we obtain nonlinear equations that can be solved by numerical methods. Finally, the proposed model is applied to the data of the broad money (% GDP) of Morocco.},
  archive      = {J_SII},
  author       = {Nafidi, Ahmed and Rida, Oussama and Bahij, Meriem and Achchab, Boujemaa},
  doi          = {10.4310/21-SII675},
  journal      = {Statistics and Its Interface},
  number       = {1},
  pages        = {63-71},
  shortjournal = {Stat. Interface},
  title        = {Stochastic diffusion process based on Goel–Okumoto curve: Statistical inference and application to real data},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Subset selection of double-threshold moving average models
through the application of the bayesian method. <em>SII</em>,
<em>15</em>(1), 51–61. (<a
href="https://doi.org/10.4310/21-SII674">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Bayesian method is firstly applied for the selection of the best subset for the double-threshold moving average (DTMA) model. The Markov chain Monte Carlo (MCMC) techniques and the stochastic search variable selection (SSVS) method are used to identify the best subset model from a very large number of possible models. Simulation experiments show that the proposed method is feasible and efficient, despite the complexity being increased by the large number of subsets, and the uncertainty of the threshold and delay variables. Our method is illustrated by real data analysis on the Yen-Dollar exchange rate.},
  archive      = {J_SII},
  author       = {Liu, Jinshan and Pan, Jiazhu and Xia, Qiang and Xiao, Ying},
  doi          = {10.4310/21-SII674},
  journal      = {Statistics and Its Interface},
  number       = {1},
  pages        = {51-61},
  shortjournal = {Stat. Interface},
  title        = {Subset selection of double-threshold moving average models through the application of the bayesian method},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pathway lasso: Pathway estimation and selection with
high-dimensional mediators. <em>SII</em>, <em>15</em>(1), 39–50. (<a
href="https://doi.org/10.4310/21-SII673">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many scientific studies, it becomes increasingly important to delineate the pathways through a large number of mediators, such as genetic and brain mediators. Structural equation modeling (SEM) is a popular technique to estimate the pathway effects, commonly expressed as the product of coefficients. However, it becomes unstable and computationally challenging to fit such models with high-dimensional mediators. This paper proposes a sparse mediation model using a regularized SEM approach, where sparsity means that a small number of mediators have a nonzero mediation effect between a treatment and an outcome. To address the model selection challenge, we innovate by introducing a new penalty called Pathway Lasso . This penalty function is a convex relaxation of the non-convex product function for the mediation effects, and it enables a computationally tractable optimization criterion to estimate and select pathway effects simultaneously. We develop a fast ADMM-type algorithm to compute the model parameters, and we show that the iterative updates can be expressed in closed form. We also prove the asymptotic consistency of our Pathway Lasso estimator for the mediation effect. On both simulated data and an fMRI data set, the proposed approach yields higher pathway selection accuracy and lower estimation bias than competing methods.},
  archive      = {J_SII},
  author       = {Zhao, Yi and Luo, Xi},
  doi          = {10.4310/21-SII673},
  journal      = {Statistics and Its Interface},
  number       = {1},
  pages        = {39-50},
  shortjournal = {Stat. Interface},
  title        = {Pathway lasso: Pathway estimation and selection with high-dimensional mediators},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spatial weibull regression with multivariate log gamma
process and its applications to china earthquake economic loss.
<em>SII</em>, <em>15</em>(1), 29–38. (<a
href="https://doi.org/10.4310/21-SII672">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian spatial modeling of heavy-tailed distributions has become increasingly popular in various areas of science in recent decades. We propose a Weibull regression model with spatial random effects for analyzing extreme economic loss. Model estimation is facilitated by a computationally efficient Bayesian sampling algorithm utilizing the multivariate Log-Gamma distribution. Simulation studies are carried out to demonstrate better empirical performances of the proposed model than the generalized linear mixed effects model. An earthquake data obtained from Yunnan Seismological Bureau, China is analyzed. Logarithm of the Pseudo-marginal likelihood values are obtained to select the optimal model, and Value-at-risk, expected shortfall, and tail-value-at-risk based on posterior predictive distribution of the optimal model are calculated under different confidence levels.},
  archive      = {J_SII},
  author       = {Yang, Hou-Cheng and Xue, Yishu and Geng, Lijiang and Hu, Guanyu},
  doi          = {10.4310/21-SII672},
  journal      = {Statistics and Its Interface},
  number       = {1},
  pages        = {29-38},
  shortjournal = {Stat. Interface},
  title        = {Spatial weibull regression with multivariate log gamma process and its applications to china earthquake economic loss},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian estimation for a mortality model via the aging
process. <em>SII</em>, <em>15</em>(1), 19–28. (<a
href="https://doi.org/10.4310/21-SII670">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose a method for estimating the parameters of the aging process in order to construct mortality tables when the data is a discrete time sample of the chronological age, while no direct observations of the aging process are available. Here, the aging process is modelled through a Markov jump process with finite state space and a single absorbing state. The non-absorbing states represent the physiological ages and the absorbing state the death, so the time until death follows a phase-type distribution. A Bayesian approach has been considered, specifically a Gibbs sampler method, as part of the algorithm, we use an alternative of the uniformization method applied to Markov bridges. A simulation-based analysis has been carried out to validate the approach. Moreover, the proposed estimation algorithm has been applied to analyze two types of records of mortality real data and to construct the corresponding mortality tables, which are compared with the observed mortality.},
  archive      = {J_SII},
  author       = {Esparza, Luz Judith R. and Baltazar-Larios, Fernando},
  doi          = {10.4310/21-SII670},
  journal      = {Statistics and Its Interface},
  number       = {1},
  pages        = {19-28},
  shortjournal = {Stat. Interface},
  title        = {Bayesian estimation for a mortality model via the aging process},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sparsity-restricted estimation for the accelerated failure
time model. <em>SII</em>, <em>15</em>(1), 1–18. (<a
href="https://doi.org/10.4310/21-SII669">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many biomedical studies, such as high-throughput microarray or RNA-sequencing (RNA-seq) gene expression analyses, it is of practical interest to link gene expression profiles to censored survival phenotypes, for example, time to cancer recurrence or time to death. With the number of genes greatly exceeding the sample size and the nuances of survival data such as right censoring, regularized methods that combine the rank-based loss function and the penalty are often used to identify relevant prognostic biomarkers and yield parsimonious prediction models for event times. Existing penalization methods for survival data often use $\ell_1$ penalty to approximate the sparsity, yielding numerical convenience for its convexity. In practice, however, the $\ell_1$ approximation also leads to an inflated model size to achieve a desired cross-validated prediction error when compared to the ideal sparsity-restricted method. In this paper, we consider sparsity-restricted estimation in the accelerated failure time (AFT) model for censored survival data. An efficient and fast two-stage procedure that uses a convex regularized Gehan rank regression and a simple hard-thresholding estimation is proposed for its numerical implementation. The effectiveness of the proposed method is demonstrated by extensive simulation studies and real-data applications.},
  archive      = {J_SII},
  author       = {Zhang, Xiaoyu and Zhou, Yunpeng and Xu, Jinfeng and Yuen, Kam Chuen},
  doi          = {10.4310/21-SII669},
  journal      = {Statistics and Its Interface},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Stat. Interface},
  title        = {Sparsity-restricted estimation for the accelerated failure time model},
  volume       = {15},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
