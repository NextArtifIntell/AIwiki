<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJAR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijar---159">IJAR - 159</h2>
<ul>
<li><details>
<summary>
(2022). Lattices defined by multigranular rough sets. <em>IJAR</em>,
<em>151</em>, 413–429. (<a
href="https://doi.org/10.1016/j.ijar.2022.10.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One way to view the multigranular rough set model is that the assessment of more experts are considered when determining the approximations of a set, instead of a single equivalence relation expressing the indiscernibility of the objects. There are two approaches for modeling this: the optimistic and the pessimistic multigranular rough set models. In this paper, we analyze both approaches from a lattice-theoretic point of view. We generalize existing results for two equivalence relations (two experts) to n equivalence relations, completing them with additional findings. We also characterize the order structures of optimistic and pessimistic rough sets and determine when they form complete, or even completely distributive lattices. Additionally, we examine the properties of the Dedekind-MacNeille completion of the poset of optimistic multigranular rough sets. Some applications for information tables and for recommendation theory are also presented.},
  archive      = {J_IJAR},
  author       = {Dávid Gégény and László Kovács and Sándor Radeleczki},
  doi          = {10.1016/j.ijar.2022.10.007},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {413-429},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Lattices defined by multigranular rough sets},
  volume       = {151},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Quantum indistinguishability through exchangeability.
<em>IJAR</em>, <em>151</em>, 389–412. (<a
href="https://doi.org/10.1016/j.ijar.2022.10.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two particles are identical if all their intrinsic properties, such as spin and charge, are the same, meaning that no quantum experiment can distinguish them. In addition to the well known principles of quantum mechanics, understanding systems of identical particles requires a new postulate, the so called symmetrisation postulate . In this work, we show that the postulate corresponds to exchangeability assessments for sets of observables (gambles) in a quantum experiment, when quantum mechanics is seen as a normative and algorithmic theory guiding an agent to assess her subjective beliefs represented as (coherent) sets of gambles. Finally, we show how sets of exchangeable observables (gambles) may be updated after a measurement and discuss the issue of defining entanglement for indistinguishable particle systems.},
  archive      = {J_IJAR},
  author       = {Alessio Benavoli and Alessandro Facchini and Marco Zaffalon},
  doi          = {10.1016/j.ijar.2022.10.003},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {389-412},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Quantum indistinguishability through exchangeability},
  volume       = {151},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Natural construction method of ordinal sum implication and
its distributivity. <em>IJAR</em>, <em>151</em>, 360–388. (<a
href="https://doi.org/10.1016/j.ijar.2022.09.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, De Lima et al. introduced the left ordinal sum of fuzzy implications so that its natural negation has an ordinal sum representation, which enriches the natural negations of fuzzy implications. In this paper, we propose a natural method to construct the ordinal sum of fuzzy implications without changing its natural negation, and explore the relationship between this class of ordinal sum of fuzzy implications and some classes of ordinal sums of fuzzy implications in the literature. Moreover, we characterize the distributivity equations of such ordinal sum of fuzzy implications over t-norms and t-conorms under some conditions.},
  archive      = {J_IJAR},
  author       = {Bin Zhao and Yafei Cheng},
  doi          = {10.1016/j.ijar.2022.09.015},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {360-388},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Natural construction method of ordinal sum implication and its distributivity},
  volume       = {151},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Notes on “on (o,g)-fuzzy rough sets based on overlap and
grouping functions over complete lattices.” <em>IJAR</em>, <em>151</em>,
344–359. (<a href="https://doi.org/10.1016/j.ijar.2022.09.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Jiang and Hu characterized ( O , G ) (O,G) -fuzzy rough sets based on overlap and grouping functions over complete lattices with L -fuzzy negations, where L denotes a complete lattice. However, there are some faults in the study of ( O , G ) (O,G) -fuzzy rough sets. As there exist complete lattices without strict L -fuzzy negations or L -fuzzy involutive negations, the properties of G -lower L -fuzzy rough approximation operators need be further discussed. Meanwhile, it is wrong that the G -lower L -fuzzy rough approximation operators preserve the arbitrary union of L -fuzzy sets and O -upper L -fuzzy rough approximation operators preserve the arbitrary intersection of L -fuzzy sets. Hence, the characterizations of ( O , G ) (O,G) -fuzzy rough sets and multigranulation ( O , G ) (O,G) -fuzzy rough sets need be rectifies. For the convenience of readers, a table is provided to show the correspondences among the conclusions.},
  archive      = {J_IJAR},
  author       = {Chun Yong Wang and Rong Tao Wu and Bo Zhang},
  doi          = {10.1016/j.ijar.2022.09.013},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {344-359},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Notes on “On (O,G)-fuzzy rough sets based on overlap and grouping functions over complete lattices”},
  volume       = {151},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evidential prototype-based clustering based on transfer
learning. <em>IJAR</em>, <em>151</em>, 322–343. (<a
href="https://doi.org/10.1016/j.ijar.2022.10.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In some real clustering tasks , the data may be sparse and uncertain. Although there is usually some useful knowledge in related scenes, the data among different domains is often of great inconsistency. A new unsupervised transfer learning method is proposed in the framework of belief functions to handle the insufficiency and uncertain problems in clustering simultaneously. Firstly, under the assumption that the source and target domains have the same number of clusters, the Transfer Evidential C Means (TECM) is developed by incorporating the idea of transfer learning and evidential clustering. A novel objective function is designed to employ the cluster prototypes of the source data as references to guide the clustering process on the target. Furthermore, ETECM, as an extended version of TECM, is also introduced for the situation that the two domains have different numbers of clusters. Some experiments conducted on synthetic and real-world data sets demonstrate the advantages of TECM and ETECM.},
  archive      = {J_IJAR},
  author       = {Kuang Zhou and Mei Guo and Arnaud Martin},
  doi          = {10.1016/j.ijar.2022.10.001},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {322-343},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Evidential prototype-based clustering based on transfer learning},
  volume       = {151},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Effective and efficient structure learning with pruning and
model averaging strategies. <em>IJAR</em>, <em>151</em>, 292–321. (<a
href="https://doi.org/10.1016/j.ijar.2022.09.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning the structure of a Bayesian Network (BN) with score-based solutions involves exploring the search space of possible graphs and moving towards the graph that maximises a given objective function. Some algorithms offer exact solutions that guarantee to return the graph with the highest objective score, while others offer approximate solutions in exchange for reduced computational complexity . This paper describes an approximate BN structure learning algorithm, which we call Model Averaging Hill-Climbing (MAHC), that combines two novel strategies with hill-climbing search. The algorithm starts by pruning the search space of graphs, where the pruning strategy can be viewed as an aggressive version of the pruning strategies that are typically applied to combinatorial optimisation structure learning problems. It then performs model averaging in the hill-climbing search process and moves to the neighbouring graph that maximises the objective function, on average, for that neighbouring graph and over all its valid neighbouring graphs. Comparisons with other algorithms spanning different classes of learning suggest that the combination of aggressive pruning with model averaging is both effective and efficient, particularly in the presence of data noise.},
  archive      = {J_IJAR},
  author       = {Anthony C. Constantinou and Yang Liu and Neville K. Kitson and Kiattikun Chobtham and Zhigao Guo},
  doi          = {10.1016/j.ijar.2022.09.016},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {292-321},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Effective and efficient structure learning with pruning and model averaging strategies},
  volume       = {151},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the (dis)similarities between stationary imprecise and
non-stationary precise uncertainty models in algorithmic randomness.
<em>IJAR</em>, <em>151</em>, 272–291. (<a
href="https://doi.org/10.1016/j.ijar.2022.10.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of algorithmic randomness studies, amongst other things, what it means for infinite binary sequences to be random for some given uncertainty model. Classically, martingale-theoretic notions of randomness involve precise uncertainty models, and it is only recently that imprecision has been introduced into this context. As a consequence, the investigation into how imprecision alters our view on martingale-theoretic random sequences has only just begun. In this contribution, where we allow for non-computable uncertainty models, we establish a close and surprising connection between precise and imprecise uncertainty models in this randomness context. In particular, we show that there are stationary imprecise models and non-computable non-stationary precise models that have the exact same set of random sequences. We also give a preliminary discussion of the possible implications of our result for a statistics based on imprecise probabilities , and shed some light on the practical (ir)relevance of both imprecise and non-computable precise uncertainty models in that context.},
  archive      = {J_IJAR},
  author       = {Floris Persiau and Jasper De Bock and Gert de Cooman},
  doi          = {10.1016/j.ijar.2022.10.002},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {272-291},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {On the (dis)similarities between stationary imprecise and non-stationary precise uncertainty models in algorithmic randomness},
  volume       = {151},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Corrigendum to “GLRM: Logical pattern mining in the case of
inconsistent data distribution based on multigranulation strategy” [int.
J. Approx. Reason. 143 (2022) 78–101]. <em>IJAR</em>, <em>151</em>, 271.
(<a href="https://doi.org/10.1016/j.ijar.2022.10.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJAR},
  author       = {Qian Guo and Yuhua Qian and Xinyan Liang},
  doi          = {10.1016/j.ijar.2022.10.004},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {271},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Corrigendum to “GLRM: Logical pattern mining in the case of inconsistent data distribution based on multigranulation strategy” [Int. j. approx. reason. 143 (2022) 78–101]},
  volume       = {151},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pointwise mutual information sparsely embedded feature
selection. <em>IJAR</em>, <em>151</em>, 251–270. (<a
href="https://doi.org/10.1016/j.ijar.2022.09.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is an effective approach to dimensionality reduction. Feature selection based on rough sets and fuzzy rough sets is extensively realized by introducing diversified heuristic information . Most existing heuristic feature selection methods ignore the fact that different features have distinct classification abilities when constructing feature evaluation functions. Due to the limitations of search strategies, locally optimal feature subsets are probably selected out. Embedded feature selection based on regression analysis can avoid falling into locally optimal feature subsets to a certain extent. However, only linear relationships between feature space and decision space have been involved. To overcome those problems, a pointwise mutual information sparsely embedded feature selection model (PMISEFS) is proposed in this paper. In this model, the pointwise fuzzy mutual information matrix is constructed based on fuzzy information granules to characterize the discernibility of features as well as the nonlinear relationship between the feature space and decision space for a data set. A classification information matrix is introduced to further describe the consistency between the predicted decision and real decisions of samples. The fuzzy mutual information tensor is embedded sparsely into the decision matrix and the sparsely embedded coefficients, called information fusion coefficients (IFCs) of features, are adaptively learnt by imposing a smooth constraint to avoid over-fitting. An embedded feature selection algorithm is designed to adaptively learn optimal IFCs. Extensive experiments on various benchmark data sets are conducted and experimental results demonstrate the superiority of the proposed model over the state-of-the-art heuristic as well as embedded feature selection methods.},
  archive      = {J_IJAR},
  author       = {Tingquan Deng and Yang Huang and Ge Yang and Changzhong Wang},
  doi          = {10.1016/j.ijar.2022.09.012},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {251-270},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Pointwise mutual information sparsely embedded feature selection},
  volume       = {151},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Explanation with the winter value: Efficient computation for
hierarchical choquet integrals. <em>IJAR</em>, <em>151</em>, 225–250.
(<a href="https://doi.org/10.1016/j.ijar.2022.09.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Criteria Decision Aiding arises in many industrial applications where the user needs an explanation of the recommendation. We consider, in particular, an explanation taking the form of a contribution level assigned to each variable. Decision models are often hierarchical, and the influence is computed by the Winter value, which is an extension of the Shapley value on trees. The contribution of the paper is to propose two exact methods to efficiently compute the Winter values for a very general class of decision models known as the Choquet integral . The first one is an analytical expression for a flat model. The second one is an exact algorithm for a hierarchical model. The main idea of this algorithm is to prune the combinatorial structure on which the Winter value is computed, based on the upper and lower bounds of the utility on subtrees. Extensive simulations show that this new algorithm provides very significant computation gains compared to the state of the art.},
  archive      = {J_IJAR},
  author       = {Christophe Labreuche},
  doi          = {10.1016/j.ijar.2022.09.008},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {225-250},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Explanation with the winter value: Efficient computation for hierarchical choquet integrals},
  volume       = {151},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Direct and approximately valid probabilistic inference on a
class of statistical functionals. <em>IJAR</em>, <em>151</em>, 205–224.
(<a href="https://doi.org/10.1016/j.ijar.2022.09.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing frameworks for probabilistic inference assume the quantity of interest is the parameter of a posited statistical model. In machine learning applications, however, often there is no statistical model/parameter; the quantity of interest is a statistical functional, a feature of the underlying distribution. Model-based methods can only handle such problems indirectly, via marginalization from a model parameter to the real quantity of interest. Here we develop a generalized inferential model (IM) framework for direct probabilistic uncertainty quantification on the quantity of interest. In particular, we construct a data-dependent, bootstrap-based possibility measure for uncertainty quantification and inference. We then prove that this new approach provides approximately valid inference in the sense that the plausibility values assigned to hypotheses about the unknowns are asymptotically well-calibrated in a frequentist sense. Among other things, this implies that confidence regions for the underlying functional derived from our proposed IM are approximately valid. The method is shown to perform well in key examples, including quantile regression, and in a personalized medicine application.},
  archive      = {J_IJAR},
  author       = {Leonardo Cella and Ryan Martin},
  doi          = {10.1016/j.ijar.2022.09.011},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {205-224},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Direct and approximately valid probabilistic inference on a class of statistical functionals},
  volume       = {151},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Games of incomplete information: A framework based on belief
functions. <em>IJAR</em>, <em>151</em>, 182–204. (<a
href="https://doi.org/10.1016/j.ijar.2022.09.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a model for incomplete-information games where the knowledge of the players is represented by a Dempster-Shafer belief function. Beyond an extension of the classical definitions, it shows such a game can be transformed into an equivalent hypergraphical complete-information game (without uncertainty), thus generalizing Howson and Rosenthal&#39;s theorem to the framework of belief functions and to any number of players. The complexity of this transformation is finally studied and shown to be polynomial in the degree of k -additivity of the mass function.},
  archive      = {J_IJAR},
  author       = {Pierre Pomeret-Coquot and Helene Fargier and Érik Martin-Dorel},
  doi          = {10.1016/j.ijar.2022.09.010},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {182-204},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Games of incomplete information: A framework based on belief functions},
  volume       = {151},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Entropy for evaluation of dempster-shafer belief function
models. <em>IJAR</em>, <em>151</em>, 164–181. (<a
href="https://doi.org/10.1016/j.ijar.2022.09.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applications of Dempster-Shafer (D-S) belief functions to practical problems involve difficulties arising from their high computational complexity . One can use space-saving factored approximations such as graphical belief function models to solve them. Using an analogy with probability distributions, we represent these approximations in the form of compositional models. Since no theoretical apparatus similar to probabilistic information theory exists for D-S belief functions (e.g., dissimilarity measure analogous to the Kullback-Liebler divergence measure), the problems arise not only in connection with the design of algorithms seeking optimal approximations but also in connection with a criterion comparing two different approximations. In this respect, the application of the analogy with probability theory fails. Therefore, in this paper, we conduct some synthetic experiments and describe the results designed to reveal whether some belief function entropy definitions described in the literature can detect optimal approximations, i.e., that achieve their minimum for an optimal approximation.},
  archive      = {J_IJAR},
  author       = {Radim Jiroušek and Václav Kratochvíl and Prakash P. Shenoy},
  doi          = {10.1016/j.ijar.2022.09.009},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {164-181},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Entropy for evaluation of dempster-shafer belief function models},
  volume       = {151},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An approach to improve argumentation-based epistemic
planning with contextual preferences. <em>IJAR</em>, <em>151</em>,
130–163. (<a href="https://doi.org/10.1016/j.ijar.2022.09.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current approaches to argumentation-based planning represent an interesting proposal where defeasible argumentation is used as a practical mechanism suitable for reasoning with potentially contradictory information in dynamic environments. In many real-world planning scenarios, the development of formalisms allowing explicit preference specification over pieces of knowledge turns out to be an essential task—however, despite its importance, existing planning systems are not provided with the possibility of dynamically changing these preferences when a plan is being constructed. This paper presents an argumentation-based approach to deal with the handling of preferences when a plan is formulated; in particular, we propose using conditional expressions to select and change priorities regarding information upon which plans are constructed. Our aim is not to improve the efficiency of current planning systems, but to enhance the resulting plan itself by introducing an approach capable of representing and handling multiple preferences over defeasible knowledge. This approach will contribute to the strengthening of existing argumentation-based epistemic planning systems, providing a useful tool that the user could exploit. Finally, we also present a running-time analysis and several complexity results associated with our approach.},
  archive      = {J_IJAR},
  author       = {Juan C.L. Teze and Lluis Godo and Gerardo I. Simari},
  doi          = {10.1016/j.ijar.2022.09.005},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {130-163},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {An approach to improve argumentation-based epistemic planning with contextual preferences},
  volume       = {151},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on causal discovery: Theory and practice.
<em>IJAR</em>, <em>151</em>, 101–129. (<a
href="https://doi.org/10.1016/j.ijar.2022.09.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the laws that govern a phenomenon is the core of scientific progress. This is especially true when the goal is to model the interplay between different aspects in a causal fashion. Indeed, causal inference itself is specifically designed to quantify the underlying relationships that connect a cause to its effect. Causal discovery is a branch of the broader field of causality in which causal graphs are recovered from data (whenever possible), enabling the identification and estimation of causal effects . In this paper, we explore recent advancements in causal discovery in a unified manner, provide a consistent overview of existing algorithms developed under different settings, report useful tools and data, present real-world applications to understand why and how these methods can be fruitfully exploited.},
  archive      = {J_IJAR},
  author       = {Alessio Zanga and Elif Ozkirimli and Fabio Stella},
  doi          = {10.1016/j.ijar.2022.09.004},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {101-129},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A survey on causal discovery: Theory and practice},
  volume       = {151},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parameterized maximum-entropy-based three-way approximate
attribute reduction. <em>IJAR</em>, <em>151</em>, 85–100. (<a
href="https://doi.org/10.1016/j.ijar.2022.09.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way decision theory has emerged as an effective method for attribute reduction when dealing with vague, uncertain, or imprecise data. However, most existing attribute reduction measures in the three-way decision are non-monotonic and too strict, limiting the quality of attribute reduction. In this study, a monotonic measure called parameterized maximum entropy (PME) is proposed for approximate attribute reduction. Specifically, considering that the classification ability under uncertainty is reflected by both the decision and the degree of confidence, a novel PME measure that attaches different levels of importance to the decision with the highest probability and other decisions is provided, and its monotonicity is theoretically proven. Furthermore, the idea of trisection in the three-way decision is introduced into the process of attribute reduction, and a heuristic algorithm based on the proposed measure is developed to generate an optimal three-way approximate reduct, which greatly improves the efficiency of attribute reduction. Several experiments conducted on UCI datasets show that the proposed method achieves a favorable performance with much fewer attributes in comparison with other representative methods.},
  archive      = {J_IJAR},
  author       = {Can Gao and Jie Zhou and Jinming Xing and Xiaodong Yue},
  doi          = {10.1016/j.ijar.2022.09.007},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {85-100},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Parameterized maximum-entropy-based three-way approximate attribute reduction},
  volume       = {151},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A geometric characterization of sensitivity analysis in
monomial models. <em>IJAR</em>, <em>151</em>, 64–84. (<a
href="https://doi.org/10.1016/j.ijar.2022.09.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sensitivity analysis in probabilistic discrete graphical models is usually conducted by varying one probability at a time and observing how this affects output probabilities of interest. When one probability is varied, then others are proportionally covaried to respect the sum-to-one condition of probabilities. The choice of proportional covariation is justified by multiple optimality conditions, under which the original and the varied distributions are as close as possible under different measures. For variations of more than one parameter at a time and for the large class of discrete statistical models entertaining a regular monomial parametrisation , we demonstrate the optimality of newly defined proportional multi-way schemes with respect to an optimality criterion based on the I-divergence. We demonstrate that there are varying parameters&#39; choices for which proportional covariation is not optimal and identify the sub-family of distributions where the distance between the original distribution and the one where probabilities are covaried proportionally is minimum. This is shown by adopting a new geometric characterization of sensitivity analysis in monomial models, which include most probabilistic graphical models. We also demonstrate the optimality of proportional covariation for multi-way analyses in Naive Bayes classifiers.},
  archive      = {J_IJAR},
  author       = {Manuele Leonelli and Eva Riccomagno},
  doi          = {10.1016/j.ijar.2022.09.006},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {64-84},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A geometric characterization of sensitivity analysis in monomial models},
  volume       = {151},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A subsampling approach for bayesian model selection.
<em>IJAR</em>, <em>151</em>, 33–63. (<a
href="https://doi.org/10.1016/j.ijar.2022.08.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is common practice to use Laplace approximations to decrease the computational burden when computing the marginal likelihoods in Bayesian versions of generalised linear models (GLM). Marginal likelihoods combined with model priors are then used in different search algorithms to compute the posterior marginal probabilities of models and individual covariates . This allows performing Bayesian model selection and model averaging. For large sample sizes, even the Laplace approximation becomes computationally challenging because the optimisation routine involved needs to evaluate the likelihood on the full dataset in multiple iterations. As a consequence, the algorithm is not scalable for large datasets. To address this problem, we suggest using stochastic optimisation approaches, which only use a subsample of the data for each iteration. We combine stochastic optimisation with Markov chain Monte Carlo (MCMC) based methods for Bayesian model selection and provide some theoretical results on the convergence of the estimates for the resulting time-inhomogeneous MCMC. Finally, we report results from experiments illustrating the performance of the proposed algorithm.},
  archive      = {J_IJAR},
  author       = {Jon Lachmann and Geir Storvik and Florian Frommlet and Aliaksandr Hubin},
  doi          = {10.1016/j.ijar.2022.08.018},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {33-63},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A subsampling approach for bayesian model selection},
  volume       = {151},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning and total evidence with imprecise probabilities.
<em>IJAR</em>, <em>151</em>, 21–32. (<a
href="https://doi.org/10.1016/j.ijar.2022.08.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In dynamic learning, a rational agent must revise their credence about a question of interest in accordance with the total evidence available between the earlier and later times. We discuss situations in which an observable event F that is sufficient for the total evidence can be identified, yet its probabilistic modeling cannot be performed in a precise manner. The agent may employ imprecise (IP) models of reasoning to account for the identified sufficient event, and perform change of credence or sequential decisions accordingly. Our proposal is illustrated with four case studies: the classic Monty Hall problem, statistical inference with non-ignorable missing data, frequentist hypothesis testing , and the use of forward induction in a two-person sequential game .},
  archive      = {J_IJAR},
  author       = {Ruobin Gong and Joseph B. Kadane and Mark J. Schervish and Teddy Seidenfeld and Rafael B. Stern},
  doi          = {10.1016/j.ijar.2022.08.016},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {21-32},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Learning and total evidence with imprecise probabilities},
  volume       = {151},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neighborhood relation-based variable precision
multigranulation pythagorean fuzzy rough set approach for
multi-attribute group decision making. <em>IJAR</em>, <em>151</em>,
1–20. (<a href="https://doi.org/10.1016/j.ijar.2022.09.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, the complexity of real decision-making problem makes people pay more and more attention to the effective evaluation and selection of decision methods. Considering that the Pythagorean fuzzy set (PFS) owing its better capacity can express the uncertainties of human inherent preferences, multigranulation Pythagorean fuzzy rough set (MGPFRS) model is proposed to handle uncertain multi-attribute group decision making (MAGDM) problem. We firstly build the δ −neighborhood relation over multi-attribute Pythagorean fuzzy decision making (MAPFDM) information system based on the distance measurement. Then, combined with the principle of variable precision rough set and PF information, the rough approximation of crisp and inaccuracy concept are discussed. That is, the variable precision multigranulation rough Pythagorean fuzzy set (VMGRPFS). On this basis, given the special case of fuzzy equivalence relation, we propose the variable precision multigranulation Pythagorean fuzzy rough set (VMGPFRS). Furthermore, some fascinating properties for the VMGRPFS and VMGPFRS model are given. The corresponding models of optimistic and pessimistic are deduced respectively. The interrelationship among of the established VMGRPFS and VMGPFRS with the classical multigranulation rough set are discussed in detail. In addition, a new MAGDM method with Pythagorean fuzzy information is proposed by using VMGPFRS and PROMETHEE methods. This method points out the basic principle and algorithm of decision making. Finally, we perform our established method to select the best photovoltaic cell and implement the comparative analysis which can verify the reliability and superiority of our approach.},
  archive      = {J_IJAR},
  author       = {Bingzhen Sun and Xinrui Zhang and Chang Qi and Xiaoli Chu},
  doi          = {10.1016/j.ijar.2022.09.002},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {1-20},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Neighborhood relation-based variable precision multigranulation pythagorean fuzzy rough set approach for multi-attribute group decision making},
  volume       = {151},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Information algebras in the theory of imprecise
probabilities, an extension. <em>IJAR</em>, <em>150</em>, 311–336. (<a
href="https://doi.org/10.1016/j.ijar.2022.09.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent works, we have shown how to construct an information algebra of coherent sets of gambles, considering firstly a particular model to represent questions, called the multivariate model , and then generalizing it. Here we further extend the construction made to the highest level of generality, setting up an associated information algebra of coherent lower previsions , analyzing the connection of both the information algebras constructed with an instance of set algebras and, finally, establishing and inspecting a version of the marginal problem in this framework. Set algebras are particularly important information algebras since they are their prototypical structures. They also represent the algebraic counterparts of classical propositional logic. As a consequence, this paper details as well how propositional logic is naturally embedded into the theory of imprecise probabilities .},
  archive      = {J_IJAR},
  author       = {Arianna Casanova and Juerg Kohlas and Marco Zaffalon},
  doi          = {10.1016/j.ijar.2022.09.003},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {311-336},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Information algebras in the theory of imprecise probabilities, an extension},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Constructing overlap functions via multiplicative generators
on complete lattices. <em>IJAR</em>, <em>150</em>, 297–310. (<a
href="https://doi.org/10.1016/j.ijar.2022.09.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiplicative generators of lattice-valued overlap functions are investigated throughout this paper. To be more specific, we first obtain the multiplicative generator pairs maintaining the standard approach, and then we define the generalized multiplicative generator triples by using overlap functions instead of the multiplication operator. Conditions for multiplicative generator pairs and triples are obtained and several examples are given to illustrate the conclusions. Finally, we investigate some properties including extended homogeneity and idempotency of overlap functions constructed by generalized multiplicative generator triples.},
  archive      = {J_IJAR},
  author       = {Yi-Qun Zhang and Hua-Wen Liu},
  doi          = {10.1016/j.ijar.2022.09.001},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {297-310},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Constructing overlap functions via multiplicative generators on complete lattices},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A fuzzy content-based group recommender system with dynamic
selection of the aggregation functions. <em>IJAR</em>, <em>150</em>,
273–296. (<a href="https://doi.org/10.1016/j.ijar.2022.08.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems are currently software tools that are focused on providing users with the best choices in an overloaded search space of possible options. Hence, group recommender systems have recently become an important trend in recommendation, because they aim at recommending a special type of items so-called social items, that tend to be consumed in groups such as TV programs, travel packages, etc. Among the different types of algorithms applied for group recommender systems, this paper is focused on content-based group recommender systems, as a novel group recommendation paradigm that exploits item features in the recommendation generation process. Specifically, our goal is to introduce a new content-based group recommendation approach, based on the recommendation aggregation paradigm whose main novelty is the development of a dynamic selection process of the aggregation scheme. Such an approach is centered on the identification of group&#39;s characteristics that are matching with the most appropriate function to use in the individual recommendation aggregation step. To perform such a matching, it is proposed a fuzzy decision tree induction process. The experimental evaluation shows that this scheme improves the recommendation performance of previous content-based group recommendation approaches, as well as it serves a starting point for further research based on this dynamic selection paradigm.},
  archive      = {J_IJAR},
  author       = {Raciel Yera and Ahmad A. Alzahrani and Luis Martínez},
  doi          = {10.1016/j.ijar.2022.08.015},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {273-296},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A fuzzy content-based group recommender system with dynamic selection of the aggregation functions},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the relative value of weak information of supervision for
learning generative models: An empirical study. <em>IJAR</em>,
<em>150</em>, 258–272. (<a
href="https://doi.org/10.1016/j.ijar.2022.08.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly supervised learning is aimed to learn predictive models from partially supervised data, an easy-to-collect alternative to the costly standard full supervision. During the last decade, the research community has striven to show that learning reliable models in specific weakly supervised problems is possible. We present an empirical study that analyzes the value of weak information of supervision throughout its entire spectrum, from none to full supervision. Its contribution is assessed under the realistic assumption that a small subset of fully supervised data is available. Particularized in the problem of learning with candidate sets, we adapt Cozman and Cohen [1] key study to learning from weakly supervised data. Standard learning techniques are used to infer generative models from this type of supervision with both synthetic and real data. Empirical results suggest that weakly labeled data is helpful in realistic scenarios, where fully labeled data is scarce, and its contribution is directly related to both the amount of information of supervision and how meaningful this information is.},
  archive      = {J_IJAR},
  author       = {Jerónimo Hernández-González and Aritz Pérez},
  doi          = {10.1016/j.ijar.2022.08.012},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {258-272},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {On the relative value of weak information of supervision for learning generative models: An empirical study},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the derivation of weights from incomplete pairwise
comparisons matrices via spanning trees with crisp and fuzzy confidence
levels. <em>IJAR</em>, <em>150</em>, 242–257. (<a
href="https://doi.org/10.1016/j.ijar.2022.08.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new method for the derivation of a priority vector from an incomplete pairwise comparisons (PC) matrix. We assume that each entry of a PC matrix provided by an expert is also evaluated in terms of the expert&#39;s confidence in a particular judgment. Then, from corresponding graph representations of a given PC matrix, all spanning trees are found. For each spanning tree, a unique priority vector is obtained with the weight corresponding to the confidence levels of entries that constitute this tree. At the end, the final priority vector is obtained through an aggregation of priority vectors achieved from all spanning trees. Confidence levels are modeled by real (crisp) numbers and triangular fuzzy numbers. Numerical examples and comparisons with other methods are also provided. Last, but not least, we introduce a new formula for an upper bound of the number of spanning trees, so that a decision maker gains knowledge (in advance) on how computationally demanding the proposed method is for a given PC matrix.},
  archive      = {J_IJAR},
  author       = {Jiri Mazurek and Konrad Kułakowski},
  doi          = {10.1016/j.ijar.2022.08.014},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {242-257},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {On the derivation of weights from incomplete pairwise comparisons matrices via spanning trees with crisp and fuzzy confidence levels},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A constructing approach to multi-granularity object-induced
three-way concept lattices. <em>IJAR</em>, <em>150</em>, 229–241. (<a
href="https://doi.org/10.1016/j.ijar.2022.08.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way concept analysis is a research hotspot. Inspired by multi-scale information system, some scholars put forward and researched multi-granularity formal context. Most of the existing algorithms for constructing three-way concept lattice take care of the static formal contexts and can not deal with the multi-granularity formal context. To address this problem, this paper primarily focuses on a constructing approach to object-induced three-way concept (OE-concept) lattices for multi-granularity formal contexts. Firstly, transformation relationships between OE-concepts based on different granularities are researched. Secondly, the mutual transformation between OE-concept lattices under different granularities is proposed via these relationships, and then corresponding algorithms are proposed. Finally, several groups of datasets are selected from UCI for comparative experiments . Experimental results exhibit that our algorithms are more effective and advantageous than the latest construction algorithms .},
  archive      = {J_IJAR},
  author       = {Qian Hu and Keyun Qin and Lei Yang},
  doi          = {10.1016/j.ijar.2022.08.017},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {229-241},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A constructing approach to multi-granularity object-induced three-way concept lattices},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Notes on “on (IO,o)-fuzzy rough sets based on overlap
functions.” <em>IJAR</em>, <em>150</em>, 223–228. (<a
href="https://doi.org/10.1016/j.ijar.2022.08.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Qiao investigated the properties and topological structures of ( I O , O ) (IO,O) -fuzzy rough sets, which extended the classical conjunction operator in rough approximation operator to an overlap function O . However, there are some faults in the characterizations of ( I O , O ) (IO,O) -fuzzy rough sets, such as wrong conclusions and strict condition, even if the overlap function O is assumed to be a continuous t-norm with no non-trivial zero divisors . This paper further discusses ( I O , O ) (IO,O) -fuzzy rough sets and rectifies those faults. Moreover, some examples are presented to show those faults.},
  archive      = {J_IJAR},
  author       = {Chun Yong Wang and Sheng Nan Xu and Lijuan Wan},
  doi          = {10.1016/j.ijar.2022.08.010},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {223-228},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Notes on “On (IO,O)-fuzzy rough sets based on overlap functions”},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Probability envelopes and their dempster-shafer
approximations in statistical matching. <em>IJAR</em>, <em>150</em>,
199–222. (<a href="https://doi.org/10.1016/j.ijar.2022.08.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many economic applications require to integrate information coming from different data sources. In this work we consider a specific integration problem, called statistical matching, referring to integration of data sets where some variables are separately observed and some others are observed in all the data sets. This problem leads to the issue of non-uniqueness for the compatible (conditional) distributions and so it suggests to deal with sets of probabilities . For that we consider different strategies to get a (conditional) belief function that approximates the lower envelope of the class of compatible (conditional) probabilities. We first analyze the case without logical constraints among the variables and then generalize the obtained results by allowing for logical constraints. We finally show an application to real data.},
  archive      = {J_IJAR},
  author       = {Davide Petturiti and Barbara Vantaggi},
  doi          = {10.1016/j.ijar.2022.08.011},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {199-222},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Probability envelopes and their dempster-shafer approximations in statistical matching},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep evidential fusion network for medical image
classification. <em>IJAR</em>, <em>150</em>, 188–198. (<a
href="https://doi.org/10.1016/j.ijar.2022.08.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-modality characteristic of medical images calls for the application of information fusion theory in computer aided diagnosis (CAD) algorithm design. Recently, the research of uncertainty estimation in deep neural networks provides a new perspective for information fusion in deep learning algorithms. For medical image classification tasks, due to the difficulty in collecting large-scale datasets, it is a challenging job in the study of deep learning multi-modality medical image classification model. In this paper, we investigate the fusion method based on the belief/uncertainty estimation framework of evidential deep learning (EDL) and Dempster&#39;s rule of combination. We also propose a deep evidential fusion method to best utilize the belief assignment and uncertainty estimation for combining the information of multi-modality medical images when only small-scale and even incomplete multi-modality medical image dataset is available. The proposed method has been tested on two real-world medical image classification tasks. To maximize the use of available medical imaging resources, we extended our model to handle the modality missing problem for multi-modality learning. Experiments show that, with the proposed weighted mass calibration method , our fusion model can handle the modality missing problem in real-world applications, making it possible to incorporate more incomplete data for learning.},
  archive      = {J_IJAR},
  author       = {Shaoxun Xu and Yufei Chen and Chao Ma and Xiaodong Yue},
  doi          = {10.1016/j.ijar.2022.08.013},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {188-198},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Deep evidential fusion network for medical image classification},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Selective label enhancement for multi-label classification
based on three-way decisions. <em>IJAR</em>, <em>150</em>, 172–187. (<a
href="https://doi.org/10.1016/j.ijar.2022.08.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label classification is a challenging issue in the data science community due to the ambiguity of label semantics . Existing studies mainly focus on improving label association with logical labels, but the performance suffers from the threshold setting. Although label distribution learning gains superior discrimination, the expenditure of collecting large-scale fine-grained numerical labels is intolerable. To address the uncertainty of logical label semantics, we propose a novel model called three-way decisions with label enhancement (3WDLE). For unseen instances, we implement a trisecting-acting-outcome framework. In the trisecting stage, an uncertainty measure called global uncertain-prone degree partitions these instances into uncertain and certain regions, where the trisecting procedure is completed from label level to instance level by leveraging the distributions of pseudo-label information. In the acting stage, instances recognized as certain regions directly take the results generated by label-specific learning, whereas the remaining are reclassified by conducting selective label enhancement. The enriched knowledge generated by the label enhancement module is learnt on trustworthy instances only. In the outcome stage, we adopt five evaluation metrics to evaluate the classification performance from the perspectives of both labels and instances. In this way, three-way decisions provide a systematic methodology to deal with uncertainty in multi-label classification, which combines logical label learning with numerical label learning into a unified framework to optimize the performance of the multi-label classification model . Extensive experiments demonstrate the superiority of 3WDLE over state-of-the-art multi-label classifications with logical labels only.},
  archive      = {J_IJAR},
  author       = {Tianna Zhao and Yuanjian Zhang and Duoqian Miao and Witold Pedrycz},
  doi          = {10.1016/j.ijar.2022.08.008},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {172-187},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Selective label enhancement for multi-label classification based on three-way decisions},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Alpha-divergence minimization for deep gaussian processes.
<em>IJAR</em>, <em>150</em>, 139–171. (<a
href="https://doi.org/10.1016/j.ijar.2022.08.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes the minimization of α -divergences for approximate inference in the context of deep Gaussian processes (DGPs). The proposed method can be considered as a generalization of variational inference (VI) and expectation propagation (EP), two previously used methods for approximate inference in DGPs. Both VI and EP are based on the minimization of the Kullback-Leibler divergence. The proposed method is based on a scalable version of power expectation propagation, a method that introduces an extra parameter α that specifies the targeted α -divergence to be optimized. In particular, such a method can recover the VI solution when α → 0 α→0 and the EP solution when α → 1 α→1 . An exhaustive experimental evaluation shows that the minimization of α -divergences via the proposed method is feasible in DGPs and that choosing intermediate values of the α parameter between 0 and 1 can give better results in some problems. This means that one can improve the results of VI and EP when training DGPs. Importantly, the proposed method allows for stochastic optimization techniques, making it able to address datasets with several millions of instances.},
  archive      = {J_IJAR},
  author       = {Carlos Villacampa-Calvo and Gonzalo Hernández-Muñoz and Daniel Hernández-Lobato},
  doi          = {10.1016/j.ijar.2022.08.003},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {139-171},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Alpha-divergence minimization for deep gaussian processes},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Formal analysis of peterson’s rules for checking validity of
syllogisms with intermediate quantifiers. <em>IJAR</em>, <em>150</em>,
122–138. (<a href="https://doi.org/10.1016/j.ijar.2022.08.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we follow up on previous publications in which we studied generalized Peterson&#39;s syllogisms with intermediate quantifiers. We present results of two kinds. First we show that on semantic level all the valid syllogisms follow from two inequalities and one equality. Furthermore, we focus on six rules suggested by Peterson in his book using which he was able to verify validity of all syllogisms. The problem is that the rules are formulated in free natural language and so, they do not provide formal means using which it would be possible to explain why the rules do their job. Therefore, we suggested formal reformulation of them and showed that all the valid syllogisms with intermediate quantifiers indeed satisfy Peterson&#39;s rules.},
  archive      = {J_IJAR},
  author       = {Vilém Novák and Petra Murinová and Petr Ferbas},
  doi          = {10.1016/j.ijar.2022.08.002},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {122-138},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Formal analysis of peterson&#39;s rules for checking validity of syllogisms with intermediate quantifiers},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Variable radius neighborhood rough sets and attribute
reduction. <em>IJAR</em>, <em>150</em>, 98–121. (<a
href="https://doi.org/10.1016/j.ijar.2022.08.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neighborhood rough sets provide important insights into dealing with numerical data. Neighborhood radius , a key factor that affects data uncertainty, is uniformly given in most of the existing neighborhood rough sets. Although it is concise and convenient to construct a granular structure, the same radius is not appropriate for the unique circumstance of each element in the universe. Therefore, taking the different environment of each object and label distribution into consideration, in this paper, we propose two novel neighborhood rough set models, namely, variable radius neighborhood rough sets (VRNRs) and neighborhood rough sets based on α -covering ( α -CNRSs). They customize the neighborhood radius for each object or local region of the universe by surrounding functions. Based on an investigation of the basic properties of VRNRs and α -CNRSs, we present two attribute reduction algorithms. Moreover, three comparative experiments are designed in terms of the running time, model stability, and classification accuracy . Theoretical analyses and experimental results show that the two new neighborhood rough set models have good robustness and validity in attribute reduction and classification performance.},
  archive      = {J_IJAR},
  author       = {Di Zhang and Ping Zhu},
  doi          = {10.1016/j.ijar.2022.08.005},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {98-121},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Variable radius neighborhood rough sets and attribute reduction},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybrid ResNet based on joint basic and attention modules for
long-tailed classification. <em>IJAR</em>, <em>150</em>, 83–97. (<a
href="https://doi.org/10.1016/j.ijar.2022.08.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-tailed distribution learning is one of the critical research fields of deep learning and has gradually become a research hotspot. Existing re-sampling methods for long-tailed data classification attempt to adjust the number of tail class samples to balance the overall feature space and achieve satisfactory results. However, the methods impair the representative ability of the learned features to a certain extent, which in turn affects the tail class feature space. In this paper, we propose a hybrid ResNet based on joint basic and attention modules to enhance the tail class feature space, which provides rich discriminative and representative features in the tail class feature space. Firstly, we use hybrid ResNet to extract features, where the basic module ResNet and the attention module ResNet extract head and tail class features, respectively. The enhancement of tail class features can reduce the dependence of the classifier on head class features. Secondly, we build a fusion loss function, which considers the tradeoff between head loss and tail loss for long-tailed distribution learning. Experimental results show that the proposed model outperforms several state-of-the-art models in the long-tailed classification. Our model was 2.67\% better than the optimal method under the long-tailed Tiny-Imagenet-LT dataset with an imbalanced ratio of 100.},
  archive      = {J_IJAR},
  author       = {Wei Zhao and Yuling Su and Minjie Hu and Hong Zhao},
  doi          = {10.1016/j.ijar.2022.08.007},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {83-97},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Hybrid ResNet based on joint basic and attention modules for long-tailed classification},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Quantile-based fuzzy c-means clustering of multivariate time
series: Robust techniques. <em>IJAR</em>, <em>150</em>, 55–82. (<a
href="https://doi.org/10.1016/j.ijar.2022.07.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust fuzzy clustering of multivariate time series is addressed when the clustering purpose is grouping together series generated from similar stochastic processes . Robustness to the presence of anomalous series is attained by considering three well-known robust versions of a fuzzy C -means model based on a spectral dissimilarity measure with high discriminatory power. The dissimilarity measure compares principal component scores obtained from estimates of quantile cross-spectral densities, and the robust techniques follow the so-called metric, noise and trimmed approaches. The metric approach incorporates in the objective function a distance aimed at neutralizing the effect of the outliers, the noise approach builds an artificial cluster expected to contain the outlying series, and the trimmed approach removes the most atypical series in the dataset. As result, the proposed clustering methods take advantage of both the robust nature of these techniques and the capability of the quantile cross-spectral density to identify complex dependence structures . An extensive simulation study including multivariate linear, nonlinear and GARCH processes shows that the algorithms are substantially effective in coping with the presence of outlying series, clearly outperforming other alternative procedures. Two specific applications regarding financial and environmental series illustrate the usefulness of the presented methods.},
  archive      = {J_IJAR},
  author       = {Ángel López-Oriona and Pierpaolo D&#39;Urso and José A. Vilar and Borja Lafuente-Rego},
  doi          = {10.1016/j.ijar.2022.07.010},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {55-82},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Quantile-based fuzzy C-means clustering of multivariate time series: Robust techniques},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Normal cones corresponding to credal sets of lower
probabilities. <em>IJAR</em>, <em>150</em>, 35–54. (<a
href="https://doi.org/10.1016/j.ijar.2022.08.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Credal sets are one of the most important models for describing probabilistic uncertainty. They usually arise as convex sets of probabilistic models compatible with judgments provided in terms of coherent lower previsions or more specific models such as coherent lower probabilities or probability intervals. In finite spaces, credal sets usually take the form of convex polytopes . Many properties of convex polytopes can be derived from their normal cones , which form polyhedral complexes called normal fans. We analyze the properties of normal cones corresponding to credal sets of coherent lower probabilities. For two important classes of coherent lower probabilities, 2-monotone lower probabilities and probability intervals, we provide a detailed description of the normal fan structure. These structures are related to the structure of the extreme points of the credal sets. To arrive at our main results, we provide some general results on triangulated normal fans of convex polyhedra and their adjacency structure.},
  archive      = {J_IJAR},
  author       = {Damjan Škulj},
  doi          = {10.1016/j.ijar.2022.08.006},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {35-54},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Normal cones corresponding to credal sets of lower probabilities},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Label distribution learning with noisy labels via three-way
decisions. <em>IJAR</em>, <em>150</em>, 19–34. (<a
href="https://doi.org/10.1016/j.ijar.2022.08.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label distribution learning (LDL) as a soft-labeling paradigm is allowed to learn single or multi-labeled information distribution. Overwhelmingly, in the open world, the distribution of labels is usually disturbed by the noise (such as the man-made induction bias, shake of hardware devices), which in turn affects the decision of downstream tasks. To address this problem, we propose a novel LDL approach by using the three-way decisions theory to clear the amplified noise in this paper. First, we evaluate the confidence of each training sample and use a three-way decisions-based method to identify the trustworthy samples and the noisy samples. Second, we apply the sample correlation between the trustworthy samples and the noisy samples to correct the noisy labels. Finally, we re-weight every sample based on the learned confidences to train the robust LDL model. Experiments show that our approach has better performance in handling noisy data compared to existing algorithms.},
  archive      = {J_IJAR},
  author       = {Weiwei Li and Yuqing Lu and Lei Chen and Xiuyi Jia},
  doi          = {10.1016/j.ijar.2022.08.009},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {19-34},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Label distribution learning with noisy labels via three-way decisions},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Valid inferential models for prediction in supervised
learning problems. <em>IJAR</em>, <em>150</em>, 1–18. (<a
href="https://doi.org/10.1016/j.ijar.2022.08.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prediction, where observed data is used to quantify uncertainty about a future observation, is a fundamental problem in statistics . Prediction sets with coverage probability guarantees are a common solution, but these do not provide probabilistic uncertainty quantification in the sense of assigning beliefs to relevant assertions about the future observable. Alternatively, we recommend the use of a probabilistic predictor , a data-dependent (imprecise) probability distribution for the to-be-predicted observation given the observed data. It is essential that the probabilistic predictor be reliable or valid, and here we offer a notion of validity and explore its behavioral and statistical implications. In particular, we show that valid probabilistic predictors must be imprecise, that they avoid sure loss, and that they lead to prediction procedures with desirable frequentist error rate control properties. We provide a general construction of a provably valid probabilistic predictor, which has close connections to the powerful conformal prediction machinery, and we illustrate this construction in regression and classification applications.},
  archive      = {J_IJAR},
  author       = {Leonardo Cella and Ryan Martin},
  doi          = {10.1016/j.ijar.2022.08.001},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {1-18},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Valid inferential models for prediction in supervised learning problems},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new class of decomposition integrals on finite spaces.
<em>IJAR</em>, <em>149</em>, 192–205. (<a
href="https://doi.org/10.1016/j.ijar.2022.08.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new type of decomposition integral is introduced by using a family of decomposition integrals based on the collections relating to partitions and maximal chains of sets. This new integral extends the Lebesgue integral , and it is different from those well-known decomposition integrals, such as the Choquet, concave, pan-, Shilkret integrals and PC-integral. In the structure of a lattice on the class of decomposition integrals, the introduced decomposition integral is between the Choquet integral and the concave integral, and also between the pan-integral and the concave integral, and it is a lower bound of PC-integral. The coincidences among several well-known integrals and this new integral are also shown.},
  archive      = {J_IJAR},
  author       = {Radko Mesiar and Jun Li and Yao Ouyang and Adam Šeliga},
  doi          = {10.1016/j.ijar.2022.08.004},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {192-205},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A new class of decomposition integrals on finite spaces},
  volume       = {149},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data-driven modeling with fuzzy sets and manifolds.
<em>IJAR</em>, <em>149</em>, 178–191. (<a
href="https://doi.org/10.1016/j.ijar.2022.07.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The manifold hypothesis states that the shape of the observed data is relatively simple and that it lies on a low-dimensional manifold embedded in a high-dimensional space. We contribute to the problem of data-driven modeling by treating it as an inverse problem where the model defines a Euclidean space with a Riemannian manifold structure. In particular, our contribution shows that a fuzzy set on a bounded support defines a Riemannian manifold that can be embedded in a multidimensional space where dimension is a model parameter. A noticeable advantage of the proposed approach is its connection with the values of the membership function and independence from the dimension of the data being modeled. Last but not least, we have found various formal representations of the Laplace-Beltrami operator and use its values as an estimate of the quality of the approximate solution to the inverse problem.},
  archive      = {J_IJAR},
  author       = {Irina Perfilieva},
  doi          = {10.1016/j.ijar.2022.07.009},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {178-191},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Data-driven modeling with fuzzy sets and manifolds},
  volume       = {149},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Discrete overlap functions: Basic properties and
constructions. <em>IJAR</em>, <em>149</em>, 161–177. (<a
href="https://doi.org/10.1016/j.ijar.2022.07.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a kind of emerging binary continuous aggregation operator that has been successfully applied in many practical application problems, overlap functions on the unit closed interval have been considered by scholars on different truth values sets lately. At the same time, studying aggregation operators on finite chains, especially for commonly used binary aggregation operators, is a meaningful and hot topic in the research field of aggregation operators. In this paper, we pay attention to overlap functions on finite chains, which are called discrete overlap functions. Specifically, first, we introduce the notions of discrete overlap functions on the finite chain L with n + 2 elements and its arbitrary subchains along with an extended form of them. Second, we study some basic properties of discrete overlap functions on L , especially for the idempotent property, Archimedean property and cancellation law. In particular, we obtain some new properties which are different from those of the overlap functions on other truth values sets, for instance, every discrete overlap function on L takes the greatest element on L as the neutral element. Third, we discuss the construction methods of discrete overlap functions on L . Finally, it is worth mentioning that the results obtained in this paper provide a theoretical basis and more possibilities for the potential applications of overlap functions in other fields besides their known applications, especially for the situation of that the reasoning of experts are described by linguistic terms or labels, such as in expert systems, fuzzy control and etc.},
  archive      = {J_IJAR},
  author       = {Junsheng Qiao},
  doi          = {10.1016/j.ijar.2022.07.004},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {161-177},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Discrete overlap functions: Basic properties and constructions},
  volume       = {149},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The interpretability and scalability of
linguistic-rule-based systems for solving regression problems.
<em>IJAR</em>, <em>149</em>, 131–160. (<a
href="https://doi.org/10.1016/j.ijar.2022.07.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study applies the idea of computing with words to develop an advanced genetic method to design the Linguistic Rule Base Systems (LRBSs) from a given dataset to solve the dataset regression problem , whose rules can be considered human knowledge. It has two primary specific features. The first is its ability to ensure the uncertain equality of two dataset contents assigned to each of its designed rules: the dataset content the users capture when reading it and the one the proposed method computes and assigns to it. Then, Tarski et al.&#39;s interpretability concept in the math logics field does require the designed fuzzy sets to be isomorphic images of their assigned words. It implies their soundness in representing their words. The second is its ability to ensure the LRBs&#39; scalability, an essential feature of human knowledge stating that it can grow while maintaining its existing one. Then, the proposed method can utilize the existing LRBSs optimality to design a new optimized LRBSs generation to increase the regression precision by allowing the existing L-attributes&#39; word sets to grow. Compared to existing methods, the conducted experimental study can justify its performance and benefits in solving the regression problems using benchmark datasets in this area.},
  archive      = {J_IJAR},
  author       = {Van Thong Hoang and Cat Ho Nguyen and Duc Du Nguyen and Dinh Phong Pham and Van Long Nguyen},
  doi          = {10.1016/j.ijar.2022.07.007},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {131-160},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {The interpretability and scalability of linguistic-rule-based systems for solving regression problems},
  volume       = {149},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Three-way decisions method based on matrices approaches
oriented dynamic interval-valued information system. <em>IJAR</em>,
<em>149</em>, 116–130. (<a
href="https://doi.org/10.1016/j.ijar.2022.07.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval-valued Information Systems (IvIS) reflect the uncertain information in real scene, in which the attribute value of objects are all interval values rather than single values. Data information analysed by three-way decisions is not static but dynamically changing in IvIS, which results in the updating of positive region, boundary region and negative region of decision class X . In this paper, a matrix computational framework based on λ -similarity relation is proposed on the variation of the attribute set, attribute value and object set. Based on the framework, some incremental algorithms are proposed to calculate the positive, boundary and negative region of X in dynamic IvIS. Finally, comparative experiments on data sets from UCI are conducted when attribute set, attribute value and object set are updating over time, respectively. Experimental results show that in comparison with the traditional algorithm, the proposed algorithms can effectively save time for the computation of positive, boundary and negative region of X in dynamic IvIS.},
  archive      = {J_IJAR},
  author       = {Ji Shi and Zhongying Suo},
  doi          = {10.1016/j.ijar.2022.07.008},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {116-130},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Three-way decisions method based on matrices approaches oriented dynamic interval-valued information system},
  volume       = {149},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Aggregation and definition of an algebraic framework for
fuzzy time series: An application in the supply-demand domain.
<em>IJAR</em>, <em>149</em>, 104–115. (<a
href="https://doi.org/10.1016/j.ijar.2022.07.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a method for aggregating the information contained in sets of Time Series (TS) into a Fuzzy Time Series (FTS). First, an aggregation technique is defined, which is based on the algorithm known as Kernel Density Estimation (KDE) which reconstructs the probabilistic density function of a set of points, in this case a TS. Second, to operate with FTS, an algebraic framework is created based on Zadeh&#39;s extension principle and as a result of operating with FTS, a new FTS is obtained, which allows obtaining richer information and operating under conditions of uncertainty. Finally, the operations needed to compute the membership function of any TS in the aggregated FTS are introduced too. As a use case, it is proposed to work with sets of TS in the supply and demand domain, in such a way that information regarding the satisfaction of demand over time can be extracted. The specific application domain chosen will be that of the electricity market, analysing the consumption of buildings and their self-generation of energy to obtain information about the dependence on the electricity grid.},
  archive      = {J_IJAR},
  author       = {Luis Rodriguez-Benitez and Juan Moreno-Garcia and Ester del Castillo-Herrera and Jun Liu and Luis Jimenez-Linares},
  doi          = {10.1016/j.ijar.2022.07.005},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {104-115},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Aggregation and definition of an algebraic framework for fuzzy time series: An application in the supply-demand domain},
  volume       = {149},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cost-sensitive sequential three-way decision for information
system with fuzzy decision. <em>IJAR</em>, <em>149</em>, 85–103. (<a
href="https://doi.org/10.1016/j.ijar.2022.07.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential three-way decision (S3WD) regarded as a dynamic multi-stage decision-making model, includes three critical components: evaluation function, threshold pair, and granularity structure. In this model, the construction of granularity structure, as the basis for decision execution, is closely related to the order in which the attributes are joined, while different features may require different costs in many real-world applications. Besides, the fuzziness of label space is widespread in information systems, however, the S3WD problem of information system with fuzzy decision has received little attention. Therefore, a cost-sensitive sequential three-way decision model for the information system with fuzzy decision is proposed in this paper. Firstly, a novel granulation method is proposed based on the density neighborhood for information system with fuzzy decision, which can obtain hidden connections of different objects. On this basis, a new evaluation criterion of attribute significance is presented by considering attribute dependence and test cost simultaneously. With three different test cost distributions, a cost-sensitive sequential three-way decision model is proposed by optimizing the information granularity. Finally, experimental results indicate that the performance of this model is affected by the granulation parameter. Compared with other S3WDs, the proposed model can achieve better classification performance with lower test costs.},
  archive      = {J_IJAR},
  author       = {Wenbin Qian and Yangyang Zhou and Jin Qian and Yinglong Wang},
  doi          = {10.1016/j.ijar.2022.07.006},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {85-103},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Cost-sensitive sequential three-way decision for information system with fuzzy decision},
  volume       = {149},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ensemble learning using three-way density-sensitive spectral
clustering. <em>IJAR</em>, <em>149</em>, 70–84. (<a
href="https://doi.org/10.1016/j.ijar.2022.07.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one popular clustering algorithm in the last few years, spectral clustering is advantageous over most existing clustering algorithms. Although spectral clustering can perform well in many instances, the algorithm still has some problems. The clusters obtained by spectral clustering have crisp boundaries, which cannot reflect the fact that one cluster may not have a well-defined boundary in the real situations. Furthermore, the frequently-used distance measures in spectral clustering cannot satisfy both global and local consistency, especially for the data with multi-scale. In order to address the above limitations, we firstly present a three-way density-sensitive spectral clustering algorithm, which uses the core region and the fringe region to represent a cluster. In the proposed algorithm, we use density-sensitive distance to produce a similarity matrix , which can well capture the real data structures . An overlap clustering is introduced to obtain the upper bound (unions of the core regions and the fringe regions) of each cluster and perturbation analysis is applied to separate the core regions from the upper bounds. The fringe region of the specific cluster is the differences between the upper bound and the core region. Because a single clustering algorithm cannot always achieve a good clustering result , we develop an improved ensemble three-way spectral clustering algorithm based on ensemble strategy. The proposed ensemble algorithm randomly extracts feature subset of sample and uses the three-way density-sensitive clustering algorithm to obtain the diverse base clustering results. Based on the base clustering results, voting method is used to generate a three-way clustering result. The experimental results show that the three-way density-sensitive clustering algorithm can well explain the data structure and maintain a good clustering performance at the same time, and the ensemble three-way density-sensitive spectral clustering can improve the robustness and stability of clustering results.},
  archive      = {J_IJAR},
  author       = {Jiachen Fan and Pingxin Wang and Chunmao Jiang and Xibei Yang and Jingjing Song},
  doi          = {10.1016/j.ijar.2022.07.003},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {70-84},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Ensemble learning using three-way density-sensitive spectral clustering},
  volume       = {149},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hierarchical classification based on coarse- to fine-grained
knowledge transfer. <em>IJAR</em>, <em>149</em>, 61–69. (<a
href="https://doi.org/10.1016/j.ijar.2022.07.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical classification has become one of the most popular research topics because the scale of data has increased exponentially. Top-down hierarchical classification is an effective classification method using the hierarchical class structure as important side information. However, inter-level error propagation is a crucial problem in the top-down strategy. In this paper, we propose a hierarchical classifier based on deep branch convolutional neural networks, which achieves hierarchical classification based on coarse- to fine-grained knowledge transfer. Specifically, we use a deep convolutional neural network to extract image rough and detailed features from shallow and deep networks. We then embed the branch network at different depths of the convolutional network for hierarchical classification. We splice features from the previous branch network to the current branch. It alleviates inter-level error propagation by knowledge transfer from coarse- to fine-grained. Experimental results on four datasets show that the proposed method outperforms nine popular classifiers for hierarchical classification. Especially on the CIFAR10 dataset, our method is about 5\% better than the second-best method.},
  archive      = {J_IJAR},
  author       = {Zeyu Qiu and Minjie Hu and Hong Zhao},
  doi          = {10.1016/j.ijar.2022.07.002},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {61-69},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Hierarchical classification based on coarse- to fine-grained knowledge transfer},
  volume       = {149},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Lymphoma segmentation from 3D PET-CT images using a deep
evidential network. <em>IJAR</em>, <em>149</em>, 39–60. (<a
href="https://doi.org/10.1016/j.ijar.2022.06.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An automatic evidential segmentation method based on Dempster-Shafer theory and deep learning is proposed to segment lymphomas from three-dimensional Positron Emission Tomography (PET) and Computed Tomography (CT) images. The architecture is composed of a deep feature-extraction module and an evidential layer. The feature extraction module uses an encoder-decoder framework to extract semantic feature vectors from 3D inputs. The evidential layer then uses prototypes in the feature space to compute a belief function at each voxel quantifying the uncertainty about the presence or absence of a lymphoma at this location. Two evidential layers are compared, based on different ways of using distances to prototypes for computing mass functions. The whole model is trained end-to-end by minimizing the Dice loss function. The proposed combination of deep feature extraction and evidential segmentation is shown to outperform the baseline UNet model as well as three other state-of-the-art models on a dataset of 173 patients.},
  archive      = {J_IJAR},
  author       = {Ling Huang and Su Ruan and Pierre Decazes and Thierry Denœux},
  doi          = {10.1016/j.ijar.2022.06.007},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {39-60},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Lymphoma segmentation from 3D PET-CT images using a deep evidential network},
  volume       = {149},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A three-way clustering approach using image enhancement
operations. <em>IJAR</em>, <em>149</em>, 1–38. (<a
href="https://doi.org/10.1016/j.ijar.2022.07.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way clustering receives its motivation from three-way decisions. It uses the core set and support set to describe a cluster. The two sets divide clustering results into three parts or regions called inside, outside, and partial. The division helps identify the central core and outer sparse regions of a cluster, which is useful when the clusters have dense regions but also have vague boundaries. One of the main challenges in three-way clustering is the meaningful construction of the two sets and three regions. In this article, we introduce a blurring and sharpening inspired three-way clustering algorithm or BS3 for short. We first explain the use of blurring and sharpening operations to create a three-way representation for a typical object in an image in the form of central primary (the clear part of the object), blurry (the unclear part of the object), and the non-object part. Next, by realizing similarities between the object and a cluster, we define cluster blur and cluster sharp operations to create a three-way representation for clusters. Experimental results on real-world and synthetic datasets suggest that BS3 is comparable to best performing approaches and in many cases has superior results.},
  archive      = {J_IJAR},
  author       = {Bahar Ali and Nouman Azam and JingTao Yao},
  doi          = {10.1016/j.ijar.2022.07.001},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {1-38},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A three-way clustering approach using image enhancement operations},
  volume       = {149},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Qualitative capacities: Basic notions and potential
applications. <em>IJAR</em>, <em>148</em>, 253–290. (<a
href="https://doi.org/10.1016/j.ijar.2022.05.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Qualitative capacities are set functions valued on a finite chain, increasing in the wide sense with respect to set inclusion. This paper exploits formal analogies between qualitative capacities and numerical capacities: we first recall qualitative counterparts to Möbius transforms, game-theoretic core, and conjugate set functions. However, in the qualitative setting, possibility measures play the same role as probability measures in the quantitative setting. Then possibility and necessity measures sometimes do not convey the same type of information. This situation creates difficulties to interpret qualitative capacities and related notions inspired from the quantitative setting. In particular, we propose three different ways of using qualitative capacities: either as bounds on ill-known possibility or necessity measures, or as tools to express the decision maker attitude in qualitative criteria under uncertainty, or yet qualitative counterparts of belief functions that handle both incompleteness and inconsistency of pieces of information stemming from several sources. In the latter framework possibility and necessity measures do not represent the same type of information. We define order relations between capacities with a view to compare them in terms of informational contents . We also study a counterpart of Dempster rule of combination in the qualitative setting. We compare several capacity combination rules in the framework of an information fusion problem. Finally, we address the problem of eliciting qualitative capacities based on human-originated information.},
  archive      = {J_IJAR},
  author       = {Didier Dubois and Francis Faux and Henri Prade and Agnès Rico},
  doi          = {10.1016/j.ijar.2022.05.009},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {253-290},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Qualitative capacities: Basic notions and potential applications},
  volume       = {148},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Probabilistic programming with stochastic variational
message passing. <em>IJAR</em>, <em>148</em>, 235–252. (<a
href="https://doi.org/10.1016/j.ijar.2022.06.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic approximation methods for variational inference have recently gained popularity in the probabilistic programming community since these methods are amenable to automation and allow online, scalable, and universal approximate Bayesian inference . Unfortunately, common Probabilistic Programming Languages (PPLs) with stochastic approximation engines lack the efficiency of message passing-based inference algorithms with deterministic update rules such as Belief Propagation (BP) and Variational Message Passing (VMP). Still, Stochastic Variational Inference (SVI) and Conjugate-Computation Variational Inference (CVI) provide principled methods to integrate fast deterministic inference techniques with broadly applicable stochastic approximate inference. Unfortunately, implementation of SVI and CVI necessitates manually driven variational update rules, which does not yet exist in most PPLs. In this paper, we cast SVI and CVI explicitly in a message passing-based inference context. We provide an implementation for SVI and CVI in ForneyLab, which is an automated message passing-based probabilistic programming package in the open source Julia language. Through a number of experiments, we demonstrate how SVI and CVI extends the automated inference capabilities of message passing-based probabilistic programming.},
  archive      = {J_IJAR},
  author       = {Semih Akbayrak and İsmail Şenöz and Alp Sarı and Bert de Vries},
  doi          = {10.1016/j.ijar.2022.06.006},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {235-252},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Probabilistic programming with stochastic variational message passing},
  volume       = {148},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Attribute reduction based on d-s evidence theory in a hybrid
information system. <em>IJAR</em>, <em>148</em>, 202–234. (<a
href="https://doi.org/10.1016/j.ijar.2022.06.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important uncertainty reasoning method, Dempster-Shafer (D-S) evidence theory has been widely applied to expert system, comprehensive evaluation, information fusion and decision analysis . However, it has not been fully valued in uncertainty measurement. A hybrid information system (HIS) means an information system that contains many types of attributes (e.g., categorical attribute, real-valued attribute and attribute with missing values, etc.). It is more difficult to measure an HIS than an ordinary IS. This paper studies the use of evidence theory to measure the uncertainty of an HIS. Firstly, a novel distance between two objects in an HIS considering decision attributes is constructed, and secondly, the tolerance relation based on the constructed distance is established in an HIS. And then, belief and plausibility functions are defined by the tolerance relation. Furthermore, several algorithms for attribute reduction are designed on the basis of the defined belief and plausibility functions. In addition, we come to a series of conclusions on the relation among θ -reduction by using decision attributes, θ -belief reduction and θ -plausibility reduction, which further confirms the effectiveness of the designed attribute reduction algorithms . Finally, the experimental results and statistical test show that the defined belief and plausibility functions work well in measuring the uncertainty of an HIS and the designed reduction algorithm is superior to several state-of-the-art algorithms in classification accuracy . These results will provide a wider perspective on the uncertainty of an HIS.},
  archive      = {J_IJAR},
  author       = {Qinli Zhang and Liangdong Qu and Zhaowen Li},
  doi          = {10.1016/j.ijar.2022.06.002},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {202-234},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Attribute reduction based on D-S evidence theory in a hybrid information system},
  volume       = {148},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The normalized expected utility – entropy and variance model
for decisions under risk. <em>IJAR</em>, <em>148</em>, 174–201. (<a
href="https://doi.org/10.1016/j.ijar.2022.06.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The normalized expected utility - entropy and variance (NEU-EV) decision model and associated risk measure are proposed for the analysis and modelling of decisions under risk. The model depends on normalized entropy and variance and expected utility, can be applied to decision problems depending on actions, where the states have different numbers of outcomes. Several properties of risk perception and examples of certainty effects, common ratio effects and common consequence effects are analysed using this model, considering actions with non-negative outcomes. The results show that the NEU-EV model is an adequate model for explaining these risk decision problems.},
  archive      = {J_IJAR},
  author       = {Irene Brito},
  doi          = {10.1016/j.ijar.2022.06.005},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {174-201},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {The normalized expected utility – entropy and variance model for decisions under risk},
  volume       = {148},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Rectangles-based discrete universal fuzzy integrals.
<em>IJAR</em>, <em>148</em>, 162–173. (<a
href="https://doi.org/10.1016/j.ijar.2022.06.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using hypergraphs of survival functions , we propose a rather general method for the construction of discrete fuzzy integrals . Our method is based on various rectangle decompositions of hypergraphs and on rectangle mappings suitably evaluating the rectangles of the considered decompositions. By means of appropriate binary aggregation functions we define two types of rectangle mappings and four types of discrete fuzzy integral constructions, and we also investigate the properties of the introduced integrals and the relationships between them. All the introduced methods based on non-overlapping rectangles coincide in the case of the product aggregation function, and then the related integral is the Choquet integral . Several examples are given.},
  archive      = {J_IJAR},
  author       = {Radko Mesiar and Anna Kolesárová},
  doi          = {10.1016/j.ijar.2022.06.003},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {162-173},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Rectangles-based discrete universal fuzzy integrals},
  volume       = {148},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fuzzy closure systems: Motivation, definition and
properties. <em>IJAR</em>, <em>148</em>, 151–161. (<a
href="https://doi.org/10.1016/j.ijar.2022.06.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is to extend closure systems from being crisp sets with certain fuzzy properties to proper fuzzy sets. The presentation of the paper shows a thorough discussion on the different alternatives that could be taken to define the desired fuzzy closure systems. These plausible alternatives are discarded if they are proven impossible to be in a bijective correspondence with closure operators . Finally, a definition of fuzzy closure system is established and a one-to-one relation with closure operators is proved.},
  archive      = {J_IJAR},
  author       = {Manuel Ojeda-Hernández and Inma P. Cabrera and Pablo Cordero and Emilio Muñoz-Velasco},
  doi          = {10.1016/j.ijar.2022.06.004},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {151-161},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Fuzzy closure systems: Motivation, definition and properties},
  volume       = {148},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distributivity characterization of idempotent uni-nullnorms
and overlap or grouping functions. <em>IJAR</em>, <em>148</em>, 133–150.
(<a href="https://doi.org/10.1016/j.ijar.2022.05.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, some authors studied the distributive laws of continuous t-norms and some families of the common classes of uninorms over overlap and grouping functions in [33] , [41] , but until now a complete characterization of the distributivity on idempotent uninorms over overlap or grouping functions widely used in image processing is still unresolved. Moreover, authors in [55] characterized the distributivity equations of uni-nullnorms with continuous Archimedean underlying operators over the above two functions. In this paper, we proceed with the distributivity characterization of idempotent uni-nullnorms over them which obviously generalizes the corresponding results of idempotent uninorms over these two functions. During the process, we introduce a class of weak overlap and grouping functions with weak coefficients, and obtain the full characterizations of the above functions by considering the different values of the underlying uninorms&#39; associated functions of idempotent uni-nullnorms on the interval endpoints and comparing the values with the weak coefficients. These obtained results totally answer the question on the distributive solutions of idempotent uninorms over overlap functions, which have been mentioned as their future works in [33] . In additions, we also obtain that overlap and grouping functions have particular structures with a constant domain where its value equals to the neutral element of the idempotent uninorm when they are distributive over idempotent uninorms.},
  archive      = {J_IJAR},
  author       = {Ting-hai Zhang and Feng Qin and Jie Wan and Qimin Hu and Zhenhua Cao},
  doi          = {10.1016/j.ijar.2022.05.013},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {133-150},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Distributivity characterization of idempotent uni-nullnorms and overlap or grouping functions},
  volume       = {148},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A fast neighborhood classifier based on hash bucket with
application to medical diagnosis. <em>IJAR</em>, <em>148</em>, 117–132.
(<a href="https://doi.org/10.1016/j.ijar.2022.05.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the medical diagnosis, expensive costs will increase significantly with the increment of medical information, and they can be reduced by data mining methods. The neighborhood classifier, as one of the extensions of the neighborhood rough set, has become an intuitive and effective classification method in data mining. However, there are still some defects which limit its performance. On the one hand, most existing neighborhood classifiers suffer from high computation complexity to obtain the neighborhood of samples; on the other hand, the difference between samples in the neighborhood is ignored when classifying samples, which diminishes the classification ability of the model. Therefore, in this paper, hash buckets and distance voting rule are introduced to solve the above problems, and a fast neighborhood classifier based on hash bucket (FNC-HB) is proposed. First, all samples are mapped to corresponding buckets through the hash function . Next, for any test sample, a bucket-based adaptive neighborhood classification radius is defined, in which the artificial parameter has been eliminated. Then, to avoid the indiscernibility of traditional voting rule when predicting labels of the test sample, a new rule called distance voting rule is defined. Finally, experimental results show that FNC-HB has better classification performance and computation efficiency, which is feasible and effective.},
  archive      = {J_IJAR},
  author       = {Jiayu Xiao and Qinghua Zhang and Zhihua Ai and Guoyin Wang},
  doi          = {10.1016/j.ijar.2022.05.012},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {117-132},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A fast neighborhood classifier based on hash bucket with application to medical diagnosis},
  volume       = {148},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel interval-valued data driven type-2 possibilistic
local information c-means clustering for land cover classification.
<em>IJAR</em>, <em>148</em>, 80–116. (<a
href="https://doi.org/10.1016/j.ijar.2022.05.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the process of land cover classification, existing fuzzy clustering is not enough to describe the high-order fuzzy uncertainty, while possibilistic clustering has serious parameter dependence and cluster consistency, which makes them unable to effectively deal with the phenomena of “different objects with the same spectrum” and “different objects with the same spectrum”. Hence, this paper proposes a robust type-2 possibilistic C-means clustering with local information and interval-valued data model for remote sensing land cover classification. Firstly, according to the local neighborhood variance, remote sensing information is modeled as interval-valued data. Secondly, existing possibilistic C-means clustering is modified and an enhanced possibilistic C-means clustering is obtained. Once again, it is used to clustering interval-valued data and a single weighting exponent type-2 possibilistic C-means clustering with double distance measures is constructed. Finally, to further improve the robustness of clustering method , local information is embedded into the objective function of this enhanced type-2 possibilistic C-means clustering and a novel robust possibilistic clustering-related algorithm for remote sensing information classification is proposed. Experimental results show that the proposed algorithm outperforms existing state of the art type-2 clustering-related algorithms, and is of great significance to the interpretation of remote sensing images .},
  archive      = {J_IJAR},
  author       = {Chengmao Wu and Xiaokang Guo},
  doi          = {10.1016/j.ijar.2022.05.007},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {80-116},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A novel interval-valued data driven type-2 possibilistic local information c-means clustering for land cover classification},
  volume       = {148},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The uncertain ordered weighted averaging adequacy
coefficient operator. <em>IJAR</em>, <em>148</em>, 68–79. (<a
href="https://doi.org/10.1016/j.ijar.2022.06.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces the uncertain ordered weighted averaging adequacy coefficient (UOWAAC) operator. This novel operator uses the ordered weighted averaging (OWA) operator, the adequacy coefficient, and the interval numbers in a single formulation. This article also extends the UOWAAC operator by using order-inducing variables in the reordering process of the input arguments. This new extension is called the uncertain induced ordered weighted averaging adequacy coefficient (UIOWAAC) operator. The article also presents an application of the new approach in a multi-criteria group decision making (MCGDM) problem about international expansion. In addition, a comparative analysis is conducted with the purpose of demonstrating the superiority of the UOWAAC and UIOWAAC aggregation operators in specific situations. Likewise, the use of basic uncertain information (BUI) is discussed. The results show the usefulness of these new aggregation operators in real-life decision making problems under uncertainty, particularly when the decision maker wants to compare different alternatives with an ideal but without giving any penalty or reward in the case that the ideal levels are exceeded.},
  archive      = {J_IJAR},
  author       = {Anton Figuerola-Wischke and Anna M. Gil-Lafuente and José M. Merigó},
  doi          = {10.1016/j.ijar.2022.06.001},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {68-79},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {The uncertain ordered weighted averaging adequacy coefficient operator},
  volume       = {148},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hierarchical neighborhood entropy based multi-granularity
attribute reduction with application to gene prioritization.
<em>IJAR</em>, <em>148</em>, 57–67. (<a
href="https://doi.org/10.1016/j.ijar.2022.05.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a prominent model of granular computing , neighborhood rough set provides clear granularity organization and expression in terms of inherent parameter (neighborhood radius). Such characteristic is widely captured in a plenitude of attribute reduction procedures, while igniting a tricky issue of tuning parameters. In this study, we therefore propose a parameter-free multi-granularity attribute reduction scheme. Fundamentally, our scheme applies three-way decision as thinking in threes. First, data-aware multi-granularity structure is automatically induced from self-contained distance space instead of manually edited or appointed granularities. Second, a novel multi-granularity feature evaluation criterion named hierarchical neighborhood entropy is defined to measure the feature significance. Finally, a sequential forward searching algorithm is designed to find the optimal reduct. With application to gene prioritization, our method performed on microarray data is experimentally demonstrated to be more effective and efficient in differentially expressed genes discovery as compared with other well-established attribute reduction algorithms.},
  archive      = {J_IJAR},
  author       = {Keyu Liu and Tianrui Li and Xibei Yang and Hengrong Ju and Xin Yang and Dun Liu},
  doi          = {10.1016/j.ijar.2022.05.011},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {57-67},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Hierarchical neighborhood entropy based multi-granularity attribute reduction with application to gene prioritization},
  volume       = {148},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multidimensional fuzzy implications. <em>IJAR</em>,
<em>148</em>, 41–56. (<a
href="https://doi.org/10.1016/j.ijar.2022.05.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multidimensional fuzzy sets (MFS) is a new extension of fuzzy sets on which the membership values of an element in the discourse universe are increasingly ordered vectors on the set of real numbers in the interval [ 0 , 1 ] [0,1] . This paper aims to investigate fuzzy negations and, mainly, fuzzy implications on the set of increasingly ordered vectors on [ 0 , 1 ] [0,1] , i.e. on L ∞ ( [ 0 , 1 ] ) L∞([0,1]) , MFN and MFI in short, with respect to some partial order. In this paper we study partial orders, giving special attention to admissible orders on L ∞ ( [ 0 , 1 ] ) L∞([0,1]) . In addition, some properties and methods to construct such operators from fuzzy negations and fuzzy implications, respectively, are provided and we demonstrate that the action of the group of automorphisms on fuzzy implications on L ∞ ( [ 0 , 1 ] ) L∞([0,1]) preserves several original properties of the implication. Finally, through a specific type of representable MFI, we are able to generate a class of MFN called natural m-negations.},
  archive      = {J_IJAR},
  author       = {Landerson Santiago and Benjamin Bedregal},
  doi          = {10.1016/j.ijar.2022.05.010},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {41-56},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Multidimensional fuzzy implications},
  volume       = {148},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel three-way decision model with DEA method.
<em>IJAR</em>, <em>148</em>, 23–40. (<a
href="https://doi.org/10.1016/j.ijar.2022.05.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce data envelopment analysis (DEA) model into rough sets, and propose a novel three-way decision model to deal with the decision problems with multiple decision attributes . On the integration of the “trisecting-acting-outcome (TAO)” framework of three-way decision (3WD) and DEA model, three ordered regions (i.e. efficient region, weakly efficient region, and inefficient region) are generated in the trisecting part. The corresponding strategies are subsequently adopted to process these three regions in the acting part. Specifically, the decision making units (DMUs) in the efficient region are considered as benchmarks for the other two regions; three projection strategies are designed to improve the DMUs in the weakly efficient and inefficient regions. Besides, the effectiveness of the results of trisecting and acting is measured in the outcome evaluation part. Finally, two numerical examples are provided to validate the proposed model.},
  archive      = {J_IJAR},
  author       = {Dun Liu and Qinxia Chen},
  doi          = {10.1016/j.ijar.2022.05.003},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {23-40},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A novel three-way decision model with DEA method},
  volume       = {148},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Some implicative topological quasi-boolean algebras and
rough set models. <em>IJAR</em>, <em>148</em>, 1–22. (<a
href="https://doi.org/10.1016/j.ijar.2022.05.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper a number of implicative topological algebras have been developed which are based on the implicative quasi-Boolean algebra with operator (IqBaO) [10] . Their independence is established by several examples. Logics corresponding to these algebras are presented. Two new pairs of lower-upper approximations of a set have been introduced in order to develop the notion of duality with respect to the quasi-complementation. Set theoretic rough set models of some of the algebras are constructed using these lower-upper approximations and quasi-complementation.},
  archive      = {J_IJAR},
  author       = {Masiur Rahaman Sardar and Mihir Kumar Chakraborty},
  doi          = {10.1016/j.ijar.2022.05.008},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {1-22},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Some implicative topological quasi-boolean algebras and rough set models},
  volume       = {148},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Markovian imprecise jump processes: Extension to measurable
variables, convergence theorems and algorithms. <em>IJAR</em>,
<em>147</em>, 78–124. (<a
href="https://doi.org/10.1016/j.ijar.2022.05.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing framework of Markovian imprecise jump processes, also known as imprecise continuous-time Markov chains , is limited to bounded real variables that depend on the state of the system at a finite number of (future) time points . This is an issue in many applications, because typically the variables of interest depend on the state of the system at all time points in some – possibly unbounded – (future) interval, and they can be unbounded or even extended real valued; examples of such variables are temporal averages, the number of (selected) jumps in some interval and hitting times. To eliminate this shortcoming, we assume that the sample paths are càdlàg and use measure theory to extend the domain of Markovian imprecise jump processes to extended real-valued variables that may depend on the state of the system at all (future) time points – that is, the extended real variables that are bounded below or above and are measurable with respect to the σ -algebra generated by the cylinder events. We investigate the continuity properties of the extended lower and upper expectations with respect to point-wise convergent sequences , and this yields generalisations of the Monotone Convergence Theorem and Lebesgue&#39;s Dominated Convergence Theorem. For two particular classes of variables, we strengthen these convergence theorems and present an iterative scheme to approximate their lower and upper expectations. The first class is the number of selected jumps in some interval, and the second class are real variables that take the form of a Riemann integral over some interval; this second class includes temporal averages and occupancy times.},
  archive      = {J_IJAR},
  author       = {Alexander Erreygers and Jasper De Bock},
  doi          = {10.1016/j.ijar.2022.05.006},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {78-124},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Markovian imprecise jump processes: Extension to measurable variables, convergence theorems and algorithms},
  volume       = {147},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Using credal c4.5 for calibrated label ranking in
multi-label classification. <em>IJAR</em>, <em>147</em>, 60–77. (<a
href="https://doi.org/10.1016/j.ijar.2022.05.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Label Classification (MLC) assumes that each instance belongs to a set of labels, unlike traditional classification, where each instance corresponds to a unique value of a class variable. Calibrated Label Ranking (CLR) is an MLC algorithm that determines a ranking of labels for a given instance by considering a binary classifier for each pair of labels. In this way, it exploits pairwise label correlations. Furthermore, CLR alleviates the class-imbalance problem that usually arises in MLC because, in this domain, very few instances often belong to a label. In order to build the binary classifiers in CLR, it is required to employ a standard classification algorithm. The Decision Tree method C4.5 has been widely used in this field. In this research, we show that a version of C4.5 based on imprecise probabilities recently proposed, known as Credal C4.5, is more appropriate than C4.5 to handle the binary classification tasks in CLR. Experimental results reveal that Credal C4.5 outperforms C4.5 when both methods are used in CLR and that the difference is more statistically significant as the label noise level is higher.},
  archive      = {J_IJAR},
  author       = {Serafín Moral-García and Carlos J. Mantas and Javier G. Castellano and Joaquín Abellán},
  doi          = {10.1016/j.ijar.2022.05.005},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {60-77},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Using credal c4.5 for calibrated label ranking in multi-label classification},
  volume       = {147},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Incomplete three-way multi-attribute group decision making
based on adjustable multigranulation pythagorean fuzzy probabilistic
rough sets. <em>IJAR</em>, <em>147</em>, 40–59. (<a
href="https://doi.org/10.1016/j.ijar.2022.05.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Different from the traditional two-way decision paradigm, three-way decisions (3WD) have been extensively explored in addressing realistic multi-attribute decision making (MADM) by virtue of its powerful performances in minimizing decision risks with the added non-commitment option. Since existing 3WD models can not efficiently handle MADM issues in the group setting with incomplete high-order fuzzy information systems (ISs), the current paper focuses on exploring viable three-way multi-attribute group decision making (MAGDM) methods in light of the multi-granularity 3WD paradigm under incomplete Pythagorean fuzzy (PF) environments. First, the notion of Multigranulation (MG) incomplete PF ISs is constructed. Then, optimistic, pessimistic and adjustable MG PF probabilistic rough sets (PRSs) are proposed after patching lost values. Afterwards, the decision-making-driven 3WD method is extended via adjustable MG PF PRSs, and an improved technique for order preference by similarity to ideal solution (TOPSIS) method with entropy weights is utilized for optimal granularity selections. According to adjustable MG PF PRSs and the improved TOPSIS method, a new three-way MAGDM method is eventually established. At last, two case studies are investigated in the background of mine ventilator fault diagnosis (MVFD) and air quality evaluations (AQE), and several comparative experiments and sensitivity analysis are performed for presenting the effectiveness of the constructed theoretical methodology.},
  archive      = {J_IJAR},
  author       = {Chao Zhang and Juanjuan Ding and Jianming Zhan and Deyu Li},
  doi          = {10.1016/j.ijar.2022.05.004},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {40-59},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Incomplete three-way multi-attribute group decision making based on adjustable multigranulation pythagorean fuzzy probabilistic rough sets},
  volume       = {147},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hierarchical bayesian text modeling for the unsupervised
joint analysis of latent topics and semantic clusters. <em>IJAR</em>,
<em>147</em>, 23–39. (<a
href="https://doi.org/10.1016/j.ijar.2022.05.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topic modeling can be unified synergically with document clustering . In this manuscript, we propose two innovative unsupervised approaches for the combined modeling and interrelated accomplishment of the two tasks. Both approaches rely on respective Bayesian generative models of topics, contents and clusters in textual corpora. Such models treat topics and clusters as linked latent factors in document wording. In particular, under the generative model of the second approach, textual documents are characterized by topic distributions, that are allowed to vary around the topic distributions of their membership clusters . Within the devised models, algorithms are designed to implement Rao-Blackwellized Gibbs sampling together with parameter estimation. These are derived mathematically for carrying out topic modeling with document clustering in a simultaneous and interrelated manner. A comparative empirical evaluation demonstrates the effectiveness of the presented approaches, over different families of state-of-the-art competitors, in clustering real-world benchmark text collections and, also, uncovering their underlying semantics. Besides, a case study is developed as an insightful qualitative analysis of results on real-world text corpora.},
  archive      = {J_IJAR},
  author       = {Gianni Costa and Riccardo Ortale},
  doi          = {10.1016/j.ijar.2022.05.002},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {23-39},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Hierarchical bayesian text modeling for the unsupervised joint analysis of latent topics and semantic clusters},
  volume       = {147},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Formalization and implementation of credibility dynamics
through prioritized multiple revision. <em>IJAR</em>, <em>147</em>,
1–22. (<a href="https://doi.org/10.1016/j.ijar.2022.05.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we focus on credibility dynamics. The trust or credibility associated with a set of agents is represented by a pairwise comparison partial order of agents called credibility order. In this paper, we formalize a prioritized multiple revision operator that can be used to revise one credibility order by another credibility order. We introduce a set of postulates for this change operator, and we show that our proposed operator satisfies those postulates. We will also introduce a computer application we have developed to provide a complete implementation of our approach. The application has an intuitive graphical user interface to handle credibility orders, apply the change operator, and has some visual tools to explain the revision process.},
  archive      = {J_IJAR},
  author       = {Federico Joaquín and Luciano H. Tamargo and Alejandro J. García},
  doi          = {10.1016/j.ijar.2022.05.001},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {1-22},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Formalization and implementation of credibility dynamics through prioritized multiple revision},
  volume       = {147},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The structure theorem of three-way concept lattice.
<em>IJAR</em>, <em>146</em>, 157–173. (<a
href="https://doi.org/10.1016/j.ijar.2022.04.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way decision (3WD) is a widely used and studied mathematical theory that generalizes the thinking norm of tri-level in cognitive learning, problem solving, and information processing. By utilizing the negative information contained in data, three-way concept lattice (3WCL) developed 3WD in Formal Concept Analysis and has been applied in various applications such as conflict analysis, role based access control , knowledge discovery, concept learning, and medical diagnose. However, the connections between 3WCL and classical concept lattices have not received its deserved attention. To this end, first, this paper proved that 3WCL is exactly the minimal closure system containing both concept lattice and complementary concept lattice, and classified three-way concepts into four categories. Second, this paper proved the structure theorem of 3WCL that characterizes mathematically the relationships between concept lattice, complementary concept lattice and 3WCL as two isomorphisms. Third, this paper presented several applications of the structure theorem to reveal its essentiality in discussing the properties of 3WCL. Finally, some problems that are not involved in the structure theorem are also discussed.},
  archive      = {J_IJAR},
  author       = {Yanhui Zhai and Jianjun Qi and Deyu Li and Chao Zhang and Weihua Xu},
  doi          = {10.1016/j.ijar.2022.04.007},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {157-173},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {The structure theorem of three-way concept lattice},
  volume       = {146},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distribution-free risk analysis. <em>IJAR</em>,
<em>146</em>, 133–156. (<a
href="https://doi.org/10.1016/j.ijar.2022.04.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Elementary formulas for propagating information about means and variances through mathematical expressions have long been used by analysts. Yet the precise implications of such information are rarely articulated. This paper explores distribution-free techniques for risk analysis that do not require simulation, sampling or approximation of any kind. We describe best-possible bounds on risks that can be inferred given only information about the range, mean and variance of a random variable . These bounds generalise the classical Chebyshev inequality in an obvious way. We also collect in convenient tables several formulas for propagating range and moment information through calculations involving 7 binary convolutions (addition, subtraction, multiplication, division, powers, minimum, and maximum) and 9 unary transformations (scalar multiplication, scalar translation, exponentiation , natural and common logarithms, reciprocal, square, square root and absolute value) commonly encountered in risk expressions. These formulas are rigorous rather than approximate, and in most cases are either exact or mathematically best-possible. The formulas can be used effectively even when only interval estimates of the moments are available. Although most discussions of moment propagation assume stochastic independence among variables, this paper shows the assumption to be unnecessary and generalises formulas for the case when no assumptions are made about dependence, and when correlations are partially known. Along with partial means and variances, we show how interval covariances may be propagated and tracked through expressions.},
  archive      = {J_IJAR},
  author       = {Ander Gray and Scott Ferson and Vladik Kreinovich and Edoardo Patelli},
  doi          = {10.1016/j.ijar.2022.04.001},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {133-156},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Distribution-free risk analysis},
  volume       = {146},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A heuristic concept construction approach to collaborative
recommendation. <em>IJAR</em>, <em>146</em>, 119–132. (<a
href="https://doi.org/10.1016/j.ijar.2022.04.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Formal concept analysis was first used in collaborative filtering for over one decade. Popular approaches are based on superconcept-subconcept relationship or boolean matrix factorization . In this paper, we design a heuristic approach to construct a set of approximately strong concepts for recommendation. Here strong refers to not only big intent to ensure the similarity among users, but also big extent to ensure the stability of user groups. First, we use the intent threshold as the constraint and the area as the optimization objective to obtain approximately strong concepts. Second, we generate pre-recommendations based on the local popularity of the items implied by each concept. Finally, we determine the actual recommendation according to the number of times the item is pre-recommended to the user. Experiments have been undertaken on five popular datasets with different versions. Results show that our algorithm has lower runtime and/or higher recommendation quality compared with approaches based on concept lattice , matrix factorization, k -nearest neighbors, item-based collaborative filtering and boolean matrix factorization.},
  archive      = {J_IJAR},
  author       = {Zhong-Hui Liu and Qi Zhao and Lu Zou and Wei-Hua Xu and Fan Min},
  doi          = {10.1016/j.ijar.2022.04.004},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {119-132},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A heuristic concept construction approach to collaborative recommendation},
  volume       = {146},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The modularity equation for semi-t-operators and t-uninorms.
<em>IJAR</em>, <em>146</em>, 106–118. (<a
href="https://doi.org/10.1016/j.ijar.2022.04.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the modularity equation including semi-t-operators and T-uninorms. We discuss the modularity equation in two cases, which are semi-t-operators over T-uninorms, and T-uninorms over semi-t-operators, respectively. For the case of semi-t-operators over T-uninorms, all solutions to the equation are given. Moreover, by considering the underlying uninorm of the T-uninorm is locally internal on the boundary, necessary and sufficient conditions of the case for T-uninorms over semi-t-operators are established.},
  archive      = {J_IJAR},
  author       = {Yuan-Yuan Zhao and Hua-Wen Liu},
  doi          = {10.1016/j.ijar.2022.04.005},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {106-118},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {The modularity equation for semi-t-operators and T-uninorms},
  volume       = {146},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Argument strength in probabilistic argumentation based on
defeasible rules. <em>IJAR</em>, <em>146</em>, 79–105. (<a
href="https://doi.org/10.1016/j.ijar.2022.04.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is common for people to remark that a particular argument is a strong (or weak) argument. Having a handle on the relative strengths of arguments can help in deciding on which arguments to consider, which arguments to regard as acceptable, and on which arguments to present to others in a discussion. In computational models of argument, there is a need for a deeper understanding of argument strength. It is a multidimensional problem, and in this paper, we focus on one aspect of argument strength for deductive argumentation based on a defeasible logic. We assume a probability distribution over models of the language and consider how there are various ways to calculate argument strength based on the probabilistic necessity and sufficiency of the premises for the claim, the probabilistic sufficiency of competing premises the claim, and the probabilistic necessity of the premises for competing claims. We provide axioms for characterizing probability-based measures of argument strength, and we investigate four specific probability-based measures.},
  archive      = {J_IJAR},
  author       = {Anthony Hunter},
  doi          = {10.1016/j.ijar.2022.04.003},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {79-105},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Argument strength in probabilistic argumentation based on defeasible rules},
  volume       = {146},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Choquet-based fuzzy rough sets. <em>IJAR</em>, <em>146</em>,
62–78. (<a href="https://doi.org/10.1016/j.ijar.2022.04.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy rough set theory can be used as a tool for dealing with inconsistent data when there is a gradual notion of indiscernibility between objects. It does this by providing lower and upper approximations of concepts. In classical fuzzy rough sets , the lower and upper approximations are determined using the minimum and maximum operators, respectively. This is undesirable for machine learning applications, since it makes these approximations sensitive to outlying samples. To mitigate this problem, ordered weighted average (OWA) based fuzzy rough sets were introduced. In this paper, we show how the OWA-based approach can be interpreted intuitively in terms of vague quantification, and then generalize it to Choquet-based fuzzy rough sets (CFRS). This generalization maintains desirable theoretical properties, such as duality and monotonicity. Furthermore, it provides more flexibility for machine learning applications. In particular, we show that it enables the seamless integration of outlier detection algorithms, to enhance the robustness of machine learning algorithms based on fuzzy rough sets.},
  archive      = {J_IJAR},
  author       = {Adnan Theerens and Oliver Urs Lenz and Chris Cornelis},
  doi          = {10.1016/j.ijar.2022.04.006},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {62-78},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Choquet-based fuzzy rough sets},
  volume       = {146},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sequential multi-class three-way decisions based on
cost-sensitive learning. <em>IJAR</em>, <em>146</em>, 47–61. (<a
href="https://doi.org/10.1016/j.ijar.2022.03.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The theory of sequential three-way decisions which is in accordance with human cognition is a multi-stage decision-making progress. In fact, sequential strategy can deal with multi-class decision effectively. However, few researchers have focused on the attribute significance under multi-class decision from the perspective of cost-sensitive learning in the theory of sequential three-way decisions. By considering reconstructing the granular structure of sequential process, a new sequential multi-class three-way decision model is proposed. First, two types of decision cost in the proposed model are defined. Next, the attribute significance based on decision cost for specific class is devised. Then, through the TOPSIS method, a progress for calculating attribute sequence is proposed. Finally, the experimental results show that the performance of the proposed model has lower decision cost compared with the sequential multi-class three-way decisions.},
  archive      = {J_IJAR},
  author       = {Wenbin Chen and Qinghua Zhang and Yongyang Dai},
  doi          = {10.1016/j.ijar.2022.03.009},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {47-61},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Sequential multi-class three-way decisions based on cost-sensitive learning},
  volume       = {146},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An error correction prediction model based on three-way
decision and ensemble learning. <em>IJAR</em>, <em>146</em>, 21–46. (<a
href="https://doi.org/10.1016/j.ijar.2022.04.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a hot topic in machine learning , prediction has attracted a lot of attention nowadays. Scientific prediction can provide a guide for reducing decision-making losses and making reasonable decisions. However, most of existing prediction models still suffer from limited performance, which cannot reasonably handle complex prediction problems. In addition, there are certain limitations in the scope of different prediction models. In light of the above limitations, the paper proposes a novel error correction prediction model based on the idea of three-way decision (TWD), which is titled an ECP-TWD model. First, the back propagation algorithm optimized neural network (BPNN) model is used to achieve the pre-prediction and obtain initial prediction error series. Second, we further combine the strengths of TWD with ensemble learning , tri-divide all alternatives according to the magnitude of the prediction error of the BPNN model, and apply different strategies to re-predict the prediction error sequence in each region, so as to achieve the correction of predicted values of the BPNN model. Finally, the validity, stability and superiority of the presented model are verified based on the case analysis and experimental analysis. The results show that the ECP-TWD model has the better prediction performance compared to other state-of-the-art prediction models.},
  archive      = {J_IJAR},
  author       = {Xianfeng Huang and Jianming Zhan and Weiping Ding and Witold Pedrycz},
  doi          = {10.1016/j.ijar.2022.04.002},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {21-46},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {An error correction prediction model based on three-way decision and ensemble learning},
  volume       = {146},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ergodic theorems for capacity preserving z+d-actions.
<em>IJAR</em>, <em>146</em>, 1–20. (<a
href="https://doi.org/10.1016/j.ijar.2022.03.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate capacity preserving Z + d Z+d -actions and their ergodicity . We give the concepts of weak ergodicity and strong ergodicity for capacity preserving Z + d Z+d -actions. In particular, we establish a weak ergodic theorem and a strong ergodic theorem for capacity preserving Z + d Z+d -actions.},
  archive      = {J_IJAR},
  author       = {Haiyan Wu and Zhiming Li},
  doi          = {10.1016/j.ijar.2022.03.010},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {1-20},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Ergodic theorems for capacity preserving z+d-actions},
  volume       = {146},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Graded cubes of opposition in fuzzy formal concept analysis.
<em>IJAR</em>, <em>145</em>, 187–209. (<a
href="https://doi.org/10.1016/j.ijar.2022.03.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We recently introduced special fuzzy quantifiers named quantifier-based operators to form extended fuzzy concept lattices and to construct graded squares, hexagons, octagons and decagons of oppositions. This article aims to extend our previous works by organizing quantifier-based operators in more general structures of oppositions: the so-called graded cubes of opposition and 5-graded cubes of opposition .},
  archive      = {J_IJAR},
  author       = {Stefania Boffa and Petra Murinová and Vilém Novák and Petr Ferbas},
  doi          = {10.1016/j.ijar.2022.03.006},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {187-209},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Graded cubes of opposition in fuzzy formal concept analysis},
  volume       = {145},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Monte carlo and quasi-monte carlo methods for dempster’s
rule of combination. <em>IJAR</em>, <em>145</em>, 163–186. (<a
href="https://doi.org/10.1016/j.ijar.2022.03.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the challenges in Dempster-Shafer theory is that the data fusion calculation resulting from the popular Dempster&#39;s rule of combination is #P-complete. This imposes a computational constraint on the number of belief functions and the number of focal sets that can be combined using Dempster&#39;s rule. In this paper we develop Monte Carlo algorithms to approximate Dempster&#39;s rule of combination. The algorithms incorporate importance sampling and low-discrepancy sequences. Numerical results suggest the algorithms make it possible to apply Dempster&#39;s rule to a much larger number of belief functions and focal sets, and consequently widen the scope of applications of Dempster-Shafer theory.},
  archive      = {J_IJAR},
  author       = {Nima Salehy and Giray Ökten},
  doi          = {10.1016/j.ijar.2022.03.008},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {163-186},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Monte carlo and quasi-monte carlo methods for dempster&#39;s rule of combination},
  volume       = {145},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Finite uniform approximation of two-person games defined on
a product of staircase-function infinite spaces. <em>IJAR</em>,
<em>145</em>, 139–162. (<a
href="https://doi.org/10.1016/j.ijar.2022.03.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A method of finite uniform approximation of two-person games in staircase-function infinite spaces is presented. A pure strategy of the player is a staircase function defined on a time interval. The method consists in uniformly sampling the player&#39;s pure strategy value set and finding equilibria in “smaller” bimatrix games, each defined on a subinterval where the pure strategy value is constant. Then the equilibria are successively stacked so that the stack is an approximate solution to the initial staircase game. The (weak) consistency, equivalent to the approximate solution acceptability, is studied by how much the players&#39; payoff and equilibrium strategy change as the sampling density minimally increases. The consistency is decomposed into the payoff, equilibrium strategy support cardinality, equilibrium strategy sampling density, and support probability consistency. The most important parts are the payoff consistency and equilibrium strategy support cardinality (weak) consistency. However, it is practically reasonable to consider a relaxed payoff consistency, by which the player&#39;s payoff change in an appropriate approximation may grow at most by ε as the sampling density minimally increases. The weak consistency itself is a relaxation to the consistency, where the minimal decrement of the sampling density is ignored. An example is presented to show how the approximation is fulfilled for a case of when “smaller” bimatrix games have multiple equilibria.},
  archive      = {J_IJAR},
  author       = {Vadim V. Romanuke},
  doi          = {10.1016/j.ijar.2022.03.005},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {139-162},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Finite uniform approximation of two-person games defined on a product of staircase-function infinite spaces},
  volume       = {145},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Macsum: A new interval-valued linear operator.
<em>IJAR</em>, <em>145</em>, 121–138. (<a
href="https://doi.org/10.1016/j.ijar.2022.03.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many applications in fields as diverse as chemistry, mechanics, medicine, economics, robotics, environment, ecology, meteorology, etc. are based on the notion of system modeling. A system is a real process associating in a deterministic way an output value to one or more input values. A model is a mathematical object that allows the analysis of real phenomena and the prediction of results at a given level of approximation . One of the difficulties of modeling is the choice of the model and how to measure, predict or control the level of approximation. The linear model, where the output is obtained by a weighted sum of the inputs, is a simple model, based on a reduced number of parameters, but describing the functioning of a system in a very approximate way, without the level of approximation being known. Non-linear models are much more specific but much more difficult to use, the level of approximation being even more difficult to measure. What we propose in this article is an imprecise linear model, so the simplicity of representation and use is quite comparable to that of a linear model. This model is imprecise in the sense that the output is imprecise, although the inputs are precise, thus potentially reflecting the inadequacy of a linear model to represent the behavior of the system: the more imprecise the output, the less likely a single linear model is to correctly describe the system. This imprecise linear model can be seen as a convex set of conventional linear models, the imprecise output of this model being the convex set of outputs that would have been obtained by each linear model individually. This modeling is based on non-monotonic real-valued concave set measures.},
  archive      = {J_IJAR},
  author       = {Olivier Strauss and Agnès Rico and Yassine Hmidy},
  doi          = {10.1016/j.ijar.2022.03.003},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {121-138},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Macsum: A new interval-valued linear operator},
  volume       = {145},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Processing distortion models: A comparative study.
<em>IJAR</em>, <em>145</em>, 91–120. (<a
href="https://doi.org/10.1016/j.ijar.2022.03.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When dealing with sets of probabilities , distortion or neighbourhood models are convenient practical tools, as they rely on very little parameters. In this paper, we study their behaviour when such models are combined and processed through some reasoning tools. More specifically, we study their behaviour when merging different distortion models quantifying uncertainty on the same quantity, and when manipulating distortion models defined over multiple variables.},
  archive      = {J_IJAR},
  author       = {Sébastien Destercke and Ignacio Montes and Enrique Miranda},
  doi          = {10.1016/j.ijar.2022.03.007},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {91-120},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Processing distortion models: A comparative study},
  volume       = {145},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Introducing the closure structure and the GDPM algorithm for
mining and understanding a tabular dataset. <em>IJAR</em>, <em>145</em>,
75–90. (<a href="https://doi.org/10.1016/j.ijar.2021.12.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pattern mining is one of the most studied fields in data mining . Being mostly motivated by practitioners, pattern mining algorithms are often based on heuristics and are lacking suitable formalization . In this paper, we are revisiting pattern mining, and especially itemset mining, which allows one to analyze binary datasets in searching for interesting and meaningful itemsets and respective association rules . We introduce a concise representation –the closure structure– based on closed itemsets and their minimum generators (called “passkeys”) for capturing the intrinsic content of a dataset. The closure structure allows one to understand the content of the dataset in terms of closed sets and equivalence classes of itemsets. We discuss theoretical properties of passkeys which are concise representatives of closed itemsets. We propose a formalization of the closure structure and passkeys in terms of Formal Concept Analysis, which is well adapted to studying such elements. Besides theoretical results, we present the GDPM algorithm for enumerating passkeys and discovering the closure structure. GDPM is rather unique as it returns a characterization of a dataset content in terms of complexity levels, highlighting the diversity and the distribution of the itemsets. Finally, some experiments show how the GDPM algorithm and the closure structure can be practically used.},
  archive      = {J_IJAR},
  author       = {Tatiana Makhalova and Aleksey Buzmakov and Sergei O. Kuznetsov and Amedeo Napoli},
  doi          = {10.1016/j.ijar.2021.12.012},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {75-90},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Introducing the closure structure and the GDPM algorithm for mining and understanding a tabular dataset},
  volume       = {145},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Three-way conflict analysis based on incomplete situation
tables: A tentative study. <em>IJAR</em>, <em>145</em>, 51–74. (<a
href="https://doi.org/10.1016/j.ijar.2022.03.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing three-way conflict analysis models focus on complete situation tables and rarely involve incomplete situation tables. In this paper, we give a preliminary approach to three-way conflict analysis models based on incomplete situation tables. Firstly, we construct three-way conflict analysis models based on an incomplete three-valued situation table (ITVST). We use two different methods to establish the models. One is to establish straightly the model based on the original ITVST. The other is to convert the ITVST into a complete three-valued situation table (TVST) by supplementing the missing values with the maximum probability value method, which is called a complete TVST induced by the maximum probability value method. Then we construct the three-way conflict analysis model based on the induced complete TVST. Secondly, to deal with more uncertainty and complexity in the actual decision-making process, we generalize an ITVST to an incomplete many-valued situation table (IMVST) and establish the corresponding three-way conflict analysis models. Finally, we further extend an IMVST to an incomplete interval-valued situation table (IIVST) and construct three-way conflict analysis models based on an IIVST. We use examples to demonstrate the process of constructing conflict, neutrality, and alliance relations of agents on incomplete situation tables. Some algorithms and basic properties are also addressed.},
  archive      = {J_IJAR},
  author       = {Lang-wangqing Suo and Hai-Long Yang},
  doi          = {10.1016/j.ijar.2022.03.004},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {51-74},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Three-way conflict analysis based on incomplete situation tables: A tentative study},
  volume       = {145},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). De finetti’s coherence and exchangeability in infinitary
logic. <em>IJAR</em>, <em>145</em>, 36–50. (<a
href="https://doi.org/10.1016/j.ijar.2022.03.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We continue the investigation towards a logic-based approach to statistics within the infinitary conservative extension of Łukasiewicz logic IRL IRL and prove versions of de Finetti&#39;s theorems on coherence and exchangeability . In particular we will prove a coherence criterion for a subclass of the variety of σ -complete Riesz MV-algebras in the conditional and unconditional case, and discuss de Finetti&#39;s exchangeability in a special case.},
  archive      = {J_IJAR},
  author       = {Serafina Lapenta},
  doi          = {10.1016/j.ijar.2022.03.001},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {36-50},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {De finetti&#39;s coherence and exchangeability in infinitary logic},
  volume       = {145},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multigranulation fuzzy probabilistic rough set model on two
universes. <em>IJAR</em>, <em>145</em>, 18–35. (<a
href="https://doi.org/10.1016/j.ijar.2022.03.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy probabilistic rough set is an important mathematical model in rough set theory and has been widely used in applications. Although many studies have been taken on this topic, the existing fuzzy probabilistic rough set models are insufficient for dealing with data noise and data discretization . This motivates us to develop a better method to handle complex data. In this paper, we propose a novel fuzzy probabilistic rough set model on two universes by using λ -fuzzy sets. To further extend application field, we define upper and lower approximation operators of fuzzy probabilistic rough set in a multigranulation context and propose a novel multigranulation fuzzy probabilistic rough set model on two universes. Moreover, some interesting properties of the models are studied. The effectiveness and superiority of them are illustrated by numerical examples and experiments compared with existing models. Experimental results show that the proposed models have better performance in classification and have potential applications in decision making problems.},
  archive      = {J_IJAR},
  author       = {Dan Yang and Mingjie Cai and Qingguo Li and Feng Xu},
  doi          = {10.1016/j.ijar.2022.03.002},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {18-35},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Multigranulation fuzzy probabilistic rough set model on two universes},
  volume       = {145},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-label learning via minimax probability machine.
<em>IJAR</em>, <em>145</em>, 1–17. (<a
href="https://doi.org/10.1016/j.ijar.2022.02.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose Minimax Probability Machine for Multi-label data classification and is termed as Multi-Label Minimax Probability Machine (MLMPM). Based on data mean and covariance information, MLMPM builds a classifier that minimizes an upper bound on the mis-classification probability of unseen future data. For capturing label correlation we have considered asymmetric co-occurrency matrix into the model. The proposed model has also been extended to non-linear settings using the Mercer Kernel trick. To accelerate the training procedure, iterative weighted least squares is used to train the underlying optimization model efficiently. Extensive experimental comparisons of our proposed method with related multi-label algorithms on synthetic as well as real world multi-label datasets, along with Amazon rainforest satellite images dataset, prove its efficacy.},
  archive      = {J_IJAR},
  author       = {Reshma Rastogi (nee Khemchandani) and Sambhav Jain},
  doi          = {10.1016/j.ijar.2022.02.002},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {1-17},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Multi-label learning via minimax probability machine},
  volume       = {145},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exposing some points of interest about non-exposed points of
desirability. <em>IJAR</em>, <em>144</em>, 129–159. (<a
href="https://doi.org/10.1016/j.ijar.2022.02.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the representation of sets of desirable gambles by sets of probability mass functions . Sets of desirable gambles are a very general uncertainty model, that may be non-Archimedean, and therefore not representable by a set of probability mass functions. Recently, Cozman (2018) has shown that imposing the additional requirement of even convexity on sets of desirable gambles guarantees that they are representable by a set of probability mass functions. Already more that 20 years earlier, Seidenfeld et al. (1995) gave an axiomatisation of binary preferences—on horse lotteries, rather than on gambles—that also leads to a unique representation in terms of sets of probability mass functions. To reach this goal, they use two devices, which we will call ‘SSK–Archimedeanity’ and ‘SSK–extension’. In this paper, we will make the arguments of Seidenfeld et al. (1995) explicit in the language of gambles, and show how their ideas imply even convexity and allow for conservative reasoning with evenly convex sets of desirable gambles, by deriving an equivalence between the SSK–Archimedean natural extension, the SSK–extension, and the evenly convex natural extension.},
  archive      = {J_IJAR},
  author       = {Arthur Van Camp and Teddy Seidenfeld},
  doi          = {10.1016/j.ijar.2022.02.003},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {129-159},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Exposing some points of interest about non-exposed points of desirability},
  volume       = {144},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Symbols-meaning-value (SMV) space as a basis for a
conceptual model of data science. <em>IJAR</em>, <em>144</em>, 113–128.
(<a href="https://doi.org/10.1016/j.ijar.2022.02.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By applying the principles of three-way decision as thinking in threes, in this paper I introduce a conceptual model of data science in three steps. First, I examine examples of triadic thinking in general and trilevel thinking in specific in data science. Then, based on Weaver&#39;s trilevel categorization of communications problems, I propose the concept of the symbols-meaning-value (SMV) space and discuss three perspectives on the SMV space from the viewpoints of information science and management science, cognitive science, and computer science. I label the operations on the SMV three levels metaphorically as seeing, knowing, and doing. Finally, I put forward a SMV-space-based conceptual model of data science, in which data are a resource, the power of data is the knowledge embedded in data, and the value of data is the wise decision and the best course of action supported by data. The goals and functions of data science at the SMV three levels are, respectively, making data available, making data meaningful, and making data valuable. To demonstrate the potential contributions of the conceptual model, I comment on some of its practical values and implications.},
  archive      = {J_IJAR},
  author       = {Yiyu Yao},
  doi          = {10.1016/j.ijar.2022.02.001},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {113-128},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Symbols-meaning-value (SMV) space as a basis for a conceptual model of data science},
  volume       = {144},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel granular computing model based on three-way
decision. <em>IJAR</em>, <em>144</em>, 92–112. (<a
href="https://doi.org/10.1016/j.ijar.2022.01.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Granular computing and three-way decision are two very important methods in the field of knowledge discovery and data mining . In this paper, based on the idea of three-way decision, all attributes in the information table first are divided into three disjoint parts named indispensable attributes, rejected attributes and neutral attributes, respectively. According to the three parts of attributes, many basic and important information granules and granular structures can be induced from the information table. Then a novel granular computing model is proposed by the description operator. On the one hand, many mathematical properties related to the model proposed in this paper are systematically discussed. On the other hand, we make a preliminary and meaningful attempt to deal with network security by using this model. In addition, in order to apply the model more conveniently, two algorithms for computing description set, description degree, attribute reduction and reduction degree are developed. Finally, through numerical experiments, the validity of the algorithms and the related factors that affect the effectiveness of the algorithms are discussed in detail.},
  archive      = {J_IJAR},
  author       = {Qingzhao Kong and Xiawei Zhang and Weihua Xu and Binghan Long},
  doi          = {10.1016/j.ijar.2022.01.015},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {92-112},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A novel granular computing model based on three-way decision},
  volume       = {144},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Information efficient learning of complexly structured
preferences: Elicitation procedures and their application to decision
making under uncertainty. <em>IJAR</em>, <em>144</em>, 69–91. (<a
href="https://doi.org/10.1016/j.ijar.2022.01.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose efficient methods for elicitation of complexly structured preferences and utilize these in problems of decision making under (severe) uncertainty. Based on the general framework introduced in Jansen et al. (2018) [37] , we now design elicitation procedures and algorithms that enable decision makers to reveal their underlying preference system (i.e. two relations, one encoding the ordinal, the other the cardinal part of the preferences) while having to answer as few as possible simple ranking questions. Here, two different approaches are followed. The first approach directly utilizes the collected ranking data for obtaining the ordinal part of the preferences, while their cardinal part is constructed implicitly by measuring the decision maker&#39;s consideration times. In contrast, the second approach explicitly elicits also the cardinal part of the decision maker&#39;s preference system, however, only an approximate version of it. This approximation is obtained by additionally collecting labels of preference strength during the elicitation procedure. For both approaches, we give conditions under which they produce the decision maker&#39;s true preference system and investigate how their efficiency can be improved. For the latter purpose, besides data-free approaches, we also discuss ways for statistically guiding the elicitation procedure if data from elicitations of previous decision makers is available. Finally, we demonstrate how the proposed elicitation methods can be utilized in problems of decision under (severe) uncertainty. Precisely, we show that under certain conditions optimal decisions can be found without fully specifying the preference system.},
  archive      = {J_IJAR},
  author       = {C. Jansen and H. Blocher and T. Augustin and G. Schollmeyer},
  doi          = {10.1016/j.ijar.2022.01.016},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {69-91},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Information efficient learning of complexly structured preferences: Elicitation procedures and their application to decision making under uncertainty},
  volume       = {144},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A generalized model of three-way decision with ranking and
reference tuple. <em>IJAR</em>, <em>144</em>, 51–68. (<a
href="https://doi.org/10.1016/j.ijar.2022.01.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The theory of three-way decision was originally introduced as three regions to explain rough sets. Nowadays we can apply this theory to many important fields by defining reasonable trisecting rules. In this paper, we reconsider the two-universe model of three-way decision proposed by Xu et al. and extend it to a more general level. Specifically, we introduce a pair of thresholds to the model and propose a generalized model of three-way decision with ranking and reference tuple. We prove that, although the pairs of thresholds are infinite, we only need to consider a finite number of pairs of thresholds and their corresponding trisections. Based on this theoretical foundation, we further define a unique measure to assess the trisections, compare trisections through this measure, and propose an algorithm to compute the optimal trisection in finite steps. By comparison with other models and an example of application, we demonstrate that the generalized model is more expressive and more practical than the previous one, and has some advantages over the compared models in accuracy of trisecting and validity of explaining.},
  archive      = {J_IJAR},
  author       = {Wenyan Xu and Bing Jia and Xiaonan Li},
  doi          = {10.1016/j.ijar.2022.01.014},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {51-68},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A generalized model of three-way decision with ranking and reference tuple},
  volume       = {144},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On (o,g)-fuzzy rough sets based on overlap and grouping
functions over complete lattices. <em>IJAR</em>, <em>144</em>, 18–50.
(<a href="https://doi.org/10.1016/j.ijar.2022.01.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In rough set theory , upper and lower approximation operators are two crucial concepts. The study of these two approximation operators in the framework of lattice theory is an important generalization from the mathematical point of view. On the other hand, overlap and grouping functions, as two types of not necessarily associative binary aggregation functions different from the common binary aggregation functions triangular norms and triangular conorms , have not only rich theoretical results but also a wide range of practical applications. Therefore, based on overlap and grouping functions over complete lattices , this paper is devoted to proposing ( O , G ) (O,G) -fuzzy rough sets as a further generalization of the notion of rough sets. Firstly, we define a pair of O -upper and G -lower L -fuzzy rough approximation operators and investigate basic properties of them. Then, the characterizations of ( O , G ) (O,G) -fuzzy rough approximation operators are discussed by using different kinds of L -fuzzy relations. Meanwhile, we investigate the topological properties of ( O , G ) (O,G) -fuzzy rough sets. Furthermore, we show a brief comparison of the ( O , G ) (O,G) -fuzzy rough sets with other common rough set models. At the end of this paper, we further propose multigranulation ( O , G ) (O,G) -fuzzy rough sets over complete lattices from the viewpoint of multigranulation structure.},
  archive      = {J_IJAR},
  author       = {Haibo Jiang and Bao Qing Hu},
  doi          = {10.1016/j.ijar.2022.01.012},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {18-50},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {On (O,G)-fuzzy rough sets based on overlap and grouping functions over complete lattices},
  volume       = {144},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel method to attribute reduction based on weighted
neighborhood probabilistic rough sets. <em>IJAR</em>, <em>144</em>,
1–17. (<a href="https://doi.org/10.1016/j.ijar.2022.01.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute reduction is an important application of rough set theory . Most existing rough set models do not consider the weight information of attributes in information systems. In this paper, we first study the weight of each attribute in information systems by using data binning method and information entropy theory. Then, we propose a new rough set model of weighted neighborhood probabilistic rough sets (WNPRSs) and investigate its basic properties. Meanwhile, the dependency degree formula of an attribute relative to an attribute subset is defined based on WNPRSs. Subsequently, we design a novel attribute reduction method by using WNPRSs and the corresponding algorithm is also given. Finally, to evaluate the performance of the proposed algorithm, we conduct a data experiment and compare it with other existing attribute reduction algorithms on eight public datasets. Experimental result demonstrates that the proposed attribute reduction algorithm is effective and performs better than some of the existing algorithms.},
  archive      = {J_IJAR},
  author       = {Jingjing Xie and Bao Qing Hu and Haibo Jiang},
  doi          = {10.1016/j.ijar.2022.01.010},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {1-17},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A novel method to attribute reduction based on weighted neighborhood probabilistic rough sets},
  volume       = {144},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intuitionistic fuzzy (⊗,n)-general regular languages and
their minimization implementation. <em>IJAR</em>, <em>143</em>, 216–231.
(<a href="https://doi.org/10.1016/j.ijar.2022.01.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We firstly give the notion of intuitionistic fuzzy ( ⊗ , N ) (⊗,N) -general regular languages (IF ( ⊗ , N ) (⊗,N) -GRLs) under a t -norm ⊗ and a fuzzy negation N and study their properties. The similarities and differences between IF ( ⊗ , N ) (⊗,N) -GRLs and intuitionistic fuzzy regular languages (IFRLs) are investigated for explaining the existence of intuitionistic fuzzy automata (IFAs) ( ⊗ , N ) (⊗,N) -recognizing IF ( ⊗ , N ) (⊗,N) -GRLs. Next, we discuss whether or not the set of IF ( ⊗ , N ) (⊗,N) -GRLs is closed under the generalized operations shown here. Concretely, the set of IF ( ⊗ , N ) (⊗,N) -GRLs is closed under the generalized intersection, but not closed under the generalized complement, and the necessary and sufficient condition of closure of that set under the generalized union, the generalized concatenation and the generalized Kleene closure is thought as well. We also deliberate on the Pumping lemma and the Myhill-Nerode theorem in the framework of IF ( ⊗ , N ) (⊗,N) -GRLs. Finally, we study the minimization implementation of IF ( ⊗ , N ) (⊗,N) -GRLs, that is, for an IF ( ⊗ , N ) (⊗,N) -GRL f , if it is ( ⊗ , N ) (⊗,N) -recognized by a given accessible deterministic intuitionistic fuzzy automaton (DIFA) A A , then a polynomial-time algorithm is presented to realize the construction of a minimal DIFA ( ⊗ , N ) (⊗,N) -recognizing f by using A A .},
  archive      = {J_IJAR},
  author       = {Chao Yang},
  doi          = {10.1016/j.ijar.2022.01.013},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {216-231},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Intuitionistic fuzzy (⊗,N)-general regular languages and their minimization implementation},
  volume       = {143},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Belief functions and rough sets: Survey and new insights.
<em>IJAR</em>, <em>143</em>, 192–215. (<a
href="https://doi.org/10.1016/j.ijar.2022.01.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rough set theory and belief function theory, two popular mathematical frameworks for uncertainty representation, have been widely applied in different settings and contexts. Despite different origins and mathematical foundations, the fundamental concepts of the two formalisms (i.e., approximations in rough set theory, belief and plausibility functions in belief function theory) are closely related. In this survey article, we review the most relevant contributions studying the links between these two uncertainty representation formalisms. In particular, we discuss the theoretical relationships connecting the two approaches, as well as their applications in knowledge representation and machine learning . Special attention is paid to the combined use of these formalisms as a way of dealing with imprecise and uncertain information. The aim of this work is, thus, to provide a focused picture of these two important fields, discuss some known results and point to relevant future research directions.},
  archive      = {J_IJAR},
  author       = {Andrea Campagner and Davide Ciucci and Thierry Denœux},
  doi          = {10.1016/j.ijar.2022.01.011},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {192-215},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Belief functions and rough sets: Survey and new insights},
  volume       = {143},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Degenerate gaussian factors for probabilistic inference.
<em>IJAR</em>, <em>143</em>, 159–191. (<a
href="https://doi.org/10.1016/j.ijar.2022.01.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a parametrised factor that enables inference on Gaussian networks where linear dependencies exist among the random variables . Our factor representation is effectively a generalisation of traditional Gaussian parametrisations where the positive-definite constraint of the covariance matrix has been relaxed. For this purpose, we derive various statistical operations and results (such as marginalisation , multiplication and affine transformations of random variables) that extend the capabilities of Gaussian factors to these degenerate settings. By using this principled factor definition, degeneracies can be accommodated accurately and automatically at little additional computational cost. As illustration, we apply our methodology to a representative example involving recursive state estimation of cooperative mobile robots.},
  archive      = {J_IJAR},
  author       = {J.C. Schoeman and Corné E. van Daalen and Johan A. du Preez},
  doi          = {10.1016/j.ijar.2022.01.008},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {159-191},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Degenerate gaussian factors for probabilistic inference},
  volume       = {143},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Solving possibilistic games with incomplete information.
<em>IJAR</em>, <em>143</em>, 139–158. (<a
href="https://doi.org/10.1016/j.ijar.2022.01.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian games offer a suitable framework for games where the utility degrees are additive in essence. This approach does nevertheless not apply to ordinal games, where the utility degrees do not capture more than a ranking, nor to situations of decision under qualitative uncertainty. The present paper proposes a representation framework for ordinal games under possibilistic incomplete information and extends the fundamental notions of pure and mixed Nash equilibrium to this framework. We show that deciding whether a pure Nash equilibrium exists is a difficult task (NP-hard) and propose a Mixed Integer Linear Programming (MILP) encoding of the problem; as to the problem of computing a possibilistic mixed equilibrium, we show that it can be solved in polynomial time . An experimental study based on the GAMUT game generator confirms the feasibility of the approach.},
  archive      = {J_IJAR},
  author       = {Nahla Ben Amor and Hélène Fargier and Régis Sabbadin and Meriem Trabelsi},
  doi          = {10.1016/j.ijar.2022.01.009},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {139-158},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Solving possibilistic games with incomplete information},
  volume       = {143},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The generalized sigmoid function and its connection with
logical operators. <em>IJAR</em>, <em>143</em>, 121–138. (<a
href="https://doi.org/10.1016/j.ijar.2022.01.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we present the operator-dependent sigmoid function , which is derived from a universal unary operator called the kappa function. Here, we describe how the generalized sigmoid function is related to representable uninorms (i.e., Dombi&#39;s aggregative operator). Namely, we show that the inverse of a generalized sigmoid function is an additive generator of the aggregative operator. We provide the necessary and sufficient conditions for the form of the function that transforms the aggregative operator into a conjunctive or disjunctive logical operator. This transformation is also based on the generalized sigmoid function. Here, we show how conjunctive and disjunctive operators, which form a De Morgan system with a negation, can be derived from the aggregative operator. We point out that, under certain conditions, a set of generalized sigmoid functions is closed under the negation and modifier operators. Lastly, we demonstrate an important connection between the weighted aggregative operator and the generalized sigmoid function. Based on this connection, we provide a new interpretation of the feed-forward neural networks . We show that a perceptron-based neural network can be modeled using the aggregative operator and the generalized sigmoid function.},
  archive      = {J_IJAR},
  author       = {József Dombi and Tamás Jónás},
  doi          = {10.1016/j.ijar.2022.01.006},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {121-138},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {The generalized sigmoid function and its connection with logical operators},
  volume       = {143},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiple attribute group decision making based on
multigranulation probabilistic models, MULTIMOORA and TPOP in incomplete
q-rung orthopair fuzzy information systems. <em>IJAR</em>, <em>143</em>,
102–120. (<a href="https://doi.org/10.1016/j.ijar.2022.01.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of q-rung orthopair fuzzy sets (q-ROFSs) severs as an extended form of orthopair fuzzy sets, which excels in flexibly depicting imprecise information existed in multiple attribute group decision making (MAGDM) via allowing a greater space in terms of membership degrees (MD) and non-membership degrees (ND). Moreover, incomplete information systems play a significant role in depicting incomplete information existed in MAGDM. In this paper, for the sake of exploring MAGDM with imprecise and incomplete information, a new MAGDM method based on multigranulation probabilistic models, MULTIMOORA (Multi-Objective Optimization by Ratio Analysis plus the full MULTIplicative form) and the technique of precise order preference (TPOP) method in incomplete q-rung orthopair fuzzy (q-ROF) information systems is systematically investigated. First, the concept of multigranulation (MG) incomplete q-ROF information systems is established. Then, a completion technique is put forward to obtain MG q-ROF information systems via patching lost values. Moreover, three versions of MG q-ROF probabilistic rough sets (PRSs) are put forward in light of MG q-ROF information systems. Afterwards, a new MAGDM method is constructed by means of MG q-ROF PRSs, MULTIMOORA and the TPOP method. At last, two experimental studies from open datasets are performed to present the applicability of the constructed MAGDM method, and corresponding sensitivity analysis and comparative analysis are further conducted to demonstrate the validity of the presented methodology.},
  archive      = {J_IJAR},
  author       = {Chao Zhang and Wenhui Bai and Deyu Li and Jianming Zhan},
  doi          = {10.1016/j.ijar.2022.01.002},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {102-120},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Multiple attribute group decision making based on multigranulation probabilistic models, MULTIMOORA and TPOP in incomplete q-rung orthopair fuzzy information systems},
  volume       = {143},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). GLRM: Logical pattern mining in the case of inconsistent
data distribution based on multigranulation strategy. <em>IJAR</em>,
<em>143</em>, 78–101. (<a
href="https://doi.org/10.1016/j.ijar.2022.01.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, many learning-based methods have explored logic learning task in the assumption that the training set and testing set are from the consistent distribution, achieving good performance. But, in most cases, this assumption does not hold. In this paper, we explore this topic on the open-set logic reasoning task where the digit length and the sequence length of the training set and testing set are from inconsistent distributions. To address this issue, inspired by multigranulation studies in granular computing , we propose a granulation logic reasoning machine, namely GLRM. In this method, this open-set task is granulated into a series of sub-tasks from two dimensions : the digit length and the sequence length, and then these sub-tasks are conquered one by one. Finally, the results of the sub-tasks are organized into the final result. The effectiveness of GLRM is demonstrated by experiments on the open-set Fashion-Logic data set and the open-set Fashion-Logic task proposed in this paper. This study provides a novel view for solving open-set logic reasoning tasks and promotes the research of data-driven logic learning.},
  archive      = {J_IJAR},
  author       = {Qian Guo and Yuhua Qian and Xinyan Liang},
  doi          = {10.1016/j.ijar.2022.01.005},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {78-101},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {GLRM: Logical pattern mining in the case of inconsistent data distribution based on multigranulation strategy},
  volume       = {143},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Three-way decision based on confidence level change in rough
set. <em>IJAR</em>, <em>143</em>, 57–77. (<a
href="https://doi.org/10.1016/j.ijar.2022.01.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way decision (3WD) and rough set are two influential theories of study knowledge discovery and uncertain artificial intelligence . A central notion of 3WD is a tri-level thinking paradigm consisting of trisecting, acting, and outcome (i.e., TAO model). As is well known, movement-based on three-way decision (M-3WD) and change-based TAO model, mainly started from the perspective of effectiveness measure , are two outcome evolution studies about the three-way decision, which could lead to some limitations in application. This paper builds a change-based three-way decision (C-3WD) based on confidence level, and an application to rough set is also discussed. Furthermore, the ( α , β ) (α,β) -approximate probability regions of rough set are re-decided by the change model, and a medical decision example is introduced to explain how to make C-3WD in the classification of rough set. By comparing the effectiveness of the traditional three-way decision method with ours, it is again verified from the two aspects of cost and earns and concludes that the model in this paper is more suitable for the decision process that includes trisecting and acting. Some experiments on various datasets to demonstrate the effectiveness of our methods.},
  archive      = {J_IJAR},
  author       = {Doudou Guo and Chunmao Jiang and Peng Wu},
  doi          = {10.1016/j.ijar.2022.01.007},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {57-77},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Three-way decision based on confidence level change in rough set},
  volume       = {143},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distributivity between uni-nullnorms and mayor’s aggregation
operators. <em>IJAR</em>, <em>143</em>, 44–56. (<a
href="https://doi.org/10.1016/j.ijar.2022.01.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The full characterization of different pairs of aggregation operators that fulfill the distributivity law is crucial for many different areas such as the utility theory and the integration theory. The problem of distributivity between uni-nullnorms and Mayor&#39;s aggregation operators is being addressed through this paper. Here presented study is the next step in research of this topic and it upgrades some previously obtained results.},
  archive      = {J_IJAR},
  author       = {Dragan Jočić and Ivana Štajner-Papuga},
  doi          = {10.1016/j.ijar.2022.01.001},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {44-56},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Distributivity between uni-nullnorms and mayor&#39;s aggregation operators},
  volume       = {143},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian nonparametric change point detection for
multivariate time series with missing observations. <em>IJAR</em>,
<em>143</em>, 26–43. (<a
href="https://doi.org/10.1016/j.ijar.2021.12.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A time series is a commonly observed type of data, and it is analyzed in several ways in real applications. Within the possible analysis, change point detection is one of the crucial inferential targets for studying the behavior of a time series. We consider a multiple change point detection model for a multivariate time series . Among the possible approaches to perform multiple change point detection, we propose an extension to the multivariate case of one of the main state-of-the-art approaches, working in a Bayesian nonparametric framework. We combine a combinatorial prior distribution, which relies on a model-based clustering approach to detect the change points, with a multivariate kernel for time-dependent realizations in a general fashion. We further extend the model to the case of missing observations and derive opportune quantities to perform data imputation . Thereafter, we investigate the properties of the multivariate model with an extensive simulation study, and we apply the model to perform change point detection in two real data applications.},
  archive      = {J_IJAR},
  author       = {Riccardo Corradin and Luca Danese and Andrea Ongaro},
  doi          = {10.1016/j.ijar.2021.12.019},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {26-43},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Bayesian nonparametric change point detection for multivariate time series with missing observations},
  volume       = {143},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Knowledge transfer for causal discovery. <em>IJAR</em>,
<em>143</em>, 1–25. (<a
href="https://doi.org/10.1016/j.ijar.2021.12.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subject-specific causal discovery methods could help to make better decisions in domains where there are variations on causal relations across subjects, such as neuroscience and genetics. However, discovering subject-specific causal models from limited data sets could be challenging. Although there are several causal discovery methods, most of them are focused on finding the common causal relations of a population from data sets with enough samples. The issue of discovering subject-specific causal relations from limited data sets has not been sufficiently explored. In this paper, we propose a knowledge transfer method for discovering subject-specific causal models. Our method discovers causal probabilistic graphical models , up to Markov equivalence classes, from discrete and continuous data sets. We hypothesized that transferring weighted instances of additional sources according to their discrepancy with target instances helps to compensate for the lack of target data and improves the performance of a scored-based causal discovery method. Experimental results on synthetic data sets and benchmark causal Bayesian networks show that our proposal, under few target samples, outperforms significantly in adjacency and arrowhead recovery the baseline and alternative methods.},
  archive      = {J_IJAR},
  author       = {Verónica Rodríguez-López and Luis Enrique Sucar},
  doi          = {10.1016/j.ijar.2021.12.010},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {1-25},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Knowledge transfer for causal discovery},
  volume       = {143},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Various fuzzy connections and fuzzy concepts in complete
co-residuated lattices. <em>IJAR</em>, <em>142</em>, 451–468. (<a
href="https://doi.org/10.1016/j.ijar.2021.12.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the notions of various fuzzy connections by using distance functions on complete co-residuated lattices instead of using fuzzy partial orders on complete co-residuated lattices. We show that (1) fuzzy residuated connections induce attribute-oriented fuzzy concept lattices and object-oriented fuzzy concept lattices, (2) fuzzy Galois (resp. dual Galois) connections induce formal (resp. dual formal) fuzzy concept lattices, (3) various fuzzy concept lattices are complete lattices and (4) the relations between various fuzzy concept lattices are isomorphic or anti-isomorphic. It is shown that fuzzy relation equations can be solved using the properties of various fuzzy connections. Moreover, the concepts of closure operators , interior operators and generalized fuzzy rough sets are defined on complete co-residuated lattices.},
  archive      = {J_IJAR},
  author       = {Ju-Mok Oh and Yong Chan Kim},
  doi          = {10.1016/j.ijar.2021.12.018},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {451-468},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Various fuzzy connections and fuzzy concepts in complete co-residuated lattices},
  volume       = {142},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). OWA fuzzy regression. <em>IJAR</em>, <em>142</em>, 430–450.
(<a href="https://doi.org/10.1016/j.ijar.2021.12.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the Ordered Weighted Averaging (OWA) operators will be considered to propose general fuzzy regression modeling technique for crisp/fuzzy-input fuzzy-output data. Here, by considering various kinds of a special form of OWA operators we will be able to},
  archive      = {J_IJAR},
  author       = {Pierpaolo D&#39;Urso and Jalal Chachi},
  doi          = {10.1016/j.ijar.2021.12.009},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {430-450},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {OWA fuzzy regression},
  volume       = {142},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Few-shot learning based on hierarchical classification via
multi-granularity relation networks. <em>IJAR</em>, <em>142</em>,
417–429. (<a href="https://doi.org/10.1016/j.ijar.2021.12.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning is one of the significant areas of machine learning , which aims to recognize novel visual classes from few labeled examples. Many existing models make full use of the similarity of inner-class features and achieve satisfactory results. However, these models assume that classes are independent of each other, ignoring the inter-class relationship. In this paper, we propose a few-shot hierarchical classification model via multi-granularity relation networks (HMRN) considering both the inner-class similarity and inter-class relationship. The multi-granularity relationship among coarse- and fine-grained classes is an important auxiliary information in the class hierarchical structure originated from data. Thus, we first extract hierarchical features of different granularity classes according to the membership relationship among the classes. Second, we build multi-granularity relation networks to obtain the inner-class similarity relation of different granularity classes using the hierarchical features. Finally, we consider the tradeoff among the inner-class similarity relation of different granularity classes for hierarchical few-shot learning, which takes the information of coarse-grained classes to assist the learning of fine-grained classes. Experimental results show that our model outperforms several state-of-the-art flat (without hierarchical structure) models and hierarchical models. For example, the accuracy of HMRN is about 3.00\% better than that of flat models on the tieredImageNet dataset.},
  archive      = {J_IJAR},
  author       = {Yuling Su and Hong Zhao and Yaojin Lin},
  doi          = {10.1016/j.ijar.2021.12.013},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {417-429},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Few-shot learning based on hierarchical classification via multi-granularity relation networks},
  volume       = {142},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Information algebras in the theory of imprecise
probabilities. <em>IJAR</em>, <em>142</em>, 383–416. (<a
href="https://doi.org/10.1016/j.ijar.2021.12.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we create a bridge between desirability and information algebras: we show how coherent sets of gambles, as well as coherent lower previsions, induce such structures. This allows us to enforce the view of such imprecise-probability objects as algebraic and logical structures; moreover, it enforces the interpretation of probability as information, and gives tools to manipulate them as such.},
  archive      = {J_IJAR},
  author       = {Arianna Casanova and Juerg Kohlas and Marco Zaffalon},
  doi          = {10.1016/j.ijar.2021.12.017},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {383-416},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Information algebras in the theory of imprecise probabilities},
  volume       = {142},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A study of algorithms relating distributive lattices, median
graphs, and formal concept analysis. <em>IJAR</em>, <em>142</em>,
370–382. (<a href="https://doi.org/10.1016/j.ijar.2021.12.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study structures such as distributive lattices , distributive semilattices , and median graphs from an algorithmic point of view. Such structures are very useful in classification and phylogeny for representing lineage relationships for example. A distributive lattice can be considered as a median graph while a distributive ∨-semilattice can be considered as a median graph provided that some conditions holding on triple of elements are satisfied. Starting from a lattice structure with different representations, we study the problem of building a median graph from such structures. We make precise and propose algorithms for checking how a lattice can be distributive and can be a median graph. Then, we adapt the problem to semilattices as a lattice where the bottom element is removed is a ∨-semilattice. We also state the problem in terms of Formal Concept Analysis and the representation of a lattice as a formal context, i.e., a binary table. Moreover, we also propose as input a system of implications such as the Duquenne-Guigues basis of a lattice, and we study how to compute such a basis for a distributive semilattice. In the paper, we provide algorithms and examples which illustrate the difficulties related to these different classification tasks . In particular, the minimality of the output lattices is a condition which is hard to ensure and which cannot be always achieved.},
  archive      = {J_IJAR},
  author       = {Alain Gély and Miguel Couceiro and Laurent Miclet and Amedeo Napoli},
  doi          = {10.1016/j.ijar.2021.12.011},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {370-382},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A study of algorithms relating distributive lattices, median graphs, and formal concept analysis},
  volume       = {142},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Typicality: A formal concept analysis account.
<em>IJAR</em>, <em>142</em>, 349–369. (<a
href="https://doi.org/10.1016/j.ijar.2021.12.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We examine typicality—a significant phenomenon accompanying human concepts—within the framework of formal concept analysis. Our aim is to formalize the notion of typicality within this framework and thus provide an operational definition. We review relevant aspects and main psychological explanations of typicality, and propose a formalization based on a view of typicality propounded in the seminal work by Eleanor Rosch et al. We also provide experimental evaluation of our approach and discuss ramifications of our findings and topics to be explored in the future.},
  archive      = {J_IJAR},
  author       = {Radim Belohlavek and Tomas Mikula},
  doi          = {10.1016/j.ijar.2021.12.001},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {349-369},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Typicality: A formal concept analysis account},
  volume       = {142},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Steps towards causal formal concept analysis. <em>IJAR</em>,
<em>142</em>, 338–348. (<a
href="https://doi.org/10.1016/j.ijar.2021.12.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficiently discovering causal relations from data and representing them in a way that facilitates their use is an important problem in science that has received much attention. In this paper, we propose an adaptation of the Formal Concept Analysis formalism to the problem of discovering and representing causal relations. We show that Formal Concept Analysis structures and algorithms are well-suited to this problem.},
  archive      = {J_IJAR},
  author       = {Alexandre Bazin and Miguel Couceiro and Marie-Dominique Devignes and Amedeo Napoli},
  doi          = {10.1016/j.ijar.2021.12.007},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {338-348},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Steps towards causal formal concept analysis},
  volume       = {142},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Three-way approximate reduct based on information-theoretic
measure. <em>IJAR</em>, <em>142</em>, 324–337. (<a
href="https://doi.org/10.1016/j.ijar.2021.12.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way decision is a typical and popular methodology for decision-making and approximate reasoning, while attribute reduction is an important research topic in three-way decision. However, most attribute reduction methods based on three-way decision strictly rely on the preservation of measure criterion, which not only explicitly limits the efficiency of attribute reduction and also implicitly confines the generalization ability of the resulting reduct. In this study, we present a new three-way approximate attribute reduction method based on information-theoretic measure. More specifically, a unified framework for approximate attribute reduction is first provided. Then, the process of attribute reduction is considered to determine each attribute to be the positive region, boundary region, or negative region in terms of its correlation to the decision attribute . The negative attributes can be removed by the preservation of information-theoretic measure, while some boundary attributes are further iteratively eliminated by relaxing the measure criterion. An approximate reduct is finally formed by the positive attributes and the remaining boundary attributes. On several public UCI data sets, the proposed method achieves a much better attribute reduction rate and simultaneously gains an improvement in performance when comparing with other attribute reduction methods.},
  archive      = {J_IJAR},
  author       = {Can Gao and Zhicheng Wang and Jie Zhou},
  doi          = {10.1016/j.ijar.2021.12.008},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {324-337},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Three-way approximate reduct based on information-theoretic measure},
  volume       = {142},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Lattice-valued tree pushdown automata: Pumping lemma and
closure properties. <em>IJAR</em>, <em>142</em>, 301–323. (<a
href="https://doi.org/10.1016/j.ijar.2021.12.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce the concept of lattice-valued tree pushdown automata that extends the concepts of lattice-valued pushdown automata, lattice-valued tree automata and fuzzy tree pushdown automata. Also, we consider fuzzy tree languages recognized by lattice-valued (deterministic) tree pushdown automata (called lattice-valued context-free tree languages). Then, we prove the pumping lemma that can be used in proving that certain sets of tree languages are not recognizable. Also, we study closure properties of lattice-valued context-free tree languages with respect to some operations. We show that lattice-valued context-free tree languages recognized by lattice-valued deterministic tree pushdown automata are closed under union, concatenation, star, linear and alphabetic tree homomorphism and inverse tree homomorphism. By applying the pumping lemma on an example, we show that lattice-valued context-free tree languages are not closed under intersection. However, we prove that the intersection of lattice-valued context-free tree language and lattice-valued regular tree language is recognizable by a lattice-valued tree pushdown automaton. Also, we show that lattice-valued non-deterministic tree pushdown automata are only closed under union. However, if L L satisfies distributivity , then non-deterministic tree pushdown automata are closed under all of these operations.},
  archive      = {J_IJAR},
  author       = {Maryam Ghorani and Sunita Garhwal and Somaye Moghari},
  doi          = {10.1016/j.ijar.2021.12.002},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {301-323},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Lattice-valued tree pushdown automata: Pumping lemma and closure properties},
  volume       = {142},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Conditional distributivity equation of semi-uninorms over
uninorms. <em>IJAR</em>, <em>142</em>, 290–300. (<a
href="https://doi.org/10.1016/j.ijar.2021.12.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conditional distributivity of aggregation operators has always been the focus of research because it is crucial for various areas including integration theory, utility theory and so on. Inspired by this fact, this article is mainly devoted to dealing with the conditional distributivity of semi-uninorms over uninorms from U e min ∪ U e max Uemin∪Uemax , where semi-uninorms come from representable semi-uninorms and continuous semi-uninorms. The obtained results show that there is no representable semi-uninorm, which is conditionally distributive over such a uninorm. However, if the semi-uninorms are continuous, then the necessary and sufficient conditions for the conditional distributivity are given. And then based on the results we further show that distributivity and conditional distributivity are not equivalent in this case.},
  archive      = {J_IJAR},
  author       = {Yun-Mao Zhang and Feng Qin},
  doi          = {10.1016/j.ijar.2021.12.006},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {290-300},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Conditional distributivity equation of semi-uninorms over uninorms},
  volume       = {142},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Novel AQM analysis approach based on similarity and
dissimilarity measures of interval set for multi-expert multi-criterion
decision making. <em>IJAR</em>, <em>142</em>, 266–289. (<a
href="https://doi.org/10.1016/j.ijar.2021.11.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval sets, as a particular knowledge representation, are composed of the lower set and the upper set to represent more general uncertain qualitative information. In this paper, we aim at investigating multi-expert multi-criterion decision making (MEMCDM) based on the interval set information. In the process of MEMCDM, by comparing positive, negative and boundary regions of interval sets, we firstly propose the similarity and dissimilarity measures of interval set to describe the closeness and deviation between interval sets. Secondly, with the aid of dissimilarity, we determine the criterion weight by combining the dissimilarity difference of the judgement matrix and the result of the maximum deviation of dissimilarity. For dealing with the hesitant problem of experts, we design transformation algorithm, which provides technical support for transforming experts&#39; evaluation tables into an interval set information table. In view of the wide applicability of alternative queuing method (AQM), we extend AQM based on 0 − 1 0−1 precedence relationship matrix to address MEMCDM. The 0 − 1 0−1 precedence relationship matrix of AQM exists the incomparable situation, which can lead to the indiscernible alternatives. To reduce indiscernible alternatives and increase efficiency, we design a possibility degree of interval sets and deeply construct precedence relationship matrix. Further, we improve AQM by using possibility degree matrix and aggregating precedence relationship matrix on each alternative by weight arithmetic average (WAA). Finally, we use an example and simulation experiment of former e-commerce platform selection to elaborate and validate our proposed method.},
  archive      = {J_IJAR},
  author       = {Decui Liang and Yuanyuan Fu and Zeshui Xu},
  doi          = {10.1016/j.ijar.2021.11.008},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {266-289},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Novel AQM analysis approach based on similarity and dissimilarity measures of interval set for multi-expert multi-criterion decision making},
  volume       = {142},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A bayesian hierarchical score for structure learning from
related data sets. <em>IJAR</em>, <em>142</em>, 248–265. (<a
href="https://doi.org/10.1016/j.ijar.2021.11.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Score functions for learning the structure of Bayesian networks in the literature assume that data are a homogeneous set of observations; whereas it is often the case that they comprise different related, but not homogeneous, data sets collected in different ways. In this paper we propose a new Bayesian Dirichlet score, which we call Bayesian Hierarchical Dirichlet (BHD). The proposed score is based on a hierarchical model that pools information across data sets to learn a single encompassing network structure, while taking into account the differences in their probabilistic structures. We derive a closed-form expression for BHD using a variational approximation of the marginal likelihood, we study the associated computational cost and we evaluate its performance using simulated data. We find that, when data comprise multiple related data sets, BHD outperforms the Bayesian Dirichlet equivalent uniform (BDeu) score in terms of reconstruction accuracy as measured by the Structural Hamming distance , and that it is as accurate as BDeu when data are homogeneous. This improvement is particularly clear when either the number of variables in the network or the number of observations is large. Moreover, the estimated networks are sparser and therefore more interpretable than those obtained with BDeu thanks to a lower number of false positive arcs.},
  archive      = {J_IJAR},
  author       = {Laura Azzimonti and Giorgio Corani and Marco Scutari},
  doi          = {10.1016/j.ijar.2021.11.013},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {248-265},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A bayesian hierarchical score for structure learning from related data sets},
  volume       = {142},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Granular rough sets and granular shadowed sets: Three-way
approximations in pawlak approximation spaces. <em>IJAR</em>,
<em>142</em>, 231–247. (<a
href="https://doi.org/10.1016/j.ijar.2021.11.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Pawlak approximation space is a pair of a ground set/space and a quotient set/space of the ground set induced by an equivalence relation on the ground set. The quotient space is a simple granulation of the ground space such that an equivalence class is a granule of objects in the ground space and, at the same time, a single granular object in the quotient space. The new two-space view leads to more insights into and a deeper understanding of rough set theory . In this paper, we revisit results from rough sets from the two-space perspective and introduce the notions of granular rough sets and probabilistic granular rough sets in the quotient space, as three-way approximations of sets in the ground space. We propose a concept of granular shadowed sets in the quotient space, as three-way approximations of fuzzy sets in the ground space. We formulate a cost-sensitive method to construct a granular shadowed set from a fuzzy set. We show that, when the costs satisfy some conditions, the three granular approximations become the same for the special case where a fuzzy set is in fact a set.},
  archive      = {J_IJAR},
  author       = {Yiyu Yao and Jilin Yang},
  doi          = {10.1016/j.ijar.2021.11.012},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {231-247},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Granular rough sets and granular shadowed sets: Three-way approximations in pawlak approximation spaces},
  volume       = {142},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Incremental updating probabilistic approximations under
multi-level and multi-dimensional variations in hybrid incomplete
decision systems. <em>IJAR</em>, <em>142</em>, 206–230. (<a
href="https://doi.org/10.1016/j.ijar.2021.11.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The data types of practical application systems are various (for example, Boolean, categorical, numerical, set-valued, interval-valued and incomplete, etc.), and such complex data systems exist widely in the real world; In addition, the data is dynamic in the process of collection and screening, not only the number of objects will change, but also the number of features will vary, which leads to the knowledge being constantly changed and needing to be updated with the collation process. In this paper, aiming at the dynamic change of data in the hybrid incomplete decision system (HIDS), we mainly focus on researching the incremental updating theory and method of probabilistic approximations under the multi-level and multi-dimensional variations of objects and attributes. Firstly, for the different binary relations of multiple data types in HIDS, a normalized combination relationship-based probabilistic rough set model is proposed. Next, multi-level and multi-dimensional variations (MLMDV) of objects and attributes are analyzed; for MLMDV of the object set and the attribute set in HIDS, dynamic knowledge updating mechanisms are researched, and a matrix-based incremental algorithm for updating probabilistic approximations is designed to avoid the repeated calculation of the static algorithm and improve efficiency. Finally, a series of experiments are conducted to evaluate the efficiency of the proposed method. The experimental results of 9 data sets show that the proposed incremental algorithm can effectively update the knowledge for the multi-level and multi-dimensional variants of objects and attributes, and is superior to the static knowledge acquisition method.},
  archive      = {J_IJAR},
  author       = {Hao Ge and Chuanjian Yang},
  doi          = {10.1016/j.ijar.2021.11.010},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {206-230},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Incremental updating probabilistic approximations under multi-level and multi-dimensional variations in hybrid incomplete decision systems},
  volume       = {142},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimization problems on posets with regard to formal
concept analysis. <em>IJAR</em>, <em>142</em>, 196–205. (<a
href="https://doi.org/10.1016/j.ijar.2021.12.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Formal Concept Analysis (FCA), cover- and packing problems occur naturally as an equivalent formulation of the problem to determine the order 2-dimension and breadth of a complete lattice . Furthermore, isolation- and blocking problems provide bounds for these parameters w.r.t. the tensor product of complete lattices. This article introduces an abstract framework based on posets to treat the above mentioned optimization problems in a unified manner. From that point of view, connections to other areas of mathematics, where such optimization problems frequently occur, and the area of FCA emerge. It might even be possible that solutions to the four problems can be pulled to FCA or, vice versa, to push out solutions to the FCA cases to other areas of mathematics.},
  archive      = {J_IJAR},
  author       = {Christian Jäkel and Stefan E. Schmidt},
  doi          = {10.1016/j.ijar.2021.12.005},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {196-205},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Optimization problems on posets with regard to formal concept analysis},
  volume       = {142},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Phenotyping OSA: A time series analysis using fuzzy
clustering and persistent homology. <em>IJAR</em>, <em>142</em>,
178–195. (<a href="https://doi.org/10.1016/j.ijar.2021.10.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sleep apnea is a disorder that has serious consequences for the pediatric population. There has been recent concern that traditional diagnosis of the disorder using the apnea-hypopnea index may be ineffective in capturing its multi-faceted outcomes. In this work, we take a first step in addressing this issue by phenotyping patients using a clustering analysis of airflow time series. This is approached in three ways: using feature-based fuzzy clustering in the time and frequency domains, and using persistent homology to study the signal from a topological perspective. The fuzzy clusters are analyzed in a novel manner using a Dirichlet regression analysis , while the topological approach leverages Takens&#39; embedding theorem to study the periodicity properties of the signals.},
  archive      = {J_IJAR},
  author       = {Prachi Loliencar and Giseon Heo},
  doi          = {10.1016/j.ijar.2021.10.012},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {178-195},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Phenotyping OSA: A time series analysis using fuzzy clustering and persistent homology},
  volume       = {142},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A general bi-clustering algorithm for object data with an
application to the analysis of a lombardy railway line. <em>IJAR</em>,
<em>142</em>, 161–177. (<a
href="https://doi.org/10.1016/j.ijar.2021.12.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A general and flexible bi-clustering algorithm for the analysis of Hilbert data is presented in the Object Oriented Data Analysis framework. The algorithm, called HC2 (i.e. Hilbert Cheng and Church), is a non-parametric method to bi-cluster Hilbert data indexed in a matrix structure . The Cheng and Church approach is here extended to the general case of data embedded in a Hilbert space and then applied to the analysis of the regional railway service in the Lombardy region with the aim of identifying recurrent patterns in the passengers&#39; daily access to trains and/or stations. The analysed data, modelled as multivariate functional data and time series, allows to measure both overcrowding and travel demand, providing useful insights to best handle the service.},
  archive      = {J_IJAR},
  author       = {Agostino Torti and Marta Galvani and Alessandra Menafoglio and Piercesare Secchi and Simone Vantini},
  doi          = {10.1016/j.ijar.2021.12.003},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {161-177},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A general bi-clustering algorithm for object data with an application to the analysis of a lombardy railway line},
  volume       = {142},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning and planning in partially observable environments
without prior domain knowledge. <em>IJAR</em>, <em>142</em>, 147–160.
(<a href="https://doi.org/10.1016/j.ijar.2021.12.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Planning in stochastic and partially observable environments is a central problem in artificial intelligence . To address this issue, an accurate model or a black-box simulator of the environment is usually needed in the literature. Although some recent approaches have been proposed for learning optimal behaviors under model uncertainty, prior knowledge about the environment is still required to guarantee the performance of the proposed algorithms. With the benefits of the Predictive State Representations (PSRs) approach for state representation and model prediction, in this paper, we introduce an approach for planning under partial observability with no prior domain knowledge, where an offline PSR model is firstly learned and then combined with online Monte-Carlo tree search for planning under model uncertainty. Furthermore, we also showed that with the proposed framework, the PSR models learned via other techniques, e.g., the online PSR model learning approach, can be integrated straightforwardly. By comparing with the state-of-the-art approach of planning under model uncertainty, we demonstrated the effectiveness of the proposed approaches along with the proof of their convergence.},
  archive      = {J_IJAR},
  author       = {Yunlong Liu and Jianyang Zheng and Fangfang Chang},
  doi          = {10.1016/j.ijar.2021.12.004},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {147-160},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Learning and planning in partially observable environments without prior domain knowledge},
  volume       = {142},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cautious classification based on belief functions theory and
imprecise relabelling. <em>IJAR</em>, <em>142</em>, 130–146. (<a
href="https://doi.org/10.1016/j.ijar.2021.11.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performances of standard classifiers, i.e., any method of point prediction for classification, decline in case of imperfect data. In some sensitive domains where these imperfections are present, these classifiers need to be adapted in order to avoid any misclassification that has serious consequences. Recent works proposed to deal with this problem by using cautious classification techniques . This paper is in line with these works, especially with imprecise classifiers, i.e., the output of the classifier for an input sample that is subject to considerable imperfections is a subset of classes. The distinctive feature of our imprecise classification proposition is that it considers that in some applications, data imperfection is not limited to new samples to be classified but can also be present in training data. We therefore propose a relabelling procedure which allows us to identify imperfect samples in the training data and relabel them with an appropriate subset of candidate classes . This approach to imprecise classification is close, in some aspects, to hierarchical classification where a “parent” can be considered as a subset of classes that are the “children” in the leaves. Furthermore, the belief functions framework is considered to represent the uncertainty and imprecision about the class of a new sample where the focal elements are contained in the set of new labels of the training data. A criterion based on a generalised F β Fβ score and the obtained mass function is established to decide which subset of classes should be associated to the new sample. Several options are presented to build our classifier for the relabelling procedure and for the reasoning step. Thus, the performances of each option are presented before comparison with state-of-the-art imprecise classifiers&#39; performances. The comparisons are conducted first on randomly generated data and then on 11 UCI datasets based on five measures of imprecise classification performances. They show that our classifier achieves performances close to, sometimes better than, the best on the five measures.},
  archive      = {J_IJAR},
  author       = {Abdelhak Imoussaten and Lucie Jacquin},
  doi          = {10.1016/j.ijar.2021.11.009},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {130-146},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Cautious classification based on belief functions theory and imprecise relabelling},
  volume       = {142},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An improved three-way decision model based on prospect
theory. <em>IJAR</em>, <em>142</em>, 109–129. (<a
href="https://doi.org/10.1016/j.ijar.2021.11.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In three-way decision, how to describe the risk attitudes of decision-makers is an important issue. The prospect theory is widely used to reflect decision-makers&#39; risk attitudes and the decision rules are based on the maximum prospect value. However, the previous three-way decision models based on prospect theory neglected time outcome or they included time outcome in monetary outcome in decision process. In fact, in some cases, time outcome is a more important element in decision making, and without considering it directly may weaken the rationality of decision results. To address these problems, we construct an improved three-way decision model based on prospect theory, which simultaneously and directly considers time outcome and monetary outcome. Specially, this model is a multi-objective optimization model. Firstly, prospect theory is used to describe decision-makers&#39; risk attitudes toward monetary gains and losses as well as time gains and losses. Secondly, we construct a multi-objective optimization model and introduce preference coefficients to transform it into a single objective optimization model, which is based on the maximum comprehensive prospect value. Further, the existence and uniqueness of thresholds are proven, and the decision rules are given. Finally, an illustrative example and some comparative analyses are presented, which validate the rationality and superiority of our improved model.},
  archive      = {J_IJAR},
  author       = {Yihua Zhong and Yanhua Li and Yang Yang and Tong Li and Yanlin Jia},
  doi          = {10.1016/j.ijar.2021.11.011},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {109-129},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {An improved three-way decision model based on prospect theory},
  volume       = {142},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tensor approximation of cooperative games and their
semivalues. <em>IJAR</em>, <em>142</em>, 94–108. (<a
href="https://doi.org/10.1016/j.ijar.2021.11.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an algorithm to approximate the semivalues of general transferable-utility cooperative games that involve a large set of players 1 , … , | N | 1,…,|N| and possibly depend on uncertain parameters. We first encode the game&#39;s utility function using a low-rank tensor decomposition, namely the tensor train (TT) model, which requires a limited number of function evaluations. The TT format casts the utility as a compressed tensor of shape 2 | N | 2|N| and makes it possible to efficiently work with the exponentially-sized set of all possible coalitions of players. Given a game compressed in this manner, the proposed algorithm obtains arbitrary semivalues without incurring additional error, in particular the Shapley values and Banzhaf-Coleman indices, which are two of the most important allocation rules in cooperative game theory . Our algorithm takes O ( | N | R 2 ) O(|N|R2) operations per semivalue, where R is the game&#39;s TT rank. We show experimentally that many classical games can be compressed at low error with a moderate TT rank, making our algorithm more sample-efficient than Monte Carlo-based estimation. We also give a theoretical bound for the error of the semivalues obtained through our algorithm. Last, when the game depends on randomly distributed parameters, we are able to compute the expected semivalues efficiently.},
  archive      = {J_IJAR},
  author       = {Rafael Ballester-Ripoll},
  doi          = {10.1016/j.ijar.2021.11.007},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {94-108},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Tensor approximation of cooperative games and their semivalues},
  volume       = {142},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Coherent checking and updating of bayesian models without
specifying the model space: A decision-theoretic semantics for
possibility theory. <em>IJAR</em>, <em>142</em>, 81–93. (<a
href="https://doi.org/10.1016/j.ijar.2021.11.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Bayesian model has two parts. The first part is a family of sampling distributions that could have generated the data. The second part of a Bayesian model is a prior distribution over the sampling distributions. Both the diagnostics used to check the model and the process of updating a failed model are widely thought to violate the standard foundations of Bayesianism. That is largely because models are checked before specifying the space of all candidate replacement models, which textbook presentations of Bayesian model averaging would require. However, that is not required under a broad class of utility functions that apply when approximate model truth is an important consideration, perhaps among other important considerations. From that class, a simple criterion for model checking emerges and suggests a coherent approach to updating Bayesian models found inadequate. The criterion only requires the specification of the prior distribution up to ratios of prior densities of the models considered until the time of the check. That criterion, while justified by Bayesian decision theory, may also be derived under possibility theory from a decision-theoretic framework that generalizes the likelihood interpretation of possibility functions.},
  archive      = {J_IJAR},
  author       = {David R. Bickel},
  doi          = {10.1016/j.ijar.2021.11.006},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {81-93},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Coherent checking and updating of bayesian models without specifying the model space: A decision-theoretic semantics for possibility theory},
  volume       = {142},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LCM from FCA point of view: A CbO-style algorithm with
speed-up features. <em>IJAR</em>, <em>142</em>, 64–80. (<a
href="https://doi.org/10.1016/j.ijar.2021.11.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {LCM is an algorithm for enumeration of frequent closed itemsets in transaction databases. It is well known that when we ignore the required frequency, the closed itemsets are exactly intents of formal concepts in Formal Concept Analysis (FCA). We describe LCM in terms of FCA and show that LCM is basically the Close-by-One algorithm with multiple speed-up features for processing sparse data. We analyze the speed-up features and compare them with those of similar FCA algorithms , like FCbO and algorithms from the In-Close family.},
  archive      = {J_IJAR},
  author       = {Radek Janostik and Jan Konecny and Petr Krajča},
  doi          = {10.1016/j.ijar.2021.11.005},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {64-80},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {LCM from FCA point of view: A CbO-style algorithm with speed-up features},
  volume       = {142},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Abduction with probabilistic logic programming under the
distribution semantics. <em>IJAR</em>, <em>142</em>, 41–63. (<a
href="https://doi.org/10.1016/j.ijar.2021.11.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Probabilistic Abductive Logic Programming we are given a probabilistic logic program, a set of abducible facts, and a set of constraints. Inference in probabilistic abductive logic programs aims to find a subset of the abducible facts that is compatible with the constraints and that maximizes the joint probability of the query and the constraints. In this paper, we extend the PITA reasoner with an algorithm to perform abduction on probabilistic abductive logic programs exploiting Binary Decision Diagrams . Tests on several synthetic datasets show the effectiveness of our approach.},
  archive      = {J_IJAR},
  author       = {Damiano Azzolini and Elena Bellodi and Stefano Ferilli and Fabrizio Riguzzi and Riccardo Zese},
  doi          = {10.1016/j.ijar.2021.11.003},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {41-63},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Abduction with probabilistic logic programming under the distribution semantics},
  volume       = {142},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Notes on integer partitions. <em>IJAR</em>, <em>142</em>,
31–40. (<a href="https://doi.org/10.1016/j.ijar.2021.11.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some observations concerning the lattices of integer partitions are presented. We determine the size of the standard contexts, discuss a recursive construction and show that the lattices have unbounded breadth.},
  archive      = {J_IJAR},
  author       = {Bernhard Ganter},
  doi          = {10.1016/j.ijar.2021.11.004},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {31-40},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Notes on integer partitions},
  volume       = {142},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new type of dyad fuzzy β-covering rough set models base on
fuzzy information system and its practical application. <em>IJAR</em>,
<em>142</em>, 13–30. (<a
href="https://doi.org/10.1016/j.ijar.2021.11.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of big data, faced with massive and complex information, many mathematical concepts used to make judgments and decisions have emerged. In order to better integrate the multi-level fuzzy information, on the basis of the original covering rough set, we generalize the couple approximate operators defined by L.W. Ma to the information system and propose a new binary model—dyad fuzzy β -covering rough set models. This model can analyze and solve practical problems from multiple angles, so as to make more accurate decisions. In addition, in order to make the model more convenient for large and complex data processing, we use matrix to represent the model and realize it by computer programming. Finally, we illustrate the value of this model by solving a practical problem.},
  archive      = {J_IJAR},
  author       = {Xinli Niu and Zhenduo Sun and Xiangzhi Kong},
  doi          = {10.1016/j.ijar.2021.11.001},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {13-30},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A new type of dyad fuzzy β-covering rough set models base on fuzzy information system and its practical application},
  volume       = {142},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Rough l-fuzzy sets: Their representation and related
structures. <em>IJAR</em>, <em>142</em>, 1–12. (<a
href="https://doi.org/10.1016/j.ijar.2021.11.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The combination of fuzzy set theory and rough set theory has been discussed in a lot of research papers over the years. In this paper, we examine one such combination, namely the notion of rough L -fuzzy sets. We provide a representation theorem that determines when a pair of L -fuzzy sets is a rough L -fuzzy set, and we establish a connection between the lattice of rough fuzzy sets and the lattice of rough relations. Furthermore, we investigate the properties of the lattice of rough L -fuzzy sets and characterize the case when a three-valued Łukasiewicz-algebra can be defined on it.},
  archive      = {J_IJAR},
  author       = {Dávid Gégény and Sándor Radeleczki},
  doi          = {10.1016/j.ijar.2021.11.002},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {1-12},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Rough L-fuzzy sets: Their representation and related structures},
  volume       = {142},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). “So much data. Who needs probability?” Have we been here
before? <em>IJAR</em>, <em>141</em>, 183–189. (<a
href="https://doi.org/10.1016/j.ijar.2021.12.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Statisticians have been dealing with the paradoxes of ever more data since the French Revolution. The bigger the data, the more we know, and the more we think we know. Do we still need probability to tell us what we don&#39;t know? And what ever made us think, in the first place, that statistics needs probability? This text is adapted from an after-dinner talk given at the Fifth Bayesian , Fiducial, and Frequentist Conference, University of Michigan, May 7, 2018.},
  archive      = {J_IJAR},
  author       = {Glenn Shafer},
  doi          = {10.1016/j.ijar.2021.12.016},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {183-189},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {“So much data. who needs probability?” have we been here before?},
  volume       = {141},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Causal interpretation of graphical models. <em>IJAR</em>,
<em>141</em>, 179–182. (<a
href="https://doi.org/10.1016/j.ijar.2021.12.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shafer and Vovk have shown how to base probability theory on game theory. In this framework, we give probabilities an empirical and predictive meaning by means of a form of Cournot&#39;s principle, which says that reality will not permit a gambler to win disproportionately to the capital he risks. How does this principle apply to the causal interpretation of graphical models ?},
  archive      = {J_IJAR},
  author       = {Glenn Shafer},
  doi          = {10.1016/j.ijar.2021.12.014},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {179-182},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Causal interpretation of graphical models},
  volume       = {141},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). The notion of event in probability and causality: Situating
myself relative to bruno de finetti. <em>IJAR</em>, <em>141</em>,
171–178. (<a href="https://doi.org/10.1016/j.ijar.2021.12.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As Bruno de Finetti taught us, the notion of event in a theory of probability is fundamental, perhaps determinative. In this paper, I compare the notion of event in de Finetti&#39;s subjective theory of probability with the more situated notion of event that underlies the theory of probability and causality that I developed in the 1990s. This text was prepared for talks in Pisa, March 14, 2001, and Bologna, March 15, 2001.},
  archive      = {J_IJAR},
  author       = {Glenn Shafer},
  doi          = {10.1016/j.ijar.2021.12.015},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {171-178},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {The notion of event in probability and causality: Situating myself relative to bruno de finetti},
  volume       = {141},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Kameda toyojiro and the transfer of the western theory of
probability to japan. <em>IJAR</em>, <em>141</em>, 159–170. (<a
href="https://doi.org/10.1016/j.ijar.2021.10.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies the work of the Japanese actuary and probabilist Kameda Toyojiro (1885-1944) who took a major part in the transfer of modern probabilistic technology to Japan at the beginning of the 20th century. Very familiar with contemporary English and German works, he made an early use of certain fundamental concepts of probability theory , such as characteristic functions, and was one of those who paved the way for the spectacular development of the Japanese probabilistic school in the next generation.},
  archive      = {J_IJAR},
  author       = {Clémentine Laurens and Laurent Mazliak},
  doi          = {10.1016/j.ijar.2021.10.006},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {159-170},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Kameda toyojiro and the transfer of the western theory of probability to japan},
  volume       = {141},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). W.e. Johnson and cambridge thought on probability.
<em>IJAR</em>, <em>141</em>, 146–158. (<a
href="https://doi.org/10.1016/j.ijar.2021.10.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {W.E. Johnson (1858-1931) has long been recognized as a great Cambridge figure and has often been portrayed as the source of the view of probability as a logical relation. Yet Johnson and his influence are elusive and this paper tries to assemble what is known of the man, his circumstances and of his contribution to probability.},
  archive      = {J_IJAR},
  author       = {John Aldrich},
  doi          = {10.1016/j.ijar.2021.10.010},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {146-158},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {W.E. johnson and cambridge thought on probability},
  volume       = {141},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Homeostasis phenomenon in conformal prediction and
predictive distribution functions. <em>IJAR</em>, <em>141</em>, 131–145.
(<a href="https://doi.org/10.1016/j.ijar.2021.09.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conformal prediction is an attractive framework for prediction that is distribution free. In this article, we study in details its homeostasis property under a general regression setup and also introduce the concepts of upper and lower predictive distributions and predictive curve to establish connections to left-, right- and two-tailed hypothesis testing problems as well as the developments in confidence distributions. The homeostasis property is very attractive, since it states that under some conditions the prediction results remain valid even if the model used for learning is completely wrong. We show explicitly why the property holds in a model-based setup and also explore the boundary when the property breaks down. Beside the typical assumption used in conformal prediction that the response and covariate pairs ( y , x ) (y,x) of all subjects are iid distributed, we also study the classical regression setting in which the design is fixed with given (non-random) covariates x . The trade-offs among learning model accuracy, prediction valid and prediction efficiency are discussed, leading to an emphasis of more efforts on developing better learning models.},
  archive      = {J_IJAR},
  author       = {Min-ge Xie and Zheshi Zheng},
  doi          = {10.1016/j.ijar.2021.09.001},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {131-145},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Homeostasis phenomenon in conformal prediction and predictive distribution functions},
  volume       = {141},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Validity, consonant plausibility measures, and conformal
prediction. <em>IJAR</em>, <em>141</em>, 110–130. (<a
href="https://doi.org/10.1016/j.ijar.2021.07.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prediction of future observations is an important and challenging problem. The two mainstream approaches for quantifying prediction uncertainty use prediction regions and predictive distributions , respectively, with the latter believed to be more informative because it can perform other prediction-related tasks. The standard notion of validity, what we refer to here as Type-1 validity , focuses on coverage probability of prediction regions, while a notion of validity relevant to the other prediction-related tasks performed by predictive distributions is lacking. Here we present a new notion, called Type-2 validity , relevant to these other prediction tasks. We establish connections between Type-2 validity and coherence properties, and show that imprecise probability considerations are required in order to achieve it. We go on to show that both types of prediction validity can be achieved by interpreting the conformal prediction output as the contour function of a consonant plausibility measure. We also offer an alternative characterization of conformal prediction, based on a new nonparametric inferential model construction, wherein the appearance of consonance is natural, and prove its validity.},
  archive      = {J_IJAR},
  author       = {Leonardo Cella and Ryan Martin},
  doi          = {10.1016/j.ijar.2021.07.013},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {110-130},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Validity, consonant plausibility measures, and conformal prediction},
  volume       = {141},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Testing exchangeability: Fork-convexity, supermartingales
and e-processes. <em>IJAR</em>, <em>141</em>, 83–109. (<a
href="https://doi.org/10.1016/j.ijar.2021.06.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Suppose we observe an infinite series of coin flips X 1 , X 2 , … X1,X2,… , and wish to sequentially test the null that these binary random variables are exchangeable. Nonnegative supermartingales (NSMs) are a workhorse of sequential inference, but we prove that they are powerless for this problem. First, utilizing a geometric concept called fork-convexity (a sequential analog of convexity), we show that any process that is an NSM under a set of distributions, is also necessarily an NSM under their “fork-convex hull”. Second, we prove that the fork-convex hull of the exchangeable null consists of all possible laws over binary sequences ; this implies that any NSM under exchangeability is necessarily nonincreasing, hence always yields a powerless test for any alternative. Since testing arbitrary deviations from exchangeability is information theoretically impossible, we focus on Markovian alternatives. We combine ideas from universal inference and the method of mixtures to derive a “safe e-process”, which is a nonnegative process with expectation at most one under the null at any stopping time , and is upper bounded by a martingale, but is not itself an NSM. This in turn yields a level α sequential test that is consistent; regret bounds from universal coding also demonstrate rate-optimal power. We present ways to extend these results to any finite alphabet and to Markovian alternatives of any order using a “double mixture” approach. We provide a wide array of simulations, and give general approaches based on betting for unstructured or ill-specified alternatives. Finally, inspired by Shafer, Vovk, and Ville, we provide game-theoretic interpretations of our e-processes and pathwise results.},
  archive      = {J_IJAR},
  author       = {Aaditya Ramdas and Johannes Ruf and Martin Larsson and Wouter M. Koolen},
  doi          = {10.1016/j.ijar.2021.06.017},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {83-109},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Testing exchangeability: Fork-convexity, supermartingales and e-processes},
  volume       = {141},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Log-optimal anytime-valid e-values. <em>IJAR</em>,
<em>141</em>, 69–82. (<a
href="https://doi.org/10.1016/j.ijar.2021.09.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of measuring statistical evidence against a composite null hypothesis. We base our approach on the concept of an E-value, which measures evidence by the multiplication factor achieved by engaging in bets that are fair under the null. We adopt the log-optimality criterion for choosing among all possible E-values, which was considered earlier for a fixed sample size. We extend these ideas to sequential testing under optional stopping, by revisiting anytime-valid E-values. Our main contribution is the formulation of a sequential log-optimality criterion. We study its properties, and work out examples analytically and computationally.},
  archive      = {J_IJAR},
  author       = {Wouter M. Koolen and Peter Grünwald},
  doi          = {10.1016/j.ijar.2021.09.010},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {69-82},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Log-optimal anytime-valid E-values},
  volume       = {141},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Randomness is inherently imprecise. <em>IJAR</em>,
<em>141</em>, 28–68. (<a
href="https://doi.org/10.1016/j.ijar.2021.06.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We use the martingale-theoretic approach of game-theoretic probability to incorporate imprecision into the study of randomness. In particular, we define several notions of randomness associated with interval, rather than precise, forecasting systems, and study their properties. The richer mathematical structure that thus arises lets us, amongst other things, better understand and place existing results for the precise limit. When we focus on constant interval forecasts, we find that every sequence of binary outcomes has an associated filter of intervals it is random for. It may happen that none of these intervals is precise—a single real number—which justifies the title of this paper. We illustrate this by showing that randomness associated with non-stationary precise forecasting systems can be captured by a constant interval forecast, which must then be less precise: a gain in model simplicity is thus paid for by a loss in precision. But imprecise randomness can&#39;t always be explained away as a result of oversimplification: we show that there are sequences that are random for a constant interval forecast, but never random for any computable (more) precise forecasting system. We also show that the set of sequences that are random for a non-vacuous interval forecasting system is meagre, as it is for precise forecasting systems.},
  archive      = {J_IJAR},
  author       = {Gert de Cooman and Jasper De Bock},
  doi          = {10.1016/j.ijar.2021.06.018},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {28-68},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Randomness is inherently imprecise},
  volume       = {141},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). One-dimensional game-theoretic differential equations.
<em>IJAR</em>, <em>141</em>, 11–27. (<a
href="https://doi.org/10.1016/j.ijar.2021.03.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide a very brief introduction to typical paths and the corresponding Itô type integration. Relying on this robust Itô integration, we prove an existence and uniqueness result for one-dimensional differential equations driven by typical paths with non-Lipschitz continuous coefficients in the spirit of Yamada–Watanabe as well as an approximation result in the spirit of Doss–Sussmann.},
  archive      = {J_IJAR},
  author       = {Rafał M. Łochowski and Nicolas Perkowski and David J. Prömel},
  doi          = {10.1016/j.ijar.2021.03.003},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {11-27},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {One-dimensional game-theoretic differential equations},
  volume       = {141},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Glenn shafer — a short biography. <em>IJAR</em>,
<em>141</em>, 5–10. (<a
href="https://doi.org/10.1016/j.ijar.2022.01.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This editorial article is a biography of Glenn Shafer, briefly covering his early years, his education, and his contributions as an academic to research, teaching, and administration.},
  archive      = {J_IJAR},
  author       = {John C. Aldrich and A. Philip Dawid and Thierry Denoeux and Prakash P. Shenoy and Vladimir Vovk},
  doi          = {10.1016/j.ijar.2022.01.004},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {5-10},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Glenn shafer — a short biography},
  volume       = {141},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Probability and statistics: Foundations and history. Special
issue in honor of glenn shafer. <em>IJAR</em>, <em>141</em>, 1–4. (<a
href="https://doi.org/10.1016/j.ijar.2022.01.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJAR},
  author       = {John Aldrich and A. Philip Dawid and Thierry Denoeux and Prakash P. Shenoy and Vladimir Vovk},
  doi          = {10.1016/j.ijar.2022.01.003},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {1-4},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Probability and statistics: Foundations and history. special issue in honor of glenn shafer},
  volume       = {141},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Conditional sum-product networks: Modular probabilistic
circuits via gate functions. <em>IJAR</em>, <em>140</em>, 298–313. (<a
href="https://doi.org/10.1016/j.ijar.2021.10.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While probabilistic graphical models are a central tool for reasoning under uncertainty in AI , they are in general not as expressive as deep neural models , and inference is notoriously hard and slow. In contrast, deep probabilistic models such as sum-product networks (SPNs) capture joint distributions and ensure tractable inference, but still lack the expressive power of intractable models based on deep neural networks . In this paper, we introduce conditional SPNs (CSPNs)—conditional density estimators for multivariate and potentially hybrid domains—and develop a structure-learning approach that derives both the structure and parameters of CSPNs from data. To harness the expressive power of deep neural networks (DNNs), we also show how to realize CSPNs by conditioning the parameters of vanilla SPNs on the input using DNNs as gate functions. In contrast to SPNs whose high-level structure can not be explicitly manipulated, CSPNs can naturally be used as tractable building blocks of deep probabilistic models whose modular structure maintains high-level interpretability . In experiments, we demonstrate that CSPNs are competitive with other probabilistic models and yield superior performance on structured prediction, conditional density estimation, auto-regressive image modeling, and multilabel image classification . In particular, we show that employing CSPNs as encoders and decoders within variational autoencoders can help to relax the commonly used mean field assumption and in turn improve performance.},
  archive      = {J_IJAR},
  author       = {Xiaoting Shao and Alejandro Molina and Antonio Vergari and Karl Stelzner and Robert Peharz and Thomas Liebig and Kristian Kersting},
  doi          = {10.1016/j.ijar.2021.10.011},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {298-313},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Conditional sum-product networks: Modular probabilistic circuits via gate functions},
  volume       = {140},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Clustering-based simultaneous forecasting of life expectancy
time series through long-short term memory neural networks.
<em>IJAR</em>, <em>140</em>, 282–297. (<a
href="https://doi.org/10.1016/j.ijar.2021.10.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we apply a functional clustering method to the multivariate time series of life expectancy at birth of the female populations collected in the Human Mortality Database. We reconstruct the functional form of life expectancy from the available discrete observations and derive the curves through non-parametric smoothing. Once the clustering is realized, we perform the life expectancy simultaneous forecasting of the countries inside each cluster implementing a multivariate Long-Short Term Memory neural network . Although functional clustering has already been used in the actuarial literature, in this work it is applied for the first time to the study of life expectancy. The originality of the work also lies in the combination of a functional clustering approach with simultaneous forecasting obtained through the Long-Short Term Memory. We point out that such a combination provides a more informative outlook of the evolution of life expectancy, allowing us to depict country-specific longevity consistently with acknowledged mortality profiles. The results show that the evolution of developed countries follows a homogeneous pattern and supports the persisting homogeneity within the high longevity cluster over time. Moreover, we find a remarkable cross-country heterogeneity in the medium-low longevity cluster. By exploiting the cluster information, we improve the simultaneous forecasting of life expectancy time series using Long Short Term Memory neural networks and compare the error forecast of our approach with those of the classical VAR model, showing a better performance of the former when considering the cluster average errors.},
  archive      = {J_IJAR},
  author       = {Susanna Levantesi and Andrea Nigri and Gabriella Piscopo},
  doi          = {10.1016/j.ijar.2021.10.008},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {282-297},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Clustering-based simultaneous forecasting of life expectancy time series through long-short term memory neural networks},
  volume       = {140},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Coherent and archimedean choice in general banach spaces.
<em>IJAR</em>, <em>140</em>, 255–281. (<a
href="https://doi.org/10.1016/j.ijar.2021.09.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {I introduce and study a new notion of Archimedeanity for binary and non-binary choice between options that live in an abstract Banach space , through a very general class of choice models, called sets of desirable option sets. In order to be able to bring an important diversity of contexts into the fold, amongst which choice between horse lottery options, I pay special attention to the case where these linear spaces don&#39;t include all ‘constant’ options. I consider the frameworks of conservative inference associated with Archimedean (and coherent) choice models, and also pay quite a lot of attention to representation of general (non-binary) choice models in terms of the simpler, binary ones. The representation theorems proved here provide an axiomatic characterisation for, amongst many other choice methods, Levi&#39;s E-admissibility and Walley–Sen maximality .},
  archive      = {J_IJAR},
  author       = {Gert de Cooman},
  doi          = {10.1016/j.ijar.2021.09.005},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {255-281},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Coherent and archimedean choice in general banach spaces},
  volume       = {140},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Attributes reduction algorithms for m-polar fuzzy relation
decision systems. <em>IJAR</em>, <em>140</em>, 232–254. (<a
href="https://doi.org/10.1016/j.ijar.2021.10.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, attribute reduction has become a significant topic in relation decision systems. Their applications come from different domains of the computer sciences, including machine learning , data mining and pattern recognition, which often involve a large number of attributes in data. Several attribute reduction methods are presented in the literature in order to help solving decision-making problems efficiently. A common characterization for these approaches is still missing, that is, although attribute reduction methods of relation decision systems and fuzzy relation decision systems exist, a common generalization for them is still missing. This study presents a systematic discussion of attribute reduction based on m -polar fuzzy ( m F, in short) relation systems and m F relation decision systems, which are respective extensions of fuzzy relation systems and fuzzy relation decision systems. This study provides mathematical results on the attribute reduction algorithms based upon m F relation systems and m F relation decision systems. Both are explained with numerical examples. The resulting algorithms permit to reinterpret the upshots of traditional reduction methods, providing them with larger generality and unification abilities. Afterwards, two real-life applications of the proposed attribute reduction approaches prove their validity and feasibility. Finally, the attribute reduction methods developed here are compared with some existing approaches to show their reliability.},
  archive      = {J_IJAR},
  author       = {Muhammad Akram and Ghous Ali and José Carlos R. Alcantud},
  doi          = {10.1016/j.ijar.2021.10.005},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {232-254},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Attributes reduction algorithms for m-polar fuzzy relation decision systems},
  volume       = {140},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dilation properties of coherent nearly-linear models.
<em>IJAR</em>, <em>140</em>, 211–231. (<a
href="https://doi.org/10.1016/j.ijar.2021.10.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dilation is a puzzling phenomenon within Imprecise Probability theory : when it obtains, our uncertainty evaluation on event A is vaguer after conditioning A on B , whatever is event B in a given partition B B . In this paper we investigate dilation with coherent Nearly-Linear (NL) models. These are a family of neighbourhood models, obtaining lower/upper probabilities by linear affine transformations (with barriers) of a given probability, and encompass several well-known models, such as the Pari-Mutuel Model, the ε -contamination model, the Total Variation Model, and others. We first recall results we recently obtained for conditioning NL model with the standard procedure of natural extension and separately discuss the role of the alternative regular extension. Then, we characterise dilation for coherent NL models. For their most relevant subfamily, Vertical Barrier Models (VBM), we study the coarsening property of dilation, the extent of dilation, and constriction. The results generalise existing ones established for special VBMs. As an interesting aside, we discuss in a general framework how logical (in)dependence of A from B B or extreme evaluations for A influence dilation.},
  archive      = {J_IJAR},
  author       = {Renato Pelessoni and Paolo Vicig},
  doi          = {10.1016/j.ijar.2021.10.009},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {211-231},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Dilation properties of coherent nearly-linear models},
  volume       = {140},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ensuring reference independence and cautious monotony in
abstract argumentation. <em>IJAR</em>, <em>140</em>, 173–210. (<a
href="https://doi.org/10.1016/j.ijar.2021.10.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the symbolic artificial intelligence community, abstract argumentation with its semantics, i.e. approaches for defining sets of valid conclusions (extensions) that can be derived from argumentation graphs, is considered a promising method for non-monotonic reasoning. However, from a sequential perspective, abstract argumentation-based decision-making processes typically do not guarantee an alignment with common formal notions to assess consistency; in particular, abstract argumentation can, in itself, not enforce the satisfaction of relational principles such as reference independence (based on a key principle of microeconomic theory) and cautious monotony. In this paper, we address this issue by introducing different approaches to ensuring reference independence and cautious monotony in sequential argumentation: a reductionist , an expansionist , and an extension-selecting approach. The first two approaches are generically applicable, but may require comprehensive changes to the corresponding argumentation framework. In contrast, the latter approach guarantees that an extension of the corresponding argumentation framework can be selected to satisfy the relational principle by requiring that the used argumentation semantics is weakly reference independent or weakly cautiously monotonous , respectively, and also satisfies some additional straightforward principles. To highlight the relevance of the approach, we illustrate how the extension-selecting approach to reference independent argumentation can be applied to model (boundedly) rational economic decision-making.},
  archive      = {J_IJAR},
  author       = {Timotheus Kampik and Juan Carlos Nieves and Dov Gabbay},
  doi          = {10.1016/j.ijar.2021.10.007},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {173-210},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Ensuring reference independence and cautious monotony in abstract argumentation},
  volume       = {140},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hierarchical sequential three-way decision model.
<em>IJAR</em>, <em>140</em>, 156–172. (<a
href="https://doi.org/10.1016/j.ijar.2021.10.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge acquisition is one of the important issues in granular computing . In recent years, scholars have paid much attention to this problem and proposed the rule-based acquisition algorithms. However, a large number of the decision rules mined by the existing algorithms are not comprehensible. At the same time, the long detailed rules are easy to lead to over-fitting. In order to generate simpler and easier-to-comprehensible rules and improve human decision-making, a hierarchical sequential three-way decision model is proposed by combining sequential three-way decisions with hierarchical rough set model. Specifically, we generalize the concepts of the conditional attributes through the concept hierarchy tree, design the multi-hierarchical decision table with multiple levels of granularity , and illustrate the corresponding algorithm to acquire the generalized rules step by step. The experimental results demonstrate that the proposed model can mine hierarchical sequential three-way decision rules under different levels of granularity.},
  archive      = {J_IJAR},
  author       = {Jin Qian and DaWei Tang and Ying Yu and XiBei Yang and Shang Gao},
  doi          = {10.1016/j.ijar.2021.10.004},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {156-172},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Hierarchical sequential three-way decision model},
  volume       = {140},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning context-dependent choice functions. <em>IJAR</em>,
<em>140</em>, 116–155. (<a
href="https://doi.org/10.1016/j.ijar.2021.10.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Choice functions accept a set of alternatives as input and produce a preferred subset of these alternatives as output. We study the problem of learning such functions under conditions of context-dependence of preferences, which means that the preference in favor of a certain choice alternative may depend on what other options are also available. In spite of its practical relevance, this kind of context-dependence has received little attention in preference learning so far. We propose a suitable model based on context-dependent (latent) utility functions, thereby reducing the problem to the task of learning such utility functions. Practically, this comes with a number of challenges. For example, the set of alternatives provided as input to a choice function can be of any size, and the output of the function should not depend on the order in which the alternatives are presented. To meet these requirements, we propose two general approaches based on two representations of context-dependent utility functions, as well as instantiations in the form of appropriate end-to-end trainable neural network architectures. Moreover, to demonstrate the performance of both networks, we present extensive empirical evaluations on both synthetic and real-world datasets.},
  archive      = {J_IJAR},
  author       = {Karlson Pfannschmidt and Pritha Gupta and Björn Haddenhorst and Eyke Hüllermeier},
  doi          = {10.1016/j.ijar.2021.10.002},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {116-155},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Learning context-dependent choice functions},
  volume       = {140},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Strudel: A fast and accurate learner of
structured-decomposable probabilistic circuits. <em>IJAR</em>,
<em>140</em>, 92–115. (<a
href="https://doi.org/10.1016/j.ijar.2021.09.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic circuits (PCs) represent a probability distribution as a computational graph. Enforcing structural properties on these graphs guarantees that several inference scenarios become tractable. Among these properties, structured decomposability is a particularly appealing one: it enables the efficient and exact computations of the probability of complex logical formulas, and can be used to reason about the expected output of certain predictive models under missing data. This paper proposes Strudel , a simple, fast and accurate learning algorithm for structured-decomposable PCs. Compared to prior work for learning structured-decomposable PCs, Strudel delivers more accurate single PC models in fewer iterations, and dramatically scales learning when building ensembles of PCs. It achieves this scalability by exploiting another structural property of PCs, called determinism, and by sharing the same computational graph across mixture components. We show these advantages on standard density estimation benchmarks and challenging inference scenarios.},
  archive      = {J_IJAR},
  author       = {Meihua Dang and Antonio Vergari and Guy Van den Broeck},
  doi          = {10.1016/j.ijar.2021.09.012},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {92-115},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Strudel: A fast and accurate learner of structured-decomposable probabilistic circuits},
  volume       = {140},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Random sampling accelerator for attribute reduction.
<em>IJAR</em>, <em>140</em>, 75–91. (<a
href="https://doi.org/10.1016/j.ijar.2021.09.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the crucial topics in the development of rough set, attribute reduction has received extensive attentions because it is practical and interpretable for us to perform dimensional reduction or feature selection. Currently, to further improve the efficiency of searching reducts, many researchers have devoted themselves to designing various accelerative mechanisms. Among these existing results, it should be pointed out that the accelerators designed by reducing the scale of samples strongly depend on the distribution of data. To fill such a gap, an accelerator based on the random sampling is developed. The superiorities of our accelerator are: (1) randomly selecting samples without considering the distribution of data; (2) guidance-based evaluations and selections of attributes; (3) easily to be combined with other popular searching strategies. By comparing with 5 state-of-the-art accelerators over 24 UCI data sets: (1) our accelerator may significantly reduce the time consumption of deriving reducts and then the average speed-up ratio can exceed 10; (2) the reduct derived by our accelerator can offer competent performance in classification task .},
  archive      = {J_IJAR},
  author       = {Zhen Chen and Keyu Liu and Xibei Yang and Hamido Fujita},
  doi          = {10.1016/j.ijar.2021.09.016},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {75-91},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Random sampling accelerator for attribute reduction},
  volume       = {140},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A formal study of a generalized rough set model based on
subset approximation structure. <em>IJAR</em>, <em>140</em>, 52–74. (<a
href="https://doi.org/10.1016/j.ijar.2021.10.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a generalized rough set model based on a structure where we have a collection of subsets of the domain of discourse along with the accessibility relation. A modal logic for such a structure is proposed and the important properties of the logic viz. axiomatization , decidability , expressibility etc. are discussed.},
  archive      = {J_IJAR},
  author       = {Md. Aquil Khan and Vineeta Singh Patel},
  doi          = {10.1016/j.ijar.2021.10.001},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {52-74},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A formal study of a generalized rough set model based on subset approximation structure},
  volume       = {140},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interval-valued kriging for geostatistical mapping with
imprecise inputs. <em>IJAR</em>, <em>140</em>, 31–51. (<a
href="https://doi.org/10.1016/j.ijar.2021.10.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many geosciences data are imprecise due to various limitations and uncertainties in the measuring process. In other situations, collocated measurements of variables from the same, yet unknown, distribution are characterized with separate models that may not respect the relatedness of the measurements. One way to preserve this imprecision or relatedness in a geostatistical mapping framework is to characterize the measurements as intervals rather than single numbers. To effectively analyze the interval-valued data, this paper develops an interval-valued kriging based on the modification of a previous attempt and the recent development of the random sets theory. Numerical implementation of our interval-valued kriging is provided using a penalty-based constrained optimization algorithm. An interval-valued kriging of design ground snow loads in Ohio, USA, demonstrates the applicability and advantages of the proposed methodology.},
  archive      = {J_IJAR},
  author       = {Brennan Bean and Yan Sun and Marc Maguire},
  doi          = {10.1016/j.ijar.2021.10.003},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {31-51},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Interval-valued kriging for geostatistical mapping with imprecise inputs},
  volume       = {140},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AMG-DTRS: Adaptive multi-granulation decision-theoretic
rough sets. <em>IJAR</em>, <em>140</em>, 7–30. (<a
href="https://doi.org/10.1016/j.ijar.2021.09.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Multi-Granulation Decision-Theoretic Rough Set (MG-DTRS) is an effective method for cost-sensitive decision making from multi-view and multi-level. However, the inherent weak point of MG-DTRS model is to compute three regions with a subjectively given pair of probabilistic parameters (i.e., α and β ). To overcome this issue, this paper first proposes a generalized MG-DTRS model called Adaptive Multi-Granulation Decision-Theoretic Rough Sets (AMG-DTRS), which can adaptively obtain a pair of probabilistic thresholds by setting a compensation coefficient ζ . Then, three types of mean AMG-DTRS models are investigated, which provide a novel perspective on multi-granulation method for information fusion. Finally, the connections and differences between the proposed AMG-DTRS and the existing MGRS models are analyzed, which show the advantages and generalization of the AMG-DTRS model. In addition, there are numerous existing MGRS models can be derived explicitly by considering various MG-DTRS, MGRS and VP-MGRS based on our model. These results will be conducive to establishing the framework of information fusion for granular computing .},
  archive      = {J_IJAR},
  author       = {Pengfei Zhang and Tianrui Li and Chuan Luo and Guoqiang Wang},
  doi          = {10.1016/j.ijar.2021.09.017},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {7-30},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {AMG-DTRS: Adaptive multi-granulation decision-theoretic rough sets},
  volume       = {140},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Formal concept analysis, rough sets, and three-way
decisions. <em>IJAR</em>, <em>140</em>, 1–6. (<a
href="https://doi.org/10.1016/j.ijar.2021.09.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Formal concept analysis, rough sets, and three-way decisions are prominent theories and methods for data representation and analysis. They have been applied to data mining, machine learning, artificial intelligence as well as many other areas. This special issue contains thirty high quality state-of-art research that addresses theoretic and applicational aspects of formal concept analysis, rough sets, and three-way decisions.},
  archive      = {J_IJAR},
  author       = {JingTao Yao and Jesús Medina and Yan Zhang and Dominik Ślęzak},
  doi          = {10.1016/j.ijar.2021.09.011},
  journal      = {International Journal of Approximate Reasoning},
  pages        = {1-6},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Formal concept analysis, rough sets, and three-way decisions},
  volume       = {140},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
