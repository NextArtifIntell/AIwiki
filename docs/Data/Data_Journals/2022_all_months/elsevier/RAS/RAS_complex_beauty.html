<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>RAS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ras---154">RAS - 154</h2>
<ul>
<li><details>
<summary>
(2022). A balanced jumping control algorithm for quadruped robots.
<em>RAS</em>, <em>158</em>, 104278. (<a
href="https://doi.org/10.1016/j.robot.2022.104278">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The jumping movement of quadruped robots is crucial, so a complete set of balanced jumping algorithms is proposed in this paper due to the flaws of the current jumping algorithms. The proposed algorithm includes trajectory planning of the Center of Mass(CoM) and four jumping phases, illustrating the jumping process in detail. Tasks that a quadruped robot with the height of 0.6 m jumps up a step with the height of 0.3 m, 0.4 m, 0.5 m and 0.6 m are the research object. Optimal Parabola Trajectory of CoM(OPTC) is solved by about ten iterations based on the fastest approaching strategy before jumping. During the first phase of jumping, Ground Reaction Forces(GRFs) are precisely distributed to control six Degrees of Freedom(DoFs) based on symmetric six-dimensional spatial mechanics decoupling solution, controlling the robot to adjust itself to the best ejecting posture. The maximum displacement error is less than 0.005 m. During the second phase, full-leg ejection is implemented to eject, guaranteeing that the robot accurately tracks the OPTC after takeoff by updating proportional virtual forces. The tracking Mean Square Error(MSE) is less than 0.06. During the third phase, the flying attitude is adjusted by swinging leg theory summarized in the paper, with the maximum pitch angle less than 4.5°. Meanwhile, the theoretical landing points of feet are calculated to lead the movement of feet, ensuring a soft landing to reduce touchdown impact. The momentary landing velocities of feet are less than 0.09 m/s. During the fourth phase, the robot buffers and brakes to a static state based on the algorithm used in the first phase. Eventually, the proposed algorithms are verified through simulating experiments on Webots physical engine, and the effectiveness and feasibility are validated by the experimental results.},
  archive      = {J_RAS},
  author       = {Bende Luo and Yinlin Luo},
  doi          = {10.1016/j.robot.2022.104278},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104278},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A balanced jumping control algorithm for quadruped robots},
  volume       = {158},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Footstep planning of humanoid robot in ROS environment using
generative adversarial networks (GANs) deep learning. <em>RAS</em>,
<em>158</em>, 104269. (<a
href="https://doi.org/10.1016/j.robot.2022.104269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes deep learning-based footstep planning using Generative Adversarial Networks (GANs) for the indoor navigation of humanoid robots . The GAN-based architecture presents an efficient and accurate path to plan the footsteps of a humanoid robot on Robot Operating System (ROS) based architecture. During navigation, humanoid robots must understand their surroundings and be able to generate footsteps accurately. Although some algorithms that are based on sampling, such as Rapidly Exploring Random Tree (RRT*) and A*, are widely used for path planning , they fail to perform in narrow paths, especially for the footstep generation of humanoid robots. The widely growing deep learning approaches such as GANs are now producing extremely surprising results in solving real-life problems. The experiments conclude that GAN based approach performs better than conventional Dijkstra’s or A* algorithms. The accuracy of the generated footsteps from the GAN-based path planner comes out to be approximately 93\%.},
  archive      = {J_RAS},
  author       = {Pradumn Mishra and Urja Jain and Siddharth Choudhury and Surjeet Singh and Anish Pandey and Abhishek Sharma and Ramanpreet Singh and Vimal Kumar Pathak and Kuldeep K. Saxena and Anita Gehlot},
  doi          = {10.1016/j.robot.2022.104269},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104269},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Footstep planning of humanoid robot in ROS environment using generative adversarial networks (GANs) deep learning},
  volume       = {158},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spring-linkage integrated mechanism design for jumping
robots. <em>RAS</em>, <em>158</em>, 104268. (<a
href="https://doi.org/10.1016/j.robot.2022.104268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Legged robots can negotiate unstructured environments and have applications in education, environmental inspection, space exploration, and cargo transportation. As a powerful form of legged robots, jumping robots have attractive features due to their high efficiency, mobility, traverse obstacles, and low cost of transport. Although spring is the core component of the energy system , little related work explores the value selection of spring stiffness and the effect of different spring placements for jumping robots. In this article, we present a systematic method to select the stiffness of spring based on static analysis , jumping linkage configuration and multi-objective optimization for jumping robots. Also, to predict the motion behavior of jumping robots, we provide a comprehensive dynamic model of the robotic jumping in different phases according to the Lagrange method and the principle of virtual work, which considers the motion constraints and configuration constraints simultaneously. The proposed method and dynamic model can validate by designing a spring-linkage-based jumping robot as a showcase. The experimental results show performance improvements in jumping height in terms of both different springs’ stiffness and arrangement, which is possible to appraise a maximal enhancement of 57.88\%.},
  archive      = {J_RAS},
  author       = {Xuanchun Yin and Jinchun Yan and Sheng Wen and Jiantao Zhang},
  doi          = {10.1016/j.robot.2022.104268},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104268},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Spring-linkage integrated mechanism design for jumping robots},
  volume       = {158},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Path tracking control strategy for off-road 4WS4WD vehicle
based on robust model predictive control. <em>RAS</em>, <em>158</em>,
104267. (<a href="https://doi.org/10.1016/j.robot.2022.104267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing requirements for vehicle adaptability and maneuverability in various road environments, four-wheel-steering four-wheel-drive (4WS4WD) vehicles have attracted wider attention. This paper presents a robust model predictive control-based strategy for the path tracking of 4WS4WD vehicles considering external disturbances . The strategy combines model predictive control (MPC) and control allocation under an upper–lower structure. The main objective of the present work is to improve the robustness and stability of path tracking by developing an MPC algorithm in the upper layer. The controller design considers general disturbances caused by allocation errors and sudden disturbances caused by an outer force in the offset model. Based on the offset model, a robust MPC control law is obtained by converting the robustness constraints into a linear matrix inequality. The control law is mathematically demonstrated to be stable in multidisturbed conditions via the Lyapunov stability theorem . Through comparison with a similar control algorithm of path tracking and applying it on different uneven ground conditions, the proposed robust algorithm is found to effectively overcome disturbances on the system.},
  archive      = {J_RAS},
  author       = {Qifan Tan and Cheng Qiu and Jing Huang and Yue Yin and Xinyu Zhang and Huaping Liu},
  doi          = {10.1016/j.robot.2022.104267},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104267},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Path tracking control strategy for off-road 4WS4WD vehicle based on robust model predictive control},
  volume       = {158},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Goal-aware generative adversarial imitation learning from
imperfect demonstration for robotic cloth manipulation. <em>RAS</em>,
<em>158</em>, 104264. (<a
href="https://doi.org/10.1016/j.robot.2022.104264">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Imitation Learning (GAIL) can learn policies without explicitly defining the reward function from demonstrations. GAIL has the potential to learn policies with high-dimensional observations as input, e.g., images. By applying GAIL to a real robot, perhaps robot policies can be obtained for daily activities like washing, folding clothes, cooking, and cleaning. However, human demonstration data are often imperfect due to mistakes, which degrade the performance of the resulting policies. We address this issue by focusing on the following features: (1) many robotic tasks are goal-reaching tasks, and (2) labeling such goal states in demonstration data is relatively easy. With these in mind, this paper proposes Goal-Aware Generative Adversarial Imitation Learning (GA-GAIL), which trains a policy by introducing a second discriminator to distinguish the goal state in parallel with the first discriminator that indicates the demonstration data. This extends a standard GAIL framework to more robustly learn desirable policies even from imperfect demonstrations through a goal-state discriminator that promotes achieving the goal state. Furthermore, GA-GAIL employs the Entropy-maximizing Deep P-Network (EDPN) as a generator, which considers both the smoothness and causal entropy in the policy update, to achieve stable policy learning from two discriminators. Our proposed method was successfully applied to two real-robotic cloth-manipulation tasks: turning a handkerchief over and folding clothes. We confirmed that it learns cloth-manipulation policies without task-specific reward function design. Video of the real experiments are available at this URL .},
  archive      = {J_RAS},
  author       = {Yoshihisa Tsurumine and Takamitsu Matsubara},
  doi          = {10.1016/j.robot.2022.104264},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104264},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Goal-aware generative adversarial imitation learning from imperfect demonstration for robotic cloth manipulation},
  volume       = {158},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A generalized framework for autonomous calibration of
wheeled mobile robots. <em>RAS</em>, <em>158</em>, 104262. (<a
href="https://doi.org/10.1016/j.robot.2022.104262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic calibration allows for the fusion of data from multiple sensors such as odometers, cameras etc., by providing appropriate transformational relationships between the corresponding reference frames. For wheeled robots equipped with exteroceptive sensors, calibration entails learning the motion model of the sensor or the robot in terms of the odometric data, and must generally be performed prior to performing tasks such as simultaneous localization and mapping (SLAM). Within this context, the current trend is to carry out simultaneous calibration of odometry and exteroceptive sensors without using additional hardware. Building upon the existing simultaneous calibration algorithms, we put forth a generalized calibration framework that can not only handle robots operating in 2D with arbitrary or unknown motion models but also handle outliers in an automated manner. We first propose an algorithm based on the alternating minimization framework applicable to two-wheel differential drive. Subsequently, for arbitrary but known drive configurations we put forth an iteratively re-weighted least squares methodology leveraging an intelligent weighing scheme. Different from the existing works, these proposed algorithms require no manual intervention and seamlessly handle outliers that arise due to both systematic and non-systematic errors. Finally, we put forward a novel Gaussian Process-based non-parametric approach for calibrating wheeled robots with unknown or un-modeled drive configurations. Detailed experiments are performed to demonstrate the accuracy, usefulness, and flexibility of the proposed algorithms. 1},
  archive      = {J_RAS},
  author       = {Mohan Krishna Nutalapati and Lavish Arora and Anway Bose and Ketan Rajawat and Rajesh M. Hegde},
  doi          = {10.1016/j.robot.2022.104262},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104262},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A generalized framework for autonomous calibration of wheeled mobile robots},
  volume       = {158},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Gait rehabilitation training robot: A motion-intention
recognition approach with safety and convenience. <em>RAS</em>,
<em>158</em>, 104260. (<a
href="https://doi.org/10.1016/j.robot.2022.104260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motion-intention recognition is a vital prerequisite in active training when employing a gait rehabilitation training robot. To accurately recognize the motion intention of the elderly and the people with inconveniences in the human–robot interaction process, a novel approach of motion intention recognition with safety, accuracy, and convenience, including directional intention recognition (DIR) and speed intention recognition (SIR) is proposed in this paper. Firstly, the structures of the gait rehabilitation training robot and its motion-intention recognition system are illustrated. To ensure that the user walks in any desired direction safely and naturally, an improved distance-type fuzzy reasoning algorithm combined with a shake-intent filter and second-order optimization algorithm is proposed. It effectively eliminates the control error caused by body shaking and usage habits in human–robot interaction. Furthermore, by extracting from the pressure sensor data, a novel algorithm, taking advantage of the Gaussian probability density function (PDF)’s characteristics, is proposed for SIR, which does not increase the system complexity. Finally, a multi-directional fuzzy reasoning experiment and a human–robot interaction experiment are implemented. The results show that the algorithm can accurately recognize the motion direction intention and motion speed intention of people with weak motion capability, which also improves the safety and convenience of the interaction approach. The proposed method can be integrated into a walker with similar structures, and the whole system can be applied in hospitals, families, and other places for assisting the elderly and the disabled.},
  archive      = {J_RAS},
  author       = {A. Donghui Zhao and B. Tianqi Zhang and C. Houde Liu and D. Junyou Yang and E. Hiroshi Yokoi},
  doi          = {10.1016/j.robot.2022.104260},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104260},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Gait rehabilitation training robot: A motion-intention recognition approach with safety and convenience},
  volume       = {158},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning differentiable dynamics models for shape control of
deformable linear objects. <em>RAS</em>, <em>158</em>, 104258. (<a
href="https://doi.org/10.1016/j.robot.2022.104258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots manipulating deformable linear objects (DLOs) – such as surgical sutures in medical robotics, or cables and hoses in industrial assembly – can benefit substantially from accurate and fast differentiable predictive models. However, the off-the-shelf analytic physics models fall short of differentiability . Recently, neural-network-based data-driven models have shown promising results in learning DLO dynamics. These models have additional advantages compared to analytic physics models, as they are differentiable and can be used in gradient-based trajectory planning . Still, the data-driven approaches demand a large amount of training data, which can be challenging for real-world applications. In this paper, we propose a framework for learning a differentiable data-driven model for DLO dynamics with a minimal set of real-world data. To learn DLO twisting and bending dynamics in a 3D environment, we first introduce a new suitable DLO representation. Next, we use a recurrent network module to propagate effects between different segments along a DLO, thereby addressing a critical limitation of current state-of-the-art methods. Then, we train a data-driven model on synthetic data generated in simulation, instead of foregoing the time-consuming and laborious data collection process for real-world applications. To achieve a good correspondence between real and simulated models, we choose a set of simulation model parameters through parameter identification with only a few trajectories of a real DLO required. We evaluate several optimization methods for parameter identification and demonstrate that the differential evolution algorithm is efficient and effective for parameter identification. In DLO shape control tasks with a model-based controller, the data-driven model trained on synthetic data generated by the resulting models performs on par with the ones trained with a comparable amount of real-world data which, however, would be intractable to collect.},
  archive      = {J_RAS},
  author       = {Yuxuan Yang and Johannes A. Stork and Todor Stoyanov},
  doi          = {10.1016/j.robot.2022.104258},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104258},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Learning differentiable dynamics models for shape control of deformable linear objects},
  volume       = {158},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). HAPTR2: Improved haptic transformer for legged robots’
terrain classification. <em>RAS</em>, <em>158</em>, 104236. (<a
href="https://doi.org/10.1016/j.robot.2022.104236">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The haptic terrain classification is an essential component of a mobile walking robot control system, ensuring proper gait adaptation to the changing environmental conditions. In practice, such components are a part of an autonomous system and thus have to be lightweight, provide fast inference time, and guarantee robustness to minor changes in recorded sensory data. We propose transformer-based HAPTR and HAPTR2 terrain classification methods that use force and torque measurements from feet to meet these requirements. For reliable comparison of the proposed solutions, we adapt two classical machine learning algorithms (DTW-KNN and ROCKET), one temporal convolution network (TCN), and use the state-of-the-art CNN-RNN. The experiments are performed on publicly available PUTany and QCAT datasets. We show that the proposed HAPTR and HAPTR2 methods achieve accuracy on par or better than state-of-the-art approaches with a lower number of parameters, faster inference time, and improved robustness to input signal distortions. These features make HAPTR and HAPTR2 excel in terrain recognition tasks when considering real-world requirements.},
  archive      = {J_RAS},
  author       = {Michał Bednarek and Michał R. Nowicki and Krzysztof Walas},
  doi          = {10.1016/j.robot.2022.104236},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104236},
  shortjournal = {Robot. Auton. Syst.},
  title        = {HAPTR2: Improved haptic transformer for legged robots’ terrain classification},
  volume       = {158},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Approaching motion planning for mobile manipulators
considering the uncertainty of self-positioning and object’s pose
estimation. <em>RAS</em>, <em>158</em>, 104232. (<a
href="https://doi.org/10.1016/j.robot.2022.104232">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study focuses on the problem of determining the posture of a mobile manipulator aiming to reach a target end-effector pose. Any posture of a mobile manipulator can be described using two parameters: the pose of the mobile platform and the joint angles of the manipulator. This study proposes a posture evaluation method for determining the pose of the mobile platform while focusing on two types of uncertainty: (i) the pose error associated with the end-effector caused by the accumulated positioning error of the mobile platform and (ii) the pose estimation error of objects to be grasped. In addition to using pose errors, the proposed method considers the manipulation ability of the end-effector and the tolerance region for grasping an object by the end-effector. Furthermore, this study proposes a method based on Bayes optimization for finding acceptable moving paths for the mobile platform in environments with sparse obstacles. The effectiveness of the proposed methods was demonstrated through simulations using a mobile manipulator. According to simulation results, the proposed methods can find both moving trajectories for the mobile platform and postures for the mobile manipulator within several seconds.},
  archive      = {J_RAS},
  author       = {Kimitoshi Yamazaki and Satoshi Suzuki and Yusuke Kuribayashi},
  doi          = {10.1016/j.robot.2022.104232},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104232},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Approaching motion planning for mobile manipulators considering the uncertainty of self-positioning and object’s pose estimation},
  volume       = {158},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Trust as a metric for auction-based task assignment in a
cooperative team of robots with heterogeneous capabilities.
<em>RAS</em>, <em>157</em>, 104266. (<a
href="https://doi.org/10.1016/j.robot.2022.104266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As robots become part of our everyday lives, they may be required to cooperate without being aware of each other’s capabilities (e.g., because different teams have developed them), and therefore will have to trust each other to work together safely and efficiently. Starting from this premise, this work identifies trust as an essential metric to assign tasks to robots using auction-based mechanisms. We model trust by taking inspiration from popular models in the literature and adapting them to an open environment in which heterogeneous robots may dynamically enter or exit, execute assigned tasks, or verify the correct execution of tasks by other robots. Robots are considered to be heterogeneous in the sense that they may have different capabilities in executing and verifying the execution of actions. In the proposed model, “doing an action” and “verifying the execution of an action” are distinct, not necessarily overlapping, capabilities. Some robots may be able to do an action, whereas some robots may not be able to do it but only to observe and judge the ability of other robots to do it. After introducing the relevant formalism, the article describes the system’s architecture implemented in ROS and multiple experiments performed in simulation and with real robots (one NAO and two Pepper robots by SoftBank Robotics), providing a proof-of-concept for broader utilization of the system in cooperative robotic scenarios.},
  archive      = {J_RAS},
  author       = {Alberto Grillo and Stefano Carpin and Carmine Tommaso Recchiuto and Antonio Sgorbissa},
  doi          = {10.1016/j.robot.2022.104266},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104266},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Trust as a metric for auction-based task assignment in a cooperative team of robots with heterogeneous capabilities},
  volume       = {157},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spatial and temporal features unified self-supervised
representation learning networks. <em>RAS</em>, <em>157</em>, 104256.
(<a href="https://doi.org/10.1016/j.robot.2022.104256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robot manipulation tasks can be carried out effectively, provided the state representation is satisfactorily detailed. Embodiment difference, Viewpoint difference, and Domain difference are some of the challenges in learning from human demonstration. This work proposes a self-supervised and multi-viewpoint spatial and temporal features unified representation learning method. The algorithm consists of two components: (a) Spatial Component, which learns the setting of the environment, i.e., on which pixels to focus on most to get the best representation of the image regardless of point of view, and (b) Temporal Component that learns how snapshots taken from multiple viewpoints simultaneously (i.e., at the same time-step but from a different viewpoint) are similar and how these snaps are different from snaps taken at a different time-step but same viewpoint. Further, these representations are integrated with the Reinforcement Learning (RL) framework to learn accurate behaviors from videos of humans performing the manipulation task. The effectiveness of this approach is illustrated by training the robots to learn various manipulation tasks i.e., (a) grab objects (b) lift objects (c) open and close drawers from expert demonstrations provided by humans. The algorithm shows great promise and is highly successful across all the manipulation tasks. The robot learns to pick up objects of various shapes, sizes and colors having different orientations and placements on the table. The robot also successfully learns how to open and close drawers. The method is highly sample efficient and addresses the challenges of embodiment, viewpoint, and domain difference.},
  archive      = {J_RAS},
  author       = {Rahul Choudhary and Rahee Walambe and Ketan Kotecha},
  doi          = {10.1016/j.robot.2022.104256},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104256},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Spatial and temporal features unified self-supervised representation learning networks},
  volume       = {157},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive ORB feature detection with a variable extraction
radius in RoI for complex illumination scenes. <em>RAS</em>,
<em>157</em>, 104248. (<a
href="https://doi.org/10.1016/j.robot.2022.104248">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature detection is a crucial technique for a vision navigation system to estimate robot pose according to natural landmarks. It is difficult for the existing feature detection techniques to balance the feature quality, processing time and robustness for a vision-based robot in complex workspaces. An adaptive Oriented fast and Rotated Brief (ORB) feature detection method with a variable extraction radius in Region of Interest (RoI) is proposed to deal with these problems. Firstly, the original camera image is processed by means of the Laplace transform of Gaussian (LTOG) pyramid and the grayscale centroid method, in order to obtain the rotation and scale invariance for ORB features. Then, a RoI segmenting technique is developed to locate the image areas that contain potential ORB features due to obvious grayscale variation. Thirdly, the ORB features are extracted in RoIs by using a set of variable-radius templates, adaptive to different illumination conditions . Finally, a number of feature detection and robot localization experiments are conducted on a vision-based robot prototype in different scenes under complex illumination. The experimental results verify that the RoI segmenting technique can correctly preserve the grayscale-varying regions to search ORB features with scattered distribution but excluding the irrelevant areas to suppress feature noises, while the variable-radius template extraction method can detect more feature inliers in complex workspaces. Therefore, our adaptive ORB method can outperform other commonly-used algorithms in accuracy, efficiency and robustness.},
  archive      = {J_RAS},
  author       = {Xing Wu and Chao Sun and Leisheng Chen and Ting Zou and Wei Yang and Haining Xiao},
  doi          = {10.1016/j.robot.2022.104248},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104248},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Adaptive ORB feature detection with a variable extraction radius in RoI for complex illumination scenes},
  volume       = {157},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Performance analysis and trajectory planning of
multi-locomotion mode ankle rehabilitation robot. <em>RAS</em>,
<em>157</em>, 104246. (<a
href="https://doi.org/10.1016/j.robot.2022.104246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A multi-locomotion mode ankle rehabilitation robot (MLMARR) based on the 2-UPU/RPU (U: universal; P: prismatic; R: revolute) parallel mechanism with actuators above the end effector is proposed. In addition to the rehabilitation training of the basic motion orientation of the ankle, the MLMARR enables up/down or back/forth traction rehabilitation training, ensuring the training of muscle groups and ligaments related to the ankle motion. First, degrees-of-freedom analysis is conducted based on the screw theory. Subsequently, using the closed-loop vector method and coordinate system rotation transformation, inverse position analysis is performed and the Jacobian matrix is described. In addition, three types of kinematic singularities are identified by analyzing the Jacobian matrix . Moreover, the workspace is determined by the limit boundary method. Three rehabilitation training modes are set and dynamic simulations are performed according to the ankle rehabilitation requirements; on this basis, the linear actuators can be selected reasonably. Finally, the effectiveness and accuracy of rehabilitation training are evaluated based on experimental data obtained using an MLMARR prototype. This research reveals the characteristics and superiority of the proposed MLMARR and offers the basis for the future improvement of the device.},
  archive      = {J_RAS},
  author       = {Ya Liu and Wenjuan Lu and Huafang Wu and Yici Xia and Bo Hu and Daxing Zeng},
  doi          = {10.1016/j.robot.2022.104246},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104246},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Performance analysis and trajectory planning of multi-locomotion mode ankle rehabilitation robot},
  volume       = {157},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). UAV-based persistent full area coverage with dynamic
priorities. <em>RAS</em>, <em>157</em>, 104244. (<a
href="https://doi.org/10.1016/j.robot.2022.104244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper tackles the problem of performing persistent and complete coverage of a target space with a minimum number of Unmanned Aerial Vehicles (UAVs). The UAVs are required to preferentially visit subareas of interest with higher frequency than the rest of the surveillance area within a predefined time threshold. A Minimum Spanning Tree based recursive algorithm is firstly proposed to estimate the upper bound of minimum number of UAVs for area coverage with visiting frequency constraints. Then an autonomous path planning strategy is proposed for persistent coverage, where a combinatorial priority function is designed as the goal assignment strategy and a modified Dijkstra algorithm is applied as the goal planning to obtain the optimum path. Finally, computer simulations have been conducted for the evaluation of the proposed solution, and the obtained results show that these algorithms can compute valid and sound solutions under different setups for the UAVs.},
  archive      = {J_RAS},
  author       = {Licheng Feng and Jay Katupitiya},
  doi          = {10.1016/j.robot.2022.104244},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104244},
  shortjournal = {Robot. Auton. Syst.},
  title        = {UAV-based persistent full area coverage with dynamic priorities},
  volume       = {157},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ECO-CPP: Energy constrained online coverage path planning.
<em>RAS</em>, <em>157</em>, 104242. (<a
href="https://doi.org/10.1016/j.robot.2022.104242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some robotic platforms are expected to perform coverage path planning (CPP) on a daily basis. However, at times they may be expected to perform CPP in large unknown spaces, which are not fully coverable with the onboard limited energy supply. In these cases the platforms need to revisit the charging station multiple times, increasing mission times and the total energy needed, reducing the availability of the robots. This paper proposes a novel solution to this energy constrained online coverage path planning problem , showing effectiveness of this solution in various settings. The proposed solution is based on contour following and outperforms existing work in the literature. Additionally, this work presents a new lower bound for the minimum number of charges and energy consumed for both, offline and online, energy constrained coverage path planning problems.},
  archive      = {J_RAS},
  author       = {Sedat Dogru and Lino Marques},
  doi          = {10.1016/j.robot.2022.104242},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104242},
  shortjournal = {Robot. Auton. Syst.},
  title        = {ECO-CPP: Energy constrained online coverage path planning},
  volume       = {157},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards real-time forest inventory using handheld LiDAR.
<em>RAS</em>, <em>157</em>, 104240. (<a
href="https://doi.org/10.1016/j.robot.2022.104240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While mobile LiDAR sensors are increasingly used to scan in ecology and forestry applications, reconstruction and characterization are typically carried out offline. Motivated by this, we present an online LiDAR system which is capable of running on a handheld device. Our system is capable of creating 3D point cloud reconstructions of large forest areas, segment and track individual trees, and create an inventory for the detected trees. Segments relating to each tree are accumulated over time, and tree models are completed as more scans are captured from different perspectives. The LiDAR scans are processed in an online fashion, and feedback can be provided to the operator via a screen mounted on the device. This allows the operator to ensure the desired area is mapped satisfactorily without any gaps or missing sections. We employ a pose-graph based SLAM system with loop closures to correct for drift errors allowing us to map large areas accurately. Our mapping system also provides multi-session capability where data captured during different runs can be automatically merged in a post-processing step. In this work, we estimate the Diameter at Breast Height (DBH) of individual trees as an example parameter for the forest inventory. The DBH is estimated online by fitting a cylinder to each tree trunk through a least-squares optimization within a RANSAC loop. We demonstrate our mapping approach operating in two different forests (both ecological and commercial) with the total travel distance spanning several kilometres. Further, we also provide experimental results comparing our DBH estimation to ground-truth measurements recorded manually in an ecological forest (Wytham Woods, Oxford). We demonstrate that our DBH estimates are within ∼ ∼ 7 cm accuracy for 90\% of individual trees detected in the dataset.},
  archive      = {J_RAS},
  author       = {Alexander Proudman and Milad Ramezani and Sundara Tejaswi Digumarti and Nived Chebrolu and Maurice Fallon},
  doi          = {10.1016/j.robot.2022.104240},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104240},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Towards real-time forest inventory using handheld LiDAR},
  volume       = {157},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A rapidly-exploring random trees approach to combined task
and motion planning. <em>RAS</em>, <em>157</em>, 104238. (<a
href="https://doi.org/10.1016/j.robot.2022.104238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Task and motion planning in robotics are typically addressed by separated intertwined methods. Task planners generate abstract high-level actions to be executed, while motion planners provide the associated discrete movements in the configuration space satisfying kinodynamic constraints. However, these two planning processes are strictly dependent, therefore the problem of combining task and motion planning with a uniform approach is very relevant. In this work, we tackle this issue by proposing a RRT-based method that addresses combined task and motion planning. Our approach relies on a combined metric space where both symbolic (task) and sub-symbolic (motion) spaces are represented. The associated notion of distance is then exploited by a RRT-based planner to generate a plan that includes both symbolic actions and feasible movements in the configuration space . The proposed method is assessed in several case studies provided by a real-world hospital logistic scenario, where an omni-directional mobile robot is involved in navigation and transportation tasks.},
  archive      = {J_RAS},
  author       = {Riccardo Caccavale and Alberto Finzi},
  doi          = {10.1016/j.robot.2022.104238},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104238},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A rapidly-exploring random trees approach to combined task and motion planning},
  volume       = {157},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ICACIA: An intelligent context-aware framework for COBOT in
defense industry using ontological and deep learning models.
<em>RAS</em>, <em>157</em>, 104234. (<a
href="https://doi.org/10.1016/j.robot.2022.104234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the world’s most advanced defense technologies are robots, and the defence industry is slowly moving toward including AI in the military robots they build. For these smart robots to make their own decisions about where to go and what to do, they need to be limited by several algorithms that run continuously and at the same time. Autonomy is the range of automated systems that can be adapted to a specific mission, residual risk , and level of team cohesion between humans and robots. Self-driving robotic systems should be collaborative, which means they should be able to interact actively with humans in a shared space or in proximity to humans and robots. Human–Robot Collaboration (HRC) works better when these COBOTs are aware of their surroundings. Mobile Robot (MR) teams whose perceptual and cognitive abilities are very well developed can help a lot with context awareness . To work well with humans, these robots should know what is going on with their human and other robot teammates so they can make decisions on their own. Also, robots should be able to share information about their surroundings so that humans can benefit from a better understanding of the situation. At the same time, humans should be able to see what the robots are doing. In this paper, we propose a knowledge-based framework for humans and robots to work together to understand the context of Defense missions. An ontological model of contexts for missions, agents, and situations; a knowledge base comprising all the tools necessary for a sort of situation; and an efficient and reliable method of collaborative learning are some of its main contributions. The framework works well in terms of how long it takes for people to talk to each other. As the team continues to expand, it can also easily manage communication challenges and a widely differing event frequency range.},
  archive      = {J_RAS},
  author       = {Arodh Lal Karn and Sudhakar Sengan and Ketan Kotecha and Irina V. Pustokhina and Denis A. Pustokhin and V. Subramaniyaswamy and Dharam Buddhi},
  doi          = {10.1016/j.robot.2022.104234},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104234},
  shortjournal = {Robot. Auton. Syst.},
  title        = {ICACIA: An intelligent context-aware framework for COBOT in defense industry using ontological and deep learning models},
  volume       = {157},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving MapReduce heterogeneous performance using KNN fair
share scheduling. <em>RAS</em>, <em>157</em>, 104228. (<a
href="https://doi.org/10.1016/j.robot.2022.104228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {MapReduce is one of the essential programming models for parallel processing and distributed storage of enormous data sets. The default Hadoop implementation assumes that the executing nodes are homogeneous. Data Locality is an important feature that Hadoop introduced to improve the performance of the traditional MapReduce model. The key idea is to move the map task closer to the node where the actual data resides rather than transferring the vast data set near the computation. Data Locality helps in lowering the network congestion and improving performance. However, this practice fails when processing the data in a heterogeneous Hadoop cluster. In a heterogeneous setup, nodes with different computational capabilities pose a crucial challenge. Nodes with a faster processing capacity finish the job compared to the nodes with slower processing ability. This paper proposes a KNN based scheduler that focuses on speculative prefetching and clustering of the data. The process starts with speculative prefetching and then performing the KNN clustering on the intermediate map output before directing it to the reducer for final processing. The performance evaluation of scheduler performance is analysed by executing different workloads like WordCount, RandomText, RandomNum, and Sort. The results show that the proposed idea improves the performance of job execution},
  archive      = {J_RAS},
  author       = {Khushboo Kalia and Saurav Dixit Post-Doc and Kaushal Kumar and Rajat Gera and Kirill Epifantsev and Vinod John and Natalia Taskaeva},
  doi          = {10.1016/j.robot.2022.104228},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104228},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Improving MapReduce heterogeneous performance using KNN fair share scheduling},
  volume       = {157},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Resolved viscoelasticity control for robust walking of a
humanoid with knee-stretched posture considering singularity.
<em>RAS</em>, <em>157</em>, 104218. (<a
href="https://doi.org/10.1016/j.robot.2022.104218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resolved viscoelasticity control (RVC) method resolves multiple viscoelasticities in the task-space, including the center of gravity viscoelasticity for balancing, into the joint-space viscoelasticity. We achieved robust and compliant motions using the RVC method. In previous studies, however, the conventional knee-bent posture was used to avoid kinematic singularity , suffering from large knee joint torque. In this study, we propose an extension of the RVC that can consider the kinematic singularity . Stable knee-stretched walking has been described using a humanoid with the RVC. Using simulations and experiments, we demonstrate that this RVC method allows for stable and human-like walking while considering the singularity, reducing the knee joint torque, and improving the energy efficiency.},
  archive      = {J_RAS},
  author       = {Ko Yamamoto and Kazuya Murotani and Tianyi Ko and Yoshihiko Nakamura},
  doi          = {10.1016/j.robot.2022.104218},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104218},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Resolved viscoelasticity control for robust walking of a humanoid with knee-stretched posture considering singularity},
  volume       = {157},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LiODOM: Adaptive local mapping for robust LiDAR-only
odometry. <em>RAS</em>, <em>156</em>, 104226. (<a
href="https://doi.org/10.1016/j.robot.2022.104226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decades, Light Detection And Ranging (LiDAR) technology has been extensively explored as a robust alternative for self-localization and mapping. These approaches typically state ego-motion estimation as a non-linear optimization problem dependent on the correspondences established between the current point cloud and a map, whatever its scope, local or global. This paper proposes LiODOM, a novel LiDAR-only ODOmetry and Mapping approach for pose estimation and map-building, based on minimizing a loss function derived from a set of weighted point-to-line correspondences with a local map abstracted from the set of available point clouds. Furthermore, this work places a particular emphasis on map representation given its relevance for quick data association . To efficiently represent the environment, we propose a data structure that combined with a hashing scheme allows for fast access to any section of the map. LiODOM is validated by means of a set of experiments on public datasets, for which it compares favourably against other solutions. Its performance on-board an aerial platform is also reported.},
  archive      = {J_RAS},
  author       = {Emilio Garcia-Fidalgo and Joan P. Company-Corcoles and Francisco Bonnin-Pascual and Alberto Ortiz},
  doi          = {10.1016/j.robot.2022.104226},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104226},
  shortjournal = {Robot. Auton. Syst.},
  title        = {LiODOM: Adaptive local mapping for robust LiDAR-only odometry},
  volume       = {156},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey of robot manipulation in contact. <em>RAS</em>,
<em>156</em>, 104224. (<a
href="https://doi.org/10.1016/j.robot.2022.104224">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this survey, we present the current status on robots performing manipulation tasks that require varying contact with the environment, such that the robot must either implicitly or explicitly control the contact force with the environment to complete the task. Robots can perform more and more manipulation tasks that are still done by humans, and there is a growing number of publications on the topics of (1) performing tasks that always require contact and (2) mitigating uncertainty by leveraging the environment in tasks that, under perfect information, could be performed without contact. The recent trends have seen robots perform tasks earlier left for humans, such as massage, and in the classical tasks, such as peg-in-hole, there is a more efficient generalization to other similar tasks, better error tolerance, and faster planning or learning of the tasks. Thus, in this survey we cover the current stage of robots performing such tasks, starting from surveying all the different in-contact tasks robots can perform, observing how these tasks are controlled and represented, and finally presenting the learning and planning of the skills required to complete these tasks.},
  archive      = {J_RAS},
  author       = {Markku Suomalainen and Yiannis Karayiannidis and Ville Kyrki},
  doi          = {10.1016/j.robot.2022.104224},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104224},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A survey of robot manipulation in contact},
  volume       = {156},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stackelberg game approach for resource allocation in
device-to-device communication with heterogeneous networks.
<em>RAS</em>, <em>156</em>, 104222. (<a
href="https://doi.org/10.1016/j.robot.2022.104222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Device-to-device communication is an enabling technology for direct connection between two or more devices/users without the intermediation of a base station (BS). In heterogeneous device-to-device networks, technology such as femtocell suggests advantages such as improving coverage area, spectral efficiency, and increased capacity. However, several challenging issues like interference, resource allocation, and power control strategies need to be addressed in the macrocell–femtocell-D2D heterogeneous network. This research presents a solution for resource allocation in D2D networks by proposing a Stackelberg game approach to increase network performance and throughput. The proposed study examines a framework for a two-leader multiple-followers Stackelberg game in which the leaders are macrocell base station (MBS) and femtocell base station (FBS), and the numerous followers are D2D pairings. Based on their mobility in the cell zone, D2D users are divided into three types Each leader and follower are designed with a different utility function. The paper is focused to minimize the interference in the system and maximize the system throughput. The game is solved to a Stackelberg equilibrium and ensures D2D communication continues with optimal transmit power. The assignment of resources among various contending users using the Hungarian algorithm . The proposed model is validated through simulations in MATLAB. The results show that the proposed model reduced the interference in the network and increased the throughput of the system in terms of price, transmit power and D2D rate.},
  archive      = {J_RAS},
  author       = {Roopsi Rathi and Saurav Dixit and Shweta Bansal and Kaushal Kumar and Natalia Taskaeva and Tumanov A.Yu. and Vinod John},
  doi          = {10.1016/j.robot.2022.104222},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104222},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Stackelberg game approach for resource allocation in device-to-device communication with heterogeneous networks},
  volume       = {156},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A computational design of robotic grasper by
intelligence-based topology optimization for microassembly and
micromanipulation. <em>RAS</em>, <em>156</em>, 104209. (<a
href="https://doi.org/10.1016/j.robot.2022.104209">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In robotic microassembly and micromanipulation , robotic grasper plays a vital role in picking up and releasing the product. However, the design synthesis method for creating a new robotic grasper has not deeply considered yet. Therefore, this article presents an effective computation method for designing a new robotic grasper that can be used for microassembly and micromanipulation . Firstly, a new structural scheme of robotic grasper is made by using the topology procedure. The compliance is the objective with the stress constraint during the topology. Then, a new variant of the grasper is refined where compliant joints are needed to reach the better compliance and the elastic motions of grasping hands. In the second phase, the modeling establishment for predicting the behaviors of the grasper are built via using the intelligent computation, namely GENFIS#1-neuro-fuzzy inference system (ANFIS), GENFIS#2-ANFIS, and GENFIS#3-ANFIS. The numerical data of the grasper are collected via the design of experiment-based finite element method . The results indicated that the GENFIS#3-ANFIS type is the best solver for modeling the hand’s stroke, the resonant frequency, and the strain energy. Meanwhile, the GENFIS#2-ANFIS type was the best procedure for modeling the stress. Subsequently, the optimum geometrical dimensions of the grasper are searched by using the Bonobo optimizer to improve the four mentioned performances of the grasper. In the circumstance #1, the results found that the hand’s displacement is about 0.0922 mm, the resonant frequency is 67.6247 Hz, the elastic energy is 1.4550 mJ, and the stress is 6.7249 MPa. The circumstance #2 determined the resonant frequency of 67.6247 Hz, the hand’s displacement of 0.0883 mm, the elastic energy of 1.9914 mJ, and the stress of 6.7086 MPa. Finally, the circumstance #3 found the elastic energy of 2.0501 mJ, the hand’s displacement of 0.0884 mm, the resonant frequency of 80.0012 Hz, and the stress of 6.7046 MPa. Statistically compared with the other methods, the presented method is the simple and effective procedure for designing 3D printed robotic grasper.},
  archive      = {J_RAS},
  author       = {Ngoc Thoai Tran and Minh Phung Dang and Alokesh Pramanik and Animesh Basak and S. Shankar and Dharam Buddhi and Thanh-Phong Dao},
  doi          = {10.1016/j.robot.2022.104209},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104209},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A computational design of robotic grasper by intelligence-based topology optimization for microassembly and micromanipulation},
  volume       = {156},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A unified lloyd-based framework for multi-agent collective
behaviours. <em>RAS</em>, <em>156</em>, 104207. (<a
href="https://doi.org/10.1016/j.robot.2022.104207">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Different authors have addressed a number of problems in the area of distributed control proposing convincing solutions to specific problems such as static coverage, dynamic coverage/exploration, rendezvous, flocking, formation control . However, a major limitation of problem-specific approaches is a fundamental lack of flexibility when the group meets unexpected conditions and has to change its goal on the fly. In this paper, we show that a large class of distributed control problems can be cast into a general framework based on the adoption of the Lloyd methodology. The adoption of a unified framework enables efficient solutions for the specific problems guaranteeing at the same time important safety and functional properties and a large degree of flexibility in the execution of group tasks. The paper sets the theoretical basis for this development and proves the efficacy of the proposed solutions through extensive simulations and experimental results.},
  archive      = {J_RAS},
  author       = {Manuel Boldrer and Luigi Palopoli and Daniele Fontanelli},
  doi          = {10.1016/j.robot.2022.104207},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104207},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A unified lloyd-based framework for multi-agent collective behaviours},
  volume       = {156},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A fully integrated system for hardware-accelerated TSDF SLAM
with LiDAR sensors (HATSDF SLAM). <em>RAS</em>, <em>156</em>, 104205.
(<a href="https://doi.org/10.1016/j.robot.2022.104205">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneous Localization and Mapping (SLAM) is one of the fundamental problems in autonomous robotics. Over the years, many approaches to solve this problem for 6D poses and 3D maps based on LiDAR sensors or depth cameras have been proposed. One of the main drawbacks of the solutions found in the literature is the required computational power and corresponding energy consumption. In this paper, we present an approach for LiDAR-based SLAM that maintains a global truncated signed distance function (TSDF) to represent the map. It is implemented on a System-On-Chip (SoC) with an integrated FPGA accelerator. The proposed system is able to track the position of state-of-the-art LiDARs in real time, while maintaining a global TSDF map that can be used to create a polygonal map of the environment. We show that our implementation delivers competitive results compared to state-of-the-art algorithms while drastically reducing the power consumption compared to classical CPU or GPU-based methods.},
  archive      = {J_RAS},
  author       = {Marc Eisoldt and Julian Gaal and Thomas Wiemann and Marcel Flottmann and Marc Rothmann and Marco Tassemeier and Mario Porrmann},
  doi          = {10.1016/j.robot.2022.104205},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104205},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A fully integrated system for hardware-accelerated TSDF SLAM with LiDAR sensors (HATSDF SLAM)},
  volume       = {156},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Safe motion planning with environment uncertainty.
<em>RAS</em>, <em>156</em>, 104203. (<a
href="https://doi.org/10.1016/j.robot.2022.104203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an approach for safe motion planning under robot state and environment (obstacle and landmark location) uncertainties. To this end, we first develop an approach that accounts for the landmark uncertainties during robot localization . Existing planning approaches assume that the landmark locations are well known or are known with little uncertainty. However, this might not be true in practice. Noisy sensors and imperfect motions compound to the errors originating from the estimate of environment features. Moreover, possible occlusions and dynamic objects in the environment render imperfect landmark estimation. Consequently, not considering this uncertainty can wrongly localize the robot, leading to inefficient plans. Our approach thus incorporates the landmark uncertainty within the Bayes filter estimation framework. We also analyze the effect of considering this uncertainty and delineate the conditions under which it can be ignored. Second, we extend the state-of-the-art by computing an exact expression for the collision probability under Gaussian distributed robot motion, perception and obstacle location uncertainties. We formulate the collision probability process as a quadratic form in random variables . Under Gaussian distribution assumptions, an exact expression for collision probability is thus obtained which is computable in real-time. In contrast, existing approaches approximate the collision probability using upper-bounds that can lead to overly conservative estimate and thereby suboptimal plans. We demonstrate and evaluate our approach using a theoretical example and simulations. We also present a comparison of our approach to different state-of-the-art methods.},
  archive      = {J_RAS},
  author       = {Antony Thomas and Fulvio Mastrogiovanni and Marco Baglietto},
  doi          = {10.1016/j.robot.2022.104203},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104203},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Safe motion planning with environment uncertainty},
  volume       = {156},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An inertial human upper limb motion tracking method for
robot programming by demonstration. <em>RAS</em>, <em>156</em>, 104201.
(<a href="https://doi.org/10.1016/j.robot.2022.104201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an inertial human motion tracking for robot programming by demonstration (PbD). An original element called heading reset is proposed to catch the drift around gravity direction. It is based on a hypothesis made on the human arm motion during a task demonstration. It is used to overcome the non-use of the magnetometer due to magnetic disturbances from robotic environment. This element is implemented in an orientation estimation algorithm and compared with three other IMU algorithms and a commercial MARG algorithm. The human arm trajectory is estimated through three IMUs sensors directly set on the arm to estimate the segment orientation (hand, forearm and arm). A specific inertial-2-segment procedure is presented as well as a procedure to estimate the transformation from human reference frame to task frame, necessary for a PbD process. Experimental tests, using a robot as a reference, have been conducted to validate the different part of the method. The heading reset and the orientation algorithm show good results. The inertial-2-segment procedure is shown to be robust. Finally, experimental tests on a human arm and physical robot validate the complete method.},
  archive      = {J_RAS},
  author       = {Robin Pellois and Olivier Brüls},
  doi          = {10.1016/j.robot.2022.104201},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104201},
  shortjournal = {Robot. Auton. Syst.},
  title        = {An inertial human upper limb motion tracking method for robot programming by demonstration},
  volume       = {156},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Structural optimization of a rotary joint by hybrid method
of FEM, neural-fuzzy and water cycle–moth flame algorithm for robotics
and automation manufacturing. <em>RAS</em>, <em>156</em>, 104199. (<a
href="https://doi.org/10.1016/j.robot.2022.104199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rotary joint is used in robotic arm for mobility aids and rehabilitation device. The rotary joint often requires a compactness, a lightness, and a large load capacity in robotics as well as automation manufacturing. However, the experience-based design methods take a lot of time, finances, and human resources to achieve the mentioned multiple functions. To overcome the above difficulties, the article proposes a new design technique to solve the structural optimization for the rotary joint. The proposed optimization technique is formed by topology method, analysis of variance, finite element method , adaptive neuro-fuzzy inference system model, and water cycle moth-flame optimization algorithm . A new rotary joint is designed via the topology optimization . The adaptive neuro-fuzzy inference system is optimized by Taguchi technique to enhance the modeling accuracy. The geometry of the joint is optimized by the water cycle moth-flame optimization algorithm . The results found that the rotary joint can stand a torque of 357.46 N.mm with the equivalent stress up to 489.98 MPa. The difference between the optimal prediction results and simulations are 0.27\% and 0.58\% for the moment reaction and the equivalent stress, respectively. The small error proves the developed hybrid method has a high reliability.},
  archive      = {J_RAS},
  author       = {Ngoc Le Chau and Minh Phung Dang and Chander Prakash and Dharam Buddhi and Thanh-Phong Dao},
  doi          = {10.1016/j.robot.2022.104199},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104199},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Structural optimization of a rotary joint by hybrid method of FEM, neural-fuzzy and water cycle–moth flame algorithm for robotics and automation manufacturing},
  volume       = {156},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel stereo image self-inpainting network for autonomous
robots. <em>RAS</em>, <em>156</em>, 104197. (<a
href="https://doi.org/10.1016/j.robot.2022.104197">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, vision-based methods have exhibited promising prospects in assigning autonomous robots more capabilities for better environment perception. Since visual sensors are easily affected under extreme conditions, current image inpainting methods based on CNNs jointly with generative adversarial networks (GANs) usually generate patches quite different from the ground truth (GT), which is harmful to autonomous robots. In this paper, we propose a novel multiscale feature alignment module with an early fusion strategy to align the left and right feature maps to better capture the motion cues between them. Then, the aligned features are fused to fill holes in the left image. To aggregate the multiscale feature maps dynamically, we propose a multiscale feature aggregation module based on an attention mechanism , of which the fusion module is designed as a symmetrical architecture to adaptively incorporate the complementary contextual correlations from different feature branches. In addition, a spatial attention module able to capture the correlations among pixels is introduced into our network to enhance the inpainting capacity and generate more refined details. To evaluate the effectiveness of our proposed method, many experiments are conducted on a stereo image dataset. The quantitative and qualitative results show that our method significantly outperforms the recent state-of-the-art image inpainting methods while running over 22 fps on a single NVIDIA RTX2080Ti GPU .},
  archive      = {J_RAS},
  author       = {Xiaokang Yang and Hengyu Li and Jingyi Liu and Yonghao Xie and Huayan Pu and Shaorong Xie and Jun Luo},
  doi          = {10.1016/j.robot.2022.104197},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104197},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A novel stereo image self-inpainting network for autonomous robots},
  volume       = {156},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Continuous mapping of large surfaces with a quality
inspection robot. <em>RAS</em>, <em>156</em>, 104195. (<a
href="https://doi.org/10.1016/j.robot.2022.104195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of mapping large surfaces with a moving sensor. In particular, it proposes image registration and mapping algorithms that enable to use in continuous motion sensors that need multiple shots to perform a measurement. These methods exploit the knowledge of the shape of the part to inspect in a both efficient and accurate fashion, thus allowing to obtain a measurement quality comparable to that of static measurements, while guaranteeing fast sensor motion and thus short scanning times. This work describes the application of these methods for the mapping of carbon fibre parts with an inspection robot equipped with a sensor estimating 3D carbon fibre orientation from multiple 2D images captured with different illumination. Experiments on carbon fibre preforms of complex 3D shape demonstrates that this system accurately reconstructs in real-time the 3D fibre orientations of the outer layer of carbon fibre parts. Accuracy assessments report small errors within the tolerances allowed by the automotive industry on flat and generic 3D surfaces. The inspection robot system presented in this paper has been demonstrated both as an in-line quality inspection robot for production of carbon fibre preforms and as a measurement device for improving the draping process in the prototyping of carbon fibre parts.},
  archive      = {J_RAS},
  author       = {Matteo Munaro and Morris Antonello and Mauro Antonello and Emanuele Menegatti},
  doi          = {10.1016/j.robot.2022.104195},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104195},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Continuous mapping of large surfaces with a quality inspection robot},
  volume       = {156},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on the design and evolution of social robots —
past, present and future. <em>RAS</em>, <em>156</em>, 104193. (<a
href="https://doi.org/10.1016/j.robot.2022.104193">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the relatively young age of Human–Robot Interaction (HRI) as a field, there is a large volume of research on advances in robot hardware, software and behavior. The goal of this article is to survey trends in social robot design , to provide an evidence-based approach and guidelines that can inform future social robot development. To this end, this article systematically reviews the evolution of social robots with a focus on their applications, technical features and design. In total 9920 articles from ACM Digital Library (n=4223) and IEEE Explore (n=5697) were reviewed. In order to make this review as inclusive as possible, a broad definition of social robots was used to make decisions about inclusion/exclusion of a given social robot during the review process. As a result, a total of 344 social robots were examined in the review with features being embodiment, mobility, total number of degrees of freedom, existence of a manipulator, size, weight, shell build, applications, target user group , commercial availability, social software capabilities, sensors, interaction modalities, face, software extension capability and initial release year. This resulted in a rich dataset with detailed information about the social robots used in the HRI field. We also provide design guidelines for social robots to inform future research. Findings of this review may help both researchers &amp; practitioners to select, and/or design, the best social robot for their particular experiment or application scenario.},
  archive      = {J_RAS},
  author       = {Hamza Mahdi and Sami Alperen Akgun and Shahed Saleh and Kerstin Dautenhahn},
  doi          = {10.1016/j.robot.2022.104193},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104193},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A survey on the design and evolution of social robots — past, present and future},
  volume       = {156},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Human–cobot interaction fluency and cobot operators’ job
performance. The mediating role of work engagement: A survey.
<em>RAS</em>, <em>155</em>, 104191. (<a
href="https://doi.org/10.1016/j.robot.2022.104191">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced human–robot interaction becomes an essential resource in Industry 4.0 . Specifically, the deployment of collaborative robots (cobots) has changed the game in modern smart factories. These robotic agents assist human operators, working with them side-by-side on joint task execution. Because cobots are designed to be more co-workers than tools, fluent interaction between the operators and their robotic counterparts is critical for employees’ task accomplishment and, thus, high performance. The current study investigates the relationships between four perspectives of human–robot interaction fluency (i.e., the human emotions-oriented, the human contribution-oriented, the robot-oriented, and the team-oriented fluency) and operators’ subjective job performance. It also examines the mediating role of work engagement in these relationships. The analysis carried out on 190 male and female cobot operators working on the shop floor showed positive associations between human–robot interaction (HRI) fluency and job performance. The study confirmed the mediating role of work engagement in the relationships of human contribution-oriented fluency and team-oriented fluency with job performance. The obtained results suggest that HRI fluency relates to employee job performance because of the positive affective–cognitive state experienced by the operator when cooperating with a cobot in a coordinated and well-synchronized manner. The findings of the study are discussed within the theoretical framework of cognitive ergonomics , the Job Demand-Control-Support model, the job demands-resources model, and the job design perspective. The article finishes with a conclusion of the results and implications for organizational practice.},
  archive      = {J_RAS},
  author       = {Mateusz Paliga},
  doi          = {10.1016/j.robot.2022.104191},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104191},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Human–cobot interaction fluency and cobot operators’ job performance. the mediating role of work engagement: A survey},
  volume       = {155},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhanced calibration of camera setups for high-performance
visual odometry. <em>RAS</em>, <em>155</em>, 104189. (<a
href="https://doi.org/10.1016/j.robot.2022.104189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For robots and autonomous system that rely on visual data for operating in the real world, camera calibration is an indispensable step as it relates image information to the geometric structure of the 3D world. Although it is convenient to consider a several decades old problem as something that is swiftly solvable with a dedicated toolbox, we should still push calibration methods to their practical limits in order to gain valuable insights, and especially when robots are operating in circumstances that concern human safety. In this paper we propose a camera setup calibration procedure with emphasis on visual odometry accuracy. We focus on target-based calibration and two popular datasets are used for evaluating visual odometry and SLAM algorithms, namely the EuRoC and KITTI datasets. Our procedure consists of: (i) introducing a novel highly accurate corner detection algorithm robust to challenging illumination conditions , (ii) investigating different lens distortion models, (iii) incorporating static and dynamic board deformation models , (iv) ex-post analysis of reprojection error sensitivity and calibration parameter uncertainty, and (v) grid search method based on odometry accuracy when board poses do not constrain calibration parameters well enough. The whole process significantly reduced the reprojection error when calibrating the camera setups of the EuRoC and KITTI datasets. We tested four different odometries, namely SOFT, ORB-SLAM2, VINS-FUSION, and VISO2—all four showed higher accuracy with the proposed calibration parameters. Moreover, with the proposed calibration method our SOFT2 scored 0.53\% in translation and 0.0009 deg/m in rotation error rendering it currently the highest ranking algorithm on the KITTI scoreboard.},
  archive      = {J_RAS},
  author       = {Igor Cvišić and Ivan Marković and Ivan Petrović},
  doi          = {10.1016/j.robot.2022.104189},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104189},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Enhanced calibration of camera setups for high-performance visual odometry},
  volume       = {155},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A constraint embedding approach for dynamics modeling of
parallel kinematic manipulators with hybrid limbs. <em>RAS</em>,
<em>155</em>, 104187. (<a
href="https://doi.org/10.1016/j.robot.2022.104187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parallel kinematic manipulators (PKM) are characterized by closed kinematic loops, due to the parallel arrangement of limbs but also due to the existence of kinematic loops within the limbs. Moreover, many PKM are built with limbs constructed by serially combining kinematic loops. Such limbs are called hybrid , which form a particular class of complex limbs. Design and model-based control requires accurate dynamic PKM models desirably without model simplifications. Dynamics modeling then necessitates kinematic relations of all members of the PKM, in contrast to the standard kinematics modeling of PKM, where only the forward and inverse kinematics solution for the manipulator (relating input and output motions) are computed. This becomes more involved for PKM with hybrid limbs. In this paper a modular modeling approach is employed, where limbs are treated separately, and the individual dynamic equations of motions (EOM) are subsequently assembled to the overall model. Key to the kinematic modeling is the constraint resolution for the individual loops within the limbs. This local constraint resolution is a special case of the general constraint embedding technique. The proposed method finally allows for a systematic modeling of general PKM. The method is demonstrated for the IRSBot-2, where each limb comprises two independent loops.},
  archive      = {J_RAS},
  author       = {Andreas Müller},
  doi          = {10.1016/j.robot.2022.104187},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104187},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A constraint embedding approach for dynamics modeling of parallel kinematic manipulators with hybrid limbs},
  volume       = {155},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Strategies for large scale elastic and semantic LiDAR
reconstruction. <em>RAS</em>, <em>155</em>, 104185. (<a
href="https://doi.org/10.1016/j.robot.2022.104185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents novel strategies for spawning and fusing submaps within an elastic dense 3D reconstruction system. The proposed system uses spatial understanding of the scanned environment to control memory usage growth by fusing overlapping submaps in different ways. This allows the number of submaps and memory consumption to scale with the size of the environment rather than the duration of exploration. By analysing spatial overlap and semantic information, our system segments distinct spaces on-the-fly during exploration, such as rooms, stairwells, and indoor–outdoor transitions. The proposed system associates semantically labelled submaps with poses of SLAM pose graph to enable global elasticity. A probabilistic model to merge the voxel labels of the different submaps is incorporated to ensure correct semantic submap fusion when SLAM loop closures occur. Additionally, we present a new mathematical formulation of relative uncertainty between poses to improve the global consistency of the reconstruction. Performance is demonstrated using experiments exploring multi-floor multi-room indoor environments, indoor–outdoor transitions and large-scale outdoor experiments. Relative to our baseline, the presented approach demonstrates improved scalability and accuracy.},
  archive      = {J_RAS},
  author       = {Yiduo Wang and Milad Ramezani and Matias Mattamala and Sundara Tejaswi Digumarti and Maurice Fallon},
  doi          = {10.1016/j.robot.2022.104185},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104185},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Strategies for large scale elastic and semantic LiDAR reconstruction},
  volume       = {155},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Talk-to-resolve: Combining scene understanding and spatial
dialogue to resolve granular task ambiguity for a collocated robot.
<em>RAS</em>, <em>155</em>, 104183. (<a
href="https://doi.org/10.1016/j.robot.2022.104183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The utility of collocating robots largely depends on the easy and intuitive interaction mechanism with the human. If a robot accepts task instruction in natural language, first, it has to understand the user’s intention by decoding the instruction. However, while executing the task, the robot may face unforeseeable circumstances due to the variations in the observed scene and therefore requires further user intervention. In this article, we present a system called Talk-to-Resolve (TTR) that enables a robot to initiate a coherent dialogue exchange with the instructor by observing the scene visually to resolve the impasse. Through dialogue, it either finds a cue to move forward in the original plan, an acceptable alternative to the original plan, or affirmation to abort the task altogether. To realize the possible stalemate, we utilize the dense captions of the observed scene and the given instruction jointly to compute the robot’s next action. We evaluate our system based on a data set of initial instruction and situational scene pairs. Our system can identify the stalemate and resolve them with appropriate dialogue exchange with 82\% accuracy. Additionally, a user study reveals that the questions from our systems are more natural (4.02 on average on a scale of 1 to 5) as compared to a state-of-the-art (3.08 on average).},
  archive      = {J_RAS},
  author       = {Pradip Pramanick and Chayan Sarkar and Snehasis Banerjee and Brojeshwar Bhowmick},
  doi          = {10.1016/j.robot.2022.104183},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104183},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Talk-to-resolve: Combining scene understanding and spatial dialogue to resolve granular task ambiguity for a collocated robot},
  volume       = {155},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An incremental cross-modal transfer learning method for
gesture interaction. <em>RAS</em>, <em>155</em>, 104181. (<a
href="https://doi.org/10.1016/j.robot.2022.104181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gesture can be used as an important way for human–robot interaction, since it is able to give accurate and intuitive instructions to the robots. Various sensors can be used to capture gestures. We apply three different sensors that can provide different modalities in recognizing human gestures. Such data also owns its own statistical properties for the purpose of transfer learning : they own the same labeled data, but both the source and the validation data-sets have their own statistical distributions. To tackle the transfer learning problem across different sensors with such kind of data-sets, we propose a weighting method to adjust the probability distributions of the data, which results in a more faster convergence result. We further apply this method in a broad learning system, which has proven to be efficient to learn with the incremental learning capability. The results show that although these three sensors measure different parts of the body using different technologies, transfer learning is able to find out the weighting correlation among the data-sets. It also suggests that using the proposed transfer learning is able to adjust the data which has different distributions which may be similar to the physical correlation between different parts of the body in the context of giving gestures.},
  archive      = {J_RAS},
  author       = {Junpei Zhong and Jie Li and Ahmad Lotfi and Peidong Liang and Chenguang Yang},
  doi          = {10.1016/j.robot.2022.104181},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104181},
  shortjournal = {Robot. Auton. Syst.},
  title        = {An incremental cross-modal transfer learning method for gesture interaction},
  volume       = {155},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Loop-aware exploration graph: A concise representation of
environments for exploration and active loop-closure. <em>RAS</em>,
<em>155</em>, 104179. (<a
href="https://doi.org/10.1016/j.robot.2022.104179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous robots must have the ability to build an accurate map of an unknown environment by fully covering it in an exploration task. Several exploration approaches combine a Simultaneous Localization and Mapping (SLAM) technique with a strategy to move the robot through the environment actively looking for loops to be closed. When closing a loop, the robot revisits a previously mapped area, which allows it to reduce the uncertainty about its pose. In this paper, we present a concise environment representation named Loop-Aware Exploration Graph (LAEG). The LAEG’s nodes represent the essential information to the exploration process, such as the robot’s position and the frontiers of two different kinds, while the LAEG’s edges are the connections between these elements. Furthermore, the LAEG uses a specific type of edge to explicitly represent the predicted loops, facilitating the incorporation of this information into the exploration decision process. We also present an exploration approach that relies on the LAEG to make the decisions. Consequently, our approach maximizes the chances of closing a loop when choosing the next region to be explored, which is eased by the LAEG that represents the predicted loops as edges. The effectiveness of the proposed exploration approach was evaluated through experiments in five environments, comparing it with a greedy approach that only chases the most attractive unknown region and another one that makes the robot actively look for loop-closures.},
  archive      = {J_RAS},
  author       = {Diego Pittol and Mathias Mantelli and Renan Maffei and Mariana Kolberg and Edson Prestes},
  doi          = {10.1016/j.robot.2022.104179},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104179},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Loop-aware exploration graph: A concise representation of environments for exploration and active loop-closure},
  volume       = {155},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). User feedback and remote supervision for assisted living
with mobile robots: A field study in long-term autonomy. <em>RAS</em>,
<em>155</em>, 104170. (<a
href="https://doi.org/10.1016/j.robot.2022.104170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an ageing society, the at-home use of Socially Assistive Robots (SARs) could provide remote monitoring of their users’ well-being, together with physical and psychological support. However, private home environments are particularly challenging for SARs, due to their unstructured and dynamic nature which often contributes to robots’ failures. For this reason, even though several prototypes of SARs for elderly care have been developed, their commercialisation and wide-spread at-home use are yet to be effective. In this paper, we analyse how including the end users’ feedback impacts the SARs reliability and acceptance. To do so, we introduce a Monitoring and Logging System (MLS) for remote supervision, which increases the explainability of SAR-based systems deployed in older adults’ apartments, while also allowing the exchange of feedback between caregivers, technicians, and older adults. We then present an extensive field study showing how long-term deployment of autonomous SARs can be accomplished by relying on such a feedback loop to address any potential issue. To this end, we provide the results obtained in a 130-week long study where autonomous SARs were deployed in the apartments of 10 older adults, with the aim of possibly serving and assisting future practitioners, with the knowledge collected from this extensive experimental campaign, to fill the gap that currently exists for the widespread adoption of SARs.},
  archive      = {J_RAS},
  author       = {Matteo Luperto and Marta Romeo and Javier Monroy and Jennifer Renoux and Alessandro Vuono and Francisco-Angel Moreno and Javier Gonzalez-Jimenez and Nicola Basilico and N. Alberto Borghese},
  doi          = {10.1016/j.robot.2022.104170},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104170},
  shortjournal = {Robot. Auton. Syst.},
  title        = {User feedback and remote supervision for assisted living with mobile robots: A field study in long-term autonomy},
  volume       = {155},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dataset collection from a SubT environment. <em>RAS</em>,
<em>155</em>, 104168. (<a
href="https://doi.org/10.1016/j.robot.2022.104168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a dataset collected from the subterranean (SubT) environment with a current state-of-the-art sensors required for autonomous navigation . The dataset includes sensor measurements collected with RGB, RGB-D, event-based and thermal cameras, 2D and 3D lidars, inertial measurement unit (IMU), and ultra wideband (UWB) positioning systems which are mounted on the mobile robot. The overall sensor setup will be referred further in the article as a data collection platform. The dataset contains synchronized raw data measurements from all the sensors in the robot operating system (ROS) message format and video feeds collected with action and 360 cameras. A detailed description of the sensors embedded into the data collection platform and a data collection process are introduced. The collected dataset is aimed for evaluating navigation, localization and mapping algorithms in SubT environments. This article is accompanied with the public release of all collected datasets from the SubT environment. Link: Dataset},
  archive      = {J_RAS},
  author       = {Anton Koval and Samuel Karlsson and Sina Sharif Mansouri and Christoforos Kanellakis and Ilias Tevetzidis and Jakub Haluska and Ali-akbar Agha-mohammadi and George Nikolakopoulos},
  doi          = {10.1016/j.robot.2022.104168},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104168},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Dataset collection from a SubT environment},
  volume       = {155},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Vehicle motion segmentation via combining neural networks
and geometric methods. <em>RAS</em>, <em>155</em>, 104166. (<a
href="https://doi.org/10.1016/j.robot.2022.104166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motion segmentation is important for autonomous robots’ activities in dynamic scenes, which has been a challenging problem due to the dual motion caused by the camera and moving objects. The existing methods based on the optical or scene flow are sensitive to the environment, whereas deep learning-based methods commonly do not consider geometric constraints . Aiming at a vehicle, as the most common object in outdoor urban dynamic scenes because other objects, such as people, can be almost directly determined as a moving object, this paper proposes an object-level motion segmentation method for multiple moving objects combining geometric methods and deep learning . First, we choose three kinds of learned information, constructing object-level three-dimensional (3D) scene structure. And then, to infer motion segmentation results from learned information, we propose an instance cross-matching method to obtain instance correspondence and a motion segmentation extraction method based on instance reprojection residual to determine whether the objects are moving or not. The proposed approach is simple and direct, and it can obtain vehicle motion segmentation results from the original RGB images without using the optical or scene flow commonly used to extract motion information. Experiments on public motion segmentation datasets demonstrate that the proposed method can effectively improve the performance of vehicle motion segmentation and is superior to the most advanced methods in terms of accuracy.},
  archive      = {J_RAS},
  author       = {Min Yue and Guangyuan Fu and Ming Wu and Yuqing Zhao and Shaolei Zhang},
  doi          = {10.1016/j.robot.2022.104166},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104166},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Vehicle motion segmentation via combining neural networks and geometric methods},
  volume       = {155},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Compact lightweight magnetic gripper designed for biped
climbing robots based on coaxial rotation of multiple magnets.
<em>RAS</em>, <em>155</em>, 104164. (<a
href="https://doi.org/10.1016/j.robot.2022.104164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biped climbing robots can move and work in three-dimensional steel structures, but are extremely sensitive to the weight, size, and adsorption performance of the devices attached at both their ends. Herein, we propose a novel gripper for biped climbing robots comprising two layers of multiple fan-shaped permanent magnets, wherein the upper layer can coaxially rotate with respect to the lower layer. The novel magnetic gripper can switch between the release and adsorption states by rotating the upper layer of magnets to a particular angle, and it can approximately linearly control the adsorption force by varying this rotation angle . The structural parameters and layout of the magnets were studied and optimized, and the adsorption characteristics of the gripper were analyzed via simulations and verified via experiments. Additionally, the proposed magnetic gripper was applied in a biped climbing robot for verifying the effectiveness of the design based on three climbing tests. The results revealed that the proposed magnetic gripper outperformed the existing models in terms of adsorption force to mass ratio. The proposed gripper design offers the advantages of compact structure, simple control, and natural self-locking of the release and adsorption states.},
  archive      = {J_RAS},
  author       = {Haifei Zhu and Zidong Lin and Jingyu Yan and Pengcheng Ye and Weixin Zhang and Shixin Mao and Yisheng Guan},
  doi          = {10.1016/j.robot.2022.104164},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104164},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Compact lightweight magnetic gripper designed for biped climbing robots based on coaxial rotation of multiple magnets},
  volume       = {155},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Slope walking of humanoid robot without IMU sensor on an
unknown slope. <em>RAS</em>, <em>155</em>, 104163. (<a
href="https://doi.org/10.1016/j.robot.2022.104163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is significantly challenging to develop biped robots, such as a humanoid robot , that can walk stably in complex environments, such as a rough terrain or slope. Additionally, various kinds of sensors are required. Force and torque (FT) and inertial measurement unit (IMU) sensors are necessary for a humanoid robot to achieve stable biped walking, and it is especially difficult to realize such locomotion without an IMU sensor in complex environments, such as a slope. Therefore, a new walking algorithm is needed so that a humanoid robot is able to walk well on a slope, even if the IMU sensor is damaged. This paper proposes a slope observer that can estimate the angle of the robot, angular velocity , and slope angle without an IMU sensor, as well as a controller for posture control and stabilization on a slope. The slope observer was developed based on a disturbance observer that can estimate the angle of the robot, angular velocity , and disturbance applied to the robot using only an FT sensor. The controller was designed as state feedback control based on the slope observer. Furthermore, the posture control was designed considering the slope angle such that the robot can always stand upright on the slope. The proposed slope observer and controller were verified with certain experiments performed in the lab, and the walking experiment of a real humanoid robot RoK-3 performed on the unknown slope. [ https://youtu.be/x1PlzktlOpM ]},
  archive      = {J_RAS},
  author       = {Yun-Ho Han and Baek-Kyu Cho},
  doi          = {10.1016/j.robot.2022.104163},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104163},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Slope walking of humanoid robot without IMU sensor on an unknown slope},
  volume       = {155},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic aesthetics assessment of robotic dance motions.
<em>RAS</em>, <em>155</em>, 104160. (<a
href="https://doi.org/10.1016/j.robot.2022.104160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human dancers can understand and judge the aesthetics of their own dance motions from their movement perception. Inspired by this, we propose a novel mechanism of automatic aesthetics assessment of robotic dance motions, which is based on ensemble learning aimed at developing the autonomous judgment ability of robots. In the proposed mechanism, key pose descriptors based higher-order clustering features are designed to characterize robotic dance motion. Then, an ensemble classifier is built to train a machine aesthetics model for the automatic aesthetics assessment on robotic dance motions. The proposed mechanism has been implemented on a simulated robot environment, and experimental results show its feasibility and good performance.},
  archive      = {J_RAS},
  author       = {Hua Peng and Jing Li and Huosheng Hu and Keli Hu and Liping Zhao and Chao Tang},
  doi          = {10.1016/j.robot.2022.104160},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104160},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Automatic aesthetics assessment of robotic dance motions},
  volume       = {155},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Development of an autonomous fog computing platform using
control-theoretic approach for robot-vision applications. <em>RAS</em>,
<em>155</em>, 104158. (<a
href="https://doi.org/10.1016/j.robot.2022.104158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the dynamic modelling and linear matrix inequality (LMI) based controller design of a distributed fog computing framework for real-time robot vision applications. A mobile robot vision system acquires the images from an application environment such as a warehouse, where articles are stacked in numerous racks. We characterise the mobile robot vision data (MRVD) using frames per second (FPS) and the image resolution. From the MRVD, object detection is performed by an open-source deep learning (DL) platform for detecting and localising various objects. However, with higher FPS together with high-resolution images, the processing time by the DL algorithm increases significantly. This necessitates the deployment of a distributed computing platform with several computing nodes. In this work, we deploy a distributed fog computing environment (DFCE) for the real-time object detection in an application environment. The processing time required to handle the MRVD is called the service time. However, for efficient auto-scaling performance, the mathematical model of the DFCE, taking into consideration the characteristics of the MRVD is necessary. In this context, we envisage the application of control theory to build the dynamic model of the DFCE. A Linear Parameter Varying (LPV) model is proposed for the DFCE with the service time as the output, the number of fog nodes as the input, and the characteristics of MRVD as the time-varying parameters. At first, an LPV model for the DFCE is derived using system identification, and the model is validated using the real-time test data. The LPV model is converted to a Polytopic LPV (PLPV) model for LMI based controller design . Finally, we develop and validate a Linear Matrix Inequality (LMI) based LPV controller to meet the service time constraints for a given application environment. For localisation and trajectory tracking with obstacle avoidance in the application environment, the mobile robot implements an Extended Kalman Filter (EKF) based simultaneous localisation and mapping (SLAM) and a bug-based path planning algorithm respectively. Finally, we present, detailed controller validation results illustrating the mobile robot navigation together with the auto-scaling control for the fog computing platform to modulate the service time.},
  archive      = {J_RAS},
  author       = {Dinsha Vinod and P.S. SaiKrishna},
  doi          = {10.1016/j.robot.2022.104158},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104158},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Development of an autonomous fog computing platform using control-theoretic approach for robot-vision applications},
  volume       = {155},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A local reactive steering law for 2D collision avoidance
with curvature constraints and constant speed. <em>RAS</em>,
<em>155</em>, 104156. (<a
href="https://doi.org/10.1016/j.robot.2022.104156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motion planning algorithms for dynamic environments that explicitly take into account actuator constraints require a lot of computational effort due to replanning or optimizing trajectories. This makes them limited in use, especially for autonomous reactive behaviors that need to be computed on-board. Motivated by this need, we present a new real-time method for reactive collision avoidance for systems with bounded curvature in static and dynamic environments. Our approach relies on the implementation of a local steering law that satisfies a predefined bound on path curvature . The steering law depends on a user-defined parametric function that determines the transition between obstacle-free motion and collision avoidance by enforcing an obstacle impenetrability constraint. As such, we propose a systematic procedure which modulates the velocity vector to enforce curvature constraints in complex 2D environments characterized by static and moving obstacles. We provide theoretical guarantees for collision avoidance and we demonstrate this methodology through simulations.},
  archive      = {J_RAS},
  author       = {Andrei Marchidan and Efstathios Bakolas},
  doi          = {10.1016/j.robot.2022.104156},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104156},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A local reactive steering law for 2D collision avoidance with curvature constraints and constant speed},
  volume       = {155},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generation of co-speech gestures of robot based on morphemic
analysis. <em>RAS</em>, <em>155</em>, 104154. (<a
href="https://doi.org/10.1016/j.robot.2022.104154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a methodology for a robot to automatically generate felicitous co-speech gestures corresponding to robot utterances. First, the proposed method determines the part of a given robot utterance, where the robot makes a gesture by doing a morphemic analysis on the sentence of utterance. The part is herein called an expression unit . The method then predicts a gesture type to characterize the expression unit in the sense of conveying thoughts and feelings. The gesture type is selected from the four types of iconic, metaphoric, beat, and deictic categorized by McNeill by performing morphemic analysis on the sentence. A gesture proper to the gesture type is retrieved from a database of motion primitives that are built with predefined a limited number of words. For retrieving, Word2Vec is applied to estimate word similarity between the predefined words in the database and words in the expression unit such that the method can deal with an arbitrary sentence and generate an appropriate gesture for similar words in meaning. The proposed method showed 83\% accuracy in determining expression units and gesture types for a set of sentences in Korean. Furthermore, a user study on feasibility has been performed with a humanoid, NAO, and received positive evaluations in terms of anthropomorphism for the robot.},
  archive      = {J_RAS},
  author       = {Yu-Jung Chae and Changjoo Nam and Daseul Yang and HunSeob Sin and ChangHwan Kim and Sung-Kee Park},
  doi          = {10.1016/j.robot.2022.104154},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104154},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Generation of co-speech gestures of robot based on morphemic analysis},
  volume       = {155},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Autonomous distributed system for single-legged modular
robots to traverse environments by adaptive reconfiguration.
<em>RAS</em>, <em>155</em>, 104152. (<a
href="https://doi.org/10.1016/j.robot.2022.104152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconfigurable modular robots have the potential to achieve a range of tasks by changing their physical configuration. To identify a suitable configuration, the use of libraries has been suggested. However, such libraries usually assume centralized control, and developing a hardware-dependent library for all assumed tasks may be impractical. In this article, we focus on slope and gap traversal tasks for single-legged reconfigurable modular robots. We propose an autonomous distributed system to traverse the environments without determining the desired configuration a priori. Each module locally monitors the failure risk of the environment traversal for the entire robot. When it detects the high failure risk, the entire robot changes its morphology by adding an additional module to the component of the robot at a connecting place determined by the failure experience. By repeating the procedure, the entire robot gradually adapts the morphology to the environment and finally traverses the environment. Through dynamic simulations and robot experiments , we validated that entire robots with several initial configurations succeeded in changing their morphologies and traversing several slope and gap environments.},
  archive      = {J_RAS},
  author       = {Tomohiro Hayakawa and Fumitoshi Matsuno},
  doi          = {10.1016/j.robot.2022.104152},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104152},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Autonomous distributed system for single-legged modular robots to traverse environments by adaptive reconfiguration},
  volume       = {155},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Model-free dynamic control of robotic joints with integrated
elastic ligaments. <em>RAS</em>, <em>155</em>, 104150. (<a
href="https://doi.org/10.1016/j.robot.2022.104150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The combination of elasticity and rigidity found within mammalian limbs enables dexterous manipulation, agile, and versatile behavior, yet most modern robots are either primarily soft or rigid. Hybrid robots, composed of both soft and rigid parts, promote compliance to external forces while maintaining strength and stability provided by rigid robots. Most mammals have ligaments which connect bone to bone, enabling joints to passively redirect forces and softly constrain the range of motion. We present an approach to constructing a new class of hybrid joints through parametric design choices that adjust dynamic properties of the system. The inherent modularity and variability necessitate a model-free controller which can adjust to new contexts in relatively short time. Three joint examples are created along with three tasks to assess quality of the controllers, creating 9 total cases. We show the Soft Actor Critic (SAC) reinforcement learning algorithm outperforms a proportion–integral–derivative (PID) controller in 6/9 cases, yet this changes to 9/9 with a brief re-training period. This work presents a new class of hybrid robotic joints with modifiable dynamics and employs a model-free control training technique which can be fine-tuned for specific scenarios.},
  archive      = {J_RAS},
  author       = {A.S. Robbins and M. Ho and M. Teodorescu},
  doi          = {10.1016/j.robot.2022.104150},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104150},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Model-free dynamic control of robotic joints with integrated elastic ligaments},
  volume       = {155},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CorAl: Introspection for robust radar and lidar perception
in diverse environments using differential entropy. <em>RAS</em>,
<em>155</em>, 104136. (<a
href="https://doi.org/10.1016/j.robot.2022.104136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust perception is an essential component to enable long-term operation of mobile robots. It depends on failure resilience through reliable sensor data and pre-processing, as well as failure awareness through introspection, for example the ability to self-assess localization performance . This paper presents CorAl: a principled, intuitive, and generalizable method to measure the quality of alignment between pairs of point clouds, which learns to detect alignment errors in a self-supervised manner. CorAl compares the differential entropy in the point clouds separately with the entropy in their union to account for entropy inherent to the scene. By making use of dual entropy measurements , we obtain a quality metric that is highly sensitive to small alignment errors and still generalizes well to unseen environments. In this work, we extend our previous work on lidar-only CorAl to radar data by proposing a two-step filtering technique that produces high-quality point clouds from noisy radar scans. Thus, we target robust perception in two ways: by introducing a method that introspectively assesses alignment quality, and by applying it to an inherently robust sensor modality. We show that our filtering technique combined with CorAl can be applied to the problem of alignment classification, and that it detects small alignment errors in urban settings with up to 98\% accuracy, and with up to 96\% if trained only in a different environment. Our lidar and radar experiments demonstrate that CorAl outperforms previous methods both on the ETH lidar benchmark, which includes several indoor and outdoor environments, and the large-scale Oxford and MulRan radar data sets for urban traffic scenarios. The results also demonstrate that CorAl generalizes very well across substantially different environments without the need of retraining.},
  archive      = {J_RAS},
  author       = {Daniel Adolfsson and Manuel Castellano-Quero and Martin Magnusson and Achim J. Lilienthal and Henrik Andreasson},
  doi          = {10.1016/j.robot.2022.104136},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104136},
  shortjournal = {Robot. Auton. Syst.},
  title        = {CorAl: Introspection for robust radar and lidar perception in diverse environments using differential entropy},
  volume       = {155},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On comprehensive cascade control strategy considering a
class of overactuated autonomous non-rigid space systems with model
uncertainties. <em>RAS</em>, <em>155</em>, 102587. (<a
href="https://doi.org/10.1016/j.robot.2015.12.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With a focus on a number of state-of-the-art techniques in the area of autonomous non-rigid space systems control, realization of a comprehensive strategy is worthy of investigation to handle a set of parameters of the present overactuated processes with model uncertainties. In a word, the subject behind the research is to guarantee the desirable performance of a class of the autonomous space systems, which can be considered through the moments of inertia , the central of mass, the profile of the thrust vector and the misalignments of the propellant engine to deal with mission operation plans. There is the attitude cascade strategy including the low thrust three-axis engine off mode control, the low thrust x x -axis engine on mode control and finally the high thrust y , z y,z -axis engine on mode control, respectively. The control strategy is realized in a number of loops, as long as the on and off modes of the propellant engine are focused on the Euler angles control, in finite burn time, and quaternion vector control, in non-burn time, respectively, in line with parameters variations. It is to note that the parameters variations are coherently different in each one of the engine modes. The dynamics of high-low thrusters are taken into real consideration, where the control allocations in association with the pulse-width pulse-frequency modulators are employed to cope with a set of on–off reaction thrusters . The investigated results are finally analyzed in line with some related well-known benchmarks to verify the approach performance. The main contribution and motivation of the strategy investigated here is to propose a novel three-axis comprehensive cascade robust control solution to be able to deal with the parameters of autonomous non-rigid space systems under control with model uncertainties, in a synchronous manner, once the results regarding the tracking of the three-axis referenced commands are efficient with high accuracy along with the recent potential outcomes, researched in this area.},
  archive      = {J_RAS},
  author       = {A.H. Mazinan},
  doi          = {10.1016/j.robot.2015.12.004},
  journal      = {Robotics and Autonomous Systems},
  pages        = {102587},
  shortjournal = {Robot. Auton. Syst.},
  title        = {On comprehensive cascade control strategy considering a class of overactuated autonomous non-rigid space systems with model uncertainties},
  volume       = {155},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust walking stabilization strategy of humanoid robots on
uneven terrain via QP-based impedance/admittance control. <em>RAS</em>,
<em>154</em>, 104148. (<a
href="https://doi.org/10.1016/j.robot.2022.104148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A robust walking stabilization strategy of humanoids on uneven terrain via a QP-based impedance/ admittance control is addressed in this paper. The core idea is combining the following two strategies. The first is to reduce the effect of an unexpected contact force on the centroidal momentum dynamics, and the second is to adjust post-contact reference for the swing foot with which its pose is regulated on the obstacle. The former can be achieved by replacing the task of the trajectory tracking control for the swing foot with its task-space impedance control , and the latter follows by employing the hybrid admittance control combining the admittance control with resetting the post-contact reference. In addition, an optimal set of parameters used for the admittance control is computed via the Taguchi optimal design method . The proposed algorithm is embedded into the momentum-based whole-body control ( WBC ) framework and verified its validity by multiple simulations with the physics engine .},
  archive      = {J_RAS},
  author       = {Joonhee Jo and Gyunghoon Park and Yonghwan Oh},
  doi          = {10.1016/j.robot.2022.104148},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104148},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Robust walking stabilization strategy of humanoid robots on uneven terrain via QP-based impedance/admittance control},
  volume       = {154},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Motion control for a differential vehicle with variable
point of interest. Application: Smart cane control. <em>RAS</em>,
<em>154</em>, 104146. (<a
href="https://doi.org/10.1016/j.robot.2022.104146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses an unified solution to the trajectory tracking and path following problems for differential drive mobile robots (DDMR) considering a point of interest (PoI) with variable location relative to the vehicle. The mobile robot is modeled with an extended kinematic model avoiding typical singularities of this kind of vehicles, and allowing a straightforward definition of the corresponding inverse kinematics controller (IKC). This classical IKC fulfills the control objective with exponential error convergence but with the shortcoming of generating backward navigation when the PoI is located behind the DDMR, which is undesirable in some practical applications where the forward navigation must be preserved. This situation is theoretically analyzed, concluding that even though both forward and backward navigations correspond to equilibrium points of the closed loop, the stability of the forward navigation requires a PoI located in front of the DDMR, and the stability of the backward navigation requires a PoI located behind the DDMR. Finally, the article presents novel alternative controllers in order to always fulfill the motion objectives with stable forward navigation. Simulation results are presented to show the performance of the proposed controllers, and a real application of a robotic cane guiding its user is experimentally developed.},
  archive      = {J_RAS},
  author       = {Javier Gimenez and Flavio Roberti and Juan Marcos Toibero and Ricardo Carelli},
  doi          = {10.1016/j.robot.2022.104146},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104146},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Motion control for a differential vehicle with variable point of interest. application: Smart cane control},
  volume       = {154},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimal algorithm allocation for robotic network cloud
systems. <em>RAS</em>, <em>154</em>, 104144. (<a
href="https://doi.org/10.1016/j.robot.2022.104144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A robotic network is a system with multiple robots connected by a communication network. Certain tasks that cannot be accomplished with available robotic resources are candidates for the use of cloud robotics, which overcomes the limitations of the robot network by adding to the network, either local or remote servers or cloud infrastructure, to aid in computational demanding tasks or storage. Previous studies have mainly focused on minimizing the cost of the robots in retrieving resources by knowing the resource allocation in advance. We develop a method for a robotic network cloud system that includes robots, fog and cloud nodes, to determine where each algorithm should be allocated so that the system achieves optimal performance, regardless of which robot initiates the request. We can find the minimum required memory for the robots and the optimal way to allocate the algorithms with the shortest time to complete each task. We experimentally compare our method with a state-of-the-art method, using real-world data, showing the improvements that can be obtained.},
  archive      = {J_RAS},
  author       = {Saeid Alirezazadeh and André Correia and Luís A. Alexandre},
  doi          = {10.1016/j.robot.2022.104144},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104144},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Optimal algorithm allocation for robotic network cloud systems},
  volume       = {154},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multimodality robotic systems: Integrated combined
legged-aerial mobility for subterranean search-and-rescue. <em>RAS</em>,
<em>154</em>, 104134. (<a
href="https://doi.org/10.1016/j.robot.2022.104134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a field-hardened autonomous multimodal legged-aerial robotic system for subterranean exploration, extending a legged robot to be the carrier of an aerial platform capable of a rapid deployment in search-and-rescue scenarios. The driving force for developing such robotic configurations are the requirements for large-scale and long-term missions, where the payload capacity and long battery life of the legged robot is combined and integrated with the agile motion of the aerial agent. The multimodal robot is structured around the quadruped Boston Dynamics Spot, enhanced with a custom configured autonomy sensor payload as well as a UAV carrier platform, while the aerial agent is a custom built quadcopter. This work presents the novel design and hardware implementation as well as the onboard sensor suites. Moreover it establishes the overall autonomy architecture in a unified supervision approach while respecting each locomotion modality, including guidance, navigation, perception, state estimation, and control capabilities with a focus on rapid deployment and efficient exploration. The robotic system complete architecture is evaluated in real subterranean tunnel areas, in multiple fully autonomous search-and-rescue missions with the goal of identifying and locating objects of interest within the subterranean environment.},
  archive      = {J_RAS},
  author       = {Björn Lindqvist and Samuel Karlsson and Anton Koval and Ilias Tevetzidis and Jakub Haluška and Christoforos Kanellakis and Ali-akbar Agha-mohammadi and George Nikolakopoulos},
  doi          = {10.1016/j.robot.2022.104134},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104134},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Multimodality robotic systems: Integrated combined legged-aerial mobility for subterranean search-and-rescue},
  volume       = {154},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). APPL: Adaptive planner parameter learning. <em>RAS</em>,
<em>154</em>, 104132. (<a
href="https://doi.org/10.1016/j.robot.2022.104132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While current autonomous navigation systems allow robots to successfully drive themselves from one point to another in specific environments, they typically require extensive manual parameter re-tuning by human robotics experts in order to function in new environments. Furthermore, even for just one complex environment, a single set of fine-tuned parameters may not work well in different regions of that environment. These problems prohibit reliable mobile robot deployment by non-expert users. As a remedy, we propose Adaptive Planner Parameter Learning ( appl ), a machine learning framework that can leverage non-expert human interaction via several modalities – including teleoperated demonstrations, corrective interventions, and evaluative feedback – and also unsupervised reinforcement learning to learn a parameter policy that can dynamically adjust the parameters of classical navigation systems in response to changes in the environment. appl inherits safety and explainability from classical navigation systems while also enjoying the benefits of machine learning , i.e., the ability to adapt and improve from experience. We present a suite of individual appl methods and also a unifying cycle-of-learning scheme that combines all the proposed methods in a framework that can improve navigation performance through continual, iterative human interaction and simulation training.},
  archive      = {J_RAS},
  author       = {Xuesu Xiao and Zizhao Wang and Zifan Xu and Bo Liu and Garrett Warnell and Gauraang Dhamankar and Anirudh Nair and Peter Stone},
  doi          = {10.1016/j.robot.2022.104132},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104132},
  shortjournal = {Robot. Auton. Syst.},
  title        = {APPL: Adaptive planner parameter learning},
  volume       = {154},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hand-impedance measurements with robots during laparoscopy
training. <em>RAS</em>, <em>154</em>, 104130. (<a
href="https://doi.org/10.1016/j.robot.2022.104130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents hand-impedance measurements during laparoscopic training with physically interactive manipulators. We develop a co-manipulated robotic system allowing hand-impedance measurements in an active manipulation task with occasional environmental contact. Six professional, four trainee surgeons, and ten novice subjects participated in our experimental program for a suturing activity where the novice subjects were involved in a five weeks training practice. Variable admittance controlled robots, attached to the tools with force sensors , applied step vice velocity disturbances while subjects were trying to set the needle perpendicular to the surgical driver. Hereby, impedances of the left and right hands were computed in four different directions. Then, the measured impedance parameters across all subjects were compared with respect to the participants’ level of proficiency and skill progression via statistical analyses to demonstrate effectiveness of the system. Results indicate that hand-impedance in the direction of the suturing-line demonstrates a consistent change throughout training and across different levels of expertise in laparoscopy. Therefore, hand-impedance information, proposed here, can pave the way for future development of robotic assessment or assistance in laparoscopy training programs.},
  archive      = {J_RAS},
  author       = {Harun Tugal and Benjamin Gautier and Benjie Tang and Ghulam Nabi and Mustafa Suphi Erden},
  doi          = {10.1016/j.robot.2022.104130},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104130},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Hand-impedance measurements with robots during laparoscopy training},
  volume       = {154},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Upper extremity exoskeleton system to generate customized
therapy motions for stroke survivors. <em>RAS</em>, <em>154</em>,
104128. (<a href="https://doi.org/10.1016/j.robot.2022.104128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes the development of a seven degree-of-freedom (DOF) upper extremity exoskeleton to provide robotic therapy solutions for stroke survivors whose number is increasing along with the trend of ‘Aging Society’. Various robotic solutions have been illuminated and advanced along with their interfacing system in order to promote motor recovery after stroke. From this point of view, the proposed exoskeleton, RearMEX , is developed to (1) achieve active-actuation for the full range of human arm motions through the compact mechanical structure, (2) perform high force transparency through the reduction of the mechanical impedance , and (3) provide a user-interface for customized arm movements in active daily life. Especially, the exoskeleton system has a minimal impedance mode where a user can choose sequential desired postures for constituting a therapy motion by the simple button on the handgrip. Then, given a desired period for the movement, a novel interpolation method named norm-based time-allocating monotone Bézier interpolation is proposed to generate the corresponding trajectory with no jerk at each instant in the operational or configurational space. Furthermore, the disturbance observer (DOB) scheme is applied to achieve a robust tracking control performance on the interpolated trajectory even with model uncertainties and unexpected physical interactions with a wearer. The experimental results verify that the consistent performance can be achieved under various load conditions using the suggested controller.},
  archive      = {J_RAS},
  author       = {Beomsu Kim and Kuk-Hyun Ahn and SeungKyu Nam and Dong Jin Hyun},
  doi          = {10.1016/j.robot.2022.104128},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104128},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Upper extremity exoskeleton system to generate customized therapy motions for stroke survivors},
  volume       = {154},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Real-time identification and avoidance of simultaneous
static and dynamic obstacles on point cloud for UAVs navigation.
<em>RAS</em>, <em>154</em>, 104124. (<a
href="https://doi.org/10.1016/j.robot.2022.104124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Avoiding hybrid obstacles in unknown scenarios with an efficient flight strategy is a key challenge for unmanned aerial vehicle applications. In this paper, we introduce a more robust technique to distinguish and track dynamic obstacles from static ones with only point cloud input. Then, to achieve dynamic avoidance, we propose the forbidden pyramids method to solve the desired vehicle velocity with an efficient sampling-based method in iteration. The motion primitives are generated by solving a nonlinear optimization problem with the constraint of desired velocity and the waypoint. Furthermore, we present several techniques to deal with the position estimation error for close objects, the error for deformable objects , and the time gap between different submodules. The proposed approach is implemented to run onboard in real-time and validated extensively in simulation and real hardware tests, demonstrating our superiority in tracking robustness, energy cost, and calculating time.},
  archive      = {J_RAS},
  author       = {Han Chen and Peng Lu},
  doi          = {10.1016/j.robot.2022.104124},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104124},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Real-time identification and avoidance of simultaneous static and dynamic obstacles on point cloud for UAVs navigation},
  volume       = {154},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semi-autonomous control of prosthetic hands based on
multimodal sensing, human grasp demonstration and user intention.
<em>RAS</em>, <em>154</em>, 104123. (<a
href="https://doi.org/10.1016/j.robot.2022.104123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-autonomous control strategies for prosthetic hands provide a promising way to simplify and improve the grasping process for the user by adopting techniques usually applied in robotic grasping. Such strategies endow prosthetic hands with the ability to autonomously select and execute grasps while keeping the user in the loop to intervene at any time for triggering, accepting or rejecting decisions taken by the controller in an intuitive and easy way. In this paper, we present a semi-autonomous control strategy that allows the user to perform fluent grasping of everyday objects based on a single EMG channel and a multi-modal sensor system embedded in the hand for object perception and autonomous grasp execution. We conduct a user study with 20 subjects to assess the effectiveness and intuitiveness of our semi-autonomous control strategy and compare it to a conventional electromyography-based control strategy. The results show that the workload is reduced by 25.9\% compared to conventional electromyographic control, the physical demand is reduced by 60\% and the grasping process is accelerated by 19.4\%.},
  archive      = {J_RAS},
  author       = {Julia Starke and Pascal Weiner and Markus Crell and Tamim Asfour},
  doi          = {10.1016/j.robot.2022.104123},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104123},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Semi-autonomous control of prosthetic hands based on multimodal sensing, human grasp demonstration and user intention},
  volume       = {154},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design of intelligent fire-fighting robot based on
multi-sensor fusion and experimental study on fire scene patrol.
<em>RAS</em>, <em>154</em>, 104122. (<a
href="https://doi.org/10.1016/j.robot.2022.104122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on the current situation that most fire-fighting robots are operated by humans and do not have independent planning and operation abilities, in this paper an intelligent fire-fighting robot is designed using multi-sensor fusion. The robot has the functions of automatic inspection and fire-fighting, and can integrate the information of the operational environment and make decisions based multi-sensor fusion. An improved path-planning mechanism is proposed in order to overcome some disadvantages of the ant colony optimization algorithm, such as its easy tendency to reach local optimal solutions , slow convergence speed and weak global searching ability. A comprehensive evaluation method of the improved ACO is established to quantify its relevance and effectiveness. A joint calibration scheme for the color and temperature information obtained using an infrared thermal imager and a binocular vision camera was designed, and the internal and external parameters and distortion coefficient of the camera were successfully obtained. Based on the principle of binocular vision, a fire source detection and location strategy is proposed. When a fire source is detected, the location of the fire source is determined quickly and rescue path planning can be carried out, which improves the intelligence level of the fire-fighting robot. Finally, MATLAB and ROS are used to analyze the improved algorithm, and a fire site patrolling experiment is carried out. The results showed that the improved ACO greatly improves the convergence, reduces the number of iterations and greatly shortens the length of the patrol path, while the robot can effectively determine the location of the fire source efficiently during independent patrols and sound alarms, which will save precious time for fire-fighting and emergency rescue personnel.},
  archive      = {J_RAS},
  author       = {Shuo Zhang and Jiantao Yao and Ruochao Wang and Zisheng Liu and Chenhao Ma and Yingbin Wang and Yongsheng Zhao},
  doi          = {10.1016/j.robot.2022.104122},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104122},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Design of intelligent fire-fighting robot based on multi-sensor fusion and experimental study on fire scene patrol},
  volume       = {154},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An intelligent master–slave collaborative robot system for
cafeteria service. <em>RAS</em>, <em>154</em>, 104121. (<a
href="https://doi.org/10.1016/j.robot.2022.104121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve the efficiency and reduce the labor cost of cafeterias, an intelligent master–slave collaborative robot system is developed for cafeteria service in this paper. The developed system can automatically complete the tasks of scooping dishes, taking bowls and pouring dishes into the bowl based on master–slave collaboration. Specifically, a dynamic geometry feature graph convolution network (DGG) is devised using the 3D point cloud of the dish, which can efficiently predict the scooping positions of the different dishes. Moreover, a master–slave motion planning control method is proposed to achieve fast and smooth trajectories for both arms, which can accomplish the cafeteria service tasks collaboratively. Furthermore, we establish a dataset containing point clouds and color images of various Chinese food. Experiments demonstrate that the DGG network can achieve superior performance over other state-of-the-art point cloud segmentation networks. Besides, the designed robot system can well meet the requirements of operation accuracy and speed, confirming its practicality in cafeteria services.},
  archive      = {J_RAS},
  author       = {Mingyu Gao and Haiping Zhou and Yuxiang Yang and Zhekang Dong and Zhiwei He},
  doi          = {10.1016/j.robot.2022.104121},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104121},
  shortjournal = {Robot. Auton. Syst.},
  title        = {An intelligent master–slave collaborative robot system for cafeteria service},
  volume       = {154},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reinforcement learning control for the swimming motions of a
beaver-like, single-legged robot based on biological inspiration.
<em>RAS</em>, <em>154</em>, 104116. (<a
href="https://doi.org/10.1016/j.robot.2022.104116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex hydrodynamic modeling and analysis are considered as stumbling blocks in the motion study of underwater bionic robots. In recent years, reinforcement learning techniques have been applied for robot motion control in unknown environments. However, robots may act in an unconventional or dangerous manner during the learning process. These actions increase the training difficulty and decrease the training efficiency. In this study, a biological-inspired reinforcement learning control method is proposed. It realizes the self-learning movement policy of the robot with discretized swimming motions of a beaver without the need to establish motion models, such as hydrodynamics, of underwater robots . The biological-inspired model further reduces the robot’s ineffective movements during the reinforcement learning and improves training efficiency. The experiment results verify the environmental adaptation and self-learning ability of the proposed robot platform and proves the effectiveness of the reinforcement learning control method for robotic swimming based on biological inspiration. This study’s findings provide new ideas for the motion control of underwater bionic robots and further promote the application of artificial intelligence in underwater robots .},
  archive      = {J_RAS},
  author       = {Gang Chen and Yuwang Lu and Xin Yang and Huosheng Hu},
  doi          = {10.1016/j.robot.2022.104116},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104116},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Reinforcement learning control for the swimming motions of a beaver-like, single-legged robot based on biological inspiration},
  volume       = {154},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Output-feedback robust saturated actor–critic multi-layer
neural network controller for multi-body electrically driven tractors
with n-trailer guaranteeing prescribed output constraints. <em>RAS</em>,
<em>154</em>, 104106. (<a
href="https://doi.org/10.1016/j.robot.2022.104106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel robust saturated actor–critic multi-layer neural network controller for electrically-driven tractors with n n -trailer with unmeasurable linear and angular velocities , uncertain complex dynamics and actuator saturation while guaranteeing a prescribed performance with employing the motor dynamics. The proposed controller consists of four control loops. In the first loop, tracking errors are transformed into constraint errors via prescribed performance bounds. Then, a kinematic controller is designed. In the second loop, an output feedback robust dynamic controller is proposed via multi-layer actor–critic neural networks to approximate model uncertainties, a high-gain observer (HGO) to estimate velocities, and an adaptive robust controller to compensate external dynamic disturbances. Afterwards, a robust actuator controller is designed in third loop by employing multi-layer actor–critic neural networks to deeply diminish unknown nonlinear functions effects, and an adaptive robust controller to handle the bounded actuator disturbances. An auxiliary subsystem is considered in the final loop to reduce the danger of actuator saturation by designing an auxiliary intermediate controller. The stability under the proposed controller is studied by the Lyapunov stability synthesis, and it is proven that tracking errors remain uniformly ultimately bounded. Finally, the validity, reliability, and effectiveness of the proposed reinforcement learning-based controller is shown by means of multiple simulations and some comparisons with a quantitative study.},
  archive      = {J_RAS},
  author       = {Omid Elhaki and Khoshnam Shojaei},
  doi          = {10.1016/j.robot.2022.104106},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104106},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Output-feedback robust saturated actor–critic multi-layer neural network controller for multi-body electrically driven tractors with n-trailer guaranteeing prescribed output constraints},
  volume       = {154},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Development and application of key technologies for guide
dog robot: A systematic literature review. <em>RAS</em>, <em>154</em>,
104104. (<a href="https://doi.org/10.1016/j.robot.2022.104104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current situation of many visually handicapped people worldwide, yet the corresponding number of guide dogs is quite rare. It activates the application of advanced technology to broaden their horizons and allow them to embrace the world. This paper will review the research state of the Guide Dog Robot (GDR) for people with visual impairment and present some views. According to the application scenes, we have divided the GDR into two categories: specific scene applicable type and universal scene applicable type, with the description of different performances under various scenes. Then the current research focuses are elaborated, including localization and navigation technology, recognition of traffic signs, human–robot interaction (HRI), speed coordination, and walking structure design. Subsequently, the studying directions and challenges of GDR are discussed, and collaborative human–robot mode is believed to become the research mainstream. Finally, we conclude this review and explain why few GDR has realized commercialization . The limitations of current studies and some recommendations for future research are presented.},
  archive      = {J_RAS},
  author       = {Bin Hong and Zhangxi Lin and Xin Chen and Jing Hou and Shunya Lv and Zhendong Gao},
  doi          = {10.1016/j.robot.2022.104104},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104104},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Development and application of key technologies for guide dog robot: A systematic literature review},
  volume       = {154},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). IRotate: Active visual SLAM for omnidirectional robots.
<em>RAS</em>, <em>154</em>, 104102. (<a
href="https://doi.org/10.1016/j.robot.2022.104102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present an active visual SLAM approach for omnidirectional robots . The goal is to generate control commands that allow such a robot to simultaneously localize itself and map an unknown environment while maximizing the amount of information gained and consuming as low energy as possible. Leveraging the robot’s independent translation and rotation control, we introduce a multi-layered approach for active V-SLAM. The top layer decides on informative goal locations and generates highly informative paths to them. The second and third layers actively re-plan and execute the path, exploiting the continuously updated map and local features information. Moreover, we introduce two utility formulations to account for the presence of obstacles in the field of view and the robot’s location. Through rigorous simulations, real robot experiments , and comparisons with state-of-the-art methods, we demonstrate that our approach achieves similar coverage results with lesser overall map entropy. This is obtained while keeping the traversed distance up to 39\% shorter than the other methods and without increasing the wheels’ total rotation amount. Code and implementation details are provided as open-source, and all the generated data is available online for consultation.},
  archive      = {J_RAS},
  author       = {Elia Bonetto and Pascal Goldschmid and Michael Pabst and Michael J. Black and Aamir Ahmad},
  doi          = {10.1016/j.robot.2022.104102},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104102},
  shortjournal = {Robot. Auton. Syst.},
  title        = {IRotate: Active visual SLAM for omnidirectional robots},
  volume       = {154},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey of behavior trees in robotics and AI. <em>RAS</em>,
<em>154</em>, 104096. (<a
href="https://doi.org/10.1016/j.robot.2022.104096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Behavior Trees (BTs) were invented as a tool to enable modular AI in computer games, but have received an increasing amount of attention in the robotics community in the last decade. With rising demands on agent AI complexity, game programmers found that the Finite State Machines (FSM) that they used scaled poorly and were difficult to extend, adapt and reuse. In BTs, the state transition logic is not dispersed across the individual states, but organized in a hierarchical tree structure, with the states as leaves. This has a significant effect on modularity , which in turn simplifies both synthesis and analysis by humans and algorithms alike. These advantages are needed not only in game AI design, but also in robotics, as is evident from the research being done. In this paper we present a comprehensive survey of the topic of BTs in Artificial Intelligence and Robotic applications . The existing literature is described and categorized based on methods, application areas and contributions, and the paper is concluded with a list of open research challenges.},
  archive      = {J_RAS},
  author       = {Matteo Iovino and Edvards Scukins and Jonathan Styrud and Petter Ögren and Christian Smith},
  doi          = {10.1016/j.robot.2022.104096},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104096},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A survey of behavior trees in robotics and AI},
  volume       = {154},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybrid system for optimizing the robot mobile navigation
using ANFIS and PSO. <em>RAS</em>, <em>153</em>, 104114. (<a
href="https://doi.org/10.1016/j.robot.2022.104114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The important thing about mobile robotics is that its use satisfies rapid movement without collisions. Several methods have been designed for this purpose, but not all of them give the results expected by the user. Our contribution in this article is to allow the mobile robot to take advantage of two methods by the hybridization effect. These methods, implemented are ANFIS “Adaptive Neuro-Flou Inference System” and the PSO “Particle Swarm Optimization”. Learning by the connectionist approach of the ANFIS controller is sufficient to allow the robot to reach its target but remains unsatisfactory. The contribution of the PSO algorithm allows the hybrid controller to optimize, the speed and therefore the positions of robot. The controller thus constituted gives better simulation results of the distances measured in pixels traveled by the hybrid method .},
  archive      = {J_RAS},
  author       = {Malika Lazreg and Nacéra Benamrane},
  doi          = {10.1016/j.robot.2022.104114},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104114},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Hybrid system for optimizing the robot mobile navigation using ANFIS and PSO},
  volume       = {153},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A nonlinear state estimation framework for humanoid robots.
<em>RAS</em>, <em>153</em>, 104100. (<a
href="https://doi.org/10.1016/j.robot.2022.104100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a novel nonlinear state estimation framework for humanoid robots based on the dynamics of the center of mass (CoM) and dual-loop Kalman filter(DLKF). It effectively fuses the information from inertial measurement unit(IMU), joint encoders , and foot sensitive resistors (FSRs), and provides state estimates for various gait generation algorithms and dynamic balance controllers with CoM or divergence component of motion (DCM) feedback. Compared to the widely used linear models such as the linear inverted pendulum model (LIPM), the nonlinear dynamics of CoM effectively reduce the process error. However, the humanoid robot is a highly complex dynamic system with multiple links and joints , the dynamics of CoM are also a simplification of the whole body dynamics. As a result, it brings non-zero-mean, non-Gaussian, and correlated process error, which the conventional extend Kalman filter (EKF) cannot handle. To this end, the DLKF is adopted to compensate the process error, thus the estimator is robust to the modeling error caused by simplifications. Furthermore, the invariant extended Kalman filter (IEKF) is used for floating base kinematics estimation, and the force/torque (F/T) sensor which is difficult to integrate on smaller or cheaper robots due to the size and cost is not used in our framework. Finally, our nonlinear state estimation framework improves the accuracy of CoM and DCM estimation in a virtual environment simulation using our self-developed Defensor hydraulic humanoid robot.},
  archive      = {J_RAS},
  author       = {Jingchao Li and Zhaohui Yuan and Sheng Dong and Jingqin Zhang and Jianrui Zhang},
  doi          = {10.1016/j.robot.2022.104100},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104100},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A nonlinear state estimation framework for humanoid robots},
  volume       = {153},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive neural fuzzy reasoning method for recognizing human
movement gait phase. <em>RAS</em>, <em>153</em>, 104087. (<a
href="https://doi.org/10.1016/j.robot.2022.104087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In response to the needs of real-time and accurate detection of the human gait phase for lower limb exoskeleton, the movement of the human foot is taken as the research object, and the human gait phase division method based on human kinematics and dynamics information is studied. This paper presents a wearable foot gait analysis system based on inertial sensors and pressure sensors , and studies the human gait phase recognition method based on plantar acceleration and plantar pressure information. Based on the analysis of the relationship between the plantar acceleration–pressure information and the gait period, the adaptive neural fuzzy reasoning system is used to integrate the information of plantar acceleration and plantar pressure information so as to realize the fast gait phase division. The three proposed methods are compared with the standard results of the Vicon motion capture system by experiments. The experimental results show that the accuracy of the ANFIS method combining the acceleration information and the plantar pressure information to the human gait phase division is 99.16\%.},
  archive      = {J_RAS},
  author       = {Jiyuan Song and Aibin Zhu and Yao Tu and Han Mao and Xiaodong Zhang},
  doi          = {10.1016/j.robot.2022.104087},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104087},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Adaptive neural fuzzy reasoning method for recognizing human movement gait phase},
  volume       = {153},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hierarchical multi-robot strategies synthesis and
optimization under individual and collaborative temporal logic
specifications. <em>RAS</em>, <em>153</em>, 104085. (<a
href="https://doi.org/10.1016/j.robot.2022.104085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a hierarchical framework for multi-robot temporal logic task planning. We assume that each robot has its individual task specification and the robots have to jointly satisfy a global collaborative task specification, both described in finite linear temporal logic . To reduce the overall computational complexity , a central server firstly extracts and decomposes a collaborative task sequence from the automaton corresponding to the collaborative task specification, and allocates the subtasks in the sequence to robots. The robots then synthesize their initial execution strategies based on locally constructed product automatons, which integrate task requirements of the assigned collaborative tasks and their individual task specifications. Further, to reduce robots’ wait time in collaborations, we propose a distributed execution strategy adjusting mechanism to iteratively improve the time efficiency of robots. Finally, we prove the completeness of the proposed framework under assumptions, and analyze its time complexity and optimality . Extensive simulation results verify the scalability and optimization efficiency of the proposed method.},
  archive      = {J_RAS},
  author       = {Ruofei Bai and Ronghao Zheng and Yang Xu and Meiqin Liu and Senlin Zhang},
  doi          = {10.1016/j.robot.2022.104085},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104085},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Hierarchical multi-robot strategies synthesis and optimization under individual and collaborative temporal logic specifications},
  volume       = {153},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Synthesis of strategies for autonomous surveillance on
adversarial targets. <em>RAS</em>, <em>153</em>, 104084. (<a
href="https://doi.org/10.1016/j.robot.2022.104084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of synthesizing a controller for an agent with imperfect sensing and a quantitative surveillance objective , that is, an agent is required to maintain knowledge of the location of a moving, possibly adversarial target. We formulate the problem as a one-sided partial-information game with a winning condition expressed as a temporal logic specification. The specification encodes the quantitative surveillance requirement as well as any additional tasks. Solving a partial-information game typically involves transforming it into a perfect-information belief game using a belief-set construction. Such a transformation leads to a state-space explosion, rendering the belief game computationally intractable to solve for most realistic settings. We present a belief-set abstraction technique to transform the partial-information game to a provably sound abstract belief game that can be solved efficiently using off-the-shelf reactive synthesis tools . We introduce a counterexample-guided refinement approach to automatically achieve the abstraction precision sufficient to synthesize a strategy that is provably winning on the original partial-information game. We evaluate the proposed method on multiple case-studies, implemented on hardware as well as high-fidelity ROS/Gazebo simulations where the agent must respond in real-time to a human-controlled adversary.},
  archive      = {J_RAS},
  author       = {Suda Bharadwaj and Rayna Dimitrova and Jesse Quattrociocchi and Ufuk Topcu},
  doi          = {10.1016/j.robot.2022.104084},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104084},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Synthesis of strategies for autonomous surveillance on adversarial targets},
  volume       = {153},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). What should be the input: Investigating the environment
representations in sim-to-real transfer for navigation tasks.
<em>RAS</em>, <em>153</em>, 104081. (<a
href="https://doi.org/10.1016/j.robot.2022.104081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While training an end-to-end navigation network in the real world is usually costly, simulation serves as a safe and low-cost tool in this training process. However, training neural network models in simulation brings up the problem of effectively transferring the model from simulation to the real world (sim-to-real). In this work, we regard the environment representation as a crucial element in this transfer process, and we propose a visual information pyramid (VIP) model to investigate a practical environment representation systematically. A novel representation composed of spatial and semantic information synthesis is established accordingly, where noise model embedding is particularly considered. To explore the effectiveness of the proposed representation, we compared its performance with other popularly used representations in the literature, such as RGB image , depth image, and semantic segmentation image, in both simulated and real-world scenarios. Results suggest that our environment representation stands out. Furthermore, an analysis on the feature map is implemented to investigate the effectiveness through hidden layer reaction, which could be irradiative for future researches on sim-to-real learning-based navigation.},
  archive      = {J_RAS},
  author       = {Gang Chen and Hongzhe Yu and Wei Dong and Xinjun Sheng and Xiangyang Zhu and Han Ding},
  doi          = {10.1016/j.robot.2022.104081},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104081},
  shortjournal = {Robot. Auton. Syst.},
  title        = {What should be the input: Investigating the environment representations in sim-to-real transfer for navigation tasks},
  volume       = {153},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analysis, design and preliminary evaluation of an
anthropometric self-stabilization passive exoskeleton for enhancing the
ability of walking with loads. <em>RAS</em>, <em>153</em>, 104079. (<a
href="https://doi.org/10.1016/j.robot.2022.104079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the analysis, design and preliminary evaluation of an anthropometric self-stabilization passive exoskeleton (ASPE) with elastic band to increase the load transmission efficiency and protect and strengthen the human body during loaded walking. Firstly, we analyze the working principle of passive exoskeleton, and propose an efficient method of reducing the degrees of freedom in exoskeleton relatively, which contributes to a self-stabilization mechanism for balancing the back torque causing by the loaded backpack and assisting human hip flexion. The design of the ASPE is then introduced in detail. The novelty of the ASPE is that the human–machine interaction forces are significantly reduced by integrating the elastic band into the exoskeleton hip joint and converting load gravity into the elastic potential energy of elastic band to assist hip joint flexion. Furthermore, we analyze the dynamic modeling of the ASPE to preliminarily calculate the transmission efficiency regarding the ratio of plantar pressure of the ASPE to load gravity. Besides, we conduct the experiment of human wearing the ASPE to evaluate the performance of the ASPE regarding the ratio of the difference of human plantar pressure with and without the ASPE to load gravity. The results show that the ASPE can effectively transfer load gravity to the ground and maintain the human natural movement. The ratio of the plantar pressure of the ASPE to load gravity is more than 70\% in the simulation, and when the walking speed is 4 km/h, the ASPE reduce the human plantar pressure of 68.9\% compared to without wearing the ASPE during human walking with load. The results provide evidence for the efficient transmission of the newly designed ASPE during walking with loads. The application of the ASPE have benefits for subjects walking with loads, such as soldiers, to decrease their injuries and strengthen their ability.},
  archive      = {J_RAS},
  author       = {Nengbing Zhou and Yali Liu and Qiuzhi Song and Zhuo Qi and Weizhi Ren and Kun Zhang},
  doi          = {10.1016/j.robot.2022.104079},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104079},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Analysis, design and preliminary evaluation of an anthropometric self-stabilization passive exoskeleton for enhancing the ability of walking with loads},
  volume       = {153},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving obstacle boundary representations in predictive
occupancy mapping. <em>RAS</em>, <em>153</em>, 104077. (<a
href="https://doi.org/10.1016/j.robot.2022.104077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predictive, inference-based occupancy mapping has been used successfully in many instances to create accurate and descriptive maps from sparse data, defining occupied space in a manner suitable to support autonomous navigation . However, one key drawback of inferring occupancy based largely on the proximity of range sensor observations is inaccuracy at the boundary between occupied and free space, where sparse coverage by the sensor data can be misinterpreted. To obtain a more accurate representation of the boundary between free and occupied space, we propose several modifications to a recently published occupancy mapping algorithm that uses Bayesian generalized kernel inference. In particular, our proposed algorithm distinguishes between unknown map cells with insufficient observations, and those which are uncertain due to disagreement among numerous observations, in a predictive, inference-based occupancy map. This distinction is key to our improved ability to capture ambiguities arising at the boundary between free and occupied space. We validate our approach using synthetic range data from a simulated environment and demonstrate real-time mapping performance using range data acquired by a ground robot operating in an underground mine.},
  archive      = {J_RAS},
  author       = {Erik Pearson and Kevin Doherty and Brendan Englot},
  doi          = {10.1016/j.robot.2022.104077},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104077},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Improving obstacle boundary representations in predictive occupancy mapping},
  volume       = {153},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Person-following controller with socially acceptable robot
motion. <em>RAS</em>, <em>153</em>, 104075. (<a
href="https://doi.org/10.1016/j.robot.2022.104075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a novel stable controller for the person-following task that includes social considerations for a differential drive mobile robot equipped with an RGB-D camera and a laser range finder as main sensors. The proposed controller adapts its behavior based on the knowledge of both: a modified personal space distribution and human user velocity. Control objectives are focused hence on keeping the human user within the camera’s field-of-view while the mobile robot follows it, with a socially acceptable motion through arbitrary paths. To show the good behavior of this proposal, simulation and real experimental results are included and discussed. The asymptotic stability of the overall system is proved through the Lyapunov theory . Also, in our proposal, three state-of-the-art algorithms were integrated with the controller. In particular, a new real-time multi-person skeletal tracking system is used to obtain the relative human–robot position, a text to speech algorithm is used to confirm the commands given by the human, and also, a SLAM algorithm is used to obtain the map of the environment while the main task is being performed. Additionally, a hand gesture recognition module is included to interact with the mobile robot. This way, the robot is allowed to navigate with a socially-aware behavior in environments shared with humans. Finally, subjective and objective metrics are used as a validation method for human perception about the achieved robot motion.},
  archive      = {J_RAS},
  author       = {Julio Montesdeoca and J. Marcos Toibero and Julian Jordan and Andreas Zell and Ricardo Carelli},
  doi          = {10.1016/j.robot.2022.104075},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104075},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Person-following controller with socially acceptable robot motion},
  volume       = {153},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Quasi-critical collision-avoidance strategy for autonomous
vehicles in complex traffic scenarios based on exclusive area of
relative velocity vector algorithm. <em>RAS</em>, <em>153</em>, 104049.
(<a href="https://doi.org/10.1016/j.robot.2022.104049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collision avoidance is one of the most important requirements for autonomous vehicles, particularly in complex and congested traffic scenarios where trajectories have little safety redundancy. However, simultaneously reaching the required accuracy and universal feasibility for different collision-avoidance behaviours is difficult due to the multi-state coupled motion of vehicles. To achieve the maximum traversability and ensure the safety of autonomous vehicles in any complex scenarios, we propose a quasi-critical collision-avoidance strategy based on a newly developed algorithm: the exclusive area-of-relative-velocity vector. This strategy first involves the construction of an exclusive area-of-velocity vector for each object vehicle to extract its position relative to the subject vehicle . In this procedure, to establish a subject-motion-decoupled scenario, projective transformation is applied to regularise the moving elliptical contour of the subject vehicle as a settled circle while retaining all positional relationships between the subject and object vehicles using the invariants . Subsequently, a group of escaping conditions for this exclusive area are established to express this quasi-critical collision-avoidance strategy explicitly and mathematically. The ultimate ability to escape from such an area is determined through theoretical derivations and experiments according to vehicle dynamics. In terms of real scenario data, a set of escaping equations is established to calculate the escaping conditions subject to the current state and the ultimate motion ability. Via scenario verifications, this strategy is shown to represent the safety boundary accurately and ensure quasi-critical collision-avoidance conditions under complex scenarios.},
  archive      = {J_RAS},
  author       = {Zhaolin Liu and Jiqing Chen and Hongyang Xia and Fengchong Lan},
  doi          = {10.1016/j.robot.2022.104049},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104049},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Quasi-critical collision-avoidance strategy for autonomous vehicles in complex traffic scenarios based on exclusive area of relative velocity vector algorithm},
  volume       = {153},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A passive admittance controller to enforce remote center of
motion and tool spatial constraints with application in hands-on
surgical procedures. <em>RAS</em>, <em>152</em>, 104073. (<a
href="https://doi.org/10.1016/j.robot.2022.104073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The restriction of feasible motions of a manipulator link constrained to move through an entry port is a common problem in minimally invasive surgery procedures. Additional spatial restrictions are required to ensure the safety of sensitive regions from unintentional damage. In this work, we design a target admittance model that is proved to enforce robot tool manipulation by a human through a remote center of motion and to guarantee that the tool will never enter or touch forbidden regions . The control scheme is proved passive under the exertion of a human force ensuring manipulation stability, and smooth natural motion in hands-on surgical procedures enhancing the user’s feeling of control over the task. Its performance is demonstrated by experiments with a setup mimicking a hands-on surgical procedure comprising a KUKA LWR4+ and a virtual intraoperative environment.},
  archive      = {J_RAS},
  author       = {Theodora Kastritsi and Zoe Doulgeri},
  doi          = {10.1016/j.robot.2022.104073},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104073},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A passive admittance controller to enforce remote center of motion and tool spatial constraints with application in hands-on surgical procedures},
  volume       = {152},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Real-time wildfire monitoring with a fleet of UAVs.
<em>RAS</em>, <em>152</em>, 104071. (<a
href="https://doi.org/10.1016/j.robot.2022.104071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a wildfire monitoring system based on a fleet of Unmanned Aerial Vehicles (UAVs) to provide firefighters with precise and up-to-date information about a propagating wildfire, so that they can devise efficient suppression actions. We present an approach to plan trajectories for a fleet of fixed-wing UAVs to observe a wildfire evolving over time by tailoring the Variable Neighborhood Search metaheuristic to the problem characteristics. Realistic models of the terrain, of the fire propagation process, and of the UAVs are exploited, together with a model of the wind, to predict wildfire spread and plan accordingly the UAVs motions. Algorithms and models are integrated within a software architecture allowing tests with real and simulated UAVs flying over synthetic wildfires. Results of a mixed-reality test campaign show the ability of the proposed system to effectively map wildfire propagation.},
  archive      = {J_RAS},
  author       = {Rafael Bailon-Ruiz and Arthur Bit-Monnot and Simon Lacroix},
  doi          = {10.1016/j.robot.2022.104071},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104071},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Real-time wildfire monitoring with a fleet of UAVs},
  volume       = {152},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A review of GNSS-independent UAV navigation techniques.
<em>RAS</em>, <em>152</em>, 104069. (<a
href="https://doi.org/10.1016/j.robot.2022.104069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Application of UAVs (Unmanned Aerial Vehicles) in environments devoid of GNSS (Global Navigation Satellite System) service has motivated research into GNSS-independent navigation solutions. This paper presents an account of such solutions proposed within the last decade. Unlike most literature that abstract UAV navigation to mere localization , this work takes a bottom-up approach by assessing the navigation components namely perception, localization and motion planning presented in the selected literature. The review results indicate that only 16\% of the research presented full navigation solutions, while the rest present one or several components thereof. Besides the account of navigation solutions, our other contributions include an adapted MTOW-based (Maximum Take-Off Weight) UAV classification scheme incorporating a nano-sized UAV class, technology maturity assessment of the reviewed GNSS-independent navigation solutions and analysis of integrity monitoring frameworks.},
  archive      = {J_RAS},
  author       = {Nasser Gyagenda and Jasper V. Hatilima and Hubert Roth and Vadim Zhmud},
  doi          = {10.1016/j.robot.2022.104069},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104069},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A review of GNSS-independent UAV navigation techniques},
  volume       = {152},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust continuous motion strategy against muscle rupture
using online learning of redundant intersensory networks for
musculoskeletal humanoids. <em>RAS</em>, <em>152</em>, 104067. (<a
href="https://doi.org/10.1016/j.robot.2022.104067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Musculoskeletal humanoids have various biomimetic advantages, of which redundant muscle arrangement is one of the most important features. This feature enables variable stiffness control and allows the robot to keep moving its joints even if one of the redundant muscles breaks, but this has been rarely explored. In this study, we construct a neural network that represents the relationship among sensors in the flexible and difficult-to-modelize body of the musculoskeletal humanoid, and by learning this neural network , accurate motions can be achieved. In order to take advantage of the redundancy of muscles, we discuss the use of this network for muscle rupture detection, online update of the intersensory relationship considering the muscle rupture, and body control and state estimation using the muscle rupture information. This study explains a method of constructing a musculoskeletal humanoid that continues to move and perform tasks robustly even when one muscle breaks.},
  archive      = {J_RAS},
  author       = {Kento Kawaharazuka and Manabu Nishiura and Yasunori Toshimitsu and Yusuke Omura and Yuya Koga and Yuki Asano and Kei Okada and Koji Kawasaki and Masayuki Inaba},
  doi          = {10.1016/j.robot.2022.104067},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104067},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Robust continuous motion strategy against muscle rupture using online learning of redundant intersensory networks for musculoskeletal humanoids},
  volume       = {152},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Safe and adaptive autonomous navigation under uncertainty
based on sequential waypoints and reachability analysis. <em>RAS</em>,
<em>152</em>, 104065. (<a
href="https://doi.org/10.1016/j.robot.2022.104065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new approach for a safe autonomous navigation based on reliable state space reachability analysis. This latter improves an already proposed flexible Navigation Strategy based on Sequential Waypoint Reaching (NSbSWR) framework (Vilca et al., 2015), while considering explicitly different uncertainties in modeling and/or perception. Indeed, NSbSWR is an emergent concept that exploits its flexibility and genericity to avoid frequent complex trajectories’ planning/re-planning. The paper’s main contribution is to introduce a reachability analysis scheme as a reliable risk assessment and management policy ensuring safe autonomous navigation between the successive assigned waypoints. For this aim, interval analysis is employed to propagate uncertainties influencing the vehicle’s dynamics into the navigation system states. By solving an ordinary differential equation with uncertain variables and parameters via an interval Taylor series expansion method, all the vehicle potential reachable state-space is revealed. According to the obtained bounds of the reachable sets, a decision about the navigation safety is made. Once a collision risk is captured, the risk management layer acts to update the control parameters to master the critical situation and guarantee a proper reaching of waypoint, while avoiding any risky state. Several simulation results prove the safety, efficiency and robustness of the overall navigation under uncertainties.},
  archive      = {J_RAS},
  author       = {Nadhir Mansour Ben Lakhal and Lounis Adouane and Othman Nasri and Jaleleddine Ben Hadj Slama},
  doi          = {10.1016/j.robot.2022.104065},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104065},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Safe and adaptive autonomous navigation under uncertainty based on sequential waypoints and reachability analysis},
  volume       = {152},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Heat conduction combined grid-based optimization method for
reconfigurable pavement sweeping robot path planning. <em>RAS</em>,
<em>152</em>, 104063. (<a
href="https://doi.org/10.1016/j.robot.2022.104063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-reconfigurable robots can change their morphology to expose functionality that enables them to overcome challenges that fixed shape robots are unable to overcome. A reconfigurable pavement sweeping robot, Panthera, is able to reconfigure in width by compressing and expanding. This autonomous system overcomes challenges in the pavement cleaning industry, such as access to tight and narrow pavements. Reconfigurability in width enables the robot to maximize cleaning area in an expanded state and navigate through tight spaces in the compressed state, which fixed shape robots are unable to pass through. Despite its advantages, most path planning (PP) algorithms are developed for fixed shape robots, and there are little or no works done on PP for reconfigurable robots that are able to expand and compress in width. To tackle this challenge, we present a novel PP method for pavement-sweeping reconfigurable robots by drawing similarities between heat transfer analysis and PP. Heat travels from the heat source to the heat sink and can only travel through a conductive material . Similarly, PP enables the robot to move from start to goal while accessing the feasible areas. Our proposed path planner employs a thermal gradient ascent combined grid-based optimization algorithm to generate optimal paths for best smoothness, distance, and robot footprint. The path planner is tested in four virtual environments and validated in a real-world environment.},
  archive      = {J_RAS},
  author       = {Huy Do and Anh Vu Le and Lim Yi and Joel Chan Cheng Hoong and Minh Tran and Phan Van Duc and Minh Bui Vu and Oliver Weeger and Rajesh Elara Mohan},
  doi          = {10.1016/j.robot.2022.104063},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104063},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Heat conduction combined grid-based optimization method for reconfigurable pavement sweeping robot path planning},
  volume       = {152},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ROS-based trajectory tracking control for autonomous tracked
vehicle using optimized backstepping and sliding mode control.
<em>RAS</em>, <em>152</em>, 104058. (<a
href="https://doi.org/10.1016/j.robot.2022.104058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the trajectory tracking control of an autonomous tracked vehicle. First, the desired linear and angular velocities are evaluated based on vehicle’s kinematics. An optimized backstepping controller is proposed as the kinematic controller, whereas the controller gains are optimally obtained. Next, an integral sliding mode control (SMC) is exploited based on vehicle dynamics and slipping characteristics, to obtain the desired torques that drive the vehicle and converge its trajectory to the desired one. Moreover, stability analysis of the whole system is proven based on Lyapunov theory . Finally, simulations and real-time experiments based on robot operating system (ROS) implementation are conducted to validate the effectiveness of the proposed control algorithm and compared with a hybrid backstepping-modified PID dynamic controller.},
  archive      = {J_RAS},
  author       = {Ahmed D. Sabiha and Mohamed A. Kamel and Ehab Said and Wessam M. Hussein},
  doi          = {10.1016/j.robot.2022.104058},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104058},
  shortjournal = {Robot. Auton. Syst.},
  title        = {ROS-based trajectory tracking control for autonomous tracked vehicle using optimized backstepping and sliding mode control},
  volume       = {152},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robotic manipulation based on 3-d visual servoing and deep
neural networks. <em>RAS</em>, <em>152</em>, 104041. (<a
href="https://doi.org/10.1016/j.robot.2022.104041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The critical challenge, for robot–object-interaction, is to estimate visually the pose of the target object in a 3D space and combine it into a vision-based control scheme in manipulation applications. This paper proposes a novel reliable framework for deep ConvNet combined with visual servoing using a single RGB camera. We introduce an extensive system called Deep-Visual-Servoing (DVS) that addresses an integration of: (I) training of deep-CNNs using synthetic dataset only and operates successfully in real-world scenario, (II) continuous 3 D object pose estimation as the sensing feedback in a 3D visual servoing control scheme, and (III) design, integration and experimentation of visual servoing approach based on Lyapunov’s theory. The proposed deep based learning approach, the kinematic modeling and controller design are experimentally verified and discussed using the 6 DOF UR5 manipulator.},
  archive      = {J_RAS},
  author       = {Abdulrahman Al-Shanoon and Haoxiang Lang},
  doi          = {10.1016/j.robot.2022.104041},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104041},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Robotic manipulation based on 3-D visual servoing and deep neural networks},
  volume       = {152},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Trajectory planning of transcranial magnetic stimulation
manipulator based on time-safety collision optimization. <em>RAS</em>,
<em>152</em>, 104039. (<a
href="https://doi.org/10.1016/j.robot.2022.104039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, an optimal time-safety collision trajectory planning method of manipulator is proposed. It optimizes the coupling and contradictory performance indexes of manipulator joint motion time and safety collision coefficient. The trajectory of the manipulator can be transformed into the position and time series in the joint space by Inverse Kinematics (IK). Among the splines, quintic B-spline used commonly for interpolating robotic trajectories is preferred also in this study. Under the constraints of the manipulator, non-dominated sorting genetic algorithms-II (NSGA-II) is used to optimize the objective function. The total optimized running time is shortened by 33.07 s. The main joints damage before and after optimization of safety collision have been reduced more than 49.4\%. After quintic B-spline interpolation, the time-safety collision of manipulator trajectory are effectively optimized. In general, the execution efficiency of the manipulator is improved, the collision damage to the human head is reduced, and the motion control performance of TMS manipulator is improved to be widely used in medical clinic.},
  archive      = {J_RAS},
  author       = {Qiang Cheng and Xiaolong Hao and Yi Wang and Wenxiang Xu and Shijun Li},
  doi          = {10.1016/j.robot.2022.104039},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104039},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Trajectory planning of transcranial magnetic stimulation manipulator based on time-safety collision optimization},
  volume       = {152},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Summarizing large scale 3D mesh for urban navigation.
<em>RAS</em>, <em>152</em>, 104037. (<a
href="https://doi.org/10.1016/j.robot.2022.104037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cameras have become increasingly common in vehicles, smartphones, and advanced driver assistance systems . The areas of application of these cameras in the world of intelligent transportation systems are becoming more and more varied: pedestrian detection, line crossing detection, navigation, …A major area of research currently focuses on mapping that is essential for localization and navigation. However, this step generates an important problem of memory management . Indeed, the memory space required to accommodate the map of a small city is measured in tens gigabytes. In addition, several providers today are competing to produce High-Definition (HD) maps. These maps offer a rich and detailed representation of the environment for highly accurate localization . However, they require a large storage capacity and high transmission and update costs. To overcome these problems, we propose a solution to summarize this type of map by reducing the size while maintaining the relevance of the data for navigation based on vision only. The summary consists in a set of spherical images augmented by depth and semantic information and allowing to keep the same level of visibility in every directions. These spheres are used as landmarks to offer guidance information to a distant agent. They then have to guarantee, at a lower cost, a good level of precision and speed during navigation. Some experiments on real data demonstrate the feasibility for obtaining a summarized map while maintaining a localization with interesting performances.},
  archive      = {J_RAS},
  author       = {Imeen Ben Salah and Sébastien Kramm and Cédric Demonceaux and Pascal Vasseur},
  doi          = {10.1016/j.robot.2022.104037},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104037},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Summarizing large scale 3D mesh for urban navigation},
  volume       = {152},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Perceived safety in physical human–robot interaction—a
survey. <em>RAS</em>, <em>151</em>, 104047. (<a
href="https://doi.org/10.1016/j.robot.2022.104047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This review paper focuses on different aspects of perceived safety for a number of autonomous physical systems. This is a major aspect of robotics research, as more and more applications allow humans and autonomous systems to share their space, with crucial implications both on safety and on its perception. The alternative terms used to express related concepts (e.g., psychological safety, trust, comfort, stress, fear, and anxiety) are listed and explained. Then, the available methods to assess perceived safety (i.e., questionnaires, physiological measurements, behavioral assessment, and direct input devices) are described. Six categories of autonomous systems are considered (industrial poly-articulated manipulators, indoor mobile robots, mobile manipulators , humanoid robots , drones, and autonomous vehicles), providing an overview of the main themes related to perceived safety in the specific domain, a description of selected works, and an analysis of how motion and characteristics of the system influence the perception of safety. The survey also discusses experimental duration and location of the reviewed papers, and the connection between perceived safety and safety standards.},
  archive      = {J_RAS},
  author       = {Matteo Rubagotti and Inara Tusseyeva and Sara Baltabayeva and Danna Summers and Anara Sandygulova},
  doi          = {10.1016/j.robot.2022.104047},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104047},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Perceived safety in physical human–robot interaction—A survey},
  volume       = {151},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Environment-adaptive learning from demonstration for
proactive assistance in human–robot collaborative tasks. <em>RAS</em>,
<em>151</em>, 104046. (<a
href="https://doi.org/10.1016/j.robot.2022.104046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proactive assistance in human–robot collaboration remains a challenging objective, as the spatial–temporal coordination of the human–robot motion must be considered in conjunction with the object and environmental context. In this paper, we propose an environment-adaptive probabilistic interaction primitive method using learning-from-demonstration. In particular, we propose a novel phase estimation algorithm called Single-axis Uniform Interval Interpolation, which alleviates the restriction of Gaussian or uniform distribution of phase variables. In addition, the environmental constraints in human–robot interactive skills are learned via the regression between environmental parameters and the weight vectors . The proposed method is implemented in a proactive robotic system for typical industrial-motivated human–robot collaborative scenarios, such as assistive push-button assembly and human–robot collaborative object covering. The experimental result validates the effectiveness of the proposed approach.},
  archive      = {J_RAS},
  author       = {Kun Qian and Xin Xu and Huan Liu and Jishen Bai and Shan Luo},
  doi          = {10.1016/j.robot.2022.104046},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104046},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Environment-adaptive learning from demonstration for proactive assistance in human–robot collaborative tasks},
  volume       = {151},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A parallel shape formation method for swarm robotics.
<em>RAS</em>, <em>151</em>, 104043. (<a
href="https://doi.org/10.1016/j.robot.2022.104043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to cope with diversified tasks and unstructured environments, a parallel shape formation method for swarm robotics is introduced to adjust the system’s configuration autonomously and flexibly with the user-specified 2-D shape. Given the desired shape to be formed in the form of analytic functions, the forming task of the swarm system is divided into two sub-tasks: the edge robot forming task and the internal robot forming task. Then, the seed robot is selected through the generation and transmission of the gradient to establish the relative coordinate system, and the initial coordinates of robots are obtained through trilateral positioning. Based on that, using the artificial potential field method, under the action of gravitational force generated by the objective analytic functions and repulsion forces generated by other individuals in the neighborhood, edge individuals move to the target boundary; at the same time, internal individuals spread evenly in the target area under the action of the repulsion forces generated by each other. During the forming process, the two sub-tasks are executed in parallel, and the individuals continue to update their real-time positions by dead-reckoning until the desired shape is formed. We evaluate the feasibility and scalability of this novel method in simulation-based experiments, and implement the parallel shape formation algorithm on the Cilibot robot, a hardware system developed in our lab.},
  archive      = {J_RAS},
  author       = {Hong-an Yang and Yuhua Li and Xin Duan and Gaopan Shen and Shaohua Zhang},
  doi          = {10.1016/j.robot.2022.104043},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104043},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A parallel shape formation method for swarm robotics},
  volume       = {151},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hierarchical forest based fast online loop closure for
low-latency consistent visual-inertial SLAM. <em>RAS</em>, <em>151</em>,
104035. (<a href="https://doi.org/10.1016/j.robot.2022.104035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual-inertial odometry (VIO) shows high localization accuracy in many environments. However, the inevitable estimation drift is constantly accumulating, which even leads to failures. Hence, an efficient loop closing (LC) is necessary for correcting drift. Unlike most existing methods rely on pre-trained model, we propose an incremental hierarchical forest (HF) based LC method (HF-LC), which online encodes frames for loop closing without any prior information, and it is suitable for arbitrary images. We thoroughly exploit the duality of binary descriptors, and propose a hierarchical forest based descriptor search method for loop frame retrieval, which is extremely fast with efficient descriptor clustering, binary search, and grid based loop closure selection modules. Moreover, we integrate HF-LC into a state-of-the-art keyframe based VIO, and develop a comprehensive hierarchical forest based visual-inertial SLAM (HFVIS) system. Furthermore, a lightweight geometric verification is designed for correctness checking and pose computing of loop keyframes. Finally, all keyframe poses are further optimized in global pose-graph optimization, which achieves better consistency. The efficacy of our method is validated on ground robot and aerial vehicle datasets. Extensive results confirm that the proposed HF-LC achieves better precision–recall performance, and our HFVIS system has higher localization accuracy and superior real-time performance.},
  archive      = {J_RAS},
  author       = {Hongle Xie and Weidong Chen and Jingchuan Wang},
  doi          = {10.1016/j.robot.2022.104035},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104035},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Hierarchical forest based fast online loop closure for low-latency consistent visual-inertial SLAM},
  volume       = {151},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploring factors influencing the acceptance of social
robots among early adopters and mass market representatives.
<em>RAS</em>, <em>151</em>, 104033. (<a
href="https://doi.org/10.1016/j.robot.2022.104033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When designing social robots, it is crucial to understand the diverse expectations of different kinds of innovation adopters. Different factors influence early adopters of innovations and mass market representatives’ perceptions of the usefulness of social robots. The first aim of the study was to test how applicable the technology acceptance model 3 (TAM3) is in the context of social robots. Participants’ acceptance of social robotics in a workplace environment in the fuzzy front-end (FFE) innovation phase of a robot development project was examined. Based on the findings for the model, we developed a reduced version of the TAM3 that is more applicable for social robots. The second objective was to analyze how early adopters’ and mass market representatives’ acceptance of social robots differs. Quantitative research methods were used. For early adopters, result demonstrability has a significant influence on perceived usefulness of social robots, while for mass market representatives, perceived enjoyment has a more significant influence on perceived usefulness. The findings indicate that users’ innovation adoption style influences the factors that users consider important in the usefulness of social robots. Robot developers should take these into account during the FFE innovation phase.},
  archive      = {J_RAS},
  author       = {Ulla A. Saari and Antero Tossavainen and Kirsikka Kaipainen and Saku J. Mäkinen},
  doi          = {10.1016/j.robot.2022.104033},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104033},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Exploring factors influencing the acceptance of social robots among early adopters and mass market representatives},
  volume       = {151},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust interaction control for environments having
uncertainties. <em>RAS</em>, <em>151</em>, 104023. (<a
href="https://doi.org/10.1016/j.robot.2022.104023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physical human–robot and/or robot–environment interactions require robust contact stability because an unstable interaction could harm the human or environment. Maintaining effective contact performance while preserving robust contact stability still remains a considerable challenge. This is especially true when interacting with uncertain environments , which are characterized as systems experiencing sudden impedance changes from low to high. Although many existing control methods can be useful for practical interaction controls, they may not be applicable to some uncertain environments; they require either a priori knowledge of the environments before contact or time to update parameters while assuming contact stability during adaptation. This paper proposes a new robust interaction control strategy, the stability enforcement-then-performance enhancement, to provide effective contact performance while guaranteeing robust interaction stability in uncertain environments. The proposed strategy first stabilizes the interaction system by regulating a force input command to the robot system. For robustness to uncertain environments, this regulation is based on the robot’s own stability limit only. Performance enhancement then follows by adjusting the motion commands or adapting the robot’s impedance parameters because continuous stable contact can be maintained by the stability enforcement control even in uncertain environments. Theoretical analysis and typical contact experiments demonstrate the effectiveness of the proposed control strategy.},
  archive      = {J_RAS},
  author       = {Sehun Kim and Jeha Ryu},
  doi          = {10.1016/j.robot.2022.104023},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104023},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Robust interaction control for environments having uncertainties},
  volume       = {151},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive and multiple time-scale eligibility traces for
online deep reinforcement learning. <em>RAS</em>, <em>151</em>, 104019.
(<a href="https://doi.org/10.1016/j.robot.2021.104019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning (DRL) is one promising approach to teaching robots to perform complex tasks. Because methods that directly reuse the stored experience data cannot follow the change of the environment in robotic problems with a time-varying environment, online DRL is required. The eligibility traces method is well known as an online learning technique for improving sample efficiency in traditional reinforcement learning with linear regressors rather than DRL. The dependency between parameters of deep neural networks would destroy the eligibility traces, which is why they are not integrated with DRL. Although replacing the gradient with the most influential one rather than accumulating the gradients as the eligibility traces can alleviate this problem, the replacing operation reduces the number of reuses of previous experiences. To address these issues, this study proposes a new eligibility traces method that can be used even in DRL while maintaining high sample efficiency. When the accumulated gradients differ from those computed using the latest parameters, the proposed method takes into account the divergence between the past and latest parameters to adaptively decay the eligibility traces. Bregman divergences between outputs computed by the past and latest parameters are exploited due to the infeasible computational cost of the divergence between the past and latest parameters. In addition, a generalized method with multiple time-scale traces is designed for the first time. This design allows for the replacement of the most influential adaptively accumulated (decayed) eligibility traces. The proposed method outperformed conventional methods in terms of learning speed and task quality by the learned policy on benchmark tasks on a dynamic robotic simulator. A real-robot demonstration confirmed the significance of online DRL as well as the adaptability of the proposed method to a changing environment.},
  archive      = {J_RAS},
  author       = {Taisuke Kobayashi},
  doi          = {10.1016/j.robot.2021.104019},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104019},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Adaptive and multiple time-scale eligibility traces for online deep reinforcement learning},
  volume       = {151},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The role of pre-tensioned springs in 3 pneumatic artificial
muscles driven joint mechanisms with sliding mode controllers.
<em>RAS</em>, <em>151</em>, 104017. (<a
href="https://doi.org/10.1016/j.robot.2021.104017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the past decade, soft robotics has become a growing new field, and researchers have developed different kinds of soft robots with different actuation technologies and mechanisms. Pneumatic artificial muscles (PAMs), as one kind of the most popular soft actuators, have been widely applied to robotic systems that assist persons. However, PAMs are highly nonlinear, which makes it difficult to achieve accurate force and motion control. Another major problem is their slow response. Efforts have been made to improve the accuracy and responses of PAMs. Adding pre-tensioned springs is one efficient way to improve responses of mechatronic systems . However, the role of pre-tensioned springs in different PAMs-driven mechanical structures has not been sufficiently investigated. In this study, two joint structures combining pre-tensioned springs and PAMs were modeled and their sliding mode controllers (SMC) were designed. The control results were compared with canonical antagonistic PAMs structure in simulation experiments. Moreover, a one-joint prototype actuated by 3 PAMs connected in series with two series-connected springs, was built and used to validate the simulated model. The results with both simulation models and the prototype mechanism showed that, one of joint structure with pre-tensioned springs could achieve better step response and control accuracy than the canonical antagonistic PAMs structure.},
  archive      = {J_RAS},
  author       = {Zhongchao Zhou and Yuanyuan Wang and Wenwei Yu},
  doi          = {10.1016/j.robot.2021.104017},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104017},
  shortjournal = {Robot. Auton. Syst.},
  title        = {The role of pre-tensioned springs in 3 pneumatic artificial muscles driven joint mechanisms with sliding mode controllers},
  volume       = {151},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Overtaking decision and trajectory planning in highway via
hierarchical architecture of conditional state machine and chance
constrained model predictive control. <em>RAS</em>, <em>151</em>,
104014. (<a href="https://doi.org/10.1016/j.robot.2021.104014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An overtaking trajectory planning algorithm is an essential part of autonomous vehicles, but maximizing trip efficiency (minimum travel time) while guaranteeing safety is non-trivial. In particular, to achieve optimal trajectory results in all situations using one algorithm is challenging because overtaking is a complex maneuver in which several behaviors are combined. In this paper, an overtaking algorithm that employs a finite state machine as a high-level decision maker and chance constrained model predictive control as a trajectory planner is proposed to optimize trip efficiency and ride comfort while guaranteeing safety. By combining two methods in a hierarchical structure, the proposed algorithm takes advantage of each method to realize optimality and real-time performance. Using the conditional state machine (CSM), algorithm classifies maneuver states that can ensure safety, and sets the optimal multi-vehicle constraints in each state. The chance constrained model predictive control (MPC) plans an optimal trajectory that considers the prediction uncertainty, safety, trip efficiency and ride comfort. To rigorously evaluate both trip efficiency and safety, the performance of the proposed overtaking algorithm is evaluated in a statistical manner for various level of service (LOS) scenarios. Simulation results show that the optimal trajectory was generated in a multi-vehicle situation while ensuring higher safety than the rule-based algorithm.},
  archive      = {J_RAS},
  author       = {Seungmin Jeon and Kibeom Lee and Dongsuk Kum},
  doi          = {10.1016/j.robot.2021.104014},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104014},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Overtaking decision and trajectory planning in highway via hierarchical architecture of conditional state machine and chance constrained model predictive control},
  volume       = {151},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Uncertain moving obstacles avoiding method in 3D arbitrary
path planning for a spherical underwater robot. <em>RAS</em>,
<em>151</em>, 104011. (<a
href="https://doi.org/10.1016/j.robot.2021.104011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to avoid the risk of obstacles collision during the spherical underwater robot (SUR) move to target points in 3D arbitrary path planning , an underwater obstacle avoiding method was studied. Considering the uncertainty of the movement of obstacles in the actual environment, we present an uncertain moving obstacle avoiding method based on the improved velocity obstacle method. In addition, to reduce the distance and time of obstacle avoidance, the concept of the time of obstacle avoiding was designed. First, the size and velocity information of obstacles are obtained through the camera, which can provide an accurate decision basis for obstacles avoidance in the next step. Then, according to the time when the robot collides with the obstacle, the time of start and end of the obstacle avoidance is determined. The movement direction and velocity of the robot are obtained based on the improved velocity obstacle method and the movement characteristics of SUR. Finally, a detailed 3D arbitrary path planning analysis based on an improved ant colony algorithm was conducted. A series of experiments were carried out in the pool that validates the proposed methods are also presented.},
  archive      = {J_RAS},
  author       = {Ruochen An and Shuxiang Guo and Liang Zheng and Hideyuki Hirata and Shuoxin Gu},
  doi          = {10.1016/j.robot.2021.104011},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104011},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Uncertain moving obstacles avoiding method in 3D arbitrary path planning for a spherical underwater robot},
  volume       = {151},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Special issue on the 9th european conference on mobile
robots (ECMR 2019). <em>RAS</em>, <em>150</em>, 104050. (<a
href="https://doi.org/10.1016/j.robot.2022.104050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_RAS},
  author       = {Libor Přeučil ( Guest Editors ) and Sven Behnke and Miroslav Kulich},
  doi          = {10.1016/j.robot.2022.104050},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104050},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Special issue on the 9th european conference on mobile robots (ECMR 2019)},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Kinematic sensitivity analysis of manipulators using a novel
dimensionless index. <em>RAS</em>, <em>150</em>, 104021. (<a
href="https://doi.org/10.1016/j.robot.2022.104021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Geometric errors directly affect the position of the end-effector of a Parallel Kinematic Manipulator (PKM), thus reducing its positioning accuracy. However, the tasks that are performed by PKMs, such as high-precision machining using a kinematic model with nominal values, are affected by machine errors that are not taken into account. Therefore, it is important to make an accurate determination of a machine’s error factors to obtain an accurate error model. Identifying the most crucial geometric errors and determining a method to control them is key in improving the accuracy of PKMs. To achieve this objective, a new method of sensitivity analysis, allowing the crucial geometric errors for parallel and serial manipulators to be identified, is proposed. A new dimensionless sensitivity index, based on the definition of a Local Sensitivity Index (LSI), is used to perform this analysis. The geometric error modeling is performed by deriving the position vector of the end-effector of the PKM. To test the efficiency of the proposed method, the main sources of PAR2 PKM errors are identified. The results show that 33.3\% of the error components (main errors) from all error sources can be improved, to achieve a 51.8\% improvement in the accuracy of the position error. These results indicate that the error sensitivity analysis method is quite effective, and can significantly contribute to improving the accuracy of a PKM.},
  archive      = {J_RAS},
  author       = {Allaoua Brahmia and Ridha Kelaiaia and Olivier Company and Ahmed Chemori},
  doi          = {10.1016/j.robot.2022.104021},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104021},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Kinematic sensitivity analysis of manipulators using a novel dimensionless index},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Empirical study of future image prediction for image-based
mobile robot navigation. <em>RAS</em>, <em>150</em>, 104018. (<a
href="https://doi.org/10.1016/j.robot.2021.104018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent image-based robotic systems use predicted future state images to control robots. Therefore, the prediction accuracy of the future state image affects the performance of the robot. To predict images, most previous studies assume that the camera captures the entire scene and that the environment is static. However, in real robot applications, these assumptions do not always hold. For example, if a camera is attached to a mobile robot, its view changes from time to time. In this study, we analyzed the relationship between the performance of the image prediction model and the robot’s behavior, controlled by an image-based navigation algorithm. Through mobile robot navigation experiments using front-faced and omni-directional cameras, we discussed the capabilities of the image prediction models and demonstrated their performance when applied to the image-based navigation algorithm. Moreover, to adapt to the dynamic changes in the environment, we studied the effectiveness of directing the camera to the ceiling. We showed that robust navigation can be achieved without using images from cameras directed toward the front or the floor, because these views can be disturbed by moving objects in a dynamic environment.},
  archive      = {J_RAS},
  author       = {Yu Ishihara and Masaki Takahashi},
  doi          = {10.1016/j.robot.2021.104018},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104018},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Empirical study of future image prediction for image-based mobile robot navigation},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A framework for spatial map generation using acoustic echoes
for robotic platforms. <em>RAS</em>, <em>150</em>, 104009. (<a
href="https://doi.org/10.1016/j.robot.2021.104009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we present a framework for constructing a spatial map of an indoor environment using the concept of echolocation. More specifically, we propose a non-linear least squares (NLS) estimator which is combined with a spatial filtering technique, e.g., beamforming , to estimate both the time-of-arrival (TOA) and direction-of-arrival (DOA) of the acoustic echoes. The proposed framework is complemented with an echo detector to classify a spurious estimate and an acoustic reflector, i.e., a wall. Based on these estimators, we propose two algorithms that complement existing range sensors and aid robotic platforms in acoustic reflector localization and mapping: single-channel localization and mapping (ScLAM) and a multi-channel localization and mapping (McLAM). Compared to commonly used sensors, such as lidar , cameras and ultrasonic sensors , our proposed model-based approach can detect transparent surfaces that are typically found in an office environment and could work in audible frequency ranges. A proof-of-concept robotic platform was built to test our algorithms. According to our evaluation, both qualitative and quantitative experiments reveal that the proposed methods can detect an acoustic reflector up to a distance of 1.5 m at a signal-to-diffuse-noise ratio (SDNR) of 0 dB in a simulated environment and 10 dB in a real environment with an accuracy of 80\%.},
  archive      = {J_RAS},
  author       = {Usama Saqib and Jesper Rindom Jensen},
  doi          = {10.1016/j.robot.2021.104009},
  journal      = {Robotics and Autonomous Systems},
  pages        = {104009},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A framework for spatial map generation using acoustic echoes for robotic platforms},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dual-view 3D object recognition and detection via lidar
point cloud and camera image. <em>RAS</em>, <em>150</em>, 103999. (<a
href="https://doi.org/10.1016/j.robot.2021.103999">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When it comes to the accuracy of autonomous motion, it is necessary to consider object detection and recognition, especially for the robot application of the complex environment. This paper investigates novel dual-view 3D object detection networks combined with the Lidar point cloud and RGB image in engineering scenarios. The developed system is applied for autonomous vehicles that the detected objects are cars, cyclists, and pedestrians. Firstly, a feature extraction network based on the residual module is presented, and the specific features are from the RGB image . The point cloud is transformed into Bird’s Eye View (BEV), and the BEV feature extraction network is built based on sparse convolution. Besides, the feature maps are input into the region proposal network (RPN) to obtain the optimal proposal so that the object classification and the bounding box regression are obtained. Finally, to evaluate the flexibility of the developed framework, extensive data sets are generated through the CARLA simulator and verified on the KITTI data set and unmanned motion platform (BIT-NAZA robot), indicating that the proposed networks can achieve satisfactory performance in the real-world scenario.},
  archive      = {J_RAS},
  author       = {Jing Li and Rui Li and Jiehao Li and Junzheng Wang and Qingbin Wu and Xu Liu},
  doi          = {10.1016/j.robot.2021.103999},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103999},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Dual-view 3D object recognition and detection via lidar point cloud and camera image},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CL-MAPF: Multi-agent path finding for car-like robots with
kinematic and spatiotemporal constraints. <em>RAS</em>, <em>150</em>,
103997. (<a href="https://doi.org/10.1016/j.robot.2021.103997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Agent Path Finding has been widely studied in the past few years due to its broad application in the field of robotics and AI . However, previous solvers rely on several simplifying assumptions. This limits their applicability in numerous real-world domains that adopt nonholonomic car-like agents rather than holonomic ones. In this paper, we give a mathematical formalization of the Multi-Agent Path Finding for Car-Like robots (CL-MAPF) problem. We propose a novel hierarchical search-based solver called Car-Like Conflict-Based Search to address this problem. It applies a body conflict tree to address collisions considering the shapes of the agents. We introduce a new algorithm called Spatiotemporal Hybrid-State A* as the single-agent planner to generate agents’ paths satisfying both kinematic and spatiotemporal constraints. We also present a sequential planning version of our method, sacrificing a small amount of solution quality to achieve a significant reduction in runtime. We compare our method with two baseline algorithms on a dedicated benchmark and validate it in real-world scenarios. The experiment results show that the planning success rate of both baseline algorithms is below 50\% for all six scenarios, while our algorithm maintains that of over 98\%. It also gives clear evidence that our algorithm scales well to 100 agents in 300 m × × 300 m scenario and is able to produce solutions that can be directly applied to Ackermann-steering robots in the real world. The benchmark and source code are released in https://github.com/APRIL-ZJU/CL-CBS . The video of the experiments can be found on YouTube .},
  archive      = {J_RAS},
  author       = {Licheng Wen and Yong Liu and Hongliang Li},
  doi          = {10.1016/j.robot.2021.103997},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103997},
  shortjournal = {Robot. Auton. Syst.},
  title        = {CL-MAPF: Multi-agent path finding for car-like robots with kinematic and spatiotemporal constraints},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hovering control of an underwater robot with tilting
thrusters using the decomposition and compensation method based on a
redundant actuation model. <em>RAS</em>, <em>150</em>, 103995. (<a
href="https://doi.org/10.1016/j.robot.2021.103995">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Six-degree-of-freedom (6-DOF) hovering control is important for underwater robots to perform various tasks. Our previous underwater robot study, which used tilting thrusters , could not control 6-DOF motion simultaneously owing to several mechanical and control problems. In this study, we developed a new robot with tilting thrusters and improved 6-DOF hovering performance. The maneuverability of the robot was evaluated by analyzing the force and moment of the thrust vector. Based on this, a redundant tilting mechanism without constraints was designed to solve structural problems. A proportional–integral–derivative (PID)-based control design using the decomposition and compensation method (PID-DC) that is appropriate for this mechanism, was derived. The decomposition method was used to overcome the nonlinearity of the thrust vector caused by the tilting mechanism, and the null-space projection technique was applied to minimize the thrust force and avoid the boundary of the tilting angle. A compensator based on the empirical model of the tilting thruster transferred the control input to the system with regulation. Simulation and experimental results verified the validity of the controller for the 6-DOF hovering motion of the robot, and the hovering performance was significantly improved. Furthermore, the stability of the hovering performance under tidal currents was demonstrated through disturbance experiments.},
  archive      = {J_RAS},
  author       = {Jeongae Bak and Yecheol Moon and Jongwon Kim and Santhakumar Mohan and TaeWon Seo and Sangrok Jin},
  doi          = {10.1016/j.robot.2021.103995},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103995},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Hovering control of an underwater robot with tilting thrusters using the decomposition and compensation method based on a redundant actuation model},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cooperative distributed nonlinear model predictive control
of a formation of differentially-driven mobile robots. <em>RAS</em>,
<em>150</em>, 103993. (<a
href="https://doi.org/10.1016/j.robot.2021.103993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the increasing complexity of today’s tasks and the demand for higher performance and robustness, using a single robot is not always expedient in robotics applications . Therefore, having multiple autonomous robotic agents collaborate utilizing explicit communication is gaining more attention. The goal of this article is to develop a distributed algorithm that allows the formation control of multiple differentially-driven mobile robots. The formation control goal is formulated in a novel manner by leveraging results on the control of a single differentially-driven mobile robot, which is sophisticated due to the present non-holonomic constraint. This results in a nonlinear distributed control problem. The fundamental functionality of the developed algorithm is analyzed in simulation scenarios. The applicability to real-life scenarios is demonstrated through experiments with custom hardware. To the best of the authors’ knowledge, this is the first time that nonlinear distributed model predictive control is applied to a formation of differentially-driven mobile robots using a theoretically-founded cost function and, moreover, that the results are verified with hardware experiments.},
  archive      = {J_RAS},
  author       = {Mario Rosenfelder and Henrik Ebel and Peter Eberhard},
  doi          = {10.1016/j.robot.2021.103993},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103993},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Cooperative distributed nonlinear model predictive control of a formation of differentially-driven mobile robots},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Flexible gait transition for six wheel-legged robot with
unstructured terrains. <em>RAS</em>, <em>150</em>, 103989. (<a
href="https://doi.org/10.1016/j.robot.2021.103989">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The flexibility of gait and trajectory planning with heavy payload are the main challenges for legged stable walking of hexapod robots in unstructured terrain, especially in time-varying and local terrain mutation conditions. To guarantee adaptability in unstructured terrain environment, the factors, including the obstacle height, terrain depth, and secure foothold as well as stability state, should be considered in the gait and trajectory planning . In this article, a novel gait transition hierarchical control framework based on a flexible gait planner (FGP), and gait feedback regulator (GFR) with behavior rules is proposed for the developed hexapod wheel-legged robot (BIT-6NAZA). The core of this gait planner is to select the optimal footholds and change gait types according to secure foothold and stability margin and kinematic margin of legs, and the GFR is applied to modify the foot-end trajectory of the selected gait according to the terrain feedback information to adapt to unstructured terrain. Finally, taking BIT-6NAZA robot as an example, the simulation and experiment are carried out under the proposed control framework. The co-simulation and experimental results show that the robot can modify the foot-end trajectory in dynamic unstructured terrain and obtain elastic gait in obstacle avoidance.},
  archive      = {J_RAS},
  author       = {Zhihua Chen and Jiehao Li and Shoukun Wang and Junzheng Wang and Liling Ma},
  doi          = {10.1016/j.robot.2021.103989},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103989},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Flexible gait transition for six wheel-legged robot with unstructured terrains},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parameterised robotic system meta-model expressed by
hierarchical petri nets. <em>RAS</em>, <em>150</em>, 103987. (<a
href="https://doi.org/10.1016/j.robot.2021.103987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper presents a model-based approach to developing robotic system controllers. Central to this approach is a parameterised meta-model that describes the generic robotic system from two points of view: structure and activity. By appropriate parameterisation of the meta-model one can obtain a particular model of a robotic system performing desired tasks. The meta-model is expressed using the Robotic System Hierarchical Petri Net (RSHPN), a 6-layer Petri net tailored for robotics. Each layer describes the activity of the robotic system at a completely different level of abstraction. This guarantees the separation of concerns. The required model emerges from the meta-model by appropriate parameterisation of the layers of the RSHPN. Introduction of parameterisation enables the robot designer to focus only on the concepts derived from the domain. It greatly facilitates the robotic system development process as it gives the designer clear guidance on what needs to be defined and what is imposed by the design pattern . The resulting single RSHPN model is used both to verify some properties of the system, e.g. lack of deadlocks , but also to automatically generate controller code. The presented approach is illustrated by examples of the creation of two different robotic systems.},
  archive      = {J_RAS},
  author       = {Maksym Figat and Cezary Zieliński},
  doi          = {10.1016/j.robot.2021.103987},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103987},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Parameterised robotic system meta-model expressed by hierarchical petri nets},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Convolutionally evaluated gradient first search path
planning algorithm without prior global maps. <em>RAS</em>,
<em>150</em>, 103985. (<a
href="https://doi.org/10.1016/j.robot.2021.103985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the existing path planning algorithms require a prior global map. Although there have been some algorithms proposed for unknown environments, they can only deal with those which just have several hidden obstacles in a roughly known global map. In order to improve the efficiency of robot’s path planning without prior global maps, this paper proposes a Convolutionally Evaluated Gradient First Search (CE-GFS) path planning algorithm. It allows the robot to collect environmental information and complete path planning simultaneously. Firstly, the Gradient First Search (GFS) algorithm is proposed based on the gradient score parameter, with which the conventional cost function is replaced. The GFS can adapt to any moving direction through the environmental information surrounding the mobile robot and computing the gradient score parameter. Secondly, CE-GFS path planning algorithm is proposed based on GFS and convolutional evaluation method. The CE-GFS helps the robots to evaluate the efficiency of the global path and get global perception ability, so that they are prevented from going astray, which can significantly improve the efficiency of path planning. Finally, several simulation tests and field tests have been carried out. The test results show that convolutional evaluation improves the efficiency of CE-GFS by 86.94\% on average compared with GFS at the price of 0.18\% decrease in path planning success rate. Moreover, the time cost of the proposed CE-GFS algorithm is 42.18\% less than that of FAR-Planner in some special cases.},
  archive      = {J_RAS},
  author       = {Yizhi Wu and Fei Xie and Lei Huang and Rui Sun and Jiquan Yang and Qiang Yu},
  doi          = {10.1016/j.robot.2021.103985},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103985},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Convolutionally evaluated gradient first search path planning algorithm without prior global maps},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The PoundCloud framework for ROS-based cloud robotics: Case
studies on autonomous navigation and human–robot interaction.
<em>RAS</em>, <em>150</em>, 103981. (<a
href="https://doi.org/10.1016/j.robot.2021.103981">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the increasing popularity of the cloud robotics paradigm, the literature on the field still lacks comprehensive analysis on several aspects of the technology. Therefore, the adoption of common standards and frameworks is fundamental for developing the field and allowing practical works to be reproduced and compared. This work presents a ROS-based open framework for robot-cloud communication, easing the integration of robotics and remote cloud platforms, and discusses the implementation of the overall cloud robotics stack over open source software and commercial off-the-shelf devices. Additionally, we present two practical implementations in which most of the computation is carried out remotely and perform a series of experiments to demonstrate our technique. Our results indicate that task times can be reduced up to 15\% when using remote cloud platforms even under 150 ms average communication latency over the public Internet while observing figures as low as 2\% on throughput loss in sensor data transmission. In general, such results point to the feasibility of the presented approach in different classes of applications, even under non-ideal network and cloud settings.},
  archive      = {J_RAS},
  author       = {Ricardo C. Mello and Sergio D. Sierra M. and Wandercleyson M. Scheidegger and Marcela C. Múnera and Carlos A. Cifuentes and Moises R.N. Ribeiro and Anselmo Frizera-Neto},
  doi          = {10.1016/j.robot.2021.103981},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103981},
  shortjournal = {Robot. Auton. Syst.},
  title        = {The PoundCloud framework for ROS-based cloud robotics: Case studies on autonomous navigation and human–robot interaction},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ChildBot: Multi-robot perception and interaction with
children. <em>RAS</em>, <em>150</em>, 103975. (<a
href="https://doi.org/10.1016/j.robot.2021.103975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present an integrated robotic system capable of participating in and performing a wide range of educational and entertainment tasks collaborating with one or more children. The system, called ChildBot, features multimodal perception modules and multiple robotic agents that monitor the interaction environment and can robustly coordinate complex Child–Robot Interaction use-cases. In order to validate the effectiveness of the system and its integrated modules, we have conducted multiple experiments with a total of 52 children. Our results show improved perception capabilities in comparison to our earlier works that ChildBot was based on. In addition, we have conducted a preliminary user experience study, employing some educational/entertainment tasks, that yields encouraging results regarding the technical validity of our system and initial insights on the user experience with it.},
  archive      = {J_RAS},
  author       = {Niki Efthymiou and Panagiotis P. Filntisis and Petros Koutras and Antigoni Tsiami and Jack Hadfield and Gerasimos Potamianos and Petros Maragos},
  doi          = {10.1016/j.robot.2021.103975},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103975},
  shortjournal = {Robot. Auton. Syst.},
  title        = {ChildBot: Multi-robot perception and interaction with children},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Teleoperation methods and enhancement techniques for mobile
robots: A comprehensive survey. <em>RAS</em>, <em>150</em>, 103973. (<a
href="https://doi.org/10.1016/j.robot.2021.103973">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a world with rapidly growing levels of automation, robotics is playing an increasingly significant role in every aspect of human endeavour. In particular, many types of mobile robots are increasingly being utilised in places and for tasks that are difficult and dangerous for humans. Although the vision of fully autonomous mobile robotic platforms that can perform complex tasks without direct guidance from a human operator is compelling, the reality is that the current state of robotics technology is still a long way from being able to achieve this capability outside of very narrowly constrained contexts. Technology advancement for improved mobile robotic teleoperation and remote control is vital to enable robotic vehicles to operate with increasing autonomy levels while allowing for effective remote operation when task complexity is too great for the autonomous systems . Being motivated to bridge this gap, we present a review of existing teleoperation methods and enhancement techniques for control of mobile robots. After defining teleoperation, we provide a detailed review that analyses, categorises, and summarises existing mobile robot teleoperation methods. Next, we highlight existing enhancement techniques that have been applied to these teleoperation methods, along with their relative advantages and disadvantages. Finally, several promising future research directions are identified. The paper concludes with a discussion of research challenges and future research possibilities.},
  archive      = {J_RAS},
  author       = {MD Moniruzzaman and Alexander Rassau and Douglas Chai and Syed Mohammed Shamsul Islam},
  doi          = {10.1016/j.robot.2021.103973},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103973},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Teleoperation methods and enhancement techniques for mobile robots: A comprehensive survey},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FEM-based trajectory tracking control of a soft trunk robot.
<em>RAS</em>, <em>150</em>, 103961. (<a
href="https://doi.org/10.1016/j.robot.2021.103961">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a novel class of robots, soft robots have demonstrated many desirable mechanical properties than traditional rigid robots due to their nature of being compliant, flexible and hyper-redundant, such as great adaptability to unknown environments, safe human robot interaction (HRI), energy-saving actuation and the maneuverability to display diverse mechanical properties. However, its inherent high-DoF nature would result in some complex nonlinear behaviors , and their kinematic or dynamic models are therefore harder to deduce than the ones of conventional rigid robots. In this paper, we propose a trajectory tracking control strategy for a soft trunk robot based on Finite Element Method (FEM). We first plan a feasible trajectory for the studied robot in SOFA (a FEM-based simulator) by solving a model-prediction-control (MPC)-based optimization problem . The second step is to conduct linearization around the pre-designed trajectory, based on which an associated controller can be then developed. The detailed derivation of the mentioned work is explained accordingly. In the end, the results of experimental validation is presented to prove the feasibility of the proposed method.},
  archive      = {J_RAS},
  author       = {Ke Wu and Gang Zheng and Junfeng Zhang},
  doi          = {10.1016/j.robot.2021.103961},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103961},
  shortjournal = {Robot. Auton. Syst.},
  title        = {FEM-based trajectory tracking control of a soft trunk robot},
  volume       = {150},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AND/OR search techniques for chance constrained motion
primitive path planning. <em>RAS</em>, <em>149</em>, 103991. (<a
href="https://doi.org/10.1016/j.robot.2021.103991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motion primitive planning under parametric uncertainty may be modeled as a chance-constrained Markov Decision Process (CCMDP). Single-query solutions to CCMDPs can be obtained by searching the And/Or graph representing the state–action space of the system. The Risk-bounded AO* (RAO*) algorithm has been proposed as a solution method for this problem, but it scales poorly to MDPs resulting from a motion primitive discretization because it has no mechanism to prioritize expansion of AND nodes. This paper describes an induced heuristic for state–action pairs that can be rapidly computed by leveraging the properties of motion primitives; its value can be used to prioritize AND nodes for more efficient search. Search is further accelerated by leveraging shared symmetry in constraints and dynamics to move almost all computation necessary to enforce convex polytope constraints offline. The performance improvements are demonstrated with path planning problems involving a Dubins Car and a nonlinear aircraft model.},
  archive      = {J_RAS},
  author       = {Geordan Gutow and Jonathan D. Rogers},
  doi          = {10.1016/j.robot.2021.103991},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103991},
  shortjournal = {Robot. Auton. Syst.},
  title        = {AND/OR search techniques for chance constrained motion primitive path planning},
  volume       = {149},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bio-inspired origamic pouch motors with a high contraction
ratio and enhanced force output. <em>RAS</em>, <em>149</em>, 103983. (<a
href="https://doi.org/10.1016/j.robot.2021.103983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The range of motion and force output of soft actuators are important characteristics that determine the capacities of soft robots . Pouch motors are a family of soft fluidic actuators featuring a simple mechanical structure and easy fabrication process , but their relatively small contraction ratio constrains their potential applications. Inspired by the origami membrane in the lobster leg joint , we propose two types of origamic pouch motors in which origami structures are integrated into the longitudinal edges of traditional pouches. As a uniform and large degree of transverse expansion can be facilitated by unfolding the origami structures, a significantly larger contraction ratio and enhanced force output can be achieved. The complete workflow of origamic pouch motors is presented including the design principles, fabrication process , theoretical modeling, and experimental characterization, and multiple pouches can be conveniently assembled to realize different motion profiles with a larger range of motion as well. For application demonstrations, we develop different grippers based on origamic pouch motors for safe and forceful grasping. The results of this study can provide guidance for the development of robotic systems featuring easy fabrication, safe actuation , lightweight, a large motion range, and high force output.},
  archive      = {J_RAS},
  author       = {Shanjun Li and Jiahao Lin and Hanwen Kang and Yunjiang Cheng and Yaohui Chen},
  doi          = {10.1016/j.robot.2021.103983},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103983},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Bio-inspired origamic pouch motors with a high contraction ratio and enhanced force output},
  volume       = {149},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-agent navigation in human-shared environments: A safe
and socially-aware approach. <em>RAS</em>, <em>149</em>, 103979. (<a
href="https://doi.org/10.1016/j.robot.2021.103979">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper addresses the problem of multi-robot navigation in human shared spaces. We propose a hierarchical framework that combines global path planning , local path planning and reactive strategies, ensuring a safe and socially-aware navigation. We show through several tests and extensive experiments with a real robotic implementation that our combination of solutions delivers excellent results in terms of robustness and performance even in challenging natural scenarios.},
  archive      = {J_RAS},
  author       = {Manuel Boldrer and Alessandro Antonucci and Paolo Bevilacqua and Luigi Palopoli and Daniele Fontanelli},
  doi          = {10.1016/j.robot.2021.103979},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103979},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Multi-agent navigation in human-shared environments: A safe and socially-aware approach},
  volume       = {149},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Experimental comparison of the effect of the number of
redundant rotors on the fault tolerance performance for the proposed
multilayer UAV. <em>RAS</em>, <em>149</em>, 103977. (<a
href="https://doi.org/10.1016/j.robot.2021.103977">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, experimental investigation of the flight performance of the proposed universal Unmanned Aerial Vehicle (UAV) in case of rotor failures is presented. In the experimental flight tests, proposed universal UAV that can be converted to many different configurations due to its non-standard multi-layer structure was used in two different configurations as a standard octorotor and a multi-layer dodecarotor. Multiple outdoor experiments are conducted to show flight safety and reliability of the proposed UAV in terms of rotor failure tolerance. In order to evaluate flight safety and reliability of the proposed UAV, take-off, hovering and landing flight performance analyzes were performed in cases where one or two motors/propellers were completely lost. As performance criteria, errors in the UAV’s roll, pitch and yaw angles , altitude error and vibration in three axes were determined. The flight test results are presented both numerically and graphically. According to the results, multi-layer dodecarotor type has shown a more stable flight performance in terms of angular position errors. In addition, in both types of UAVs, in the case of failure of two rotors rotating in the opposite direction, it has been observed that the error in yaw angle is less than a rotor failure, as expected. Likewise, in the case of failure of two rotors rotating in the same direction, performance loss was observed in the control of yaw angle.},
  archive      = {J_RAS},
  author       = {Veli Bakırcıoğlu and Nihat Çabuk and Şahin Yıldırım},
  doi          = {10.1016/j.robot.2021.103977},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103977},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Experimental comparison of the effect of the number of redundant rotors on the fault tolerance performance for the proposed multilayer UAV},
  volume       = {149},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A fast robotic arm gravity compensation updating approach
for industrial application using sparse selection and reconstruction.
<em>RAS</em>, <em>149</em>, 103971. (<a
href="https://doi.org/10.1016/j.robot.2021.103971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing complexity of robot tasks in the industrial field, sometimes the manipulator needs to change the payload or replace end-effectors frequently in a period of time, which will cause the change of gravity model. This paper presents a fast gravity compensation updating method based on sparse selection and reconstruction. Instead of using the classic model, feature sets in the formulation of dynamic motion are exploited and the gravity model learning is transformed into a sparse problem. Then, the Alternating Direction Multiplier Method (ADMM) is used to accelerate the process of solving the sparse optimization problem and reconstructing the effective features of the gravity model from the original signal. The merits of our method are that it does not depend on any kinematic and dynamic parameters, and there is no need to redesign the specific excitation trajectory in the gravity model updating. Thus, the updating process avoids heavy work of calibration and simplifies the labor complexity considerably from the conventional analytical methods. The results of various payload experiments on a real 7-DOF manipulator show that the proposed method can update the gravity compensation model efficiently and accurately.},
  archive      = {J_RAS},
  author       = {Chenglong Yu and Zhiqi Li and Dapeng Yang and Hong Liu},
  doi          = {10.1016/j.robot.2021.103971},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103971},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A fast robotic arm gravity compensation updating approach for industrial application using sparse selection and reconstruction},
  volume       = {149},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Autonomous capture of agile flying objects using UAVs: The
MBZIRC 2020 challenge. <em>RAS</em>, <em>149</em>, 103970. (<a
href="https://doi.org/10.1016/j.robot.2021.103970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel approach for autonomously catching fast flying objects is presented, as inspired by the Mohamed Bin Zayed International Robotics Challenge (MBZIRC) 2020. In this competition, an autonomous Unmanned Aerial Vehicle (UAV) was used to intercept a ball carried by a fast flying drone. The presented solution utilizes a 3D LiDAR sensor for quick and robust target detection. The trajectory of the target is estimated and predicted to select a suitable interception position. The interceptor UAV is navigated into the interception position to safely approach the target. The interception position is frequently being adjusted based on the updated estimation and prediction of the target’s motion to ensure that the ball is caught in the dedicated onboard net. After a successful interception is detected, the UAV lands in a designated landing area. The proposed concept was intensively tested and refined in demanding outdoor conditions with strong winds and varying perception conditions to achieve the robustness required by both the demanding application and the competition. In the MBZIRC 2020 competition, our solution scored second place in Challenge 1 and first place in a combined Grand Challenge. This manuscript will provide a detailed description of the applied methods and an evaluation of our approach with data collected from real-world experiments. In addition, we present achievements of our R&amp;D towards the transition from the MBZIRC competition to an autonomous drone interceptor, which was the main motivation of this challenge.},
  archive      = {J_RAS},
  author       = {Matouš Vrba and Yurii Stasinchuk and Tomáš Báča and Vojtěch Spurný and Matěj Petrlík and Daniel Heřt and David Žaitlík and Martin Saska},
  doi          = {10.1016/j.robot.2021.103970},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103970},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Autonomous capture of agile flying objects using UAVs: The MBZIRC 2020 challenge},
  volume       = {149},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A virtual force interaction scheme for multi-robot
environment monitoring. <em>RAS</em>, <em>149</em>, 103967. (<a
href="https://doi.org/10.1016/j.robot.2021.103967">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The autonomous multi-robot system is an emerging technology that has a wide range of potential applications, such as environmental monitoring, exploration of unknown area, battlefield surveillance , and search and rescue. One major challenge in such applications is how to deploy each robotic agent autonomously in a distributed manner. In this paper, we proposed a distributed coverage control strategy named multi-stage virtual force interaction scheme (VFIS), where the agents’ deployment process is split into stages and each agent iteratively seeks its next position according to the interaction among agents and the interaction between agents and the perceived environment. The interactions are realized via virtual repulsive forces and virtual vortex forces, where the latter are newly proposed to enhance the exploration capability of agents. We also designed a group of benchmark testing problems for the mission of monitoring coverage of complex environments with unknown obstacles. Extensive simulation experiments were conducted based on the defined benchmark configurations and the results showed a favorable performance of the invented strategy. In addition, practical experiments were carried out using a group of mobile robots, which validated the effectiveness of the proposed method.},
  archive      = {J_RAS},
  author       = {Kang Ji and Qian Zhang and Zhi Yuan and Hui Cheng and Dingli Yu},
  doi          = {10.1016/j.robot.2021.103967},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103967},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A virtual force interaction scheme for multi-robot environment monitoring},
  volume       = {149},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Nonlinear ESO-based tracking control for warehouse mobile
robots with detachable loads. <em>RAS</em>, <em>149</em>, 103965. (<a
href="https://doi.org/10.1016/j.robot.2021.103965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is an essential task to guarantee satisfactory tracking performance for a warehouse mobile robot with a detachable load. To this end, a nonlinear extended state observer (ESO)-based tracking control is investigated via a double closed-loop framework in this paper. A kinematics controller is designed in an outer loop to generate desired velocities for the warehouse mobile robot. A nonlinear ESO with an improved error function is proposed in an inner loop to estimate load variations and internal unmodeled dynamics. Then a nonlinear error feedback controller based on estimation values is given to track the desired velocities from the outer loop. Simulation and experiment results illustrate the effectiveness and superiority of the proposed control strategy.},
  archive      = {J_RAS},
  author       = {Peng Li and Hongjiu Yang and Hongbo Li and Shiqing Liang},
  doi          = {10.1016/j.robot.2021.103965},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103965},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Nonlinear ESO-based tracking control for warehouse mobile robots with detachable loads},
  volume       = {149},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-maneuver vertical parking path planning and control in
a narrow space. <em>RAS</em>, <em>149</em>, 103964. (<a
href="https://doi.org/10.1016/j.robot.2021.103964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automatic parking system can replace people to complete the parking task and reduce the burden of driving. The size of the parking space affects the number of parking operations and the time for parking planning to be completed. Parking planning in narrow space is a challenging problem, especially in crowded urban environments. This paper presents a parking path planning method in a narrow vertical parking space. First, the parking path planning method can be used in narrow corridor spaces and narrow spots. According to the size of the corridor space and the parking space obtained by the environment perception, this method can determine the number of parking maneuvers and the start parking position. Second, to allow the vehicle to generate a parking path at any position to reach the parking starting point, the system generates a target line set that considers control error factors. It will also select the optimal target line based on the current position. Third, the vehicle cannot complete the parking while traveling along the original parking path when the factual error is greater than the reserved error. Therefore, a re-planning method based on geometric planning is proposed to improve the robustness of the system. Finally, through the establishment of longitudinal and lateral driver models, the effectiveness of the path planning method is verified, and compared with other path planning methods, it proves that the method proposed in this paper performs well in the number of maneuvers and planning time in a small space.},
  archive      = {J_RAS},
  author       = {Lei Cai and Hsin Guan and Hao Lun Zhang and Xin Jia and Jun Zhan},
  doi          = {10.1016/j.robot.2021.103964},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103964},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Multi-maneuver vertical parking path planning and control in a narrow space},
  volume       = {149},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Correspondenceless scan-to-map-scan matching of homoriented
2D scans for mobile robot localisation. <em>RAS</em>, <em>149</em>,
103957. (<a href="https://doi.org/10.1016/j.robot.2021.103957">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of this study is improving the location estimate of a mobile robot capable of motion on a plane and mounted with a conventional 2D LIDAR sensor, given an initial guess for its location on a 2D map of its surroundings. Documented herein is the theoretical reasoning behind solving a matching problem between two homoriented 2D scans, one derived from the robot’s physical sensor and one derived by simulating its operation within the map, in a manner that does not require the establishing of correspondences between their constituting rays. Two results are proved and subsequently shown through experiments. The first is that the true position of the sensor can be recovered with arbitrary precision when the physical sensor reports faultless measurements and there is no discrepancy between the environment the robot operates in and its perception of it by the robot. The second is that when either is affected by disturbance, the location estimate is bound in a neighbourhood of the true location whose radius is proportional to the affecting disturbance.},
  archive      = {J_RAS},
  author       = {Alexandros Filotheou},
  doi          = {10.1016/j.robot.2021.103957},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103957},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Correspondenceless scan-to-map-scan matching of homoriented 2D scans for mobile robot localisation},
  volume       = {149},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The semantic PHD filter for multi-class target tracking:
From theory to practice. <em>RAS</em>, <em>149</em>, 103947. (<a
href="https://doi.org/10.1016/j.robot.2021.103947">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order for a mobile robot to be able to effectively operate in complex, dynamic environments it must be capable of understanding both where and what the objects around them are. In this paper we introduce the semantic probability hypothesis density (SPHD) filter, which allows robots to simultaneously track multiple classes of targets despite measurement uncertainty, including false positive detections, false negative detections, measurement noise, and target misclassification . The SPHD filter is capable of incorporating a different motion model for each type of target and of functioning in situations where the number of targets is unknown and time-varying. To demonstrate the efficacy of the SPHD filter, we conduct both simulated and hardware tests with multiple target types containing both static and dynamic targets. We show that the SPHD filter allows effective tracking of multiple classes of targets even with detection error to some level, and performs better than a collection of PHD filters running in parallel, one for each target class. We also provide a detailed methodology that practitioners can use to fit the probabilistic sensor models necessary to run the SPHD filter.},
  archive      = {J_RAS},
  author       = {Jun Chen and Zhanteng Xie and Philip Dames},
  doi          = {10.1016/j.robot.2021.103947},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103947},
  shortjournal = {Robot. Auton. Syst.},
  title        = {The semantic PHD filter for multi-class target tracking: From theory to practice},
  volume       = {149},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Visual detection and tracking algorithms for minimally
invasive surgical instruments: A comprehensive review of the
state-of-the-art. <em>RAS</em>, <em>149</em>, 103945. (<a
href="https://doi.org/10.1016/j.robot.2021.103945">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minimally invasive surgical instrument visual detection and tracking is one of the core algorithms of minimally invasive surgical robots . With the development of machine vision and robotics, related technologies such as virtual reality, three-dimensional reconstruction, path planning , and human–machine collaboration can be applied to surgical operations to assist clinicians or use surgical robots to complete clinical operations. The minimally invasive surgical instrument vision detection and tracking algorithm analyzes the image transmitted by the surgical robot endoscope, extracting the position of the surgical instrument tip in the image, so as to provide the surgical navigation. This technology can greatly improve the accuracy and success rate of surgical operations. The purpose of this paper is to further study the visual detection and tracking technology of minimally invasive surgical instruments, summarize the existing research results, and apply it to the surgical robot project. By reading the literature, the author summarized the theoretical basis and related algorithms of this technology in recent years. Finally, the author compares the accuracy, speed and application scenario of each algorithm, and analyzes the advantages and disadvantages of each algorithm. The papers included in the review were selected through Web of Science, Google Scholar, PubMed and CNKI searches using the keywords: “object detection”, “object tracking”, “surgical tool detection”, “surgical tool tracking”, “surgical instrument detection” and “surgical instrument tracking” limiting results to the year range 1985–2021. Our study shows that this technology will have a great development prospect in the aspects of accuracy and real-time improvement in the future.},
  archive      = {J_RAS},
  author       = {Yan Wang and Qiyuan Sun and Zhenzhong Liu and Lin Gu},
  doi          = {10.1016/j.robot.2021.103945},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103945},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Visual detection and tracking algorithms for minimally invasive surgical instruments: A comprehensive review of the state-of-the-art},
  volume       = {149},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhanced ant colony algorithm with communication mechanism
for mobile robot path planning. <em>RAS</em>, <em>148</em>, 103949. (<a
href="https://doi.org/10.1016/j.robot.2021.103949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In mobile robot path planning , the ant colony algorithm has the problem that the historical paths explored by ants cannot be fully utilized. With this in mind, in this paper an enhanced ant colony algorithm with a communication mechanism is proposed. The communication mechanism is inspired by the contact of ant tentacles in nature, which can integrate historical paths to obtain a better composite path. To further improve the algorithm, an enlarged roulette method is presented to accelerate the convergence. Subsequently, an adaptive sigmoid attenuation function is designed to optimize the heuristic information at different stages. The various forms of the deadlock problem are analyzed and specific strategies formulated. Finally, parameter determination and comparison experiments are carried out. The experimental results demonstrate the efficiency of the proposed method and its considerable advantages in enhancing the performance of the ant colony algorithm.},
  archive      = {J_RAS},
  author       = {Wenbin Hou and Zhihua Xiong and Changsheng Wang and Howard Chen},
  doi          = {10.1016/j.robot.2021.103949},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103949},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Enhanced ant colony algorithm with communication mechanism for mobile robot path planning},
  volume       = {148},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards robot modularity — a review of international
modularity standardization for service robots. <em>RAS</em>,
<em>148</em>, 103943. (<a
href="https://doi.org/10.1016/j.robot.2021.103943">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper presents ISO standardization work carried out to formulate guidelines for service robot modularity for assisting the development of open plug-n-play modules that can be easily assembled to create application specific robots and robot systems. Although robot modularity has been an active research field for many years, the developments have had little impact on advancing robot markets due to their individualist nature and the results not having sufficiently wide relevance or appeal. The paper initially provides an overview of the new ISO 22166-1 service robot modularity standard and aims to illustrate how to implement it with several use cases. Specific innovations produced in realizing robot modules under the guidance of ISO are introduced and two simple approaches based on block diagram approaches (the line and circle diagrams) are proposed for implementing and designing modular robots. Finally, the paper presents several use cases as examples where the new ISO robot modular approach can be used to good effect.},
  archive      = {J_RAS},
  author       = {Yibo Zou and Donghan Kim and Philip Norman and Jose Espinosa and Jen-Chieh Wang and Gurvinder S. Virk},
  doi          = {10.1016/j.robot.2021.103943},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103943},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Towards robot modularity — a review of international modularity standardization for service robots},
  volume       = {148},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A feedback-based manoeuvre planner for nonprehensile
magnetic micromanipulation of large microscopic biological objects.
<em>RAS</em>, <em>148</em>, 103941. (<a
href="https://doi.org/10.1016/j.robot.2021.103941">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper reports a feedback-based manoeuvre planning approach for automated nonprehensile selective micromanipulation of large, microscopic biological objects ( ∼ 100 μ m ∼100μm ). We employ ferromagnetic micro-particles as microrobots actuated via a global magnetic field produced by electromagnetic coils placed in quadrupole configuration. The microrobot motion is programmed to push the target object to the goal location. We employ a three-step approach comprising: (a) generate a collision-free optimal path between the initial and the commanded goal location, (b) generate a manoeuvre planning algorithm that invokes one of the three motion manoeuvres, namely, ‘approach’, ‘push’, and ‘align’ depending upon the instantaneous locations of the microrobot, target object, and the desired waypoint, and (c) deploy a simple proportional controller that determines the currents required in the electromagnetic coils that can produce a suitable magnetic field for executing the manoeuvre invoked by the manoeuvre planner. This paper reports a number of validation experiments conducted on both zebrafish, i.e., Danio rerio embryos and silica beads as target objects. We envisage that the developed inexpensive approach can be useful in robotic manipulation of biological objects with sizes in hundreds of microns including large biological cells, polyploid giant cancer cells (PGCC), multicellular spheroids, Dictyostelium slug, human oocytes, and autophagy candidates. We also believe that functionalizing the microrobots with living cells or suitable chemicals will make it possible to perform on-chip biological experiments in future.},
  archive      = {J_RAS},
  author       = {Dharmveer Agarwal and Ajay D. Thakur and Atul Thakur},
  doi          = {10.1016/j.robot.2021.103941},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103941},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A feedback-based manoeuvre planner for nonprehensile magnetic micromanipulation of large microscopic biological objects},
  volume       = {148},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Introducing shell formation and a thermodynamics-inspired
concept for swarm robotic systems. <em>RAS</em>, <em>148</em>, 103939.
(<a href="https://doi.org/10.1016/j.robot.2021.103939">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a new formation for swarm robotic systems is introduced. This formation, which is made up of a portion of swarm members and encircles the whole swarm, is called the shell formation. In this regard, an effective algorithm for developing the shell formation in swarm robotic systems is established. The interaction mechanism among swarm agents is based on the method of artificial potential fields and the local rule of the nearest neighbor. Subsequently, inspired by the thermodynamic science and based on the introduced shell formation, the thermodynamic concept of pressure is generalized to swarm robotic systems. Finally, the efficacy of the introduced shell formation in solving the problem of passing through a narrow passage is studied via numerical simulations.},
  archive      = {J_RAS},
  author       = {Ahmad Mahdian Parrany and Aria Alasty},
  doi          = {10.1016/j.robot.2021.103939},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103939},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Introducing shell formation and a thermodynamics-inspired concept for swarm robotic systems},
  volume       = {148},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Knowledge triggering, extraction and storage via human–robot
verbal interaction. <em>RAS</em>, <em>148</em>, 103938. (<a
href="https://doi.org/10.1016/j.robot.2021.103938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article describes a novel approach to expand in run-time the knowledge base of an Artificial Conversational Agent . A technique for automatic knowledge extraction from the user’s sentence and four methods to insert the new acquired concepts in the knowledge base have been developed and integrated into a system that has already been tested for knowledge-based conversation between a social humanoid robot and residents of care homes. The run-time addition of new knowledge allows overcoming some limitations that affect most robots and chatbots : the incapability of engaging the user for a long time due to the restricted number of conversation topics. The insertion in the knowledge base of new concepts recognized in the user’s sentence is expected to result in a wider range of topics that can be covered during an interaction, making the conversation less repetitive. Two experiments are presented to assess the performance of the knowledge extraction technique, and the efficiency of the developed insertion methods when adding several concepts in the Ontology.},
  archive      = {J_RAS},
  author       = {Lucrezia Grassi and Carmine Tommaso Recchiuto and Antonio Sgorbissa},
  doi          = {10.1016/j.robot.2021.103938},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103938},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Knowledge triggering, extraction and storage via human–robot verbal interaction},
  volume       = {148},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An adaptive learning and control framework based on dynamic
movement primitives with application to human–robot handovers.
<em>RAS</em>, <em>148</em>, 103935. (<a
href="https://doi.org/10.1016/j.robot.2021.103935">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object handover is a fundamental skill needed in many human–robot collaboration tasks ranging from industrial manipulation to daily service. It remains challenging for robots to perform a handover as flexibly and fluently as a human. This article proposes a framework based on Dynamic Movement Primitives (DMP) that enables robot to learn from human demonstrations and transfer the skill into human–robot handovers. In particular, we focus on the problem of dealing with time varying handover locations. Compared to the conventional DMP formalism, the proposed method contains the following extensions: (1) uncertainty-aware learning with Gaussian Process , (2) a weighting function to control the transition of the shape and goal attraction terms, (3) an orientation-based spatial scaling, (4) online parameter adaption with human feedback. Moreover, inspired by the principle of cooperative DMPs, we present an equivalent model to study the interactive dynamics in human–robot handovers. The proposed framework has been validated in experiments and evaluated by both subjective and objective metrics. Results show an enhancement of success rate, fluency and human comfort.},
  archive      = {J_RAS},
  author       = {Min Wu and Bertram Taetz and Yanhao He and Gabriele Bleser and Steven Liu},
  doi          = {10.1016/j.robot.2021.103935},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103935},
  shortjournal = {Robot. Auton. Syst.},
  title        = {An adaptive learning and control framework based on dynamic movement primitives with application to human–robot handovers},
  volume       = {148},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sharing visual-inertial data for collaborative decentralized
simultaneous localization and mapping. <em>RAS</em>, <em>148</em>,
103933. (<a href="https://doi.org/10.1016/j.robot.2021.103933">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building on the maturity of single-robot SLAM algorithms, collaborative SLAM has brought significant gains in terms of efficiency and robustness, but has also raised new challenges to cope with like informational, network and resource constraints. Several multi-robot frameworks have been coined for visual SLAM, ranging from highly-integrated and fully-centralized architectures to fully distributed and decentralized methods. However, many proposed architectures compromise the autonomy of the robots in fusing the data processed by the other agents to enhance their own estimation accuracy. In this paper, we propose three methods to share visual-inertial information, based on rigid, condensed and pruned visual-inertial packets. We also propose a common collaborative SLAM architecture to organize the computation, exchange and integration of such packets. We evaluated those methods on the EuRoC (Burri et al. 2016) dataset and on our custom dataset AirMuseum (Dubois et al. 2020). Experiments showed that the proposed methods allow the agents to build, exchange and integrate consistent visual-inertial packets, and improve their trajectory estimation accuracy up to several centimeters.},
  archive      = {J_RAS},
  author       = {Rodolphe Dubois and Alexandre Eudes and Vincent Frémont},
  doi          = {10.1016/j.robot.2021.103933},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103933},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Sharing visual-inertial data for collaborative decentralized simultaneous localization and mapping},
  volume       = {148},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PTPGC: Pedestrian trajectory prediction by graph attention
network with ConvLSTM. <em>RAS</em>, <em>148</em>, 103931. (<a
href="https://doi.org/10.1016/j.robot.2021.103931">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of intelligent systems, such as self-driving vehicles, service robots and surveillance systems, pedestrian trajectory prediction has become a very challenging problem. How to perceive, understand and predict the motion patterns of pedestrians in a highly crowded and chaotic environment in order to prevent future collisions becomes a top priority. The motion of pedestrians is not only affected by their own factors, but also by surrounding neighbors. To solve the above problems, we propose a model named PTPGC based on graph attention and convolutional long short-term memory (ConvLSTM) network to predict multiple reasonable pedestrian trajectories. Firstly, the pedestrians are represented in a dynamic graph by setting a Euclidean distance threshold. Then, a graph attention network is used to learn the spatial interaction relationship of all pedestrians in each time step, and a temporal convolutional network (TCN) is used to encode the pedestrians’ own factors. Finally, we use the ConvLSTM to iteratively predict the multiple reasonable and feasible future trajectories of pedestrians. Experiments show that our model has a higher prediction accuracy on two public pedestrian data sets (ETH and UCY) compared with the existing baselines for pedestrian trajectory prediction, and the generated trajectories are more in line with social rationality and physical constraints.},
  archive      = {J_RAS},
  author       = {Juan Yang and Xu Sun and Rong Gui Wang and Li Xia Xue},
  doi          = {10.1016/j.robot.2021.103931},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103931},
  shortjournal = {Robot. Auton. Syst.},
  title        = {PTPGC: Pedestrian trajectory prediction by graph attention network with ConvLSTM},
  volume       = {148},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An analysis of international use of robots for COVID-19.
<em>RAS</em>, <em>148</em>, 103922. (<a
href="https://doi.org/10.1016/j.robot.2021.103922">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article analyses data collected from press reports, social media, and the scientific literature on 338 instances of robots used explicitly in response to COVID-19 from 24 Jan, 2020, to 23 Jan, 2021, in 48 countries. The analysis was guided by four overarching questions: (1) What were robots used for in the COVID-19 response? (2) When were they used? (3) How did different countries innovate? and 4) Did having a national policy on robotics influence a country’s innovation and insertion of robotics for COVID-19? The findings indicate that robots were used for six different sociotechnical work domains and 29 discrete use cases. When robots were used varied greatly on the country; although many countries did report an increase at the beginning of their first surge. To understand the findings of how innovation occurred, the data was examined through the lens of the technology’s maturity according to NASA’s Technical Readiness Assessment metrics. Through this lens, findings note that existing robots were used for more than 78\% of the instances; slightly modified robots made up 10\%; and truly novel robots or novel use cases constituted 12\% of the instances. The findings clearly indicate that countries with a national robotics initiative were more likely to use robotics more often and for broader purposes. Finally, the dataset and analysis produces a broad set of implications that warrant further study and investigation. The results from this analysis are expected to be of value to the robotics and robotics policy community in preparing robots for rapid insertion into future disasters.},
  archive      = {J_RAS},
  author       = {Robin R. Murphy and Vignesh B.M. Gandudi and Trisha Amin and Angela Clendenin and Jason Moats},
  doi          = {10.1016/j.robot.2021.103922},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103922},
  shortjournal = {Robot. Auton. Syst.},
  title        = {An analysis of international use of robots for COVID-19},
  volume       = {148},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A collaborative robot for COVID-19 oropharyngeal swabbing.
<em>RAS</em>, <em>148</em>, 103917. (<a
href="https://doi.org/10.1016/j.robot.2021.103917">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The coronavirus disease 2019 (COVID-19) outbreak has increased mortality and morbidity world-wide. Oropharyngeal swabbing is a well-known and commonly used sampling technique for COVID-19 diagnose around the world. We developed a robot to assist with COVID-19 oropharyngeal swabbing to prevent frontline clinical staff from being infected. The robot integrates a UR5 manipulator, rigid–flexible coupling (RFC) manipulator, force-sensing and control subsystem, visual subsystem and haptic device. The robot has strength in intrinsically safe and high repeat positioning accuracy. In addition, we also achieve one-dimensional constant force control in the automatic scheme (AS). Compared with the rigid sampling robot, the developed robot can perform the oropharyngeal swabbing procedure more safely and gently, reducing risk. Alternatively, a novel robot control schemes called collaborative manipulation scheme (CMS) which combines a automatic phase and teleoperation phase is proposed. At last, comparative experiments of three schemes were conducted, including CMS, AS, and teleoperation scheme (TS). The experimental results shows that CMS obtained the highest score according to the evaluation equation. CMS has the excellent performance in quality, experience and adaption. Therefore, the proposal of CMS is meaningful which is more suitable for robot-sampling.},
  archive      = {J_RAS},
  author       = {Yongquan Chen and Qiwen Wang and Chuliang Chi and Chengjiang Wang and Qing Gao and Heng Zhang and Zheng Li and Zonggao Mu and Ruihuan Xu and Zhenglong Sun and Huihuan Qian},
  doi          = {10.1016/j.robot.2021.103917},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103917},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A collaborative robot for COVID-19 oropharyngeal swabbing},
  volume       = {148},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast robotic pencil drawing based on image evolution by
means of genetic algorithm. <em>RAS</em>, <em>148</em>, 103912. (<a
href="https://doi.org/10.1016/j.robot.2021.103912">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Even if pencil drawing is the basic method of human artistic expression, it remains at the forefront of scientific attention in the field of robotics, which focuses mainly on painting. Although various methods of artistic robotic drawing have been developed in the past, the results are not always satisfactory. The vast majority of existing systems focus only on sketches, and detailed pencil drawings are time-consuming. In this article, we present a novel general robotic system for creating realistic pencil drawings based on image evolution. We show that by procedural image generation approach using genetic algorithms , we can create realistic drawings with an element of machine creativity. Furthermore, we show that the image approximation using even simple line segments leads to aesthetic and fast drawings. Finally, we describe a hardware solution using an industrial robot, a software implementation, and preliminary experimental results.},
  archive      = {J_RAS},
  author       = {Michal Adamik and Jozef Goga and Jarmila Pavlovicova and Andrej Babinec and Ivan Sekaj},
  doi          = {10.1016/j.robot.2021.103912},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103912},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Fast robotic pencil drawing based on image evolution by means of genetic algorithm},
  volume       = {148},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A magnetic crawler wall-climbing robot with capacity of high
payload on the convex surface. <em>RAS</em>, <em>148</em>, 103907. (<a
href="https://doi.org/10.1016/j.robot.2021.103907">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are two challenges for wall-climbing robots in the maintenance and inspection of large vertical ferromagnetic structures: the requirement of high load capacity and the curved appearance of the wall. An improved magnetic crawler wall-climbing robot is presented in this paper. Without increasing the adhesion force , a load dispersion mechanism (LDM) is proposed to enhance the payload capacity of the crawler wall-climbing robot, through making full use of the magnetic adhesion force for resisting the overturning moment. Based on the passive independent suspension, a flexible connection scheme of the robot skeleton is proposed, that renders the wall-climbing robot move on the convex surface . Experiment results show that the magnetic crawler wall-climbing robot can move on the cylindrical wall whose curvature radius is 3000 mm. In motion, the robot can carry 75 kg payload. In the static state, the robot can afford 150 kg payload.},
  archive      = {J_RAS},
  author       = {Junyu Hu and Xu Han and Yourui Tao and Shizhe Feng},
  doi          = {10.1016/j.robot.2021.103907},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103907},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A magnetic crawler wall-climbing robot with capacity of high payload on the convex surface},
  volume       = {148},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-reconfiguration of shape-shifting modular robots with
triangular structure. <em>RAS</em>, <em>147</em>, 103930. (<a
href="https://doi.org/10.1016/j.robot.2021.103930">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a reconfiguration algorithm for shape-shifting modular robots with a triangular structure. The algorithm is derived from a novel description of the configuration space based on extended binary trees. Extended binary trees representing the same configuration are grouped into equivalence classes, which allows for a one-to-one correspondence between a configuration and its mathematical representation. Reconfiguration is then accomplished by a successive construction of the goal configuration , realized by moving individual modules along the surface of the robot and building up the binary tree of the goal configuration by populating unoccupied binary tree indices in ascending order with new modules. The algorithm is capable of solving the self-reconfiguration problem for modular robots with a triangular structure in O ( n 2 ) O(n2) reconfiguration steps and is demonstrated on two reconfiguration examples. We then discuss the limits of the proposed methods, regarding constraints on the implementation and the lack of efficient collision avoidance , and outline possible resolutions.},
  archive      = {J_RAS},
  author       = {Michael Gerbl and Johannes Gerstmayr},
  doi          = {10.1016/j.robot.2021.103930},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103930},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Self-reconfiguration of shape-shifting modular robots with triangular structure},
  volume       = {147},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Formation control of distance and orientation based-model of
an omnidirectional robot and a quadrotor UAV. <em>RAS</em>,
<em>147</em>, 103921. (<a
href="https://doi.org/10.1016/j.robot.2021.103921">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a dynamic model based on distance and orientation between an omnidirectional mobile robot and a quadrotor Unmanned Aerial Vehicle (UAV), both under the leader–follower scheme. It is assumed that the omnidirectional robot is already controlled in order to follow a desired trajectory . On the other hand, a backstepping with a Continuous Sliding-Mode Control (C-SMC) are designed for the quadrotor with the objective of keeping a distance and formation angle with respect to the omnidirectional robot . Numerical simulations and real-time experiments show the performance of the proposed control strategy.},
  archive      = {J_RAS},
  author       = {Jaime González-Sierra and Alejandro Dzul and Edgar Martínez},
  doi          = {10.1016/j.robot.2021.103921},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103921},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Formation control of distance and orientation based-model of an omnidirectional robot and a quadrotor UAV},
  volume       = {147},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Area-coverage planning for spray-based surface disinfection
with a mobile manipulator. <em>RAS</em>, <em>147</em>, 103920. (<a
href="https://doi.org/10.1016/j.robot.2021.103920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of robots has significantly increased to fight highly contagious diseases like SARS-COV-2, Ebola, MERS, and others. One of the important applications of robots to fight such infectious diseases is disinfection . Manual disinfection can be a time-consuming, risky, labor-intensive, and mundane, and humans may fail to disinfect critical areas due to the resulting fatigue. Autonomous or semi-autonomous mobile manipulators mounted with a spray nozzle at the end-effector can be very effective in spraying disinfectant liquid for deep disinfection of objects and surfaces. In this paper, we present an area-coverage planning algorithm to compute a path that the nozzle follows to disinfect surfaces represented by their point clouds. We project the point cloud on a plane and produce a polygon on which we generate multiple spray paths using our branch and bound-based tree search area-coverage algorithm such that the spray paths cover the entire area of the polygon. An appropriate spray path is chosen using a robot capability map-based selection criterion. We generate mobile manipulator trajectories using successive refinement-based parametric optimization so that the paths for the nozzle are followed accurately. Thereafter, we need to make sure that the joint velocities of the mobile manipulator are regulated appropriately such that each point on the surface receives enough disinfectant spray. To this end, we compute the time intervals between the robot path waypoints such that enough disinfectant liquid is sprayed on all points of the point cloud that results in thorough disinfection of the surface, and the particular robot path is executed in the minimum possible time. We have implemented the area-coverage planning and mobile manipulator motion planning on five test scenarios in simulation using our ADAMMS-SD (Agile Dexterous Autonomous Mobile Manipulation System for Surface Disinfection) robot. We benchmark our spray path generation algorithm with three competing methods by showing that the generated paths are significantly more efficient in terms of area coverage and reducing disinfectant wastage. We also show the time interval computation between successive waypoints results in thorough disinfection of surfaces.},
  archive      = {J_RAS},
  author       = {Shantanu Thakar and Rishi K. Malhan and Prahar M. Bhatt and Satyandra K. Gupta},
  doi          = {10.1016/j.robot.2021.103920},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103920},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Area-coverage planning for spray-based surface disinfection with a mobile manipulator},
  volume       = {147},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Occupant-centric robotic air filtration and planning for
classrooms for safer school reopening amid respiratory pandemics.
<em>RAS</em>, <em>147</em>, 103919. (<a
href="https://doi.org/10.1016/j.robot.2021.103919">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coexisting with the current COVID-19 pandemic is a global reality that comes with unique challenges impacting daily interactions, business, and facility maintenance. A monumental challenge accompanied is continuous and effective disinfection of shared spaces, such as office/school buildings, elevators, classrooms, and cafeterias. Although ultraviolet light and chemical sprays are routines for indoor disinfection, they irritate humans, hence can only be used when the facility is unoccupied. Stationary air filtration systems, while being irritation-free and commonly available, fail to protect all occupants due to limitations in air circulation and diffusion. Hence, we present a novel collaborative robot (cobot) disinfection system equipped with a Bernoulli Air Filtration Module, with a design that minimizes disturbance to the surrounding airflow and maneuverability among occupants for maximum coverage. The influence of robotic air filtration on dosage at neighbors of a coughing source is analyzed with derivations from a Computational Fluid Dynamics (CFD) simulation. Based on the analysis, the novel occupant-centric online rerouting algorithm decides the path of the robot. The rerouting ensures effective air filtration that minimizes the risk of occupants under their detected layout. The proposed system was tested on a 2 × 3 seating grid (empty seats allowed) in a classroom, and the worst-case dosage for all occupants was chosen as the metric. The system reduced the worst-case dosage among all occupants by 26\% and 19\% compared to a stationary air filtration system with the same flow rate, and a robotic air filtration system that traverses all the seats but without occupant-centric planning of its path, respectively. Hence, we validated the effectiveness of the proposed robotic air filtration system.},
  archive      = {J_RAS},
  author       = {Haoguang Yang and Mythra V. Balakuntala and Jhon J. Quiñones and Upinder Kaur and Abigayle E. Moser and Ali Doosttalab and Antonio Esquivel-Puentes and Tanya Purwar and Luciano Castillo and Xin Ma and Lucy T. Zhang and Richard M. Voyles},
  doi          = {10.1016/j.robot.2021.103919},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103919},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Occupant-centric robotic air filtration and planning for classrooms for safer school reopening amid respiratory pandemics},
  volume       = {147},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Arranging test tubes in racks using combined task and motion
planning. <em>RAS</em>, <em>147</em>, 103918. (<a
href="https://doi.org/10.1016/j.robot.2021.103918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper develops a robotic manipulation system to meet the pressing needs for handling a large number of test tubes in clinical examination and replace or reduce human labor. It presents the technical details of the system, which separates and arranges test tubes in racks with the help of 3D vision and artificial intelligence (AI) planning. The developed system only requires a person to put a rack with mixed and non-arranged tubes in front of a robot. The robot autonomously performs recognition, reasoning, planning, manipulation, etc., and returns a rack with separated and arranged tubes. The system is simple-to-use, and there are no requests for expert knowledge in robotics. We expect such a system to play an important role in helping managing bulky examination samples. We also hope similar systems could be extended to other clinical manipulation like handling mixers and pipettes in the future.},
  archive      = {J_RAS},
  author       = {Weiwei Wan and Takeyuki Kotaka and Kensuke Harada},
  doi          = {10.1016/j.robot.2021.103918},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103918},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Arranging test tubes in racks using combined task and motion planning},
  volume       = {147},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Real-time adaptive impedance compensator using simultaneous
perturbation stochastic approximation for enhanced physical human–robot
interaction transparency. <em>RAS</em>, <em>147</em>, 103916. (<a
href="https://doi.org/10.1016/j.robot.2021.103916">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the physical human–robot interaction (pHRi) system, the human and the robot are physically coupled, and it makes the human and the robot always influence each other. In engineering tasks, using a force sensor is the norm for control the robot through the interaction force between the human and the robot. However, the force measured from the force sensor contains the force intended by human motion and the natural force feedback generated by the robot movement and the human hand impedance due to the coupled dynamics. Therefore, it is necessary to characterize the human hand dynamics to improve transparency. However, it is difficult to estimate the human hand impedance, which is the primary source of natural force feedback in real-time. This paper proposes a real-time adaptive hand impedance compensator to enhance transparency in various pHRi conditions with human hand dynamics. The proposed algorithm regulates the impedance compensator’s parameters to find optimal values that minimize the energy-based cost function using Simultaneous Perturbation Stochastic Approximation (SPSA) and AMSGrad. SPSA is a useful method when the exact relationship between the parameters and the cost function is unknown. AMSGrad is a state-of-the-art technique widely used as an adaptive learning rate method in deep learning fields. The proposed real-time adaptive impedance compensator decreases the influence of natural force feedback by updating the parameter appropriately depending on the pHRi conditions, thus improving the transparency.},
  archive      = {J_RAS},
  author       = {Kyeong Ha Lee and Seung Guk Baek and Hyuk Jin Lee and Seung Ho Lee and Ja Choon Koo},
  doi          = {10.1016/j.robot.2021.103916},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103916},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Real-time adaptive impedance compensator using simultaneous perturbation stochastic approximation for enhanced physical human–robot interaction transparency},
  volume       = {147},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The performance and cognitive workload analysis of a
multimodal speech and visual gesture (mSVG) UAV control interface.
<em>RAS</em>, <em>147</em>, 103915. (<a
href="https://doi.org/10.1016/j.robot.2021.103915">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper conducts a comparison of the performance and cognitive workload between three UAV control interfaces on an nCA (navigation control autonomy) Tier 1-III flight navigation task . The first interface is the standard RC Joystick (RCJ) controller, the second interface is the multimodal speech and visual gesture (mSVG) interface, and the third interface is the modified version of the RCJ interface with altitude, attitude, and position (AAP) assist. The modified RCJ interface was achieved with the aid of the Keyboard (KBD). A model of the mSVG interface previously designed and tested was used in this comparison. An experiment study was designed to measure the completion time and navigation accuracy of participants using each of the three interfaces, on a developed path_v02 test flight path. Thirty-seven (37) participants volunteered. The NASA task load index (TLX) survey questionnaire was administered at the end of each interface experiment to access the participants experience and to estimate the interface cognitive workload. A commercial software, the RealFlight Drone Simulator (RFDS) was used to estimate the RCJ skill level of the participants. From the results of the experiment, it was shown that the flying hours, the number of months flying, and the RFDS Level 4 challenge performance was a good estimator for participants RCJ flying skill level. A two-way result was obtained in the comparison of the RCJ and mSVG interfaces. It was concluded that, although the mSVG was better than the standard RCJ interface, the AAP-assisted RCJ was found to be as effective as (in some cases better than) the mSVG interface. It was also shown, from the speech gesture ratio result, that the participants had a preference for gesture over speech when using the mSVG interface. Some further works such as an outdoor field test and a performance comparison at higher nCA levels were suggested.},
  archive      = {J_RAS},
  author       = {Ayodeji Opeyemi Abioye and Stephen D. Prior and Peter Saddington and Sarvapali D. Ramchurn},
  doi          = {10.1016/j.robot.2021.103915},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103915},
  shortjournal = {Robot. Auton. Syst.},
  title        = {The performance and cognitive workload analysis of a multimodal speech and visual gesture (mSVG) UAV control interface},
  volume       = {147},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robotic odor source localization via adaptive bio-inspired
navigation using fuzzy inference methods. <em>RAS</em>, <em>147</em>,
103914. (<a href="https://doi.org/10.1016/j.robot.2021.103914">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic odor source localization (OSL) has been viewed as a challenging task due to the turbulent nature of airflows and the resulting odor plume characteristics. The key to solving an OSL problem is designing an effective olfactory-based navigation algorithm, which guides a plume-tracing robot to find the odor source via tracing emitted plumes. Inspired by the mate-seeking behaviors of male moths, this article presents a behavior-based navigation algorithm for using on a mobile robot to locate an odor source in an unknown environment. Unlike traditional bio-inspired algorithms, which use fixed parameters to formulate robot search trajectories, we design a fuzzy controller to perceive the environment and adjust trajectory parameters based on the current search situation. Therefore, the robot can automatically adapt the scale of search trajectories to fit environmental changes and balance the exploration and exploitation of the search. Simulation and on-vehicle results show that compared to two classical olfactory-based navigation algorithms, the proposed algorithm is more efficient and outperforms them in terms of the averaged search time and success rate.},
  archive      = {J_RAS},
  author       = {Lingxiao Wang and Shuo Pang},
  doi          = {10.1016/j.robot.2021.103914},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103914},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Robotic odor source localization via adaptive bio-inspired navigation using fuzzy inference methods},
  volume       = {147},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). VisibleSim: A behavioral simulation framework for lattice
modular robots. <em>RAS</em>, <em>147</em>, 103913. (<a
href="https://doi.org/10.1016/j.robot.2021.103913">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simulation is one of the most important tools for robotics research, as it serves several crucial purposes such as prototyping, learning, avoiding dispensable hardware costs, or studying future systems that cannot be fabricated yet. Large scale self-reconfiguring modular robotic systems are an instance of such systems. Yet, current modular robotic simulators are overwhelmingly physics-based, which are good for real-world simulation but can be superfluous and sacrifice scalability when studying such systems through a behavioral lens. This paper introduces VisibleSim , an open-source behavioral simulator for lattice-based modular robots that uses discrete-event simulation. We describe the principles behind the simulator and introduce its features and usage from a user standpoint. VisibleSim has unique features like extensibility, versatility, and flexibility, it can also be used as a powerful visualization tool and has already a proven track record with several modular robotic architectures. We present a stress test composed of, ultimately, 32 million simulated robots, a new record in the field of modular robotic simulation.},
  archive      = {J_RAS},
  author       = {Pierre Thalamy and Benoît Piranda and André Naz and Julien Bourgeois},
  doi          = {10.1016/j.robot.2021.103913},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103913},
  shortjournal = {Robot. Auton. Syst.},
  title        = {VisibleSim: A behavioral simulation framework for lattice modular robots},
  volume       = {147},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Local-HDP: Interactive open-ended 3D object category
recognition in real-time robotic scenarios. <em>RAS</em>, <em>147</em>,
103911. (<a href="https://doi.org/10.1016/j.robot.2021.103911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a non-parametric hierarchical Bayesian approach for open-ended 3D object categorization, named the Local Hierarchical Dirichlet Process (Local-HDP). This method allows an agent to learn independent topics for each category incrementally and to adapt to the environment in time. Each topic is a distribution of the visual words over a predefined dictionary. Using an inference algorithm, these latent variables are inferred from the dataset. Subsequently, the category of an object is determined based on the likelihood of generating a 3D object from the model. Hierarchical Bayesian approaches like Latent Dirichlet Allocation (LDA) can transform low-level features to high-level conceptual topics for 3D object categorization. However, the efficiency and accuracy of LDA-based approaches depend on the number of topics that is chosen manually. Moreover, fixing the number of topics for all categories can lead to overfitting or underfitting of the model. In contrast, the proposed Local-HDP can autonomously determine the number of topics for each category. Furthermore, the online variational inference method has been adapted for fast posterior approximation in the Local-HDP model. Experiments show that the proposed Local-HDP method outperforms other state-of-the-art approaches in terms of accuracy, scalability, and memory efficiency by a large margin. Moreover, two robotic experiments have been conducted to show the applicability of the proposed approach in real-time applications.},
  archive      = {J_RAS},
  author       = {H. Ayoobi and H. Kasaei and M. Cao and R. Verbrugge and B. Verheij},
  doi          = {10.1016/j.robot.2021.103911},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103911},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Local-HDP: Interactive open-ended 3D object category recognition in real-time robotic scenarios},
  volume       = {147},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Backstepping control for a UAV-manipulator tuned by cuckoo
search algorithm. <em>RAS</em>, <em>147</em>, 103910. (<a
href="https://doi.org/10.1016/j.robot.2021.103910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manipulators coupled with an Unmanned Aerial Vehicle (UAV) have made it possible to perform aerial handling, transport, and picking maneuvers. One of the techniques used to control these systems is a backstepping controller that has shown high performance compared to a PID in the face of uncertainties and parametric disturbances. This paper presents the study of a backstepping controller for a mobile manipulator (MM–UAV) system tuned with the Cuckoo Search algorithm (CS) for trajectory tracking. Unlike other research, this study focuses on optimization using this metaheuristic algorithm that has never been applied in an MM–UAV. The system is divided in a novel way to implement the CS, considering the dependence of each rotation axis with the correspondence translation axis. Additionally, the tuning focuses on two critical points of the dynamic response, the overshoot and settling time. The results at the simulation and experimental level show that for all cases, a settling time of fewer than 0.8 s and overshoot is minor than 2\%. This allows a balanced response of the system, which directly impacts energy consumption. The results are compared with a PID controller to verify the proposed work efficiency, showing a reduction of up to 8\% of overshoots without exceeding in any experiment the maximum settling time of 0.8 s imposed to the system.},
  archive      = {J_RAS},
  author       = {Omar Rodríguez-Abreo and Francisco-Javier Ornelas-Rodríguez and Alfonso Ramírez-Pedraza and Juan B. Hurtado-Ramos and José-Joel González-Barbosa},
  doi          = {10.1016/j.robot.2021.103910},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103910},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Backstepping control for a UAV-manipulator tuned by cuckoo search algorithm},
  volume       = {147},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design, development and evaluation of latex harvesting robot
based on flexible toggle. <em>RAS</em>, <em>147</em>, 103906. (<a
href="https://doi.org/10.1016/j.robot.2021.103906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural rubber latex is an important energy material. However, the harvest of latex is still manual, and there are few researches on automatic work. This paper proposed a method for robot to harvest from each rubber tree without stopping. The robot toggled the collection cup through the flexible actuator, the cup poured out the latex and rotated to the next collection position. In this way, it not only completed the harvest work, but also prepared for the next collection. Aiming at the problem of latex splashing during rapid toggle, the structural parameters of the collection cup and the flexible actuator were modeled and studied. This method made the rotation speed of the collection cup smoother and avoids splashing. To enable the robot to accurately complete the harvesting work, this paper used two-dimensional Light Detection and Ranging (LiDAR) and ranging sensor to locate the space position of the collection cup. The results show that when the toggle speed is 0.5 m/s and the latex volume is 300 ml, the average shaking height is 3.58 mm. In the field test, the lateral error of positioning is less than 8.86 mm, and the height error is less than 0.72 mm; the average harvest rate is 98.18\%. The robot has high efficiency and good stability, and can be applied to the rubber plantation to harvest automatically.},
  archive      = {J_RAS},
  author       = {Song Wang and Hang Zhou and Chunlong Zhang and Luzhen Ge and Wei Li and Ting Yuan and Wenqiang Zhang and Junxiong Zhang},
  doi          = {10.1016/j.robot.2021.103906},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103906},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Design, development and evaluation of latex harvesting robot based on flexible toggle},
  volume       = {147},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-robot task allocation in disaster response: Addressing
dynamic tasks with deadlines and robots with range and payload
constraints. <em>RAS</em>, <em>147</em>, 103905. (<a
href="https://doi.org/10.1016/j.robot.2021.103905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper tackles a class of multi-robot task allocation (MRTA) problems called “Single-Task Robots and Single-Robot Tasks” or SR–ST problems, subject to the following additional characteristics: tasks with deadlines, tasks that are generated during the mission, and robots with range and payload constraints (thus requiring multiple tours per robot). While these characteristics are typical of various disaster response and commercial applications, there is a lack of online MRTA solutions to address them. To solve this class of complex MRTA problems, an efficient online method (which is also suitable for decentralized deployment) is developed based on the construction and weighted matching of bipartite graphs . An exact integer linear programming (ILP) formulation of this class of MRTA problems is also developed, the solution of which serves both as an offline MRTA approach and as a provably optimal benchmark against which the online method is compared. The new methods are applied to a flood response problem where multiple unmanned aerial vehicles must respond to victims spread out over a large area. The results show that the new online algorithm closely trails the offline ILP method in terms of task completion performance, while being &gt; 1 0 3 &amp;gt;103 times more computationally efficient compared to the ILP method. Dedicated case studies provide further insights into the favorable scalability of the online method with an increasing number of UAVs — offering up to 46\% higher task completion compared to a random walk baseline in huge 1000-task problems. Lastly, application to a slightly different class of SR–ST problems and comparison of the ensuing results with that of corresponding state-of-the-art methods demonstrate the potential wider applicability of the proposed online MRTA method.},
  archive      = {J_RAS},
  author       = {Payam Ghassemi and Souma Chowdhury},
  doi          = {10.1016/j.robot.2021.103905},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103905},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Multi-robot task allocation in disaster response: Addressing dynamic tasks with deadlines and robots with range and payload constraints},
  volume       = {147},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Application of the unscented kalman filter in position
estimation a case study on a robot for precise positioning.
<em>RAS</em>, <em>147</em>, 103904. (<a
href="https://doi.org/10.1016/j.robot.2021.103904">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-precision measurement is a common task in many engineering applications . In these cases, sensor fusion algorithms represented by Kalman filter and its variants are effective and practical. It is introduced in the article, how to use this sensor fusion algorithm in a high-precision tracking task, where only one sensor (tacheometer) is used in the project. It is also discussed in the article how to build estimation models, including measurement model and motion model, for specific robot positioning problems. A variety of related models are compared in this article. The best model that utilize the prior knowledge of robot motion is proposed, which can not only meet the high precision requirements, but also have robustness to the robot operating environment.},
  archive      = {J_RAS},
  author       = {Christoph Naab and Zhuoxun Zheng},
  doi          = {10.1016/j.robot.2021.103904},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103904},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Application of the unscented kalman filter in position estimation a case study on a robot for precise positioning},
  volume       = {147},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design and experimental validation of a robust model
predictive control for the optimal trajectory tracking of a small-scale
autonomous bulldozer. <em>RAS</em>, <em>147</em>, 103903. (<a
href="https://doi.org/10.1016/j.robot.2021.103903">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory tracking of an unmanned ground vehicle (UGV) is essential due to its extensive construction, agriculture, and military applications. In this paper, we propose an efficient, robust model predictive control (RMPC) for the trajectory tracking of a small-scale autonomous bulldozer in the presence of perturbations by unknown but bounded disturbances . The proposed RMPC is designed by considering a linearised tracking error-based model combined with a feed-forward and optimal control action to achieve the proposed trajectory. The presence of a corrective feedback controller as a time-varying finite-time linear quadratic regulator (LQR) suppresses the uncertainties acting on the real system by regulating around the nominal system. Pose estimation, required for control feedback , is based on sensor data fusion performed by an extended Kalman filter (EKF) map-based localiser, which processes inertial measurement unit (IMU) and light detection and ranging (LiDAR) measurements. Experiments are performed using a real robot (Husky A200) to validate the proposed control scheme’s performance. The experimental results show that the proposed controller can safely track target trajectories with low processing time, small tracking errors, and smooth control actions. Finally, the proposed control scheme is compared with related techniques and outperforms them in tracking accuracy.},
  archive      = {J_RAS},
  author       = {Subhan Khan and Jose Guivant and Xuesong Li},
  doi          = {10.1016/j.robot.2021.103903},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103903},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Design and experimental validation of a robust model predictive control for the optimal trajectory tracking of a small-scale autonomous bulldozer},
  volume       = {147},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robotic picking in dense clutter via domain invariant
learning from synthetic dense cluttered rendering. <em>RAS</em>,
<em>147</em>, 103901. (<a
href="https://doi.org/10.1016/j.robot.2021.103901">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic picking of diverse range of novel objects is a great challenge in dense clutter, in which objects are stacked together tightly. However, collecting large-scale dataset with dense grasp labels is extremely time-consuming, and there is a huge gap between synthetic and real images. In this paper, we explore suction based grasping from synthetic multi object rendering . To avoid tedious human labeling, we present a pipeline to model stacked objects in simulation and generate photorealistic rendering RGB-D images with dense suction point labels. To reduce simulation-to-reality gap from synthetic images to low-quality RGB-D camera, we propose a novel domain-invariant Suction Quality Neural Network (diSQNN) by training on labeled synthetic dataset with unlabeled real dataset. Specifically, diSQNN fuses photorealistic color feature and adversarial depth feature, and uses a domain discriminator on depth extractor to align depth feature distribution from synthetic and real images. We evaluate our proposed method by comparing with other baseline and suction detection method. The results demonstrate the effectiveness of our synthetic dense cluttered rendering . And through feature alignment, our domain invariant learning method can learn grasp related features, while ignoring domain related disturbing features, which maintains a high transfer performance on real RGB-D images. On a physical robot with vacuum-based gripper, the proposed method achieves average picking success rate of 91\% and 88\% for known objects and novel objects in a tote without using any manual labels.},
  archive      = {J_RAS},
  author       = {Wenhai Liu and Weiming Wang and Yang You and Teng Xue and Zhenyu Pan and Jin Qi and Jie Hu},
  doi          = {10.1016/j.robot.2021.103901},
  journal      = {Robotics and Autonomous Systems},
  pages        = {103901},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Robotic picking in dense clutter via domain invariant learning from synthetic dense cluttered rendering},
  volume       = {147},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
