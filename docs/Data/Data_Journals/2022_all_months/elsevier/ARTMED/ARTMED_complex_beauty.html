<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ARTMED_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="artmed---133">ARTMED - 133</h2>
<ul>
<li><details>
<summary>
(2022). CATNet: Cross-event attention-based time-aware network for
medical event prediction. <em>ARTMED</em>, <em>134</em>, 102440. (<a
href="https://doi.org/10.1016/j.artmed.2022.102440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical event prediction (MEP) is a fundamental task in the healthcare domain, which needs to predict medical events, including medications, diagnosis codes, laboratory tests , procedures, outcomes, and so on, according to historical medical records of patients. Many researchers have tried to build MEP models to overcome the challenges caused by the heterogeneous and irregular temporal characteristics of EHR data. However, most of them consider the heterogenous and temporal medical events separately and ignore the correlations among different types of medical events, especially relations between heterogeneous historical medical events and target medical events. In this paper, we propose a novel neural network based on attention mechanism called Cross-event Attention-based Time-aware Network (CATNet) for MEP. It is a time-aware, event-aware and task-adaptive method with the following advantages: 1) modeling heterogeneous information and temporal information in a unified way and considering irregular temporal characteristics locally and globally respectively, 2) taking full advantage of correlations among different types of events via cross-event attention. Experiments on two public datasets (MIMIC-III and eICU) show CATNet outperforms other state-of-the-art methods on various MEP tasks. The source code of CATNet is released at https://github.com/sherry6247/CATNet.git .},
  archive      = {J_ARTMED},
  author       = {Sicen Liu and Xiaolong Wang and Yang Xiang and Hui Xu and Hui Wang and Buzhou Tang},
  doi          = {10.1016/j.artmed.2022.102440},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102440},
  shortjournal = {Artif. Intell. Med.},
  title        = {CATNet: Cross-event attention-based time-aware network for medical event prediction},
  volume       = {134},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Investigating the understandability of XAI methods for
enhanced user experience: When bayesian network users became detectives.
<em>ARTMED</em>, <em>134</em>, 102438. (<a
href="https://doi.org/10.1016/j.artmed.2022.102438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the medical domain, the uptake of an AI tool crucially depends on whether clinicians are confident that they understand the tool. Bayesian networks are popular AI models in the medical domain, yet, explaining predictions from Bayesian networks to physicians and patients is non-trivial. Various explanation methods for Bayesian network inference have appeared in literature, focusing on different aspects of the underlying reasoning. While there has been a lot of technical research, there is little known about the actual user experience of such methods. In this paper, we present results of a study in which four different explanation approaches were evaluated through a survey by questioning a group of human participants on their perceived understanding in order to gain insights about their user experience.},
  archive      = {J_ARTMED},
  author       = {Raphaela Butz and Renée Schulz and Arjen Hommersom and Marko van Eekelen},
  doi          = {10.1016/j.artmed.2022.102438},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102438},
  shortjournal = {Artif. Intell. Med.},
  title        = {Investigating the understandability of XAI methods for enhanced user experience: When bayesian network users became detectives},
  volume       = {134},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bolus insulin calculation without meal information. A
reinforcement learning approach. <em>ARTMED</em>, <em>134</em>, 102436.
(<a href="https://doi.org/10.1016/j.artmed.2022.102436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In continuous subcutaneous insulin infusion and multiple daily injections, insulin boluses are usually calculated based on patient-specific parameters, such as carbohydrates-to-insulin ratio (CR), insulin sensitivity-based correction factor (CF), and the estimation of the carbohydrates (CHO) to be ingested. This study aimed to calculate insulin boluses without CR, CF, and CHO content, thereby eliminating the errors caused by misestimating CHO and alleviating the management burden on the patient. A Q-learning-based reinforcement learning algorithm (RL) was developed to optimise bolus insulin doses for in-silico type 1 diabetic patients. A realistic virtual cohort of 68 patients with type 1 diabetes that was previously developed by our research group, was considered for the in-silico trials. The results were compared to those of the standard bolus calculator (SBC) with and without CHO misestimation using open-loop basal insulin therapy. The percentage of the overall duration spent in the target range of 70–180 mg/dL was 73.4% and 72.37%, &lt; &amp;lt; 70 mg/dL was 1.96 and 0.70%, and &gt; &amp;gt; 180 mg/dL was 23.40 and 24.63%, respectively, for RL and SBC without CHO misestimation. The results revealed that RL outperformed SBC in the presence of CHO misestimation, and despite not knowing the CHO content of meals, the performance of RL was similar to that of SBC in perfect conditions. This algorithm can be incorporated into artificial pancreas and automatic insulin delivery systems in the future.},
  archive      = {J_ARTMED},
  author       = {Sayyar Ahmad and Aleix Beneyto and Ivan Contreras and Josep Vehi},
  doi          = {10.1016/j.artmed.2022.102436},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102436},
  shortjournal = {Artif. Intell. Med.},
  title        = {Bolus insulin calculation without meal information. a reinforcement learning approach},
  volume       = {134},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Virtual disease landscape using mechanics-informed machine
learning: Application to esophageal disorders. <em>ARTMED</em>,
<em>134</em>, 102435. (<a
href="https://doi.org/10.1016/j.artmed.2022.102435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Esophageal disorders are related to the mechanical properties and function of the esophageal wall. Therefore, to understand the underlying fundamental mechanisms behind various esophageal disorders, it is crucial to map mechanical behavior of the esophageal wall in terms of mechanics-based parameters corresponding to altered bolus transit and increased intrabolus pressure. We present a hybrid framework that combines fluid mechanics and machine learning to identify the underlying physics of various esophageal disorders (motility disorders, eosinophilic esophagitis , reflux disease, scleroderma esophagus) and maps them onto a parameter space which we call the virtual disease landscape (VDL). A one-dimensional inverse model processes the output from an esophageal diagnostic device called the functional lumen imaging probe (FLIP) to estimate the mechanical “health” of the esophagus by predicting a set of mechanics-based parameters such as esophageal wall stiffness, muscle contraction pattern and active relaxation of esophageal wall. The mechanics-based parameters were then used to train a neural network that consists of a variational autoencoder that generated a latent space and a side network that predicted mechanical work metrics for estimating esophagogastric junction motility. The latent vectors along with a set of discrete mechanics-based parameters define the VDL and formed clusters corresponding to specific esophageal disorders. The VDL not only distinguishes among disorders but also displayed disease progression over time. Finally, we demonstrated the clinical applicability of this framework for estimating the effectiveness of a treatment and tracking patients&#39; condition after a treatment.},
  archive      = {J_ARTMED},
  author       = {Sourav Halder and Jun Yamasaki and Shashank Acharya and Wenjun Kou and Guy Elisha and Dustin A. Carlson and Peter J. Kahrilas and John E. Pandolfino and Neelesh A. Patankar},
  doi          = {10.1016/j.artmed.2022.102435},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102435},
  shortjournal = {Artif. Intell. Med.},
  title        = {Virtual disease landscape using mechanics-informed machine learning: Application to esophageal disorders},
  volume       = {134},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mining context-aware resource profiles in the presence of
multitasking. <em>ARTMED</em>, <em>134</em>, 102434. (<a
href="https://doi.org/10.1016/j.artmed.2022.102434">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Healthcare organisations are becoming increasingly aware of the need to improve their care processes and to manage their scarce resources efficiently to secure high-quality care standards. As these processes are knowledge-intensive and heavily depend on human resources, a comprehensive understanding of the complex relationship between processes and resources is indispensable for efficient resource management. Organisational mining, a subfield of Process Mining, reveals insights into how (human) resources organise their work based on analysing process execution data recorded in Health Information Systems (HIS). This can be used to, e.g., discover resource profiles which are groups of resources performing similar activity instances, providing an extensive overview of resource behaviour within healthcare organisations. Healthcare managers can employ these insights to allocate their resources efficiently, e.g., by improving the scheduling and staffing of nurses. Existing resource profiling algorithms are limited in their ability to apprehend the complex relationship between processes and resources because they do not take into account the context in which activities were executed, particularly in the context of multitasking. Therefore, this paper introduces ResProMin–MT to discover context-aware resource profiles in the presence of multitasking. In contrast to the state-of-the-art, ResProMin–MT is capable of taking into account more complex contextual activity dimensions, such as activity durations and the degree of multitasking by resources. We demonstrate the feasibility of our method within a real-life healthcare context, validated by medical domain experts.},
  archive      = {J_ARTMED},
  author       = {Gerhardus A.W.M. van Hulzen and Chiao-Yun Li and Niels Martin and Sebastiaan J. van Zelst and Benoît Depaire},
  doi          = {10.1016/j.artmed.2022.102434},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102434},
  shortjournal = {Artif. Intell. Med.},
  title        = {Mining context-aware resource profiles in the presence of multitasking},
  volume       = {134},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MF-OMKT: Model fusion based on online mutual knowledge
transfer for breast cancer histopathological image classification.
<em>ARTMED</em>, <em>134</em>, 102433. (<a
href="https://doi.org/10.1016/j.artmed.2022.102433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pathological diagnosis is considered as the benchmark for the detection of breast cancer. With the increasing number of patients, computer-aided histopathological image classification can assist pathologists in improving breast cancer diagnosis accuracy and working efficiency. However, a single model is insufficient for effective diagnosis, and this also does not accord with the principle of centralized decision-making. Starting from the real pathological diagnosis scenario, we propose a novel model fusion framework based on online mutual knowledge transfer (MF-OMKT) for breast cancer histopathological image classification . The OMKT part based on deep mutual learning (DML) imitates the mutual communication and learning between multiple experienced pathologists, which can break the isolation of single models and provides sufficient complementarity among heterogeneous networks for MF. The MF part based on adaptive feature fusion uses the complementarity to train a powerful fusion classifier. MF imitates the centralized decision-making process of these pathologists. We used the MF-OMKT model to classify breast cancer histopathological images (BreakHis dataset) into benign and malignant as well as eight subtypes. The accuracy of our model reaches the range of [99.27 %, 99.84 %] for binary classification . And that for multi-class classification reaches the range of [96.14 %, 97.53 %]. Additionally, MF-OMKT is applied to the classification of skin cancer images (ISIC 2018 dataset) and achieves an accuracy of 94.90 %. MF-OMKT is an effective and versatile framework for medical image classification .},
  archive      = {J_ARTMED},
  author       = {Guangli Li and Chuanxiu Li and Guangting Wu and Guangxin Xu and Ying Zhou and Hongbin Zhang},
  doi          = {10.1016/j.artmed.2022.102433},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102433},
  shortjournal = {Artif. Intell. Med.},
  title        = {MF-OMKT: Model fusion based on online mutual knowledge transfer for breast cancer histopathological image classification},
  volume       = {134},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An explainable deep learning-based algorithm with an
attention mechanism for predicting the live birth potential of mouse
embryos. <em>ARTMED</em>, <em>134</em>, 102432. (<a
href="https://doi.org/10.1016/j.artmed.2022.102432">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In assisted reproductive technology (ART), embryos produced by in vitro fertilization (IVF) are graded according to their live birth potential, and high-grade embryos are preferentially transplanted. However, rates of live birth following clinical ART remain low worldwide. Grading is based on the embryo shape at a limited number of stages and does not consider the shape of embryos and intracellular structures, e.g., nuclei, at various stages important for normal embryogenesis . Here, we developed a Normalized Multi-View Attention Network (NVAN) that directly predicts live birth potential from the nuclear structure in live-cell fluorescence images of mouse embryos from zygote to across a wide range of stages. The input is morphological features of cell nuclei , which were extracted as multivariate time-series data by using the segmentation algorithm for mouse embryos. The classification accuracy of our method (83.87%) greatly exceeded that of existing machine-learning methods and that of visual inspection by embryo culture specialists. Our method also has a new attention mechanism that allows us to determine which values of multivariate time-series data, used to describe nuclear morphology, were the basis for the prediction. By visualizing the features that contributed most to the prediction of live birth potential, we found that the size and shape of the nucleus at the morula stage and at the time of cell division were important for live birth prediction. We anticipate that our method will help ART and developmental engineering as a new basic technology for IVF embryo selection.},
  archive      = {J_ARTMED},
  author       = {Yuta Tokuoka and Takahiro G. Yamada and Daisuke Mashiko and Zenki Ikeda and Tetsuya J. Kobayashi and Kazuo Yamagata and Akira Funahashi},
  doi          = {10.1016/j.artmed.2022.102432},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102432},
  shortjournal = {Artif. Intell. Med.},
  title        = {An explainable deep learning-based algorithm with an attention mechanism for predicting the live birth potential of mouse embryos},
  volume       = {134},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ubiquitous and smart healthcare monitoring frameworks based
on machine learning: A comprehensive review. <em>ARTMED</em>,
<em>134</em>, 102431. (<a
href="https://doi.org/10.1016/j.artmed.2022.102431">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the COVID-19 pandemic, the patient care delivery paradigm rapidly shifted to remote technological solutions. Rising rates of life expectancy of older people, and deaths due to chronic diseases (CDs) such as cancer, diabetes and respiratory disease pose many challenges to healthcare. While the feasibility of Remote Patient Monitoring (RPM) with a Smart Healthcare Monitoring (SHM) framework was somewhat questionable before the COVID-19 pandemic, it is now a proven commodity and is on its way to becoming ubiquitous. More health organizations are adopting RPM to enable CD management in the absence of individual monitoring. The current studies on SHM have reviewed the applications of IoT and/or Machine Learning (ML) in the domain, their architecture, security, privacy and other network related issues. However, no study has analyzed the AI and ubiquitous computing advances in SHM frameworks. The objective of this research is to identify and map key technical concepts in the SHM framework. In this context an interesting and meaningful classification of the research articles surveyed for this work is presented. The comprehensive and systematic review is based on the “Preferred Reporting Items for Systematic Review and Meta-Analysis” (PRISMA) approach. A total of 2540 papers were screened from leading research archives from 2016 to March 2021, and finally, 50 articles were selected for review. The major advantages, developments, distinctive architectural structure , components, technical challenges and possibilities in SHM are briefly discussed. A review of various recent cloud and fog computing based architectures, major ML implementation challenges, prospects and future trends is also presented. The survey primarily encourages the data driven predictive analytics aspects of healthcare and the development of ML models for health empowerment.},
  archive      = {J_ARTMED},
  author       = {Anand Motwani and Piyush Kumar Shukla and Mahesh Pawar},
  doi          = {10.1016/j.artmed.2022.102431},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102431},
  shortjournal = {Artif. Intell. Med.},
  title        = {Ubiquitous and smart healthcare monitoring frameworks based on machine learning: A comprehensive review},
  volume       = {134},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Medical resource allocation planning by integrating machine
learning and optimization models. <em>ARTMED</em>, <em>134</em>, 102430.
(<a href="https://doi.org/10.1016/j.artmed.2022.102430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Patients&#39; waiting time is a major issue in the Canadian healthcare system. The planning for resource allocation impacts patients&#39; waiting time in medicare settings. This research focuses on the reduction of patients&#39; waiting time by providing better planning for radiological resource allocation and efficient workload distribution . Resource allocation planning is directly related to the number of patient-arrival and it is hard to predict such uncertain parameters in the future time frame. The number of patient-arrival also varies across different modalities and different timeframes which makes the patient-arrival prediction challenging. In this research, a new three-phase solution framework is proposed where a new multi-target machine learning technique is integrated with an optimization model. In the first phase, a novel Ensemble of Pruned Regressor Chain (EPRC) model is developed and trained offline to predict uncertain parameters, such as patients&#39; arrival. The proposed model is then compared with two popular multi-target prediction methods to evaluate the model&#39;s accuracy. In the second phase, the trained model is deployed in the real-time environment to forecast patients&#39; arrival, miss Turn Around Time (miss-TAT) rate, and probable workload count. The forecasted data is used in phase three where a new multi-objective optimization model is developed to determine workload allocation. The Weighted-sum method is used to get efficient solutions. The proposed model is deployed in a Canadian healthcare company and evaluated using real-time healthcare data . It is observed in terms of accuracy, the proposed EPRC model performed 10.81 % better compared to the other multi-target models considered in this study. It is also noticed that the forecasting results have a direct impact on the workload distribution, where the proposed model decreases the total workload by approximately 25 %. Besides, the result shows the efficient workload distribution provided by the proposed framework can reduce the average patients&#39; waiting time by 8.17 %.},
  archive      = {J_ARTMED},
  author       = {Tasquia Mizan and Sharareh Taghipour},
  doi          = {10.1016/j.artmed.2022.102430},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102430},
  shortjournal = {Artif. Intell. Med.},
  title        = {Medical resource allocation planning by integrating machine learning and optimization models},
  volume       = {134},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The applications of machine learning in HIV neutralizing
antibodies research—a systematic review. <em>ARTMED</em>, <em>134</em>,
102429. (<a href="https://doi.org/10.1016/j.artmed.2022.102429">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning algorithms play an essential role in bioinformatics and allow exploring the vast and noisy biological data in unrivaled ways. This paper is a systematic review of the applications of machine learning in the study of HIV neutralizing antibodies . This significant and vast research domain can pave the way to novel treatments and to a vaccine. We selected the relevant papers by investigating the available literature from the Web of Science and PubMed databases in the last decade. The computational methods are applied in neutralization potency prediction, neutralization span prediction against multiple viral strains, antibody–virus binding sites detection, enhanced antibodies design , and the study of the antibody-induced immune response. These methods are viewed from multiple angles spanning data processing, model description, feature selection, evaluation, and sometimes paper comparisons. The algorithms are diverse and include supervised, unsupervised, and generative types. Both classical machine learning and modern deep learning were taken into account. The review ends with our ideas regarding future research directions and challenges.},
  archive      = {J_ARTMED},
  author       = {Vlad-Rareş Dănăilă and Speranţa Avram and Cătălin Buiu},
  doi          = {10.1016/j.artmed.2022.102429},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102429},
  shortjournal = {Artif. Intell. Med.},
  title        = {The applications of machine learning in HIV neutralizing antibodies research—A systematic review},
  volume       = {134},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A non-invasive machine learning mechanism for early disease
recognition on twitter: The case of anemia. <em>ARTMED</em>,
<em>134</em>, 102428. (<a
href="https://doi.org/10.1016/j.artmed.2022.102428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media sites, such as Twitter, provide the means for users to share their stories, feelings, and health conditions during the disease course . Anemia , the most common type of blood disorder , is recognized as a major public health problem all over the world. Yet very few studies have explored the potential of recognizing anemia from online posts. This study proposed a novel mechanism for recognizing anemia based on the associations between disease symptoms and patients&#39; emotions posted on the Twitter platform. We used k-means and Latent Dirichlet Allocation (LDA) algorithms to group similar tweets and to identify hidden disease topics. Both disease emotions and symptoms were mapped using the Apriori algorithm. The proposed approach was evaluated using a number of classifiers. A higher prediction accuracy of 98.96 % was achieved using Sequential Minimal Optimization (SMO). The results revealed that fear and sadness emotions are dominant among anemic patients. The proposed mechanism is the first of its kind to diagnose anemia using textual information posted on social media sites. It can advance the development of intelligent health monitoring systems and clinical decision-support systems.},
  archive      = {J_ARTMED},
  author       = {Samer Muthana Sarsam and Hosam Al-Samarraie and Ahmed Ibrahim Alzahrani and Abdul Samad Shibghatullah},
  doi          = {10.1016/j.artmed.2022.102428},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102428},
  shortjournal = {Artif. Intell. Med.},
  title        = {A non-invasive machine learning mechanism for early disease recognition on twitter: The case of anemia},
  volume       = {134},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). COVID-DSNet: A novel deep convolutional neural network for
detection of coronavirus (SARS-CoV-2) cases from CT and chest x-ray
images. <em>ARTMED</em>, <em>134</em>, 102427. (<a
href="https://doi.org/10.1016/j.artmed.2022.102427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 (SARS-CoV-2), which causes acute respiratory syndrome, is a contagious and deadly disease that has devastating effects on society and human life. COVID-19 can cause serious complications, especially in patients with pre-existing chronic health problems such as diabetes, hypertension, lung cancer, weakened immune systems, and the elderly. The most critical step in the fight against COVID-19 is the rapid diagnosis of infected patients. Computed Tomography (CT), chest X-ray (CXR), and RT-PCR diagnostic kits are frequently used to diagnose the disease. However, due to difficulties such as the inadequacy of RT-PCR test kits and false negative (FN) results in the early stages of the disease, the time-consuming examination of medical images obtained from CT and CXR imaging techniques by specialists/doctors, and the increasing workload on specialists, it is challenging to detect COVID-19. Therefore, researchers have suggested searching for new methods in COVID- 19 detection. In analysis studies with CT and CXR radiography images, it was determined that COVID-19-infected patients experienced abnormalities related to COVID-19. The anomalies observed here are the primary motivation for artificial intelligence researchers to develop COVID-19 detection applications with deep convolutional neural networks. Here, convolutional neural network-based deep learning algorithms from artificial intelligence technologies with high discrimination capabilities can be considered as an alternative approach in the disease detection process. This study proposes a deep convolutional neural network, COVID-DSNet, to diagnose typical pneumonia (bacterial, viral) and COVID-19 diseases from CT, CXR, hybrid CT + CXR images. In the multi-classification study with the CT dataset, 97.60 % accuracy and 97.60 % sensitivity values were obtained from the COVID-DSNet model, and 100 %, 96.30 %, and 96.58 % sensitivity values were obtained in the detection of typical, common pneumonia and COVID-19, respectively. The proposed model is an economical, practical deep learning network that data scientists can benefit from and develop. Although it is not a definitive solution in disease diagnosis, it may help experts as it produces successful results in detecting pneumonia and COVID-19.},
  archive      = {J_ARTMED},
  author       = {Hatice Catal Reis and Veysel Turk},
  doi          = {10.1016/j.artmed.2022.102427},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102427},
  shortjournal = {Artif. Intell. Med.},
  title        = {COVID-DSNet: A novel deep convolutional neural network for detection of coronavirus (SARS-CoV-2) cases from CT and chest X-ray images},
  volume       = {134},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detecting 3D syndromic faces as outliers using unsupervised
normalizing flow models. <em>ARTMED</em>, <em>134</em>, 102425. (<a
href="https://doi.org/10.1016/j.artmed.2022.102425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many genetic syndromes are associated with distinctive facial features . Several computer-assisted methods have been proposed that make use of facial features for syndrome diagnosis. Training supervised classifiers, the most common approach for this purpose, requires large, comprehensive, and difficult to collect databases of syndromic facial images . In this work, we use unsupervised, normalizing flow-based manifold and density estimation models trained entirely on unaffected subjects to detect syndromic 3D faces as statistical outliers. Furthermore, we demonstrate a general, user-friendly, gradient-based interpretability mechanism that enables clinicians and patients to understand model inferences. 3D facial surface scans of 2471 unaffected subjects and 1629 syndromic subjects representing 262 different genetic syndromes were used to train and evaluate the models. The flow-based models outperformed unsupervised comparison methods, with the best model achieving an ROC-AUC of 86.3% on a challenging, age and sex diverse data set. In addition to highlighting the viability of outlier-based syndrome screening tools, our methods generalize and extend previously proposed outlier scores for 3D face-based syndrome detection, resulting in improved performance for unsupervised syndrome detection.},
  archive      = {J_ARTMED},
  author       = {Jordan J. Bannister and Matthias Wilms and J. David Aponte and David C. Katz and Ophir D. Klein and Francois P.J. Bernier and Richard A. Spritz and Benedikt Hallgrímsson and Nils D. Forkert},
  doi          = {10.1016/j.artmed.2022.102425},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102425},
  shortjournal = {Artif. Intell. Med.},
  title        = {Detecting 3D syndromic faces as outliers using unsupervised normalizing flow models},
  volume       = {134},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SurvivalCNN: A deep learning-based method for gastric cancer
survival prediction using radiological imaging data and
clinicopathological variables. <em>ARTMED</em>, <em>134</em>, 102424.
(<a href="https://doi.org/10.1016/j.artmed.2022.102424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiological images have shown promising effects in patient prognostication. Deep learning provides a powerful approach for in-depth analysis of imaging data and integration of multi-modal data for modeling. In this work, we propose SurvivalCNN , a deep learning structure for cancer patient survival prediction using CT imaging data and non-imaging clinical data. In SurvivalCNN, a supervised convolutional neural network is designed to extract volumetric image features, and radiomics features are also integrated to provide potentially different imaging information. Within SurvivalCNN, a novel multi-thread multi-layer perceptron module, namely, SurvivalMLP, is proposed to perform survival prediction from censored survival data. We evaluate the proposed SurvivalCNN framework on a large clinical dataset of 1061 gastric cancer patients for both overall survival (OS) and progression-free survival (PFS) prediction. We compare SurvivalCNN to three different modeling methods and examine the effects of various sets of data/features when used individually or in combination. With five-fold cross validation, our experimental results show that SurvivalCNN achieves averaged concordance index 0.849 and 0.783 for predicting OS and PFS, respectively, outperforming the compared state-of-the-art methods and the clinical model. After future validation, the proposed SurvivalCNN model may serve as a clinical tool to improve gastric cancer patient survival estimation and prognosis analysis.},
  archive      = {J_ARTMED},
  author       = {Degan Hao and Qiong Li and Qiu-Xia Feng and Liang Qi and Xi-Sheng Liu and Dooman Arefan and Yu-Dong Zhang and Shandong Wu},
  doi          = {10.1016/j.artmed.2022.102424},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102424},
  shortjournal = {Artif. Intell. Med.},
  title        = {SurvivalCNN: A deep learning-based method for gastric cancer survival prediction using radiological imaging data and clinicopathological variables},
  volume       = {134},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fuzzy-SIRD model: Forecasting COVID-19 death tolls
considering governments intervention. <em>ARTMED</em>, <em>134</em>,
102422. (<a href="https://doi.org/10.1016/j.artmed.2022.102422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling the trend of contagious diseases has particular importance for managing them and reducing the side effects on society. In this regard, researchers have proposed compartmental models for modeling the spread of diseases. However, these models suffer from a lack of adaptability to variations of parameters over time. This paper introduces a new Fuzzy Susceptible–Infectious–Recovered–Deceased (Fuzzy-SIRD) model for covering the weaknesses of the simple compartmental models. Due to the uncertainty in forecasting diseases, the proposed Fuzzy-SIRD model represents the government intervention as an interval type 2 Mamdani fuzzy logic system. Also, since society’s response to government intervention is not a static reaction, the proposed model uses a first-order linear system to model its dynamics. In addition, this paper uses the Particle Swarm Optimization (PSO) algorithm for optimally selecting system parameters. The objective function of this optimization problem is the Root Mean Square Error (RMSE) of the system output for the deceased population in a specific time interval. This paper provides many simulations for modeling and predicting the death tolls caused by COVID-19 disease in seven countries and compares the results with the simple SIRD model. Based on the reported results, the proposed Fuzzy-SIRD model can reduce the root mean square error of predictions by more than 80% in the long-term scenarios, compared with the conventional SIRD model. The average reduction of RMSE for the short-term and long-term predictions are 45.83% and 72.56%, respectively. The results also show that the principle goal of the proposed modeling, i.e., creating a semantic relation between the basic reproduction number , government intervention, and society’s response to interventions, has been well achieved. As the results approve, the proposed model is a suitable and adaptable alternative for conventional compartmental models.},
  archive      = {J_ARTMED},
  author       = {Amir Arslan Haghrah and Sehraneh Ghaemi and Mohammad Ali Badamchizadeh},
  doi          = {10.1016/j.artmed.2022.102422},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102422},
  shortjournal = {Artif. Intell. Med.},
  title        = {Fuzzy-SIRD model: Forecasting COVID-19 death tolls considering governments intervention},
  volume       = {134},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive and personalized user behavior modeling in complex
event processing platforms for remote health monitoring systems.
<em>ARTMED</em>, <em>134</em>, 102421. (<a
href="https://doi.org/10.1016/j.artmed.2022.102421">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Taking care of people who need constant care is essential and its cost is rising every day. Many intelligent remote health monitoring systems have been developed from the past till now. Intelligent systems explainability has become a necessity after the worldwide adoption of such systems, especially in the health domain to explain and justify decisions made by intelligent systems. Rule-based techniques are among the best in terms of explainability. However, there are several challenges associated with remote health monitoring systems in general and rule-based techniques, specifically. In this research, an adaptive platform based on Complex Event Processing (CEP) has been proposed for user behavior modeling to provide adaptive and personalized remote health monitoring. This system can manage a massive amount of data in real-time utilizing the CEP engine. It can also avoid human errors in setting rules thresholds by extracting thresholds from previous data using JRip rule-based classifier. Moreover, a feature selection method is proposed to decrease the high number of features while maintaining accuracy. Additionally, a rule adaption method has been proposed to cope with changes over time. Additionally, a personalized rule adaption method is proposed to address the need for responsiveness of the system to the special requirements of each user. The experimental results on both hospital and activity data sets showed that the proposed rule adaption method improves the accuracy by about 15 % compared to non-adaptive systems. Additionally, the proposed personalized rule adaption method has an accuracy improvement of about 3 % to 6 % on both mentioned datasets.},
  archive      = {J_ARTMED},
  author       = {Mohammad Mehdi Naseri and Shima Tabibian and Elaheh Homayounvala},
  doi          = {10.1016/j.artmed.2022.102421},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102421},
  shortjournal = {Artif. Intell. Med.},
  title        = {Adaptive and personalized user behavior modeling in complex event processing platforms for remote health monitoring systems},
  volume       = {134},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Breast cancer detection and classification in mammogram
using a three-stage deep learning framework based on PAA algorithm.
<em>ARTMED</em>, <em>134</em>, 102419. (<a
href="https://doi.org/10.1016/j.artmed.2022.102419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep learning has been used to develop an automatic breast cancer detection and classification tool to assist doctors. In this paper, we proposed a three-stage deep learning framework based on an anchor-free object detection algorithm , named the Probabilistic Anchor Assignment (PAA) to improve diagnosis performance by automatically detecting breast lesions (i.e., mass and calcification) and further classifying mammograms into benign or malignant. Firstly, a single-stage PAA-based detector roundly finds suspicious breast lesions in mammogram . Secondly, we designed a two-branch ROI detector to further classify and regress these lesions that aim to reduce the number of false positives . Besides, in this stage, we introduced a threshold-adaptive post-processing algorithm with dense breast information. Finally, the benign or malignant lesions would be classified by an ROI classifier which combines local-ROI features and global-image features. In addition, considering the strong correlation between the task of detection head of PAA and the task of whole mammogram classification, we added an image classifier that utilizes the same global-image features to perform image classification . The image classifier and the ROI classifier jointly guide to enhance the feature extraction ability and further improve the performance of classification. We integrated three public datasets of mammograms (CBIS-DDSM, INbreast, MIAS) to train and test our model and compared our framework with recent state-of-the-art methods. The results show that our proposed method can improve the diagnostic efficiency of radiologists by automatically detecting and classifying breast lesions and classifying benign and malignant mammograms.},
  archive      = {J_ARTMED},
  author       = {Jiale Jiang and Junchuan Peng and Chuting Hu and Wenjing Jian and Xianming Wang and Weixiang Liu},
  doi          = {10.1016/j.artmed.2022.102419},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102419},
  shortjournal = {Artif. Intell. Med.},
  title        = {Breast cancer detection and classification in mammogram using a three-stage deep learning framework based on PAA algorithm},
  volume       = {134},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep variational graph autoencoders for novel host-directed
therapy options against COVID-19. <em>ARTMED</em>, <em>134</em>, 102418.
(<a href="https://doi.org/10.1016/j.artmed.2022.102418">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic has been keeping asking urgent questions with respect to therapeutic options. Existing drugs that can be repurposed promise rapid implementation in practice because of their prior approval. Conceivably, there is still room for substantial improvement, because most advanced artificial intelligence techniques for screening drug repositories have not been exploited so far. We construct a comprehensive network by combining year-long curated drug–protein/protein–protein interaction data on the one hand, and most recent SARS-CoV-2 protein interaction data on the other hand. We learn the structure of the resulting encompassing molecular interaction network and predict missing links using variational graph autoencoders (VGAEs), as a most advanced deep learning technique that has not been explored so far. We focus on hitherto unknown links between drugs and human proteins that play key roles in the replication cycle of SARS-CoV-2. Thereby, we establish novel host-directed therapy (HDT) options whose utmost plausibility is confirmed by realistic simulations. As a consequence, many of the predicted links are likely to be crucial for the virus to thrive on the one hand, and can be targeted with existing drugs on the other hand.},
  archive      = {J_ARTMED},
  author       = {Sumanta Ray and Snehalika Lall and Anirban Mukhopadhyay and Sanghamitra Bandyopadhyay and Alexander Schönhuth},
  doi          = {10.1016/j.artmed.2022.102418},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102418},
  shortjournal = {Artif. Intell. Med.},
  title        = {Deep variational graph autoencoders for novel host-directed therapy options against COVID-19},
  volume       = {134},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semantic coherence markers: The contribution of perplexity
metrics. <em>ARTMED</em>, <em>134</em>, 102393. (<a
href="https://doi.org/10.1016/j.artmed.2022.102393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Devising automatic tools to assist specialists in the early detection of mental disturbances and psychotic disorders is to date a challenging scientific problem and a practically relevant activity. In this work we explore how language models (that are probability distributions over text sequences) can be employed to analyze language and discriminate between mentally impaired and healthy subjects. We have preliminarily explored whether perplexity can be considered a reliable metrics to characterize an individual’s language. Perplexity was originally conceived as an information-theoretic measure to assess how much a given language model is suited to predict a text sequence or, equivalently, how much a word sequence fits into a specific language model. We carried out an extensive experimentation with healthy subjects, and employed language models as diverse as N-grams – from 2-grams to 5-grams – and GPT-2, a transformer-based language model. Our experiments show that irrespective of the complexity of the employed language model, perplexity scores are stable and sufficiently consistent for analyzing the language of individual subjects, and at the same time sensitive enough to capture differences due to linguistic registers adopted by the same speaker, e.g., in interviews and political rallies. A second array of experiments was designed to investigate whether perplexity scores may be used to discriminate between the transcripts of healthy subjects and subjects suffering from Alzheimer Disease (AD). Our best performing models achieved full accuracy and F-score (1.00 in both precision/specificity and recall/sensitivity) in categorizing subjects from both the AD class, and control subjects. These results suggest that perplexity can be a valuable analytical metrics with potential application to supporting early diagnosis of symptoms of mental disorders.},
  archive      = {J_ARTMED},
  author       = {Davide Colla and Matteo Delsanto and Marco Agosto and Benedetto Vitiello and Daniele P. Radicioni},
  doi          = {10.1016/j.artmed.2022.102393},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102393},
  shortjournal = {Artif. Intell. Med.},
  title        = {Semantic coherence markers: The contribution of perplexity metrics},
  volume       = {134},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). IDT: An incremental deep tree framework for biological image
classification. <em>ARTMED</em>, <em>134</em>, 102392. (<a
href="https://doi.org/10.1016/j.artmed.2022.102392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, breast and cervical cancers are respectively the first and fourth most common causes of cancer death in females. It is believed that, automated systems based on artificial intelligence would allow the early diagnostic which increases significantly the chances of proper treatment and survival. Although Convolutional Neural Networks (CNNs) have achieved human-level performance in object classification tasks , the regular growing of the amount of medical data and the continuous increase of the number of classes make them difficult to learn new tasks without being re-trained from scratch. Nevertheless, fine tuning and transfer learning in deep models are techniques that lead to the well-known catastrophic forgetting problem. In this paper, an Incremental Deep Tree (IDT) framework for biological image classification is proposed to address the catastrophic forgetting of CNNs allowing them to learn new classes while maintaining acceptable accuracies on the previously learnt ones. To evaluate the performance of our approach, the IDT framework is compared against with three popular incremental methods, namely iCaRL, LwF and SupportNet. The experimental results on MNIST dataset achieved 87 % of accuracy and the obtained values on the BreakHis, the LBC and the SIPaKMeD datasets are promising with 92 %, 98 % and 93 % respectively.},
  archive      = {J_ARTMED},
  author       = {Wafa Mousser and Salima Ouadfel and Abdelmalik Taleb-Ahmed and Ilham Kitouni},
  doi          = {10.1016/j.artmed.2022.102392},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {102392},
  shortjournal = {Artif. Intell. Med.},
  title        = {IDT: An incremental deep tree framework for biological image classification},
  volume       = {134},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A manifesto on explainability for artificial intelligence in
medicine. <em>ARTMED</em>, <em>133</em>, 102423. (<a
href="https://doi.org/10.1016/j.artmed.2022.102423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid increase of interest in, and use of, artificial intelligence (AI) in computer applications has raised a parallel concern about its ability (or lack thereof) to provide understandable, or explainable , output to users. This concern is especially legitimate in biomedical contexts, where patient safety is of paramount importance . This position paper brings together seven researchers working in the field with different roles and perspectives, to explore in depth the concept of explainable AI , or XAI , offering a functional definition and conceptual framework or model that can be used when considering XAI. This is followed by a series of desiderata for attaining explainability in AI, each of which touches upon a key domain in biomedicine .},
  archive      = {J_ARTMED},
  author       = {Carlo Combi and Beatrice Amico and Riccardo Bellazzi and Andreas Holzinger and Jason H. Moore and Marinka Zitnik and John H. Holmes},
  doi          = {10.1016/j.artmed.2022.102423},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102423},
  shortjournal = {Artif. Intell. Med.},
  title        = {A manifesto on explainability for artificial intelligence in medicine},
  volume       = {133},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CycleGAN for virtual stain transfer: Is seeing really
believing? <em>ARTMED</em>, <em>133</em>, 102420. (<a
href="https://doi.org/10.1016/j.artmed.2022.102420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital Pathology is an area prone to high variation due to multiple factors which can strongly affect diagnostic quality and visual appearance of the Whole-Slide-Images (WSIs). The state-of-the art methods to deal with such variation tend to address this through style-transfer inspired approaches. Usually, these solutions directly apply successful approaches from the literature, potentially with some task-related modifications. The majority of the obtained results are visually convincing, however, this paper shows that this is not a guarantee that such images can be directly used for either medical diagnosis or reducing domain shift.This article shows that slight modification in a stain transfer architecture, such as a choice of normalisation layer, while resulting in a variety of visually appealing results, surprisingly greatly effects the ability of a stain transfer model to reduce domain shift. By extensive qualitative and quantitative evaluations , we confirm that translations resulting from different stain transfer architectures are distinct from each other and from the real samples. Therefore conclusions made by visual inspection or pretrained model evaluation might be misleading.},
  archive      = {J_ARTMED},
  author       = {Jelica Vasiljević and Zeeshan Nisar and Friedrich Feuerhake and Cédric Wemmert and Thomas Lampert},
  doi          = {10.1016/j.artmed.2022.102420},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102420},
  shortjournal = {Artif. Intell. Med.},
  title        = {CycleGAN for virtual stain transfer: Is seeing really believing?},
  volume       = {133},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cardiac anomaly detection considering an additive noise and
convolutional distortion model of heart sound recordings.
<em>ARTMED</em>, <em>133</em>, 102417. (<a
href="https://doi.org/10.1016/j.artmed.2022.102417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiac auscultation is an essential point-of-care method used for the early diagnosis of heart diseases. Automatic analysis of heart sounds for abnormality detection is faced with the challenges of additive noise and sensor-dependent degradation. This paper aims to develop methods to address the cardiac abnormality detection problem when both of these components are present in the cardiac auscultation sound. We first mathematically analyze the effect of additive noise and convolutional distortion on short-term mel-filterbank energy-based features and a Convolutional Neural Network (CNN) layer. Based on the analysis, we propose a combination of linear and logarithmic spectrogram-image features. These 2D features are provided as input to a residual CNN network (ResNet) for heart sound abnormality detection. Experimental validation is performed first on an open-access, multiclass heart sound dataset where we analyzed the effect of additive noise by mixing lung sound noise with the recordings. In noisy conditions, the proposed method outperforms one of the best-performing methods in the literature achieving an Macc (mean of sensitivity and specificity) of 89.55% and an average F-1 score of 82.96%, respectively, when averaged over all noise levels . Next, we perform heart sound abnormality detection (binary classification) experiments on the 2016 Physionet/CinC Challenge dataset that involves noisy recordings obtained from multiple stethoscope sensors. The proposed method achieves significantly improved results compared to the conventional approaches on this dataset, in the presence of both additive noise and channel distortion, with an area under the ROC (receiver operating characteristics) curve (AUC) of 91.36%, F-1 score of 84.09%, and Macc of 85.08%. We also show that the proposed method shows the best mean accuracy across different source domains, including stethoscope and noise variability, demonstrating its effectiveness in different recording conditions. The proposed combination of linear and logarithmic features along with the ResNet classifier effectively minimizes the impact of background noise and sensor variability for classifying phonocardiogram (PCG) signals. The method thus paves the way toward developing computer-aided cardiac auscultation systems in noisy environments using low-cost stethoscopes.},
  archive      = {J_ARTMED},
  author       = {Farhat Binte Azam and Md. Istiaq Ansari and Shoyad Ibn Sabur Khan Nuhash and Ian McLane and Taufiq Hasan},
  doi          = {10.1016/j.artmed.2022.102417},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102417},
  shortjournal = {Artif. Intell. Med.},
  title        = {Cardiac anomaly detection considering an additive noise and convolutional distortion model of heart sound recordings},
  volume       = {133},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). XPM: Enhancing exogenous data visibility. <em>ARTMED</em>,
<em>133</em>, 102409. (<a
href="https://doi.org/10.1016/j.artmed.2022.102409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Process mining is a well-established discipline with applications in many industry sectors, including healthcare. To date, few publications have considered the context in which processes execute. Little consideration has been given as to how contextual data (exogenous data) can be practically included for process mining analysis, beyond including case or event attributes in a typical event log. We show that the combination of process data (endogenous) and exogenous data can generate insights not possible with standard process mining techniques . Our contributions are a framework for process mining with exogenous data and new analyses, where exogenous data and process behaviour are linked to process outcomes. Our new analyses visualise exogenous data, highlighting the trends and variations, to show where overlaps or distinctions exist between outcomes. We applied our analyses in a healthcare setting and show that clinicians could extract insights about differences in patients’ vital signs (exogenous data) relevant to clinical outcomes. We present two evaluations, using a publicly available data set, MIMIC-III, to demonstrate the applicability of our analysis. These evaluations show that process mining can integrate large amounts of physiologic data and interventions, with resulting discrimination and conversion to clinically interpretable information.},
  archive      = {J_ARTMED},
  author       = {Adam Banham and Sander J.J. Leemans and Moe T. Wynn and Robert Andrews and Kevin B. Laupland and Lucy Shinners},
  doi          = {10.1016/j.artmed.2022.102409},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102409},
  shortjournal = {Artif. Intell. Med.},
  title        = {XPM: Enhancing exogenous data visibility},
  volume       = {133},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Temporal deep learning framework for retinopathy prediction
in patients with type 1 diabetes. <em>ARTMED</em>, <em>133</em>, 102408.
(<a href="https://doi.org/10.1016/j.artmed.2022.102408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The adoption of electronic health records in hospitals has ensured the availability of large datasets that can be used to predict medical complications. The trajectories of patients in real-world settings are highly variable, making longitudinal data modeling challenging. In recent years, significant progress has been made in the study of deep learning models applied to time series; however, the application of these models to irregular medical time series (IMTS) remains limited. To address this issue, we developed a generic deep-learning-based framework for modeling IMTS that facilitates the comparative studies of sequential neural networks (transformers and long short-term memory) and irregular time representation techniques. A validation study to predict retinopathy complications was conducted on 1207 patients with type 1 diabetes in a French database using their historical glycosylated hemoglobin measurements, without any data aggregation or imputation. The transformer-based model combined with the soft one-hot representation of time gaps achieved the highest score: an area under the receiver operating characteristic curve of 88.65%, specificity of 85.56%, sensitivity of 83.33% and an improvement of 11.7% over the same architecture without time information. This is the first attempt to predict retinopathy complications in patients with type 1 diabetes using deep learning and longitudinal data collected from patient visits. This study highlighted the significance of modeling time gaps between medical records to improve prediction performance and the utility of a generic framework for conducting extensive comparative studies.},
  archive      = {J_ARTMED},
  author       = {Sara Rabhi and Frédéric Blanchard and Alpha Mamadou Diallo and Djamal Zeghlache and Céline Lukas and Aurélie Berot and Brigitte Delemer and Sara Barraud},
  doi          = {10.1016/j.artmed.2022.102408},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102408},
  shortjournal = {Artif. Intell. Med.},
  title        = {Temporal deep learning framework for retinopathy prediction in patients with type 1 diabetes},
  volume       = {133},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Weakly supervised learning using attention gates for colon
cancer histopathological image segmentation. <em>ARTMED</em>,
<em>133</em>, 102407. (<a
href="https://doi.org/10.1016/j.artmed.2022.102407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Artificial Intelligence namely Deep Learning methods have revolutionized a wide range of domains and applications. Besides, Digital Pathology has so far played a major role in the diagnosis and the prognosis of tumors. However, the characteristics of the Whole Slide Images namely the gigapixel size, high resolution and the shortage of richly labeled samples have hindered the efficiency of classical Machine Learning methods. That goes without saying that traditional methods are poor in generalization to different tasks and data contents. Regarding the success of Deep learning when dealing with Large Scale applications, we have resorted to the use of such models for histopathological image segmentation tasks . First, we review and compare the classical UNet and Att-UNet models for colon cancer WSI segmentation in a sparsely annotated data scenario. Then, we introduce novel enhanced models of the Att-UNet where different schemes are proposed for the skip connections and spatial attention gates positions in the network. In fact, spatial attention gates assist the training process and enable the model to avoid irrelevant feature learning . Alternating the presence of such modules namely in our Alter-AttUNet model adds robustness and ensures better image segmentation results. In order to cope with the lack of richly annotated data in our AiCOLO colon cancer dataset, we suggest the use of a multi-step training strategy that also deals with the WSI sparse annotations and unbalanced class issues. All proposed methods outperform state-of-the-art approaches but Alter-AttUNet generates the best compromise between accurate results and light network. The model achieves 95.88% accuracy with our sparse AiCOLO colon cancer datasets. Finally, to evaluate and validate our proposed architectures we resort to publicly available WSI data : the NCT-CRC-HE-100K , the CRC-5000 and the Warwick colon cancer histopathological dataset. Respective accuracies of 99.65%, 99.73% and 79.03% were reached. A comparison with state-of-art approaches is established to view and compare the key solutions for histopathological image segmentation.},
  archive      = {J_ARTMED},
  author       = {A. Ben Hamida and M. Devanne and J. Weber and C. Truntzer and V. Derangère and F. Ghiringhelli and G. Forestier and C. Wemmert},
  doi          = {10.1016/j.artmed.2022.102407},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102407},
  shortjournal = {Artif. Intell. Med.},
  title        = {Weakly supervised learning using attention gates for colon cancer histopathological image segmentation},
  volume       = {133},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evolutionary optimisation of antibiotic dosing regimens for
bacteria with different levels of resistance. <em>ARTMED</em>,
<em>133</em>, 102405. (<a
href="https://doi.org/10.1016/j.artmed.2022.102405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Antimicrobial resistance is one of the biggest threats to global health, food security, and development. Antibiotic overuse and misuse are the main drivers for the emergence of resistance. It is crucial to optimise the use of existing antibiotics in order to improve medical outcomes, decrease toxicity and reduce the emergence of resistance. We formulate the design of antibiotic dosing regimens as an optimisation problem, and use an evolutionary algorithm suited to continuous optimisation (differential evolution) to solve it. Regimens are represented as vectors of real numbers encoding daily doses, which can vary across the treatment duration. A stochastic mathematical model of bacterial infections with tuneable resistance levels is used to evaluate the effectiveness of evolved regimens. The objective is to minimise the treatment failure rate, subject to a constraint on the maximum total antibiotic used. We consider simulations with different levels of bacterial resistance, two ways of administering the drug (orally and intravenously), as well as coinfections with two strains of bacteria. Our approach produced effective dosing regimens, with an average improvement in lowering the failure rate 30%, when compared with standard fixed-daily-dose regimens with the same total amount of antibiotic.},
  archive      = {J_ARTMED},
  author       = {Mila Goranova and Gabriela Ochoa and Patrick Maier and Andrew Hoyle},
  doi          = {10.1016/j.artmed.2022.102405},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {102405},
  shortjournal = {Artif. Intell. Med.},
  title        = {Evolutionary optimisation of antibiotic dosing regimens for bacteria with different levels of resistance},
  volume       = {133},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Septic shock prediction and knowledge discovery through
temporal pattern mining. <em>ARTMED</em>, <em>132</em>, 102406. (<a
href="https://doi.org/10.1016/j.artmed.2022.102406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sepsis is the body&#39;s adverse response to infection which can lead to septic shock and eventually death if not treated in a timely manner. Analyzing patterns in sepsis patients&#39; health status over time can help predict septic shock before its onset allowing healthcare providers to be more proactive. Temporal pattern mining methods can be used to identify trends in a patient&#39;s health status over time. If these methods return too many patterns, however, this can hinder knowledge discovery and practical implementation at the bedside in acute care settings. We propose a framework to find a small number of relevant temporal patterns in electronic health records for the early prediction of septic shock. Our framework consists of a temporal pattern mining method and three pattern selection techniques based on non-contrasted group support (PST1), contrasted group support (PST2), and model predictive power (PST3, PST4). We find that model-based feature selection approaches PST3 and PST4 yield the best prediction performance among these techniques. However, PST2 identifies more multi-state patterns with abnormal health states, which can give healthcare providers indicators of patient deterioration towards septic shock. Hence, from a knowledge discovery perspective, it may be worthwhile to sacrifice a small amount of prediction power for actionable patient health information through the implementation of PST2.},
  archive      = {J_ARTMED},
  author       = {Joseph K. Agor and Ruoting Li and Osman Y. Özaltın},
  doi          = {10.1016/j.artmed.2022.102406},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102406},
  shortjournal = {Artif. Intell. Med.},
  title        = {Septic shock prediction and knowledge discovery through temporal pattern mining},
  volume       = {132},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Quality assessment of machine learning models for diagnostic
imaging in orthopaedics: A systematic review. <em>ARTMED</em>,
<em>132</em>, 102396. (<a
href="https://doi.org/10.1016/j.artmed.2022.102396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning (ML) models are emerging at a rapid pace in orthopaedic imaging due to their ability to facilitate timely diagnostic and treatment decision making. However, despite a considerable increase in model development and ML-related publications, there has been little evaluation regarding the quality of these studies. In order to successfully move forward with the implementation of ML models for diagnostic imaging in orthopaedics , it is imperative that we ensure models are held at a high standard and provide applicable, reliable and accurate results. Multiple reporting guidelines have been developed to help authors and reviewers of ML models, such as the Checklist for AI in Medical Imaging (CLAIM) and the Quality Assessment of Diagnostic Accuracy Studies (QUADAS-2) tool. Previous investigations of prognostic orthopaedic ML models have reported concerns with regard to the rate of transparent reporting. Therefore, an assessment of whether ML models for diagnostic imaging in orthopaedics adequately and clearly report essential facets of their model development is warranted. To evaluate (1) the completeness of the CLAIM checklist and (2) the risk of bias according to the QUADAS-2 tool for ML-based orthopaedic diagnostic imaging models. This study sought to identify ML details that researchers commonly fail to report and to provide recommendations to improve reporting standards for diagnostic imaging ML models. A systematic review was performed to identify ML-based diagnostic imaging models in orthopaedic surgery. Articles published within the last 5 years were included. Two reviewers independently extracted data using the CLAIM checklist and QUADAS-2 tool, and discrepancies were resolved by discussion with at least two additional reviewers. After screening 7507 articles, 91 met the study criteria. The mean completeness of CLAIM items was 63 % (SD ± 28 %). Among the worst reported CLAIM items were item 28 (metrics of model performance), item 13 (the handling of missing data) and item 9 (data preprocessing steps), with only 2 % (2/91), 8 % (7/91) and 13 % (12/91) of studies correctly reporting these items, respectively. The QUADAS-2 tool revealed that the patient selection domain was at the highest risk of bias: 18 % (16/91) of studies were at high risk of bias and 32 % (29/91) had an unknown risk of bias. This review demonstrates that the reporting of relevant information, such as handling missing data and data preprocessing steps, by diagnostic ML studies for orthopaedic imaging studies is limited. Additionally, a substantial number of works were at high risk of bias. Future studies describing ML-based models for diagnostic imaging should adhere to acknowledged methodological standards to maximize the quality and applicability of their models.},
  archive      = {J_ARTMED},
  author       = {Amanda Lans and Robertus J.B. Pierik and John R. Bales and Mitchell S. Fourman and David Shin and Laura N. Kanbier and Jack Rifkin and William H. DiGiovanni and Rohan R. Chopra and Rana Moeinzad and Jorrit-Jan Verlaan and Joseph H. Schwab},
  doi          = {10.1016/j.artmed.2022.102396},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102396},
  shortjournal = {Artif. Intell. Med.},
  title        = {Quality assessment of machine learning models for diagnostic imaging in orthopaedics: A systematic review},
  volume       = {132},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Suicidal behaviour prediction models using machine learning
techniques: A systematic review. <em>ARTMED</em>, <em>132</em>, 102395.
(<a href="https://doi.org/10.1016/j.artmed.2022.102395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early detection and prediction of suicidal behaviour are key factors in suicide control. In conjunction with recent advances in the field of artificial intelligence, there is increasing research into how machine learning can assist in the detection, prediction and treatment of suicidal behaviour. Therefore, this study aims to provide a comprehensive review of the literature exploring machine learning techniques in the study of suicidal behaviour prediction. A search of four databases was conducted: Web of Science, PubMed , Dimensions, and Scopus for research papers dated between January 2016 and September 2021. The search keywords are ‘data mining’, ‘machine learning’ in combination with ‘suicidal behaviour’, ‘suicide’, ‘suicide attempt’, ‘suicidal ideation’, ‘suicide plan’ and ‘self-harm’. The studies that used machine learning techniques were synthesized according to the countries of the articles, sample description, sample size , classification tasks, number of features used to develop the models, types of machine learning techniques, and evaluation of performance metrics. Thirty-five empirical articles met the criteria to be included in the current review. We provide a general overview of machine learning techniques, examine the feature categories, describe methodological challenges, and suggest areas for improvement and research directions. Ensemble prediction models have been shown to be more accurate and useful than single prediction models. Machine learning has great potential for improving estimates of future suicidal behaviour and monitoring changes in risk over time. Further research can address important challenges and potential opportunities that may contribute to significant advances in suicide prediction.},
  archive      = {J_ARTMED},
  author       = {Noratikah Nordin and Zurinahni Zainol and Mohd Halim Mohd Noor and Lai Fong Chan},
  doi          = {10.1016/j.artmed.2022.102395},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102395},
  shortjournal = {Artif. Intell. Med.},
  title        = {Suicidal behaviour prediction models using machine learning techniques: A systematic review},
  volume       = {132},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Defining factors in hospital admissions during COVID-19
using LSTM-FCA explainable model. <em>ARTMED</em>, <em>132</em>, 102394.
(<a href="https://doi.org/10.1016/j.artmed.2022.102394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outbreaks of the COVID-19 pandemic caused by the SARS-CoV-2 infection that started in Wuhan, China, have quickly spread worldwide. The current situation has contributed to a dynamic rate of hospital admissions. Global efforts by Artificial Intelligence (AI) and Machine Learning (ML) communities to develop solutions to assist COVID-19-related research have escalated ever since. However, despite overwhelming efforts from the AI and ML community, many machine learning-based AI systems have been designed as black boxes . This paper proposes a model that utilizes Formal Concept Analysis (FCA) to explain a machine learning technique called Long–short Term Memory (LSTM) on a dataset of hospital admissions due to COVID-19 in the United Kingdom. This paper intends to increase the transparency of decision-making in the era of ML by using the proposed LSTM-FCA explainable model. Both LSTM and FCA are able to evaluate the data and explain the model to make the results more understandable and interpretable. The results and discussions are helpful and may lead to new research to optimize the use of ML in various real-world applications and to contain the disease.},
  archive      = {J_ARTMED},
  author       = {Nurul Izrin Md Saleh and Hadhrami Ab Ghani and Zairul Jilani},
  doi          = {10.1016/j.artmed.2022.102394},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102394},
  shortjournal = {Artif. Intell. Med.},
  title        = {Defining factors in hospital admissions during COVID-19 using LSTM-FCA explainable model},
  volume       = {132},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mathematical modeling and AI based decision making for
COVID-19 suspects backed by novel distance and similarity measures on
plithogenic hypersoft sets. <em>ARTMED</em>, <em>132</em>, 102390. (<a
href="https://doi.org/10.1016/j.artmed.2022.102390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It goes without saying that coronavirus (COVID-19) is an infectious disease and many countries are coping with its different variants. Owing to the limited medical facilities, vaccine and medical experts, need of the hour is to intelligently tackle its spread by making artificial intelligence (AI) based smart decisions for COVID-19 suspects who develop different symptoms and they are kept under observation and monitored to see the severity of the symptoms. The target of this study is to analyze COVID-19 suspects data and detect whether a suspect is a COVID-19 patient or not, and if yes, then to what extent, so that a suitable decision can be made. The decision can be categorized such that an infected person can be isolated or quarantined at home or at a facilitation center or the person can be sent to the hospital for the treatment. This target is achieved by designing a mathematical model of COVID-19 suspects in the form of a multi-criteria decision making (MCDM) model and a novel AI based technique is devised and implemented with the help of newly developed plithogenic distance and similarity measures in fuzzy environment. All findings are depicted graphically for a clear understanding and to provide an insight of the necessity and effectiveness of the proposed method. The concept and results of the proposed technique make it suitable for implementation in machine learning, deep learning , pattern recognition etc.},
  archive      = {J_ARTMED},
  author       = {Muhammad Rayees Ahmad and Usman Afzal},
  doi          = {10.1016/j.artmed.2022.102390},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102390},
  shortjournal = {Artif. Intell. Med.},
  title        = {Mathematical modeling and AI based decision making for COVID-19 suspects backed by novel distance and similarity measures on plithogenic hypersoft sets},
  volume       = {132},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A deep LSTM autoencoder-based framework for predictive
maintenance of a proton radiotherapy delivery system. <em>ARTMED</em>,
<em>132</em>, 102387. (<a
href="https://doi.org/10.1016/j.artmed.2022.102387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unscheduled machine downtime can cause treatment interruptions and adversely impact patient treatment outcomes. Conventional Quality Assurance (QA) programs of a proton Pencil Beam Scanning (PBS) system ensure its operational performance by keeping the beam parameters within clinical tolerances but often do not reveal the underlying issues of the device prior to a machine malfunction event. In this study, we propose a Predictive Maintenance (PdM) approach that leverages an advanced analytical tool built on a deep neural network to detect treatment delivery machine issues early. Beam delivery log file data from daily QA performed at the Burr Proton Center of Massachusetts General Hospital were collected. A novel PdM framework consisting of long short-term memory-based autoencoder (LSTM-AE) modeling of the proton PBS delivery system and a Mahalanobis distance-based error metric evaluation was constructed to detect rare anomalous machine events. These included QA beam pauses, clinical operational issues, and treatment interruptions. The model was trained in an unsupervised fashion on the QA data of normal sessions so that the model learned characteristics of normal machine operation. The anomaly is quantified as the multivariate deviation between the model predicted data and the measured data of the day using Mahalanobis distance (M-Score). Two-layer and three-layer Long short-term memory-based stacked autoencoder (LSTM-SAE) models were optimized for exploring model performance improvement. Model validation was performed with two clinical datasets and was analyzed using the area under the precision-recall curve (AUPRC) and the area under the receiver operating characteristic (AUROC). LSTM-SAE models showed strong performance in predicting QA beam pauses for both clinical validation datasets. Despite severe skew in the dataset, the model achieved AUPRC of 0.60 and 0.82 and AUROC of 0.75 and 0.92 in the respective 2018 and 2020 datasets. Moreover, these amount to 2.8-fold and 10.7-fold enhancement compared to the respective baseline event rates. In addition, in terms of treatment interruption events, model prediction enabled 3.88-fold and 51.2-fold detection improvement, while the detection improvement for clinical operational issues was 1.04-fold and 1.37-fold, respectively, in the 2018 and 2020 datasets. Our novel deep LSTM-SAE-based framework allows for highly discriminative prediction of anomalous machine events and demonstrates great promise for enabling PdM for proton PBS beam delivery.},
  archive      = {J_ARTMED},
  author       = {Tai Dou and Benjamin Clasie and Nicolas Depauw and Tim Shen and Robert Brett and Hsiao-Ming Lu and Jacob B. Flanz and Kyung-Wook Jee},
  doi          = {10.1016/j.artmed.2022.102387},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102387},
  shortjournal = {Artif. Intell. Med.},
  title        = {A deep LSTM autoencoder-based framework for predictive maintenance of a proton radiotherapy delivery system},
  volume       = {132},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Domain generalization in deep learning based mass detection
in mammography: A large-scale multi-center study. <em>ARTMED</em>,
<em>132</em>, 102386. (<a
href="https://doi.org/10.1016/j.artmed.2022.102386">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer-aided detection systems based on deep learning have shown great potential in breast cancer detection. However, the lack of domain generalization of artificial neural networks is an important obstacle to their deployment in changing clinical environments. In this study, we explored the domain generalization of deep learning methods for mass detection in digital mammography and analyzed in-depth the sources of domain shift in a large-scale multi-center setting. To this end, we compared the performance of eight state-of-the-art detection methods, including Transformer based models, trained in a single domain and tested in five unseen domains. Moreover, a single-source mass detection training pipeline was designed to improve the domain generalization without requiring images from the new domain. The results show that our workflow generalized better than state-of-the-art transfer learning based approaches in four out of five domains while reducing the domain shift caused by the different acquisition protocols and scanner manufacturers. Subsequently, an extensive analysis was performed to identify the covariate shifts with the greatest effects on detection performance, such as those due to differences in patient age, breast density, mass size, and mass malignancy. Ultimately, this comprehensive study provides key insights and best practices for future research on domain generalization in deep learning based breast cancer detection.},
  archive      = {J_ARTMED},
  author       = {Lidia Garrucho and Kaisar Kushibar and Socayna Jouide and Oliver Diaz and Laura Igual and Karim Lekadir},
  doi          = {10.1016/j.artmed.2022.102386},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102386},
  shortjournal = {Artif. Intell. Med.},
  title        = {Domain generalization in deep learning based mass detection in mammography: A large-scale multi-center study},
  volume       = {132},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A deep learning pipeline for the automated segmentation of
posterior limb of internal capsule in preterm neonates. <em>ARTMED</em>,
<em>132</em>, 102384. (<a
href="https://doi.org/10.1016/j.artmed.2022.102384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segmentation of specific brain tissue from MRI volumes is of great significance for brain disease diagnosis, progression assessment, and monitoring of neurological conditions. Manual segmentation is time-consuming, laborious, and subjective, which significantly amplifies the need for automated processes. Over the last decades, the active development in the field of deep learning , especially convolutional neural networks (CNNs), and the associated performance improvements have increased the demand for the application of CNN-based methods to provide consistent measurements and quantitative analyses . In this paper, we present an efficient deep learning approach for the segmentation of brain tissue. More specifically, we address the problem of segmentation of the posterior limb of the internal capsule (PLIC) in preterm neonates. To this end, we propose a CNN-based pipeline comprised of slice-selection modules and a multi-view segmentation model, which exploits the 3D information contained in the MRI volumes to improve segmentation performance. One special feature of the proposed method is its ability to identify one desired slice out of the whole image volume, which is relevant for pediatricians in terms of prognosis. To increase computational efficiency, we apply a strategy that automatically reduces the information contained in the MRI volumes to its relevant parts. Finally, we conduct an expert rating alongside standard evaluation metrics, such as dice score, to evaluate the performance of the proposed framework. We demonstrate the benefit of the multi-view technique by comparing it with its single-view counterparts, which reveals that the proposed method strikes a good balance between exploiting the available image information and reducing the required computing power compared to 3D segmentation networks. Standard evaluation metrics as, well as expert-based assessment, confirm the good performance of the proposed framework, with the latter being more relevant in terms of clinical applicability. We demonstrate that the proposed deep learning pipeline can compete with the experts in terms of accuracy. To prove the generalisability of the proposed method, we additionally assess our deep learning pipeline to data from the Developing Human Connectome Project (dHCP).},
  archive      = {J_ARTMED},
  author       = {Nadja Gruber and Malik Galijasevic and Milovan Regodic and Astrid Ellen Grams and Christian Siedentopf and Ruth Steiger and Marlene Hammerl and Markus Haltmeier and Elke Ruth Gizewski and Tanja Janjic},
  doi          = {10.1016/j.artmed.2022.102384},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102384},
  shortjournal = {Artif. Intell. Med.},
  title        = {A deep learning pipeline for the automated segmentation of posterior limb of internal capsule in preterm neonates},
  volume       = {132},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CheXGAT: A disease correlation-aware network for thorax
disease diagnosis from chest x-ray images. <em>ARTMED</em>,
<em>132</em>, 102382. (<a
href="https://doi.org/10.1016/j.artmed.2022.102382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chest X-ray (CXR) imaging is one of the most common diagnostic imaging techniques in clinical diagnosis and is usually used for radiological examinations to screen for thorax diseases . In this paper, we propose a novel computer-aided diagnosis (CAD) system based on a hybrid deep learning model composed of a convolutional neural network (CNN) and a graph neural network (GNN). The system is intended to explore implicit correlations between thorax diseases to aid in the multilabel chest X-ray image classification task, which we term ‶ CheXGAT ‶. Specifically, the proposed CheXGAT framework comprises two main modules: an image representation learning (IRL) module and a graph representation learning (GRL) module. We employ the IRL module to learn high-level visual representation features from the CXR image. From the GRL module, the self-attention mechanism aggregates neighborhood features from the graphic structure to enhance the implicit correlation between thorax diseases. We adopted a data-driven method to create a disease correlation matrix that works on the message passing and aggregation process for the nodes in the GRL module. After end-to-end training, the GRL module enhances the correlation between thorax diseases to improve diagnosis performance. We performed experiments on the NIH Chest X-ray14 dataset, which contains 112,120 frontal-view radiographs; each image has multiple thorax disease labels. In the experimental results, the average AUC score of our proposed CheXGAT model reached 0.8266, and the AUC scores of Emphysema and Hernia reached 0.9447 and 0.9313, respectively. In addition, we visualized explanations via a gradient-based localization method in our proposed CheXGAT framework. Compared with previous studies, the experimental results show the competitive performance of our framework. Specifically, we propose a CAD system that uses a hybrid model to help radiologists identify CXR images from 14 chest diseases for clinical diagnosis.},
  archive      = {J_ARTMED},
  author       = {Yan-Wei Lee and Sheng-Kai Huang and Ruey-Feng Chang},
  doi          = {10.1016/j.artmed.2022.102382},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102382},
  shortjournal = {Artif. Intell. Med.},
  title        = {CheXGAT: A disease correlation-aware network for thorax disease diagnosis from chest X-ray images},
  volume       = {132},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine learning and the electrocardiogram over two decades:
Time series and meta-analysis of the algorithms, evaluation metrics and
applications. <em>ARTMED</em>, <em>132</em>, 102381. (<a
href="https://doi.org/10.1016/j.artmed.2022.102381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of artificial intelligence to interpret the electrocardiogram (ECG) has predominantly included the use of knowledge engineered rule-based algorithms which have become widely used today in clinical practice. However, over recent decades, there has been a steady increase in the number of research studies that are using machine learning (ML) to read or interrogate ECG data. The aim of this study is to review the use of ML with ECG data using a time series approach. Papers that address the subject of ML and the ECG were identified by systematically searching databases that archive papers from January 1995 to October 2019. Time series analysis was used to study the changing popularity of the different types of ML algorithms that have been used with ECG data over the past two decades. Finally, a meta-analysis of how various ML techniques performed for various diagnostic classifications was also undertaken. A total of 757 papers was identified. Based on results, the use of ML with ECG data started to increase sharply (p &lt; 0.001) from 2012. Healthcare applications, especially in heart abnormality classification, were the most common application of ML when using ECG data (p &lt; 0.001). However, many new emerging applications include using ML and the ECG for biometrics and driver drowsiness. The support vector machine was the technique of choice for a decade. However, since 2018, deep learning has been trending upwards and is likely to be the leading technique in the coming few years. Despite the accuracy paradox, accuracy was the most frequently used metric in the studies reviewed, followed by sensitivity, specificity, F1 score and then AUC. Applying ML using ECG data has shown promise. Data scientists and physicians should collaborate to ensure that clinical knowledge is being applied appropriately and is informing the design of ML algorithms. Data scientists also need to consider knowledge guided feature engineering and the explicability of the ML algorithm as well as being transparent in the algorithm&#39;s performance to appropriately calibrate human-AI trust. Future work is required to enhance ML performance in ECG classification.},
  archive      = {J_ARTMED},
  author       = {Khaled Rjoob and Raymond Bond and Dewar Finlay and Victoria McGilligan and Stephen J. Leslie and Ali Rababah and Aleeha Iftikhar and Daniel Guldenring and Charles Knoery and Anne McShane and Aaron Peace and Peter W. Macfarlane},
  doi          = {10.1016/j.artmed.2022.102381},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102381},
  shortjournal = {Artif. Intell. Med.},
  title        = {Machine learning and the electrocardiogram over two decades: Time series and meta-analysis of the algorithms, evaluation metrics and applications},
  volume       = {132},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic depression score estimation with word embedding
models. <em>ARTMED</em>, <em>132</em>, 102380. (<a
href="https://doi.org/10.1016/j.artmed.2022.102380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depression is one of the most common mental health illnesses. The biggest obstacle lies in an efficient and early detection of the disorder. Self-report questionnaires are the instruments used by medical experts to elaborate a diagnosis. These questionnaires were designed by analyzing different depressive symptoms . However, factors such as social stigmas negatively affect the success of traditional methods. This paper presents a novel approach for automatically estimating the degree of depression in social media users . In this regard, we addressed the task Measuring the Severity of the Signs of Depression of eRisk 2020, an initiative in the CLEF Conference. We aimed to explore neural language models to exploit different aspects of the subject’s writings depending on the symptom to capture. We devised two distinct methods based on the symptoms’ sensitivity in terms of willingness on commenting about them publicly. The first exploits users’ general language based on their publications. The second seeks more direct evidence from publications that specifically mention the symptoms concerns. Both methods automatically estimate the Beck Depression Inventory (BDI-II) total score. For evaluating our proposals, we used benchmark Reddit data for depression severity estimation. Our findings showed that approaches based on neural language models are a feasible alternative for estimating depression rating scales, even when small amounts of training data are available.},
  archive      = {J_ARTMED},
  author       = {Anxo Pérez and Javier Parapar and Álvaro Barreiro},
  doi          = {10.1016/j.artmed.2022.102380},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102380},
  shortjournal = {Artif. Intell. Med.},
  title        = {Automatic depression score estimation with word embedding models},
  volume       = {132},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic diagnosis of arrhythmia with electrocardiogram
using multiple instance learning: From rhythm annotation to heartbeat
prediction. <em>ARTMED</em>, <em>132</em>, 102379. (<a
href="https://doi.org/10.1016/j.artmed.2022.102379">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The electrocardiogram (ECG) is a commonly used technique for detecting arrhythmias and many other cardiac diseases . Automatic ECG diagnosis has seen tremendous success in recent years, owing to the rapid development of the deep learning (DL) approach. Existing works on automatic ECG diagnosis can be divided roughly into two categories: prediction at the rhythm level from an ECG record, and prediction at the heartbeat level, although their relationship was seldom studied previously. In this paper, we address the following question: can we train an abnormal heartbeat detection model using solely data annotated at the rhythm level? We first used multiple instance learning (MIL) to model the relationship between an ECG record (whose label is given at the rhythm level and is provided as an input) and the heartbeats in the ECG (whose labels are to be predicted). Then, we sequentially trained two models, a rhythm model for detecting abnormal heartbeats in an ECG record labeled as arrhythmia, and a heartbeat model for classifying heartbeats as normal or various types of arrhythmias . We trained and tested our models using 61,853 ECG records with rhythm annotations. The experimental results demonstrate that the heartbeat model achieves a macro-average F1 score of 0.807 in classifying four types of arrhythmias as well as normal heartbeats. Our model significantly outperforms the model directly trained with 15,385 ECG heartbeats with heartbeat annotations, demonstrating the viability of our strategy for training a high-performing heartbeat-level automatic diagnostic model using only rhythm annotation.},
  archive      = {J_ARTMED},
  author       = {Xuan Zhang and Hui Wu and Ting Chen and Guangyu Wang},
  doi          = {10.1016/j.artmed.2022.102379},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102379},
  shortjournal = {Artif. Intell. Med.},
  title        = {Automatic diagnosis of arrhythmia with electrocardiogram using multiple instance learning: From rhythm annotation to heartbeat prediction},
  volume       = {132},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine learning-based models for gestational diabetes
mellitus prediction before 24–28 weeks of pregnancy: A review.
<em>ARTMED</em>, <em>132</em>, 102378. (<a
href="https://doi.org/10.1016/j.artmed.2022.102378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gestational Diabetes Mellitus (GDM) is a hyperglycemia state that impairs maternal and offspring health, short and long-term. It is usually diagnosed at 24–28 weeks of pregnancy (WP), but at that time the fetal phenotype is already altered. Machine learning (ML)-based models have emerged as an auspicious alternative to predict this pathology earlier, however, they must be validated in different populations before their implementation in routine clinical practice. This review aims to give an overview of the ML-based models that have been proposed to predict GDM before 24–28 WP, with special emphasis on their current validation state and predictive performance. Articles were searched in PubMed . Manuscripts written in English and published before January 1, 2022, were considered. 109 original research studies were selected, and categorized according to the type of variables that their models involved: medical, i.e. clinical and/or biochemical parameters; alternative, i.e. metabolites, peptides or proteins, micro-ribonucleic acid molecules, microbiota genera, or other variables that did not fit into the first category; or mixed, i.e. both medical and alternative data. Only 8.3 % of the reviewed models have had validation in independent studies, with low or moderate performance for GDM prediction. In contrast, several models that lack of independent validation have shown a very high predictive power. The evaluation of these promising models in future independent validation studies would allow to assess their performance on different populations, and continue their way towards clinical implementation. Once settled, ML-based models would help to predict GDM earlier, initiate its treatment timely and prevent its negative consequences on maternal and offspring health.},
  archive      = {J_ARTMED},
  author       = {Daniela Mennickent and Andrés Rodríguez and Marcelo Farías-Jofré and Juan Araya and Enrique Guzmán-Gutiérrez},
  doi          = {10.1016/j.artmed.2022.102378},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102378},
  shortjournal = {Artif. Intell. Med.},
  title        = {Machine learning-based models for gestational diabetes mellitus prediction before 24–28 weeks of pregnancy: A review},
  volume       = {132},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Boosting lesion annotation via aggregating explicit
relations in external medical knowledge graph. <em>ARTMED</em>,
<em>132</em>, 102376. (<a
href="https://doi.org/10.1016/j.artmed.2022.102376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting a comprehensive set of relevant labels on chest X-ray images faces great challenges towards bridging visual and textual modalities. Despite the success of Graph Convolutional Networks (GCN) on modeling label dependencies using co-occurrence matrix generated from dataset, they still suffer from inherent label imbalance in dataset and ignore the explicit relations among labels presented in external medical knowledge graph (KG). We argue that jointly exploiting both the label co-occurrence matrix in dataset and the label relations in external knowledge graph facilitates multi-label lesion annotation. To model relevant lesion labels more comprehensively, we propose a KG-augmented model via Aggregating Explicit Relations for multi-label lesion annotation, called AER-GCN. The KG-augmented model employs GCN to learn the explicit label relations in external medical KG, and aggregates the explicit relations into statistical graph built from label co-occurrence information. Specially, we present three approaches on modeling the explicit label correlations in external knowledge, and two approaches on incorporating the explicit relations into co-occurrence relations for lesion annotation. We exploit SNOMED CT as the source of external knowledge and evaluate the performance of AER-GCN on the ChestX-ray and IU X-ray datasets. Extensive experiments demonstrate that our model outperforms other state-of-the-art models.},
  archive      = {J_ARTMED},
  author       = {Yixin Chen and Xianbing Zhao and Buzhou Tang},
  doi          = {10.1016/j.artmed.2022.102376},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102376},
  shortjournal = {Artif. Intell. Med.},
  title        = {Boosting lesion annotation via aggregating explicit relations in external medical knowledge graph},
  volume       = {132},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep multi-scale resemblance network for the sub-class
differentiation of adrenal masses on computed tomography images.
<em>ARTMED</em>, <em>132</em>, 102374. (<a
href="https://doi.org/10.1016/j.artmed.2022.102374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accurate classification of mass lesions in the adrenal glands (‘adrenal masses’), detected with computed tomography (CT), is important for diagnosis and patient management. Adrenal masses can be benign or malignant and benign masses have varying prevalence. Classification methods based on convolutional neural networks (CNNs) are the state-of-the-art in maximizing inter-class differences in large medical imaging training datasets. The application of CNNs, to adrenal masses is challenging due to large intra-class variations, large inter-class similarities and imbalanced training data due to the size of the mass lesions. We developed a deep multi-scale resemblance network (DMRN) to overcome these limitations and leveraged paired CNNs to evaluate the intra-class similarities. We used multi-scale feature embedding to improve the inter-class separability by iteratively combining complementary information produced at different scales of the input to create structured feature descriptors . We augmented the training data with randomly sampled paired adrenal masses to reduce the influence of imbalanced training data. We used 229 CT scans of patients with adrenal masses for evaluation. In a five-fold cross-validation, our method had the best results (89.52 % in accuracy) when compared to the state-of-the-art methods ( p &lt; 0.05). We conducted a generalizability analysis of our method on the ImageCLEF 2016 competition dataset for medical subfigure classification, which consists of a training set of 6776 images and a test set of 4166 images across 30 classes. Our method achieved better classification performance (85.90 % in accuracy) when compared to the existing methods and was competitive when compared with methods that require additional training data (1.47 % lower in accuracy). Our DMRN sub-classified adrenal masses on CT and was superior to state-of-the-art approaches.},
  archive      = {J_ARTMED},
  author       = {Lei Bi and Jinman Kim and Tingwei Su and Michael Fulham and David Dagan Feng and Guang Ning},
  doi          = {10.1016/j.artmed.2022.102374},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102374},
  shortjournal = {Artif. Intell. Med.},
  title        = {Deep multi-scale resemblance network for the sub-class differentiation of adrenal masses on computed tomography images},
  volume       = {132},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predicting disease progress with imprecise lab test results.
<em>ARTMED</em>, <em>132</em>, 102373. (<a
href="https://doi.org/10.1016/j.artmed.2022.102373">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clinical lab tests play an important role in disease diagnose and medical treatment, the test results have been utilized widely in predictive modeling tasks in healthcare. However, in most existing works, the loss function implicitly assumes that the value of the sample used to be predicted is the only correct one. This assumption fails to hold for lab test data, which usually are within respective tolerable ranges or imprecision ranges. In addition, the historical lab test data is always organized based on their sequential position, the timestamps between the data are often neglected. In this paper, we study the issue of building robust models while simultaneously taking imprecision and timestamp of the data into account with better generalization. In particular, “IR loss” is proposed in which each data in imprecision range space has a certain probability to be the real value, participating in the loss calculation. The loss is then defined as the integral of the error of each point in the impression range space. The sampling and discretization methods are proposed for loss calculation. A heuristic learning algorithm is developed to learn the model parameters. We further apply IR loss for disease progress prediction while the input data is organized as sequence. We reformulate the prediction task with timestamp based on Long Short-Term Memory (LSTM) network. At the same time, the timestamp is readily combined with the proposed IR loss to avoid the change of predicted result caused by the change of the test values in small time range. We conducted the experiments based on two real world datasets. Experimental results show that the prediction method based on IR loss can provide more accurate prediction result for different kinds of task and diverse learning methods. Our method can also provide more stable and consistent results when test samples are generated from imprecision range and small time range.},
  archive      = {J_ARTMED},
  author       = {Mei Wang and Zhihua Lin and Ruihua Li and Ye Li and Jianwen Su},
  doi          = {10.1016/j.artmed.2022.102373},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102373},
  shortjournal = {Artif. Intell. Med.},
  title        = {Predicting disease progress with imprecise lab test results},
  volume       = {132},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Explainable multiple abnormality classification of chest CT
volumes. <em>ARTMED</em>, <em>132</em>, 102372. (<a
href="https://doi.org/10.1016/j.artmed.2022.102372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding model predictions is critical in healthcare, to facilitate rapid verification of model correctness and to guard against use of models that exploit confounding variables. We introduce the challenging new task of explainable multiple abnormality classification in volumetric medical images, in which a model must indicate the regions used to predict each abnormality. To solve this task, we propose a multiple instance learning convolutional neural network , AxialNet, that allows identification of top slices for each abnormality. Next we incorporate HiResCAM , an attention mechanism , to identify sub-slice regions. We prove that for AxialNet, HiResCAM explanations are guaranteed to reflect the locations the model used, unlike Grad-CAM which sometimes highlights irrelevant locations. Armed with a model that produces faithful explanations, we then aim to improve the model’s learning through a novel mask loss that leverages HiResCAM and 3D allowed regions to encourage the model to predict abnormalities based only on the organs in which those abnormalities appear. The 3D allowed regions are obtained automatically through a new approach, PARTITION, that combines location information extracted from radiology reports with organ segmentation maps obtained through morphological image processing . Overall, we propose the first model for explainable multi-abnormality prediction in volumetric medical images, and then use the mask loss to achieve a 33% improvement in organ localization of multiple abnormalities in the RAD-ChestCT dataset of 36,316 scans, representing the state of the art. This work advances the clinical applicability of multiple abnormality modeling in chest CT volumes.},
  archive      = {J_ARTMED},
  author       = {Rachel Lea Draelos and Lawrence Carin},
  doi          = {10.1016/j.artmed.2022.102372},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102372},
  shortjournal = {Artif. Intell. Med.},
  title        = {Explainable multiple abnormality classification of chest CT volumes},
  volume       = {132},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An interpretable CNN-based CAD system for skin lesion
diagnosis. <em>ARTMED</em>, <em>132</em>, 102370. (<a
href="https://doi.org/10.1016/j.artmed.2022.102370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, convolutional neural networks have greatly outperformed previous systems based on handcrafted features once the size of public databases has increased. However, these algorithms learn feature representations that are difficult to interpret and analyse. On the other hand, experts require automatic systems to explain their decisions according to clinical criteria which, in the field of melanoma diagnosis, are related to the analysis of dermoscopic features found in the lesions. In recent years, the interpretability of deep networks has been explored using methods that obtain visual features highlighted by neurones or analyse activations to extract more useful information. Following the latter approach, this study proposes a system for melanoma diagnosis that explicitly incorporates dermoscopic feature segmentations into a diagnosis network through a channel modulation scheme. Modulation weights control the influence of the detected visual patterns based on the lesion content. As shown in the experimental section, our design not only improves the system performance on the ISIC 2016 (average AUC of 86.6% vs. 85.8%) and 2017 (average AUC of 94.0% vs. 93.8%) datasets, but also notably enhances the interpretability of the diagnosis, providing useful and intuitive cues to clinicians.},
  archive      = {J_ARTMED},
  author       = {Javier López-Labraca and Iván González-Díaz and Fernando Díaz-de-María and Alejandro Fueyo-Casado},
  doi          = {10.1016/j.artmed.2022.102370},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102370},
  shortjournal = {Artif. Intell. Med.},
  title        = {An interpretable CNN-based CAD system for skin lesion diagnosis},
  volume       = {132},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evolutionary deep feature selection for compact
representation of gigapixel images in digital pathology.
<em>ARTMED</em>, <em>132</em>, 102368. (<a
href="https://doi.org/10.1016/j.artmed.2022.102368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the recent progress in Deep Neural Networks (DNNs) to characterize histopathology images, compactly representing a gigapixel whole-slide image (WSI) via salient features to enable computational pathology is still an urgent need and a significant challenge. In this paper, we propose a novel WSI characterization approach to represent, search and classify biopsy specimens using a compact feature vector (CFV) extracted from a multitude of deep feature vectors. Since the non-optimal design and training of deep networks may result in many irrelevant and redundant features and also cause computational bottlenecks , we proposed a low-cost stochastic method to optimize the output of pre-trained deep networks using evolutionary algorithms to generate a very small set of features to accurately represent each tissue/biopsy. The performance of the proposed method has been assessed using WSIs from the publicly available TCGA image data . In addition to acquiring a very compact representation (i.e., 11,000 times smaller than the initial set of features), the optimized features achieved 93% classification accuracy resulting in 11% improvement compared to the published benchmarks. The experimental results reveal that the proposed method can reliably select salient features of the biopsy sample. Furthermore, the proposed approach holds the potential to immensely facilitate the adoption of digital pathology by enabling a new generation of WSI representation for efficient storage and more user-friendly visualization.},
  archive      = {J_ARTMED},
  author       = {Azam Asilian Bidgoli and Shahryar Rahnamayan and Taher Dehkharghanian and Abtin Riasatian and Shivam Kalra and Manit Zaveri and Clinton J.V. Campbell and Anil Parwani and Liron Pantanowitz and H.R. Tizhoosh},
  doi          = {10.1016/j.artmed.2022.102368},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102368},
  shortjournal = {Artif. Intell. Med.},
  title        = {Evolutionary deep feature selection for compact representation of gigapixel images in digital pathology},
  volume       = {132},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A self-training teacher-student model with an automatic
label grader for abdominal skeletal muscle segmentation.
<em>ARTMED</em>, <em>132</em>, 102366. (<a
href="https://doi.org/10.1016/j.artmed.2022.102366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning on a limited number of labels/annotations is a challenging task for medical imaging analysis. In this paper, we propose a novel self-training segmentation pipeline (Self-Seg in short) for segmenting skeletal muscle in CT images. Self-Seg starts with a small set of annotated images and then iteratively learns from unlabeled datasets to gradually improve the segmentation performance . Self-Seg follows a semi-supervised teacher-student learning scheme and there are two contributions: 1) we construct a self-attention UNet to improve segmentation over the classical UNet model, and 2) we implement an automatic label grader to implicitly incorporate medical knowledge for quality assurance of pseudo labels, from which good quality pseudo labels are identified to enhance learning of the segmentation model . We perform extensive experiments on three CT image datasets and show promising results on five evaluation settings, and we also compared our method to several baseline and related methods and achieved superior performance.},
  archive      = {J_ARTMED},
  author       = {Degan Hao and Maaz Ahsan and Tariq Salim and Andres Duarte-Rojo and Dadashzadeh Esmaeel and Yudong Zhang and Dooman Arefan and Shandong Wu},
  doi          = {10.1016/j.artmed.2022.102366},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102366},
  shortjournal = {Artif. Intell. Med.},
  title        = {A self-training teacher-student model with an automatic label grader for abdominal skeletal muscle segmentation},
  volume       = {132},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-structure bone segmentation in pediatric MR images
with combined regularization from shape priors and adversarial network.
<em>ARTMED</em>, <em>132</em>, 102364. (<a
href="https://doi.org/10.1016/j.artmed.2022.102364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Morphological and diagnostic evaluation of pediatric musculoskeletal system is crucial in clinical practice. However, most segmentation models do not perform well on scarce pediatric imaging data. We propose a new pre-trained regularized convolutional encoder–decoder network for the challenging task of segmenting heterogeneous pediatric magnetic resonance (MR) images. To this end, we have conceived a novel optimization scheme for the segmentation network which comprises additional regularization terms to the loss function. In order to obtain globally consistent predictions, we incorporate a shape priors based regularization, derived from a non-linear shape representation learnt by an auto-encoder. Additionally, an adversarial regularization computed by a discriminator is integrated to encourage precise delineations. The proposed method is evaluated for the task of multi-bone segmentation on two scarce pediatric imaging datasets from ankle and shoulder joints , comprising pathological as well as healthy examinations. The proposed method performed either better or at par with previously proposed approaches for Dice, sensitivity, specificity, maximum symmetric surface distance, average symmetric surface distance, and relative absolute volume difference metrics. We illustrate that the proposed approach can be easily integrated into various bone segmentation strategies and can improve the prediction accuracy of models pre-trained on large non-medical images databases. The obtained results bring new perspectives for the management of pediatric musculoskeletal disorders .},
  archive      = {J_ARTMED},
  author       = {Arnaud Boutillon and Bhushan Borotikar and Valérie Burdin and Pierre-Henri Conze},
  doi          = {10.1016/j.artmed.2022.102364},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102364},
  shortjournal = {Artif. Intell. Med.},
  title        = {Multi-structure bone segmentation in pediatric MR images with combined regularization from shape priors and adversarial network},
  volume       = {132},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Global and local attentional feature alignment for domain
adaptive nuclei detection in histopathology images. <em>ARTMED</em>,
<em>132</em>, 102341. (<a
href="https://doi.org/10.1016/j.artmed.2022.102341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated nuclei detection is crucial prerequisites for a number of histopathology related image analysis such as cancer diagnosis. Although existing deep learning based nuclei detection methods have achieved promising results, they cannot effectively deal with domain shift problem caused by different staining procedures and organ specific nuclear morphology. To handle this problem, in this paper a novel adversarial feature alignment method is proposed for domain adaptive nuclei detection, which includes both global alignment and local attentional alignment components to transfer the knowledge from source domain to target domain. Specifically, in local attentional alignment component, by using nuclei locations as guidance we extract local features and perform adversarial alignment. Furthermore, to address the issue that these local features from nuclei regions often contain insufficient information because of the small size of nuclei, we introduce an efficient location-aware self-attention (LocSA) module to refine local features by utilizing cues from all nuclei for obtaining discriminative features to perform successful feature alignment. Extensive experimental results are provided on two adaptation scenarios and our method demonstrates favorable performance against existing domain adaptation methods, which highlights the effectiveness of the proposed method for domain adaptive nuclei detection.},
  archive      = {J_ARTMED},
  author       = {Zhi Wang and Xiaoya Zhu and Ao Li and Yuan Wang and Gang Meng and Minghui Wang},
  doi          = {10.1016/j.artmed.2022.102341},
  journal      = {Artificial Intelligence in Medicine},
  month        = {10},
  pages        = {102341},
  shortjournal = {Artif. Intell. Med.},
  title        = {Global and local attentional feature alignment for domain adaptive nuclei detection in histopathology images},
  volume       = {132},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning with multiresolution handcrafted features for
brain MRI segmentation. <em>ARTMED</em>, <em>131</em>, 102365. (<a
href="https://doi.org/10.1016/j.artmed.2022.102365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The segmentation of magnetic resonance (MR) images is a crucial task for creating pseudo computed tomography (CT) images which are used to achieve positron emission tomography (PET) attenuation correction. One of the main challenges of creating pseudo CT images is the difficulty to obtain an accurate segmentation of the bone tissue in brain MR images. Deep convolutional neural networks (CNNs) have been widely and efficiently applied to perform MR image segmentation. The aim of this work is to propose a segmentation approach that combines multiresolution handcrafted features with CNN-based features to add directional properties and enrich the set of features to perform segmentation. The main objective is to efficiently segment the brain into three tissue classes: bone, soft tissue, and air. The proposed method combines non subsampled Contourlet (NSCT) and non subsampled Shearlet (NSST) coefficients with CNN’s features using different mechanisms. The entropy value is calculated to select the most useful coefficients and reduce the input’s dimensionality. The segmentation results are evaluated using fifty clinical brain MR and CT images by calculating the precision, recall, dice similarity coefficient (DSC), and Jaccard similarity coefficient (JSC). The results are also compared to other methods reported in the literature. The DSC of the bone class is improved from 0.6179 ± 0.0006 to 0.6416 ± 0.0006. The addition of multiresolution features of NSCT and NSST with CNN’s features demonstrates promising results. Moreover, NSST coefficients provide more useful information than NSCT coefficients.},
  archive      = {J_ARTMED},
  author       = {Imene Mecheter and Maysam Abbod and Abbes Amira and Habib Zaidi},
  doi          = {10.1016/j.artmed.2022.102365},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102365},
  shortjournal = {Artif. Intell. Med.},
  title        = {Deep learning with multiresolution handcrafted features for brain MRI segmentation},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An end-to-end tracking method for polyp detectors in
colonoscopy videos. <em>ARTMED</em>, <em>131</em>, 102363. (<a
href="https://doi.org/10.1016/j.artmed.2022.102363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning based computer-aided diagnosis technology demonstrates an encouraging performance in aspect of polyp lesion detection on reducing the miss rate of polyps during colonoscopies . However, to date, few studies have been conducted for tracking polyps that have been detected in colonoscopy videos, which is an essential and intuitive issue in clinical intelligent video analysis task ( e.g . lesion counting, lesion retrieval, report generation). In the paradigm of conventional tracking-by-detection system, detection task for lesion localization is separated from the tracking task for cropped lesions re-identification. In the multi object tracking problem , each target is supposed to be tracked by invoking a tracker after the detector, which introduces multiple inferences and leads to external resource and time consumption. To tackle these problems, we proposed a plug-in module named instance tracking head (ITH) for synchronous polyp detection and tracking, which can be simply inserted into object detection frameworks. It embeds a feature-based polyp tracking procedure into the detector frameworks to achieve multi-task model training. ITH and detection head share the model backbone for low level feature extraction, and then low level feature flows into the separate branches for task-driven model training. For feature maps from the same receptive field, the region of interest head assigns these features to the detection head and the ITH, respectively, and outputs the object category, bounding box coordinates, and instance feature embedding simultaneously for each specific polyp target. We also proposed a method based on similarity metric learning. The method makes full use of the prior boxes in the object detector to provide richer and denser instance training pairs, to improve the performance of the model evaluation on the tracking task. Compared with advanced tracking-by-detection paradigm methods, detectors with proposed ITH can obtain comparative tracking performance but approximate 30% faster speed. Optimized model based on Scaled-YOLOv4 detector with ITH illustrates good trade-off between detection (mAP 91.70%) and tracking (MOTA 92.50% and Rank-1 Acc 88.31%) task at the frame rate of 66 FPS. The proposed structure demonstrates the potential to aid clinicians in real-time detection with online tracking or offline retargeting of polyp instances during colonoscopies.},
  archive      = {J_ARTMED},
  author       = {Tao Yu and Ne Lin and Xu Zhang and Yanqi Pan and Huiyi Hu and Wenfang Zheng and Jiquan Liu and Weiling Hu and Huilong Duan and Jianmin Si},
  doi          = {10.1016/j.artmed.2022.102363},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102363},
  shortjournal = {Artif. Intell. Med.},
  title        = {An end-to-end tracking method for polyp detectors in colonoscopy videos},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial intelligence in acute respiratory distress
syndrome: A systematic review. <em>ARTMED</em>, <em>131</em>, 102361.
(<a href="https://doi.org/10.1016/j.artmed.2022.102361">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acute respiratory distress syndrome (ARDS) is a life-threatening pulmonary disease with a high clinical and cost burden across the globe. Artificial intelligence (AI), an emerging area, has been used for various purposes in ARDS. We aim to summarize the currently available literature on various applications of AI in ARDS through a systematic review . PubMed was searched from inception to February 2021 to collate all the studies. Additionally, a bibliographic search of included studies and a random search on Google, Google Scholar, and Research Gate were performed to identify relevant articles. Studies published in English language that employed data about developing and/or assessing the role of AI in the various aspects of ARDS were considered for this review. Three independent reviewers performed study selection and data extraction ; any disagreements were settled through consensus or discussion with another member of the research team. A total of 19 studies published between the year 2002 and 2020 were included. In these included studies, AI was used for various purposes in ARDS such as diagnosis (n = 10; 53 %), risk stratification (n = 1; 5 %), prediction of severity (n = 3; 17 %), management (n = 2; 10 %), prediction of mortality (n = 2; 10 %), and decision making (n = 1; 5 %). The area under the curve among the developed models in the included studies ranged between 0.8 and 1, which is considered to be very good to excellent. AI is revolutionizing healthcare and has a wide range of applications in ARDS, such as minimizing cost and enhancing outcomes.},
  archive      = {J_ARTMED},
  author       = {Muhammed Rashid and Manasvini Ramakrishnan and Viji Pulikkel Chandran and Siddeshappa Nandish and Sreedharan Nair and Vishal Shanbhag and Girish Thunga},
  doi          = {10.1016/j.artmed.2022.102361},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102361},
  shortjournal = {Artif. Intell. Med.},
  title        = {Artificial intelligence in acute respiratory distress syndrome: A systematic review},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Graph neural network modelling as a potentially effective
method for predicting and analyzing procedures based on patients’
diagnoses. <em>ARTMED</em>, <em>131</em>, 102359. (<a
href="https://doi.org/10.1016/j.artmed.2022.102359">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, the healthcare sector strives to improve the quality of patient care management and to enhance/increase its economic performance/efficiency (e.g., cost-effectiveness) by healthcare providers . The data stored in electronic health records (EHRs) offer the potential to uncover relevant patterns relating to diseases and therapies, which in turn could help identify empirical medical guidelines to reflect best practices in a healthcare system. Based on this pattern of identification model, it is thus possible to implement recommender systems with the notion that a higher volume of procedures is often associated with better high-quality models. Although there are several different applications that uses machine learning methods to identify such patterns, such identification is still a challenge, due in part because these methods often ignore the basic structure of the population, or even considering the similarity of diagnoses and patient typology. To this end, we have developed a method based on graph-data representation aimed to cluster ‘similar’ patients. Using such a model, patients will be linked when there is a same and/or similar patterns are being observed amongst them, a concept that will enable the construction of a network-like structure which is called a patient graph. 1 This structure can be then analyzed by Graph Neural Networks (GNN) to identify relevant labels, and in this case the appropriate medical procedures that will be recommended. We were able to construct a patient graph structure based on the patient&#39;s basic information like age and gender as well as the diagnosis and the trained GNNs models to identify the corresponding patient&#39;s therapies using a synthetic patient database. We have even compared our GNN models against different baseline models (using the SCIKIT-learn library of python) and also against the performance of these different model-methods. We have found that the GNNs models are superior, with an average improvement of the f1 score of 6.48 % in respect to the baseline models. In addition, the GNNs models are useful in performing additional clustering analysis which allow a distinctive identification of specific therapeutic/treatment clusters relating to a particular combination of diagnoses. We found that the GNNs models offer a promising lead to model the distribution of diagnoses in patient population, and is thus a better model in identifying patients with similar phenotype based on the combination of morbidities and/or comorbidities. Nevertheless, network/graph building is still challenging and prone to biases as it is highly dependent on how the ICD distribution affects the patient network embedding space. This graph setup not only requires a high quality of the underlying diagnostic ecosystem, but it also requires a good understanding on how patients at hand are identified by disease respectively. For this reason, additional work is still needed to better improve patient embedding in graph structures for future investigations and the applications of this service-based technology. Therefore, there has not been any interventional study yet.},
  archive      = {J_ARTMED},
  author       = {Juan G. Diaz Ochoa and Faizan E Mustafa},
  doi          = {10.1016/j.artmed.2022.102359},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102359},
  shortjournal = {Artif. Intell. Med.},
  title        = {Graph neural network modelling as a potentially effective method for predicting and analyzing procedures based on patients&#39; diagnoses},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Research on identification of key brittleness factors in
emergency medical resources support system based on complex network.
<em>ARTMED</em>, <em>131</em>, 102350. (<a
href="https://doi.org/10.1016/j.artmed.2022.102350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the problem of difficulty in identifying the key brittleness factors in the emergency medical resources support system (EMRSS), the principle of Interpretive Structural Modeling is utilized to construct a hierarchical recursive structural model for probing the influencing factors of the brittleness risk formation in the system. Further, by incorporating with the complex network theory , the network of the emergency medical resources support system has been built. The integrated value reflecting the importance of the network nodes is calculated by integrating the local nodes and the whole network to identify the critical factors that lead to the collapse of the emergency medical system. The validity of the method was verified by Advanced Research Project Agency network. The results showed that the key brittleness factors in EMRSS mainly include the professional competence of staff, the amount of government funding and the passing rate of quality sampling medical supplies in storage. It is hoped that this study provides useful information for reducing the brittleness risk and ensuring the safe operation of the system.},
  archive      = {J_ARTMED},
  author       = {Benhong Peng and Jiaojiao Ge and Guo Wei and Anxia Wan},
  doi          = {10.1016/j.artmed.2022.102350},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102350},
  shortjournal = {Artif. Intell. Med.},
  title        = {Research on identification of key brittleness factors in emergency medical resources support system based on complex network},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CACP-DeepGram: Classification of anticancer peptides via
deep neural network and skip-gram-based word embedding model.
<em>ARTMED</em>, <em>131</em>, 102349. (<a
href="https://doi.org/10.1016/j.artmed.2022.102349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cancer is a Toxic health concern worldwide, it happens when cellular modifications cause the irregular growth and division of human cells. Several traditional approaches such as therapies and wet laboratory-based methods have been applied to treat cancer cells. However, these methods are considered less effective due to their high cost and diverse side effects . According to recent advancements, peptide-based therapies have attracted the attention of scientists because of their high selectivity. Peptide therapy can efficiently treat the targeted cells, without affecting the normal cells. Due to the rapid increase of peptide sequences , an accurate prediction model has become a challenging task. Keeping the significance of anticancer peptides (ACPs) in cancer treatment, an intelligent and reliable prediction model is highly indispensable. In this paper, a FastText-based word embedding strategy has been employed to represent each peptide sample via a skip-gram model. After extracting the peptide embedding descriptors, the deep neural network (DNN) model was applied to accurately discriminate the ACPs. The optimized parameters of DNN achieved an accuracy of 96.94 %, 93.41 %, and 94.02 % using training, alternate, and independent samples, respectively. It was observed that our proposed cACP-DeepGram model outperformed and reported ~10 % highest prediction accuracy than existing predictors. It is suggested that the cACP-DeepGram model will be a reliable tool for scientists and might play a valuable role in academic research and drug discovery . The source code and the datasets are publicly available at https://github.com/shahidakbarcs/cACP-DeepGram .},
  archive      = {J_ARTMED},
  author       = {Shahid Akbar and Maqsood Hayat and Muhammad Tahir and Salman Khan and Fawaz Khaled Alarfaj},
  doi          = {10.1016/j.artmed.2022.102349},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102349},
  shortjournal = {Artif. Intell. Med.},
  title        = {CACP-DeepGram: Classification of anticancer peptides via deep neural network and skip-gram-based word embedding model},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Harmony search: Current studies and uses on healthcare
systems. <em>ARTMED</em>, <em>131</em>, 102348. (<a
href="https://doi.org/10.1016/j.artmed.2022.102348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the popular metaheuristic search algorithms is Harmony Search (HS). It has been verified that HS can find solutions to optimization problems due to its balanced exploratory and convergence behavior and its simple and flexible structure. This capability makes the algorithm preferable to be applied in several real-world applications in various fields, including healthcare systems, different engineering fields, and computer science. The popularity of HS urges us to provide a comprehensive survey of the literature on HS and its variants on health systems, analyze its strengths and weaknesses , and suggest future research directions. In this review paper, the current studies and uses of harmony search are studied in four main domains. (i) The variants of HS, including its modifications and hybridization. (ii) Summary of the previous review works. (iii) Applications of HS in healthcare systems. (iv) And finally, an operational framework is proposed for the applications of HS in healthcare systems. The main contribution of this review is intended to provide a thorough examination of HS in healthcare systems while also serving as a valuable resource for prospective scholars who want to investigate or implement this method.},
  archive      = {J_ARTMED},
  author       = {Maryam T. Abdulkhaleq and Tarik A. Rashid and Abeer Alsadoon and Bryar A. Hassan and Mokhtar Mohammadi and Jaza M. Abdullah and Amit Chhabra and Sazan L. Ali and Rawshan N. Othman and Hadil A. Hasan and Sara Azad and Naz A. Mahmood and Sivan S. Abdalrahman and Hezha O. Rasul and Nebojsa Bacanin and S. Vimal},
  doi          = {10.1016/j.artmed.2022.102348},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102348},
  shortjournal = {Artif. Intell. Med.},
  title        = {Harmony search: Current studies and uses on healthcare systems},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cardiovascular disease detection from high utility rare rule
mining. <em>ARTMED</em>, <em>131</em>, 102347. (<a
href="https://doi.org/10.1016/j.artmed.2022.102347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a method to search rare cardiovascular disease symptom rules from historical health examination records according to its hazard ratio utility and further detect the disease given new medical record data. Further, we aim to assist both medical experts and patients by alerting the current symptoms and preparing the early treatments. In general, the proposed method first deals with the uncertainty of age and other continuous features using a fuzzy set . Next, we define the hazard ratio utility of each item set to assist the mining process. Based on the utility, we discover the rare cardiovascular disease patterns employing High Utility Rare Itemset Mining. At last, we add a prediction step to check the given health record data whether diagnosed cardiovascular. Subsequently, we can obtain rare symptoms of cardiovascular disease, which are later applied to detect the new related record data. The rare symptoms that are confirmed by their utility risk for cardiovascular disease can assist the medical experts&#39; decision better than the common symptoms as it is often hard to be recognized at a glance. The proposed method evaluated on a public cardiovascular dataset. The experimental results showed that the generated rare cardiovascular disease patterns successfully applied to detect the cardiovascular given the symptoms data.},
  archive      = {J_ARTMED},
  author       = {Mohammad Iqbal and Muhammad Nanda Setiawan and Mohammad Isa Irawan and Ku Muhammad Naim Ku Khalif and Noryanti Muhammad and Mohd Khairul Bazli Mohd Aziz},
  doi          = {10.1016/j.artmed.2022.102347},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102347},
  shortjournal = {Artif. Intell. Med.},
  title        = {Cardiovascular disease detection from high utility rare rule mining},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Medical visual question answering based on question-type
reasoning and semantic space constraint. <em>ARTMED</em>, <em>131</em>,
102346. (<a href="https://doi.org/10.1016/j.artmed.2022.102346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical visual question answering (Med-VQA) aims to accurately answer clinical questions about medical images. Despite its enormous potential for application in the medical domain, the current technology is still in its infancy. Compared with general visual question answering task, Med-VQA task involve more demanding challenges. First, clinical questions about medical images are usually diverse due to different clinicians and the complexity of diseases. Consequently, noise is inevitably introduced when extracting question features. Second, Med-VQA task have always been regarded as a classification problem for predefined answers, ignoring the relationships between candidate responses. Thus, the Med-VQA model pays equal attention to all candidate answers when predicting answers. In this paper, a novel Med-VQA framework is proposed to alleviate the above-mentioned problems. Specifically, we employed a question-type reasoning module severally to closed-ended and open-ended questions, thereby extracting the important information contained in the questions through an attention mechanism and filtering the noise to extract more valuable question features. To take advantage of the relational information between answers, we designed a semantic constraint space to calculate the similarity between the answers and assign higher attention to answers with high correlation. To evaluate the effectiveness of the proposed method, extensive experiments were conducted on a public dataset, namely VQA-RAD. Experimental results showed that the proposed method achieved better performance compared to other the state-of-the-art methods. The overall accuracy, closed-ended accuracy, and open-ended accuracy reached 74.1 %, 82.7 %, and 60.9 %, respectively. It is worth noting that the absolute accuracy of the proposed method improved by 5.5 % for closed-ended questions.},
  archive      = {J_ARTMED},
  author       = {Meiling Wang and Xiaohai He and Luping Liu and Linbo Qing and Honggang Chen and Yan Liu and Chao Ren},
  doi          = {10.1016/j.artmed.2022.102346},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102346},
  shortjournal = {Artif. Intell. Med.},
  title        = {Medical visual question answering based on question-type reasoning and semantic space constraint},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The interactive fuzzy linguistic term set and its
application in multi-attribute decision making. <em>ARTMED</em>,
<em>131</em>, 102345. (<a
href="https://doi.org/10.1016/j.artmed.2022.102345">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-attribute decision making problems, some decision information interact with each other. The paper proposes an interactive fuzzy linguistic term set to describe the interactive information in multi-attribute decision making problems. The properties of the interactive fuzzy linguistic term set and its advantages of improving the consistency of decision information are discussed, which are also interpreted from the geometric point of view. Meanwhile, some numerical examples are given to illustrate its application in dealing with the interactive information in multi-attribute decision making problems, which can improve the effectiveness of the decision results and promote the development of artificial intelligence .},
  archive      = {J_ARTMED},
  author       = {Dan Peng and Jie Wang and Donghai Liu and Yu Cheng},
  doi          = {10.1016/j.artmed.2022.102345},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102345},
  shortjournal = {Artif. Intell. Med.},
  title        = {The interactive fuzzy linguistic term set and its application in multi-attribute decision making},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Attribute-aware interpretation learning for thyroid
ultrasound diagnosis. <em>ARTMED</em>, <em>131</em>, 102344. (<a
href="https://doi.org/10.1016/j.artmed.2022.102344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thyroid nodule diagnosis from ultrasound images is a critical computer-aided diagnosis task. Previous works tried to imitate the doctor&#39;s diagnosis logic by considering the key attributes to improve the diagnosis performance and explaining the conclusion. However, their clinical feasibilities are still ambiguous because of the ignorance of the correlation between attribute features and global characteristics, as well as the lack of clinical effectiveness evaluation of result interpretations. Following the common logic of ultrasonic investigation, we design a novel Attribute-Aware Interpretation Learning (AAIL) model, consisting of attribute properties discovery module and attribute-global feature fusion module. Adequate result interpretation ensures reliability and transparency of diagnostic conclusions, including the visualization of attribute features and the relationship between attributes and the global feature. Extensive experiments on a practical dataset demonstrate the model&#39;s effectiveness, and an innovative human-computer collaborative experiment demonstrates the auxiliary diagnostic ability of the interpretations that can benefit professional doctors.},
  archive      = {J_ARTMED},
  author       = {Ming Kong and Qing Guo and Shuowen Zhou and Mengze Li and Kun Kuang and Zhengxing Huang and Fei Wu and Xiaohong Chen and Qiang Zhu},
  doi          = {10.1016/j.artmed.2022.102344},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102344},
  shortjournal = {Artif. Intell. Med.},
  title        = {Attribute-aware interpretation learning for thyroid ultrasound diagnosis},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modelling and assessing one- and two-drug dose titrations.
<em>ARTMED</em>, <em>131</em>, 102343. (<a
href="https://doi.org/10.1016/j.artmed.2022.102343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In health-care, there is a need to quantify medical errors. Among these errors, we observe wrong dose prescriptions. Drug dose titration (DT) is the process by which dosage is progressively adjusted to the patient till a steady dose is reached. Depending on the clinical disease, drug, and patient condition, dose titration can follow different procedures. Once modeled, these procedures can serve for clinical homogenization, standardization, decision support and retrospective analysis. Here, we propose a language to model dose titration procedures. The language was used to formalize one- and two-drug titration of chronic and acute cases, and to perform retrospective analysis of the drug titration processes on 253 patients diagnosed of diabetes mellitus type 2 and treated with metformin , 321 patients treated of chonic heart failure with furosemide , 155 patients with hyperuricemia treated with allopurinol as initial drug and febuxostat as alternative drug, and 187 hyperuricemia patients with primary drug allopurinol and supplementary drug probenecid , in order to identify different types of drug titration deviations from standard DT methods.},
  archive      = {J_ARTMED},
  author       = {David Riaño and Špela Pečnik and Josep Ramon Alonso and Aida Kamišalić},
  doi          = {10.1016/j.artmed.2022.102343},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {102343},
  shortjournal = {Artif. Intell. Med.},
  title        = {Modelling and assessing one- and two-drug dose titrations},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Electrocardiogram analysis of post-stroke elderly people
using one-dimensional convolutional neural network model with
gradient-weighted class activation mapping. <em>ARTMED</em>,
<em>130</em>, 102342. (<a
href="https://doi.org/10.1016/j.artmed.2022.102342">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stroke is the second leading cause of death globally after ischemic heart disease , also a risk factor of cardioembolic stroke. Thus, we postulate that heartbeats encapsulate vital signals related to stroke. With the rapid advancement of deep neural networks (DNNs), it emerges as a powerful tool to decipher intriguing heartbeat patterns associated with post-stroke patients. In this study, we propose the use of a one-dimensional convolutional network (1D-CNN) architecture to build a binary classifier that distinguishes electrocardiograms (ECGs) between the post-stroke and the stroke-free. We have built two 1D-CNNs that were used to identify distinct patterns from an openly accessible ECG dataset collected from elderly post-stroke patients. In addition to prediction accuracy, which is the primary focus of existing ECG deep neural network methods, we have utilized Gradient-weighted Class Activation Mapping (GRAD-CAM) to facilitate model interpretation by uncovering subtle ECG patterns captured by our model. Our stroke model has achieved ~90 % accuracy and 0.95 area under the Receiver Operating Characteristic curve. Findings suggest that the core PQRST complex alone is important but not sufficient to differentiate the post-stroke and the stroke-free. In conclusion, we have developed an accurate stroke model using the latest DNN method. Importantly, our work has illustrated an approach to enhance model interpretation, overcoming the black-box issue confronting DNNs, fostering higher user confidence and adoption of DNNs in medicine.},
  archive      = {J_ARTMED},
  author       = {Eric S. Ho and Zhaoyi Ding},
  doi          = {10.1016/j.artmed.2022.102342},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102342},
  shortjournal = {Artif. Intell. Med.},
  title        = {Electrocardiogram analysis of post-stroke elderly people using one-dimensional convolutional neural network model with gradient-weighted class activation mapping},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning for alzheimer’s disease diagnosis: A survey.
<em>ARTMED</em>, <em>130</em>, 102332. (<a
href="https://doi.org/10.1016/j.artmed.2022.102332">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer&#39;s Disease (AD) is an irreversible neurodegenerative disease that results in a progressive decline in cognitive abilities. Since AD starts several years before the onset of the symptoms, its early detection is challenging due to subtle changes in biomarkers mainly detectable in different neuroimaging modalities. Developing computer-aided diagnostic models based on deep learning can provide excellent opportunities for the analysis of different neuroimage modalities along with other non-image biomarkers. In this survey, we perform a comparative analysis of about 100 published papers since 2019 that employ basic deep architectures such as CNN , RNN , and generative models for AD diagnosis. Moreover, about 60 papers that have applied a trending topic or architecture for AD are investigated. Explainable models, normalizing flows, graph-based deep architectures, self-supervised learning, and attention mechanisms are considered. The main challenges in this body of literature have been categorized and explained from data-related, methodology-related, and clinical adoption aspects. We conclude our paper by addressing some future perspectives and providing recommendations to conduct further studies for AD diagnosis.},
  archive      = {J_ARTMED},
  author       = {M. Khojaste-Sarakhsi and Seyedhamidreza Shahabi Haghighi and S.M.T. Fatemi Ghomi and Elena Marchiori},
  doi          = {10.1016/j.artmed.2022.102332},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102332},
  shortjournal = {Artif. Intell. Med.},
  title        = {Deep learning for alzheimer&#39;s disease diagnosis: A survey},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning for image-based liver analysis — a
comprehensive review focusing on malignant lesions. <em>ARTMED</em>,
<em>130</em>, 102331. (<a
href="https://doi.org/10.1016/j.artmed.2022.102331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based methods, in particular, convolutional neural networks and fully convolutional networks are now widely used in the medical image analysis domain. The scope of this review focuses on the analysis using deep learning of focal liver lesions, with a special interest in hepatocellular carcinoma and metastatic cancer ; and structures like the parenchyma or the vascular system . Here, we address several neural network architectures used for analyzing the anatomical structures and lesions in the liver from various imaging modalities such as computed tomography , magnetic resonance imaging and ultrasound. Image analysis tasks like segmentation, object detection and classification for the liver, liver vessels and liver lesions are discussed. Based on the qualitative search, 91 papers were filtered out for the survey, including journal publications and conference proceedings. The papers reviewed in this work are grouped into eight categories based on the methodologies used. By comparing the evaluation metrics, hybrid models performed better for both the liver and the lesion segmentation tasks, ensemble classifiers performed better for the vessel segmentation tasks and combined approach performed better for both the lesion classification and detection tasks. The performance was measured based on the Dice score for the segmentation, and accuracy for the classification and detection tasks, which are the most commonly used metrics.},
  archive      = {J_ARTMED},
  author       = {Shanmugapriya Survarachakan and Pravda Jith Ray Prasad and Rabia Naseem and Javier Pérez de Frutos and Rahul Prasanna Kumar and Thomas Langø and Faouzi Alaya Cheikh and Ole Jakob Elle and Frank Lindseth},
  doi          = {10.1016/j.artmed.2022.102331},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102331},
  shortjournal = {Artif. Intell. Med.},
  title        = {Deep learning for image-based liver analysis — a comprehensive review focusing on malignant lesions},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Diffusion tensor estimation with transformer neural
networks. <em>ARTMED</em>, <em>130</em>, 102330. (<a
href="https://doi.org/10.1016/j.artmed.2022.102330">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion tensor imaging (DTI) is a widely used method for studying brain white matter development and degeneration. However, standard DTI estimation methods depend on a large number of high-quality measurements. This would require long scan times and can be particularly difficult to achieve with certain patient populations such as neonates. Here, we propose a method that can accurately estimate the diffusion tensor from only six diffusion-weighted measurements. Our method achieves this by learning to exploit the relationships between the diffusion signals and tensors in neighboring voxels. Our model is based on transformer networks, which represent the state of the art in modeling the relationship between signals in a sequence. In particular, our model consists of two such networks. The first network estimates the diffusion tensor based on the diffusion signals in a neighborhood of voxels. The second network provides more accurate tensor estimations by learning the relationships between the diffusion signals as well as the tensors estimated by the first network in neighboring voxels. Our experiments with three datasets show that our proposed method achieves highly accurate estimations of the diffusion tensor and is significantly superior to three competing methods. Estimations produced by our method with six diffusion-weighted measurements are comparable with those of standard estimation methods with 30–88 diffusion-weighted measurements. Hence, our method promises shorter scan times and more reliable assessment of brain white matter, particularly in non-cooperative patients such as neonates and infants.},
  archive      = {J_ARTMED},
  author       = {Davood Karimi and Ali Gholipour},
  doi          = {10.1016/j.artmed.2022.102330},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102330},
  shortjournal = {Artif. Intell. Med.},
  title        = {Diffusion tensor estimation with transformer neural networks},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Gated tree-based graph attention network (GTGAT) for medical
knowledge graph reasoning. <em>ARTMED</em>, <em>130</em>, 102329. (<a
href="https://doi.org/10.1016/j.artmed.2022.102329">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph (KG) is a multi-relational data that has proven valuable for many tasks including decision making and semantic search . In this paper, we present GTGAT (Gated Tree-based Graph Attention), a method for tackling the problems of transductive and inductive reasoning in generalized KGs. Based on recent advancement of graph attention network (GAT), we develop a gated tree-based method to distill valuable information in neighborhood via hierarchical-aware and semantic-aware attention mechanism. Our approach not only addresses several key challenges of GAT but is also capable of undertaking multiple downstream tasks. Experimental results have revealed that our proposed GTGAT has matched state-of-the-art approaches across transductive benchmarks on the Cora, Citeseer, and electronic medical record networks (EMRNet). Meanwhile, the inductive experiments on medical knowledge graphs show that GTGAT surpasses the best competing methods for personalized disease diagnosis.},
  archive      = {J_ARTMED},
  author       = {Jingchi Jiang and Tao Wang and Boran Wang and Linjiang Ma and Yi Guan},
  doi          = {10.1016/j.artmed.2022.102329},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102329},
  shortjournal = {Artif. Intell. Med.},
  title        = {Gated tree-based graph attention network (GTGAT) for medical knowledge graph reasoning},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A meta-learning algorithm for respiratory flow prediction
from FBG-based wearables in unrestrained conditions. <em>ARTMED</em>,
<em>130</em>, 102328. (<a
href="https://doi.org/10.1016/j.artmed.2022.102328">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The continuous monitoring of an individual&#39;s breathing can be an instrument for the assessment and enhancement of human wellness. Specific respiratory features are unique markers of the deterioration of a health condition, the onset of a disease, fatigue and stressful circumstances. The early and reliable prediction of high-risk situations can result in the implementation of appropriate intervention strategies that might be lifesaving. Hence, smart wearables for the monitoring of continuous breathing have recently been attracting the interest of many researchers and companies. However, most of the existing approaches do not provide comprehensive respiratory information. For this reason, a meta-learning algorithm based on LSTM neural networks for inferring the respiratory flow from a wearable system embedding FBG sensors and inertial units is herein proposed. Different conventional machine learning approaches were implemented as well to ultimately compare the results. The meta-learning algorithm turned out to be the most accurate in predicting respiratory flow when new subjects are considered. Furthermore, the LSTM model memory capability has been proven to be advantageous for capturing relevant aspects of the breathing pattern. The algorithms were tested under different conditions, both static and dynamic, and with more unobtrusive device configurations. The meta-learning results demonstrated that a short one-time calibration may provide subject-specific models which predict the respiratory flow with high accuracy, even when the number of sensors is reduced. Flow RMS errors on the test set ranged from 22.03 L/min, when the minimum number of sensors was considered, to 9.97 L/min for the complete setting (target flow range: 69.231 ± 21.477 L/min). The correlation coefficient r between the target and the predicted flow changed accordingly, being higher ( r = 0.9) for the most comprehensive and heterogeneous wearable device configuration. Similar results were achieved even with simpler settings which included the thoracic sensors ( r ranging from 0.84 to 0.88; test flow RMSE = 10.99 L/min, when exclusively using the thoracic FBGs). The further estimation of respiratory parameters, i.e., rate and volume, with low errors across different breathing behaviors and postures proved the potential of such approach. These findings lay the foundation for the implementation of reliable custom solutions and more sophisticated artificial intelligence-based algorithms for daily life health-related applications.},
  archive      = {J_ARTMED},
  author       = {Mariangela Filosa and Luca Massari and Davide Ferraro and Giacomo D&#39;Alesio and Jessica D&#39;Abbraccio and Andrea Aliperta and Daniela Lo Presti and Joshua Di Tocco and Martina Zaltieri and Carlo Massaroni and Maria Chiara Carrozza and Maurizio Ferrarin and Marco Di Rienzo and Emiliano Schena and Calogero Maria Oddo},
  doi          = {10.1016/j.artmed.2022.102328},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102328},
  shortjournal = {Artif. Intell. Med.},
  title        = {A meta-learning algorithm for respiratory flow prediction from FBG-based wearables in unrestrained conditions},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimization of the organizational structure in hospitals to
account for patients with multiple diseases. <em>ARTMED</em>,
<em>130</em>, 102327. (<a
href="https://doi.org/10.1016/j.artmed.2022.102327">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many hospitals operate with a structure that separates inpatients according to their primary disease. Conversely, these hospitals may reduce the cases of bed shortage and provide a better care for patients with multiple diseases by striving for a setup containing fewer nursing wards. We present a method for optimizing the organizational structure in a hospital where the medical specialties are consolidated into fewer wards. The patient diagnoses are the basis of our approach as we derive an improved organizational structure by using a heuristic optimization algorithm. In this algorithm, we evaluate the solution by simulating the patient flow and penalize the objective value for every patient with a diagnosis that does not match the specialties in the ward. Through numerical experimentation, and data from a Danish hospital, we validate the applicability of our approach. The proposed algorithm converged to the optimal solution in all smaller problem instances. Further, tests with the hospital data indicate that consolidating medical specialties into fewer wards is beneficial for patients with diagnoses stemming from various medical specialties.},
  archive      = {J_ARTMED},
  author       = {Anders Reenberg Andersen and Andreas Linhardt Plesner},
  doi          = {10.1016/j.artmed.2022.102327},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102327},
  shortjournal = {Artif. Intell. Med.},
  title        = {Optimization of the organizational structure in hospitals to account for patients with multiple diseases},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Assessing putative bias in prediction of anti-microbial
resistance from real-world genotyping data under explicit causal
assumptions. <em>ARTMED</em>, <em>130</em>, 102326. (<a
href="https://doi.org/10.1016/j.artmed.2022.102326">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Whole genome sequencing (WGS) is quickly becoming the customary means for identification of antimicrobial resistance (AMR) due to its ability to obtain high resolution information about the genes and mechanisms that are causing resistance and driving pathogen mobility. By contrast, traditional phenotypic (antibiogram) testing cannot easily elucidate such information. Yet development of AMR prediction tools from genotype-phenotype data can be biased, since sampling is non-randomized. Sample provenience, period of collection, and species representation can confound the association of genetic traits with AMR. Thus, prediction models can perform poorly on new data with sampling distribution shifts. In this work –under an explicit set of causal assumptions– we evaluate the effectiveness of propensity-based rebalancing and confounding adjustment on antibiotic resistance prediction using genotype-phenotype AMR data from the Pathosystems Resource Integration Center (PATRIC). We select bacterial genotypes (encoded as k -mer signatures, i.e., DNA fragments of length k ), country, year, species, and AMR phenotypes for the tetracycline drug class, preparing test data with recent genomes coming from a single country. We test boosted logistic regression (BLR) and random forests (RF) with/without bias-handling. On 10,936 instances, we find evidence of species, location and year imbalance with respect to the AMR phenotype. The crude versus bias-adjusted change in effect of genetic signatures on AMR varies but only moderately (selecting the top 20,000 out of 40+ million k -mers). The area under the receiver operating characteristic (AUROC) of the RF (0.95) is comparable to that of BLR (0.94) on both out-of-bag samples from bootstrap and the external test (n = 1085), where AUROCs do not decrease. We observe a 1 %–5 % gain in AUROC with bias-handling compared to the sole use of genetic signatures. In conclusion, we recommend using causally-informed prediction methods for modeling real-world AMR data; however, traditional adjustment or propensity-based methods may not provide advantage in all use cases and further methodological development should be sought.},
  archive      = {J_ARTMED},
  author       = {Mattia Prosperi and Christina Boucher and Jiang Bian and Simone Marini},
  doi          = {10.1016/j.artmed.2022.102326},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102326},
  shortjournal = {Artif. Intell. Med.},
  title        = {Assessing putative bias in prediction of anti-microbial resistance from real-world genotyping data under explicit causal assumptions},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). All-cause mortality prediction in T2D patients with iTirps.
<em>ARTMED</em>, <em>130</em>, 102325. (<a
href="https://doi.org/10.1016/j.artmed.2022.102325">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mortality in the type II diabetic elderly population can sometimes be prevented through intervention, for which risk assessment through predictive modeling is required. Since Electronic Health Records data are typically heterogeneous and sparse, the use of Temporal Abstraction and time intervals mining to discover frequent Time Intervals Related Patterns (TIRPs) is employed. While TIRPs are used as features for a predictive model , the temporal relations between them in general, and among each TIRP&#39;s instances are not represented. We introduce a novel TIRP based representation called integer-TIRP (iTirp) in which the TIRPs become channels containing values that represent the TIRP instances that were detected at each time point . Then the iTirp representation is fed into a Deep Learning architecture, that learns this kind of temporal relations, using a Recurrent Neural Network or a Convolutional Neural Network . Additionally, a predictive committee is introduced in which raw data and iTirp data are concatenated as inputs. Our results show that iTirps based models outperform the use of deep learning with raw data, resulting in 82% AUC.},
  archive      = {J_ARTMED},
  author       = {Pavel Novitski and Cheli Melzer Cohen and Avraham Karasik and Varda Shalev and Gabriel Hodik and Robert Moskovitch},
  doi          = {10.1016/j.artmed.2022.102325},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {102325},
  shortjournal = {Artif. Intell. Med.},
  title        = {All-cause mortality prediction in T2D patients with iTirps},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distributed application of guideline-based decision support
through mobile devices: Implementation and evaluation. <em>ARTMED</em>,
<em>129</em>, 102324. (<a
href="https://doi.org/10.1016/j.artmed.2022.102324">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditionally guideline (GL)-based Decision Support Systems (DSSs) use a centralized infrastructure to generate recommendations to care providers, rather than to patients at home. However, managing patients at home is often preferable, reducing costs and empowering patients. Thus, we wanted to explore an option in which patients, in particular chronic patients, might be assisted by a local DSS, which interacts as needed with the central DSS engine, to manage their disease outside the standard clinical settings. To design, implement, and demonstrate the technical and clinical feasibility of a new architecture for a distributed DSS that provides patients with evidence-based guidance, offered through applications running on the patients&#39; mobile devices, monitoring and reacting to changes in the patient&#39;s personal environment, and providing the patients with appropriate GL-based alerts and personalized recommendations; and increase the overall robustness of the distributed application of the GL. We have designed and implemented a novel projection–callback (PCB) model, in which small portions of the evidence-based guideline&#39;s procedural knowledge are projected from a projection engine within the central DSS server, to a local DSS that resides on each patient&#39;s mobile device. The local DSS applies the knowledge using the mobile device&#39;s local resources. The GL projections generated by the projection engine are adapted to the patient&#39;s previously defined preferences and, implicitly, to the patient&#39;s current context, in a manner that is embodied in the projected therapy plans. When appropriate, as defined by a temporal pattern within the projected plan, the local DSS calls back the central DSS, requesting further assistance, possibly another projection. To support the new model, the initial specification of the GL includes two levels: one for the central DSS, and one for the local DSS. We have implemented a distributed GL-based DSS using the projection–callback model within the MobiGuide EU project, which automatically manages chronic patients at home using sensors on the patients and their mobile phone . We assessed the new GL specification process, by specifying two very different, complex GLs: for Gestational Diabetes Mellitus , and for Atrial Fibrillation . Then, we evaluated the new computational architecture by applying the two GLs to the automated clinical management, at real time, of patients in two different countries: Spain and Italy, respectively. The specification using the new projection-callback model was found to be quite feasible. We found significant differences between the distributed versions of the two GLs, suggesting further research directions and possibly additional ways to analyze and characterize GLs. Applying the two GLs to the two patient populations proved highly feasible as well. The mean time between the central and local interactions was quite different for the two GLs: 3.95 ± 1.95 days in the case of the gestational diabetes domain, and 23.80 ± 12.47 days, in the case of the atrial fibrillation domain, probably corresponding to the difference in the distributed specifications of the two GLs. Most of the interaction types were due to projections to the local DSS (83%); others were data notifications, mostly to change context (17%). Some of the data notifications were triggered due to technical errors. The robustness of the distributed architecture was demonstrated through the successful recovery from multiple crashes of the local DSS. The new projection-callback model has been demonstrated to be feasible, from specification to distributed application. Different GLs might significantly differ, however, in their distributed specification and application characteristics. Distributed medical DSSs can facilitate the remote management of chronic patients by enabling the central DSSs to delegate, in a dynamic fashion, determined by the patient&#39;s context , much of the monitoring and treatment management decisions to the mobile device. Patients can be kept in their home environment, while still maintaining, through the projection-callback mechanism, several of the advantages of a central DSS, such as access to the patient&#39;s longitudinal record, and to an up-to-date evidence-based GL repository.},
  archive      = {J_ARTMED},
  author       = {Erez Shalom and Ayelet Goldstein and Elior Ariel and Moshe Sheinberger and Valerie Jones and Boris Van Schooten and Yuval Shahar},
  doi          = {10.1016/j.artmed.2022.102324},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {102324},
  shortjournal = {Artif. Intell. Med.},
  title        = {Distributed application of guideline-based decision support through mobile devices: Implementation and evaluation},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybrid learning method based on feature clustering and
scoring for enhanced COVID-19 breath analysis by an electronic nose.
<em>ARTMED</em>, <em>129</em>, 102323. (<a
href="https://doi.org/10.1016/j.artmed.2022.102323">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breath pattern analysis based on an electronic nose (e-nose), which is a noninvasive, fast, and low-cost method, has been continuously used for detecting human diseases, including the coronavirus disease 2019 (COVID-19). Nevertheless, having big data with several available features is not always beneficial because only a few of them will be relevant and useful to distinguish different breath samples (i.e., positive and negative COVID-19 samples). In this study, we develop a hybrid machine learning-based algorithm combining hierarchical agglomerative clustering analysis and permutation feature importance method to improve the data analysis of a portable e-nose for COVID-19 detection (GeNose C19). Utilizing this learning approach, we can obtain an effective and optimum feature combination, enabling the reduction by half of the number of employed sensors without downgrading the classification model performance. Based on the cross-validation test results on the training data, the hybrid algorithm can result in accuracy, sensitivity, and specificity values of (86 ± 3)%, (88 ± 6)%, and (84 ± 6)%, respectively. Meanwhile, for the testing data, a value of 87% is obtained for all the three metrics. These results exhibit the feasibility of using this hybrid filter-wrapper feature-selection method to pave the way for optimizing the GeNose C19 performance.},
  archive      = {J_ARTMED},
  author       = {Shidiq Nur Hidayat and Trisna Julian and Agus Budi Dharmawan and Mayumi Puspita and Lily Chandra and Abdul Rohman and Madarina Julia and Aditya Rianjanu and Dian Kesumapramudya Nurputra and Kuwat Triyana and Hutomo Suryo Wasisto},
  doi          = {10.1016/j.artmed.2022.102323},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {102323},
  shortjournal = {Artif. Intell. Med.},
  title        = {Hybrid learning method based on feature clustering and scoring for enhanced COVID-19 breath analysis by an electronic nose},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comprehensive survey on gait analysis: History,
parameters, approaches, pose estimation, and future work.
<em>ARTMED</em>, <em>129</em>, 102314. (<a
href="https://doi.org/10.1016/j.artmed.2022.102314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human gait is a periodic motion of body segments—the analysis of motion and related studies is termed gait analysis . Gait Analysis has gained much popularity because of its applications in clinical diagnosis, rehabilitation methods, gait biometrics, robotics, sports, and biomechanics . Traditionally, subjective assessment of the gait was conducted by health experts; however, with the advancement in technology, gait analysis can now be performed objectively and empirically for better and more reliable assessment. State-of-the-art semi-subjective and objective techniques for gait analysis have limitations that can be mitigated using advanced machine learning-based approaches. This paper aims to provide a narrative and a comprehensive analysis of cutting-edge gait analysis techniques and insight into clinical gait analysis. The literature of the previous surveys during the last decade is discussed. This paper presents an elaborated schema, including gait analysis history, parameters, machine learning approaches for marker-based and marker-less analysis, applications, and performance measures . This paper also explores the pose estimation techniques for clinical gait analysis that open future research directions in this area.},
  archive      = {J_ARTMED},
  author       = {Dimple Sethi and Sourabh Bharti and Chandra Prakash},
  doi          = {10.1016/j.artmed.2022.102314},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {102314},
  shortjournal = {Artif. Intell. Med.},
  title        = {A comprehensive survey on gait analysis: History, parameters, approaches, pose estimation, and future work},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine learning and pre-medical education. <em>ARTMED</em>,
<em>129</em>, 102313. (<a
href="https://doi.org/10.1016/j.artmed.2022.102313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning and artificial intelligence (AI)-driven technologies are contributing significantly to various facets of medicine and care management. It is likely that the next generation of healthcare professionals will be confronted with a series of innovations that are powered by AI, and they may not have sufficient time during their professional tenure to learn about the underlying machine learning frameworks that are driving these systems. Educating the aspiring clinicians and care providers with the right foundational courses in machine learning as part of postsecondary education will likely transform them as high-tech physicians and care providers of the future.},
  archive      = {J_ARTMED},
  author       = {Vijaya B. Kolachalama},
  doi          = {10.1016/j.artmed.2022.102313},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {102313},
  shortjournal = {Artif. Intell. Med.},
  title        = {Machine learning and pre-medical education},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A rapid review of machine learning approaches for
telemedicine in the scope of COVID-19. <em>ARTMED</em>, <em>129</em>,
102312. (<a href="https://doi.org/10.1016/j.artmed.2022.102312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic has rapidly spread around the world. The rapid transmission of the virus is a threat that hinders the ability to contain the disease propagation. The pandemic forced widespread conversion of in-person to virtual care delivery through telemedicine . Given this gap, this article aims at providing a literature review of machine learning-based telemedicine applications to mitigate COVID-19. A rapid review of the literature was conducted in six electronic databases published from 2015 through 2020. The process of data extraction was documented using a PRISMA flowchart for inclusion and exclusion of studies. As a result, the literature search identified 1.733 articles, from which 16 articles were included in the review. We developed an updated taxonomy and identified challenges, open questions, and current data types . Our taxonomy and discussion contribute with a significant degree of coverage from subjects related to the use of machine learning to improve telemedicine in response to the COVID-19 pandemic. The evidence identified by this rapid review suggests that machine learning, in combination with telemedicine, can provide a strategy to control outbreaks by providing smart triage of patients and remote monitoring . Also, the use of telemedicine during future outbreaks could be further explored and refined.},
  archive      = {J_ARTMED},
  author       = {Luana Carine Schünke and Blanda Mello and Cristiano André da Costa and Rodolfo Stoffel Antunes and Sandro José Rigo and Gabriel de Oliveira Ramos and Rodrigo da Rosa Righi and Juliana Nichterwitz Scherer and Bruna Donida},
  doi          = {10.1016/j.artmed.2022.102312},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {102312},
  shortjournal = {Artif. Intell. Med.},
  title        = {A rapid review of machine learning approaches for telemedicine in the scope of COVID-19},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Construction of a confounder-free clinical MRI dataset in
the mass general brigham system for classification of alzheimer’s
disease. <em>ARTMED</em>, <em>129</em>, 102309. (<a
href="https://doi.org/10.1016/j.artmed.2022.102309">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has the potential to standardize and automate diagnostics for complex medical imaging data, but real-world clinical images are plagued by a high degree of heterogeneity and confounding factors that may introduce imbalances and biases to such processes. To address this, we developed and applied a data matching algorithm to 467,464 clinical brain magnetic resonance imaging (MRI) data from the Mass General Brigham (MGB) healthcare system for Alzheimer&#39;s disease (AD) classification. We identified 18 technical and demographic confounding factors that can be readily distinguished by MRI or have significant correlations with AD status and isolated a training set free from these confounds. We then applied an ensemble of 3D ResNet-50 deep learning models to classify brain MRIs between groups of AD, mild cognitive impairment (MCI), and healthy controls . From a confounder-free matched dataset of 287,367 MRI files, we achieved an area under the receiver operating characteristic (AUROC) of 0.82 in distinguishing healthy controls from patients with AD or MCI. We also showed that confounding factors in heterogeneous clinical data could lead to artificial gains in model performance for disease classification , which our data matching approach could correct. This approach could accelerate using deep learning models for clinical diagnosis and find broad applications in medical image analysis .},
  archive      = {J_ARTMED},
  author       = {Matthew Leming and Sudeshna Das and Hyungsoon Im},
  doi          = {10.1016/j.artmed.2022.102309},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {102309},
  shortjournal = {Artif. Intell. Med.},
  title        = {Construction of a confounder-free clinical MRI dataset in the mass general brigham system for classification of alzheimer&#39;s disease},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FSPBO-DQN: SeGAN based segmentation and fractional student
psychology optimization enabled deep q network for skin cancer detection
in IoT applications. <em>ARTMED</em>, <em>129</em>, 102299. (<a
href="https://doi.org/10.1016/j.artmed.2022.102299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin cancer is one of the dangerous types of cancer and the rate of death is increasing due to the lack of knowledge in prevention and the symptoms. It is a common cancer type around the world and it occurs when the skin cells are damaged. Hence, the detection of skin cancer near the beginning is important to prevent the spread of cancer and to increase the survival rate . Recently, image processing and machine learning techniques gained more interest in medical applications. However, early analysis of skin cancer images is very challenging due to factors, like variations in the color illumination, light reflections from the skin surface, and different sizes and shapes of lesions. To detect skin cancer at an early stage and to increase the survival rate , an effective skin cancer detection method is introduced in this study using the proposed Fractional Student Psychology Based Optimization-based Deep Q Network (FSPBO-based DQN) in the wireless network scenario. At first, the nodes simulated in the network area are allowed to capture the healthcare information to make the detection strategy using the proposed method. Then, the routing is performed by the proposed Fractional Student Psychology Based Optimization (FSPBO) algorithm by considering the fitness parameters, like distance, energy, trust, and delay. After the images (healthcare information) are reached the Base Station (BS), the pre-processing, segmentation, and cancer detection processes are carried out to detect the skin lesions . Initially, the image is fed to pre-processing phase, where a Type II Fuzzy System and cuckoo search optimization algorithm (T2FCS) filter is employed to remove the noise of images. Then, the pre-processed images are fed to the segmentation phase, where speech enhancement Generative Adversarial Network (SeGAN) is used to generate the segmented results . Afterward, the Deep Q Network (DQN) detects the skin cancer based on the segmented results, and the training of DQN is made using the proposed FSPBO algorithm, which is designed by integrating the Student Psychology Based Optimization (SPBO) and Fractional Calculus (FC). The proposed method is more robust and reduces computation time and complexity. Moreover, the proposed method achieved higher performance by considering the measures, namely accuracy, sensitivity, and specificity with the values of 92.364%, 93.20%, and 92.63%.},
  archive      = {J_ARTMED},
  author       = {K. Suresh Kumar and N. Suganthi and Satish Muppidi and B. Santhosh Kumar},
  doi          = {10.1016/j.artmed.2022.102299},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {102299},
  shortjournal = {Artif. Intell. Med.},
  title        = {FSPBO-DQN: SeGAN based segmentation and fractional student psychology optimization enabled deep q network for skin cancer detection in IoT applications},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multilabel classification of medical concepts for patient
clinical profile identification. <em>ARTMED</em>, <em>128</em>, 102311.
(<a href="https://doi.org/10.1016/j.artmed.2022.102311">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of electronic health records has provided a large volume of unstructured biomedical information. Extracting patient characteristics from these data has become a major challenge, especially in languages other than English. Inspired by the French Text Mining Challenge (DEFT 2021) [1] in which we participated, our study proposes a multilabel classification of clinical narratives, allowing us to automatically extract the main features of a patient report. Our system is an end-to-end pipeline from raw text to labels with two main steps: named entity recognition and multilabel classification. Both steps are based on a neural network architecture based on transformers. To train our final classifier, we extended the dataset with all English and French Unified Medical Language System (UMLS) vocabularies related to human diseases. We focus our study on the multilingualism of training resources and models, with experiments combining French and English in different ways (multilingual embeddings or translation). We obtained an overall average micro-F1 score of 0.811 for the multilingual version, 0.807 for the French-only version and 0.797 for the translated version. Our study proposes an original multilabel classification of French clinical notes for patient phenotyping. We show that a multilingual algorithm trained on annotated real clinical notes and UMLS vocabularies leads to the best results.},
  archive      = {J_ARTMED},
  author       = {Christel Gérardin and Perceval Wajsbürt and Pascal Vaillant and Ali Bellamine and Fabrice Carrat and Xavier Tannier},
  doi          = {10.1016/j.artmed.2022.102311},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {102311},
  shortjournal = {Artif. Intell. Med.},
  title        = {Multilabel classification of medical concepts for patient clinical profile identification},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Medical checkup data analysis method based on LiNGAM and its
application to nonalcoholic fatty liver disease. <em>ARTMED</em>,
<em>128</em>, 102310. (<a
href="https://doi.org/10.1016/j.artmed.2022.102310">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although medical checkup data would be useful for identifying unknown factors of disease progression , a causal relationship between checkup items should be taken into account for precise analysis. Missing values in medical checkup data must be appropriately imputed because checkup items vary from person to person, and items that have not been tested include missing values. In addition, the patients with target diseases or disorders are small in comparison with the total number of persons recorded in the data, which means medical checkup data is an imbalanced data analysis. We propose a new method for analyzing the causal relationship in medical checkup data to discover disease progression factors based on a linear non-Gaussian acyclic model (LiNGAM), a machine learning technique for causal inference. In the proposed method, specific regression coefficients calculated through LiNGAM were compared to estimate the causal strength of the checkup items on disease progression, which is referred to as LiNGAM-beta. We also propose an analysis framework consisting of LiNGAM-beta, collaborative filtering (CF), and a sampling approach for causal inference of medical checkup data. CF and the sampling approach are useful for missing value imputation and balancing of the data distribution. We applied the proposed analysis framework to medical checkup data for identifying factors of Nonalcoholic fatty liver disease (NAFLD) development. The checkup items related to metabolic syndrome and age showed high causal effects on NAFLD severity. The level of blood urea nitrogen (BUN) would have a negative effect on NAFLD severity. Snoring frequency, which is associated with obstructive sleep apnea , affected NAFLD severity, particularly in the male group. Sleep duration also affected NAFLD severity in persons over fifty years old. These analysis results are consistent with previous reports about the causes of NAFLD; for example, NAFLD and metabolic syndrome are mutual and bi-directionally related, and BUN has a negative effect on NAFLD progression. Thus, our analysis result is plausible. The proposed analysis framework including LiNGAM-beta can be applied to various medical checkup data and will contribute to discovering unknown disease factors.},
  archive      = {J_ARTMED},
  author       = {Tsuyoshi Uchida and Koichi Fujiwara and Kenichi Nishioji and Masao Kobayashi and Manabu Kano and Yuya Seko and Kanji Yamaguchi and Yoshito Itoh and Hiroshi Kadotani},
  doi          = {10.1016/j.artmed.2022.102310},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {102310},
  shortjournal = {Artif. Intell. Med.},
  title        = {Medical checkup data analysis method based on LiNGAM and its application to nonalcoholic fatty liver disease},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intelligent and strong robust CVS-LVAD control based on
soft-actor-critic algorithm. <em>ARTMED</em>, <em>128</em>, 102308. (<a
href="https://doi.org/10.1016/j.artmed.2022.102308">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Left ventricular assist device (LVAD) is an effective method to treat ventricular failure. According to the physiological conditions of different patients, the device adaptively adjusts its rotation speed to change LVAD output. In this study, a physiological control system for LVAD based on deep reinforcement learning (DRL) is proposed. The system estimates the amount of blood required by LVAD based on a Starling-like method. The DRL controller regulates LVAD to adjust the speed and quickly approach the target value. The changes of vascular resistance, myocardial contractility, and the transition from rest to exercise were simulated, and the single factor and mixed factor experiments were carried out to compare the effects of DRL controller and proportional integral derivative (PID) controller, which controls the system according to the difference between measured variables and expected values. Two metrics are used to illustrate the regulation effect: the sum of absolute error (SAE) and the response time of the two controllers, where SAE is the difference between the estimated required pumped blood flow LVADQ e and the actual measured blood flow LVADQ m . The experimental result shows that the SAE of the DRL controller is 47.6% of that of the PID controller, and the response time of the DRL controller is 38.6% of that of the PID controller. This study demonstrates that the LVAD based on the DRL controller can respond more quickly and more effectively to the different physiological needs of a variety of patients than a PID controller.},
  archive      = {J_ARTMED},
  author       = {Te Li and Wenbo Cui and Nan Xie and Heng Li and Haibo Liu and Xu Li and Yongqing Wang},
  doi          = {10.1016/j.artmed.2022.102308},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {102308},
  shortjournal = {Artif. Intell. Med.},
  title        = {Intelligent and strong robust CVS-LVAD control based on soft-actor-critic algorithm},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Assigning diagnosis codes using medication history.
<em>ARTMED</em>, <em>128</em>, 102307. (<a
href="https://doi.org/10.1016/j.artmed.2022.102307">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diagnosis assignment is the process of assigning disease codes to patients. Automatic diagnosis assignment has the potential to validate code assignments, correct erroneous codes, and register completion. Previous methods build on text-based techniques utilizing medical notes but are inapplicable in the absence of these notes. We propose using patients&#39; medication data to assign diagnosis codes. We present a proof-of-concept study using medical data from an American dataset (MIMIC-III) and Danish nationwide registers to train a machine-learning-based model that predicts an extensive collection of diagnosis codes for multiple levels of aggregation over a disease hierarchy. We further suggest a specialized loss function designed to utilize the innate hierarchical nature of the disease hierarchy. We evaluate the proposed method on a subset of 567 disease codes. Moreover, we investigate the technique&#39;s generalizability and transferability by (1) training and testing models on the same subsets of disease codes over the two medical datasets and (2) training models on the American dataset while evaluating them on the Danish dataset, respectively. Results demonstrate the proposed method can correctly assign diagnosis codes on multiple levels of aggregation from the disease hierarchy over the American dataset with recall 70.0% and precision 69.48% for top-10 assigned codes; thereby being comparable to text-based techniques. Furthermore, the specialized loss function performs consistently better than the non-hierarchical state-of-the-art version. Moreover, results suggest the proposed method is language and dataset-agnostic, with initial indications of transferability over subsets of disease codes.},
  archive      = {J_ARTMED},
  author       = {Emil Riis Hansen and Tomer Sagi and Katja Hose and Gregory Y.H. Lip and Torben Bjerregaard Larsen and Flemming Skjøth},
  doi          = {10.1016/j.artmed.2022.102307},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {102307},
  shortjournal = {Artif. Intell. Med.},
  title        = {Assigning diagnosis codes using medication history},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). It’s the data, stupid: Inflection point for artificial
intelligence in indian healthcare. <em>ARTMED</em>, <em>128</em>,
102300. (<a href="https://doi.org/10.1016/j.artmed.2022.102300">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Indian healthcare is fast growing and with significant chunk of it being in small, fragmented, informal sector; Artificial Intelligence (AI) is pegged as a magical tool for a better healthcare system. There is an inclination to merely mimic the US approach in the on-going policy making and legislative exercises, which can have serious fallouts for Indian healthcare. India needs a different approach to suite her unique requirements. In this regard, each of the five stages in AI development lifecycle has been analyzed in the light of current on-ground realities. These boil down to three fold challenges of how to increase adoption of digital health , prevent data silos and create maximum value from data. Availability of quality data for value addition without barriers and restrictions is the common denominator for leveraging the full potential of AI. This requires liberal policies enabling secondary use of data in developing countries with rapidly growing healthcare sector akin to India. This has to be carefully balanced with data privacy and security. Restrictive healthcare data policies and laws can slow down adoption of digitization, perpetuate status-quo, be biased towards the incumbent players, cause Industry stagnation and thus will do more harm than good. It is therefore the data policies that will make or break AI in Indian healthcare.},
  archive      = {J_ARTMED},
  author       = {Anjali Ramaswamy and Naveen R. Gowda and H. Vikas and Meghana Prabhu and D.K. Sharma and Praveen R. Gowda and Deepak Mohan and Atul Kumar},
  doi          = {10.1016/j.artmed.2022.102300},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {102300},
  shortjournal = {Artif. Intell. Med.},
  title        = {It&#39;s the data, stupid: Inflection point for artificial intelligence in indian healthcare},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Understanding what patients think about hospitals: A deep
learning approach for detecting emotions in patient opinions.
<em>ARTMED</em>, <em>128</em>, 102298. (<a
href="https://doi.org/10.1016/j.artmed.2022.102298">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most hospital assessment systems are based on the study of objective statistical variables as well as patient opinions on their experiences with respect to the services offered by each hospital. Nevertheless, studies have indicated that most of these assessment systems fail to detect patient emotions when they are assessing their stays in a hospital. This information is vital to understanding most of the patient reviews, which are very complex and convey several emotions per review. Therefore, this study aimed to address the problem of detecting multiple emotions from patient reviews. First, a large set of patient opinions was collected from a website that allowed patients to publish their experiences when visiting hospitals. Second, each opinion was labeled with the corresponding conveyed emotions. Third, a deep learning architecture based on a bidirectional gated recurrent unit with a multichannel convolutional neural network layer was proposed to detect multiple emotions from these reviews. Finally, the hyperparameters of this architecture were fine-tuned and different pretrained word embedding models were configured to test its performance. The results confirmed that our proposed method outperformed other deep learning and machine learning-based algorithms and achieved an average accuracy of 95.82%. Furthermore, the experiments show that clinical-domain word embedding slightly outperforms other general-domain word embeddings, although general-domain embeddings are larger in terms of dimensions. The combination of the gated recurrent unit and the multichannel convolutional neural network is able to exploit both semantic and syntactic characteristics of patient opinions. The findings of this study identify research gaps related to areas such as opinion-based hospital recommendations, thereby providing future research directions.},
  archive      = {J_ARTMED},
  author       = {Jesus Serrano-Guerrero and Mohammad Bani-Doumi and Francisco P. Romero and Jose A. Olivas},
  doi          = {10.1016/j.artmed.2022.102298},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {102298},
  shortjournal = {Artif. Intell. Med.},
  title        = {Understanding what patients think about hospitals: A deep learning approach for detecting emotions in patient opinions},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine learning-based heart disease diagnosis: A systematic
literature review. <em>ARTMED</em>, <em>128</em>, 102289. (<a
href="https://doi.org/10.1016/j.artmed.2022.102289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heart disease is one of the significant challenges in today&#39;s world and one of the leading causes of many deaths worldwide. Recent advancement of machine learning (ML) application demonstrates that using electrocardiogram (ECG) and patients&#39; data, detecting heart disease during the early stage is feasible. However, both ECG and patients&#39; data are often imbalanced, which ultimately raises a challenge for the traditional ML to perform unbiasedly. Over the years, several data level and algorithm level solutions have been exposed by many researchers and practitioners. To provide a broader view of the existing literature, this study takes a systematic literature review (SLR) approach to uncover the challenges associated with imbalanced data in heart diseases predictions. Before that, we conducted a meta-analysis using 451 reference literature acquired from the reputed journals between 2012 and November 15, 2021. For in-depth analysis, 49 referenced literature has been considered and studied, taking into account the following factors: heart disease type, algorithms, applications, and solutions. Our SLR study revealed that the current approaches encounter various open problems/issues when dealing with imbalanced data, eventually hindering their practical applicability and functionality. In the diagnosis of heart disease, machine learning approaches help to improve data-driven decision-making. A metadata analysis of 451 articles and content analysis of 49 selected articles of heart disease diagnosis. Researchers primarily concentrated on enhancing the performance of the models while disregarding other issues such as the interpretability and explainability of Machine learning algorithms .},
  archive      = {J_ARTMED},
  author       = {Md Manjurul Ahsan and Zahed Siddique},
  doi          = {10.1016/j.artmed.2022.102289},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {102289},
  shortjournal = {Artif. Intell. Med.},
  title        = {Machine learning-based heart disease diagnosis: A systematic literature review},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial intelligence for forecasting and diagnosing
COVID-19 pandemic: A focused review. <em>ARTMED</em>, <em>128</em>,
102286. (<a href="https://doi.org/10.1016/j.artmed.2022.102286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The outbreak of novel corona virus 2019 (COVID-19) has been treated as a public health crisis of global concern by the World Health Organization (WHO). COVID-19 pandemic hugely affected countries worldwide raising the need to exploit novel, alternative and emerging technologies to respond to the emergency created by the weak health-care systems. In this context, Artificial Intelligence (AI) techniques can give a valid support to public health authorities, complementing traditional approaches with advanced tools. This study provides a comprehensive review of methods, algorithms, applications, and emerging AI technologies that can be utilized for forecasting and diagnosing COVID-19. The main objectives of this review are summarized as follows. (i) Understanding the importance of AI approaches such as machine learning and deep learning for COVID-19 pandemic; (ii) discussing the efficiency and impact of these methods for COVID-19 forecasting and diagnosing; (iii) providing an extensive background description of AI techniques to help non-expert to better catch the underlying concepts; (iv) for each work surveyed, give a detailed analysis of the rationale behind the approach, highlighting the method used, the type and size of data analyzed, the validation method, the target application and the results achieved; (v) focusing on some future challenges in COVID-19 forecasting and diagnosing.},
  archive      = {J_ARTMED},
  author       = {Carmela Comito and Clara Pizzuti},
  doi          = {10.1016/j.artmed.2022.102286},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {102286},
  shortjournal = {Artif. Intell. Med.},
  title        = {Artificial intelligence for forecasting and diagnosing COVID-19 pandemic: A focused review},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Early identification of ICU patients at risk of
complications: Regularization based on robustness and stability of
explanations. <em>ARTMED</em>, <em>128</em>, 102283. (<a
href="https://doi.org/10.1016/j.artmed.2022.102283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this study is to build machine learning models to predict severe complications using administrative and clinical elements that are collected immediately after patient admission to the intensive care unit (ICU). Risk models are of increasing importance in the ICU setting. However, they generally present the black-box issue because they do not provide meaningful information about the logic involved in patient-specific predictions. Fortunately, effective algorithms exist for explaining black-box models, and in practice, they offer valuable explanations for model predictions. These explanations are becoming essential to engender trust and accreditation to the model. However, once the model is implemented, a major issue is whether it will continue to employ the same prediction logic as originally intended to. To build our models, features are obtained from patient administrative data, laboratory results and vital signs available within the first hour after ICU admission. This enables our models to provide great anticipation because complications can occur at any moment during ICU stay. To build models that continue to work as originally designed we first propose to measure (i) how the provided explanations vary for different inputs (that is, robustness), and (ii) how the provided explanations change with models built from different patient sub-populations (that is, stability). Second, we employ these measures as regularization terms that are coupled with a feature selection procedure such that the final model provides predictions with more robust and stable explanations. Experiments were conducted on a dataset containing 6000 ICU admissions of 5474 patients. Results obtained on an external validation cohort of 1069 patients with 1086 ICU admissions showed that selecting features based on robustness led to gains in terms of predictive power that varied from 6.8% to 9.4%, whereas selecting features based on stability led to gains that varied from 7.2% to 11.5%, depending on the target complication. Our results are of practical importance as our models predict complications with great anticipation, thus facilitating timely and protective interventions.},
  archive      = {J_ARTMED},
  author       = {Tiago Amador and Saulo Saturnino and Adriano Veloso and Nivio Ziviani},
  doi          = {10.1016/j.artmed.2022.102283},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {102283},
  shortjournal = {Artif. Intell. Med.},
  title        = {Early identification of ICU patients at risk of complications: Regularization based on robustness and stability of explanations},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Radiology report generation for proximal femur fractures
using deep classification and language generation models.
<em>ARTMED</em>, <em>128</em>, 102281. (<a
href="https://doi.org/10.1016/j.artmed.2022.102281">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proximal femur fractures represent a major health concern, and substantially contribute to the morbidity of elderly. Correct classification and diagnosis of hip fractures has a significant impact on mortality, costs and hospital stay. In this paper, we present a method and empirical validation for automatic subclassification of proximal femur fractures and Dutch radiological report generation that does not rely on manually curated data. The fracture classification model was trained on 11,000 X-ray images obtained from 5000 electronic health records in a general hospital. To generate the Dutch reports, we first trained an embedding model on 20,000 radiological reports of pelvic region fractures, and used its embeddings in the report generation model. We trained the report generation model on the 5000 radiological reports associated with the fracture cases. Our report generation model is on par with state-of-the-art in terms of BLEU and ROUGE scores. This is promising, because in contrast to those earlier works, our approach does not require manual preprocessing of either images or the reports. This boosts the applicability of automatic clinical report generation in practice. A quantitative and qualitative user study among medical students found no significant difference in provenance of real and generated reports. A qualitative, in-depth clinical relevance study with medical domain experts showed that from a human perspective the quality of the generated reports approximates the quality of the original reports and highlights challenges in creating sufficiently detailed and versatile training data for automatic radiology report generation.},
  archive      = {J_ARTMED},
  author       = {Olivier Paalvast and Meike Nauta and Marion Koelle and Jeroen Geerdink and Onno Vijlbrief and Johannes H. Hegeman and Christin Seifert},
  doi          = {10.1016/j.artmed.2022.102281},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {102281},
  shortjournal = {Artif. Intell. Med.},
  title        = {Radiology report generation for proximal femur fractures using deep classification and language generation models},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial intelligence-inspired comprehensive framework for
covid-19 outbreak control. <em>ARTMED</em>, <em>127</em>, 102288. (<a
href="https://doi.org/10.1016/j.artmed.2022.102288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 is a life-threatening contagious virus that has spread across the globe rapidly. To reduce the outbreak impact of COVID-19 virus illness, continual identification and remote surveillance of patients are essential. Medical service delivery based on the Internet of Things (IoT) technology backed up by the fog-cloud paradigm is an efficient and time-sensitive solution for remote patient surveillance . Conspicuously, a comprehensive framework based on Radio Frequency Identification Device (RFID) and body-wearable sensor technologies supported by the fog-cloud platform is proposed for the identification and management of COVID-19 patients. The J48 decision tree is used to assess the infection degree of the user based on corresponding symptoms. RFID is used to detect Temporal Proximity Interactions (TPI) among users. Using TPI quantification, Temporal Network Analysis is used to analyze and track the current stage of the COVID-19 spread. The statistical performance and accuracy of the framework are assessed by utilizing synthetically-generated data for 250,000 users. Based on the comparative analysis, the proposed framework acquired an enhanced measure of classification accuracy , and sensitivity of 96.68% and 94.65% respectively. Moreover, significant improvement has been registered for proposed fog-cloud-based data analysis in terms of Temporal Delay efficacy, Precision, and F-measure.},
  archive      = {J_ARTMED},
  author       = {Munish Bhatia and Ankush Manocha and Tariq Ahamed Ahanger and Abdullah Alqahtani},
  doi          = {10.1016/j.artmed.2022.102288},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102288},
  shortjournal = {Artif. Intell. Med.},
  title        = {Artificial intelligence-inspired comprehensive framework for covid-19 outbreak control},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CapillaryNet: An automated system to quantify skin capillary
density and red blood cell velocity from handheld vital microscopy.
<em>ARTMED</em>, <em>127</em>, 102287. (<a
href="https://doi.org/10.1016/j.artmed.2022.102287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Capillaries are the smallest vessels in the body which are responsible for delivering oxygen and nutrients to surrounding cells. Various life-threatening diseases are known to alter the density of healthy capillaries and the flow velocity of erythrocytes within the capillaries. In previous studies, capillary density and flow velocity were manually assessed by trained specialists. However, manual analysis of a standard 20-s microvascular video requires 20 min on average and necessitates extensive training. Thus, manual analysis has been reported to hinder the application of microvascular microscopy in a clinical environment. To address this problem, this paper presents a fully automated state-of-the-art system to quantify skin nutritive capillary density and red blood cell velocity captured by handheld-based microscopy videos. The proposed method combines the speed of traditional computer vision algorithms with the accuracy of convolutional neural networks to enable clinical capillary analysis. The results show that the proposed system fully automates capillary detection with an accuracy exceeding that of trained analysts and measures several novel microvascular parameters that had eluded quantification thus far, namely, capillary hematocrit and intracapillary flow velocity heterogeneity. The proposed end-to-end system, named CapillaryNet, can detect capillaries at ~0.9 s per frame with ~93% accuracy. The system is currently used as a clinical research product in a larger e-health application to analyse capillary data captured from patients suffering from COVID-19, pancreatitis, and acute heart diseases. CapillaryNet narrows the gap between the analysis of microcirculation images in a clinical environment and state-of-the-art systems.},
  archive      = {J_ARTMED},
  author       = {Maged Abdalla Helmy Abdou and Tuyen Trung Truong and Anastasiya Dykyy and Paulo Ferreira and Eric Jul},
  doi          = {10.1016/j.artmed.2022.102287},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102287},
  shortjournal = {Artif. Intell. Med.},
  title        = {CapillaryNet: An automated system to quantify skin capillary density and red blood cell velocity from handheld vital microscopy},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). BreastScreening-AI: Evaluating medical intelligent agents
for human-AI interactions. <em>ARTMED</em>, <em>127</em>, 102285. (<a
href="https://doi.org/10.1016/j.artmed.2022.102285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we developed BreastScreening-AI within two scenarios for the classification of multimodal beast images: (1) Clinician-Only ; and (2) Clinician-AI . The novelty relies on the introduction of a deep learning method into a real clinical workflow for medical imaging diagnosis. We attempt to address three high-level goals in the two above scenarios. Concretely, how clinicians: i) accept and interact with these systems, revealing whether are explanations and functionalities required; ii) are receptive to the introduction of AI-assisted systems, by providing benefits from mitigating the clinical error; and iii) are affected by the AI assistance. We conduct an extensive evaluation embracing the following experimental stages: (a) patient selection with different severities, (b) qualitative and quantitative analysis for the chosen patients under the two different scenarios. We address the high-level goals through a real-world case study of 45 clinicians from nine institutions. We compare the diagnostic and observe the superiority of the Clinician-AI scenario, as we obtained a decrease of 27% for False-Positives and 4% for False-Negatives. Through an extensive experimental study, we conclude that the proposed design techniques positively impact the expectations and perceptive satisfaction of 91% clinicians, while decreasing the time-to-diagnose by 3 min per patient.},
  archive      = {J_ARTMED},
  author       = {Francisco Maria Calisto and Carlos Santiago and Nuno Nunes and Jacinto C. Nascimento},
  doi          = {10.1016/j.artmed.2022.102285},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102285},
  shortjournal = {Artif. Intell. Med.},
  title        = {BreastScreening-AI: Evaluating medical intelligent agents for human-AI interactions},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Word-level text highlighting of medical texts for telehealth
services. <em>ARTMED</em>, <em>127</em>, 102284. (<a
href="https://doi.org/10.1016/j.artmed.2022.102284">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The medical domain is often subject to information overload. The digitization of healthcare, constant updates to online medical repositories, and increasing availability of biomedical datasets make it challenging to effectively analyze the data. This creates additional workload for medical professionals who are heavily dependent on medical data to complete their research and consult their patients. This paper aims to show how different text highlighting techniques can capture relevant medical context. This would reduce the doctors&#39; cognitive load and response time to patients by facilitating them in making faster decisions, thus improving the overall quality of online medical services. Three different word-level text highlighting methodologies are implemented and evaluated. The first method uses Term Frequency - Inverse Document Frequency (TF-IDF) scores directly to highlight important parts of the text. The second method is a combination of TF-IDF scores, Word2Vec and the application of Local Interpretable Model-Agnostic Explanations to classification models . The third method uses neural networks directly to make predictions on whether or not a word should be highlighted. Our numerical study shows that the neural network approach is successful in highlighting medically-relevant terms and its performance is improved as the size of the input segment increases.},
  archive      = {J_ARTMED},
  author       = {Ozan Ozyegen and Devika Kabe and Mucahit Cevik},
  doi          = {10.1016/j.artmed.2022.102284},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102284},
  shortjournal = {Artif. Intell. Med.},
  title        = {Word-level text highlighting of medical texts for telehealth services},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Chinese clinical named entity recognition via multi-head
self-attention based BiLSTM-CRF. <em>ARTMED</em>, <em>127</em>, 102282.
(<a href="https://doi.org/10.1016/j.artmed.2022.102282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clinical named entity recognition (CNER) is a fundamental step for many clinical Natural Language Processing (NLP) systems, which aims to recognize and classify clinical entities such as diseases, symptoms, exams, body parts and treatments in clinical free texts. In recent years, with the development of deep learning technology, deep neural networks (DNNs) have been widely used in Chinese clinical named entity recognition and many other clinical NLP tasks . However, these state-of-the-art models failed to make full use of the global information and multi-level semantic features in clinical texts. We design an improved character-level representation approach which integrates the character embedding and the character-label embedding to enhance the specificity and diversity of feature representations. Then, a multi-head self-attention based Bi-directional Long Short-Term Memory Conditional Random Field (MUSA-BiLSTM-CRF) model is proposed. By introducing the multi-head self-attention and combining a medical dictionary, the model can more effectively capture the weight relationships between characters and multi-level semantic feature information, which is expected to greatly improve the performance of Chinese clinical named entity recognition. We evaluate our model on two CCKS challenge (CCKS2017 Task 2 and CCKS2018 Task 1) benchmark datasets and the experimental results show that our proposed model achieves the best performance competing with the state-of-the-art DNN based methods.},
  archive      = {J_ARTMED},
  author       = {Ying An and Xianyun Xia and Xianlai Chen and Fang-Xiang Wu and Jianxin Wang},
  doi          = {10.1016/j.artmed.2022.102282},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102282},
  shortjournal = {Artif. Intell. Med.},
  title        = {Chinese clinical named entity recognition via multi-head self-attention based BiLSTM-CRF},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fall risk assessment through a synergistic multi-source DNN
learning model. <em>ARTMED</em>, <em>127</em>, 102280. (<a
href="https://doi.org/10.1016/j.artmed.2022.102280">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Falls are a complex problem and play a leading role in the development of disabilities in the older population. While fall detection systems are important, it is also essential to work on fall preventive strategies, which will have the most significant impact in reducing disability in the elderly. In this work, we explore a prospective cohort study , specifically designed for examining novel risk factors for falls in community-living older adults. Various types of data were acquired that are common for real-world applications. Learning from multiple data sources often leads to more valuable findings than any of the data sources can provide alone. However, simply merging features from disparate datasets usually will not produce a synergy effect . Hence, it becomes crucial to properly manage the synergy, complementarity, and conflicts that arise in multi-source learning. In this work, we propose a multi-source learning approach called the Synergy LSTM model , which exploits complementarity among textual fall descriptions together with people&#39;s physical characteristics. We further use the learned complementarities to evaluate fall risk factors present in the data. Experiment results show that our Synergy LSTM model can significantly improve classification performance and capture meaningful relations between data from multiple sources.},
  archive      = {J_ARTMED},
  author       = {Olga Andreeva and Wei Ding and Suzanne G. Leveille and Yurun Cai and Ping Chen},
  doi          = {10.1016/j.artmed.2022.102280},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102280},
  shortjournal = {Artif. Intell. Med.},
  title        = {Fall risk assessment through a synergistic multi-source DNN learning model},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic sleep stage classification: A light and efficient
deep neural network model based on time, frequency and fractional
fourier transform domain features. <em>ARTMED</em>, <em>127</em>,
102279. (<a href="https://doi.org/10.1016/j.artmed.2022.102279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposed a novel method for automatic sleep stage classification based on the time, frequency, and fractional Fourier transform (FRFT) domain features extracted from a single-channel electroencephalogram (EEG). Bidirectional long short-term memory was applied to the proposed model to train it to learn the sleep stage transition rules according to the American Academy of Sleep Medicine&#39;s manual for automatic sleep stage classification. Results indicated that the features extracted from the fractional Fourier-transformed single-channel EEG may improve the performance of sleep stage classification. For the Fpz-Cz EEG of Sleep-EDF with 30 s epochs, the overall accuracy of the model increased by circa 1% with the help of the FRFT domain features and even reached 81.6%. This work thus made the application of FRFT to automatic sleep stage classification possible. The parameters of the proposed model measured 0.31 MB, which are 5% of those of DeepSleepNet, but its performance is similar to that of DeepSleepNet. Hence, the proposed model is a light and efficient model based on deep neural networks , which also has a prospect for on-device machine learning.},
  archive      = {J_ARTMED},
  author       = {Yuyang You and Xuyang Zhong and Guozheng Liu and Zhihong Yang},
  doi          = {10.1016/j.artmed.2022.102279},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102279},
  shortjournal = {Artif. Intell. Med.},
  title        = {Automatic sleep stage classification: A light and efficient deep neural network model based on time, frequency and fractional fourier transform domain features},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fermatean fuzzy ELECTRE multi-criteria group decision-making
and most suitable biomedical material selection. <em>ARTMED</em>,
<em>127</em>, 102278. (<a
href="https://doi.org/10.1016/j.artmed.2022.102278">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ELECTRE is a family of multi-criteria decision analysis techniques, which has the ability to provide as much as possible precise and suitable set of actions or alternatives to the underlying problem by eliminating the alternatives, which are outranked by others. Group decision-making is an effective process to provide the most appropriate solution to real-world decision-making scenarios by considering and merging the expert opinions of multiple individuals on the problem. The aim of this study is to present an extended version of the ELECTRE I model called the Fermatean fuzzy ELECTRE I method for of multi-criteria group decision-making with Fermatean fuzzy human assessments. The method proposed in this study has the possibility to solve multi-criteria group decision-making problems by using the Fermatean fuzzy decision matrix obtained in Fermatean fuzzy number form in the evaluations made with the available alternatives based on expert opinions. First, the mathematical description of the multi-criteria group decision-making problem with Fermatean fuzzy information has been given. Then, the proposed Fermatean fuzzy ELECTRE I method to deal with the problem has been presented. After the determination of the relative importance degree of experts, the Fermatean fuzzy aggregated averaging operator is employed to merge the individual Fermatean fuzzy decision matrices produced by the experts into the aggregated Fermatean fuzzy decision matrix. Next, for pairwise comparison of available alternatives with respect to considered criteria, the concepts of Fermatean fuzzy strong, midrange, and weak concordance and discordance sets are based on the approach of score function and accuracy function defined for Fermatean fuzzy numbers. Afterward, Fermatean fuzzy concordance and discordance matrices are defined, constructed by concordance and discordance indices. Finally, Fermatean fuzzy effective concordance and discordance matrices are computed to obtain Fermatean fuzzy aggregated outranking matrix, indicating abstract information on dominations of suitable alternatives to the others. The proposed method will be used in material selection in distinct implementations, exclusively in biomedical applications where the prosthesis materials should have similar characteristics to human tissues. Since biomedical materials are used in various parts of the human body for many different purposes, in this study, material selection will be made using the method presented for the femoral component of the hip joint prosthesis for orthopedists and practitioners who will choose biomaterials.},
  archive      = {J_ARTMED},
  author       = {Murat Kirişci and Ibrahim Demir and Necip Şimşek},
  doi          = {10.1016/j.artmed.2022.102278},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102278},
  shortjournal = {Artif. Intell. Med.},
  title        = {Fermatean fuzzy ELECTRE multi-criteria group decision-making and most suitable biomedical material selection},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel multi-objective medical feature selection compass
method for binary classification. <em>ARTMED</em>, <em>127</em>, 102277.
(<a href="https://doi.org/10.1016/j.artmed.2022.102277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of Artificial Intelligence in medical decision support systems has been widely studied. Since a medical decision is frequently the result of a multi-objective optimization problem , a popular challenge combining Artificial Intelligence and Medicine is Multi-Objective Feature Selection ( MOFS ). This article proposes a novel approach for MOFS applied to medical binary classification . It is built upon a Genetic Algorithm and a 3-Dimensional Compass that aims at guiding the search towards a desired trade-off between: Number of features, Accuracy and Area Under the ROC Curve ( AUC ). This method, the Genetic Algorithm with multi-objective Compass ( GAwC ), outperforms all other competitive genetic algorithm-based MOFS approaches on several real-world medical datasets. Moreover, by considering AUC as one of the objectives, GAwC guarantees the classification quality of the solution it provides thus making it a particularly interesting approach for medical problems where both healthy and ill patients should be accurately detected. Finally, GAwC is applied to a real-world medical classification problem and its results are discussed and justified both from a medical point of view and in terms of classification quality.},
  archive      = {J_ARTMED},
  author       = {Nicolas Gutowski and Daniel Schang and Olivier Camp and Pierre Abraham},
  doi          = {10.1016/j.artmed.2022.102277},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102277},
  shortjournal = {Artif. Intell. Med.},
  title        = {A novel multi-objective medical feature selection compass method for binary classification},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Breast cancer detection using artificial intelligence
techniques: A systematic literature review. <em>ARTMED</em>,
<em>127</em>, 102276. (<a
href="https://doi.org/10.1016/j.artmed.2022.102276">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cancer is one of the most dangerous diseases to humans, and yet no permanent cure has been developed for it. Breast cancer is one of the most common cancer types . According to the National Breast Cancer Foundation, in 2020 alone, more than 276,000 new cases of invasive breast cancer and more than 48,000 non-invasive cases were diagnosed in the US. To put these figures in perspective, 64% of these cases are diagnosed early in the disease&#39;s cycle, giving patients a 99% chance of survival. Artificial intelligence and machine learning have been used effectively in detection and treatment of several dangerous diseases, helping in early diagnosis and treatment, and thus increasing the patient&#39;s chance of survival. Deep learning has been designed to analyze the most important features affecting detection and treatment of serious diseases. For example, breast cancer can be detected using genes or histopathological imaging. Analysis at the genetic level is very expensive, so histopathological imaging is the most common approach used to detect breast cancer. In this research work, we systematically reviewed previous work done on detection and treatment of breast cancer using genetic sequencing or histopathological imaging with the help of deep learning and machine learning. We also provide recommendations to researchers who will work in this field.},
  archive      = {J_ARTMED},
  author       = {Ali Bou Nassif and Manar Abu Talib and Qassim Nasir and Yaman Afadar and Omar Elgendy},
  doi          = {10.1016/j.artmed.2022.102276},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102276},
  shortjournal = {Artif. Intell. Med.},
  title        = {Breast cancer detection using artificial intelligence techniques: A systematic literature review},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exemplar darknet19 feature generation technique for
automated kidney stone detection with coronal CT images.
<em>ARTMED</em>, <em>127</em>, 102274. (<a
href="https://doi.org/10.1016/j.artmed.2022.102274">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kidney stone is a commonly seen ailment and is usually detected by urologists using computed tomography (CT) images. It is difficult and time-consuming to detect small stones in CT images. Hence, an automated system can help clinicians to detect kidney stones accurately. In this work, a novel transfer learning-based image classification method (ExDark19) has been proposed to detect kidney stones using CT images. The iterative neighborhood component analysis (INCA) is employed to select the most informative feature vectors and these selected features vectors are fed to the k nearest neighbor (kNN) classifier to detect kidney stones with a ten-fold cross-validation (CV) strategy. The proposed ExDark19 model yielded an accuracy of 99.22% with 10-fold CV and 99.71% using the hold-out validation method. Our results demonstrate that the proposed ExDark19 detect kidney stones over 99% accuracies for two validation techniques. This developed automated system can assist the urologists to validate their manual screening of kidney stones and hence reduce the possible human error.},
  archive      = {J_ARTMED},
  author       = {Mehmet Baygin and Orhan Yaman and Prabal Datta Barua and Sengul Dogan and Turker Tuncer and U. Rajendra Acharya},
  doi          = {10.1016/j.artmed.2022.102274},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102274},
  shortjournal = {Artif. Intell. Med.},
  title        = {Exemplar darknet19 feature generation technique for automated kidney stone detection with coronal CT images},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FlauBERT vs. CamemBERT: Understanding patient’s answers by a
french medical chatbot. <em>ARTMED</em>, <em>127</em>, 102264. (<a
href="https://doi.org/10.1016/j.artmed.2022.102264">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a number of circumstances, obtaining health-related information from a patient is time-consuming, whereas a chatbot interacting efficiently with that patient might help saving health care professional time and better assisting the patient. Making a chatbot understand patients&#39; answers uses Natural Language Understanding (NLU) technology that relies on ‘intent’ and ‘slot’ predictions. Over the last few years, language models (such as BERT) pre-trained on huge amounts of data achieved state-of-the-art intent and slot predictions by connecting a neural network architecture (e.g., linear, recurrent, long short-term memory, or bidirectional long short-term memory) and fine-tuning all language model and neural network parameters end-to-end. Currently, two language models are specialized in French language : FlauBERT and CamemBERT. This study was designed to find out which combination of language model and neural network architecture was the best for intent and slot prediction by a chatbot from a French corpus of clinical cases. The comparisons showed that FlauBERT performed better than CamemBERT whatever the network architecture used and that complex architectures did not significantly improve performance vs. simple ones whatever the language model. Thus, in the medical field, the results support recommending FlauBERT with a simple linear network architecture.},
  archive      = {J_ARTMED},
  author       = {Corentin Blanc and Alexandre Bailly and Élie Francis and Thierry Guillotin and Fadi Jamal and Béchara Wakim and Pascal Roy},
  doi          = {10.1016/j.artmed.2022.102264},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102264},
  shortjournal = {Artif. Intell. Med.},
  title        = {FlauBERT vs. CamemBERT: Understanding patient&#39;s answers by a french medical chatbot},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel methodology for head and neck carcinoma treatment
stage detection by means of model checking. <em>ARTMED</em>,
<em>127</em>, 102263. (<a
href="https://doi.org/10.1016/j.artmed.2022.102263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Head and neck cancers are diagnosed at an annual rate of 3% to 7% with respect to the total number of cancers, and 50% to 75% of such new tumours occur in the upper aerodigestive tract. In this paper we propose formal methods based approach aimed to identify the head and neck tumour treatment stage by means of model checking. We exploit a set of radiomic features to model medical imaging as a labelled transition system to verify treatment stage properties. We experiment the proposed method using a public dataset related to computed tomography images obtained in different treatment stages, reaching an accuracy ranging from 0.924 to 0.978 in treatment stage detection. The study confirms the effectiveness of the adoption of formal methods in the head and neck carcinoma treatment stage detection to support radiologists and pathologists .},
  archive      = {J_ARTMED},
  author       = {Luca Brunese and Francesco Mercaldo and Alfonso Reginelli and Antonella Santone},
  doi          = {10.1016/j.artmed.2022.102263},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102263},
  shortjournal = {Artif. Intell. Med.},
  title        = {A novel methodology for head and neck carcinoma treatment stage detection by means of model checking},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A method for the early prediction of chronic diseases based
on short sequential medical data. <em>ARTMED</em>, <em>127</em>, 102262.
(<a href="https://doi.org/10.1016/j.artmed.2022.102262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Noncommunicable diseases (NCDs) have become the leading cause of death worldwide. NCDs&#39; chronicity , hiddenness, and irreversibility make patients&#39; disease self-awareness extremely important in disease control but hard to achieve. With an accumulation of electronic health record (EHR) data, it has become possible to predict NCDs early through machine learning approaches . However, EHR data from latent NCD patients are often irregularly sampled temporally, and the data sequences are short and imbalanced, which prevents researchers from fully and effectively using such data. Here, we outline the characteristics of typical short sequential data for NCD early prediction and emphasize the importance of using such data in machine learning schemes . We then propose a novel NCD early prediction method: the short sequential medical data-based early prediction method (SSEPM). The SSEPM network contains two stacked subnetworks for multilabel enhancement. In each subnetwork, long short-term memory (LSTM) and attention layers are implemented to extract both temporal and nontemporal embedded features. During training, with prior clinical knowledge of the NCD characteristics, a random connection (RC) process is proposed for data augmentation . Comparative experiments involving ten-fold cross-validation are performed with real-world medical data to predict 5 NCDs. The result shows that the SSEPM outperforms the state-of-the-art NCD early prediction algorithms and works well in dealing with short sequential data. The results also suggest that the direct use of short sequential data could be more effective than formatting datasets with temporal exclusion limitations.},
  archive      = {J_ARTMED},
  author       = {Chengkai Wu and Tianshu Zhou and Yu Tian and Junya Wu and Jingsong Li and Zhong Liu},
  doi          = {10.1016/j.artmed.2022.102262},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {102262},
  shortjournal = {Artif. Intell. Med.},
  title        = {A method for the early prediction of chronic diseases based on short sequential medical data},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detection of bladder cancer with feature fusion, transfer
learning and CapsNets. <em>ARTMED</em>, <em>126</em>, 102275. (<a
href="https://doi.org/10.1016/j.artmed.2022.102275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper confronts two approaches to classify bladder lesions shown in white light cystoscopy images when using small datasets: the classical one, where handcrafted-based features feed pattern recognition systems and the modern deep learning-based (DL) approach. In between, there are alternative DL models that had not received wide attention from the scientific community, even though they can be more appropriate for small datasets such as the human brain motivated capsule neural networks (CapsNets). However, CapsNets have not yet matured hence presenting lower performances than the most classic DL models. These models require higher computational resources , more computational skills from the physician and are more prone to overfitting, making them sometimes prohibitive in the routine of clinical practice. This paper shows that carefully handcrafted features used with more robust models can reach similar performances to the conventional DL-based models and deep CapsNets, making them more useful for clinical applications. Concerning feature extraction, it is proposed a new feature fusion approach for Ta and T1 bladder tumor detection by using decision fusion from multiple classifiers in a scheme known as stacking of classifiers. Three Neural Networks perform classification on three different feature sets, namely: Covariance of Color Histogram of Oriented Gradients, proposed in the ambit of this paper; Local Binary Patterns and Wavelet Coefficients taken from lower scales. Data diversity is ensured by a fourth Neural Network, which is used for decision fusion by combining the outputs of the ensemble elements to produce the classifier output. Both Feed Forward Neural Networks and Radial Basis Functions are used in the experiments. Contrarily, DL-based models extract automatically the best features at the cost of requiring huge amounts of training data , which in turn can be alleviated by using the Transfer Learning (TL) strategy. In this paper VGG16 and ResNet-34 pretrained in ImageNet were used for TL, slightly outperforming the proposed ensemble. CapsNets may overcome CNNs given their ability to deal with objects rotational invariance and spatial relationships. Therefore, they can be trained from scratch in applications using small amounts of data, which was beneficial for the current case, improving accuracy from 94.6% to 96.9%.},
  archive      = {J_ARTMED},
  author       = {Nuno R. Freitas and Pedro M. Vieira and Agostinho Cordeiro and Catarina Tinoco and Nuno Morais and João Torres and Sara Anacleto and M. Pilar Laguna and Estevão Lima and Carlos S. Lima},
  doi          = {10.1016/j.artmed.2022.102275},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {102275},
  shortjournal = {Artif. Intell. Med.},
  title        = {Detection of bladder cancer with feature fusion, transfer learning and CapsNets},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Weak label based bayesian u-net for optic disc segmentation
in fundus images. <em>ARTMED</em>, <em>126</em>, 102261. (<a
href="https://doi.org/10.1016/j.artmed.2022.102261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fundus images have been widely used in routine examinations of ophthalmic diseases. For some diseases, the pathological changes mainly occur around the optic disc area; therefore, detection and segmentation of the optic disc are critical pre-processing steps in fundus image analysis. Current machine learning based optic disc segmentation methods typically require manual segmentation of the optic disc for the supervised training. However, it is time consuming to annotate pixel-level optic disc masks and inevitably induces inter-subject variance. To address these limitations, we propose a weak label based Bayesian U-Net exploiting Hough transform based annotations to segment optic discs in fundus images. To achieve this, we build a probabilistic graphical model and explore a Bayesian approach with the state-of-the-art U-Net framework. To optimize the model, the expectation-maximization algorithm is used to estimate the optic disc mask and update the weights of the Bayesian U-Net, alternately. Our evaluation demonstrates strong performance of the proposed method compared to both fully- and weakly-supervised baselines.},
  archive      = {J_ARTMED},
  author       = {Hao Xiong and Sidong Liu and Roneel V. Sharan and Enrico Coiera and Shlomo Berkovsky},
  doi          = {10.1016/j.artmed.2022.102261},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {102261},
  shortjournal = {Artif. Intell. Med.},
  title        = {Weak label based bayesian U-net for optic disc segmentation in fundus images},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-modal fusion framework based on multi-task
correlation learning for cancer prognosis prediction. <em>ARTMED</em>,
<em>126</em>, 102260. (<a
href="https://doi.org/10.1016/j.artmed.2022.102260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Morphological attributes from histopathological images and molecular profiles from genomic data are important information to drive diagnosis, prognosis, and therapy of cancers. By integrating these heterogeneous but complementary data, many multi-modal methods are proposed to study the complex mechanisms of cancers, and most of them achieve comparable or better results from previous single-modal methods. However, these multi-modal methods are restricted to a single task (e.g., survival analysis or grade classification), and thus neglect the correlation between different tasks. In this study, we present a multi-modal fusion framework based on multi-task correlation learning (MultiCoFusion) for survival analysis and cancer grade classification, which combines the power of multiple modalities and multiple tasks. Specifically, a pre-trained ResNet-152 and a sparse graph convolutional network (SGCN) are used to learn the representations of histopathological images and mRNA expression data respectively. Then these representations are fused by a fully connected neural network (FCNN), which is also a multi-task shared network. Finally, the results of survival analysis and cancer grade classification output simultaneously. The framework is trained by an alternate scheme. We systematically evaluate our framework using glioma datasets from The Cancer Genome Atlas (TCGA). Results demonstrate that MultiCoFusion learns better representations than traditional feature extraction methods. With the help of multi-task alternating learning, even simple multi-modal concatenation can achieve better performance than other deep learning and traditional methods. Multi-task learning can improve the performance of multiple tasks not just one of them, and it is effective in both single-modal and multi-modal data.},
  archive      = {J_ARTMED},
  author       = {Kaiwen Tan and Weixian Huang and Xiaofeng Liu and Jinlong Hu and Shoubin Dong},
  doi          = {10.1016/j.artmed.2022.102260},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {102260},
  shortjournal = {Artif. Intell. Med.},
  title        = {A multi-modal fusion framework based on multi-task correlation learning for cancer prognosis prediction},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Lesion-attention pyramid network for diabetic retinopathy
grading. <em>ARTMED</em>, <em>126</em>, 102259. (<a
href="https://doi.org/10.1016/j.artmed.2022.102259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the most common diabetic complications , diabetic retinopathy (DR) can cause retinal damage , vision loss and even blindness. Automated DR grading technology has important clinical significance, which can help ophthalmologists achieve rapid and early diagnosis. With the popularity of deep learning , DR grading based on the convolutional neural networks (CNNs) has become the mainstream method. Unfortunately, although the CNN-based method can achieve satisfactory diagnostic accuracy , it lacks significant clinical information. In this paper, a lesion-attention pyramid network (LAPN) is presented. The pyramid network integrates the subnetworks with different resolutions to get multi-scale features. In order to take the lesion regions in the high-resolution image as the diagnostic evidence, the low-resolution network calculates the lesion activation map (using the weakly-supervised localization method) and guides the high-resolution network to concentrate on the lesion regions. Furthermore, a lesion attention module (LAM) is designed to capture the complementary relationship between the high-resolution features and the low-resolution features, and to fuse the lesion activation map. Experiment results show that the proposed scheme outperforms other existing approaches, and the proposed method can provide lesion activation map with lesion consistency as an additional evidence for clinical diagnosis.},
  archive      = {J_ARTMED},
  author       = {Xiang Li and Yuchen Jiang and Jiusi Zhang and Minglei Li and Hao Luo and Shen Yin},
  doi          = {10.1016/j.artmed.2022.102259},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {102259},
  shortjournal = {Artif. Intell. Med.},
  title        = {Lesion-attention pyramid network for diabetic retinopathy grading},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spatio-temporal mixture process estimation to detect
dynamical changes in population. <em>ARTMED</em>, <em>126</em>, 102258.
(<a href="https://doi.org/10.1016/j.artmed.2022.102258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Population monitoring is a challenge in many areas such as public health and ecology. We propose a method to model and monitor population distributions over space and time, in order to build an alert system for spatio-temporal data changes. Assuming that mixture models can correctly model populations, we propose a new version of the Expectation-Maximization (EM) algorithm to better estimate the number of clusters and their parameters at the same time. This algorithm is compared to existing methods on several simulated datasets. We then combine the algorithm with a temporal statistical model, allowing for the detection of dynamical changes in population distributions, and call the result a spatio-temporal mixture process (STMP). We test STMPs on synthetic data , and consider several different behaviors of the distributions, to fit this process. Finally, we validate STMPs on a real data set of positive diagnosed patients to coronavirus disease 2019. We show that our pipeline correctly models evolving real data and detects epidemic changes.},
  archive      = {J_ARTMED},
  author       = {Solange Pruilh and Anne-Sophie Jannot and Stéphanie Allassonnière},
  doi          = {10.1016/j.artmed.2022.102258},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {102258},
  shortjournal = {Artif. Intell. Med.},
  title        = {Spatio-temporal mixture process estimation to detect dynamical changes in population},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic pediatric congenital heart disease classification
based on heart sound signal. <em>ARTMED</em>, <em>126</em>, 102257. (<a
href="https://doi.org/10.1016/j.artmed.2022.102257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Congenital heart diseases (CHD) are the most common birth defects , and the early diagnosis of CHD is crucial for CHD therapy. However, there are relatively few studies on intelligent auscultation for pediatric CHD, due to the fact that effective cooperation of the patient is required for the acquisition of useable heart sounds by electronic stethoscopes, yet the quality of heart sounds in pediatric is poor compared to adults due to the factors such as crying and breath sounds. This paper presents a novel pediatric CHD intelligent auscultation method based on electronic stethoscope. Firstly, a pediatric CHD heart sound database with a total of 941 PCG signal is established. Then a segment-based heart sound segmentation algorithm is proposed, which is based on PCG segment to achieve the segmentation of cardiac cycles, and therefore can reduce the influence of local noise to the global. Finally, the accurate classification of CHD is achieved using a majority voting classifier with Random Forest and Adaboost classifier based on 84 features containing time domain and frequency domain. Experimental results show that the performance of the proposed method is competitive, and the accuracy, sensitivity, specificity and f1-score of classification for CHD are 0.953, 0.946, 0.961 and 0.953 respectively.},
  archive      = {J_ARTMED},
  author       = {Weize Xu and Kai Yu and Jingjing Ye and Haomin Li and Jiajia Chen and Fei Yin and Jingfang Xu and Jihua Zhu and Die Li and Qiang Shu},
  doi          = {10.1016/j.artmed.2022.102257},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {102257},
  shortjournal = {Artif. Intell. Med.},
  title        = {Automatic pediatric congenital heart disease classification based on heart sound signal},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving vascular access creation among hemodialysis
patients: An agent-based modeling and simulation approach.
<em>ARTMED</em>, <em>126</em>, 102253. (<a
href="https://doi.org/10.1016/j.artmed.2022.102253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chronic kidney disease is a worldwide public health problem, and vascular access is known as hemodialysis patients&#39; lifeline. Hemodialysis is the most common treatment for kidney replacement. The choice of vascular access should be “patient-centered.” However, the preferred or optimal type of vascular access that is generally recommended by clinical guidelines for hemodialysis patients is a native Arteriovenous Fistula (AVF). Despite the recommendations of the guidelines, unfortunately, many hemodialysis patients undergo dialysis through the catheter. Thus, this issue must be controlled by healthcare providers to reduce the adverse events of choosing this access for patients. As such, the prevalence of the concept of “first fistula , catheter last,” identification of barriers to catheterization and effective factors in the use of native venous arterial fistula , as well as evaluating its impact on improving health and quality of life should be considered. To this aim, we have developed an agent-based simulation to investigate the effects of different agents on this process, as well as plan to achieve the desired status for improving and optimizing vascular access creation and maintenance. The decisions and behaviors of the stakeholders (agents) play a critical role in hemodialysis processes, so we have simulated their behaviors and decisions that are the most essential factor in establishing the system&#39;s status. To understand and evaluate the current situation, several experts, including nephrologists , surgeons, and dialysis nurses have been recruited to detect the factors influencing this process plus the relevant stakeholders, and their roles and effects. Our study has shown that agent-based modeling has a great potential in developing a simulation model to improve vascular access creation among hemodialysis patients.},
  archive      = {J_ARTMED},
  author       = {Seyedeh Fatemeh Mousavi and Mohammad Mehdi Sepehri and Roghaye Khasha and Seyed Hamzeh Mousavi},
  doi          = {10.1016/j.artmed.2022.102253},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {102253},
  shortjournal = {Artif. Intell. Med.},
  title        = {Improving vascular access creation among hemodialysis patients: An agent-based modeling and simulation approach},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel lifelong machine learning-based method to eliminate
calibration drift in clinical prediction models. <em>ARTMED</em>,
<em>125</em>, 102256. (<a
href="https://doi.org/10.1016/j.artmed.2022.102256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clinical prediction models (CPMs) constructed based on artificial intelligence have been proven to have positive impacts on clinical activities. However, the deterioration of CPM performance over time has rarely been studied. This paper proposes a model updating method to solve the calibration drift issue caused by data drift. This paper proposes a novel model updating method based on lifelong machine learning (LML). The effectiveness of the proposed method is verified in four tumor datasets, and a comprehensive comparison with other model updating methods is performed. Changes in data distributions cause model performances to drift. The four compared model updating methods have different effects in terms of improving the discrimination and calibration abilities of the tested models. The LML method proposed in this study improves model performance better than or equivalent to the other methods. The proposed method achieved a mean AUC of 0.8249, 0.8780, 0.8261, and 0.8489, a mean AUPRC of 0.7782, 0.9730, 0.4655, and 0.5728, a mean F1 of 0.6866, 0.9552, 0.2985, and 0.3585, and a mean estimated calibration index (ECI) of 0.0320, 0.0338, 0.0101, and 0.0115 using colorectal , lung, breast and prostate cancer datasets. The LML framework simultaneously monitors model performance and the distribution of disease risk characteristics, enabling it to effectively address the performance degradation caused by gradual and sudden data drifts and provide reasonable explanations for the causes of performance degradation . Monitoring model performance and the underlying data distribution can promote model life cycle iteration with “development-deployment-maintenance-monitoring” as the core, which, in turn, ensures that the model can provide accurate predictions, guides the model update process and explains the causes of model performance changes.},
  archive      = {J_ARTMED},
  author       = {Shengqiang Chi and Yu Tian and Feng Wang and Tianshu Zhou and Shan Jin and Jingsong Li},
  doi          = {10.1016/j.artmed.2022.102256},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {102256},
  shortjournal = {Artif. Intell. Med.},
  title        = {A novel lifelong machine learning-based method to eliminate calibration drift in clinical prediction models},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Brain gray matter nuclei segmentation on quantitative
susceptibility mapping using dual-branch convolutional neural network.
<em>ARTMED</em>, <em>125</em>, 102255. (<a
href="https://doi.org/10.1016/j.artmed.2022.102255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abnormal iron accumulation in the brain subcortical nuclei has been reported to be correlated to various neurodegenerative diseases , which can be measured through the magnetic susceptibility from the quantitative susceptibility mapping (QSM). To quantitatively measure the magnetic susceptibility , the nuclei should be accurately segmented, which is a tedious task for clinicians. In this paper, we proposed a dual-branch residual-structured U-Net (DB-ResUNet) based on 3D convolutional neural network (CNN) to automatically segment such brain gray matter nuclei. Due to memory limit, 3D-CNN-based methods typically adopted image patches, instead of the whole volumetric image, which, however, ignored the spatial contextual information of the neighboring patches, and therefore led to the accuracy loss. To better tradeoff segmentation accuracy and the memory efficiency, the proposed DB-ResUNet incorporated patches with different resolutions. By jointly using QSM and 3D T 1 weighted imaging (T 1 WI) as inputs, the proposed method was able to achieve better segmentation accuracy over its single-branch counterpart, as well as the conventional atlas-based method and the classical 3D CNN structures. The susceptibility values and the volumes were also measured, which indicated that the measurements from the proposed DB-ResUNet was able to present high correlation with values from the manually annotated regions of interest.},
  archive      = {J_ARTMED},
  author       = {Chao Chai and Pengchong Qiao and Bin Zhao and Huiying Wang and Guohua Liu and Hong Wu and Wen Shen and Chen Cao and Xinchen Ye and Zhiyang Liu and Shuang Xia},
  doi          = {10.1016/j.artmed.2022.102255},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {102255},
  shortjournal = {Artif. Intell. Med.},
  title        = {Brain gray matter nuclei segmentation on quantitative susceptibility mapping using dual-branch convolutional neural network},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ISSMF: Integrated semantic and spatial information of
multi-level features for automatic segmentation in prenatal ultrasound
images. <em>ARTMED</em>, <em>125</em>, 102254. (<a
href="https://doi.org/10.1016/j.artmed.2022.102254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an effective way of routine prenatal diagnosis , ultrasound (US) imaging has been widely used recently. Biometrics obtained from the fetal segmentation shed light on fetal health monitoring. However, the segmentation in US images has strict requirements for sonographers on accuracy, making this task quite time-consuming and tedious. In this paper, we use DeepLabv3+ as the backbone and propose an Integrated Semantic and Spatial Information of Multi-level Features (ISSMF) based network to achieve the automatic and accurate segmentation of four parts of the fetus in US images while most of the previous works only segment one or two parts. Our contributions are threefold. First, to incorporate semantic information of high-level features and spatial information of low-level features of US images, we introduce a multi-level feature fusion module to integrate the features at different scales. Second, we propose to leverage the content-aware reassembly of features (CARAFE) upsampler to deeply explore the semantic and spatial information of multi-level features. Third, in order to alleviate performance degradation caused by batch normalization (BN) when batch size is small, we use group normalization (GN) instead. Experiments on four parts of fetus in US images show that our method outperforms the U-Net, DeepLabv3+ and the U-Net++ and the biometric measurements based on our segmentation results are pretty close to those derived from sonographers with ten-year work experience .},
  archive      = {J_ARTMED},
  author       = {Yihao Sun and Hongjian Yang and Jiliu Zhou and Yan Wang},
  doi          = {10.1016/j.artmed.2022.102254},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {102254},
  shortjournal = {Artif. Intell. Med.},
  title        = {ISSMF: Integrated semantic and spatial information of multi-level features for automatic segmentation in prenatal ultrasound images},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Comment on “finding reduced raman spectroscopy fingerprint
of skin samples for melanoma diagnosis through machine learning.”
<em>ARTMED</em>, <em>125</em>, 102252. (<a
href="https://doi.org/10.1016/j.artmed.2022.102252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper comments on the article “Finding reduced Raman spectroscopy fingerprint of skin samples for melanoma diagnosis through machine learning” by D. C. Araújo et al. The authors apply Raman spectroscopy for the classification of benign and malignant skin neoplasms based on their Raman spectra. Despite the high performance of the proposed technique it may provide unreasonably high accuracy because of incorrect cross-validation procedure. To confirm the possibility to discriminate neoplasm skin tissues based on Raman spectra analysis the authors should provide additional data regarding utilized cross-validation procedure.},
  archive      = {J_ARTMED},
  author       = {Ivan A. Bratchenko and Lyudmila A. Bratchenko},
  doi          = {10.1016/j.artmed.2022.102252},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {102252},
  shortjournal = {Artif. Intell. Med.},
  title        = {Comment on “Finding reduced raman spectroscopy fingerprint of skin samples for melanoma diagnosis through machine learning”},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Subtle anomaly detection: Application to brain MRI analysis
of de novo parkinsonian patients. <em>ARTMED</em>, <em>125</em>, 102251.
(<a href="https://doi.org/10.1016/j.artmed.2022.102251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of recent deep learning techniques, computerized methods for automatic lesion segmentation have reached performances comparable to those of medical practitioners. However, little attention has been paid to the detection of subtle physiological changes caused by evolutive pathologies, such as neurodegenerative diseases . In this work, we leverage deep learning models to detect anomalies in brain diffusion tensor imaging (DTI) parameter maps of recently diagnosed and untreated ( de novo ) patients with Parkinson&#39;s disease (PD). For this purpose, we trained auto-encoders on parameter maps of healthy controls ( n = 56) and tested them on those of de novo PD patients ( n = 129). We considered large reconstruction errors between the original and reconstructed images to be anomalies that, when quantified, allow discerning between de novo PD patients and healthy controls. The most discriminating brain macro-region was found to be the white matter with a ROC-AUC 68.3 (IQR 5.4) and the best subcortical structure , the GPi (ROC-AUC 62.6 IQR 5.4). Our results indicate that our deep learning-based model can detect potentially pathological regions in de novo PD patients, without requiring any expert delineation. This may enable extracting neuroimaging biomarkers of PD in the future, but further testing on larger cohorts is needed. Such models can be seamlessly extended with additional parameter maps and applied to study the physio-pathology of other neurological diseases .},
  archive      = {J_ARTMED},
  author       = {Verónica Muñoz-Ramírez and Virgilio Kmetzsch and Florence Forbes and Sara Meoni and Elena Moro and Michel Dojat},
  doi          = {10.1016/j.artmed.2022.102251},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {102251},
  shortjournal = {Artif. Intell. Med.},
  title        = {Subtle anomaly detection: Application to brain MRI analysis of de novo parkinsonian patients},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pathologic liver tumor detection using feature aligned
multi-scale convolutional network. <em>ARTMED</em>, <em>125</em>,
102244. (<a href="https://doi.org/10.1016/j.artmed.2022.102244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of the most common type of liver tumor, that is, hepatocellular carcinoma (HCC), is one essential step to liver pathology image analysis. In liver tissue, common cell change phenomena such as apoptosis , necrosis, and steatosis are similar in tumor and benign tissue. Hence, the detection of HCC may fail when the patches covered only limited tissue region without enough neighboring cell structure information. To address this problem, a Feature Aligned Multi-Scale Convolutional Network (FA-MSCN) architecture is proposed in this paper for automatic liver tumor detection based on whole slide images (WSI). The proposed network integrates the features obtained at different magnification levels to improve the detection performance by referencing more neighboring information. The FA-MSCN consists of two parallel convolutional networks in which one would extract high-resolution features and the other would extract low-resolution features by atrous convolution. The low-resolution features then go through central cropping, upsampling, and concatenation with high-resolution features for final classification. The experimental results demonstrated that Multi-Scale Convolutional Network (MSCN) improves the detection performance compared to Single-Scale Convolutional Network (SSCN), and that the FA-MSCN is superior to both SSCN and MSCN, demonstrating on HCC detection.},
  archive      = {J_ARTMED},
  author       = {Tsung-Lung Yang and Hung-Wen Tsai and Wei-Che Huang and Jung-Chia Lin and Jia-Bin Liao and Nan-Haw Chow and Pau-Choo Chung},
  doi          = {10.1016/j.artmed.2022.102244},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {102244},
  shortjournal = {Artif. Intell. Med.},
  title        = {Pathologic liver tumor detection using feature aligned multi-scale convolutional network},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-scale keypoint estimation network with
self-supervision for spinal curvature assessment of idiopathic scoliosis
from the imperfect dataset. <em>ARTMED</em>, <em>125</em>, 102235. (<a
href="https://doi.org/10.1016/j.artmed.2021.102235">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Idiopathic scoliosis (IS) is a common lifetime disease, which exhibits an obvious deformity of spinal curvature to seriously affect heart and lung function. Accurate radiographic assessment of spinal curvature is vitally important for the clinical diagnosis and treatment planning of idiopathic scoliosis. Deep learning algorithms have been widely adopted to the medical image analysis with the remarkable advancement in computer vision . The automated methods can improve the efficiency of clinical diagnosis to relieve the burden of doctors, which have advantage in dealing with the tedious and repetitive tasks. However, existing methods usually require sufficiently large training datasets with strict annotation, which are costly and laborious especially for medical images. Moreover, the medical images of serious IS always contain the blurry and occlusive parts, which would make the accurate and robust estimation of the spinal curvature more difficult. In this paper, a dot annotation approach is presented to train the spinal curvature assessment model, rather than using strict annotation of IS X-ray images. We develop a multi-scale keypoint estimation network to reduce the requirement for large training datasets, in which the Squeeze-and-Excitation (SE) blocks are incorporated to improve the representational capacity of the model. Then, a self-supervision module is designed to alleviate the blurry and occlusive problem, and we use the two-view radiographic assessments of IS to generate a 3D spinal curvature. Finally, extensive experiments are conducted on a collected clinical dataset, in which we obtain 81.5 AP and the average E d between the predicted keypoints and the ground truths is 0.43, making an improvement over the mainstream approaches.},
  archive      = {J_ARTMED},
  author       = {Tianyu Liu and Yu Wang and Yukang Yang and Ming Sun and Wenhui Fan and Cody Bunger and Cheng Wu},
  doi          = {10.1016/j.artmed.2021.102235},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {102235},
  shortjournal = {Artif. Intell. Med.},
  title        = {A multi-scale keypoint estimation network with self-supervision for spinal curvature assessment of idiopathic scoliosis from the imperfect dataset},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ResAttenGAN: Simultaneous segmentation of multiple spinal
structures on axial lumbar MRI image using residual attention and
adversarial learning. <em>ARTMED</em>, <em>124</em>, 102243. (<a
href="https://doi.org/10.1016/j.artmed.2022.102243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An axial MRI image of the lumbar spine generally contains multiple spinal structures and their simultaneous segmentation will help analyze the pathogenesis of the spinal disease, generate the spinal medical report, and make a clinical surgery plan for the treatment of the spinal disease. However, it is still a challenging issue that multiple spinal structures are segmented simultaneously and accurately because of the large diversities of the same spinal structure in intensity, resolution, position, shape, and size, the implicit borders between different structures, and the overfitting problem caused by the insufficient training data . In this paper, we propose a novel network framework ResAttenGAN to address these challenges and achieve the simultaneous and accurate segmentation of disc, neural foramina, thecal sac, and posterior arch. ResAttenGAN comprises three modules, i.e. full feature fusion (FFF) module, residual refinement attention (RRA) module, and adversarial learning (AL) module. The FFF module captures multi-scale feature information and fully fuse the features at all hierarchies for generating the discriminative feature representation. The RRA module is made up of a local position attention block and a residual border refinement block to accurately locate the implicit borders and refine their pixel-wise classification. The AL module smooths and strengthens the higher-order spatial consistency to solve the overfitting problem. Experimental results show that the three integrated modules in ResAttenGAN have advantages in tackling the above challenges and ResAttenGAN outperforms the existing segmentation methods under evaluation metrics .},
  archive      = {J_ARTMED},
  author       = {Hao Gong and Jianhua Liu and Bo Chen and Shuo Li},
  doi          = {10.1016/j.artmed.2022.102243},
  journal      = {Artificial Intelligence in Medicine},
  month        = {2},
  pages        = {102243},
  shortjournal = {Artif. Intell. Med.},
  title        = {ResAttenGAN: Simultaneous segmentation of multiple spinal structures on axial lumbar MRI image using residual attention and adversarial learning},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhancing dynamic ECG heartbeat classification with
lightweight transformer model. <em>ARTMED</em>, <em>124</em>, 102236.
(<a href="https://doi.org/10.1016/j.artmed.2022.102236">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Arrhythmia is a common class of Cardiovascular disease which is the cause for over 31% of all death over the world, according to WHOs&#39; report. Automatic detection and classification of arrhythmia, as an effective tool of early warning, has recently been received more and more attention, especially in the applications of wearable devices for data capturing. However, different from traditional application scenarios, wearable electrocardiogram (ECG) devices have some drawbacks, such as being subject to multiple abnormal interferences, thus making accurate ventricular contraction (PVC) and supraventricular premature beat (SPB) detection to be more challenging. The traditional models for heartbeat classification suffer from the problem of large-scale parameters and the performance in dynamic ECG heartbeat classification is not satisfactory. In this paper, we propose a novel light model Lightweight Fussing Transformer to address these problems. We developed a more lightweight structure named LightConv Attention (LCA) to replace the self-attention of Fussing Transformer. LCA has reached remarkable performance level equal to or higher than self-attention with fewer parameters. In particular, we designed a stronger embedding structure (Convolutional Neural Network with attention mechanism) to enhance the weight of features of internal morphology of the heartbeat. Furthermore, we have implemented the proposed methods on real datasets and experimental results have demonstrated outstanding accuracy of detecting PVC and SPB.},
  archive      = {J_ARTMED},
  author       = {Lingxiao Meng and Wenjun Tan and Jiangang Ma and Ruofei Wang and Xiaoxia Yin and Yanchun Zhang},
  doi          = {10.1016/j.artmed.2022.102236},
  journal      = {Artificial Intelligence in Medicine},
  month        = {2},
  pages        = {102236},
  shortjournal = {Artif. Intell. Med.},
  title        = {Enhancing dynamic ECG heartbeat classification with lightweight transformer model},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predicting liver cancers using skewed epidemiological data.
<em>ARTMED</em>, <em>124</em>, 102234. (<a
href="https://doi.org/10.1016/j.artmed.2021.102234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Liver Cancer is a threat to human health and life over the world. The key to reduce liver cancer incidence is to identify high-risk populations and carry out individualized interventions before cancer occurrence. Building predictive models based on machine learning algorithms is an effective and economical way to forecast potential liver cancers. However, since the dataset is usually extremely skewed (negative samples are much more than positive samples), machine learning models suffer from severe bias and make unreliable predictions. In this paper, we systematically evaluate existing approaches in tackling class-imbalance problem and introduce two undersampling methods. The first is based on K-means++, where robust clustering centers are appointed as negative samples. The second is based on learning vector quantization , which considers diagnostic labels during clustering, and the prototypes are used as negative data. In this way, positive and negative samples are rebalanced. The algorithm is applied to five-year liver cancer prediction in Early Diagnosis and Treatment of Urban Cancer project in China. We achieve an AUC of 0.76 when no clinical measure except for epidemiological information is used. Experimental results show the advantage of our method over existing oversampling, undersampling, ensemble algorithms, and state-of-the-art outlier detection algorithms. This work explores a feasible and practical roadmap to tackle skewed medical data in cancer prediction and benefits applications targeted to human health and well-being.},
  archive      = {J_ARTMED},
  author       = {Jinpeng Li and Yaling Tao and Huaiwei Cong and Enwei Zhu and Ting Cai},
  doi          = {10.1016/j.artmed.2021.102234},
  journal      = {Artificial Intelligence in Medicine},
  month        = {2},
  pages        = {102234},
  shortjournal = {Artif. Intell. Med.},
  title        = {Predicting liver cancers using skewed epidemiological data},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-stage machine learning model for diagnosis of
esophageal manometry. <em>ARTMED</em>, <em>124</em>, 102233. (<a
href="https://doi.org/10.1016/j.artmed.2021.102233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-resolution manometry (HRM) is the primary procedure used to diagnose esophageal motility disorders . Its manual interpretation and classification, including evaluation of swallow-level outcomes and then derivation of a study-level diagnosis based on Chicago Classification (CC), may be limited by inter-rater variability and inaccuracy of an individual interpreter. We hypothesized that an automatic diagnosis platform using machine learning and artificial intelligence approaches could be developed to accurately identify esophageal motility diagnoses. Further, a multi-stage modeling framework, akin to the step-wise approach of the CC, was utilized to leverage advantages of a combination of machine learning approaches including deep-learning models and feature-based models. Models were trained and tested using a dataset comprised of 1741 patients&#39; HRM studies with CC diagnoses assigned by expert physician raters. In the swallow-level stage, three models based on convolutional neural networks (CNNs) were developed to predict swallow type and swallow pressurization (test accuracies of 0.88 and 0.93, respectively), and integrated relaxation pressure (IRP)(regression model with test error of 4.49 mmHg). At the study-level stage, model selection from families of the expert-knowledge-based rule models, xgboost models and artificial neural network(ANN) models were conducted. A simple model-agnostic strategy of model balancing motivated by Bayesian principles was utilized, which gave rise to model averaging weighted by precision scores. The averaged (blended) models and individual models were compared and evaluated, of which the best performance on test dataset is 0.81 in top-1 prediction, 0.92 in top-2 predictions. This is the first artificial-intelligence style model to automatically predict esophageal motility (CC) diagnoses from HRM studies using raw multi-swallow data and it achieved high accuracy. Thus, this proposed modeling framework could be broadly applied to assist with HRM interpretation in a clinical setting.},
  archive      = {J_ARTMED},
  author       = {Wenjun Kou and Dustin A. Carlson and Alexandra J. Baumann and Erica N. Donnan and Jacob M. Schauer and Mozziyar Etemadi and John E. Pandolfino},
  doi          = {10.1016/j.artmed.2021.102233},
  journal      = {Artificial Intelligence in Medicine},
  month        = {2},
  pages        = {102233},
  shortjournal = {Artif. Intell. Med.},
  title        = {A multi-stage machine learning model for diagnosis of esophageal manometry},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel transfer learning model for traditional herbal
medicine prescription generation from unstructured resources and
knowledge. <em>ARTMED</em>, <em>124</em>, 102232. (<a
href="https://doi.org/10.1016/j.artmed.2021.102232">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional Chinese medicine (TCM) is an essential part of the world&#39;s traditional medicine . However, there are still many issues in the promotion and development of TCM, such as a lot of unique TCM treatments are taught only between the master and an apprentice in practice, it takes dozens of years for a TCM practitioner to master them and the complicated TCM treatment principles. Intelligent TCM models, as a promising method, can overcome these issues. The performance of previously proposed AI models for intelligent TCM is restricted since they rely on clinical medical records , which are limited, hard to collect, and unavailable for intelligent TCM researchers. In this work, we propose a two-stage transfer learning model to generate TCM prescriptions from a few medical records and TCM documentary resources, called TCMBERT for short. First, the TCMBERT is trained on TCM books. Then, it is fine-tuned on a limited number of medical records to generate TCM prescriptions. The experimental results show that the proposed model outperforms the state-of-the-art methods in all comparison baselines on the TCM prescription generation task. The TCMBERT and the training process can be used in TCM tasks and other medical tasks for dealing with textual resources.},
  archive      = {J_ARTMED},
  author       = {Zhi Liu and Changyong Luo and Dianzheng Fu and Jun Gui and Zeyu Zheng and Liang Qi and Haojian Guo},
  doi          = {10.1016/j.artmed.2021.102232},
  journal      = {Artificial Intelligence in Medicine},
  month        = {2},
  pages        = {102232},
  shortjournal = {Artif. Intell. Med.},
  title        = {A novel transfer learning model for traditional herbal medicine prescription generation from unstructured resources and knowledge},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RMS-UNet: Residual multi-scale UNet for liver and lesion
segmentation. <em>ARTMED</em>, <em>124</em>, 102231. (<a
href="https://doi.org/10.1016/j.artmed.2021.102231">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precise segmentation is in demand for hepatocellular carcinoma or metastasis clinical diagnosis due to the heterogeneous appearance and diverse anatomy of the liver on scanned abdominal computed tomography (CT) images. In this study, we present an automatic unified registration-free deep-learning-based model with residual block and dilated convolution for training end-to-end liver and lesion segmentation. A multi-scale approach has also been utilized to explore novel inter-slice features with multi-channel input images. A novel objective function is introduced to deal with fore- and background pixels imbalance based on the joint metric of dice coefficient and absolute volumetric difference. Further, batch normalization is used to improve the learning without any loss of useful information. The proposed methodology is extensively validated and tested on 30% of the publicly available Dircadb, LiTS, Sliver07, and Chaos datasets. A comparative analysis is conducted based on multiple evaluation metrics frequently used in segmentation competitions. The results show substantial improvement, with mean dice scores of 97.31 , 97.38 , 97.39 and 95.49% for the Dircadb, LiTS, Sliver07, and Chaos liver test sets, and 91.92 and 86.70% for Dircadb and LiTS lesion segmentation. It should be noted that we achieve the best lesion segmentation performance on common datasets. The obtained qualitative and quantitative results demonstrate that our proposed model outperform other state-of-the-art methods for liver and lesion segmentation, with competitive performance on additional datasets. Henceforth, it is envisaged as being applicable to pertinent medical segmentation applications.},
  archive      = {J_ARTMED},
  author       = {Rayyan Azam Khan and Yigang Luo and Fang-Xiang Wu},
  doi          = {10.1016/j.artmed.2021.102231},
  journal      = {Artificial Intelligence in Medicine},
  month        = {2},
  pages        = {102231},
  shortjournal = {Artif. Intell. Med.},
  title        = {RMS-UNet: Residual multi-scale UNet for liver and lesion segmentation},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The three ghosts of medical AI: Can the black-box present
deliver? <em>ARTMED</em>, <em>124</em>, 102158. (<a
href="https://doi.org/10.1016/j.artmed.2021.102158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our title alludes to the three Christmas ghosts encountered by Ebenezer Scrooge in A Christmas Carol , who guide Ebenezer through the past, present, and future of Christmas holiday events. Similarly, our article takes readers through a journey of the past, present, and future of medical AI. In doing so, we focus on the crux of modern machine learning: the reliance on powerful but intrinsically opaque models. When applied to the healthcare domain, these models fail to meet the needs for transparency that their clinician and patient end-users require. We review the implications of this failure, and argue that opaque models (1) lack quality assurance, (2) fail to elicit trust, and (3) restrict physician-patient dialogue. We then discuss how upholding transparency in all aspects of model design and model validation can help ensure the reliability and success of medical AI.},
  archive      = {J_ARTMED},
  author       = {Thomas P. Quinn and Stephan Jacobs and Manisha Senadeera and Vuong Le and Simon Coghlan},
  doi          = {10.1016/j.artmed.2021.102158},
  journal      = {Artificial Intelligence in Medicine},
  month        = {2},
  pages        = {102158},
  shortjournal = {Artif. Intell. Med.},
  title        = {The three ghosts of medical AI: Can the black-box present deliver?},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Training radiomics-based CNNs for clinical outcome
prediction: Challenges, strategies and findings. <em>ARTMED</em>,
<em>123</em>, 102230. (<a
href="https://doi.org/10.1016/j.artmed.2021.102230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiological images play a central role in radiotherapy , especially in target volume delineation. Radiomic feature extraction has demonstrated its potential for predicting patient outcome and cancer risk assessment prior to treatment. However, inherent methodological challenges such as severe class imbalance , small training sample size , multi-centre data and weak correlation of image representations to outcomes are yet to be addressed adequately. Current radiomic analysis relies on segmented images (e.g., of tumours) for feature extraction, leading to loss of important context information in surrounding tissue. In this work, we examine the correlation between radiomics and clinical outcomes by combining two data modalities: pre-treatment computerized tomography (CT) imaging data and contours of segmented gross tumour volumes (GTVs). We focus on a clinical head &amp; neck cancer dataset and design an efficient convolutional neural network (CNN) architecture together with appropriate machine learning strategies to cope with the challenges. During the training process on two cohorts, our algorithm learns to produce clinical outcome predictions by automatically extracting radiomic features. Test results on two other cohorts show state-of-the-art performance in predicting different clinical endpoints (i.e., distant metastasis : AUC = 0.91; loco-regional failure: AUC = 0.78; overall survival : AUC = 0.70 on segmented CT data) compared to prior studies. Furthermore, we also conduct extensive experiments both on the whole CT dataset and a combination of CT and GTV contours to investigate different learning strategies for this task. For example, further experiments indicate that overall survival prediction significantly improves to 0.83 AUC by combining CT and GTV contours as inputs, and the combination provides more intuitive visual explanations for patient outcome predictions.},
  archive      = {J_ARTMED},
  author       = {Shuchao Pang and Matthew Field and Jason Dowling and Shalini Vinod and Lois Holloway and Arcot Sowmya},
  doi          = {10.1016/j.artmed.2021.102230},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102230},
  shortjournal = {Artif. Intell. Med.},
  title        = {Training radiomics-based CNNs for clinical outcome prediction: Challenges, strategies and findings},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A dual-layer context-based architecture for the detection of
anomalous instructions sent to medical devices. <em>ARTMED</em>,
<em>123</em>, 102229. (<a
href="https://doi.org/10.1016/j.artmed.2021.102229">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex medical devices are controlled by instructions sent from a host personal computer (PC) to the device. Anomalous instructions can introduce many potentially harmful threats to patients (e.g., radiation overexposure), to physical device components (e.g., manipulation of device motors), or to functionality (e.g., manipulation of medical images). Threats can occur due to cyber-attacks, human error (e.g., using the wrong protocol, or misconfiguring the protocol&#39;s parameters by a technician), or host PC software bugs. Thus, anomalous instructions might represent an intentional threat to the patient or to the device, a human error, or simply a non-optimal operation of the device. To protect medical devices, we propose a new dual-layer architecture. The architecture analyzes the instructions sent from the host PC to the physical components of the device, to detect anomalous instructions using two detection layers: (1) an unsupervised context-free (CF) layer that detects anomalies based solely on the instruction&#39;s content and inter-correlations; and (2) a supervised context-sensitive (CS) layer that detects anomalies in both the clinical objective and patient contexts using a set of supervised classifiers pre-trained for each specific context. The proposed dual-layer architecture was evaluated in the computed tomography (CT) domain, using 4842 CT instructions that we recorded, including two types of CF anomalous instructions, four types of clinical objective context instructions and four types of patient context instructions. The CF layer was evaluated using 14 unsupervised anomaly detection algorithms. The CS layer was evaluated using six supervised classification algorithms applied to each context (i.e., clinical objective or patient). Adding the second CS supervised layer to the architecture improved the overall anomaly detection performance (by improving the detection of CS anomalous instructions [when they were not also CF anomalous]) from an F1 score baseline of 72.6%, to an improved F1 score of 79.1% to 99.5% (depending on the clinical objective or patient context used). Adding, the semantics-oriented CS layer enables the detection of CS anomalies using the semantics of the device&#39;s procedure, which is not possible when using just the purely syntactic CF layer. However, adding the CS layer also introduced a somewhat increased false positive rate (FPR), and thus reduced somewhat the specificity of the overall process. We conclude that by using both the CF and CS layers, a dual-layer architecture can better detect anomalous instructions to medical devices. The increased FPR might be reduced, in the future, through the use of stronger models, and by training them on more data. The improved accuracy, and the potential capability of adding explanations to both layers, might be useful for creating decision support systems for medical device technicians.},
  archive      = {J_ARTMED},
  author       = {Tom Mahler and Erez Shalom and Yuval Elovici and Yuval Shahar},
  doi          = {10.1016/j.artmed.2021.102229},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102229},
  shortjournal = {Artif. Intell. Med.},
  title        = {A dual-layer context-based architecture for the detection of anomalous instructions sent to medical devices},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Gene selection for microarray data classification via
multi-objective graph theoretic-based method. <em>ARTMED</em>,
<em>123</em>, 102228. (<a
href="https://doi.org/10.1016/j.artmed.2021.102228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent decades, the improvement of computer technology has increased the growth of high-dimensional microarray data . Thus, data mining methods for DNA microarray data classification usually involve samples consisting of thousands of genes. One of the efficient strategies to solve this problem is gene selection, which improves the accuracy of microarray data classification and also decreases computational complexity . In this paper, a novel social network analysis-based gene selection approach is proposed. The proposed method has two main objectives of the relevance maximization and redundancy minimization of the selected genes. In this method, on each iteration, a maximum community is selected repetitively. Then among the existing genes in this community, the appropriate genes are selected by using the node centrality-based criterion. The reported results indicate that the developed gene selection algorithm while increasing the classification accuracy of microarray data, will also decrease the time complexity.},
  archive      = {J_ARTMED},
  author       = {Mehrdad Rostami and Saman Forouzandeh and Kamal Berahmand and Mina Soltani and Meisam Shahsavari and Mourad Oussalah},
  doi          = {10.1016/j.artmed.2021.102228},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102228},
  shortjournal = {Artif. Intell. Med.},
  title        = {Gene selection for microarray data classification via multi-objective graph theoretic-based method},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Continuous action deep reinforcement learning for propofol
dosing during general anesthesia. <em>ARTMED</em>, <em>123</em>, 102227.
(<a href="https://doi.org/10.1016/j.artmed.2021.102227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anesthesiologists simultaneously manage several aspects of patient care during general anesthesia . Automating administration of hypnotic agents could enable more precise control of a patient&#39;s level of unconsciousness and enable anesthesiologists to focus on the most critical aspects of patient care. Reinforcement learning (RL) algorithms can be used to fit a mapping from patient state to a medication regimen. These algorithms can learn complex control policies that, when paired with modern techniques for promoting model interpretability, offer a promising approach for developing a clinically viable system for automated anesthestic drug delivery. We expand on our prior work applying deep RL to automated anesthetic dosing by now using a continuous-action model based on the actor-critic RL paradigm. The proposed RL agent is composed of a policy network that maps observed anesthetic states to a continuous probability density over propofol-infusion rates and a value network that estimates the favorability of observed states. We train and test three versions of the RL agent using varied reward functions. The agent is trained using simulated pharmacokinetic/pharmacodynamic models with randomized parameters to ensure robustness to patient variability. The model is tested on simulations and retrospectively on nine general anesthesia cases collected in the operating room. We utilize Shapley additive explanations to gain an understanding of the factors with the greatest influence over the agent&#39;s decision-making. The deep RL agent significantly outperformed a proportional-integral-derivative controller (median episode median absolute performance error 1.9% ± 1.8 and 3.1% ± 1.1). The model that was rewarded for minimizing total doses performed the best across simulated patient demographics (median episode median performance error 1.1% ± 0.5). When run on real-world clinical datasets, the agent recommended doses that were consistent with those administered by the anesthesiologist. The proposed approach marks the first fully continuous deep RL algorithm for automating anesthestic drug dosing. The reward function used by the RL training algorithm can be flexibly designed for desirable practices (e.g. use less anesthetic) and bolstered performances. Through careful analysis of the learned policies, techniques for interpreting dosing decisions, and testing on clinical data, we confirm that the agent&#39;s anesthetic dosing is consistent with our understanding of best-practices in anesthesia care.},
  archive      = {J_ARTMED},
  author       = {Gabriel Schamberg and Marcus Badgeley and Benyamin Meschede-Krasa and Ohyoon Kwon and Emery N. Brown},
  doi          = {10.1016/j.artmed.2021.102227},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102227},
  shortjournal = {Artif. Intell. Med.},
  title        = {Continuous action deep reinforcement learning for propofol dosing during general anesthesia},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DI++: A deep learning system for patient condition
identification in clinical notes. <em>ARTMED</em>, <em>123</em>, 102224.
(<a href="https://doi.org/10.1016/j.artmed.2021.102224">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately recording a patient&#39;s medical conditions in an EHR system is the basis of effectively documenting patient health status, coding for billing, and supporting data-driven clinical decision making. However, patient conditions are often not fully captured in structured EHR systems, but may be documented in unstructured clinical notes. The challenge is that not all disease mentions in clinical notes actually refer to a patient&#39;s conditions. We developed a two-step workflow for identifying patient&#39;s conditions from clinical notes: disease mention extraction and disease mention classification. We implemented this workflow in a prototype system, DI++, for Disease Identification. An advanced deep learning model, CLSTM-Attention model, is developed for disease mention classification in DI++. Extensive empirical evaluation on about one million pages of de-identified clinical notes demonstrates that DI++ has significant performance advantage over existing systems on F1 Score, Area Under the Curve metrics, and efficiency. The proposed CLSTM-Attention model outperforms the existing deep learning models for disease mention classification.},
  archive      = {J_ARTMED},
  author       = {Jinhe Shi and Xiangyu Gao and William C. Kinsman and Chenyu Ha and Guodong Gordon Gao and Yi Chen},
  doi          = {10.1016/j.artmed.2021.102224},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102224},
  shortjournal = {Artif. Intell. Med.},
  title        = {DI++: A deep learning system for patient condition identification in clinical notes},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mapping twenty years of antimicrobial resistance research
trends. <em>ARTMED</em>, <em>123</em>, 102216. (<a
href="https://doi.org/10.1016/j.artmed.2021.102216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Antimicrobial resistance (AMR) is a global threat to health and healthcare. In response to the growing AMR burden, research funding also increased. However, a comprehensive overview of the research output, including conceptual, temporal, and geographical trends, is missing. Therefore, this study uses topic modelling, a machine learning approach, to reveal the scientific evolution of AMR research and its trends, and provides an interactive user interface for further analyses. Structural topic modelling (STM) was applied on a text corpus resulting from a PubMed query comprising AMR articles (1999–2018). A topic network was established and topic trends were analysed by frequency, proportion, and importance over time and space. In total, 88 topics were identified in 158,616 articles from 166 countries. AMR publications increased by 450% between 1999 and 2018, emphasizing the vibrancy of the field. Prominent topics in 2018 were Strategies for emerging resistances and diseases , Nanoparticles , and Stewardship . Emerging topics included Water and environment , and Sequencing . Geographical trends showed prominence of Multidrug-resistant tuberculosis (MDR-TB) in the WHO African Region, corresponding with the MDR-TB burden. China and India were growing contributors in recent years, following the United States of America as overall lead contributor. This study provides a comprehensive overview of the AMR research output thereby revealing the AMR research response to the increased AMR burden. Both the results and the publicly available interactive database serve as a base to inform and optimise future research.},
  archive      = {J_ARTMED},
  author       = {Christian F. Luz and J. Magnus van Niekerk and Julia Keizer and Nienke Beerlage-de Jong and L.M. Annemarie Braakman-Jansen and Alfred Stein and Bhanu Sinha and J.E.W.C. van Gemert-Pijnen (Lisette) and Corinna Glasner},
  doi          = {10.1016/j.artmed.2021.102216},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102216},
  shortjournal = {Artif. Intell. Med.},
  title        = {Mapping twenty years of antimicrobial resistance research trends},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial intelligence (AI) in breast cancer care -
leveraging multidisciplinary skills to improve care. <em>ARTMED</em>,
<em>123</em>, 102215. (<a
href="https://doi.org/10.1016/j.artmed.2021.102215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ARTMED},
  author       = {Maria Joao Cardoso and Nehmat Houssami and Giuseppe Pozzi and Brigitte Séroussi},
  doi          = {10.1016/j.artmed.2021.102215},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102215},
  shortjournal = {Artif. Intell. Med.},
  title        = {Artificial intelligence (AI) in breast cancer care - leveraging multidisciplinary skills to improve care},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Missing data imputation on biomedical data using deeply
learned clustering and l2 regularized regression based on symmetric
uncertainty. <em>ARTMED</em>, <em>123</em>, 102214. (<a
href="https://doi.org/10.1016/j.artmed.2021.102214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big data era in healthcare led to the generation of high dimensional datasets like genomic datasets, electronic health records etc. One among the critical issues to be addressed in such datasets is handling incomplete data that may yield misleading results if not handled properly. Imputation is considered to be an effective way when the missing data rate is high. While imputation accuracy and classification accuracy are the two important metrics generally considered by most of the imputation techniques, high dimensional datasets such as genomic datasets motivated the need for imputation techniques that are also computationally efficient and preserves the structure of the dataset. This paper proposes a novel approach to missing data imputation in biomedical datasets using an ensemble of deeply learned clustering and L2 regularized regression based on symmetric uncertainty. The experiments are conducted with different proportion of missing data on both genomic and non-genomic biomedical datasets for different types of missingness pattern. Our proposed approach is compared with seven proven baseline imputation methods and two recently proposed imputation approaches. The results show that the proposed approach outperforms the other approaches considered in our experimentation in terms of imputation accuracy and computational efficiency despite preserving the structure of the dataset. Thus, the overall classification accuracy of the biomedical classification tasks is also improved when our proposed missing data imputation technique is used.},
  archive      = {J_ARTMED},
  author       = {Gayathri Nagarajan and L.D. Dhinesh Babu},
  doi          = {10.1016/j.artmed.2021.102214},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102214},
  shortjournal = {Artif. Intell. Med.},
  title        = {Missing data imputation on biomedical data using deeply learned clustering and l2 regularized regression based on symmetric uncertainty},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tetromino pattern based accurate EEG emotion classification
model. <em>ARTMED</em>, <em>123</em>, 102210. (<a
href="https://doi.org/10.1016/j.artmed.2021.102210">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, emotion recognition using electroencephalogram (EEG) signals is becoming a hot research topic . The aim of this paper is to classify emotions of EEG signals using a novel game-based feature generation function with high accuracy. Hence, a multileveled handcrafted feature generation automated emotion classification model using EEG signals is presented. A novel textural features generation method inspired by the Tetris game called Tetromino is proposed in this work. The Tetris game is one of the famous games worldwide, which uses various characters in the game. First, the EEG signals are subjected to discrete wavelet transform (DWT) to create various decomposition levels . Then, novel features are generated from the decomposed DWT sub-bands using the Tetromino method. Next, the maximum relevance minimum redundancy (mRMR) features selection method is utilized to select the most discriminative features , and the selected features are classified using support vector machine classifier. Finally, each channel&#39;s results (validation predictions) are obtained, and the mode function-based voting method is used to obtain the general results. We have validated our developed model using three databases (DREAMER, GAMEEMO, and DEAP). We have attained 100% accuracies using DREAMER and GAMEEMO datasets. Furthermore, over 99% of classification accuracy is achieved for DEAP dataset. Thus, our developed emotion detection model has yielded the best classification accuracy rate compared to the state-of-the-art techniques and is ready to be tested for clinical application after validating with more diverse datasets. Our results show the success of the presented Tetromino pattern-based EEG signal classification model validated using three public emotional EEG datasets.},
  archive      = {J_ARTMED},
  author       = {Turker Tuncer and Sengul Dogan and Mehmet Baygin and U. Rajendra Acharya},
  doi          = {10.1016/j.artmed.2021.102210},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102210},
  shortjournal = {Artif. Intell. Med.},
  title        = {Tetromino pattern based accurate EEG emotion classification model},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ADHD classification using auto-encoding neural network and
binary hypothesis testing. <em>ARTMED</em>, <em>123</em>, 102209. (<a
href="https://doi.org/10.1016/j.artmed.2021.102209">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attention Deficit Hyperactivity Disorder (ADHD) is a highly prevalent neurodevelopmental disease of school-age children. Early diagnosis is crucial for ADHD treatment, wherein its neurobiological diagnosis (or classification) is helpful and provides the objective evidence to clinicians. The existing ADHD classification methods suffer two problems, i.e., insufficient data and feature noise disturbance from other associated disorders. As an attempt to overcome these difficulties, a novel deep-learning classification architecture based on a binary hypothesis testing framework and a modified auto-encoding (AE) network is proposed in this paper. The binary hypothesis testing framework is introduced to cope with insufficient data of ADHD database. Brain functional connectivities (FCs) of test data (without seeing their labels) are incorporated during feature selection along with those of training data and affect the sequential deep learning procedure under binary hypotheses. On the other hand, the modified AE network is developed to capture more effective features from training data, such that the difference of inter- and intra-class variability scores between binary hypotheses can be enlarged and effectively alleviate the disturbance of feature noise. On the test of ADHD-200 database, our method significantly outperforms the existing classification methods. The average accuracy reaches 99.6% with the leave-one-out cross validation. Our method is also more robust and practically convenient for ADHD classification due to its uniform parameter setting across various datasets.},
  archive      = {J_ARTMED},
  author       = {Yibin Tang and Jia Sun and Chun Wang and Yuan Zhong and Aimin Jiang and Gang Liu and Xiaofeng Liu},
  doi          = {10.1016/j.artmed.2021.102209},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102209},
  shortjournal = {Artif. Intell. Med.},
  title        = {ADHD classification using auto-encoding neural network and binary hypothesis testing},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Revealing traces of depression through personal statements
analysis in social media. <em>ARTMED</em>, <em>123</em>, 102202. (<a
href="https://doi.org/10.1016/j.artmed.2021.102202">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depression is a common and very important health issue with serious effects in the daily life of people. Recently, several researchers have explored the analysis of user-generated data in social media to detect and diagnose signs of this mental disorder in individuals. In this regard, we tackled the depression detection task in social media considering the idea that terms located in phrases exposing personal statements (i.e., phrases characterized by the use of singular first person pronouns) have a special value for revealing signs of depression. First, we assessed the value of the personal statements for depression detection in social media. Second, we adapted an automatic approach that emphasizes the personal statements by means of a feature selection method and a term weighting scheme. Finally, we addressed the task in hand as an early detection problem, where the aim is to detect traces of depression with as much anticipation as possible. For evaluating these ideas, benchmark Reddit data for depression detection was used. The obtained results indicate that the personal statements have high relevance for revealing traces of depression. Furthermore, the results on early scenarios demonstrated that the proposed approach achieves high competitiveness compared with state-of-the-art methods, while maintaining its simplicity and interpretability.},
  archive      = {J_ARTMED},
  author       = {Rosa María Ortega-Mendoza and Delia Irazú Hernández-Farías and Manuel Montes-y-Gómez and Luis Villaseñor-Pineda},
  doi          = {10.1016/j.artmed.2021.102202},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {102202},
  shortjournal = {Artif. Intell. Med.},
  title        = {Revealing traces of depression through personal statements analysis in social media},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
