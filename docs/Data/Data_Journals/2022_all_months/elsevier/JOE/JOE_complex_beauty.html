<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JOE_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="joe---141">JOE - 141</h2>
<ul>
<li><details>
<summary>
(2022). Probability assessments of an ice-free arctic: Comparing
statistical and climate model projections. <em>JOE</em>,
<em>231</em>(2), 520–534. (<a
href="https://doi.org/10.1016/j.jeconom.2020.12.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The downward trend in the amount of Arctic sea ice has a wide range of environmental and economic consequences including important effects on the pace and intensity of global climate change. Based on several decades of satellite data, we provide statistical forecasts of Arctic sea ice extent during the rest of this century. The best fitting statistical model indicates that overall sea ice coverage is declining at an increasing rate. By contrast, average projections from the CMIP5 global climate models foresee a gradual slowing of Arctic sea ice loss even in scenarios with high carbon emissions . Our long-range statistical projections also deliver probability assessments of the timing of an ice-free Arctic. These results indicate almost a 60 percent chance of an effectively ice-free Arctic Ocean sometime during the 2030s — much earlier than the average projection from the global climate models.},
  archive      = {J_JOE},
  author       = {Francis X. Diebold and Glenn D. Rudebusch},
  doi          = {10.1016/j.jeconom.2020.12.007},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {520-534},
  shortjournal = {J. Econ.},
  title        = {Probability assessments of an ice-free arctic: Comparing statistical and climate model projections},
  volume       = {231},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Nowcasting with large bayesian vector autoregressions.
<em>JOE</em>, <em>231</em>(2), 500–519. (<a
href="https://doi.org/10.1016/j.jeconom.2021.04.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monitoring economic conditions in real time, or nowcasting, and Big Data analytics share some challenges, sometimes called the three “Vs”. Indeed, nowcasting is characterized by the use of a large number of time series (Volume), the complexity of the data covering various sectors of the economy, with different frequencies and precision and asynchronous release dates (Variety), and the need to incorporate new information continuously and in a timely manner (Velocity). In this paper, we explore three alternative routes to nowcasting with Bayesian Vector Autoregressive (BVAR) models and find that they can effectively handle the three Vs by producing, in real time, accurate probabilistic predictions of US economic activity and a meaningful narrative by means of scenario analysis.},
  archive      = {J_JOE},
  author       = {Jacopo Cimadomo and Domenico Giannone and Michele Lenza and Francesca Monti and Andrej Sokol},
  doi          = {10.1016/j.jeconom.2021.04.012},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {500-519},
  shortjournal = {J. Econ.},
  title        = {Nowcasting with large bayesian vector autoregressions},
  volume       = {231},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SVARs with occasionally-binding constraints. <em>JOE</em>,
<em>231</em>(2), 477–499. (<a
href="https://doi.org/10.1016/j.jeconom.2021.07.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a structural VAR in which an occasionally-binding constraint generates censoring of one of the dependent variables. Once the censoring mechanism is triggered, we allow some of the coefficients for the remaining variables to change. We show that a necessary condition for a unique reduced form is that regression functions for the non-censored variables are continuous at the censoring point and that parameters satisfy some mild restrictions. In our application the censored variable is a nominal interest rate constrained by an effective lower bound (ELB). According to our estimates based on U.S. data, once the ELB becomes binding, the coefficients in the inflation equation change significantly, which translates into a change of the inflation responses to (unconventional) monetary policy and demand shocks. Our results suggest that the presence of the ELB is indeed empirically relevant for the propagation of shocks. We also obtain a shadow interest rate that shows a significant accommodation in the early phase of the Great Recession , followed by a mild and steady accommodation until liftoff in 2016.},
  archive      = {J_JOE},
  author       = {S. Borağan Aruoba and Marko Mlikota and Frank Schorfheide and Sergio Villalvazo},
  doi          = {10.1016/j.jeconom.2021.07.013},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {477-499},
  shortjournal = {J. Econ.},
  title        = {SVARs with occasionally-binding constraints},
  volume       = {231},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Joint bayesian inference about impulse responses in VAR
models. <em>JOE</em>, <em>231</em>(2), 457–476. (<a
href="https://doi.org/10.1016/j.jeconom.2021.05.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We derive the Bayes estimator of vectors of structural VAR impulse responses under a range of alternative loss functions. We also discuss the construction of joint credible regions for vectors of impulse responses as the lowest posterior risk region under the same loss functions. We show that conventional impulse response estimators such as the posterior median response function or the posterior mean response function are not in general the Bayes estimator of the impulse response vector obtained by stacking the impulse responses of interest. We illustrate that such pointwise estimators may imply response function shapes that are incompatible with any possible parameterization of the underlying model. Moreover, conventional pointwise quantile error bands are not a valid measure of the estimation uncertainty about the impulse response vector because they ignore the mutual dependence of the responses. In practice, they tend to understate substantially the estimation uncertainty about the impulse response vector.},
  archive      = {J_JOE},
  author       = {Atsushi Inoue and Lutz Kilian},
  doi          = {10.1016/j.jeconom.2021.05.010},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {457-476},
  shortjournal = {J. Econ.},
  title        = {Joint bayesian inference about impulse responses in VAR models},
  volume       = {231},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Approximate maximum likelihood for complex structural
models. <em>JOE</em>, <em>231</em>(2), 432–456. (<a
href="https://doi.org/10.1016/j.jeconom.2021.05.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Indirect Inference (I-I) is a popular technique for estimating complex parametric models whose likelihood function is intractable, however, the statistical efficiency of I-I estimation is questionable. While the efficient method of moments, Gallant and Tauchen (1996), promises efficiency, the price to pay for this efficiency is a loss of parsimony and thereby a potential lack of robustness to model misspecification . This stands in contrast to simpler I-I estimation strategies, which are known to display less sensitivity to model misspecification due in large part to their focus on specific elements of the underlying structural model. In this research, we propose a new simulation-based approach that maintains the parsimony of I-I estimation, which is often critical in empirical applications, but can also deliver estimators that are nearly as efficient as maximum likelihood. This new approach is based on using a constrained approximation to the structural model, which ensures identification and can deliver estimators that are consistent and nearly efficient. We demonstrate this approach through several examples, and show that this approach can deliver estimators that are nearly as efficient as maximum likelihood, when feasible, but can be employed in many situations where maximum likelihood is infeasible.},
  archive      = {J_JOE},
  author       = {Veronika Czellar and David T. Frazier and Eric Renault},
  doi          = {10.1016/j.jeconom.2021.05.009},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {432-456},
  shortjournal = {J. Econ.},
  title        = {Approximate maximum likelihood for complex structural models},
  volume       = {231},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Monetary reforms and inflation expectations in japan:
Evidence from inflation-indexed bonds. <em>JOE</em>, <em>231</em>(2),
410–431. (<a
href="https://doi.org/10.1016/j.jeconom.2021.10.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We assess the impact of news concerning recent Japanese monetary reforms on long-term inflation expectations using an arbitrage-free term structure model of nominal and real yields. Our model accounts for the value of deflation protection embedded in Japanese inflation-indexed bonds issued since 2013, which is sizable and time-varying. Our results suggest that Japanese long-term inflation expectations have remained positive despite extensive spells of deflation, leaving inflation risk premia mostly negative during this period. Moreover, adjusting for deflation protection demonstrates that market responses to policy changes were not as inflationary as they appear under standard modeling procedures. Consequently, the reforms were less “disappointing” than is widely perceived.},
  archive      = {J_JOE},
  author       = {Jens H.E. Christensen and Mark M. Spiegel},
  doi          = {10.1016/j.jeconom.2021.10.007},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {410-431},
  shortjournal = {J. Econ.},
  title        = {Monetary reforms and inflation expectations in japan: Evidence from inflation-indexed bonds},
  volume       = {231},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Words speak as loudly as actions: Central bank communication
and the response of equity prices to macroeconomic announcements.
<em>JOE</em>, <em>231</em>(2), 387–409. (<a
href="https://doi.org/10.1016/j.jeconom.2021.07.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the literature has already widely documented the effects of macroeconomic news announcements on asset prices, as well as their asymmetric impact during good and bad times, we focus on the reaction to news based on the description of the state of the economy as painted by the Federal Open Market Committee (FOMC) statements. We develop a novel FOMC sentiment index using textual analysis techniques, and find that news has a bigger (smaller) effect on equity prices during bad (good) times as described by the FOMC sentiment index. Our analysis suggests that the FOMC sentiment index offers a reading on current and future macroeconomic conditions that will affect the probability of a change in interest rates , and the reaction of equity prices to news depends on the FOMC sentiment index which is one of the best predictors of this probability .},
  archive      = {J_JOE},
  author       = {Ben Gardner and Chiara Scotti and Clara Vega},
  doi          = {10.1016/j.jeconom.2021.07.014},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {387-409},
  shortjournal = {J. Econ.},
  title        = {Words speak as loudly as actions: Central bank communication and the response of equity prices to macroeconomic announcements},
  volume       = {231},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Testing for parameter instability and structural change in
persistent predictive regressions. <em>JOE</em>, <em>231</em>(2),
361–386. (<a
href="https://doi.org/10.1016/j.jeconom.2021.05.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops parameter instability and structural change tests within predictive regressions for economic systems governed by persistent vector autoregressive dynamics. Specifically, in a setting where all – or a subset – of the variables may be fractionally integrated and the predictive relation may feature cointegration, we provide sup-Wald break tests that are constructed using the Local speCtruM (LCM) approach. The new tests cover both parameter variation and multiple structural changes with unknown break dates, and the number of breaks being known or unknown. We establish asymptotic limit theory for the tests, showing that it coincides with standard testing procedures. As a consequence, existing critical values for tied-down Bessel processes may be applied, without modification. We implement the new structural change tests to explore the stability of the fractionally cointegrating relation between implied- and realized volatility (IV and RV). Moreover, we assess the relative efficiency of IV forecasts against a challenging time-series benchmark constructed from high-frequency data. Unlike existing studies, we find evidence that the IV–RV cointegrating relation is unstable, and that carefully constructed time-series forecasts are more efficient than IV in capturing low-frequency movements in RV.},
  archive      = {J_JOE},
  author       = {Torben G. Andersen and Rasmus T. Varneskov},
  doi          = {10.1016/j.jeconom.2021.05.011},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {361-386},
  shortjournal = {J. Econ.},
  title        = {Testing for parameter instability and structural change in persistent predictive regressions},
  volume       = {231},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). From zero to hero: Realized partial (co)variances.
<em>JOE</em>, <em>231</em>(2), 348–360. (<a
href="https://doi.org/10.1016/j.jeconom.2021.04.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a generalization of the class of realized semivariance and semicovariance measures introduced by Barndorff-Nielsen et al. (2010) and Bollerslev et al. (2020a) to allow for a finer decomposition of realized (co)variances. The new “realized partial (co)variances” allow for multiple thresholds with various locations, rather than the single fixed threshold of zero used in semi (co)variances. We adopt methods from machine learning to choose the thresholds to maximize the out-of-sample forecast performance of time series models based on realized partial (co)variances. We find that in low dimensional settings it is hard, but not impossible, to improve upon the simple fixed threshold of zero. In large dimensions, however, the zero threshold embedded in realized semi covariances emerges as a robust choice.},
  archive      = {J_JOE},
  author       = {Tim Bollerslev and Marcelo C. Medeiros and Andrew J. Patton and Rogier Quaedvlieg},
  doi          = {10.1016/j.jeconom.2021.04.013},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {348-360},
  shortjournal = {J. Econ.},
  title        = {From zero to hero: Realized partial (co)variances},
  volume       = {231},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Conditional rotation between forecasting models.
<em>JOE</em>, <em>231</em>(2), 329–347. (<a
href="https://doi.org/10.1016/j.jeconom.2021.10.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We establish conditions under which forecasting performance can be improved by rotating between a set of underlying forecasts whose predictive accuracy is tracked using a set of time-varying monitoring instruments. We characterize the properties that the monitoring instruments must possess to be useful for identifying, at each point in time, the best forecast and show that these reflect both the accuracy of the predictors used by the underlying forecasting models and the strength of the monitoring instruments. Finite-sample bounds on forecasting performance that account for estimation error are used to compute the expected loss of the competing forecasts as well as for the dynamic rotation strategy. Finally, using Monte Carlo simulations and empirical applications to forecasting inflation and stock returns , we demonstrate the potential gains from using conditioning information to rotate between forecasts.},
  archive      = {J_JOE},
  author       = {Yinchu Zhu and Allan Timmermann},
  doi          = {10.1016/j.jeconom.2021.10.006},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {329-347},
  shortjournal = {J. Econ.},
  title        = {Conditional rotation between forecasting models},
  volume       = {231},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial for special issue in honor of francis x. diebold.
<em>JOE</em>, <em>231</em>(2), 327–328. (<a
href="https://doi.org/10.1016/j.jeconom.2021.10.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JOE},
  author       = {Atsushi Inoue and Lutz Kilian and Andrew Patton},
  doi          = {10.1016/j.jeconom.2021.10.005},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {327-328},
  shortjournal = {J. Econ.},
  title        = {Editorial for special issue in honor of francis x. diebold},
  volume       = {231},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Incentives, search engines, and the elicitation of
subjective beliefs: Evidence from representative online survey
experiments. <em>JOE</em>, <em>231</em>(1), 304–326. (<a
href="https://doi.org/10.1016/j.jeconom.2020.03.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A large literature studies subjective beliefs about economic facts using unincentivized survey questions. We devise randomized experiments in a representative online survey to investigate whether incentivizing belief accuracy affects stated beliefs about average earnings by professional degree and average public school spending. Incentive provision does not impact earnings beliefs, but improves school-spending beliefs. Response spikes suggest that the latter effect likely reflects increased online-search activity. Consistently, an experiment that just encourages search-engine usage produces very similar results. Another experiment provides no evidence of experimenter-demand effects. Overall, results suggest a trade-off between increased respondent effort and the risk of inducing online-search activity when incentivizing beliefs in online surveys.},
  archive      = {J_JOE},
  author       = {Elisabeth Grewenig and Philipp Lergetporer and Katharina Werner and Ludger Woessmann},
  doi          = {10.1016/j.jeconom.2020.03.022},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {304-326},
  shortjournal = {J. Econ.},
  title        = {Incentives, search engines, and the elicitation of subjective beliefs: Evidence from representative online survey experiments},
  volume       = {231},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Surveying business uncertainty. <em>JOE</em>,
<em>231</em>(1), 282–303. (<a
href="https://doi.org/10.1016/j.jeconom.2020.03.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We elicit subjective probability distributions from business executives about their own-firm outcomes at a one-year look-ahead horizon. In terms of question design, our key innovation is to let survey respondents freely select support points and probabilities in five-point distributions over future sales growth, employment, and investment. In terms of data collection, we develop and field a new monthly panel Survey of Business Uncertainty. The SBU began in 2014 and now covers about 1,750 firms drawn from all 50 states, every major nonfarm industry , and a range of firm sizes. We find three key results. First, firm-level growth expectations are highly predictive of realized growth rates. Second, firm-level subjective uncertainty predicts the magnitudes of future forecast errors and future forecast revisions. Third, subjective uncertainty rises with the firm’s absolute growth rate in the previous year and with the magnitude of recent revisions to its expected growth rate. We aggregate over firm-level forecast distributions to construct monthly indices of business expectations (first moment) and uncertainty (second moment) for the U.S. private sector.},
  archive      = {J_JOE},
  author       = {David Altig and Jose Maria Barrero and Nicholas Bloom and Steven J. Davis and Brent Meyer and Nicholas Parker},
  doi          = {10.1016/j.jeconom.2020.03.021},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {282-303},
  shortjournal = {J. Econ.},
  title        = {Surveying business uncertainty},
  volume       = {231},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tail and center rounding of probabilistic expectations in
the health and retirement study. <em>JOE</em>, <em>231</em>(1), 265–281.
(<a href="https://doi.org/10.1016/j.jeconom.2020.03.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study rounding of numerical expectations in the Health and Retirement Study (HRS) between 2002 and 2014. We document that respondent-specific rounding patterns across questions in individual waves are quite stable across waves. We discover a tendency by about half of the respondents to provide more refined responses in the tails of the 0–100 scale than the center. In contrast, only about five percent of the respondents give more refined responses in the center than the tails. We find that respondents tend to report the values 25 and 75 more frequently than other values ending in 5. We also find that rounding practices vary somewhat across question domains and respondent characteristics. We propose an inferential approach that assumes stability of response tendencies across questions and waves to infer person-specific rounding in each question domain and scale segment and that replaces each point-response with an interval representing the range of possible values of the true latent belief. Using expectations from the 2016 wave of the HRS, we validate our approach. To demonstrate the consequences of rounding on inference, we compare best-predictor estimates from face-value expectations with those implied by our intervals.},
  archive      = {J_JOE},
  author       = {Pamela Giustinelli and Charles F. Manski and Francesca Molinari},
  doi          = {10.1016/j.jeconom.2020.03.020},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {265-281},
  shortjournal = {J. Econ.},
  title        = {Tail and center rounding of probabilistic expectations in the health and retirement study},
  volume       = {231},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimal frequency of portfolio evaluation in a choice
experiment with ambiguity and loss aversion. <em>JOE</em>,
<em>231</em>(1), 248–264. (<a
href="https://doi.org/10.1016/j.jeconom.2020.11.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We estimate a structural model using data from a novel experiment investigating how investors’ preferred frequency of portfolio evaluations balance the opposing effects of ambiguity and loss aversion. Investors in the experiment face initial ambiguity concerning return distributions for an asset. They observe draws from the true return distribution of the asset, allowing them to reduce their ambiguity through time. We exploit portfolio choices and stated beliefs over possible return distributions to estimate preferences and ambiguity updating rules. We find that 70\% of investors would opt for a high frequency of portfolio evaluations, reflecting the dominating effect of ambiguity aversion over loss aversion.},
  archive      = {J_JOE},
  author       = {Charles Bellemare and Sabine Kröger and Kouamé Marius Sossou},
  doi          = {10.1016/j.jeconom.2020.11.003},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {248-264},
  shortjournal = {J. Econ.},
  title        = {Optimal frequency of portfolio evaluation in a choice experiment with ambiguity and loss aversion},
  volume       = {231},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Heterogeneity in households’ stock market beliefs: Levels,
dynamics, and epistemic uncertainty. <em>JOE</em>, <em>231</em>(1),
232–247. (<a
href="https://doi.org/10.1016/j.jeconom.2020.11.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyse a long panel of households’ stock market beliefs to gain insights into the nature of the levels, dynamics, and informativeness of these expectations. In a first step, we classify respondents into one of five groups based on their beliefs data alone. In a second step, we estimate models of expectations at the group level so that belief levels, volatility, and response to information can vary freely across groups. At opposite extremes in terms of optimism we identify pessimists who expect substantially negative returns and financially sophisticated individuals whose expectations are close to the historical average. Two groups expect average returns around zero and differ only in how they respond to information: Extrapolators who become more optimistic following positive information and mean-reverters for whom the opposite is the case. The final group is characterised by its members being unable or unwilling to quantify their beliefs about future returns.},
  archive      = {J_JOE},
  author       = {Hans-Martin von Gaudecker and Axel Wogrolly},
  doi          = {10.1016/j.jeconom.2020.11.011},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {232-247},
  shortjournal = {J. Econ.},
  title        = {Heterogeneity in households’ stock market beliefs: Levels, dynamics, and epistemic uncertainty},
  volume       = {231},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamics and heterogeneity of subjective stock market
expectations. <em>JOE</em>, <em>231</em>(1), 213–231. (<a
href="https://doi.org/10.1016/j.jeconom.2021.09.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Between 2004 and 2016, we elicited individuals’ subjective expectations of stock market returns in a Dutch internet panel at bi-annual intervals. In this paper, we develop a panel data model with a finite mixture of expectation types who differ in how they use past stock market returns to form current stock market expectations. The model allows for rounding in the probabilistic responses and for observed and unobserved heterogeneity at several levels. We estimate the type distribution in the population and find evidence for considerable heterogeneity in expectation types and meaningful variation over time, in particular during the financial crisis of 2008/09.},
  archive      = {J_JOE},
  author       = {Florian Heiss and Michael Hurd and Maarten van Rooij and Tobias Rossmann and Joachim Winter},
  doi          = {10.1016/j.jeconom.2021.09.010},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {213-231},
  shortjournal = {J. Econ.},
  title        = {Dynamics and heterogeneity of subjective stock market expectations},
  volume       = {231},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Incentive-driven inattention. <em>JOE</em>, <em>231</em>(1),
188–212. (<a
href="https://doi.org/10.1016/j.jeconom.2020.06.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {“Rational inattention” is becoming increasingly prominent in economic modeling , but there is little empirical evidence for its central premise-that the choice of attention results from a cost-benefit optimization. Observational data typically do not allow researchers to infer attention choices from observables. We fill this gap in the literature by exploiting a unique dataset of professional forecasters who update their inflation forecasts at days of their choice. In the data we observe how many forecasters update (extensive margin of updating), the magnitude of the update (intensive margin), and the objective of optimization (forecast accuracy). There are also “shifters” in incentives: A contest that increases the benefit of accurate forecasting, and the release of official data that reduces the cost of processing information. These features allow us to link observables to attention and incentive parameters. We structurally estimate a model where the decision to update and the magnitude of the update are endogenous and the latter is the outcome of a rational inattention optimization. The empirical findings provide support for the key implication of rational inattention that information-processing efforts react to changing incentives. Counterfactuals reveal that accuracy is maximized if the contest date coincides with the release of information, aligning higher benefits with lower costs of attention.},
  archive      = {J_JOE},
  author       = {Wagner Piazza Gaglianone and Raffaella Giacomini and João Victor Issler and Vasiliki Skreta},
  doi          = {10.1016/j.jeconom.2020.06.010},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {188-212},
  shortjournal = {J. Econ.},
  title        = {Incentive-driven inattention},
  volume       = {231},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Beliefs about public debt and the demand for government
spending. <em>JOE</em>, <em>231</em>(1), 165–187. (<a
href="https://doi.org/10.1016/j.jeconom.2020.09.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We examine how beliefs about the debt-to-GDP ratio affect people’s attitudes towards government spending and taxation. Using representative samples of the US population, we run a series of experiments in which we provide half of our respondents with information about the debt-to-GDP ratio in the US. Based on a total of more than 4,000 respondents, we find that most people underestimate the debt-to-GDP ratio and reduce their support for government spending once they learn about the actual amount of debt, but do not substantially alter their attitudes towards taxation. The treatment effects seem to operate through changes in expectations about fiscal sustainability and persist in a four-week follow-up.},
  archive      = {J_JOE},
  author       = {Christopher Roth and Sonja Settele and Johannes Wohlfart},
  doi          = {10.1016/j.jeconom.2020.09.011},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {165-187},
  shortjournal = {J. Econ.},
  title        = {Beliefs about public debt and the demand for government spending},
  volume       = {231},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Marriage, children, and labor supply: Beliefs and outcomes.
<em>JOE</em>, <em>231</em>(1), 148–164. (<a
href="https://doi.org/10.1016/j.jeconom.2020.03.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While a large literature is interested in the relationship between family and labor supply outcomes, little is known about the expectations of these objects at earlier stages. We examine these expectations, taking advantage of unique data from the Berea Panel Study. In addition to characterizing expectations, starting during college, the data details outcomes for ten years after graduation. Methodological contributions come from approaches to validate quality of survey expectations data and the recognition that expectations data, along with longitudinal data , can potentially help address endogeneity issues arising in the estimation of the causal effect of family on labor supply.},
  archive      = {J_JOE},
  author       = {Yifan Gong and Ralph Stinebrickner and Todd Stinebrickner},
  doi          = {10.1016/j.jeconom.2020.03.023},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {148-164},
  shortjournal = {J. Econ.},
  title        = {Marriage, children, and labor supply: Beliefs and outcomes},
  volume       = {231},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Understanding migration aversion using elicited
counterfactual choice probabilities. <em>JOE</em>, <em>231</em>(1),
123–147. (<a
href="https://doi.org/10.1016/j.jeconom.2020.07.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates how migration and location choice decisions depend on a large set of location characteristics, with particular focus on measuring the importance and nature of non-monetary costs of moving. We employ a stated-preference approach to elicit respondents’ choice probabilities for a set of hypothetical choice scenarios, using two waves from the NY Fed’s Survey of Consumer Expectations. Our stated probabilistic choice approach allows us to recover the distribution of individual-level preferences for location and mobility attributes without concerns about omitted variables and selection biases that hamper analyses based on observed mobility choices alone. We estimate substantial heterogeneity in the willingness-to-pay (WTP) for location characteristics and in moving costs, both across and within demographic groups. We find moving costs to be strongly associated with attachment to the current neighborhood and dwelling and to social networks. Our results indicate evidence of sorting into current locations based on preferences for location attributes as well as a strong negative association between respondents’ non-monetary moving costs and their moving expectations and actual mobility decisions.},
  archive      = {J_JOE},
  author       = {Gizem Koşar and Tyler Ransom and Wilbert van der Klaauw},
  doi          = {10.1016/j.jeconom.2020.07.056},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {123-147},
  shortjournal = {J. Econ.},
  title        = {Understanding migration aversion using elicited counterfactual choice probabilities},
  volume       = {231},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The role of heterogeneous risk preferences, discount rates,
and earnings expectations in college major choice. <em>JOE</em>,
<em>231</em>(1), 98–122. (<a
href="https://doi.org/10.1016/j.jeconom.2020.04.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We estimate a rich model of college major choice using a panel of experimentally-derived data. Our estimation strategy combines two types of data: data on self-reported beliefs about future earnings from potential human capital decisions and survey-based measures of risk and time preferences. We show how to use these data to identify a general life-cycle model, allowing for rich patterns of heterogeneous beliefs and preferences. Our data allow us to separate perceptions about the degree of risk or about the current versus future payoffs for a choice from the individual’s preference for risk and patience. Comparing our estimates of the general model to estimates of models which ignore heterogeneity in risk and time preferences, we find that these restricted models overstate the importance of earnings to major choice. Additionally, we show that while men are less risk averse and patient than women, gender differences in expectations about own-earnings, risk aversion , and patience cannot explain gender gaps in major choice.},
  archive      = {J_JOE},
  author       = {Arpita Patnaik and Joanna Venator and Matthew Wiswall and Basit Zafar},
  doi          = {10.1016/j.jeconom.2020.04.050},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {98-122},
  shortjournal = {J. Econ.},
  title        = {The role of heterogeneous risk preferences, discount rates, and earnings expectations in college major choice},
  volume       = {231},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Academic and non-academic investments at university: The
role of expectations, preferences and constraints. <em>JOE</em>,
<em>231</em>(1), 74–97. (<a
href="https://doi.org/10.1016/j.jeconom.2020.03.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper estimates a discrete choice model of time allocation decisions made by university students. We consider investments in academic and non-academic activities, such as job placements or volunteering. Identification is achieved using data collected through a recent survey of UK university students on subjective expectations about the returns to these activities, and the enjoyment students derive from them. Unobserved heterogeneity in the choice set is addressed using a sufficient set logit method. The analysis reveals significant ethnic differences in the level of investments, expected academic and labour market returns, and enjoyment of academic and non-academic activities. Simulations suggest that existing constraints play an important role in explaining ethnic gaps in investments.},
  archive      = {J_JOE},
  author       = {Adeline Delavande and Emilia Del Bono and Angus Holford},
  doi          = {10.1016/j.jeconom.2020.03.019},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {74-97},
  shortjournal = {J. Econ.},
  title        = {Academic and non-academic investments at university: The role of expectations, preferences and constraints},
  volume       = {231},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-perceptions about academic achievement: Evidence from
mexico city. <em>JOE</em>, <em>231</em>(1), 58–73. (<a
href="https://doi.org/10.1016/j.jeconom.2020.06.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A growing body of evidence suggests that people exhibit large biases when processing information about themselves, but less is known about the underlying inference process. This paper studies belief updating patterns regarding academic ability in a large sample of students transitioning from middle to high school in Mexico City. The analysis takes advantage of rich and longitudinal data on subjective beliefs together with randomized feedback about individual performance on an achievement test. On average, the performance feedback reduces the relative role of priors on posteriors and shifts substantial probability mass toward the signal. Further evidence reveals that males and high-socioeconomic status students tend to process new information on their own ability more effectively.},
  archive      = {J_JOE},
  author       = {Matteo Bobba and Veronica Frisancho},
  doi          = {10.1016/j.jeconom.2020.06.009},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {58-73},
  shortjournal = {J. Econ.},
  title        = {Self-perceptions about academic achievement: Evidence from mexico city},
  volume       = {231},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parental beliefs about returns to child health investments.
<em>JOE</em>, <em>231</em>(1), 33–57. (<a
href="https://doi.org/10.1016/j.jeconom.2020.03.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Childhood obesity has adverse health and productivity consequences and it poses negative externalities to health services. To shed light on the role of parents, we elicit parental beliefs about the returns and the persistence of a healthy diet and exercise routine in childhood. Parents believe both types of investments to improve child and adult health outcomes. Consistent with a model of taste formation, parents believe that childhood health behaviors persist into adulthood. We show that perceived returns are predictive of health investments and outcomes, and that less educated parents view the returns to health investments to be lower. Our descriptive evidence suggests that beliefs contribute to the socioeconomic inequality in health outcomes and the intergenerational transmission of obesity.},
  archive      = {J_JOE},
  author       = {Pietro Biroli and Teodora Boneva and Akash Raja and Christopher Rauh},
  doi          = {10.1016/j.jeconom.2020.03.018},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {33-57},
  shortjournal = {J. Econ.},
  title        = {Parental beliefs about returns to child health investments},
  volume       = {231},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Maternal subjective expectations about the technology of
skill formation predict investments in children one year later.
<em>JOE</em>, <em>231</em>(1), 3–32. (<a
href="https://doi.org/10.1016/j.jeconom.2020.07.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A growing literature reports significant socio-economic gaps in investments in the human capital of young children. Because the returns to these investments may be huge, parenting programs attempt to improve children’s environments by increasing parental expectations about the importance of investments for their children’s human capital formation . We contribute to this literature by investigating the relevance of maternal subjective expectations (MSE) about the technology of skill formation in predicting investments in the human capital of children. We develop and implement a framework to elicit and analyze MSE data. We launch a longitudinal study with 822 participants, all of whom were women in the second trimester of their first pregnancy at the date of enrollment. In the first wave of the study, during pregnancy, we elicited the woman’s MSE. In the second wave, approximately one year later, we measured maternal investments using the Home Observation for the Measurement of the Environment (HOME) Inventory. The vast majority of study participants believe that the Cobb–Douglas technology of skill formation describes the process of child development accurately. We observed substantial heterogeneity in MSE about the impact of human capital at birth and investments in child development at age two. Family income explains part of this heterogeneity in MSE. The higher the family income, the higher the MSE about the impact of investment in child development. We find that a one-standard-deviation of MSE measured at pregnancy is associated with 11\% of a standard deviation in investments measured when the child is approximately nine months old.},
  archive      = {J_JOE},
  author       = {Flávio Cunha and Irma Elo and Jennifer Culhane},
  doi          = {10.1016/j.jeconom.2020.07.044},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {3-32},
  shortjournal = {J. Econ.},
  title        = {Maternal subjective expectations about the technology of skill formation predict investments in children one year later},
  volume       = {231},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Introduction to the journal of econometrics annals issue on
“subjective expectations and probabilities in economics.” <em>JOE</em>,
<em>231</em>(1), 1–2. (<a
href="https://doi.org/10.1016/j.jeconom.2022.01.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JOE},
  author       = {Adeline Delavande and Wilbert van der Klaauw and Joachim Winter and Basit Zafar},
  doi          = {10.1016/j.jeconom.2022.01.002},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {1-2},
  shortjournal = {J. Econ.},
  title        = {Introduction to the journal of econometrics annals issue on “Subjective expectations and probabilities in economics”},
  volume       = {231},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). How should parameter estimation be tailored to the
objective? <em>JOE</em>, <em>230</em>(2), 535–558. (<a
href="https://doi.org/10.1016/j.jeconom.2020.12.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study parameter estimation from the sample X , when the objective is to maximize the expected value of a criterion function, Q , for a distinct sample, Y . This is the situation that arises when a model is estimated for the purpose of describing other data than those used for estimation, such as in forecasting problems. A natural candidate for solving max T ∈ σ ( X ) E Q ( Y , T ) is the innate estimator, θ ˆ = arg max θ Q ( X , θ ) . While the innate estimator has certain advantages, we show that the asymptotically efficient estimator takes the form θ ̃ = arg max θ Q ̃ ( X , θ ) , where Q ̃ is defined from a likelihood function in conjunction with Q . The likelihood-based estimator is, however, fragile, as misspecification is harmful in two ways. First, the likelihood-based estimator may be inefficient under misspecification. Second, and more importantly, the likelihood approach requires a parameter transformation that depends on the true model, causing an improper mapping to be used under misspecification.},
  archive      = {J_JOE},
  author       = {Peter Reinhard Hansen and Elena-Ivona Dumitrescu},
  doi          = {10.1016/j.jeconom.2020.12.014},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {535-558},
  shortjournal = {J. Econ.},
  title        = {How should parameter estimation be tailored to the objective?},
  volume       = {230},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Local mispricing and microstructural noise: A parametric
perspective. <em>JOE</em>, <em>230</em>(2), 510–534. (<a
href="https://doi.org/10.1016/j.jeconom.2021.06.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We extend the classic ”martingale-plus-noise” model for high-frequency returns to accommodate an error correction mechanism and endogenous pricing errors. It is motivated by (i) novel empirical evidence documenting that microstructure noise exhibits frequently changing patterns of serial dependence which are interwoven with innovations to the efficient price; (ii) building a bridge between high-frequency econometrics and market microstructure models. We identify temporal pricing error correction and noise endogeneity as complementary components driving high-frequency dynamics and inducing two separate regimes, characterized by the sign of the return serial correlation and an implied bias in realized variance estimates. We document frequent fluctuations between these regimes, which can be associated with price discovery in a setting with incomplete information and learning. The model links critical concepts from high-frequency statistics and market microstructure theory, suggesting new avenues for volatility estimation.},
  archive      = {J_JOE},
  author       = {Torben G. Andersen and Ilya Archakov and Gökhan Cebiroglu and Nikolaus Hautsch},
  doi          = {10.1016/j.jeconom.2021.06.006},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {510-534},
  shortjournal = {J. Econ.},
  title        = {Local mispricing and microstructural noise: A parametric perspective},
  volume       = {230},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Testing for the presence of jump components in jump
diffusion models. <em>JOE</em>, <em>230</em>(2), 483–509. (<a
href="https://doi.org/10.1016/j.jeconom.2021.06.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose a nonparametric test to determine whether an underlying jump diffusion process indeed contains jump component, or equivalently, is indeed a diffusion. Our test is based upon a robust threshold estimation of diffusive volatility and the kernel estimation of the conditional moment function of the squared instantaneous increments of the underlying process. We show that our test statistic has asymptotic standard normal distribution under the null hypothesis of no jumps, is consistent against fixed alternatives, and may detect local alternatives that shrink to diffusions at certain convergence rates, when sampling interval shrinks to zero and time span is either fixed or expands. We only assume that the jump diffusion process is recurrent, thus allowing for both stationary and nonstationary cases. In addition, we provide a regression bootstrap test and establish its validity. A Monte Carlo simulation is conducted to examine the finite sample performances of our test, and an empirical illustration is also provided.},
  archive      = {J_JOE},
  author       = {Bin Wang and Xu Zheng},
  doi          = {10.1016/j.jeconom.2021.06.005},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {483-509},
  shortjournal = {J. Econ.},
  title        = {Testing for the presence of jump components in jump diffusion models},
  volume       = {230},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Nonparametric inference for quantile cointegrations with
stationary covariates. <em>JOE</em>, <em>230</em>(2), 453–482. (<a
href="https://doi.org/10.1016/j.jeconom.2021.06.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the inference problems in nonlinear quantile regressions with both stationary and nonstationary covariates . The nonparametric local constant quantile estimator is proposed to estimate the unknown quantile regression function , whose asymptotic properties are established under quite general conditions. Specification testing of the quantile regression function is further considered through a statistic constructed based on the integrated squared distance between the parametric and the nonparametric estimators for the regression function. The test statistic is shown to converge to a random variable related to the local time of an Ornstein–Uhlenbeck process under the parametric null . The power of the test against local alternatives is also investigated. Additional asymptotic results on the null parametric quantile estimators and a bootstrap test are developed as well. Numerical results demonstrate that the proposed nonparametric estimator and the specification test enjoy attractive finite sample performance.},
  archive      = {J_JOE},
  author       = {Yundong Tu and Han-Ying Liang and Qiying Wang},
  doi          = {10.1016/j.jeconom.2021.06.002},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {453-482},
  shortjournal = {J. Econ.},
  title        = {Nonparametric inference for quantile cointegrations with stationary covariates},
  volume       = {230},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GMM quantile regression. <em>JOE</em>, <em>230</em>(2),
432–452. (<a
href="https://doi.org/10.1016/j.jeconom.2020.11.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops generalized method of moments (GMM) estimation and inference procedures for quantile regression models. We propose a GMM estimator for simultaneous estimation across multiple quantiles . This estimator allows us to model quantile regression coefficients using flexible parametric restrictions across quantiles . The restrictions and simultaneous estimation lead to efficiency gains compared to standard methods. We establish the asymptotic properties of the GMM estimators when the number of quantiles used is fixed and when it diverges to infinity jointly with the sample size. As an alternative to GMM, we also propose a minimum distance estimator over a given subset of quantiles. Moreover, we provide specification tests for the imposed restrictions. The estimators and tests we propose are simple to implement in practice. Monte Carlo simulations provide numerical evidence of the finite sample properties of the methods. Finally, we apply the proposed methods to estimate the effects of smoking on birthweight of live infants at the extreme bottom of the conditional distribution.},
  archive      = {J_JOE},
  author       = {Sergio Firpo and Antonio F. Galvao and Cristine Pinto and Alexandre Poirier and Graciela Sanroman},
  doi          = {10.1016/j.jeconom.2020.11.014},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {432-452},
  shortjournal = {J. Econ.},
  title        = {GMM quantile regression},
  volume       = {230},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust post-selection inference of high-dimensional mean
regression with heavy-tailed asymmetric or heteroskedastic errors.
<em>JOE</em>, <em>230</em>(2), 416–431. (<a
href="https://doi.org/10.1016/j.jeconom.2021.05.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a robust post-selection inference method based on the Huber loss for the regression coefficients , when the error distribution is heavy-tailed and asymmetric in a high-dimensional linear model with an intercept term. The asymptotic properties of the resulting estimators are established under mild conditions. We also extend the proposed method to accommodate heteroscedasticity assuming the error terms are symmetric and other suitable conditions. Statistical tests for low-dimensional parameters or individual coefficient in the high-dimensional linear model are also studied. Simulation studies demonstrate desirable properties of the proposed method. An application to a genomic dataset about riboflavin production rate is provided.},
  archive      = {J_JOE},
  author       = {Dongxiao Han and Jian Huang and Yuanyuan Lin and Guohao Shen},
  doi          = {10.1016/j.jeconom.2021.05.006},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {416-431},
  shortjournal = {J. Econ.},
  title        = {Robust post-selection inference of high-dimensional mean regression with heavy-tailed asymmetric or heteroskedastic errors},
  volume       = {230},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimation of varying coefficient models with measurement
error. <em>JOE</em>, <em>230</em>(2), 388–415. (<a
href="https://doi.org/10.1016/j.jeconom.2020.12.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a semiparametric estimator for varying coefficient models when the regressors in the nonparametric components are measured with error. Varying coefficient models are an extension of other popular semiparametric models, including partially linear and nonparametric additive models , and deliver an attractive solution to the curse-of-dimensionality. We use deconvolution kernel estimation in a two-step procedure and show that the estimator is consistent and asymptotically normally distributed. We do not assume that we know the distribution of the measurement error a priori. Instead, we suppose we have access to a repeated measurement of the noisy regressor and present results using the approach of Delaigle, Hall and Meister (2008) and, for cases when the measurement error may be asymmetric, the approach of Li and Vuong (1998) based on Kotlarski’s (1967) identity. We show that the convergence rate of the estimator is significantly reduced when the distribution of the measurement error is assumed unknown and possibly asymmetric. We study the small sample behaviour of our estimator in a simulation study and apply it to a real dataset. In particular, we consider the role of cognitive ability in augmenting the effect of risk preferences on earnings.},
  archive      = {J_JOE},
  author       = {Hao Dong and Taisuke Otsu and Luke Taylor},
  doi          = {10.1016/j.jeconom.2020.12.013},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {388-415},
  shortjournal = {J. Econ.},
  title        = {Estimation of varying coefficient models with measurement error},
  volume       = {230},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimation and inference about tail features with tail
censored data. <em>JOE</em>, <em>230</em>(2), 363–387. (<a
href="https://doi.org/10.1016/j.jeconom.2021.01.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers estimation and inference about tail features such as tail index and extreme quantile when the observations beyond some threshold are censored. Ignoring such tail censoring could lead to substantial bias and size distortion, even if the censored probability is tiny. We first propose a new maximum likelihood estimator (MLE) based on the Pareto tail approximation and derive its asymptotic properties . Then, we propose an alternative method of constructing confidence intervals by resorting to extreme value theory . The MLE and the confidence intervals deliver excellent small sample performance, as shown by Monte Carlo simulations . Finally, we apply the proposed methods to estimate and construct confidence intervals for the tail index of the distribution of macroeconomic disasters and the coefficient of risk aversion using the dataset collected by Barro and Ursúa (2008). Our empirical findings are substantially different from those obtained from the existing methods.},
  archive      = {J_JOE},
  author       = {Yulong Wang and Zhijie Xiao},
  doi          = {10.1016/j.jeconom.2021.01.013},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {363-387},
  shortjournal = {J. Econ.},
  title        = {Estimation and inference about tail features with tail censored data},
  volume       = {230},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast and accurate variational inference for models with many
latent variables. <em>JOE</em>, <em>230</em>(2), 339–362. (<a
href="https://doi.org/10.1016/j.jeconom.2021.05.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Models with a large number of latent variables are often used to utilize the information in big or complex data, but can be difficult to estimate. Variational inference methods provide an attractive solution. These methods use an approximation to the posterior density, yet for large latent variable models existing choices can be inaccurate or slow to calibrate. Here, we propose a family of tractable variational approximations that are more accurate and faster to calibrate for this case. It combines a parsimonious approximation for the parameter posterior with the exact conditional posterior of the latent variables. We derive a simplified expression for the re-parameterization gradient of the variational lower bound, which is the main ingredient of optimization algorithms used for calibration. Implementation only requires exact or approximate generation from the conditional posterior of the latent variables, rather than computation of their density. In effect, our method provides a new way to employ Markov chain Monte Carlo (MCMC) within variational inference. We illustrate using two complex contemporary econometric examples. The first is a nonlinear multivariate state space model for U.S. macroeconomic variables . The second is a random coefficients tobit model applied to two million sales by 20,000 individuals in a consumer panel. In both cases, our approximating family is considerably more accurate than mean field or structured Gaussian approximations, and faster than MCMC. Last, we show how to implement data sub-sampling in variational inference for our approximation, further reducing computation time. MATLAB code implementing the method is provided.},
  archive      = {J_JOE},
  author       = {Rubén Loaiza-Maya and Michael Stanley Smith and David J. Nott and Peter J. Danaher},
  doi          = {10.1016/j.jeconom.2021.05.002},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {339-362},
  shortjournal = {J. Econ.},
  title        = {Fast and accurate variational inference for models with many latent variables},
  volume       = {230},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Inference on covariance-mean regression. <em>JOE</em>,
<em>230</em>(2), 318–338. (<a
href="https://doi.org/10.1016/j.jeconom.2021.05.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we introduce a covariance-mean regression model with heterogeneous similarity matrices. It not only links the covariance of responses to heterogeneous similarity matrices induced by auxiliary information, but also establishes the relationship between the mean of responses and covariates . Under this new model setting, however, two statistical inference challenges are encountered. The first challenge is that the consistency of the covariance estimator based on the standard profile likelihood approach breaks down. Hence, we propose an adjustment and develop the Z Z -estimation and unconstrained/constrained ordinary least squares estimation methods. We demonstrate that the resulting estimators are consistent and asymptotically normal. The second challenge is testing the adequacy of the covariance-mean regression model comprising both the multivariate mean regression and the heterogeneous covariance matrices . Correspondingly, we introduce two diagnostic test statistics and then obtain their theoretical properties. The proposed estimators and tests are illustrated via extensive simulations and an empirical example study of the stock return comovement in the US stock market.},
  archive      = {J_JOE},
  author       = {Tao Zou and Wei Lan and Runze Li and Chih-Ling Tsai},
  doi          = {10.1016/j.jeconom.2021.05.004},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {318-338},
  shortjournal = {J. Econ.},
  title        = {Inference on covariance-mean regression},
  volume       = {230},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sampling properties of the bayesian posterior mean with an
application to WALS estimation. <em>JOE</em>, <em>230</em>(2), 299–317.
(<a href="https://doi.org/10.1016/j.jeconom.2021.04.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many statistical and econometric learning methods rely on Bayesian ideas. When applied in a frequentist setting, their precision is often assessed using the posterior variance. This is permissible asymptotically, but not necessarily in finite samples. We explore this issue focusing on weighted-average least squares (WALS), a Bayesian-frequentist ‘fusion’. Exploiting the sampling properties of the posterior mean in the normal location model, we derive estimators of the finite-sample bias and variance of WALS. We study the performance of the proposed estimators in an empirical application and a closely related Monte Carlo experiment which analyze the impact of legalized abortion on crime.},
  archive      = {J_JOE},
  author       = {Giuseppe De Luca and Jan R. Magnus and Franco Peracchi},
  doi          = {10.1016/j.jeconom.2021.04.008},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {299-317},
  shortjournal = {J. Econ.},
  title        = {Sampling properties of the bayesian posterior mean with an application to WALS estimation},
  volume       = {230},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Markov switching panel with endogenous synchronization
effects. <em>JOE</em>, <em>230</em>(2), 281–298. (<a
href="https://doi.org/10.1016/j.jeconom.2021.04.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new dynamic panel model with multi-layer network effects. Series-specific latent Markov chain processes drive the dynamics of the observable processes, and several types of interaction effects among the hidden chains allow for various degrees of endogenous synchronization of both latent and observable processes. The interaction is driven by a multi-layer network with exogenous and endogenous connectivity layers. We provide some theoretical properties of the model, develop a Bayesian inference framework and an efficient Markov Chain Monte Carlo algorithm for estimating parameters, latent states, and endogenous network layers. An application to the US-state coincident indicators shows that the synchronization in the US economy is generated by network effects among the states. The inclusion of a multi-layer network provides a new tool for measuring the effects of the public policies that impact the connectivity between the US states, such as mobility restrictions or job support schemes. The proposed new model and the related inference are general and may find application in a wide spectrum of datasets where the extraction of endogenous interaction effects is relevant and of interest.},
  archive      = {J_JOE},
  author       = {Komla M. Agudze and Monica Billio and Roberto Casarin and Francesco Ravazzolo},
  doi          = {10.1016/j.jeconom.2021.04.004},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {281-298},
  shortjournal = {J. Econ.},
  title        = {Markov switching panel with endogenous synchronization effects},
  volume       = {230},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Nonparametric jump variation measures from options.
<em>JOE</em>, <em>230</em>(2), 255–280. (<a
href="https://doi.org/10.1016/j.jeconom.2021.04.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel nonparametric method for estimating tail jump variation measures from short-dated options, which can achieve rate-efficiency and works in a general infinite jump activity setting, avoiding parametric or semiparametric assumptions for the jump measure. The method is based on expressing the measures of interest as integrals of the Laplace transforms of the jump compensator and developing methods for recovering nonparametrically the latter from the available option data. The separation of volatility from jumps is done in a novel way by making use of the second derivative of the Laplace transform of the returns, de-biased using either the value of the Laplace transform or of its second derivative evaluated at high frequencies. A Monte Carlo study shows the superiority of the newly-developed method over existing ones in empirically realistic settings. In an empirical application to S&amp;P 500 index options, we find risk-neutral negative market tail jump variation that is on average smaller than previous estimates of it, is generated by smaller-sized jumps, and has less dependence on the level of diffusive volatility.},
  archive      = {J_JOE},
  author       = {Viktor Todorov},
  doi          = {10.1016/j.jeconom.2021.04.005},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {255-280},
  shortjournal = {J. Econ.},
  title        = {Nonparametric jump variation measures from options},
  volume       = {230},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Global temperatures and greenhouse gases: A common features
approach. <em>JOE</em>, <em>230</em>(2), 240–254. (<a
href="https://doi.org/10.1016/j.jeconom.2021.04.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a common features approach for testing for common trends and estimating long-run relationships between variables with complex trends. Using this approach, we establish that global temperatures and the concentration of greenhouse gases share a common trend and we estimate their long-run relationship without conditioning on the exact nature of this trend.},
  archive      = {J_JOE},
  author       = {Li Chen and Jiti Gao and Farshid Vahid},
  doi          = {10.1016/j.jeconom.2021.04.003},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {240-254},
  shortjournal = {J. Econ.},
  title        = {Global temperatures and greenhouse gases: A common features approach},
  volume       = {230},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predictive functional linear models with diverging number of
semiparametric single-index interactions. <em>JOE</em>, <em>230</em>(2),
221–239. (<a
href="https://doi.org/10.1016/j.jeconom.2021.03.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When predicting crop yield using both functional and multivariate predictors, the prediction performances benefit from the inclusion of the interactions between the two sets of predictors. We assume the interaction depends on a nonparametric, single-index structure of the multivariate predictor and reduce each functional predictor’s dimension using functional principal component analysis (FPCA). Allowing the number of FPCA scores to diverge to infinity, we consider a sequence of semiparametric working models with a diverging number of predictors, which are FPCA scores with estimation errors. We show that the parametric component of the model is root-n consistent and asymptotically normal, the overall prediction error is dominated by the estimation of the nonparametric interaction function, and justify a CV-based procedure to select the tuning parameters.},
  archive      = {J_JOE},
  author       = {Yanghui Liu and Yehua Li and Raymond J. Carroll and Naisyin Wang},
  doi          = {10.1016/j.jeconom.2021.03.010},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {221-239},
  shortjournal = {J. Econ.},
  title        = {Predictive functional linear models with diverging number of semiparametric single-index interactions},
  volume       = {230},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Affine arbitrage-free yield net models with application to
the euro debt crisis. <em>JOE</em>, <em>230</em>(1), 201–220. (<a
href="https://doi.org/10.1016/j.jeconom.2021.11.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a parsimonious class of affine arbitrage-free yield net models for consistent bond pricing across maturities and issuers of different risk levels. Containing a core curve and multiple peripheral curves, the yield net is spanned by three layers of factors: base factors spanning all curves, and common and individual spread factors. Under the arbitrage-free assumption, we prove a parsimonious solution to the risk-neutral process that guarantees joint identification of parameters and latent states. By using a Bayesian estimation method with a marginal Metropolis–Hastings algorithm and specification tests based on MCMC output, we apply the model to weekly treasury yields of Germany, Italy, Spain, and Greece from 2009 to 2016. The results show that the extracted common credit risk is a level factor in spread, and market liquidity risk is a slope factor. Further, the net structure helps reconstruct the Greek yield curve even with only its 10-year yield available throughout the sample.},
  archive      = {J_JOE},
  author       = {Zhiwu Hong and Linlin Niu and Chen Zhang},
  doi          = {10.1016/j.jeconom.2021.11.002},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {201-220},
  shortjournal = {J. Econ.},
  title        = {Affine arbitrage-free yield net models with application to the euro debt crisis},
  volume       = {230},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Factor investing: A bayesian hierarchical approach.
<em>JOE</em>, <em>230</em>(1), 183–200. (<a
href="https://doi.org/10.1016/j.jeconom.2021.11.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the asset allocation problem when returns are predictable. We introduce a market-timing Bayesian hierarchical (BH) approach that adopts heterogeneous time-varying coefficients driven by lagged fundamental characteristics. Our approach estimates the conditional expected returns and residual covariance matrix jointly enables evaluating the estimation risk in the portfolio analysis. The hierarchical prior allows the modeling of different assets separately while sharing information across assets. We demonstrate the performance of the U.S. equity market, and our BH approach outperforms most alternative methods in terms of point prediction and interval coverage. In addition, the BH efficient portfolio achieves monthly returns of 0.92\% and a significant Jensen’s alpha of 0.32\% in sector investment over the past twenty years. We detect that technology, energy, and manufacturing are the most critical sectors in the past decade, and size, investment, and short-term reversal factors are heavily weighted in our portfolio. Furthermore, the stochastic discount factor constructed by our BH approach can explain many risk anomalies.},
  archive      = {J_JOE},
  author       = {Guanhao Feng and Jingyu He},
  doi          = {10.1016/j.jeconom.2021.11.001},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {183-200},
  shortjournal = {J. Econ.},
  title        = {Factor investing: A bayesian hierarchical approach},
  volume       = {230},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Asymptotically valid bayesian inference in the presence of
distributional misspecification in VAR models. <em>JOE</em>,
<em>230</em>(1), 154–182. (<a
href="https://doi.org/10.1016/j.jeconom.2020.12.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inaccurately imposing Gaussian distributional assumptions in standard multivariate time series models does not affect inference on the autoregressive coefficients but distorts both classical and Bayesian inference on the volatility matrix whenever the true error distribution has excess kurtosis relative to the multivariate normal density. Inference on the intercept is also affected whenever the innovations are generated from a non-symmetric distribution. As a result of distributional misspecification, Bayesian methods lead to asymptotically invalid posterior inference for the intercept and the volatility matrix and, consequently, invalid posterior credible sets for quantities such as impulse responses, variance decompositions and density forecasts. We propose a robust and computationally fast Bayesian procedure which delivers asymptotically correct posterior credible sets without the need for distributional assumptions. The proposed corrected Bayesian posteriors for the volatility matrix and the intercept vector are based on the asymptotic covariance of the QML estimators and admit a closed form. Implementation of the procedure requires consistent estimation of the multivariate skewness and kurtosis of the innovations, and we propose novel shrinkage estimators designed to shrink these large dimensional objects towards the skewness and kurtosis of a Gaussian vector. We extend our robust Bayesian analysis to accommodate non-Gaussian disturbances in the presence of parameter instability, by combining the estimators of the current paper with semi-parametric kernel-type methods. We demonstrate that our estimators deliver correct posterior coverage rates in an extensive Monte Carlo exercise under a variety of distributional specifications. Finally, we present empirical evidence that imposing Gaussianity or homoskedasticity assumptions on financial and uncertainty shocks is not justified and may lead to misleading empirical conclusions.},
  archive      = {J_JOE},
  author       = {Katerina Petrova},
  doi          = {10.1016/j.jeconom.2020.12.011},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {154-182},
  shortjournal = {J. Econ.},
  title        = {Asymptotically valid bayesian inference in the presence of distributional misspecification in VAR models},
  volume       = {230},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian nonparametric learning of how skill is distributed
across the mutual fund industry. <em>JOE</em>, <em>230</em>(1), 131–153.
(<a href="https://doi.org/10.1016/j.jeconom.2021.04.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we use Bayesian nonparametric learning to estimate the skill of actively managed mutual funds and also to estimate the population distribution of skill. A nonparametric hierarchical prior, where the hyperprior distribution is unknown and modeled with a Dirichlet Process prior, is used to model the skill parameter, with its posterior predictive distribution being an estimate of the population distribution. Our nonparametric approach is equivalent to an infinitely ordered mixture of normals where we resolve the uncertainty in the number of mixture components by learning how to partition the funds into groups according to the average ability and the variability in the skill of a group. By resolving the mixture’s uncertainty, our nonparametric prior avoids having to sequentially estimate and test an array of pre-specified, finite ordered, mixture priors. Applying our Bayesian nonparametric learning approach to a panel of actively managed, domestic equity funds, we find the population distribution of skill to be fat-tailed, skewed towards higher levels of performance, with two distinct modes – a primary mode where the average ability covers the average fees charged by funds, and a secondary mode at a performance level where a fund loses money for its investors.},
  archive      = {J_JOE},
  author       = {Mark Fisher and Mark J. Jensen},
  doi          = {10.1016/j.jeconom.2021.04.002},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {131-153},
  shortjournal = {J. Econ.},
  title        = {Bayesian nonparametric learning of how skill is distributed across the mutual fund industry},
  volume       = {230},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Real-time bayesian learning and bond return predictability.
<em>JOE</em>, <em>230</em>(1), 114–130. (<a
href="https://doi.org/10.1016/j.jeconom.2020.04.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper examines statistical and economic evidence of out-of-sample bond return predictability for a real-time Bayesian investor who learns about parameters, hidden states, and predictive models over time. We find some statistical evidence using information contained in forward rates. However, such statistical predictability can hardly generate any economic value for investors. Furthermore, we find that strong statistical and economic evidence of bond return predictability from fully-revised macroeconomic data vanishes when real-time macroeconomic information is used. We also show that highly levered investments in bonds can improve short-run bond return predictability.},
  archive      = {J_JOE},
  author       = {Runqing Wan and Andras Fulop and Junye Li},
  doi          = {10.1016/j.jeconom.2020.04.052},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {114-130},
  shortjournal = {J. Econ.},
  title        = {Real-time bayesian learning and bond return predictability},
  volume       = {230},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Posterior-based wald-type statistics for hypothesis testing.
<em>JOE</em>, <em>230</em>(1), 83–113. (<a
href="https://doi.org/10.1016/j.jeconom.2021.11.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new Wald-type statistic is proposed for hypothesis testing based on Bayesian posterior distributions under the correct model specification. The new statistic can be explained as a posterior version of the Wald statistic and has several nice properties. First, it is well-defined under improper prior distributions. Second, it avoids Jeffreys–Lindley–Bartlett’s paradox. Third, under the null hypothesis and repeated sampling, it follows a χ 2 χ2 distribution asymptotically, offering an asymptotically pivotal test. Fourth, it only requires inverting the posterior covariance for parameters of interest. Fifth and perhaps most importantly, when a random sample from the posterior distribution (such as MCMC output) is available, the proposed statistic can be easily obtained as a by-product of posterior simulation. In addition, the numerical standard error of the estimated proposed statistic can be computed based on random samples. A robust version of the test statistic is developed under model misspecification and inherits many nice properties of the new posterior statistic. The finite sample performance of the statistics is examined in Monte Carlo studies . The method is applied to two latent variable models used in microeconometrics and financial econometrics .},
  archive      = {J_JOE},
  author       = {Xiaobin Liu and Yong Li and Jun Yu and Tao Zeng},
  doi          = {10.1016/j.jeconom.2021.11.003},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {83-113},
  shortjournal = {J. Econ.},
  title        = {Posterior-based wald-type statistics for hypothesis testing},
  volume       = {230},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive bayesian estimation of conditional
discrete-continuous distributions with an application to stock market
trading activity. <em>JOE</em>, <em>230</em>(1), 62–82. (<a
href="https://doi.org/10.1016/j.jeconom.2021.11.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider Bayesian nonparametric estimation of conditional discrete-continuous distributions. Our model is based on a mixture of normal distributions with covariate dependent mixing probabilities . We use continuous latent variables for modeling the discrete part of the distribution. The marginal distribution of covariates is not modeled. Under anisotropic smoothness conditions on the data generating conditional distribution and a possibly increasing number of the support points for the discrete part of the distribution, we show that the posterior in our model contracts at frequentist adaptive optimal rates up to a log factor. Our results also imply an upper bound on the posterior contraction rate for predictive distributions when the data follow an ergodic Markov process and our model is used for modeling the Markov transition distribution. The proposed model performs well in an application to stock market trading activity.},
  archive      = {J_JOE},
  author       = {Andriy Norets and Justinas Pelenis},
  doi          = {10.1016/j.jeconom.2021.11.004},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {62-82},
  shortjournal = {J. Econ.},
  title        = {Adaptive bayesian estimation of conditional discrete-continuous distributions with an application to stock market trading activity},
  volume       = {230},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parsimony inducing priors for large scale state–space
models. <em>JOE</em>, <em>230</em>(1), 39–61. (<a
href="https://doi.org/10.1016/j.jeconom.2021.11.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {State–space models are commonly used in the engineering, economic, and statistical literature. They are flexible and encompass many well-known statistical models, including random coefficient autoregressive models and dynamic factor models. Bayesian analysis of state–space models has attracted much interest in recent years. However, for large scale models, prior specification becomes a challenging issue in Bayesian inference. In this paper, we propose a flexible prior for state–space models. The proposed prior is a mixture of four commonly entertained models, yet achieving parsimony in high-dimensional systems. Here “parsimony” is represented by the idea that, in a large system, some states may not be time-varying. Our prior for the state–space component’s standard deviation is capable to accommodate different scenarios. Simulation and simple examples are used throughout this paper to demonstrate the performance of the proposed prior. As an application, we consider the time-varying conditional covariance matrices of daily log returns of the components of the S&amp;P 100 index, leading to a state–space model with roughly five thousand time-varying states. Our model for this large system enables us to use parallel computing.},
  archive      = {J_JOE},
  author       = {Hedibert F. Lopes and Robert E. McCulloch and Ruey S. Tsay},
  doi          = {10.1016/j.jeconom.2021.11.005},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {39-61},
  shortjournal = {J. Econ.},
  title        = {Parsimony inducing priors for large scale state–space models},
  volume       = {230},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian and maximum likelihood analysis of large-scale
panel choice models with unobserved heterogeneity. <em>JOE</em>,
<em>230</em>(1), 20–38. (<a
href="https://doi.org/10.1016/j.jeconom.2020.11.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the estimation and inference procedures for the case of a logistic panel regression model with interactive fixed effects, where multiple individual effects are allowed and the model is capable of capturing high-dimensional cross-section dependence. The proposed model also allows for heterogeneous regression coefficients . New Bayesian and non-Bayesian approaches are introduced to estimate the model parameters. We investigate the asymptotic behaviors of the estimated parameters. We show the consistency and asymptotic normality of the estimated regression coefficients and the estimated interactive fixed effects when both the cross-section and time-series dimensions of the panel go to infinity. We prove that the dimensionality of the interactive effects can be consistently estimated by the proposed information criterion. Monte Carlo simulations demonstrate the satisfactory performance of the proposed method. Finally, the method is applied to study the performance of New York City medallion drivers in terms of efficiency.},
  archive      = {J_JOE},
  author       = {Tomohiro Ando and Jushan Bai and Kunpeng Li},
  doi          = {10.1016/j.jeconom.2020.11.013},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {20-38},
  shortjournal = {J. Econ.},
  title        = {Bayesian and maximum likelihood analysis of large-scale panel choice models with unobserved heterogeneity},
  volume       = {230},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian factor-adjusted sparse regression. <em>JOE</em>,
<em>230</em>(1), 3–19. (<a
href="https://doi.org/10.1016/j.jeconom.2020.06.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many sparse regression methods rely on an assumption that the covariates are weakly correlated, which hardly holds in many economic and financial datasets. To relax this assumption, we model the strongly correlated covariates by a factor structure: strong correlations among covariates are modeled by common factors, while the remaining variations of covariates are modeled as idiosyncratic components. We then propose a factor-adjusted sparse regression model and develop a semi-Bayesian estimation method for it. Posterior contraction rate and model selection consistency are established by a non-asymptotic analysis. Experimental studies show that the proposed method outperforms its Lasso analogue, manifests insensitivity to overestimates of the number of common factors, pays a negligible price when covariates are uncorrelated, scales up well with increasing sample size, dimensionality and sparsity, and converges fast to the posterior distribution . An application to the U.S. bond risk premia lends further support to the proposed model and method.},
  archive      = {J_JOE},
  author       = {Jianqing Fan and Bai Jiang and Qiang Sun},
  doi          = {10.1016/j.jeconom.2020.06.012},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {3-19},
  shortjournal = {J. Econ.},
  title        = {Bayesian factor-adjusted sparse regression},
  volume       = {230},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian methods in economics and finance: Editor’s
introduction. <em>JOE</em>, <em>230</em>(1), 1–2. (<a
href="https://doi.org/10.1016/j.jeconom.2021.12.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JOE},
  author       = {Jun Yu},
  doi          = {10.1016/j.jeconom.2021.12.004},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {1-2},
  shortjournal = {J. Econ.},
  title        = {Bayesian methods in economics and finance: Editor’s introduction},
  volume       = {230},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Volatility of volatility: Estimation and tests based on
noisy high frequency data with jumps. <em>JOE</em>, <em>229</em>(2),
422–451. (<a
href="https://doi.org/10.1016/j.jeconom.2021.02.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We establish a feasible central limit theorem with convergence rate n 1 / 8 n1/8 for the estimation of the integrated volatility of volatility (VoV) based on noisy high-frequency data with jumps. This is the first inference theory ever built for VoV estimation under such a general setup. The central limit theorem is applied to provide interval estimates of the VoV and conduct hypothesis tests. Furthermore, when one is interested in the null hypothesis that the VoV is zero, we show that a more powerful test can be established based on a VoV estimator with a convergence rate n 1 / 5 n1/5 under the null . Empirical results on the S&amp;P 500 and individual stocks show strong evidence of non-zero VoV.},
  archive      = {J_JOE},
  author       = {Yingying Li and Guangying Liu and Zhiyuan Zhang},
  doi          = {10.1016/j.jeconom.2021.02.007},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {422-451},
  shortjournal = {J. Econ.},
  title        = {Volatility of volatility: Estimation and tests based on noisy high frequency data with jumps},
  volume       = {229},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spurious functional-coefficient regression models and robust
inference with marginal integration. <em>JOE</em>, <em>229</em>(2),
396–421. (<a
href="https://doi.org/10.1016/j.jeconom.2020.12.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Functional-coefficient cointegrating models have become popular to model nonlinear nonstationarity in econometrics (Cai et al., 2009; Xiao, 2009). However, there is rare study on testing the existence of functional-coefficient cointegration. Consequently, functional-coefficient regressions involving nonstationary regressors may be spurious. This paper investigates the effect that spurious functional-coefficient regression has on the model diagnostics. We find that common characteristics of spurious regressions are manifest, including divergent local significance tests, random local goodness-of-fit, and local Durbin–Watson ratio converging to zero, complementing those discovered in spurious linear and nonparametric regressions (Phillips, 1986, 2009). In addition, spuriousness causes the divergences of the global significance tests proposed by Xiao (2009) and Sun et al. (2016), which are likely to produce misleading conclusions for practitioners when cointegration tests fail to reject a spurious regression. To resolve the problems, we propose a simple-to-implement inference procedure based on a semiparametric balanced regression, by augmenting regressors of the original spurious regression with lagged dependent variable and independent variables, with the aid of the marginal integration. This procedure achieves spurious regression detection via standard nonparametric inferential asymptotics, and is found robust to the true relationship between the integrated processes. The theoretical results are also corroborated by simulations.},
  archive      = {J_JOE},
  author       = {Yundong Tu and Ying Wang},
  doi          = {10.1016/j.jeconom.2020.12.010},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {396-421},
  shortjournal = {J. Econ.},
  title        = {Spurious functional-coefficient regression models and robust inference with marginal integration},
  volume       = {229},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Testing the eigenvalue structure of spot and integrated
covariance. <em>JOE</em>, <em>229</em>(2), 363–395. (<a
href="https://doi.org/10.1016/j.jeconom.2021.02.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For vector Itô semimartingale dynamics, we derive the asymptotic distributions of likelihood-ratio-type test statistics for the purpose of identifying the eigenvalue structure of both integrated and spot covariance matrices estimated using high-frequency data. Unlike the existing approaches where the cross-section dimension grows to infinity, our tests do not necessarily require large cross-section and thus allow for a wide range of applications. The tests, however, are based on non-standard asymptotic distributions with many nuisance parameters . Another contribution of this paper consists in proposing a bootstrap method to approximate these asymptotic distributions. While standard bootstrap methods focus on sampling point-wise returns, the proposed method replicates features of the asymptotic approximation of the statistics of interest that guarantee its validity. A Monte Carlo simulation study shows that the bootstrap-based test controls size and has power for even moderate size samples .},
  archive      = {J_JOE},
  author       = {Prosper Dovonon and Abderrahim Taamouti and Julian Williams},
  doi          = {10.1016/j.jeconom.2021.02.006},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {363-395},
  shortjournal = {J. Econ.},
  title        = {Testing the eigenvalue structure of spot and integrated covariance},
  volume       = {229},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Transformations and moment conditions for dynamic fixed
effects logit models. <em>JOE</em>, <em>229</em>(2), 350–362. (<a
href="https://doi.org/10.1016/j.jeconom.2021.01.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes transformations for dynamic fixed effects logit models. First, these transformations construct valid moment conditions for the case with neither explanatory variables nor time dummies. Using valid moment conditions, we can obtain the first-order condition of the conditional maximum likelihood estimator proposed by Chamberlain (1985). Next, we derive valid moment conditions based on the transformations for the cases with strictly exogenous continuous explanatory variables and/or time dummies when the number of time periods is four or more. Transformations of these moment conditions exactly coincide with a subset of those obtained by Honoré and Weidner (2020) using the functional differencing approach proposed by Bonhomme (2012).},
  archive      = {J_JOE},
  author       = {Yoshitsugu Kitazawa},
  doi          = {10.1016/j.jeconom.2021.01.007},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {350-362},
  shortjournal = {J. Econ.},
  title        = {Transformations and moment conditions for dynamic fixed effects logit models},
  volume       = {229},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On LASSO for predictive regression. <em>JOE</em>,
<em>229</em>(2), 322–349. (<a
href="https://doi.org/10.1016/j.jeconom.2021.02.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explanatory variables in a predictive regression typically exhibit low signal strength and various degrees of persistence. Variable selection in such a context is of great importance. In this paper, we explore the pitfalls and possibilities of the LASSO methods in this predictive regression framework. In the presence of stationary, local unit root, and cointegrated predictors, we show that the adaptive LASSO cannot asymptotically eliminate all cointegrating variables with zero regression coefficients . This new finding motivates a novel post-selection adaptive LASSO, which we call the twin adaptive LASSO (TAlasso), to restore variable selection consistency. Accommodating the system of heterogeneous regressors , TAlasso achieves the well-known oracle property. In contrast, conventional LASSO fails to attain coefficient estimation consistency and variable screening in all components simultaneously. We apply these LASSO methods to evaluate the short- and long-horizon predictability of S&amp;P 500 excess returns.},
  archive      = {J_JOE},
  author       = {Ji Hyung Lee and Zhentao Shi and Zhan Gao},
  doi          = {10.1016/j.jeconom.2021.02.002},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {322-349},
  shortjournal = {J. Econ.},
  title        = {On LASSO for predictive regression},
  volume       = {229},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Nonparametric estimation of the random coefficients model:
An elastic net approach. <em>JOE</em>, <em>229</em>(2), 299–321. (<a
href="https://doi.org/10.1016/j.jeconom.2020.11.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates and extends the computationally attractive nonparametric random coefficients estimator of Fox et al. (2011). We show that their estimator is a special case of the nonnegative LASSO, explaining its sparse nature observed in many applications. Recognizing this link, we extend the estimator, transforming it into a special case of the nonnegative elastic net. The extension improves the estimator’s recovery of the true support and allows for more accurate estimates of the random coefficients’ distribution. Our estimator is a generalization of the original estimator and therefore, is guaranteed to have a model fit at least as good as the original one. A theoretical analysis of both estimators’ properties shows that, under conditions, our generalized estimator approximates the true distribution more accurately. Two Monte Carlo experiments and an application to a travel mode data set illustrate the improved performance of the generalized estimator.},
  archive      = {J_JOE},
  author       = {Florian Heiss and Stephan Hetzenecker and Maximilian Osterhaus},
  doi          = {10.1016/j.jeconom.2020.11.010},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {299-321},
  shortjournal = {J. Econ.},
  title        = {Nonparametric estimation of the random coefficients model: An elastic net approach},
  volume       = {229},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A doubly corrected robust variance estimator for linear GMM.
<em>JOE</em>, <em>229</em>(2), 276–298. (<a
href="https://doi.org/10.1016/j.jeconom.2020.09.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new finite sample corrected variance estimator for the linear generalized method of moments (GMM) including the one-step, two-step, and iterated estimators. Our formula also corrects the over-identification bias in variance estimation on top of the commonly used finite sample correction of Windmeijer (2005), which corrects the bias from estimating the efficient weight matrix , so is doubly corrected. An important feature of the proposed double correction is that it automatically provides robustness to misspecification of the moment condition. In contrast, the conventional variance estimator and the Windmeijer correction are inconsistent under misspecification. That is, the double correction formula proposed in this paper provides a convenient way to obtain improved inference under correct specification and robustness against misspecification at the same time.},
  archive      = {J_JOE},
  author       = {Jungbin Hwang and Byunghoon Kang and Seojeong Lee},
  doi          = {10.1016/j.jeconom.2020.09.010},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {276-298},
  shortjournal = {J. Econ.},
  title        = {A doubly corrected robust variance estimator for linear GMM},
  volume       = {229},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sieve IV estimation of cross-sectional interaction models
with nonparametric endogenous effect. <em>JOE</em>, <em>229</em>(2),
263–275. (<a
href="https://doi.org/10.1016/j.jeconom.2020.11.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we consider cross-sectional interaction models including spatial autoregressive models and peer effects models as special cases. Our model allows the endogenous effect – the effect of others’ outcomes on one’s own outcome – to be nonlinear and nonparametric. For the model estimation, we propose a sieve instrumental variable estimator and establish both its consistency and asymptotic normality . Furthermore, we propose a nonparametric specification test for the linearity of the endogenous effect. Under the null hypothesis of linearity, we show that the test statistic is asymptotically distributed as normal. As an empirical illustration, we focus on the data on regional economic performance investigated by Gennaioli et al. (2013). This empirical analysis highlights the usefulness of the proposed model and method.},
  archive      = {J_JOE},
  author       = {Tadao Hoshino},
  doi          = {10.1016/j.jeconom.2020.11.008},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {263-275},
  shortjournal = {J. Econ.},
  title        = {Sieve IV estimation of cross-sectional interaction models with nonparametric endogenous effect},
  volume       = {229},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On improvability of model selection by model averaging.
<em>JOE</em>, <em>229</em>(2), 246–262. (<a
href="https://doi.org/10.1016/j.jeconom.2020.12.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In regression, model averaging (MA) provides an alternative to model selection (MS), and asymptotic efficiency theories have been derived for both MS and MA. Basically, under sensible conditions, MS asymptotically achieves the smallest estimation loss/risk among the candidate models, and MA does so among averaged estimators from the models with convex weights. Clearly, MA can beat MS by any extent in rate of convergence when all the candidate models have large biases that can be canceled out by a MA scheme. To our knowledge, however, a foundational issue has not been addressed in the literature. That is, when there is no advantage of reducing approximation error, does MA offer any significant improvement over MS in regression estimation? In this paper, we answer this question in a nested model setting that has been often used in the frequentist MA research area. A remarkable implication is that the much celebrated asymptotic efficiency of MS (e.g., by AIC) does not necessarily justify MS as commonly interpreted as achieving the best possible performance. In a nutshell, the oracle model (i.e., the unknowable best model among all the candidates) can be significantly improved by MA under certain conditions. A simulation study supports the theoretical findings.},
  archive      = {J_JOE},
  author       = {Jingfu Peng and Yuhong Yang},
  doi          = {10.1016/j.jeconom.2020.12.003},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {246-262},
  shortjournal = {J. Econ.},
  title        = {On improvability of model selection by model averaging},
  volume       = {229},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semiparametric model averaging prediction for dichotomous
response. <em>JOE</em>, <em>229</em>(2), 219–245. (<a
href="https://doi.org/10.1016/j.jeconom.2020.09.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model averaging has attracted abundant attentions in the past decades as it emerges as an impressive forecasting device in econometrics , social sciences and medicine. So far most developed model averaging methods focus only on either parametric models or nonparametric models with a continuous response. In this paper, we propose a semiparametric model averaging prediction (SMAP) method for a dichotomous response. The idea is to approximate the unknown score function by a linear combination of one-dimensional marginal score functions. The weight parameters involved in the approximation are obtained by first smoothing the nonparametric marginal scores and then applying the parametric model averaging via a maximum likelihood estimation . The proposed SMAP provides greater flexibility than parametric models while being more stable than a fully nonparametric approach. Theoretical properties are investigated in two practical scenarios: (i) covariates are conditionally independent given the response; and (ii) the conditional independence assumption does not hold. In the first scenario, we show that SMAP puts weight one to the true model and hence the model averaging estimators are consistent. In the second scenario in which a “true” model may not exist, SMAP is shown to be asymptotically optimal in the sense that its Kullback–Leibler loss is asymptotically identical to that of the best – but infeasible – model averaging estimator. Empirical evidences from simulation studies and a real data analysis are presented to support and illustrate our methods.},
  archive      = {J_JOE},
  author       = {Fang Fang and Jialiang Li and Xiaochao Xia},
  doi          = {10.1016/j.jeconom.2020.09.008},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {219-245},
  shortjournal = {J. Econ.},
  title        = {Semiparametric model averaging prediction for dichotomous response},
  volume       = {229},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Projected estimation for large-dimensional matrix factor
models. <em>JOE</em>, <em>229</em>(1), 201–217. (<a
href="https://doi.org/10.1016/j.jeconom.2021.04.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose a projection estimation method for large-dimensional matrix factor models with cross-sectionally spiked eigenvalues. By projecting the observation matrix onto the row or column factor space, we simplify factor analysis for matrix series to that of a lower-dimensional tensor. This method also reduces the magnitudes of the idiosyncratic error components, thereby increasing the signal-to-noise ratio, because the projection matrix linearly filters the idiosyncratic error matrix. We theoretically prove that the projected estimators of the factor loading matrices achieve faster convergence rates than existing estimators under similar conditions. Asymptotic distributions of the projected estimators are also presented. A novel iterative procedure is given to specify the pair of row and column factor numbers. Extensive numerical studies verify the empirical performance of the projection method. Two real examples in finance and macroeconomics reveal factor patterns across rows and columns, which coincide with financial, economic, or geographical interpretations.},
  archive      = {J_JOE},
  author       = {Long Yu and Yong He and Xinbing Kong and Xinsheng Zhang},
  doi          = {10.1016/j.jeconom.2021.04.001},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {201-217},
  shortjournal = {J. Econ.},
  title        = {Projected estimation for large-dimensional matrix factor models},
  volume       = {229},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Maximum likelihood estimation and inference for high
dimensional generalized factor models with application to
factor-augmented regressions. <em>JOE</em>, <em>229</em>(1), 180–200.
(<a href="https://doi.org/10.1016/j.jeconom.2020.11.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper reestablishes the main results in Bai (2003) and Bai and Ng (2006) for generalized factor models, with slightly stronger conditions on the relative magnitude of N (number of subjects) and T (number of time periods). Convergence rates of the estimated factor space and loading space and asymptotic normality of the estimated factors and loadings are established under mild conditions that allow for linear, Logit, Probit, Tobit, Poisson and some other single-index nonlinear models . The probability density/mass function is allowed to vary across subjects and time, thus mixed models are also allowed for. For factor-augmented regressions, this paper establishes the limit distributions of the parameter estimates, the conditional mean, and the forecast when factors estimated from nonlinear/mixed data are used as proxies for the true factors.},
  archive      = {J_JOE},
  author       = {Fa Wang},
  doi          = {10.1016/j.jeconom.2020.11.002},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {180-200},
  shortjournal = {J. Econ.},
  title        = {Maximum likelihood estimation and inference for high dimensional generalized factor models with application to factor-augmented regressions},
  volume       = {229},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Kotlarski with a factor loading. <em>JOE</em>,
<em>229</em>(1), 176–179. (<a
href="https://doi.org/10.1016/j.jeconom.2020.12.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This note extends the Kotlarski (1967) Lemma to show exactly what is identified when we allow for an unknown factor loading on the common unobserved factor . That is, this note completely characterizes identification of the model Y = = cV + + U and X = = V + + W, where the joint distribution of Y and X is known, while the constant c and the mutually independent random variables V, U, and W are unobserved. Potential applications include measurement error models and panel data factor models.},
  archive      = {J_JOE},
  author       = {Arthur Lewbel},
  doi          = {10.1016/j.jeconom.2020.12.012},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {176-179},
  shortjournal = {J. Econ.},
  title        = {Kotlarski with a factor loading},
  volume       = {229},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). High-dimensional test for alpha in linear factor pricing
models with sparse alternatives. <em>JOE</em>, <em>229</em>(1), 152–175.
(<a href="https://doi.org/10.1016/j.jeconom.2021.07.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of testing for the presence of alpha in Linear Factor Pricing Models. We propose a novel test of the max-of-squares type, which is designed to deal with the high dimensionality of the securities and the sparse alternatives. We rigorously show that the proposed test has attractive theoretical properties and demonstrate its superior performance via Monte Carlo experiments. These results are established when the number of securities is larger than the time dimension of the return series, and the alternative hypothesis is sparse, i.e. the alpha vector is sparse. As a general alternative, we suggest to combine the max-of-squares type test and a sum-of-squares type test, to benefit from the power advantages of both tests. We apply the two proposed tests to the monthly returns on securities in the Chinese and the U.S. stock markets, respectively under the Fama–French three-factor model, and confirm the usefulness of the proposed tests in detecting the presence of alpha.},
  archive      = {J_JOE},
  author       = {Long Feng and Wei Lan and Binghui Liu and Yanyuan Ma},
  doi          = {10.1016/j.jeconom.2021.07.011},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {152-175},
  shortjournal = {J. Econ.},
  title        = {High-dimensional test for alpha in linear factor pricing models with sparse alternatives},
  volume       = {229},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Functional time series approach to analyzing asset returns
co-movements. <em>JOE</em>, <em>229</em>(1), 127–151. (<a
href="https://doi.org/10.1016/j.jeconom.2020.11.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new approach for modeling the time varying behavior and time series evolution of asset returns co-movements. Here, the co-movement in each period is captured by a trajectory of returns correlation, then a sequence of this over time and the time series evolution are studied. We rely on functional principal components to achieve dimension reduction and to construct the dynamic space of interest, while introducing a new class of information criteria in order to identify the finite dimensionality of the curve time series. Our method is able to combine two of the most applied ideas in the literature, namely economics (or finance) based and time-series based time-varying correlation models. This offers a general specification that is able to model processes of time-varying time-series correlations generated under many existing models that have dominated the financial literature for several decades. To illustrate its empirical relevance, we apply our method to model the time varying co-movement of exchange rate returns for a group of small open economies with large financial sectors. Our empirical results indicate that concepts of time varying correlation enabled by existing methods are too restrictive to accommodate fully the time varying behavior and time series evolution of the returns correlation. On the other hand, our method gives a more complete picture and is able to provide more accurate correlation forecasts.},
  archive      = {J_JOE},
  author       = {Patrick W. Saart and Yingcun Xia},
  doi          = {10.1016/j.jeconom.2020.11.012},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {127-151},
  shortjournal = {J. Econ.},
  title        = {Functional time series approach to analyzing asset returns co-movements},
  volume       = {229},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Factor models with many assets: Strong factors, weak
factors, and the two-pass procedure. <em>JOE</em>, <em>229</em>(1),
103–126. (<a
href="https://doi.org/10.1016/j.jeconom.2021.01.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper re-examines the problem of estimating risk premia in unconditional linear factor pricing models. Typically, the data used in the empirical literature are characterized by weakness of some pricing factors, strong cross-sectional dependence in the errors, and (moderately) high cross-sectional dimensionality. Using an asymptotic framework where the number of assets/portfolios grows with the time span of the data while the risk exposures of weak factors are local-to-zero, we show that the conventional two-pass estimation procedure delivers inconsistent estimates of the risk premia. We propose a new estimation procedure based on sample-splitting instrumental variables regression . The proposed estimator of risk premia is robust to weak included factors and to the presence of strong unaccounted cross-sectional error dependence. We prove the consistency of the new estimator, establish asymptotically valid inferences using Wald statistics , verify performance of the new procedure in simulations, and revisit some empirical studies.},
  archive      = {J_JOE},
  author       = {Stanislav Anatolyev and Anna Mikusheva},
  doi          = {10.1016/j.jeconom.2021.01.002},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {103-126},
  shortjournal = {J. Econ.},
  title        = {Factor models with many assets: Strong factors, weak factors, and the two-pass procedure},
  volume       = {229},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Factor models with local factors — determining the number of
relevant factors. <em>JOE</em>, <em>229</em>(1), 80–102. (<a
href="https://doi.org/10.1016/j.jeconom.2021.04.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We extend the theory on factor models by incorporating “local” factors into the model. Local factors affect only an unknown subset of the observed variables. This implies a continuum of eigenvalues of the covariance matrix , as is commonly observed in applications. We derive which factors are pervasive enough to be economically important and which factors are pervasive enough to be estimable using the common principal component estimator. We then introduce a new class of estimators to determine the number of those relevant factors. Unlike existing estimators, our estimators use not only the eigenvalues of the covariance matrix , but also its eigenvectors . We find that incorporating partial sums of the eigenvectors into our estimators leads to significant gains in performance in simulations.},
  archive      = {J_JOE},
  author       = {Simon Freyaldenhoven},
  doi          = {10.1016/j.jeconom.2021.04.006},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {80-102},
  shortjournal = {J. Econ.},
  title        = {Factor models with local factors — determining the number of relevant factors},
  volume       = {229},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimation and inference in heterogeneous spatial panels
with a multifactor error structure. <em>JOE</em>, <em>229</em>(1),
55–79. (<a href="https://doi.org/10.1016/j.jeconom.2021.05.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a unifying econometric framework for the analysis of heterogeneous panel data models that can account for both spatial dependence and common factors. To tackle the challenging issues of endogeneity due to the spatial lagged term and the correlation between the regressors and factors, we propose the CCEX-IV estimation procedure that approximates factors by the cross-section averages of regressors and deals with the spatial endogeneity using the internal instrumental variables. We develop the individual and Mean Group estimators, and establish their consistency and asymptotic normality . By contrast, the Pooled estimator is shown to be inconsistent in the presence of parameter heterogeneity. Monte Carlo simulations confirm that the finite sample performance of the proposed estimators is quite satisfactory. We demonstrate the usefulness of our approach with an application to the house price growth for Local Authority Districts in the UK over 1997Q1–2016Q4.},
  archive      = {J_JOE},
  author       = {Jia Chen and Yongcheol Shin and Chaowen Zheng},
  doi          = {10.1016/j.jeconom.2021.05.003},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {55-79},
  shortjournal = {J. Econ.},
  title        = {Estimation and inference in heterogeneous spatial panels with a multifactor error structure},
  volume       = {229},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An incidental parameters free inference approach for panels
with common shocks. <em>JOE</em>, <em>229</em>(1), 19–54. (<a
href="https://doi.org/10.1016/j.jeconom.2021.03.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a novel Method of Moments approach for panel data models with endogenous regressors and unobserved common factors. The proposed approach does not require estimating explicitly a large number of parameters in either time-series or cross-sectional dimension, T T and N N respectively. Hence, it is free from the incidental parameter problem. In particular, the proposed approach does not suffer from “Nickell bias” of order O ( T − 1 ) O(T−1) , nor from bias terms that are of order O ( N − 1 ) O(N−1) . Therefore, it can operate under substantially weaker restrictions compared to existing large T T procedures. Two alternative GMM estimators are analyzed; one makes use of a fixed number of “averaged estimating equations” à la Anderson and Hsiao (1982), whereas the other one makes use of “stacked estimating equations”, the total number of which increases at the rate of O ( T ) O(T) . It is demonstrated that both estimators are consistent and asymptotically mixed-normal as N → ∞ N→∞ for any value of T T . Low-level conditions that ensure local and global identification in this setup are examined using several examples.},
  archive      = {J_JOE},
  author       = {Artūras Juodis and Vasilis Sarafidis},
  doi          = {10.1016/j.jeconom.2021.03.011},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {19-54},
  shortjournal = {J. Econ.},
  title        = {An incidental parameters free inference approach for panels with common shocks},
  volume       = {229},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Asymptotic properties of correlation-based principal
component analysis. <em>JOE</em>, <em>229</em>(1), 1–18. (<a
href="https://doi.org/10.1016/j.jeconom.2021.08.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is a common practice to conduct principal component analysis (PCA) using standardized data, which is equivalent to applying PCA to the correlation matrix rather than the covariance matrix . Yet little research has been done about such differences in the context of high frequency data. This paper bridges this gap. We derive the analytical forms of the asymptotic biases and variances for the estimators of the integrated eigenvalues and eigenvectors . Furthermore, we propose a novel jackknife-type estimator of the asymptotic variance of the integrated volatility functional estimator. This new variance estimator shows much better finite sample performances compared to other existing ones. This paper also proposes several statistical tests for some commonly tested hypotheses in the literature. Simulation results show that one will get misleading results if one uses the analytical results of the covariance case when applying PCA on the correlation matrix .},
  archive      = {J_JOE},
  author       = {Jungjun Choi and Xiye Yang},
  doi          = {10.1016/j.jeconom.2021.08.003},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {1-18},
  shortjournal = {J. Econ.},
  title        = {Asymptotic properties of correlation-based principal component analysis},
  volume       = {229},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An integrated panel data approach to modelling economic
growth. <em>JOE</em>, <em>228</em>(2), 379–397. (<a
href="https://doi.org/10.1016/j.jeconom.2020.09.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Empirical growth analysis is plagued with three problems – variable selection, parameter heterogeneity and cross-sectional dependence – which are addressed independently from each other in most studies. This study is to propose an integrated framework that allows for parameter heterogeneity and cross-sectional error dependence, while simultaneously performing variable selection. We derive the asymptotic properties of the estimator, and apply the framework to a dataset of 89 countries over the period from 1960 to 2014. Our results support the “optimistic” conclusion of Sala-I-Martin (1997), and also reveal some cross-country patterns not found previously.},
  archive      = {J_JOE},
  author       = {Guohua Feng and Jiti Gao and Bin Peng},
  doi          = {10.1016/j.jeconom.2020.09.009},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {379-397},
  shortjournal = {J. Econ.},
  title        = {An integrated panel data approach to modelling economic growth},
  volume       = {228},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Illuminating economic growth. <em>JOE</em>, <em>228</em>(2),
359–378. (<a
href="https://doi.org/10.1016/j.jeconom.2021.05.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper seeks to illuminate national accounts GDP growth using satellite-recorded nighttime lights in a measurement error model framework. Using recently developed results in conjunction with reasonable assumptions about the exogeneity of the lights data generating process, we identify and estimate the relationship between nighttime light growth and GDP growth, as well as the nonparametric distribution of errors in both measures. We obtain three key results: (i) the elasticity of nighttime lights to GDP is about 1.3; (ii) national accounts GDP growth measures are less precise for low and middle income countries, and nighttime lights can play a big role in improving such measures; and (iii) our new measure of GDP growth, based on the optimal combination of nighttime lights and national accounts data under our identification assumptions, implies that China and India had considerably lower growth rates than official data suggested between 1993 and 2013. We expect our statistical framework and methodology to have a broad impact on measuring GDP using additional information.},
  archive      = {J_JOE},
  author       = {Yingyao Hu and Jiaxiong Yao},
  doi          = {10.1016/j.jeconom.2021.05.007},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {359-378},
  shortjournal = {J. Econ.},
  title        = {Illuminating economic growth},
  volume       = {228},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A stochastic dominance test under survey nonresponse with an
application to comparing trust levels in lebanese public institutions.
<em>JOE</em>, <em>228</em>(2), 342–358. (<a
href="https://doi.org/10.1016/j.jeconom.2021.09.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic dominance comparisons of distributions based on ordinal data arise in many areas of economics. This paper develops a testing procedure for such comparisons under survey sampling from large finite populations with nonresponse using the worst-case bounds of the distributions. The advantage of using these bounds in distributional comparisons is that conclusions are robust to the nature of the nonresponse-generating mechanism. While these bounds on the distributions are often too wide in practice, we show that they can be informative for distributional comparisons in an empirical analysis. This paper examines the dynamics of trust in Lebanese public institutions using the 2013 wave of the World Values Survey as well as the 2016 and 2018 waves of the Arab Barometer , and finds convincing evidence of a decrease in confidence in most public institutions between 2013 and 2016.},
  archive      = {J_JOE},
  author       = {Ali Fakih and Paul Makdissi and Walid Marrouch and Rami V. Tabri and Myra Yazbeck},
  doi          = {10.1016/j.jeconom.2021.09.016},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {342-358},
  shortjournal = {J. Econ.},
  title        = {A stochastic dominance test under survey nonresponse with an application to comparing trust levels in lebanese public institutions},
  volume       = {228},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Latent complementarity in bundles models. <em>JOE</em>,
<em>228</em>(2), 322–341. (<a
href="https://doi.org/10.1016/j.jeconom.2021.10.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies partial identification of latent complementarity in an optimizing model with two goods and binary quantities of each good (buy/do not buy). We provide bounds on the fraction of individuals for whom goods are complements, or substitutes. When utility indices are unknown, we present simple bounds that require only the average structural function (“mean demands”). We show these simple bounds are sharp with only a binary demand shifter. Next, we characterize sharp bounds with richer variation in covariates when utility indices are known, using either the average structural function or structural choice probabilities . In simulations with binary variation in regressors for both goods, we find that the latter bounds coincide. Together, these results indicate that mean demands contain rich information for measuring complementarity without observing whether goods are chosen together.},
  archive      = {J_JOE},
  author       = {Roy Allen and John Rehbeck},
  doi          = {10.1016/j.jeconom.2021.10.004},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {322-341},
  shortjournal = {J. Econ.},
  title        = {Latent complementarity in bundles models},
  volume       = {228},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Infinite markov pooling of predictive distributions.
<em>JOE</em>, <em>228</em>(2), 302–321. (<a
href="https://doi.org/10.1016/j.jeconom.2021.10.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces novel approaches to forecast pooling methods based on a nonparametric prior for a weight vector combining predictive densities. The first approach places a Dirichlet process prior on the weight vector and generalizes the static linear pool. The second approach uses a hierarchical Dirichlet process prior to allow the weight vector to follow an infinite hidden Markov chain . This generalizes dynamic prediction pools to the nonparametric setting. Efficient posterior simulation based on MCMC methods is also examined. Detailed applications to short-term interest rates , realized covariance matrices and asset pricing models demonstrate that the nonparametric pool forecasts well. The paper concludes with extensions and an application for calibrating and combining predictive densities.},
  archive      = {J_JOE},
  author       = {Xin Jin and John M. Maheu and Qiao Yang},
  doi          = {10.1016/j.jeconom.2021.10.010},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {302-321},
  shortjournal = {J. Econ.},
  title        = {Infinite markov pooling of predictive distributions},
  volume       = {228},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Instrument-free identification and estimation of
differentiated products models using cost data. <em>JOE</em>,
<em>228</em>(2), 278–301. (<a
href="https://doi.org/10.1016/j.jeconom.2021.12.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new methodology for identifying and estimating demand in differentiated products models when demand and cost data are available. The method deals with the endogeneity of prices to demand shocks and the endogeneity of outputs to cost shocks by using cost data rather than instruments. Further, we allow for unobserved market size. Using Monte Carlo experiments, we show that our method works well in contexts where commonly used instruments are invalid. We also apply our method to the estimation of deposit demand in the US banking industry .},
  archive      = {J_JOE},
  author       = {David P. Byrne and Susumu Imai and Neelam Jain and Vasilis Sarafidis},
  doi          = {10.1016/j.jeconom.2021.12.006},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {278-301},
  shortjournal = {J. Econ.},
  title        = {Instrument-free identification and estimation of differentiated products models using cost data},
  volume       = {228},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Can we measure inflation expectations using twitter?
<em>JOE</em>, <em>228</em>(2), 259–277. (<a
href="https://doi.org/10.1016/j.jeconom.2021.12.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drawing on Italian tweets, we employ textual data and machine learning techniques to build new real-time measures of consumers’ inflation expectations . First, we select keywords to identify tweets related to prices and expectations thereof. Second, we build a set of daily measures of inflation expectations around the selected tweets, combining the Latent Dirichlet Allocation (LDA) with a dictionary-based approach, using manually labeled bi-grams and tri-grams. Finally, we show that Twitter-based indicators are highly correlated with both monthly survey-based and daily market-based inflation expectations . Our new indicators anticipate consumers’ expectations, proving to be a good real-time proxy, and provide additional information beyond market-based expectations, professional forecasts, and realized inflation . The results suggest that Twitter can be a new timely source for eliciting beliefs.},
  archive      = {J_JOE},
  author       = {Cristina Angelico and Juri Marcucci and Marcello Miccoli and Filippo Quarta},
  doi          = {10.1016/j.jeconom.2021.12.008},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {259-277},
  shortjournal = {J. Econ.},
  title        = {Can we measure inflation expectations using twitter?},
  volume       = {228},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An explainable attention network for fraud detection in
claims management. <em>JOE</em>, <em>228</em>(2), 244–258. (<a
href="https://doi.org/10.1016/j.jeconom.2020.05.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Insurance companies must manage millions of claims per year. While most of these are not fraudulent, those that are nevertheless cost insurance companies and those they insure vast amounts of money. The ultimate goal is to develop a predictive model that can single out fraudulent claims and pay out non-fraudulent ones automatically. Health care claims have a peculiar data structure, comprising inputs of varying length and variables with a large number of categories. Both issues are challenging for traditional econometric methods. We develop a deep learning model that can handle these challenges by adapting methods from text classification . Using a large dataset from a private health insurer in Germany, we show that the model we propose outperforms a conventional machine learning model. With the rise of digitalization, unstructured data with characteristics similar to ours will become increasingly common in applied research, and methods to deal with such data will be needed.},
  archive      = {J_JOE},
  author       = {Helmut Farbmacher and Leander Löw and Martin Spindler},
  doi          = {10.1016/j.jeconom.2020.05.021},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {244-258},
  shortjournal = {J. Econ.},
  title        = {An explainable attention network for fraud detection in claims management},
  volume       = {228},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Measuring news sentiment. <em>JOE</em>, <em>228</em>(2),
221–243. (<a
href="https://doi.org/10.1016/j.jeconom.2020.07.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper demonstrates state-of-the-art text sentiment analysis tools while developing a new time-series measure of economic sentiment derived from economic and financial newspaper articles from January 1980 to April 2015. We compare the predictive accuracy of a large set of sentiment analysis models using a sample of articles that have been rated by humans on a positivity/negativity scale. The results highlight the gains from combining existing lexicons and from accounting for negation. We also generate our own sentiment-scoring model, which includes a new lexicon built specifically to capture the sentiment in economic news articles. This model is shown to have better predictive accuracy than existing “off-the-shelf” models. Lastly, we provide two applications to the economic research on sentiment. First, we show that daily news sentiment is predictive of movements of survey-based measures of consumer sentiment. Second, motivated by Barsky and Sims (2012), we estimate the impulse responses of macroeconomic variables to sentiment shocks, finding that positive sentiment shocks increase consumption, output, and interest rates and dampen inflation .},
  archive      = {J_JOE},
  author       = {Adam Hale Shapiro and Moritz Sudhof and Daniel J. Wilson},
  doi          = {10.1016/j.jeconom.2020.07.053},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {221-243},
  shortjournal = {J. Econ.},
  title        = {Measuring news sentiment},
  volume       = {228},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SONIC: SOcial network analysis with influencers and
communities. <em>JOE</em>, <em>228</em>(2), 177–220. (<a
href="https://doi.org/10.1016/j.jeconom.2021.02.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of social media characteristics into an econometric framework requires modeling a high dimensional dynamic network with dimensions of parameter typically much larger than the number of observations. To cope with this problem, we introduce SONIC, a new high-dimensional network model that assumes that (1) only few influencers drive the network dynamics; (2) the community structure of the network is characterized by homogeneity of response to specific influencers, implying their underlying similarity. An estimation procedure is proposed based on a greedy algorithm and LASSO regularization . Through theoretical study and simulations, we show that the matrix parameter can be estimated even when sample size is smaller than the size of the network. Using a novel dataset retrieved from one of leading social media platforms — StockTwits and quantifying their opinions via natural language processing, we model the opinions network dynamics among a select group of users and further detect the latent communities. With a sparsity regularization, we can identify important nodes in the network.},
  archive      = {J_JOE},
  author       = {Cathy Yi-Hsuan Chen and Wolfgang Karl Härdle and Yegor Klochkov},
  doi          = {10.1016/j.jeconom.2021.02.008},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {177-220},
  shortjournal = {J. Econ.},
  title        = {SONIC: SOcial network analysis with influencers and communities},
  volume       = {228},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Variation and efficiency of high-frequency betas.
<em>JOE</em>, <em>228</em>(1), 156–175. (<a
href="https://doi.org/10.1016/j.jeconom.2020.05.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the efficient estimation of betas from high-frequency return data on a fixed time interval . Under an assumption of equal diffusive and jump betas, we derive the semiparametric efficiency bound for estimating the common beta and develop an adaptive estimator that attains the efficiency bound. We further propose a Hausman type test for deciding whether the common beta assumption is true from the high-frequency data. In our empirical analysis we provide examples of stocks and time periods for which a common market beta assumption appears true and ones for which this is not the case. We further quantify empirically the gains from the efficient common beta estimation developed in the paper.},
  archive      = {J_JOE},
  author       = {Congshan Zhang and Jia Li and Viktor Todorov and George Tauchen},
  doi          = {10.1016/j.jeconom.2020.05.022},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {156-175},
  shortjournal = {J. Econ.},
  title        = {Variation and efficiency of high-frequency betas},
  volume       = {228},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Copula-based time series with filtered nonstationarity.
<em>JOE</em>, <em>228</em>(1), 127–155. (<a
href="https://doi.org/10.1016/j.jeconom.2020.10.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Economic and financial time series data can exhibit nonstationary and nonlinear patterns simultaneously. This paper studies copula-based time series models that capture both patterns. We introduce a procedure where nonstationarity is removed via a filtration, and then the nonlinear temporal dependence in the filtered data is captured via a flexible Markov copula . We propose two estimators of the copula dependence parameters: the parametric (two-step) copula estimator where the marginal distribution of the filtered series is estimated parametrically; and the semiparametric (two-step) copula estimator where the marginal distribution is estimated via a rescaled empirical distribution of the filtered series. We show that the limiting distribution of the parametric copula estimator depends on the nonstationary filtration and the parametric marginal distribution estimation, and may be non-normal. Surprisingly, the limiting distribution of the semiparametric copula estimator using the filtered data is shown to be the same as that without nonstationary filtration, which is normal and free of marginal distribution specification. The simple and robust properties of the semiparametric copula estimators extend to models with misspecified copulas, and facilitate statistical inferences , such as hypothesis testing and model selection tests, on semiparametric copula-based dynamic models in the presence of nonstationarity. Monte Carlo studies and real data applications are presented.},
  archive      = {J_JOE},
  author       = {Xiaohong Chen and Zhijie Xiao and Bo Wang},
  doi          = {10.1016/j.jeconom.2020.10.008},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {127-155},
  shortjournal = {J. Econ.},
  title        = {Copula-based time series with filtered nonstationarity},
  volume       = {228},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust bayesian inference in proxy SVARs. <em>JOE</em>,
<em>228</em>(1), 107–126. (<a
href="https://doi.org/10.1016/j.jeconom.2021.02.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop methods for robust Bayesian inference in structural vector autoregressions (SVARs) where the parameters of interest are set-identified using external instruments, or ‘proxy SVARs’. Set-identification in these models typically occurs when there are multiple instruments for multiple structural shocks. Existing Bayesian approaches to inference in proxy SVARs require researchers to specify a single prior over the model’s parameters, but, under set-identification, a component of the prior is never revised. We extend the robust Bayesian approach to inference in set-identified models proposed by Giacomini and Kitagawa in press[a] – which allows researchers to relax potentially controversial point-identifying restrictions without having to specify an unrevisable prior – to proxy SVARs. We provide new results on the frequentist validity of the approach in proxy SVARs. We also explore the effect of instrument strength on inference about the identified set. We illustrate our approach by revisiting Mertens and Ravn (2013) and relaxing the assumption that they impose to obtain point identification.},
  archive      = {J_JOE},
  author       = {Raffaella Giacomini and Toru Kitagawa and Matthew Read},
  doi          = {10.1016/j.jeconom.2021.02.003},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {107-126},
  shortjournal = {J. Econ.},
  title        = {Robust bayesian inference in proxy SVARs},
  volume       = {228},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Constrained estimation using penalization and MCMC.
<em>JOE</em>, <em>228</em>(1), 85–106. (<a
href="https://doi.org/10.1016/j.jeconom.2021.02.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study inference for parameters defined by either classical extremum estimators or Laplace-type estimators subject to general nonlinear constraints on the parameters. We show that running MCMC on the penalized version of the problem offers a computationally attractive alternative to solving the original constrained optimization problem . Bayesian credible intervals are asymptotically valid confidence intervals in a pointwise sense, providing exact asymptotic coverage for general functions of the parameters. We allow for nonadaptive and adaptive penalizations using the ℓ p ℓp for p ⩾ 1 p⩾1 penalty functions. These methods are motivated by and include as special cases model selection and shrinkage methods such as the LASSO and its Bayesian and adaptive versions. A simulation study validates the theoretical results. We also provide an empirical application on estimating the joint density of U.S. real consumption and asset returns subject to Euler equation constraints in a CRRA asset pricing model.},
  archive      = {J_JOE},
  author       = {A. Ronald Gallant and Han Hong and Michael P. Leung and Jessie Li},
  doi          = {10.1016/j.jeconom.2021.02.004},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {85-106},
  shortjournal = {J. Econ.},
  title        = {Constrained estimation using penalization and MCMC},
  volume       = {228},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian estimation of long-run risk models using sequential
monte carlo. <em>JOE</em>, <em>228</em>(1), 62–84. (<a
href="https://doi.org/10.1016/j.jeconom.2020.12.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a likelihood-based Bayesian method that exploits up-to-date sequential Monte Carlo methods to efficiently estimate long-run risk models in which the conditional variance of consumption growth follows either an autoregressive (AR) process or an autoregressive gamma (ARG) process. We use the U.S. quarterly consumption and asset returns data from the postwar period to implement estimation. Our findings are: (1) informative priors on the preference parameters can help to improve model performance; (2) expected consumption growth has a very persistent component, whereas consumption volatility is less persistent; (3) while the ARG-based model performs better than the AR-based one statistically, the latter could fit asset returns better; and (4) the solution method matters more for estimation in the AR-based model than in the ARG-based model.},
  archive      = {J_JOE},
  author       = {Andras Fulop and Jeremy Heng and Junye Li and Hening Liu},
  doi          = {10.1016/j.jeconom.2020.12.008},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {62-84},
  shortjournal = {J. Econ.},
  title        = {Bayesian estimation of long-run risk models using sequential monte carlo},
  volume       = {228},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimation and inference for the counterfactual distribution
and quantile functions in continuous treatment models. <em>JOE</em>,
<em>228</em>(1), 39–61. (<a
href="https://doi.org/10.1016/j.jeconom.2020.12.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Donald and Hsu (2014) studied the estimation and inference for the counterfactual distribution and quantile functions in a binary treatment model. We extend their work to the continuous treatment model. Specifically, we propose a weighted regression estimator for the counterfactual distribution but we estimate the weighting function from a covariate balancing equation by maximizing a globally concave criterion function. We estimate the quantile function by inverting the estimated counterfactual distribution. To test the distributional effect, we consider the (uniform) confidence bands, the sup and L2 distance, and the Mann–Whitney test. We also consider the stochastic dominance test for the distributional effect and the L2 test for constant quantiles . A simulation study reveals that our tests exhibit a satisfactory finite-sample performance, and an application shows their practical value.},
  archive      = {J_JOE},
  author       = {Chunrong Ai and Oliver Linton and Zheng Zhang},
  doi          = {10.1016/j.jeconom.2020.12.009},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {39-61},
  shortjournal = {J. Econ.},
  title        = {Estimation and inference for the counterfactual distribution and quantile functions in continuous treatment models},
  volume       = {228},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Nonparametric bayes subject to overidentified moment
conditions. <em>JOE</em>, <em>228</em>(1), 27–38. (<a
href="https://doi.org/10.1016/j.jeconom.2021.02.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonparametric Bayesian estimation subject to overidentified moment equations is a challenge because the support of the posterior is a manifold of lower dimension than the number of model parameters. The manifold therefore has Lebesgue measure zero thus inhibiting the use of the most commonly used Bayesian estimation method: MCMC (Markov Chain Monte Carlo). This study proposes an effective MCMC algorithm and algorithms for estimating scale and the normalizing constant. The algorithms are illustrated with two illustrative applications.},
  archive      = {J_JOE},
  author       = {A. Ronald Gallant},
  doi          = {10.1016/j.jeconom.2021.02.005},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {27-38},
  shortjournal = {J. Econ.},
  title        = {Nonparametric bayes subject to overidentified moment conditions},
  volume       = {228},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). High-dimensional linear models with many endogenous
variables. <em>JOE</em>, <em>228</em>(1), 4–26. (<a
href="https://doi.org/10.1016/j.jeconom.2021.06.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional linear models with endogenous variables play an increasingly important role in the recent econometric literature. In this work, we allow for models with many endogenous variables and make use of many instrumental variables to achieve identification. Because of the high-dimensionality in the structural equation, constructing honest confidence regions with asymptotically correct coverage is non-trivial. Our main contribution is to propose estimators and confidence regions that achieve this goal. Our approach relies on moment conditions that satisfy the usual instrument orthogonality condition but also have an additional orthogonality property with respect to specific linear combinations of the endogenous variables which are treated as nuisance parameters . We propose new pivotal procedures for estimating the high-dimensional nuisance parameters which appear in our formulation. We use a multiplier bootstrap procedure to compute critical values and establish its validity for achieving simultaneously valid confidence regions for a potentially high-dimensional set of endogenous variable coefficients.},
  archive      = {J_JOE},
  author       = {Alexandre Belloni and Christian Hansen and Whitney Newey},
  doi          = {10.1016/j.jeconom.2021.06.011},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {4-26},
  shortjournal = {J. Econ.},
  title        = {High-dimensional linear models with many endogenous variables},
  volume       = {228},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). New directions in nonlinear structural estimation: Bayes and
frequentist. <em>JOE</em>, <em>228</em>(1), 1–3. (<a
href="https://doi.org/10.1016/j.jeconom.2021.10.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JOE},
  author       = {George Tauchen},
  doi          = {10.1016/j.jeconom.2021.10.003},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {1-3},
  shortjournal = {J. Econ.},
  title        = {New directions in nonlinear structural estimation: Bayes and frequentist},
  volume       = {228},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Corrigendum to “predictability of stock returns and asset
allocation under structural breaks” [j. Econometrics 164 (2011) 60–78].
<em>JOE</em>, <em>227</em>(2), 513–517. (<a
href="https://doi.org/10.1016/j.jeconom.2020.02.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We revisit the estimation algorithm of Pettenuzzo and Timmermann (2011) and show how to apply the posterior simulation test of Geweke (2004) to locate and correct an error in the original posterior sampling algorithm. The main modification for the new algorithm is the introduction of a Metropolis–Hasting step to draw the precision parameters of the return and predictor equations, taking into account the correlation between the error terms of the two equations. We find that the modification of the original algorithm has very minor effects on the empirical results reported in Pettenuzzo and Timmermann (2011). In particular, for both the dividend yield and Treasury bill predictors the updated algorithm finds that the models best supported by the data, as measured by the SIC, match those reported in the original paper.},
  archive      = {J_JOE},
  author       = {Davide Pettenuzzo and Yong Song and Allan Timmermann},
  doi          = {10.1016/j.jeconom.2020.02.008},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {513-517},
  shortjournal = {J. Econ.},
  title        = {Corrigendum to “Predictability of stock returns and asset allocation under structural breaks” [J. econometrics 164 (2011) 60–78]},
  volume       = {227},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Corrigendum to “large bayesian vector autoregressions with
stochastic volatility and non-conjugate priors” [j. Econometrics 212 (1)
(2019) 137–154]. <em>JOE</em>, <em>227</em>(2), 506–512. (<a
href="https://doi.org/10.1016/j.jeconom.2021.11.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The original algorithm contained a mistake that meant the conditional distributions used for the VAR’s coefficients were missing a piece of information. We propose a new algorithm that uses the same factorization but includes the missing term. The new, correct algorithm has the same computational complexity as the old, incorrect one (i.e., O ( N 4 ) O(N4) ), and therefore it still allows the estimation of large VARs.},
  archive      = {J_JOE},
  author       = {Andrea Carriero and Joshua Chan and Todd E. Clark and Massimiliano Marcellino},
  doi          = {10.1016/j.jeconom.2021.11.010},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {506-512},
  shortjournal = {J. Econ.},
  title        = {Corrigendum to “Large bayesian vector autoregressions with stochastic volatility and non-conjugate priors” [J. econometrics 212 (1) (2019) 137–154]},
  volume       = {227},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Comment on “large bayesian vector autoregressions with
stochastic volatility and non-conjugate priors.” <em>JOE</em>,
<em>227</em>(2), 498–505. (<a
href="https://doi.org/10.1016/j.jeconom.2021.10.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fully Bayesian inference in a vector autoregression with stochastic volatility (VAR-SV) typically relies on simulations from a multi-step Markov chain Monte Carlo (MCMC) algorithm. Carriero et al. (2019) propose a new, faster, “triangular” algorithm (TA) to replace the systemwide algorithm (SWA) in the most time-consuming step of the VAR-SV’s standard MCMC algorithm. This paper analytically shows that the TA and SWA generally sample from different distributions, thereby disproving a central claim of Carriero et al. (2019). Replacing the SWA with the TA thus results in an ad hoc change to the MCMC algorithm’s transition kernel, leaving a priori unknown the formal relationship between the model’s posterior and simulations from the MCMC algorithm using the TA.},
  archive      = {J_JOE},
  author       = {Mark Bognanni},
  doi          = {10.1016/j.jeconom.2021.10.008},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {498-505},
  shortjournal = {J. Econ.},
  title        = {Comment on “Large bayesian vector autoregressions with stochastic volatility and non-conjugate priors”},
  volume       = {227},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The drift burst hypothesis. <em>JOE</em>, <em>227</em>(2),
461–497. (<a
href="https://doi.org/10.1016/j.jeconom.2020.11.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The drift burst hypothesis postulates the existence of short-lived locally explosive trends in the price paths of financial assets. The recent U.S. equity and treasury flash crashes can be viewed as two high-profile manifestations of such dynamics, but we argue that drift bursts of varying magnitude are an expected and regular occurrence in financial markets that can arise through established mechanisms of liquidity provision. We show how to build drift bursts into the continuous-time Itô semimartingale model, elaborate on the conditions required for the process to remain arbitrage-free, and propose a nonparametric test statistic that identifies drift bursts from noisy high-frequency data. We apply the test and demonstrate that drift bursts are a stylized fact of the price dynamics across equities, fixed income, currencies and commodities. Drift bursts occur once a week on average, and the majority of them are accompanied by subsequent price reversion and can thus be regarded as “flash crashes.” The reversal is found to be stronger for negative drift bursts with large trading volume, which is consistent with endogenous demand for immediacy during market crashes.},
  archive      = {J_JOE},
  author       = {Kim Christensen and Roel Oomen and Roberto Renò},
  doi          = {10.1016/j.jeconom.2020.11.004},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {461-497},
  shortjournal = {J. Econ.},
  title        = {The drift burst hypothesis},
  volume       = {227},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Residual-augmented IVX predictive regression. <em>JOE</em>,
<em>227</em>(2), 429–460. (<a
href="https://doi.org/10.1016/j.jeconom.2020.11.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bias correction in predictive regressions is known to reduce the empirical size problems of OLS-based predictability tests with persistent predictors. This paper shows that bias correction is also achieved in the context of the extended instrumental variable (IVX) predictability testing framework introduced by Kostakis et al. (2015). To be specific, new IVX-based statistics subject to a bias correction analogous to that proposed by Amihud and Hurvich (2004) are introduced. Four important contributions are provided: first, we characterize the effects that bias-reduction adjustments have on the asymptotic distributions of the IVX test statistics in a general context allowing for short-run dynamics and heterogeneity; second, we discuss the validity of the procedure when predictors are stationary as well as near-integrated; third, we conduct an exhaustive Monte Carlo analysis to investigate the small in- and out-of-sample properties of the test procedures and their sensitivity to distinctive features that characterize predictive regressions in practice, such as strong persistence, endogeneity, and non-Gaussian innovations; and fourth, we provide an analysis of real estate return and rent growth predictability in 19 OECD countries.},
  archive      = {J_JOE},
  author       = {Matei Demetrescu and Paulo M.M. Rodrigues},
  doi          = {10.1016/j.jeconom.2020.11.007},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {429-460},
  shortjournal = {J. Econ.},
  title        = {Residual-augmented IVX predictive regression},
  volume       = {227},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Simultaneous inference for time-varying models.
<em>JOE</em>, <em>227</em>(2), 408–428. (<a
href="https://doi.org/10.1016/j.jeconom.2021.03.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A general class of non-stationary time series is considered in this paper. We estimate the time-varying coefficients by using local linear M-estimation. For these estimators, weak Bahadur representations are obtained and are used to construct simultaneous confidence bands. For practical implementation, we propose a bootstrap based method to circumvent the slow logarithmic convergence of the theoretical simultaneous bands. Our results substantially generalize and unify the treatments for several time-varying regression and auto-regression models. The performance for tvARCH and tvGARCH models is studied in simulations and a few real-life applications of our study are presented through the analysis of some popular financial datasets.},
  archive      = {J_JOE},
  author       = {Sayar Karmakar and Stefan Richter and Wei Biao Wu},
  doi          = {10.1016/j.jeconom.2021.03.002},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {408-428},
  shortjournal = {J. Econ.},
  title        = {Simultaneous inference for time-varying models},
  volume       = {227},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Functional coefficient panel modeling with communal
smoothing covariates. <em>JOE</em>, <em>227</em>(2), 371–407. (<a
href="https://doi.org/10.1016/j.jeconom.2021.03.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Behavior at the individual level in panels is often influenced by aspects of the system in aggregate. In particular, the interaction between individual-specific explanatory variables and an individual dependent variable may be affected by ‘global’ variables that are relevant in decision making and shared communally by all individuals in the sample. To capture such behavioral features, we employ a functional coefficient panel model in which certain communal covariates may jointly influence panel interactions by means of their impact on the model coefficients. Two classes of estimation procedures are proposed, one based on cross-section averaged data, the other on the full panel. The asymptotic properties of these methods are obtained and compared, allowing for sequential and joint expansion of the cross-section and time series sample sizes. Limit theory for the associated fixed effects estimators is derived and inferential procedures are developed to test hypotheses concerning the functional coefficients. The finite sample performance of the proposed estimators and tests are examined by simulation. An empirical illustration is provided in which the regional sensitivity of housing rental prices to available job numbers is studied with national labor force participation rate as the communal smoothing covariate. Strong evidence is found supporting the functional coefficient specification with this country-wide smoothing variable.},
  archive      = {J_JOE},
  author       = {Peter C.B. Phillips and Ying Wang},
  doi          = {10.1016/j.jeconom.2021.03.004},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {371-407},
  shortjournal = {J. Econ.},
  title        = {Functional coefficient panel modeling with communal smoothing covariates},
  volume       = {227},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semiparametric testing with highly persistent predictors.
<em>JOE</em>, <em>227</em>(2), 347–370. (<a
href="https://doi.org/10.1016/j.jeconom.2021.03.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the issue of semiparametric efficiency in the bivariate regression problem with a highly persistent predictor, where the joint distribution of the innovations is regarded an infinite-dimensional nuisance parameter . Using a structural representation of the limit experiment and exploiting invariance relationships therein, we construct invariant point-optimal tests for the regression coefficient of interest. This approach naturally leads to a family of feasible tests based on the component-wise ranks of the innovations that can gain considerable power relative to existing tests under non-Gaussian innovation distributions, while behaving equivalently under Gaussianity. When an i.i.d. assumption on the innovations is appropriate for the data at hand, our tests exploit the efficiency gains possible. Moreover, we show by simulation that our test remains well behaved under some forms of conditional heteroskedasticity .},
  archive      = {J_JOE},
  author       = {Bas J.M. Werker and Bo Zhou},
  doi          = {10.1016/j.jeconom.2021.03.016},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {347-370},
  shortjournal = {J. Econ.},
  title        = {Semiparametric testing with highly persistent predictors},
  volume       = {227},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Maximum likelihood estimation for score-driven models.
<em>JOE</em>, <em>227</em>(2), 325–346. (<a
href="https://doi.org/10.1016/j.jeconom.2021.06.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We establish strong consistency and asymptotic normality of the maximum likelihood estimator for stochastic time-varying parameter models driven by the score of the predictive conditional likelihood function. For this purpose, we formulate primitive conditions for global identification, invertibility , strong consistency, and asymptotic normality both under correct specification and misspecification of the model. A detailed illustration is provided for a conditional volatility model with disturbances from the Student’s t distribution.},
  archive      = {J_JOE},
  author       = {Francisco Blasques and Janneke van Brummelen and Siem Jan Koopman and André Lucas},
  doi          = {10.1016/j.jeconom.2021.06.003},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {325-346},
  shortjournal = {J. Econ.},
  title        = {Maximum likelihood estimation for score-driven models},
  volume       = {227},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stationary vine copula models for multivariate time series.
<em>JOE</em>, <em>227</em>(2), 305–324. (<a
href="https://doi.org/10.1016/j.jeconom.2021.11.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series exhibit two types of dependence: across variables and across time points . Vine copulas are graphical models for the dependence and can conveniently capture both types of dependence in the same model. We derive the maximal class of graph structures that guarantee stationarity under a natural and verifiable condition called translation invariance. We propose computationally efficient methods for estimation, simulation, prediction, and uncertainty quantification and show their validity by asymptotic results and simulations. The theoretical results allow for misspecified models and, even when specialized to the iid case, go beyond what is available in the literature. The new model class is illustrated by an application to forecasting returns of a portfolio of 20 stocks, where they show excellent forecast performance. The paper is accompanied by an open source software implementation.},
  archive      = {J_JOE},
  author       = {Thomas Nagler and Daniel Krüger and Aleksey Min},
  doi          = {10.1016/j.jeconom.2021.11.015},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {305-324},
  shortjournal = {J. Econ.},
  title        = {Stationary vine copula models for multivariate time series},
  volume       = {227},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Realized matrix-exponential stochastic volatility with
asymmetry, long memory and higher-moment spillovers. <em>JOE</em>,
<em>227</em>(1), 285–304. (<a
href="https://doi.org/10.1016/j.jeconom.2021.06.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper develops a novel realized matrix-exponential stochastic volatility model of multivariate returns and realized covariances that incorporates asymmetry and long memory (hereafter the RMESV-ALM model), and higher-moment spillovers . The matrix exponential transformation guarantees the positive definiteness of the dynamic covariance matrix . We decompose the likelihood function of the RMESV-ALM model into two components: one based on the conventional Kalman filter , and the other evaluated by a Monte Carlo likelihood technique. We consider a two-step quasi-maximum likelihood estimator for maximizing the likelihood function, and examine the finite sample properties of the estimator. The specification enables us to analyze asymmetric and higher-moment spillover effects in the covariance dynamics via news impact curves and impulse response functions . Using high frequency data for three US financial assets, the new model is estimated and evaluated. The forecasting performance of the new model is compared with a novel dynamic realized matrix-exponential conditional covariance model . Our empirical results suggest the RMESV-ALE specification to be superior, and spillover effects are found from returns or volatility to the remaining volatilities.},
  archive      = {J_JOE},
  author       = {Manabu Asai and Chia-Lin Chang and Michael McAleer},
  doi          = {10.1016/j.jeconom.2021.06.008},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {285-304},
  shortjournal = {J. Econ.},
  title        = {Realized matrix-exponential stochastic volatility with asymmetry, long memory and higher-moment spillovers},
  volume       = {227},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybrid quantile estimation for asymmetric power GARCH
models. <em>JOE</em>, <em>227</em>(1), 264–284. (<a
href="https://doi.org/10.1016/j.jeconom.2020.05.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Asymmetric power GARCH models have been widely used to study the higher order moments of financial returns, while their quantile estimation has been rarely investigated. This paper introduces a simple monotonic transformation on its conditional quantile function to make the quantile regression tractable. The asymptotic normality of the resulting quantile estimators is established under either stationarity or non-stationarity. Moreover, based on the estimation procedure, new tests for strict stationarity and asymmetry are also constructed. This is the first try of the quantile estimation for non-stationary ARCH-type models in the literature. The usefulness of the proposed methodology is illustrated by simulation results and real data analysis.},
  archive      = {J_JOE},
  author       = {Guochang Wang and Ke Zhu and Guodong Li and Wai Keung Li},
  doi          = {10.1016/j.jeconom.2020.05.005},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {264-284},
  shortjournal = {J. Econ.},
  title        = {Hybrid quantile estimation for asymmetric power GARCH models},
  volume       = {227},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bootstrap inference on the boundary of the parameter space,
with application to conditional volatility models. <em>JOE</em>,
<em>227</em>(1), 241–263. (<a
href="https://doi.org/10.1016/j.jeconom.2020.05.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is a well-established fact that – with an unknown number of nuisance parameters at the boundary – testing a null hypothesis on the boundary of the parameter space is infeasible in practice as the limiting distributions of standard test statistics are non-pivotal. In particular, likelihood ratio statistics have limiting distributions which can be characterized in terms of quadratic forms minimized over cones, where the shape of the cones depends on the unknown location of the (possibly multiple) model parameters not restricted by the null hypothesis. We propose to solve this inference problem by a novel bootstrap , which we show to be valid under general conditions, irrespective of the presence of (unknown) nuisance parameters on the boundary. That is, the new bootstrap replicates the unknown limiting distribution of the likelihood ratio statistic under the null hypothesis and is bounded (in probability) under the alternative. The new bootstrap approach , which is very simple to implement, is based on shrinkage of the parameter estimates used to generate the bootstrap sample toward the boundary of the parameter space at an appropriate rate. As an application of our general theory, we treat the problem of inference in finite-order ARCH models with coefficients subject to inequality constraints. Extensive Monte Carlo simulations illustrate that the proposed bootstrap has attractive finite sample properties both under the null and under the alternative hypothesis.},
  archive      = {J_JOE},
  author       = {Giuseppe Cavaliere and Heino Bohn Nielsen and Rasmus Søndergaard Pedersen and Anders Rahbek},
  doi          = {10.1016/j.jeconom.2020.05.006},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {241-263},
  shortjournal = {J. Econ.},
  title        = {Bootstrap inference on the boundary of the parameter space, with application to conditional volatility models},
  volume       = {227},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LADE-based inferences for autoregressive models with
heavy-tailed g-GARCH(1, 1) noise. <em>JOE</em>, <em>227</em>(1),
228–240. (<a
href="https://doi.org/10.1016/j.jeconom.2020.06.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the least absolute deviation (LAD) estimator of the autoregressive model with heavy-tailed G-GARCH(1, 1) noise. When the tail index α ∈ ( 1 , 2 ] α∈(1,2] , it is shown that the LAD estimator asymptotically converges to a linear function of a series of α α -stable random vectors with a rate of convergence n 1 − 1 / α n1−1/α . The result is significantly different from that of the corresponding least square estimator which is not consistent, and partially solves the problem on the asymptoticity of the LAD estimator when the tail index is less than 2. A simulation study is carried out to assess the performance of the LAD estimator and a real example is given to illustrate this approach.},
  archive      = {J_JOE},
  author       = {Xingfa Zhang and Rongmao Zhang and Yuan Li and Shiqing Ling},
  doi          = {10.1016/j.jeconom.2020.06.011},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {228-240},
  shortjournal = {J. Econ.},
  title        = {LADE-based inferences for autoregressive models with heavy-tailed G-GARCH(1, 1) noise},
  volume       = {227},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Identification of structural multivariate GARCH models.
<em>JOE</em>, <em>227</em>(1), 212–227. (<a
href="https://doi.org/10.1016/j.jeconom.2020.07.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The class of multivariate GARCH models is widely used to quantify and monitor volatility and correlation dynamics of financial time series. While many specifications have been proposed in the literature, these models are typically silent about the system inherent transmission of implied orthogonalized shocks to vector returns. In a framework of non-Gaussian independent structural shocks, this paper proposes a loss statistic, based on higher order co-moments, to discriminate in a data-driven way between alternative structural assumptions about the transmission scheme, and hence identify the structural model. Consistency of identification is shown theoretically and via a simulation study. In its structural form, a four dimensional system comprising US and Latin American stock market returns points to a substantial volatility transmission from the US to the Latin American markets. The identified structural model improves the estimation of classical measures of portfolio risk, as well as corresponding variations.},
  archive      = {J_JOE},
  author       = {Christian M. Hafner and Helmut Herwartz and Simone Maxand},
  doi          = {10.1016/j.jeconom.2020.07.019},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {212-227},
  shortjournal = {J. Econ.},
  title        = {Identification of structural multivariate GARCH models},
  volume       = {227},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Occupation density estimation for noisy high-frequency data.
<em>JOE</em>, <em>227</em>(1), 189–211. (<a
href="https://doi.org/10.1016/j.jeconom.2020.05.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the nonparametric estimation of occupation densities for semimartingale processes observed with noise. As leading examples we consider the stochastic volatility of a latent efficient price process, the volatility of the latent noise that separates the efficient price from the actually observed price, and nonlinear transformations of these processes. Our estimation methods are decidedly nonparametric and consist of two steps: the estimation of the spot price and noise volatility processes based on pre-averaging techniques and in-fill asymptotic arguments, followed by a kernel-type estimation of the occupation densities. Our spot volatility estimates attain the optimal rate of convergence, and are robust to leverage effects, price and volatility jumps, general forms of serial dependence in the noise, and random irregular sampling. The convergence rates of our occupation density estimates are directly related to that of the estimated spot volatilities and the smoothness of the true occupation densities. An empirical application involving high-frequency equity data illustrates the usefulness of the new methods in illuminating time-varying risks, market liquidity, and informational asymmetries across time and assets.},
  archive      = {J_JOE},
  author       = {Congshan Zhang and Jia Li and Tim Bollerslev},
  doi          = {10.1016/j.jeconom.2020.05.013},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {189-211},
  shortjournal = {J. Econ.},
  title        = {Occupation density estimation for noisy high-frequency data},
  volume       = {227},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Asset selection based on high frequency sharpe ratio.
<em>JOE</em>, <em>227</em>(1), 168–188. (<a
href="https://doi.org/10.1016/j.jeconom.2020.05.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In portfolio choice problems, the classical Mean–Variance model in Markowitz (1952) relies heavily on the covariance structure among assets. As the number and types of assets increase rapidly, traditional methods to estimate the covariance matrix and its inverse suffer from the common issues in high or ultra-high dimensional analysis. To avoid the issue of estimating the covariance matrix with high or ultra-high dimensional data, we propose a fast procedure to reduce dimension based on a new risk/return measure constructed from intra-day high frequency data and select assets via Dependent Sure Explained Variability and Independence Screening (D-SEVIS). While most feature screening methods assume i.i.d. samples, by nature of our data, we make contribution to studying D-SEVIS for samples with serial correlation , specifically, for the stationary α α -mixing processes. Under α α -mixing condition, we prove that D-SEVIS satisfies sure screening property and ranking consistency property. More importantly, with the assets selected through D-SEVIS, we will build a portfolio that earns more excess return compared with several existing portfolio allocation methods. We illustrate this advantage of our asset selection method with the real data from the stock market.},
  archive      = {J_JOE},
  author       = {Christina Dan Wang and Zhao Chen and Yimin Lian and Min Chen},
  doi          = {10.1016/j.jeconom.2020.05.007},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {168-188},
  shortjournal = {J. Econ.},
  title        = {Asset selection based on high frequency sharpe ratio},
  volume       = {227},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient estimation of high-dimensional dynamic covariance
by risk factor mapping: Applications for financial risk management.
<em>JOE</em>, <em>227</em>(1), 151–167. (<a
href="https://doi.org/10.1016/j.jeconom.2020.04.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to explore a modified method of high-dimensional dynamic variance–covariance matrix estimation via risk factor mapping, which can yield a dependence estimation of asset returns within a large portfolio with high computational efficiency. The essence of our methodology is to express the time-varying dependence of high-dimensional return variables using the co-movement concept of returns with respect to risk factors. A novelty of the proposed methodology is to allow mapping matrices, which govern the co-movement of returns, to be time-varying. We also consider the flexible modeling of risk factors by a copula multivariate generalized autoregressive conditional heteroscedasticity (MGARCH) model. Through the proposed risk factor mapping model, the number of parameters and the time complexity are functions of a small number of risk factors instead of the number of stocks in the portfolio, making our proposed methodology highly scalable. We adopt Bayesian methods to estimate unknown parameters and various risk measures in the proposed model. The proposed risk mapping method and financial applications are demonstrated by an empirical study of the Hong Kong stock market. The assessment of the effectiveness of the mapping via risk measure estimation is also discussed.},
  archive      = {J_JOE},
  author       = {Mike K.P. So and Thomas W.C. Chan and Amanda M.Y. Chu},
  doi          = {10.1016/j.jeconom.2020.04.040},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {151-167},
  shortjournal = {J. Econ.},
  title        = {Efficient estimation of high-dimensional dynamic covariance by risk factor mapping: Applications for financial risk management},
  volume       = {227},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Β in the tails. <em>JOE</em>, <em>227</em>(1), 134–150. (<a
href="https://doi.org/10.1016/j.jeconom.2020.06.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Do hedge funds hedge? In negative states of the world, often not as much as they should. For several styles, we report larger market betas when market returns are low (i.e., “beta in the tails”). We justify this finding through a combination of negative-mean jumps in the market returns and large market jump betas: when moving to the left tail of the market return distribution jump dynamics dominate continuous dynamics and the overall systematic risk of the fund is driven by the higher systematic risk associated with return discontinuities. Methodologically, the separation of continuous and discontinuous dynamics is conducted by exploiting the informational content of the high-order infinitesimal cross-moments of hedge-fund and market returns.},
  archive      = {J_JOE},
  author       = {Federico M. Bandi and Roberto Renò},
  doi          = {10.1016/j.jeconom.2020.06.006},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {134-150},
  shortjournal = {J. Econ.},
  title        = {β in the tails},
  volume       = {227},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Testing capital asset pricing models using
functional-coefficient panel data models with cross-sectional
dependence. <em>JOE</em>, <em>227</em>(1), 114–133. (<a
href="https://doi.org/10.1016/j.jeconom.2020.07.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a functional-coefficient panel data model with cross-sectional dependence motivated by re-examining the empirical performance of conditional capital asset pricing model . In order to characterize the time-varying property of assets’ betas and alpha, our proposed model allows the betas to be unknown functions of some macroeconomic and financial instruments. Moreover, a common factor structure is introduced to characterize cross-sectional dependence which is an attractive feature under a panel data regression setting as different assets or portfolios may be affected by same unobserved shocks. Compared to the existing studies, such as the classic Fama–MacBeth two-step procedure, our model can achieve substantial efficiency gains for inference by adopting a one-step procedure using the entire sample rather than a single cross-sectional regression at each time point . We propose a local linear common correlated effects estimator for estimating time-varying betas by pooling the data. The consistency and asymptotic normality of the proposed estimators are established. Another methodological and empirical challenge in asset pricing is how to test the constancy of conditional betas and the significance of pricing errors, we echo this challenge by constructing an L 2 L2 -norm statistic for functional-coefficient panel data models allowing for cross-sectional dependence. We show that the new test statistic has a limiting standard normal distribution under the null hypothesis. Finally, the method is applied to test the model in Fama and French (1993) using Fama–French 25 and 100 portfolios, sorted by size and book-to-market ratio, respectively, dated from July 1963 to July 2018.},
  archive      = {J_JOE},
  author       = {Zongwu Cai and Ying Fang and Qiuhua Xu},
  doi          = {10.1016/j.jeconom.2020.07.018},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {114-133},
  shortjournal = {J. Econ.},
  title        = {Testing capital asset pricing models using functional-coefficient panel data models with cross-sectional dependence},
  volume       = {227},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Testing for episodic predictability in stock returns.
<em>JOE</em>, <em>227</em>(1), 85–113. (<a
href="https://doi.org/10.1016/j.jeconom.2020.01.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Standard tests based on predictive regressions estimated over the full available sample data have tended to find little evidence of predictability in stock returns. Recent approaches based on the analysis of subsamples of the data suggest in fact that predictability where it occurs might exist only within so-called “pockets of predictability” rather than across the entire sample. However, these methods are prone to the criticism that the subsample dates are endogenously determined such that the use of standard critical values appropriate for full sample tests will result in incorrectly sized tests leading to spurious findings of stock returns predictability. To avoid the problem of endogenously-determined sample splits, we propose new tests derived from sequences of predictability statistics systematically calculated over subsamples of the data. Specifically, we will base tests on the maximum of such statistics from sequences of forward and backward recursive, rolling, and double-recursive predictive subsample regressions. We develop our approach using the over-identified instrumental variable-based predictability test statistics of Breitung and Demetrescu (2015). This approach is based on partial-sum asymptotics and so, unlike many other popular approaches including, for example, those based on Bonferroni corrections, can be readily adapted to implementation over sequences of subsamples. We show that the limiting null distributions of our proposed test statistics depend in general on whether the putative predictor is strongly or weakly persistent and on any heteroskedasticity present (indeed on any time-variation present in the unconditional variance matrix of the innovations), the latter even if the subsample statistics are based on heteroskedasticity-robust standard errors. As a consequence, we develop fixed regressor wild bootstrap implementations of the tests which we demonstrate to be first-order asymptotically valid. Finite sample behaviour against a variety of temporarily predictable processes is considered. An empirical application to US stock returns illustrates the usefulness of the new predictability testing methods we propose.},
  archive      = {J_JOE},
  author       = {Matei Demetrescu and Iliyan Georgiev and Paulo M.M. Rodrigues and A.M. Robert Taylor},
  doi          = {10.1016/j.jeconom.2020.01.001},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {85-113},
  shortjournal = {J. Econ.},
  title        = {Testing for episodic predictability in stock returns},
  volume       = {227},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A time-varying parameter model for local explosions.
<em>JOE</em>, <em>227</em>(1), 65–84. (<a
href="https://doi.org/10.1016/j.jeconom.2021.05.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Financial and economic time series can feature locally explosive behaviour when bubbles are formed. We develop a time-varying parameter model that is capable of describing this behaviour in time series data . Our proposed dynamic model can be used to predict the emergence, existence and burst of bubbles. We adopt a flexible observation driven model specification that allows for different bubble shapes and behaviour. We establish stationarity , ergodicity , and bounded moments of the data generated by our model. Furthermore, we obtain the consistency and asymptotic normality of the maximum likelihood estimator . Given the parameter estimates in the model, the implied filter is capable of extracting the unobserved bubble process from the observed data. We study finite-sample properties of our estimator through a Monte Carlo simulation study. Finally, we show that our model compares well with existing noncausal models in a financial application concerning the Bitcoin/US dollar exchange rate.},
  archive      = {J_JOE},
  author       = {Francisco Blasques and Siem Jan Koopman and Marc Nientker},
  doi          = {10.1016/j.jeconom.2021.05.008},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {65-84},
  shortjournal = {J. Econ.},
  title        = {A time-varying parameter model for local explosions},
  volume       = {227},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Testing the existence of moments for GARCH processes.
<em>JOE</em>, <em>227</em>(1), 47–64. (<a
href="https://doi.org/10.1016/j.jeconom.2020.05.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is generally admitted that many financial time series have heavy tailed marginal distributions. When time series models are fitted on such data, the non-existence of appropriate moments may invalidate standard statistical tools used for inference. Moreover, the existence of moments can be crucial for risk management, for instance when risk is measured through the expected shortfall. This paper considers testing the existence of moments in the framework of GARCH processes. While the second-order stationarity condition does not depend on the distribution of the innovation, higher-order moment conditions involve moments of the independent innovation process. We propose tests for the existence of high moments of the returns process which are based on the joint asymptotic distribution of the Quasi-Maximum Likelihood (QML) estimator of the volatility parameters and empirical moments of the residuals. A bootstrap procedure is proposed to improve the finite-sample performance of our test. To achieve efficiency gains we consider non Gaussian QML estimators founded on reparameterizations of the GARCH model, and we discuss optimality issues. Monte Carlo experiments and an empirical study illustrate the asymptotic results.},
  archive      = {J_JOE},
  author       = {Christian Francq and Jean-Michel Zakoïan},
  doi          = {10.1016/j.jeconom.2020.05.009},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {47-64},
  shortjournal = {J. Econ.},
  title        = {Testing the existence of moments for GARCH processes},
  volume       = {227},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Understanding temporal aggregation effects on kurtosis in
financial indices. <em>JOE</em>, <em>227</em>(1), 25–46. (<a
href="https://doi.org/10.1016/j.jeconom.2020.07.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Indices of financial returns typically display sample kurtosis that declines towards the Gaussian value 3 as the sampling interval increases. This paper uses stochastic unit root (STUR) and continuous time analysis to explain the phenomenon. Limit theory for the sample kurtosis reveals that STUR specifications provide two sources of excess kurtosis, both of which decline with the sampling interval. Limiting kurtosis is shown to be random and is a functional of the limiting price process. Using a continuous time version of the model under no-drift, local drift, and drift inclusions, we suggest a new continuous time kurtosis measure for financial returns that assists in reconciling these models with the empirical kurtosis characteristics of returns. Simulations are reported and applications to several financial indices demonstrate the usefulness of this approach.},
  archive      = {J_JOE},
  author       = {Offer Lieberman and Peter C.B. Phillips},
  doi          = {10.1016/j.jeconom.2020.07.035},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {25-46},
  shortjournal = {J. Econ.},
  title        = {Understanding temporal aggregation effects on kurtosis in financial indices},
  volume       = {227},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Goodness-of-fit testing for time series models via distance
covariance. <em>JOE</em>, <em>227</em>(1), 4–24. (<a
href="https://doi.org/10.1016/j.jeconom.2020.05.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many statistical modeling frameworks, goodness-of-fit tests are typically administered to the estimated residuals. In the time series setting, whiteness of the residuals is assessed using the sample autocorrelation function . For many time series models , especially those used for financial time series, the key assumption on the residuals is that they are in fact independent and not just uncorrelated. In this paper, we apply the auto-distance covariance function (ADCV) to evaluate the serial dependence of the estimated residuals. Distance covariance can discriminate between dependence and independence of two random vectors. The limit behavior of the test statistic based on the ADCV is derived for a general class of time series models . One of the key aspects in this theory is adjusting for the dependence that arises due to parameter estimation. This adjustment has essentially the same form regardless of the model specification. We illustrate the results in simulated examples.},
  archive      = {J_JOE},
  author       = {Phyllis Wan and Richard A. Davis},
  doi          = {10.1016/j.jeconom.2020.05.008},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {4-24},
  shortjournal = {J. Econ.},
  title        = {Goodness-of-fit testing for time series models via distance covariance},
  volume       = {227},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Overview: Time series analysis of higher moments and
distributions of financial data. <em>JOE</em>, <em>227</em>(1), 1–3. (<a
href="https://doi.org/10.1016/j.jeconom.2021.10.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JOE},
  author       = {Torben G. Andersen and Chia-Lin Chang and Shiqing Ling},
  doi          = {10.1016/j.jeconom.2021.10.001},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {1-3},
  shortjournal = {J. Econ.},
  title        = {Overview: Time series analysis of higher moments and distributions of financial data},
  volume       = {227},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimating unobserved individual heterogeneity using
pairwise comparisons. <em>JOE</em>, <em>226</em>(2), 477–497. (<a
href="https://doi.org/10.1016/j.jeconom.2020.11.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new method for studying environments with unobserved individual heterogeneity. Based on model-implied pairwise inequalities , the method classifies individuals in the sample into groups defined by discrete unobserved heterogeneity with unknown support. We establish conditions under which the groups are identified and consistently estimated through our method. We show that the method performs well in finite samples through Monte Carlo simulation . We then apply the method to estimate a model of lowest-price procurement auctions with unobserved bidder heterogeneity, using data from the California highway procurement market.},
  archive      = {J_JOE},
  author       = {Elena Krasnokutskaya and Kyungchul Song and Xun Tang},
  doi          = {10.1016/j.jeconom.2020.11.009},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {477-497},
  shortjournal = {J. Econ.},
  title        = {Estimating unobserved individual heterogeneity using pairwise comparisons},
  volume       = {226},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Inference in ordered response games with complete
information. <em>JOE</em>, <em>226</em>(2), 451–476. (<a
href="https://doi.org/10.1016/j.jeconom.2021.09.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study inference in complete information games with discrete strategy spaces. Unlike binary games, we allow for rich strategy spaces and we only assume that they are ordinal in nature. We derive observable implications of equilibrium play under mild shape restrictions on payoff functions , and we characterize sharp identified sets for model parameters. We propose a novel inference method based on a test statistic that embeds conditional moment inequalities implied by equilibrium behavior. Our statistic has asymptotically pivotal properties that depend on the measure of contact sets, to which our statistic adapts automatically. In the case of two players and strategic substitutes we show that certain payoff parameters are point identified under mild conditions. We embed conventional point estimates for these parameters in our conditional moment inequality test statistic in order to perform inference on the remaining (partially identified) parameters. We apply our method to model the number of stores operated by Lowe’s and Home Depot in geographic markets and perform inference on several quantities of economic interest.},
  archive      = {J_JOE},
  author       = {Andrés Aradillas-López and Adam M. Rosen},
  doi          = {10.1016/j.jeconom.2021.09.017},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {451-476},
  shortjournal = {J. Econ.},
  title        = {Inference in ordered response games with complete information},
  volume       = {226},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A test of the selection on observables assumption using a
discontinuously distributed covariate. <em>JOE</em>, <em>226</em>(2),
423–450. (<a
href="https://doi.org/10.1016/j.jeconom.2021.09.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a test of the selection on observables assumption that neither requires instruments nor excluded covariates from the structural function. Instead, we rely on the presence of a discontinuously distributed variable among the set of controls. We develop formal testing procedures for a non-parametric additively separable model for binary and finite treatment variables. We also outline a nonparametric nonseparable extension. Our test is easy to implement and should be useful in many empirical settings. Specifically, we employ it to study selection concerns in the estimation of the impact of a nutritional aid program for pregnant women on birth weight.},
  archive      = {J_JOE},
  author       = {Umair Khalil and Neşe Yıldız},
  doi          = {10.1016/j.jeconom.2021.09.018},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {423-450},
  shortjournal = {J. Econ.},
  title        = {A test of the selection on observables assumption using a discontinuously distributed covariate},
  volume       = {226},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A wavelet method for panel models with jump discontinuities
in the parameters. <em>JOE</em>, <em>226</em>(2), 399–422. (<a
href="https://doi.org/10.1016/j.jeconom.2021.09.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While a substantial literature on structural break change point analysis exists for univariate time series, research on large panel data models has not been as extensive. In this paper, a novel method for estimating panel models with multiple structural changes is proposed. The breaks are allowed to occur at unknown points in time and may affect the multivariate slope parameters individually. Our method adapts Haar wavelets to the structure of the observed variables in order to detect the change points of the parameters consistently. We also develop methods to address endogenous regressors within our modeling framework. The asymptotic property of our estimator is established. In our application, we examine the impact of algorithmic trading on standard measures of market quality such as liquidity and volatility over a time period that covers the financial meltdown that began in 2007. We are able to detect jumps in regression slope parameters automatically without using ad-hoc subsample selection criteria.},
  archive      = {J_JOE},
  author       = {O. Bada and A. Kneip and D. Liebl and T. Mensinger and J. Gualtieri and R.C. Sickles},
  doi          = {10.1016/j.jeconom.2021.09.006},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {399-422},
  shortjournal = {J. Econ.},
  title        = {A wavelet method for panel models with jump discontinuities in the parameters},
  volume       = {226},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimating multinomial choice models with unobserved choice
sets. <em>JOE</em>, <em>226</em>(2), 368–398. (<a
href="https://doi.org/10.1016/j.jeconom.2021.06.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new approach to estimating multinomial choice models when each consumer’s actual choice set is unobservable but could be bounded by two known sets, i.e., the largest and smallest possible choice sets. The bounds on choice set, combined with a monotonicity property derived from utility maximization, imply a system of inequality restrictions on observed choice probabilities that could be used to identify and estimate the model. A key insight is that the identification of random utility model can be achieved without exact information on consumers’ choice sets, which generalizes the identification result of the standard multinomial choice model. The effectiveness of the proposed approach is demonstrated via a range of Monte Carlo experiments as well as an empirical application to consumer demand for potato chips using household scanner data.},
  archive      = {J_JOE},
  author       = {Zhentong Lu},
  doi          = {10.1016/j.jeconom.2021.06.004},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {368-398},
  shortjournal = {J. Econ.},
  title        = {Estimating multinomial choice models with unobserved choice sets},
  volume       = {226},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Identification of dynamic games with unobserved
heterogeneity and multiple equilibria. <em>JOE</em>, <em>226</em>(2),
343–367. (<a
href="https://doi.org/10.1016/j.jeconom.2020.11.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides sufficient conditions for nonparametrically identifying dynamic games with incomplete information, allowing for multiple equilibria and payoff-relevant unobservables. Our identification involves two steps. We first identify the equilibrium conditional choice probabilities and state transitions using the Markov property and four-period data. The first step of our identification relies on eigenvalue-eigenvector decomposition, and thus incurs the same issue of identification up-to-label-swapping as the existing literature. This makes it difficult to identify payoff primitives in the second step, which requires consistent matching of unobserved types across different values of the observed variables. Instead of imposing assumptions such as monotonicity, we address this type-matching problem by exploiting the Markov property and longitudinal variations of observables in the intermediate periods to link different decompositions.},
  archive      = {J_JOE},
  author       = {Yao Luo and Ping Xiao and Ruli Xiao},
  doi          = {10.1016/j.jeconom.2020.11.016},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {343-367},
  shortjournal = {J. Econ.},
  title        = {Identification of dynamic games with unobserved heterogeneity and multiple equilibria},
  volume       = {226},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sample selection models with monotone control functions.
<em>JOE</em>, <em>226</em>(2), 321–342. (<a
href="https://doi.org/10.1016/j.jeconom.2021.01.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The celebrated Heckman selection model yields a selection correction function (control function) proportional to the inverse Mills ratio, which is monotone. This paper studies a sample selection model that does not impose parametric distributional assumptions on the latent error terms, while maintaining the monotonicity of the control function. We show that a positive (negative) dependence condition on the latent error terms is sufficient for the monotonicity of the control function. The condition is equivalent to a restriction on the copula function of latent error terms. Using the monotonicity, we propose a tuning-parameter-free semiparametric estimation method and establish root n n -consistency and asymptotic normality for the estimates of finite-dimensional parameters. A new test for selectivity is also developed in the presence of the shape restriction. Simulations and an empirical application are conducted to illustrate the usefulness of the proposed methods.},
  archive      = {J_JOE},
  author       = {Ruixuan Liu and Zhengfei Yu},
  doi          = {10.1016/j.jeconom.2021.01.010},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {321-342},
  shortjournal = {J. Econ.},
  title        = {Sample selection models with monotone control functions},
  volume       = {226},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Testing for risk aversion in first-price sealed-bid
auctions. <em>JOE</em>, <em>226</em>(2), 295–320. (<a
href="https://doi.org/10.1016/j.jeconom.2020.11.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider testing for risk aversion in first-price sealed-bid auctions with symmetric bidders and independent private values. We impose several restrictions on the parameter space, which are all implied by Guerre et al. (2009)’s exclusion restriction, and we articulate what restrictions are needed for our test to control the limiting size and to be pointwise consistent. Critical values can be obtained from the standard normal distribution . We also analyze local-power properties and show that our test detects local alternative at the parametric rate.},
  archive      = {J_JOE},
  author       = {Sung Jae Jun and Federico Zincenko},
  doi          = {10.1016/j.jeconom.2020.11.015},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {295-320},
  shortjournal = {J. Econ.},
  title        = {Testing for risk aversion in first-price sealed-bid auctions},
  volume       = {226},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Identification of nonparametric monotonic regression models
with continuous nonclassical measurement errors. <em>JOE</em>,
<em>226</em>(2), 269–294. (<a
href="https://doi.org/10.1016/j.jeconom.2020.09.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides sufficient conditions for identification of a nonparametric regression model with an unobserved continuous regressor subject to nonclassical measurement error. The measurement error may be directly correlated with the latent regressor in the model. Our identification strategy does not require the availability of additional data information, such as a secondary measurement, an instrumental variable , or an auxiliary sample. Our main assumptions for nonparametric identification include monotonicity of the regression function , independence of the regression error , and completeness of the measurement error distribution. We also propose a sieve maximum likelihood estimator and investigate its finite sample property through Monte Carlo simulations .},
  archive      = {J_JOE},
  author       = {Yingyao Hu and Susanne Schennach and Ji-Liang Shiu},
  doi          = {10.1016/j.jeconom.2020.09.014},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {269-294},
  shortjournal = {J. Econ.},
  title        = {Identification of nonparametric monotonic regression models with continuous nonclassical measurement errors},
  volume       = {226},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Inference on estimators defined by mathematical programming.
<em>JOE</em>, <em>226</em>(2), 248–268. (<a
href="https://doi.org/10.1016/j.jeconom.2021.06.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an inference procedure for a class of estimators defined as the solutions to linear and convex quadratic programming problems in which the coefficients in both the objective function and the constraints of the problem are estimated from data and hence involve sampling error. We argue that the Karush–Kuhn–Tucker conditions that characterize the solutions to these programming problems can be treated as moment conditions; by doing so, we transform the problem of inference on the solution to a constrained optimization problem (which is non-standard) into one involving inference on inequalities with pre-estimated coefficients, which is better understood. Our approach is valid regardless of whether the problem has a unique solution or multiple solutions. We apply our method to various portfolio selection models, in which the confidence sets can be non-convex, lower-dimensional manifolds.},
  archive      = {J_JOE},
  author       = {Yu-Wei Hsieh and Xiaoxia Shi and Matthew Shum},
  doi          = {10.1016/j.jeconom.2021.06.001},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {248-268},
  shortjournal = {J. Econ.},
  title        = {Inference on estimators defined by mathematical programming},
  volume       = {226},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Quantile regression methods for first-price auctions.
<em>JOE</em>, <em>226</em>(2), 224–247. (<a
href="https://doi.org/10.1016/j.jeconom.2021.02.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper proposes a quantile-regression inference framework for first-price auctions with symmetric risk-neutral bidders under the independent private-value paradigm. It is first shown that a private-value quantile regression generates a quantile regression for the bids. The private-value quantile regression can be easily estimated from the bid quantile regression and its derivative with respect to the quantile level. This also allows to test for various specification or exogeneity null hypothesis using the observed bids in a simple way. A new local polynomial technique is proposed to estimate the latter over the whole quantile level interval. Plug-in estimation of functionals is also considered, as needed for the expected revenue or the case of CRRA risk-averse bidders, which is amenable to our framework. A quantile-regression analysis to USFS timber is found more appropriate than the homogenized-bid methodology and illustrates the contribution of each explanatory variable to the private-value distribution. Linear interactive sieve extensions are proposed and studied in the Appendices.},
  archive      = {J_JOE},
  author       = {Nathalie Gimenes and Emmanuel Guerre},
  doi          = {10.1016/j.jeconom.2021.02.009},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {224-247},
  shortjournal = {J. Econ.},
  title        = {Quantile regression methods for first-price auctions},
  volume       = {226},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Identification of semiparametric model coefficients, with an
application to collective households. <em>JOE</em>, <em>226</em>(2),
205–223. (<a
href="https://doi.org/10.1016/j.jeconom.2021.02.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove identification of coefficients for a set of semiparametric specifications that are related to multiple index models. Potential applications of these results include models of observed heterogeneity in production functions and in consumer demand systems. We then generalize these results to identify a class of collective household consumption models. We extend the existing literature by proving point identification, rather than the weaker generic identification, of all the features of the collective household model, including price effects. We estimate the model using Japanese consumption data, and find substantial variation in resource shares and indifference scales across households of different sizes.},
  archive      = {J_JOE},
  author       = {Arthur Lewbel and Xirong Lin},
  doi          = {10.1016/j.jeconom.2021.02.010},
  journal      = {Journal of Econometrics},
  number       = {2},
  pages        = {205-223},
  shortjournal = {J. Econ.},
  title        = {Identification of semiparametric model coefficients, with an application to collective households},
  volume       = {226},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Censored quantile regression survival models with a cure
proportion. <em>JOE</em>, <em>226</em>(1), 192–203. (<a
href="https://doi.org/10.1016/j.jeconom.2020.12.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new quantile regression model for survival data is proposed that permits a positive proportion of subjects to become unsusceptible to recurrence of disease following treatment or based on other observable characteristics. In contrast to prior proposals for quantile regression estimation of censored survival models, we propose a new “data augmentation” approach to estimation. Our approach has computational advantages over earlier approaches proposed by Wu and Yin (2013, 2017). We compare our method with the two estimation strategies proposed by Wu and Yin and demonstrate its advantageous empirical performance in simulations. The methods are also illustrated with data from a Lung Cancer survival study.},
  archive      = {J_JOE},
  author       = {Naveen Narisetty and Roger Koenker},
  doi          = {10.1016/j.jeconom.2020.12.005},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {192-203},
  shortjournal = {J. Econ.},
  title        = {Censored quantile regression survival models with a cure proportion},
  volume       = {226},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Approximation of sign-regular kernels. <em>JOE</em>,
<em>226</em>(1), 171–191. (<a
href="https://doi.org/10.1016/j.jeconom.2021.07.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parameterized integrals, q y = ∫ K x , y d P x , are common in economic applications. To optimize a parameterized integral, or to relate one such integral to others, it is helpful to reduce the rank of the kernel K while controlling approximation error. A bound on the uniform approximation error of K x , y ≈ ∑ i = 1 n f i x g i y also bounds the uniform approximation error of q y ≈ ∑ i = 1 n c i g i y = ∑ i = 1 n ∫ f i x d P x g i y over all y and all signed measures P whose total variation does not exceed a fixed bound (such as probability measures), which may be useful in optimizing q or in relating q to other parameterized integrals. Bounding the mean squared error or the local error in approximating K generally does not bound the uniform approximation error of q . Many economically interesting kernels of parameterized integrals, including exp c x y , the Gaussian probability density function , and a wide class of Green’s functions, satisfy a condition known as strict sign-regularity . For K x , y strictly sign-regular on a rectangular domain x ∈ x L , x U , y ∈ y L , y U , I introduce a new method to efficiently compute a lower bound on the uniform error achievable by any rank- n approximation. I also provide a novel method to construct a rank- n approximation that numerically achieves the lower bound in every example I have examined, so in each such example my new method solves, to within rounding error, (1) inf f i , g i i = 1 n sup x ∈ x L , x U , y ∈ y L , y U K x , y − ∑ i = 1 n f i x g i y . My approach uses tools from the literature on n -widths in approximation theory (as summarized by Pinkus (1985)). I show that my new method’s uniform error can be orders of magnitude smaller than that of a Taylor series with the same rank. It also outperforms singular function approximations and the Chebfun2 approach of Townsend and Trefethen (2013) in uniform error, typically by wide margins. I describe several applications that demonstrate the practical utility of my approximation method.},
  archive      = {J_JOE},
  author       = {Thomas A. Knox},
  doi          = {10.1016/j.jeconom.2021.07.009},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {171-191},
  shortjournal = {J. Econ.},
  title        = {Approximation of sign-regular kernels},
  volume       = {226},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Who wins, who loses? Identification of conditional causal
effects, and the welfare impact of changing wages. <em>JOE</em>,
<em>226</em>(1), 155–170. (<a
href="https://doi.org/10.1016/j.jeconom.2021.02.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The incidence of tax and other policy changes depends on their impact on equilibrium wages. In a standard model of labor supply, the impact of wage changes on a worker’s welfare equals current labor supply times the induced wage change. Worker heterogeneity implies that wage changes vary across workers. In this context, in order to identify welfare effects one needs to identify the causal effect of policy changes on wages conditional on baseline labor supply and wages. This paper characterizes identification of such outcome-conditioned causal effects for general vectors of endogenous outcomes. Even with exogenous policy variation, outcome-conditioned causal effects are only partially identified for outcome vectors of dimension larger than one. We provide assumptions restricting heterogeneity of effects just enough for point-identification and propose corresponding estimators. This paper then applies the proposed approach to analyze the distributional welfare impact (i) of the expansion of the Earned Income Tax Credit (EITC) in the 1990s, using variation in state supplements in order to identify causal effects, and (ii) of historical changes of the wage distribution in the US in the 1990s. For the EITC, we find negative welfare effects of depressed wages as a consequence of increased labor supply, in particular for individuals earning around $20,000 per year. Looking at historical changes, we find modest welfare gains rising linearly with earnings.},
  archive      = {J_JOE},
  author       = {Maximilian Kasy},
  doi          = {10.1016/j.jeconom.2021.02.001},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {155-170},
  shortjournal = {J. Econ.},
  title        = {Who wins, who loses? identification of conditional causal effects, and the welfare impact of changing wages},
  volume       = {226},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analyzing cross-validation for forecasting with structural
instability. <em>JOE</em>, <em>226</em>(1), 139–154. (<a
href="https://doi.org/10.1016/j.jeconom.2020.10.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When forecasting with economic time series data , researchers often use a restricted window of observations or downweight past observations in order to mitigate the potential effects of parameter instability. In this paper, we study the problem of selecting a window for point forecasts made at the end of the sample. We develop asymptotic approximations to the sampling properties of window selection methods, and post-window selection point forecasts, where there is local parameter instability of various sorts. We examine risk properties of point forecasts made after cross-validation to select the window, and compare this approach to some alternative methods of selecting the window. We also propose a quasi-Bayesian form of cross-validation that we find to have good risk properties.},
  archive      = {J_JOE},
  author       = {Keisuke Hirano and Jonathan H. Wright},
  doi          = {10.1016/j.jeconom.2020.10.009},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {139-154},
  shortjournal = {J. Econ.},
  title        = {Analyzing cross-validation for forecasting with structural instability},
  volume       = {226},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semiparametrically efficient estimation of the average
linear regression function. <em>JOE</em>, <em>226</em>(1), 115–138. (<a
href="https://doi.org/10.1016/j.jeconom.2021.07.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let Y Y be an outcome of interest, X X a vector of treatment measures, and W W a vector of pre-treatment control variables. Here X X may include (combinations of) continuous, discrete, or non-mutually exclusive “treatments”. Consider the linear regression of Y Y onto X X in a subpopulation homogeneous in W = w W=w (formally a conditional linear predictor). Let b 0 w b0w be the coefficient vector on X X in this regression. We introduce a semiparametrically efficient estimate of the average β 0 = E b 0 W β0=Eb0W . When X X is binary-valued (multi-valued) our procedure recovers the (a vector of) average treatment effect(s). When X X is continuously-valued, or consists of multiple non-exclusive treatments, our estimand coincides with the average partial effect (APE) of X X on Y Y when the underlying potential response function is linear in X X , but otherwise heterogeneous across agents. When the potential response function takes a general nonlinear/heterogeneous form, and X X is continuously-valued, our procedure recovers a weighted average of the gradient of this response across individuals and values of X X . We provide a simple, and semiparametrically efficient, method of covariate adjustment for settings with complicated treatment regimes. Our method generalizes familiar methods of covariate adjustment used for program evaluation as well as methods of semiparametric regression (e.g., the partially linear regression model).},
  archive      = {J_JOE},
  author       = {Bryan S. Graham and Cristine Campos de Xavier Pinto},
  doi          = {10.1016/j.jeconom.2021.07.008},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {115-138},
  shortjournal = {J. Econ.},
  title        = {Semiparametrically efficient estimation of the average linear regression function},
  volume       = {226},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Minimax-regret sample design in anticipation of missing
data, with application to panel data. <em>JOE</em>, <em>226</em>(1),
104–114. (<a
href="https://doi.org/10.1016/j.jeconom.2020.12.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Missing data problems are ubiquitous in data collection. In surveys, these problems may arise from unit response, item nonresponse, and panel attrition. Building on the Dominitz and Manski (2017) study of choice between two or more sampling processes that differ in cost and quality, we study minimax-regret sample design in anticipation of missing data, where the collected data will be used for prediction under square loss of the values of functions of two variables. The analysis imposes no assumptions that restrict unobserved outcomes. Findings are reported for prediction of the values of linear and indicator functions using panel data with attrition. We also consider choice between a panel and repeated cross sections.},
  archive      = {J_JOE},
  author       = {Jeff Dominitz and Charles F. Manski},
  doi          = {10.1016/j.jeconom.2020.12.006},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {104-114},
  shortjournal = {J. Econ.},
  title        = {Minimax-regret sample design in anticipation of missing data, with application to panel data},
  volume       = {226},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimation and inference of semiparametric models using data
from several sources. <em>JOE</em>, <em>226</em>(1), 80–103. (<a
href="https://doi.org/10.1016/j.jeconom.2020.10.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the estimation and inference of nonlinear econometric models when the economic variables are contained in different data sets. We construct a semiparametric minimum distance (SMD) estimator of the unknown structural parameter of interest when there are some common conditioning variables in different data sets. The SMD estimator is shown to be consistent and has an asymptotic normal distribution . We provide the explicit form of the optimal weight for the SMD estimation. We provide a consistent estimator of the variance–covariance matrix of the SMD estimator, and hence inference procedures of the unknown parameter vector . The finite sample performances of the SMD estimators and the proposed inference procedures are investigated in few alternative Monte Carlo simulation studies.},
  archive      = {J_JOE},
  author       = {Moshe Buchinsky and Fanghua Li and Zhipeng Liao},
  doi          = {10.1016/j.jeconom.2020.10.011},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {80-103},
  shortjournal = {J. Econ.},
  title        = {Estimation and inference of semiparametric models using data from several sources},
  volume       = {226},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design-based analysis in difference-in-differences settings
with staggered adoption. <em>JOE</em>, <em>226</em>(1), 62–79. (<a
href="https://doi.org/10.1016/j.jeconom.2020.10.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we study estimation of and inference for average treatment effects in a setting with panel data. We focus on the staggered adoption setting where units, e.g , individuals, firms, or states, adopt the policy or treatment of interest at a particular point in time, and then remain exposed to this treatment at all times afterwards. We take a design perspective where we investigate the properties of estimators and procedures given assumptions on the assignment process. We show that under random assignment of the adoption date the standard Difference-In-Differences (DID) estimator is an unbiased estimator of a particular weighted average causal effect . We characterize the exact finite sample properties of this estimand, and show that the standard variance estimator is conservative.},
  archive      = {J_JOE},
  author       = {Susan Athey and Guido W. Imbens},
  doi          = {10.1016/j.jeconom.2020.10.012},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {62-79},
  shortjournal = {J. Econ.},
  title        = {Design-based analysis in difference-in-differences settings with staggered adoption},
  volume       = {226},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust likelihood estimation of dynamic panel data models.
<em>JOE</em>, <em>226</em>(1), 21–61. (<a
href="https://doi.org/10.1016/j.jeconom.2021.03.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop likelihood-based estimators for autoregressive panel data models that are consistent in the presence of time series heteroskedasticity. Bias-corrected conditional score estimators, random effects maximum likelihood in levels and first differences, and estimators that impose mean stationarity are considered for general autoregressive models with individual effects. We investigate identification under unit roots, and show that random effects estimation in levels may achieve substantial efficiency gains relative to estimation from data in differences. In an empirical application, we find evidence against unit roots in individual earnings processes from the Panel Study of Income Dynamics and the Spanish section of the European Community Household Panel.},
  archive      = {J_JOE},
  author       = {Javier Alvarez and Manuel Arellano},
  doi          = {10.1016/j.jeconom.2021.03.005},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {21-61},
  shortjournal = {J. Econ.},
  title        = {Robust likelihood estimation of dynamic panel data models},
  volume       = {226},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feedback in panel data models. <em>JOE</em>,
<em>226</em>(1), 4–20. (<a
href="https://doi.org/10.1016/j.jeconom.2019.08.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Much of the analysis of panel data has been based on an assumption of strict exogeneity. Distributions are specified for outcome variables conditional on a latent individual effect and conditional on observed predictor variables at all dates, with the future values of the predictor variables assumed to have no effect on the conditional distribution. The paper relaxes this assumption in order to allow for lagged dependent variables and, more generally, for feedback from lagged dependent variables to current values of the predictor variables. Such feedback would arise in an evaluation study if the treatment variable is randomly assigned only conditional on the individual effect and on previous outcomes. An information bound is derived for a semiparametric regression model with sequential moment restrictions, with the information set increasing over time. The bound is then applied to a model with a (scalar) multiplicative random effect. The mean of the random effect conditional on the predictor variables is not restricted, so that the random effect can control for various omitted variables. This conditional mean is the nonparametric component of the semiparametric regression model. There is a transformation that eliminates the random effect and leads to a set of sequential moment restrictions in which the moment function depends on only a finite-dimensional parameter. The information bound for this simpler problem coincides with that of the original problem. The form of the optimal instrumental variables is derived. The paper also considers the identification problems that arise when the random effect is a vector with two or more components.},
  archive      = {J_JOE},
  author       = {Gary Chamberlain},
  doi          = {10.1016/j.jeconom.2019.08.018},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {4-20},
  shortjournal = {J. Econ.},
  title        = {Feedback in panel data models},
  volume       = {226},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Introduction to the annals issue in honor of gary
chamberlain. <em>JOE</em>, <em>226</em>(1), 1–3. (<a
href="https://doi.org/10.1016/j.jeconom.2021.09.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JOE},
  author       = {Bryan Graham and Keisuke Hirano},
  doi          = {10.1016/j.jeconom.2021.09.001},
  journal      = {Journal of Econometrics},
  number       = {1},
  pages        = {1-3},
  shortjournal = {J. Econ.},
  title        = {Introduction to the annals issue in honor of gary chamberlain},
  volume       = {226},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
