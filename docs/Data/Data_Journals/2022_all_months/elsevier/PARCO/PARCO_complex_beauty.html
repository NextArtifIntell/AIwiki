<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>PARCO_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="parco---51">PARCO - 51</h2>
<ul>
<li><details>
<summary>
(2022). Efficient parallel branch-and-bound approaches for exact
graph edit distance problem. <em>PARCO</em>, <em>114</em>, 102984. (<a
href="https://doi.org/10.1016/j.parco.2022.102984">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Edit Distance (GED) is a well-known measure used in the graph matching to measure the similarity/dissimilarity between two graphs by computing the minimum cost of edit operations needed to transform one graph into another. This process, Which appears to be simple, is known NP-hard and time consuming since the search space is increasing exponentially. One way to optimally solve this problem is by using Branch and Bound (B&amp;B) algorithms, Which reduce the computation time required to explore the whole search space by performing an implicit enumeration of the search space instead of an exhaustive one based on a pruning technique. nevertheless, They remain inefficient when dealing with large problem instances due to the impractical running time needed to explore the whole search space. To overcome this issue, We propose in this paper three parallel B&amp;B approaches based on shared memory to exploit the multi-core CPU processors: First, a work-stealing approach where several instances of the B&amp;B algorithm explore a single search tree concurrently achieving speedups up to 24 × × faster than the sequential version. Second, a tree-based approach where multiple parts of the search tree are explored simultaneously by independent B&amp;B instances achieving speedups up to 28 × × . Finally, Due to the irregular nature of the GED problem, two load-balancing strategies are proposed to ensure a fair workload between parallel processes achieving impressive speedups up to 300 × × . all experiments have been carried out on well-known datasets},
  archive      = {J_PARCO},
  author       = {Adel Dabah and Ibrahim Chegrane and Saïd Yahiaoui and Ahcene Bendjoudi and Nadia Nouali-Taboudjemat},
  doi          = {10.1016/j.parco.2022.102984},
  journal      = {Parallel Computing},
  pages        = {102984},
  shortjournal = {Parallel Comput.},
  title        = {Efficient parallel branch-and-bound approaches for exact graph edit distance problem},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Graph optimization algorithm using symmetry and host bias
for low-latency indirect network. <em>PARCO</em>, <em>114</em>, 102983.
(<a href="https://doi.org/10.1016/j.parco.2022.102983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is known that an indirect network with a small host-to-host Average Shortest Path Length (h-ASPL) improves overall system performance in a parallel computer system. As a means to discuss such indirect networks in graph theory, the Order/Radix Problem (ORP) has been proposed. ORP involves finding a graph with a minimum h-ASPL that satisfies a given number of hosts and radix. A graph in ORP represents an indirect network and has two types of vertices: host and switch. We propose an optimization algorithm to generate graphs with a sufficiently small h-ASPL. The primary features of the proposed algorithm are the symmetry of the graph and the bias of the hosts adjacent to each switch. These features reduce the computational time to calculate the h-ASPL and improve the search performance of the algorithm. The performance of the proposed algorithm is evaluated using problems presented by Graph Golf, an international ORP competition. Our results show that the proposed algorithm can generate graphs with a smaller h-ASPL than the existing algorithm. To evaluate the performance of the graphs generated by the proposed algorithm, we use the parallel simulation framework SimGrid and the parallel benchmark collection NAS Parallel Benchmarks. Our results also show that the graphs generated by the proposed algorithm have higher performance than those generated by the existing algorithm.},
  archive      = {J_PARCO},
  author       = {Masahiro Nakao and Masaki Tsukamoto and Yoshiko Hanada and Keiji Yamamoto},
  doi          = {10.1016/j.parco.2022.102983},
  journal      = {Parallel Computing},
  pages        = {102983},
  shortjournal = {Parallel Comput.},
  title        = {Graph optimization algorithm using symmetry and host bias for low-latency indirect network},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). NekRS, a GPU-accelerated spectral element navier–stokes
solver. <em>PARCO</em>, <em>114</em>, 102982. (<a
href="https://doi.org/10.1016/j.parco.2022.102982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of NekRS, a GPU-oriented thermal-fluids simulation code based on the spectral element method (SEM) is described. For performance portability , the code is based on the open concurrent compute abstraction and leverages scalable developments in the SEM code Nek5000 and in libParanumal, which is a library of high-performance kernels for high-order discretizations and PDE-based miniapps. Critical performance sections of the Navier–Stokes time advancement are addressed. Performance results on several platforms are presented, including scaling to 27,648 V100s on OLCF Summit, for calculations of up to 60B grid points (240B degrees-of-freedom).},
  archive      = {J_PARCO},
  author       = {Paul Fischer and Stefan Kerkemeier and Misun Min and Yu-Hsiang Lan and Malachi Phillips and Thilina Rathnayake and Elia Merzari and Ananias Tomboulides and Ali Karakus and Noel Chalmers and Tim Warburton},
  doi          = {10.1016/j.parco.2022.102982},
  journal      = {Parallel Computing},
  pages        = {102982},
  shortjournal = {Parallel Comput.},
  title        = {NekRS, a GPU-accelerated spectral element Navier–Stokes solver},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SGPM: A coroutine framework for transaction processing.
<em>PARCO</em>, <em>114</em>, 102980. (<a
href="https://doi.org/10.1016/j.parco.2022.102980">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coroutine is able to increase program concurrency and processor core utilization. However, for adapting the coroutine-to-transaction model, the existing coroutine package has the following disadvantages: (1) Additional scheduler threads incur synchronization overhead when the load between scheduler threads and worker threads is unbalanced. (2) Coroutines are swapped out periodically to prevent deadlocks , which will increase the conflict rate by adding suspended transactions. (3) Supporting only the swap-out function (yield, await, etc.) cannot flexibly control the transaction swap-in time. In this paper, we present SGPM, a coroutine framework for transaction processing . To adapt to the coroutine-to-transaction model, SGPM has the following properties: First, it eliminates scheduler threads and the periodic coroutine switch. Second, it provides a variety of coroutine scheduling strategies to make all types of concurrency control protocols run on SGPM reasonably. We implement eight well-known concurrency control on SGPM and, particularly, we use SGPM to optimize the performance of four wound-wait concurrency control among them, including 2PL, SS2PL, Calvin, and EWV. The experiment result demonstrates that after SGPM optimization 2PL and SS2PL outperform OCC and MVCC, and the throughput of Calvin and EWV is also improved by 1.2x and 1.3x respectively.},
  archive      = {J_PARCO},
  author       = {Xinyuan Wang and Hejiao Huang},
  doi          = {10.1016/j.parco.2022.102980},
  journal      = {Parallel Computing},
  pages        = {102980},
  shortjournal = {Parallel Comput.},
  title        = {SGPM: A coroutine framework for transaction processing},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tausch: A halo exchange library for large heterogeneous
computing systems using MPI, OpenCL, and CUDA. <em>PARCO</em>,
<em>114</em>, 102973. (<a
href="https://doi.org/10.1016/j.parco.2022.102973">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exchanging halo data is a common task in modern scientific computing applications and efficient handling of this operation is critical for the performance of the overall simulation. Tausch is a novel header-only library that provides a simple API for efficiently handling these types of data movements. Tausch supports both simple CPU-only systems, but also more complex heterogeneous systems with both CPUs and GPUs . It currently supports both OpenCL and CUDA for communicating with GPGPU devices, and allows for communication between GPGPUs and CPUs. The API allows for drop-in replacement in existing codes and can be used for the communication layer in new codes. This paper provides an overview of the approach taken in Tausch, and a performance analysis that demonstrates expected and achieved performance. We highlight the ease of use and performance with three applications: First Tausch is compared to the halo exchange framework from two Mantevo applications, HPCCG and miniFE, and then it is used to replace a legacy halo exchange library in the flexible multigrid solver framework Cedar.},
  archive      = {J_PARCO},
  author       = {Lukas Spies and Amanda Bienz and David Moulton and Luke Olson and Andrew Reisner},
  doi          = {10.1016/j.parco.2022.102973},
  journal      = {Parallel Computing},
  pages        = {102973},
  shortjournal = {Parallel Comput.},
  title        = {Tausch: A halo exchange library for large heterogeneous computing systems using MPI, OpenCL, and CUDA},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A method for efficient radio astronomical data gridding on
multi-core vector processor. <em>PARCO</em>, <em>113</em>, 102972. (<a
href="https://doi.org/10.1016/j.parco.2022.102972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gridding is the performance-critical step in the data reduction pipeline for radio astronomy research, allowing astronomers to create the correct sky images for further analysis. Like the 2D stencil computation, gridding iteratively updates the output cells by convolution, where the value at each output cell in the space is computed as a weighted sum of neighboring point values. Existing state-of-the-art works have achieved performance improvement of gridding by using multi-core CPUs and GPUs in real-world applications, and their study proved that gridding is a type of scientific computation with high-density computing characteristics. However, low computational performance or high power consumption becomes the main limitation for their processing of large-scale astronomical data. The high-density computing feature of gridding provides opportunities to accelerate it on the multi-core vector processor with vector-SIMD architectures. However, existing works’ (such as those implemented on CPUs or GPUs) task parallelization and data transfer strategies are inefficient to perform gridding directly on the vector processor without any dedicated mapping algorithm . M-DSP is a multi-core vector processor with vector-SIMD architectures designed for the next-generation exascale supercomputer , delivering high performance with ultra-low power consumption . In this paper, we present, for the first time, a novel method to achieve efficient gridding on the M-DSP. Specifically, we propose a gridding workflow designed for the vector-SIMD architectures and present a vectorized version of the gridding convolution algorithm to fully exploit the computational power of the M-DSP. In addition, centering on the processor architectures, we propose task-based parallelization strategies for block and line computing as well as different data loading strategies to achieve high parallel performance and high data transfer efficiency. Experimental results show that our work on M-DSP exhibits very competitive performance compared to other methods running on CPUs or GPUs . This demonstrates the efficiency of our method and the fact that the vector-SIMD architecture is beneficial for scientific computing with ”high density” characteristics, which can exploit its wide vector core and achieve higher performance than its competitors.},
  archive      = {J_PARCO},
  author       = {Hao Wang and Ce Yu and Jian Xiao and Shanjiang Tang and Yu Lu and Hao Fu and Bo Kang and Gang Zheng and Chenzhou Cui},
  doi          = {10.1016/j.parco.2022.102972},
  journal      = {Parallel Computing},
  pages        = {102972},
  shortjournal = {Parallel Comput.},
  title        = {A method for efficient radio astronomical data gridding on multi-core vector processor},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast calculation of isostatic compensation correction using
the GPU-parallel prism method. <em>PARCO</em>, <em>113</em>, 102970. (<a
href="https://doi.org/10.1016/j.parco.2022.102970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Isostatic compensation is a crucial component of crustal structure analysis and geoid calculations in cases of gravity reduction. However, large-scale and high-precision calculations are limited by the inefficiencies of the strict prism method and the low accuracy of the approximate calculation formula. In this study, we propose a new method of terrain grid re-encoding and an eight-component strict prism integral disassembly using a compute unified device architecture parallel programming platform. We use a fast parallel algorithm for the isostatic compensation correction, using the strict prism method based on CPU + GPU heterogeneous parallelization with efficient task allocation and GPU thread overloading procedure. The results of this study provide a rigorous, fast, and accurate solution for high-resolution and high-precision isostatic compensation corrections. To ensure an absolute calculation accuracy of 10 −6 mGal, the maximum acceleration ratio of the calculation was set to at least 730 using one GPU and 2241 using four GPUs, which shortens the calculation time and improves the calculation efficiency.},
  archive      = {J_PARCO},
  author       = {Yan Huang and Qingbin Wang and Minghao Lv and Xingguang Song and Jinkai Feng and Xuli Tan and Ziyan Huang and Chuyuan Zhou},
  doi          = {10.1016/j.parco.2022.102970},
  journal      = {Parallel Computing},
  pages        = {102970},
  shortjournal = {Parallel Comput.},
  title        = {Fast calculation of isostatic compensation correction using the GPU-parallel prism method},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Accelerating communication for parallel programming models
on GPU systems. <em>PARCO</em>, <em>113</em>, 102969. (<a
href="https://doi.org/10.1016/j.parco.2022.102969">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an increasing number of leadership-class systems embrace GPU accelerators in the race towards exascale, efficient communication of GPU data is becoming one of the most critical components of high-performance computing. For developers of parallel programming models , implementing support for GPU-aware communication using native APIs for GPUs such as CUDA can be a daunting task as it requires considerable effort with little guarantee of performance. In this work, we demonstrate the capability of the Unified Communication X (UCX) framework to compose a GPU-aware communication layer that serves multiple parallel programming models of the Charm++ ecosystem: Charm++, Adaptive MPI (AMPI), and Charm4py. We demonstrate the performance impact of our designs with microbenchmarks adapted from the OSU benchmark suite, obtaining improvements in latency of up to 10.1x in Charm++, 11.7x in AMPI, and 17.4x in Charm4py. We also observe increases in bandwidth of up to 10.1x in Charm++, 10x in AMPI, and 10.5x in Charm4py. We show the potential impact of our designs on real-world applications by evaluating a proxy application for the Jacobi iterative method, improving the communication performance by up to 12.4x in Charm++, 12.8x in AMPI, and 19.7x in Charm4py.},
  archive      = {J_PARCO},
  author       = {Jaemin Choi and Zane Fink and Sam White and Nitin Bhat and David F. Richards and Laxmikant V. Kale},
  doi          = {10.1016/j.parco.2022.102969},
  journal      = {Parallel Computing},
  pages        = {102969},
  shortjournal = {Parallel Comput.},
  title        = {Accelerating communication for parallel programming models on GPU systems},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). QoS-aware dynamic resource allocation with improved
utilization and energy efficiency on GPU. <em>PARCO</em>, <em>113</em>,
102958. (<a href="https://doi.org/10.1016/j.parco.2022.102958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although GPUs have been indispensable in data centers , meeting the Quality of Service (QoS) under task consolidation on GPU is extremely challenging. Previous works mostly rely on the static task or resource scheduling and cannot handle the QoS violation during runtime. In addition, existing works fail to exploit the computing characteristics of batch tasks, and thus waste the opportunities to reduce power consumption while improving GPU utilization. To address the above problems, we propose a new runtime mechanism SMQoS that can dynamically adjust the resource allocation during runtime to meet the QoS of latency-sensitive (LS) tasks and determine the optimal resource allocation for batch tasks to improve GPU utilization and power efficiency. We implement the proposed mechanism on both simulator ( SMQoS ) and real GPU hardware ( RH-SMQoS ). The experimental results show that both SMQoS and RH-SMQoS can achieve better QoS for LS tasks and higher throughput for batch tasks compared to the state-of-the-art works. With hardware extension, the SMQoS can further reduce the power consumption by power gating idle computing resources.},
  archive      = {J_PARCO},
  author       = {Qingxiao Sun and Liu Yi and Hailong Yang and Mingzhen Li and Zhongzhi Luan and Depei Qian},
  doi          = {10.1016/j.parco.2022.102958},
  journal      = {Parallel Computing},
  pages        = {102958},
  shortjournal = {Parallel Comput.},
  title        = {QoS-aware dynamic resource allocation with improved utilization and energy efficiency on GPU},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ParGeMSLR: A parallel multilevel schur complement low-rank
preconditioning and solution package for general sparse matrices.
<em>PARCO</em>, <em>113</em>, 102956. (<a
href="https://doi.org/10.1016/j.parco.2022.102956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper discusses parGeMSLR , a C++/MPI software library for the solution of sparse systems of linear algebraic equations via preconditioned Krylov subspace methods in distributed-memory computing environments. The preconditioner implemented in parGeMSLR is based on algebraic domain decomposition and partitions the symmetrized adjacency graph recursively into several non-overlapping partitions via a p p -way vertex separator, where p p is an integer multiple of the total number of MPI processes. From a numerical perspective, parGeMSLR builds a Schur complement approximate inverse preconditioner as the sum between the matrix inverse of the interface coupling matrix and a low-rank correction term. To reduce the cost associated with the computation of the approximate inverse matrices, parGeMSLR exploits a multilevel partitioning of the algebraic domain. The parGeMSLR library is implemented on top of the Message Passing Interface and can solve both real and complex linear systems. Furthermore, parGeMSLR can take advantage of hybrid computing environments with in-node access to one or more Graphics Processing Units . Finally, the parallel efficiency (weak and strong scaling) of parGeMSLR is demonstrated on a few model problems arising from discretizations of 3D Partial Differential Equations .},
  archive      = {J_PARCO},
  author       = {Tianshi Xu and Vassilis Kalantzis and Ruipeng Li and Yuanzhe Xi and Geoffrey Dillon and Yousef Saad},
  doi          = {10.1016/j.parco.2022.102956},
  journal      = {Parallel Computing},
  pages        = {102956},
  shortjournal = {Parallel Comput.},
  title        = {ParGeMSLR: A parallel multilevel schur complement low-rank preconditioning and solution package for general sparse matrices},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SVM-SMO-SGD: A hybrid-parallel support vector machine
algorithm using sequential minimal optimization with stochastic gradient
descent. <em>PARCO</em>, <em>113</em>, 102955. (<a
href="https://doi.org/10.1016/j.parco.2022.102955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Support Vector Machine (SVM) method is one of the popular machine learning algorithms as it gives high accuracy. However, like most machine learning algorithms , the resource consumption of the SVM algorithm in terms of time and memory increases linearly as the dataset grows. In this study, a parallel-hybrid algorithm that combines SVM, Sequential Minimal Optimization (SMO) with Stochastic Gradient Descent (SGD) methods have been proposed to optimize the calculation of the weight costs. The performance of the proposed SVM-SMO-SGD algorithm was compared with classical SMO and Compute Unified Device Architecture (CUDA) based approaches on the well-known datasets (i.e., Diabetes, Healthcare Stroke Prediction, Adults) with 520, 5110, and 32,560 samples, respectively. According to the results, Sequential SVM-SMO-SGD is 3.81 times faster in terms of time, and 1.04 times more efficient RAM consumption than the classical SMO algorithm . The parallel SVM-SMO-SGD algorithm, on the other hand, is 75.47 times faster than the classical SMO algorithm in terms of time. It is also 1.9 times more efficient in RAM consumption. The overall classification accuracy of all algorithms is 87\% in the Diabetes dataset, 95\% in the Healthcare Stroke Prediction dataset, and 82\% in the Adults dataset.},
  archive      = {J_PARCO},
  author       = {Gizen Mutlu and Çiğdem İnan Acı},
  doi          = {10.1016/j.parco.2022.102955},
  journal      = {Parallel Computing},
  pages        = {102955},
  shortjournal = {Parallel Comput.},
  title        = {SVM-SMO-SGD: A hybrid-parallel support vector machine algorithm using sequential minimal optimization with stochastic gradient descent},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimizing small channel 3D convolution on GPU with tensor
core. <em>PARCO</em>, <em>113</em>, 102954. (<a
href="https://doi.org/10.1016/j.parco.2022.102954">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many scenarios, particularly scientific AI applications, algorithm engineers widely adopt more complex convolution, e.g. 3D CNN , to improve the accuracy. Scientific AI applications with 3D-CNN, which tends to train with volumetric datasets , substantially increase the size of the input, which in turn potentially restricts the channel sizes (e.g. less than 64) under the constraints of limited device memory capacity. Since existing convolution implementations tend to split and parallelize computing the small channel convolution from channel dimension, they usually cannot fully exploit the performance of GPU accelerator, in particular that configured with the emerging tensor core. In this work, we target on enhancing the performance of small channel 3D convolution on the GPU platform configured with tensor cores. Our analysis shows that the channel size of convolution has a great effect on the performance of existing convolution implementations, that are memory-bound on tensor core. By leveraging the memory hierarchy characteristics and the WMMA API of tensor core, we propose and implement holistic optimizations for both promoting the data access efficiency and intensifying the utilization of computing units . Experiments show that our implementation can obtain 1.1x–5.4x speedup comparing to the cuDNN’s implementations for the 3D convolutions on different GPU platforms. We also evaluate our implementations on two practical scientific AI applications and observe up to 1.7x and 2.0x overall speedups compared with using cuDNN on V100 GPU.},
  archive      = {J_PARCO},
  author       = {Jiazhi Jiang and Dan Huang and Jiangsu Du and Yutong Lu and Xiangke Liao},
  doi          = {10.1016/j.parco.2022.102954},
  journal      = {Parallel Computing},
  pages        = {102954},
  shortjournal = {Parallel Comput.},
  title        = {Optimizing small channel 3D convolution on GPU with tensor core},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Routing brain traffic through the von neumann bottleneck:
Efficient cache usage in spiking neural network simulation code on
general purpose computers. <em>PARCO</em>, <em>113</em>, 102952. (<a
href="https://doi.org/10.1016/j.parco.2022.102952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simulation is a third pillar next to experiment and theory in the study of complex dynamic systems such as biological neural networks . Contemporary brain-scale networks correspond to directed random graphs of a few million nodes, each with an in-degree and out-degree of several thousands of edges, where nodes and edges correspond to the fundamental biological units, neurons and synapses, respectively. The activity in neuronal networks is also sparse. Each neuron occasionally transmits a brief signal, called spike, via its outgoing synapses to the corresponding target neurons. In distributed computing these targets are scattered across thousands of parallel processes. The spatial and temporal sparsity represents an inherent bottleneck for simulations on conventional computers: irregular memory-access patterns cause poor cache utilization. Using an established neuronal network simulation code as a reference implementation, we investigate how common techniques to recover cache performance such as software-induced prefetching and software pipelining can benefit a real-world application. The algorithmic changes reduce simulation time by up to 50\%. The study exemplifies that many-core systems assigned with an intrinsically parallel computational problem can alleviate the von Neumann bottleneck of conventional computer architectures .},
  archive      = {J_PARCO},
  author       = {J. Pronold and J. Jordan and B.J.N. Wylie and I. Kitayama and M. Diesmann and S. Kunkel},
  doi          = {10.1016/j.parco.2022.102952},
  journal      = {Parallel Computing},
  pages        = {102952},
  shortjournal = {Parallel Comput.},
  title        = {Routing brain traffic through the von neumann bottleneck: Efficient cache usage in spiking neural network simulation code on general purpose computers},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Operational data analytics in practice: Experiences from
design to deployment in production HPC environments. <em>PARCO</em>,
<em>113</em>, 102950. (<a
href="https://doi.org/10.1016/j.parco.2022.102950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As HPC systems continue to grow in scale and complexity, efficient and manageable operation is increasingly critical. For this reason, many centers are starting to explore the use of Operational Data Analytics (ODA) techniques, which extract knowledge from the massive amounts of data produced by monitoring systems and use it for enacting control over system knobs, or for aiding administrators through visualization. As ODA is a multi-faceted problem, much research effort has gone into finding solutions to its separate aspects: however, comprehensive solutions to enable production use of ODA are still rare, while accounts of ODA experiences and the associated challenges are even harder to come across. In this work we aim to bridge the gap between ODA research and production use by presenting our own experiences, associated with proactive control of warm-water inlet temperatures and visualization of job data on two different HPC systems. We cover the entire development process, starting from a description of requirements and challenges, and down to design, deployment and evaluation. Moreover, we discuss a series of critical points related to the maintainability of ODA, and propose action items in an effort to drive the community forward. We rely on a series of open-source tools and techniques, which make for a generic ODA framework that is suitable for most use cases.},
  archive      = {J_PARCO},
  author       = {Alessio Netti and Michael Ott and Carla Guillen and Daniele Tafani and Martin Schulz},
  doi          = {10.1016/j.parco.2022.102950},
  journal      = {Parallel Computing},
  pages        = {102950},
  shortjournal = {Parallel Comput.},
  title        = {Operational data analytics in practice: Experiences from design to deployment in production HPC environments},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parallel multi-view HEVC for heterogeneously embedded
cluster system. <em>PARCO</em>, <em>112</em>, 102948. (<a
href="https://doi.org/10.1016/j.parco.2022.102948">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a computer cluster with heterogeneous computing components intended to provide concurrency and parallelism with embedded processors to achieve a real-time Multi-View High-Efficiency Video Coding (MV-HEVC) encoder/decoder with a maximum resolution of 1088p. The latest MV-HEVC standard represents a significant improvement over the previous video coding standard (MVC). However, the MV-HEVC standard also has higher computational complexity . To this point, research using the MV-HEVC has had to use the Central Processing Unit (CPU) on a Personal Computer (PC) or workstation for decompression , because MV-HEVC is much more complex than High-Efficiency Video Coding (HEVC), and because decompressors need higher parallelism to decompress in real time. It is particularly difficult to encode/decode in an embedded device. Therefore, we propose a novel framework for an MV-HEVC encoder/decoder that is based on a heterogeneously distributed embedded system . To this end, we use a parallel computing method to divide the video into multiple blocks and then code the blocks independently in each sub-work node with a group of pictures and a coding tree unit level. To appropriately assign the tasks to each work node, we propose a new allocation method that makes the operation of the entire heterogeneously distributed system more efficient. Our experimental results show that, compared to the single device (3D-HTM single threading), the proposed distributed MV-HEVC decoder and encoder performance increased approximately (20.39 and 68.7) times under 20 devices (multithreading) with the CTU level of a 1088p resolution video, respectively. Further, at the proposed GOP level, the decoder and encoder performance with 20 devices (multithreading) respectively increased approximately (20.78 and 77) times for a 1088p resolution video with heterogeneously distributed computing compared to the single device (3D-HTM single threading).},
  archive      = {J_PARCO},
  author       = {Seo Jin Jang and Wei Liu and Wei Li and Yong Beom Cho},
  doi          = {10.1016/j.parco.2022.102948},
  journal      = {Parallel Computing},
  pages        = {102948},
  shortjournal = {Parallel Comput.},
  title        = {Parallel multi-view HEVC for heterogeneously embedded cluster system},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Energy-efficient scheduling algorithms based on task
clustering in heterogeneous spark clusters. <em>PARCO</em>,
<em>112</em>, 102947. (<a
href="https://doi.org/10.1016/j.parco.2022.102947">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spark is widely used for its fast in-memory processing. It is important to improve energy efficiency under deadline constrains. In this paper, a Task Performance Clustering of Best Fitting Decrease (TPCBFD) scheduling algorithm is proposed. It divides tasks in Spark into three types, with the different types of tasks being placed on nodes with superior performance. However, the basic computation time for TPCBFD takes up a large proportion of the task execution time, so the Energy-Aware TPCBFD (EATPCBFD) algorithm based on the proposed energy consumption model is proposed, focusing on optimizing energy efficiency and Service Level Agreement (SLA) service times. The experimental results show that EATPCBFD increases the average energy efficiency in Spark by 77\% and the average passing rate of SLA service time by 14\% compared to comparison algorithms. EATPCBFD has higher energy efficiency on average than comparison algorithms under deadline. The average energy efficiency of EATPCBFD with the deadline constraint is higher than the comparison algorithm.},
  archive      = {J_PARCO},
  author       = {Wenhu Shi and Hongjian Li and Junzhe Guan and Hang Zeng and Rafe Misskat jahan},
  doi          = {10.1016/j.parco.2022.102947},
  journal      = {Parallel Computing},
  pages        = {102947},
  shortjournal = {Parallel Comput.},
  title        = {Energy-efficient scheduling algorithms based on task clustering in heterogeneous spark clusters},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimizing convolutional neural networks on multi-core
vector accelerator. <em>PARCO</em>, <em>112</em>, 102945. (<a
href="https://doi.org/10.1016/j.parco.2022.102945">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vector Accelerators have been widely used in scientific computing. It also shows great potential to accelerate the computational performance of convolutional neural networks (CNNs). However, previous general CNN-mapping methods introduced a large amount of intermediate data and additional conversion, and the resulting memory overhead would cause great performance loss. To address these issues and achieve high computational efficiency, this paper proposes an efficient CNN-mapping method dedicated to vector accelerators, including: 1) Data layout method: establishing a set of efficient data storage and computing models for various CNN networks on vector accelerators. It achieves high memory access efficiency and high vectorization efficiency. 2) A conversion method: convert the computation of convolutional layers and fully connected layers into large-scale matrix multiplication, and convert the computation of pooling layers into row computation of matrix. All conversions are implemented by extracting rows from a two-dimensional matrix, with high data access and transmission efficiency, and without additional memory overhead and data conversion. Based on these methods, we design a vectorization mechanism to vectorize convolutional, pooling and fully connected layers on a vector accelerator, which can be applied for various CNN models. This mechanism takes full advantage of the parallel computing capability of the multi-core vector accelerator and further improves the performance of deep convolutional neural networks. The experimental results show that the average computational efficiency of the convolutional layers and full connected layers of AlexNet, VGG-19, GoogleNet and ResNet-50 is 93.3\% and 93.4\% respectively, and the average data access efficiency of pooling layer is 70\%. Compared to NVIDIA inference GPUs, our accelerator achieves a 36.1\% performance improvement, comparable to NVIDIA V100 GPUs. Compared with Matrix2000 of similar architecture, our accelerator achieves a 17-45\% improvement in computational efficiency.},
  archive      = {J_PARCO},
  author       = {Zhong Liu and Xin Xiao and Chen Li and Sheng Ma and Deng Rangyu},
  doi          = {10.1016/j.parco.2022.102945},
  journal      = {Parallel Computing},
  pages        = {102945},
  shortjournal = {Parallel Comput.},
  title        = {Optimizing convolutional neural networks on multi-core vector accelerator},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving cryptanalytic applications with stochastic
runtimes on GPUs and multicores. <em>PARCO</em>, <em>112</em>, 102944.
(<a href="https://doi.org/10.1016/j.parco.2022.102944">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate cryptanalytic applications comprised of many independent tasks that exhibit a stochastic runtime distribution. We compare four algorithms for executing such applications on GPUs and on multicore CPUs with SIMD units. We demonstrate that for four different distributions, multiple problem sizes, and three platforms the best strategy varies. We support our analytic results by extensive experiments on an Intel Skylake-based multicore CPU and a high performance GPU (Nvidia Volta).},
  archive      = {J_PARCO},
  author       = {Lena Oden and Jörg Keller},
  doi          = {10.1016/j.parco.2022.102944},
  journal      = {Parallel Computing},
  pages        = {102944},
  shortjournal = {Parallel Comput.},
  title        = {Improving cryptanalytic applications with stochastic runtimes on GPUs and multicores},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Performance and accuracy predictions of approximation
methods for shortest-path algorithms on GPUs. <em>PARCO</em>,
<em>112</em>, 102942. (<a
href="https://doi.org/10.1016/j.parco.2022.102942">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approximate computing techniques, where less-than-perfect solutions are acceptable, present performance-accuracy trade-offs by performing inexact computations. Moreover, heterogeneous architectures , a combination of miscellaneous compute units, offer high performance as well as energy efficiency. Graph algorithms utilize the parallel computation units of heterogeneous GPU architectures as well as performance improvements offered by approximation methods. Since different approximations yield different speedup and accuracy loss for the target execution, it becomes impractical to test all methods with various parameters. In this work, we perform approximate computations for the three shortest-path graph algorithms and propose a machine learning framework to predict the impact of the approximations on program performance and output accuracy. We evaluate random predictions for both synthetic and real road-network graphs, and predictions of the large graph cases from small graph instances. We achieve less than 5\% prediction error rates for speedup and inaccuracy values.},
  archive      = {J_PARCO},
  author       = {Busenur Aktılav and Işıl Öz},
  doi          = {10.1016/j.parco.2022.102942},
  journal      = {Parallel Computing},
  pages        = {102942},
  shortjournal = {Parallel Comput.},
  title        = {Performance and accuracy predictions of approximation methods for shortest-path algorithms on GPUs},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Low-synch gram–schmidt with delayed reorthogonalization for
krylov solvers. <em>PARCO</em>, <em>112</em>, 102940. (<a
href="https://doi.org/10.1016/j.parco.2022.102940">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The parallel strong-scaling of iterative methods is often determined by the number of global reductions at each iteration. Low-synch Gram–Schmidt algorithms are applied here to the Arnoldi algorithm to reduce the number of global reductions and therefore to improve the parallel strong-scaling of iterative solvers for nonsymmetric matrices such as the GMRES and the Krylov–Schur iterative methods. In the Arnoldi context, the Q R QR factorization is “left-looking” and processes one column at a time. Among the methods for generating an orthogonal basis for the Arnoldi algorithm, the classical Gram–Schmidt algorithm, with reorthogonalization (CGS2) requires three global reductions per iteration. A new variant of CGS2 that requires only one reduction per iteration is presented and applied to the Arnoldi algorithm. Delayed CGS2 (DCGS2) employs the minimum number of global reductions per iteration (one) for a one-column at-a-time algorithm. The main idea behind the new algorithm is to group global reductions by rearranging the order of operations. DCGS2 must be carefully integrated into an Arnoldi expansion or a GMRES solver. Numerical stability experiments assess robustness for Krylov–Schur eigenvalue computations . Performance experiments on the ORNL Summit supercomputer then establish the superiority of DCGS2 over CGS2.},
  archive      = {J_PARCO},
  author       = {Daniel Bielich and Julien Langou and Stephen Thomas and Kasia Świrydowicz and Ichitaro Yamazaki and Erik G. Boman},
  doi          = {10.1016/j.parco.2022.102940},
  journal      = {Parallel Computing},
  pages        = {102940},
  shortjournal = {Parallel Comput.},
  title        = {Low-synch Gram–Schmidt with delayed reorthogonalization for krylov solvers},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Resource allocation for task-level speculative scientific
applications: A proof of concept using parallel trajectory splicing.
<em>PARCO</em>, <em>112</em>, 102936. (<a
href="https://doi.org/10.1016/j.parco.2022.102936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The constant increase in parallelism available on large-scale distributed computers poses major scalability challenges to many scientific applications. A common strategy to improve scalability is to express algorithms in terms of independent tasks that can be executed concurrently on a runtime system . In this manuscript, we consider a generalization of this approach where task-level speculation is allowed. In this context, a probability is attached to each task which corresponds to the likelihood that the output of the speculative task will be consumed as part of the larger calculation. We consider the problem of optimal resource allocation to each of the possible tasks so as to maximize the total expected computational throughput. The power of this approach is demonstrated by analyzing its application to Parallel Trajectory Splicing, a massively-parallel long-time-dynamics method for atomistic simulations .},
  archive      = {J_PARCO},
  author       = {Andrew Garmon and Vinay Ramakrishnaiah and Danny Perez},
  doi          = {10.1016/j.parco.2022.102936},
  journal      = {Parallel Computing},
  pages        = {102936},
  shortjournal = {Parallel Comput.},
  title        = {Resource allocation for task-level speculative scientific applications: A proof of concept using parallel trajectory splicing},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A coarse-grained multicomputer parallel algorithm for the
sequential substring constrained longest common subsequence problem.
<em>PARCO</em>, <em>111</em>, 102927. (<a
href="https://doi.org/10.1016/j.parco.2022.102927">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the sequential substring constrained longest common subsequence (SSCLCS) problem. It is widely used in the bioinformatics field. Given two strings X and Y with respective lengths m and n , formed on an alphabet Σ and a constraint sequence C formed by ordered strings ( c 1 , c 2 , … , c l ) with total length r , the SSCLCS problem is to find the longest common subsequence D between X and Y such that D contains in an ordered way c 1 , c 2 , … , c l . To solve this problem, Tseng et al. proposed a dynamic-programming algorithm that runs in O m n r + ( m + n ) | Σ | time. We rely on this work to propose a parallel algorithm for the SSCLCS problem on the Coarse-Grained Multicomputer (CGM) model. We design a three-dimensional partitioning technique of the corresponding dependency graph to reduce the latency time of processors by ensuring that at each step, the size of the subproblems to be performed by processors is small. It also minimizes the number of communications between processors. Our solution requires O n m r + ( m + n ) | Σ | p execution time with O ( p ) communication rounds on p processors. The experimental results show that our solution speedups up to 59.7 on 64 processors. This is better than the CGM-based parallel techniques that have been used in solving similar problems.},
  archive      = {J_PARCO},
  author       = {Vianney Kengne Tchendji and Hermann Bogning Tepiele and Mathias Akong Onabid and Jean Frédéric Myoupo and Jerry Lacmou Zeutouo},
  doi          = {10.1016/j.parco.2022.102927},
  journal      = {Parallel Computing},
  pages        = {102927},
  shortjournal = {Parallel Comput.},
  title        = {A coarse-grained multicomputer parallel algorithm for the sequential substring constrained longest common subsequence problem},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). C-lop: Accurate contention-based modeling of MPI concurrent
communication. <em>PARCO</em>, <em>111</em>, 102925. (<a
href="https://doi.org/10.1016/j.parco.2022.102925">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {MPI communication optimization is a crucial stage to optimize high-performance applications. As a formal analysis of MPI communication, the communication performance models have made some achievements in improving the efficiency of collective algorithms and optimizing communication scheduling. However, previous models are difficult to model asynchronous concurrent communication and do not take into account numerous contention factors. In this paper, we present C -Lop, an incremental MPI performance model based on τ τ -Lop. Firstly, C -Lop proposes a method for asynchronous modeling of concurrent communication. As the only model that considers concurrent transmission, τ τ -Lop describes the cost of the all processes as a whole without distinguishing the cost of each process. Here, C -Lop uses the idea of asynchronous modeling that describe the cost of the system by averaging the communication cost per process. It can describe the communication cost for some systems with out-of-sync communication more accurately. Moreover, C -Lop introduces the parameter C to represent the contention, and considers the contention of concurrent transmissions on network-on-chip , data reuse , and contention of noncommunication processes to make a more accuracy estimation. Furthermore, parameter C can be customized to fit more application scenarios. In addition, we evaluate several common collective algorithms, a matrix multiplication algorithm (SUMMA), and two kinds of communication in a three-dimensional multi-grid application on the Tianhe-3 prototype, and results show that C -Lop outperforms the competition.},
  archive      = {J_PARCO},
  author       = {Ziheng Wang and Heng Chen and Weiling Cai and Xiaoshe Dong and Xingjun Zhang},
  doi          = {10.1016/j.parco.2022.102925},
  journal      = {Parallel Computing},
  pages        = {102925},
  shortjournal = {Parallel Comput.},
  title        = {C-lop: Accurate contention-based modeling of MPI concurrent communication},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimal ATAPE task scheduling on reconfigurable and
partitionable hierarchical hypercube networks. <em>PARCO</em>,
<em>111</em>, 102923. (<a
href="https://doi.org/10.1016/j.parco.2022.102923">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hierarchical hypercube (HHC) network ( N =2 n , n =2 m + m, m ≥2) is one of scalable networks for the large-scale parallel-computing systems since its implementation cost is lower than the popular hypercube (HC) network. However, the complicated HHC-routing may conflict (due to the reduction-of-edges in the hierarchical construction) and cannot be reconfigured simply for k &gt; 2 m nodes-per-task. Thus, a crucial research to fulfill the HHC-network is the conflict-free routing since the conflict is not handled easily during runtime. Recently, the HHC-conflict was solved by the shortest-path routing and the special HHC-partitioning, called the grouping-of-cross dual-cube (GCD) partitioning, for k =2 m +1 nodes-per-task. In this study, we propose the reconfigurable-and-partitionable HHC (RP-HHC) network for 2 m +2 ≤ k ≤ N /2 M -1 nodes-per-task ( M =2 m -1 ) by the grouping-of-cross sub-system (GCS) combining (the optimal reconfiguring). Moreover, we present the efficient task-scheduling and processor-allocation, incorporated with the reconfigured binary-tree. Since the first-fit policy is fast but returns low-performance while the best-fit policy yields high-performance but is time-consuming, we propose the efficient best-fit driven-policy to work as fast as the first-fit policy while maintaining the high-performance. The correctness of new reconfiguring and time-complexity of task-allocation were analyzed. In experiments, all-to-all personalized exchange (ATAPE) communication was assessed to confirm no-conflict on the RP-HHC systems.},
  archive      = {J_PARCO},
  author       = {Nuntipat Phisutthangkoon and Jeeraporn Werapun},
  doi          = {10.1016/j.parco.2022.102923},
  journal      = {Parallel Computing},
  pages        = {102923},
  shortjournal = {Parallel Comput.},
  title        = {Optimal ATAPE task scheduling on reconfigurable and partitionable hierarchical hypercube networks},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spatial- and time- division multiplexing in CNN accelerator.
<em>PARCO</em>, <em>111</em>, 102922. (<a
href="https://doi.org/10.1016/j.parco.2022.102922">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread use of real-time data analysis by artificial intelligence (AI), the integration of accelerators is attracting attention from the perspectives of their low power consumption and low latency. The objective of this research is to increase accelerator resource efficiency and further reduce power consumption by sharing accelerators among multiple users while maintaining real-time performance. To achieve the accelerator-sharing system, we define three requirements: high device utilization, fair device utilization among users, and real-time performance. Targeting the AI inference use case, this paper proposes a system that shares a field-programmable gate array (FPGA) among multiple users by switching the convolutional neural network (CNN) models stored in the device memory on the FPGA, while satisfying the three requirements. The proposed system uses different behavioral models for workloads with predictable and unpredictable data arrival timing. For the workloads with predictable data arrival timing, the system uses spatial-division multiplexing of the FPGA device memory to achieve real-time performance and high device utilization. Specifically, the FPGA device memory controller of the system transparently preloads and caches the CNN models into the FPGA device memory before the data arrival. For workloads with unpredictable data arrival timing, the system transfers CNN models to the FPGA device memory upon data arrival using time-division multiplexing of FPGA device memory. In the latter case of unpredictable workloads, the switch cost between CNN models is non-negligible to achieve real-time performance and high device utilization, so the system integrates a new scheduling algorithm that considers the switch time of the CNN models. For both predictable and unpredictable workloads, user fairness is achieved by using an ageing technique in the scheduling algorithm that increases the priority of jobs in accordance with the job waiting time. The evaluation results show that the scheduling overhead of the proposed system is negligible for both predictable and unpredictable workloads providing practical real-time performance. For unpredictable workloads, the new scheduling algorithm improves fairness by 24\%–94\% and resource efficiency by 31\%–33\% compared to traditional algorithms using first-come first-served or round-robin. For predictable workloads, the system improves fairness by 50.5\% compared to first-come first-served and achieves 99.5\% resource efficiency.},
  archive      = {J_PARCO},
  author       = {Tetsuro Nakamura and Shogo Saito and Kei Fujimoto and Masashi Kaneko and Akinori Shiraga},
  doi          = {10.1016/j.parco.2022.102922},
  journal      = {Parallel Computing},
  pages        = {102922},
  shortjournal = {Parallel Comput.},
  title        = {Spatial- and time- division multiplexing in CNN accelerator},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards electronic structure-based ab-initio molecular
dynamics simulations with hundreds of millions of atoms. <em>PARCO</em>,
<em>111</em>, 102920. (<a
href="https://doi.org/10.1016/j.parco.2022.102920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We push the boundaries of electronic structure-based ab-initio molecular dynamics (AIMD) beyond 100 million atoms. This scale is otherwise barely reachable with classical force-field methods or novel neural network and machine learning potentials. We achieve this breakthrough by combining innovations in linear-scaling AIMD, efficient and approximate sparse linear algebra, low and mixed-precision floating-point computation on GPUs, and a compensation scheme for the errors introduced by numerical approximations. The core of our work is the non-orthogonalized local submatrix method (NOLSM), which scales very favorably to massively parallel computing systems and translates large sparse matrix operations into highly parallel, dense matrix operations that are ideally suited to hardware accelerators. We demonstrate that the NOLSM method, which is at the center point of each AIMD step, is able to achieve a sustained performance of 324 PFLOP/s in mixed FP16/FP32 precision corresponding to an efficiency of 67.7\% when running on 1536 NVIDIA A100 GPUs.},
  archive      = {J_PARCO},
  author       = {Robert Schade and Tobias Kenter and Hossam Elgabarty and Michael Lass and Ole Schütt and Alfio Lazzaro and Hans Pabst and Stephan Mohr and Jürg Hutter and Thomas D. Kühne and Christian Plessl},
  doi          = {10.1016/j.parco.2022.102920},
  journal      = {Parallel Computing},
  pages        = {102920},
  shortjournal = {Parallel Comput.},
  title        = {Towards electronic structure-based ab-initio molecular dynamics simulations with hundreds of millions of atoms},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Building a novel physical design of a distributed big data
warehouse over a hadoop cluster to enhance OLAP cube query performance.
<em>PARCO</em>, <em>111</em>, 102918. (<a
href="https://doi.org/10.1016/j.parco.2022.102918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving OLAP (Online Analytical Processing) query performance in a distributed system on top of Hadoop is a challenging task. An OLAP Cube query comprises several relational operations, such as selection, join, and group-by aggregation. It is well-known that star join and group-by aggregation are the most costly operations in a Hadoop database system. These operations indeed increase network traffic and may overflow memory; to overcome these difficulties, numerous partitioning and data load balancing techniques have been proposed in the literature. However, some issues remain questionable, such as decreasing the Spark stages and the network I/O for an OLAP query being executed on a distributed system. In a precedent work, we proposed a novel data placement strategy for a big data warehouse over a Hadoop cluster. This data warehouse schema enhances the projection, selection, and star-join operations of an OLAP query, such that the system’s query-optimizer can perform a star join process locally, in only one spark stage without a shuffle phase. Also, the system can skip loading unnecessary data blocks when executing the predicates. In this paper, we extend our previous work with further technical details and experiments, and we propose a new dynamic approach to improve the group-by aggregation. To evaluate our approach, we conduct some experiments on a cluster with 15 nodes. Experimental results show that our method outperforms existing approaches in terms of OLAP query evaluation time.},
  archive      = {J_PARCO},
  author       = {Yassine Ramdane and Omar Boussaid and Doulkifli Boukraà and Nadia Kabachi and Fadila Bentayeb},
  doi          = {10.1016/j.parco.2022.102918},
  journal      = {Parallel Computing},
  pages        = {102918},
  shortjournal = {Parallel Comput.},
  title        = {Building a novel physical design of a distributed big data warehouse over a hadoop cluster to enhance OLAP cube query performance},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Metall: A persistent memory allocator for data-centric
analytics. <em>PARCO</em>, <em>111</em>, 102905. (<a
href="https://doi.org/10.1016/j.parco.2022.102905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data analytics applications transform raw input data into analytics-specific data structures before performing analytics. Unfortunately, such data ingestion steps are often more expensive than analytics. In addition, various types of NVRAM devices are already used in many HPC systems today. Such devices will be useful for storing and reusing data structures beyond a single process life cycle . We developed Metall, a persistent memory allocator built on top of the memory-mapped file mechanism. Metall enables applications to transparently allocate custom C++ data structures into various types of persistent memories. Metall incorporates a concise and high-performance memory management algorithm inspired by Supermalloc and the rich C++ interface developed by Boost.Interprocess library. On a dynamic graph construction workload, Metall achieved up to 11.7x and 48.3x performance improvements over Boost.Interprocess and memkind (PMEM kind), respectively. We also demonstrate Metall’s high adaptability by integrating Metall into a graph processing framework, GraphBLAS Template Library. This study’s outcomes indicate that Metall will be a strong tool for accelerating future large-scale data analytics by allowing applications to leverage persistent memory efficiently.},
  archive      = {J_PARCO},
  author       = {Keita Iwabuchi and Karim Youssef and Kaushik Velusamy and Maya Gokhale and Roger Pearce},
  doi          = {10.1016/j.parco.2022.102905},
  journal      = {Parallel Computing},
  pages        = {102905},
  shortjournal = {Parallel Comput.},
  title        = {Metall: A persistent memory allocator for data-centric analytics},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Scalable communication for high-order stencil computations
using CUDA-aware MPI. <em>PARCO</em>, <em>111</em>, 102904. (<a
href="https://doi.org/10.1016/j.parco.2022.102904">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern compute nodes in high-performance computing provide a tremendous level of parallelism and processing power. However, as arithmetic performance has been observed to increase at a faster rate relative to memory and network bandwidths, optimizing data movement has become critical for achieving strong scaling in many communication-heavy applications. This performance gap has been further accentuated with the introduction of graphics processing units, which can provide by multiple factors higher throughput in data-parallel tasks than central processing units. In this work, we explore the computational aspects of iterative stencil loops and implement a generic communication scheme using CUDA-aware MPI, which we use to accelerate magnetohydrodynamics simulations based on high-order finite differences and third-order Runge–Kutta integration. We put particular focus on improving intra-node locality of workloads. Our GPU implementation scales strongly from one to 64 devices at 50\%–87\% of the expected efficiency based on a theoretical performance model. Compared with a multi-core CPU solver, our implementation exhibits 20– 60 × 60× speedup and 9– 12 × 12× improved energy efficiency in compute-bound benchmarks on 16 nodes.},
  archive      = {J_PARCO},
  author       = {Johannes Pekkilä and Miikka S. Väisälä and Maarit J. Käpylä and Matthias Rheinhardt and Oskar Lappi},
  doi          = {10.1016/j.parco.2022.102904},
  journal      = {Parallel Computing},
  pages        = {102904},
  shortjournal = {Parallel Comput.},
  title        = {Scalable communication for high-order stencil computations using CUDA-aware MPI},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ginkgo—a math library designed for platform portability.
<em>PARCO</em>, <em>111</em>, 102902. (<a
href="https://doi.org/10.1016/j.parco.2022.102902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an era of increasing computer system diversity, the portability of software from one system to another plays a central role. Software portability is important for the software developers as many software projects have a lifetime longer than a specific system, e.g., a supercomputer , and it is important for the domain scientists that realize their scientific application in a software framework and want to be able to run on one or another system. On a high level, there exist two approaches for realizing platform portability: (1) implementing software using a portability layer leveraging any technique which always generates specific kernels from another language or through an interface for running on different architectures; and (2) providing backends for different hardware architectures, with the backends typically differing in how and in which programming language functionality is realized due to using the language of choice for each hardware (e.g., CUDA kernels for NVIDIA GPUs , SYCL (DPC++) kernels to targeting Intel GPUs and other supported hardware, …). In practice, these two approaches can be combined in applications to leverage their respective strengths. In this paper, we present how we realize portability across different hardware architectures for the Ginkgo library by following the second strategy and the goal to not only port to new hardware architectures but also achieve good performance. We present the Ginkgo library design, separating algorithms from hardware-specific kernels forming the distinct hardware executors, and report our experience when adding execution backends for NVIDIA, AMD, and Intel GPUs. We also present the performance we achieve with this approach for distinct hardware backends.},
  archive      = {J_PARCO},
  author       = {Terry Cojean and Yu-Hsiang Mike Tsai and Hartwig Anzt},
  doi          = {10.1016/j.parco.2022.102902},
  journal      = {Parallel Computing},
  pages        = {102902},
  shortjournal = {Parallel Comput.},
  title        = {Ginkgo—A math library designed for platform portability},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reconfiguration algorithms for synchronous communication on
switch based degradable arrays. <em>PARCO</em>, <em>111</em>, 102901.
(<a href="https://doi.org/10.1016/j.parco.2022.102901">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synchronous communication is one of the most important issues in high performance architectures for large scale of parallel computing , such as matrix computing, image processing , etc. Mesh-connected processor array is characteristic of synchronous communication due to the same length of the interconnects between the neighboring processing elements (PEs) in rows/columns. But long interconnects caused by faulty PEs clearly impact the synchronous communication between the adjacent rows/columns. If long interconnects exist between two adjacent rows, we say that a synchronous communication delay is caused. This paper contributes algorithms to construct logical arrays with synchronous communication in a given host array. Specifically, an algorithm for synchronous communication array ( ASCA ) is firstly presented, to construct a maximum logical array with synchronous communication. When all of the long interconnects are independent each other, the proposed algorithm is proved to be optimal. After that, two heuristic algorithms are also proposed, to construct a logical array with given size, by integrating the proposed ASCA and two exclusion schemes. The proposed two exclusion schemes are based on strategies of divide-and-conquer and the longest logical column first, respectively. In addition, the lower bound of synchronous communication delay for a logical array is calculated by an algorithm also developed in this paper, in order to evaluate the synchronous performance of reconfiguration algorithms . Simulation results show that, the proposed two heuristic algorithms have their own advantages for different cases. The synchronous communication delay of the logical arrays is significantly reduced, and it is very close to the lower bound for the cases of small fault density and larger exclusion rate. For 32 × 32 physical arrays with exclusion rates that are larger than 15\%, the synchronous communication delay of logical array is reduced from 11.09 to 6.97, which is more closer to the lower bound 4.43, for different fault densities on average.},
  archive      = {J_PARCO},
  author       = {Yalan Wu and Jigang Wu and Peng Liu and Yinhe Han and Thambipillai Srikanthan},
  doi          = {10.1016/j.parco.2022.102901},
  journal      = {Parallel Computing},
  pages        = {102901},
  shortjournal = {Parallel Comput.},
  title        = {Reconfiguration algorithms for synchronous communication on switch based degradable arrays},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Task-parallel tiled direct solver for dense symmetric
indefinite systems. <em>PARCO</em>, <em>111</em>, 102900. (<a
href="https://doi.org/10.1016/j.parco.2022.102900">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a direct solver for symmetric indefinite linear systems. The program is parallelized via the OpenMP task construct and outperforms existing programs. The proposed solver avoids pivoting, which requires a lot of data movement, during factorization with preconditioning using the symmetric random butterfly transformation. The matrix data layout is tiled after the preconditioning to more efficiently use cache memory during factorization. Given the low-rank property of the input matrices, an adaptive crossing approximation is used to make a low-rank approximation before the update step to reduce the computation load. Iterative refinement is then used to improve the accuracy of the final result. Finally, the performance of the proposed solver is compared to that of various symmetric indefinite linear system solvers to show its superiority.},
  archive      = {J_PARCO},
  author       = {Zhongyu Shen and Jilin Zhang and Tomohiro Suzuki},
  doi          = {10.1016/j.parco.2022.102900},
  journal      = {Parallel Computing},
  pages        = {102900},
  shortjournal = {Parallel Comput.},
  title        = {Task-parallel tiled direct solver for dense symmetric indefinite systems},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards scaling community detection on distributed-memory
heterogeneous systems. <em>PARCO</em>, <em>111</em>, 102898. (<a
href="https://doi.org/10.1016/j.parco.2022.102898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In most real-world networks, nodes/vertices tend to be organized into tightly-knit modules known as communities or clusters such that nodes within a community are more likely to be connected or related to one another than they are to the rest of the network. Community detection in a network (graph) is aimed at finding a partitioning of the vertices into communities. The goodness of the partitioning is commonly measured using modularity . Maximizing modularity is an NP-complete problem. In 2008, Blondel et al. introduced a multi-phase, multi-iteration heuristic for modularity maximization called the Louvain method. Owing to its speed and ability to yield high quality communities, the Louvain method continues to be one of the most widely used tools for serial community detection. Distributed multi-GPU systems pose significant challenges and opportunities for efficient execution of parallel applications. Graph algorithms , in particular, have been known to be harder to parallelize on such platforms, due to irregular memory accesses, low computation to communication ratios, and load balancing problems that are especially hard to address on multi-GPU systems. In this paper, we present our ongoing work on distributed-memory implementation of Louvain method on heterogeneous systems . We build on our prior work parallelizing the Louvain method for community detection on traditional CPU-only distributed systems without GPUs. Corroborated by an extensive set of experiments on multi-GPU systems, we demonstrate competitive performance to existing distributed-memory CPU-based implementation, up to 3.2 × × speedup using 16 nodes of OLCF Summit relative to two nodes, and up to 19 × × speedup relative to the NVIDIA RAPIDS® cuGraph ® implementation on a single NVIDIA V100 GPU from DGX-2 platform, while achieving high quality solutions comparable to the original Louvain method. To the best of our knowledge, this work represents the first effort for community detection on distributed multi-GPU systems. Our approach and related findings can be extended to numerous other iterative graph algorithms on multi-GPU systems.},
  archive      = {J_PARCO},
  author       = {Nitin Gawande and Sayan Ghosh and Mahantesh Halappanavar and Antonino Tumeo and Ananth Kalyanaraman},
  doi          = {10.1016/j.parco.2022.102898},
  journal      = {Parallel Computing},
  pages        = {102898},
  shortjournal = {Parallel Comput.},
  title        = {Towards scaling community detection on distributed-memory heterogeneous systems},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). OpenACC + athread collaborative optimization of
silicon-crystal application on sunway TaihuLight. <em>PARCO</em>,
<em>111</em>, 102893. (<a
href="https://doi.org/10.1016/j.parco.2022.102893">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Silicon-Crystal application based on molecular dynamics (MD) is used to simulate the thermal conductivity of the crystal, which adopts the Tersoff potential to simulate the trajectory of the silicon crystal. Based on the OpenACC version, to better solve the problem of discrete memory access and write dependency, task pipeline optimization and the interval graph coloring scheduling method are proposed. Also, the part of codes on CPEs is vectorized by the SIMD command to further improve the computational performance. After the collaborative development of OpenACC+Athread, the performance has been improved by 16.68 times and achieves 2.34X speedup compared with the OpenACC version. Moreover, the application is expanded to 66,560 cores and can simulate reactions of 268,435,456 silicon atoms .},
  archive      = {J_PARCO},
  author       = {Jianguo Liang and Rong Hua and Wenqiang Zhu and Yuxi Ye and You Fu and Hao Zhang},
  doi          = {10.1016/j.parco.2022.102893},
  journal      = {Parallel Computing},
  pages        = {102893},
  shortjournal = {Parallel Comput.},
  title        = {OpenACC + athread collaborative optimization of silicon-crystal application on sunway TaihuLight},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Special issue of selected papers from EuroMPI/USA 2020.
<em>PARCO</em>, <em>111</em>, 102875. (<a
href="https://doi.org/10.1016/j.parco.2021.102875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_PARCO},
  doi          = {10.1016/j.parco.2021.102875},
  journal      = {Parallel Computing},
  pages        = {102875},
  shortjournal = {Parallel Comput.},
  title        = {Special issue of selected papers from EuroMPI/USA 2020},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Linear solvers for power grid optimization problems: A
review of GPU-accelerated linear solvers. <em>PARCO</em>, <em>111</em>,
102870. (<a href="https://doi.org/10.1016/j.parco.2021.102870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The linear equations that arise in interior methods for constrained optimization are sparse symmetric indefinite, and they become extremely ill-conditioned as the interior method converges. These linear systems present a challenge for existing solver frameworks based on sparse LU or LDL T LDLT decompositions. We benchmark five well known direct linear solver packages on CPU- and GPU-based hardware, using matrices extracted from power grid optimization problems . The achieved solution accuracy varies greatly among the packages. None of the tested packages delivers significant GPU acceleration for our test cases. For completeness of the comparison we include results for MA57, which is one of the most efficient and reliable CPU solvers for this class of problem.},
  archive      = {J_PARCO},
  author       = {Kasia Świrydowicz and Eric Darve and Wesley Jones and Jonathan Maack and Shaked Regev and Michael A. Saunders and Stephen J. Thomas and Slaven Peleš},
  doi          = {10.1016/j.parco.2021.102870},
  journal      = {Parallel Computing},
  pages        = {102870},
  shortjournal = {Parallel Comput.},
  title        = {Linear solvers for power grid optimization problems: A review of GPU-accelerated linear solvers},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). High performance sparse multifrontal solvers on modern GPUs.
<em>PARCO</em>, <em>110</em>, 102897. (<a
href="https://doi.org/10.1016/j.parco.2022.102897">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We have ported the numerical factorization and triangular solve phases of the sparse direct solver STRUMPACK to GPU . STRUMPACK implements sparse LU factorization using the multifrontal algorithm, which performs most of its operations in dense linear algebra operations on so-called frontal matrices of various sizes. Our GPU implementation off-loads these dense linear algebra operations, as well as the sparse scatter–gather operations between frontal matrices. For the larger frontal matrices, our GPU implementation relies on vendor libraries such as cuBLAS and cuSOLVER for NVIDIA GPUs and rocBLAS and rocSOLVER for AMD GPUs. For the smaller frontal matrices we developed custom CUDA and HIP kernels to reduce kernel launch overhead. Overall, high performance is achieved by identifying submatrix factorizations corresponding to sub-trees of the multifrontal assembly tree which fit entirely in GPU memory. The multi-GPU setting uses SLATE (Software for Linear Algebra Targeting Exascale) as a modern GPU-aware replacement for ScaLAPACK. On 4 nodes of SUMMIT the code runs ∼ 10 × ∼10× faster when using all 24 V100 GPUs compared to when it only uses the 168 POWER9 cores. On 8 SUMMIT nodes, using 48 V100 GPUs, the sparse solver reaches over 50TFlop/s. Compared to SuperLU, on a single V100, for a set of 17 matrices our implementation is faster for all but one matrix, and is on average 5 × 5× (median 4 × 4× ) faster},
  archive      = {J_PARCO},
  author       = {Pieter Ghysels and Ryan Synk},
  doi          = {10.1016/j.parco.2022.102897},
  journal      = {Parallel Computing},
  pages        = {102897},
  shortjournal = {Parallel Comput.},
  title        = {High performance sparse multifrontal solvers on modern GPUs},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parallel graph coloring algorithms for distributed GPU
environments. <em>PARCO</em>, <em>110</em>, 102896. (<a
href="https://doi.org/10.1016/j.parco.2022.102896">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph coloring is often used in parallelizing scientific computations that run in distributed and multi-GPU environments; it identifies sets of independent data that can be updated in parallel. Many algorithms exist for graph coloring on a single GPU or in distributed memory, but to the best of our knowledge, hybrid MPI+GPU algorithms have been unexplored until this work. We present several MPI+GPU coloring approaches based on the distributed coloring algorithms of Gebremedhin et al. and the shared-memory algorithms of Deveci et al. The on-node parallel coloring uses implementations in KokkosKernels, which provide parallelization for both multicore CPUs and GPUs. We further extend our approaches to compute distance-2 and partial distance-2 colorings, giving the first known distributed, multi-GPU algorithm for these problems. In addition, we propose a novel heuristic to reduce communication for recoloring in distributed graph coloring. Our experiments show that our approaches operate efficiently on inputs too large to fit on a single GPU and scale up to graphs with 76.7 billion edges running on 128 GPUs.},
  archive      = {J_PARCO},
  author       = {Ian Bogle and George M. Slota and Erik G. Boman and Karen D. Devine and Sivasankaran Rajamanickam},
  doi          = {10.1016/j.parco.2022.102896},
  journal      = {Parallel Computing},
  pages        = {102896},
  shortjournal = {Parallel Comput.},
  title        = {Parallel graph coloring algorithms for distributed GPU environments},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Compiler-assisted, adaptive runtime system for the support
of OpenMP in embedded multicores. <em>PARCO</em>, <em>110</em>, 102895.
(<a href="https://doi.org/10.1016/j.parco.2022.102895">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The latest versions of OpenMP have introduced constructs for exploiting heterogeneous compute units alongside the main multicore cpu . The offloaded program portions (kernels) may generate parallelism within the target device by employing standard OpenMP constructs. However co-processors, especially embedded ones, often have limited resources to provide efficient OpenMP support. Designing an OpenMP infrastructure for such devices is a challenge and a usual design decision is to support OpenMP only partially. In this work, we present a novel solution to this problem. We propose a compiler-assisted, adaptive runtime system organization, which generates application-specific support by implementing only the OpenMP functionality required each time. Full OpenMP support is available if needed. However, in the usual scenario where kernels do not require complex OpenMP functionalities, our method can lead to dramatically reduced executable sizes, which usually offer additional performance benefits. The mechanism is based on preparatory compile-time kernel analysis which generates metrics regarding the OpenMP functionality present in each kernel. These are then fed to a mapper module which, given a set of rules, decides what the optimal runtime configuration is. Our proposal is demonstrated by a complete implementation on the popular Parallella-16 board, exhibiting consistently large size savings and significant performance gains.},
  archive      = {J_PARCO},
  author       = {Spiros N. Agathos and Vassilios V. Dimakopoulos and Ilias K. Kasmeridis},
  doi          = {10.1016/j.parco.2022.102895},
  journal      = {Parallel Computing},
  pages        = {102895},
  shortjournal = {Parallel Comput.},
  title        = {Compiler-assisted, adaptive runtime system for the support of OpenMP in embedded multicores},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tight lower bound on power consumption for scheduling
real-time periodic tasks in core-level DVFS systems. <em>PARCO</em>,
<em>110</em>, 102892. (<a
href="https://doi.org/10.1016/j.parco.2022.102892">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic voltage and frequency scaling (DVFS) is a widely used solution to reduce power consumption . Modern multi-core architectures support core-level DVFS, where each core has its own power supply and can change its frequency independently from other cores. This paper aims at optimizing power consumption of multi-core processors while ensuring deadline constraints of real-time periodic tasks. From theoretical aspects, we prove a tight lower bound of power consumption for executing real-time tasks, which indicates to what extent scheduling algorithms can approach. From practical aspects, we propose a Power Scaling Algorithm (PSA) to assign real-time periodic tasks to a power efficient platform. PSA not only determines the optimal frequencies for each core, but also provides the appropriate number of active cores, which can skip the local optimum and achieve the global minimum. This lower power bound is validated by several extensive experiments.},
  archive      = {J_PARCO},
  author       = {Fei Teng and Lei Yu and Xiao Liu and Pei Lai},
  doi          = {10.1016/j.parco.2022.102892},
  journal      = {Parallel Computing},
  pages        = {102892},
  shortjournal = {Parallel Comput.},
  title        = {Tight lower bound on power consumption for scheduling real-time periodic tasks in core-level DVFS systems},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An evaluation of fast segmented sorting implementations on
GPUs. <em>PARCO</em>, <em>110</em>, 102889. (<a
href="https://doi.org/10.1016/j.parco.2021.102889">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world problems require a sorting operation as part of their efficient solution. Some examples of this are real-time plasma diagnostic , image re-ranking, and suffix array construction. These problems usually involve a large amount of data, so their solutions need a particular application of the sorting procedure, consisting of sorting several arrays in matrix rows or array segments, an operation called segmented sorting. Previous studies showed that a merge sort-based strategy and a strategy called fix sort executed this operation on GPUs with good performance for different array sizes. In this work, we compare the fastest segmented sorting GPU implementations on seven different GPU models with various input data scenarios, including scenarios with varying numbers of segments, segment sizes, and considering segments of the same and different sizes. We first performed algorithm analysis to explain how the number of segments affects each implementation’s performance. Then, we perform an S-curve analysis and observe that, even though each strategy might be the fastest option for a subset of the sorting scenarios, some approaches may cause very high slowdowns on specific scenarios. We also compare the strategies using heat maps , show that their performance depends on the array size and number of segments, and propose a recommendation map to support selecting the best overall implementation based on the size and number of segments. Our experimental results show that choosing a strategy based on our recommendation map leads to the best strategy on 47.57\% of the cases and a maximum slowdown of less than 1.5 times in 93.58\% of the cases. Moreover, on average, the recommended strategy is only 1.11 × × worse than the optimum one. Finally, we evaluated how each strategy behaves when sorting arrays with different and equal segment sizes and showed that the fix sort-based approaches take roughly the same time to sort arrays with equal or different segment sizes, while the approach proposed by Hou et al. usually takes longer to sort arrays with different segment sizes than arrays with equal segment sizes.},
  archive      = {J_PARCO},
  author       = {Rafael F. Schmid and Flávia Pisani and Edson N. Cáceres and Edson Borin},
  doi          = {10.1016/j.parco.2021.102889},
  journal      = {Parallel Computing},
  pages        = {102889},
  shortjournal = {Parallel Comput.},
  title        = {An evaluation of fast segmented sorting implementations on GPUs},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Octopus-DF: Unified DataFrame-based cross-platform data
analytic system. <em>PARCO</em>, <em>110</em>, 102879. (<a
href="https://doi.org/10.1016/j.parco.2021.102879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, DataFrame serves as a core to model and implement numerous machine learning and data analytic algorithms. Traditional data analytic programming languages , such as Python, provide the DataFrame programming model natively. In the big data era, it is a natural demand to introduce the DataFrame model into distributed computing systems for convenient big data analysis . Therefore, various DataFrame libraries have been implemented on Spark and Dask. However, these distributed computing systems contain some parallelism semantics which are not very straightforward for data analysts. Also, a DataFrame-based algorithm may have quite different performance for various datasets over different platforms. And, it is difficult for data analysts to choose the optimal platforms that achieve the best performance for their programs. To address these problems, we build a unified DataFrame-based data analytic system Octopus-DF. Octopus-DF integrates Pandas, Dask, and Spark as the backend computing platforms and exposes the most widely used Pandas-style APIs to users. Then, as DataFrame computation performance plays a critical role in the computing efficiency of DataFrame-based data analytic algorithms, we designed a set of DataFrame computation optimizations which are divided into two parts: (1) multiple indexing and DAG optimizations, and (2) cross-platform scheduling strategy. Experimental results show that Octopus-DF outperformed the existing single platforms with 11.72 × × speedup on average. Compared with the existing platform combination strategies, Octopus-DF can achieve the optimal one. Moreover, the proposed optimizations can effectively speedup the execution workflow .},
  archive      = {J_PARCO},
  author       = {Rong Gu and Jun Shi and Xiaofei Chen and Zhaokang Wang and Yang Che and Kai Zhang and Yihua Huang},
  doi          = {10.1016/j.parco.2021.102879},
  journal      = {Parallel Computing},
  pages        = {102879},
  shortjournal = {Parallel Comput.},
  title        = {Octopus-DF: Unified DataFrame-based cross-platform data analytic system},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A case study on parallel HDF5 dataset concatenation for high
energy physics data analysis. <em>PARCO</em>, <em>110</em>, 102877. (<a
href="https://doi.org/10.1016/j.parco.2021.102877">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In High Energy Physics (HEP), experimentalists generate large volumes of data that, when analyzed, helps us better understand the fundamental particles and their interactions. This data is often captured in many files of small size, creating a data management challenge for scientists. In order to better facilitate data management, transfer, and analysis on large scale platforms, it is advantageous to aggregate data further into a smaller number of larger files. However, this translation process can consume significant time and resources, and if performed incorrectly the resulting aggregated files can be inefficient for highly parallel access during analysis on large scale platforms. In this paper, we present our case study on parallel I/O strategies and HDF5 features for reducing data aggregation time, making effective use of compression, and ensuring efficient access to the resulting data during analysis at scale. We focus on NOvA detector data in this case study, a large-scale HEP experiment generating many terabytes of data. The lessons learned from our case study inform the handling of similar datasets, thus expanding community knowledge related to this common data management task.},
  archive      = {J_PARCO},
  author       = {Sunwoo Lee and Kai-yuan Hou and Kewei Wang and Saba Sehrish and Marc Paterno and James Kowalkowski and Quincey Koziol and Robert B. Ross and Ankit Agrawal and Alok Choudhary and Wei-keng Liao},
  doi          = {10.1016/j.parco.2021.102877},
  journal      = {Parallel Computing},
  pages        = {102877},
  shortjournal = {Parallel Comput.},
  title        = {A case study on parallel HDF5 dataset concatenation for high energy physics data analysis},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Accelerating domain propagation: An efficient GPU-parallel
algorithm over sparse matrices. <em>PARCO</em>, <em>109</em>, 102874.
(<a href="https://doi.org/10.1016/j.parco.2021.102874">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_PARCO},
  author       = {Boro Sofranac and Ambros Gleixner and Sebastian Pokutta},
  doi          = {10.1016/j.parco.2021.102874},
  journal      = {Parallel Computing},
  pages        = {102874},
  shortjournal = {Parallel Comput.},
  title        = {Accelerating domain propagation: An efficient GPU-parallel algorithm over sparse matrices},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The BondMachine, a moldable computer architecture.
<em>PARCO</em>, <em>109</em>, 102873. (<a
href="https://doi.org/10.1016/j.parco.2021.102873">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Future systems will be characterized by the presence of many computing core in a single device, on large scale data centers or even at the level of IoT devices. The ability to fully exploit computational architectures’ heterogeneity and concurrency will be a key point. In this manuscript we present the BondMachine (BM), an innovative prototype software ecosystem aimed at creating facilities where hardware and software are co-designed, guaranteeing a full exploitation of fabric capabilities (both in terms of concurrency and heterogeneity) with several hardware optimization possibilities. The fundamental innovation of the BM is to provide a new kind of computer architecture , where the hardware dynamically adapts to the specific computational problem rather than being static and generic, as in standard CPUs synthesized in silicon . Hardware can be designed to fit precisely any computational task needs, implementing only the processing units needed and discarding generic solutions. By using BMs within FPGA technologies end-to-end solutions could be realized, in which the creation of domain-specific hardware is part of the development process as much as the software stack. FPGA technology allows to create independent processing units on a single low-power board, and to design their interconnections “in silicon” to maximally fit the design needs. The processors of the BMs are suitable for computational structures like neural networks and tensor processing models. Machine Learning (ML) and Deep Learning (DL) popularity keeps increasing in scientific and industrial areas.},
  archive      = {J_PARCO},
  author       = {Mirko Mariotti and Daniel Magalotti and Daniele Spiga and Loriano Storchi},
  doi          = {10.1016/j.parco.2021.102873},
  journal      = {Parallel Computing},
  pages        = {102873},
  shortjournal = {Parallel Comput.},
  title        = {The BondMachine, a moldable computer architecture},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Using long vector extensions for MPI reductions.
<em>PARCO</em>, <em>109</em>, 102871. (<a
href="https://doi.org/10.1016/j.parco.2021.102871">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The modern CPU’s design, including the deep memory hierarchies and SIMD/vectorization capability have a more significant impact on algorithms’ efficiency than the modest frequency increase observed recently. The current introduction of wide vector instruction set extensions (AVX and SVE) motivated vectorization to become a critical software component to increase efficiency and close the gap to peak performance. In this paper, we investigate the impact of the vectorization of MPI reduction operations. We propose an implementation of predefined MPI reduction operations using vector intrinsics (AVX and SVE) to improve the time-to-solution of the predefined MPI reduction operations. The evaluation of the resulting software stack under different scenarios demonstrates that the approach is not only efficient but also generalizable to many vector architectures. Experiments conducted on varied architectures (Intel Xeon Gold, AMD Zen 2, and Arm A64FX), show that the proposed vector extension optimized reduction operations significantly reduce completion time for collective communication reductions. With these optimizations, we achieve higher memory bandwidth and an increased efficiency for local computations, which directly benefit the overall cost of collective reductions and applications based on them.},
  archive      = {J_PARCO},
  author       = {Dong Zhong and Qinglei Cao and George Bosilca and Jack Dongarra},
  doi          = {10.1016/j.parco.2021.102871},
  journal      = {Parallel Computing},
  pages        = {102871},
  shortjournal = {Parallel Comput.},
  title        = {Using long vector extensions for MPI reductions},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reducing queuing impact in streaming applications with
irregular dataflow. <em>PARCO</em>, <em>109</em>, 102863. (<a
href="https://doi.org/10.1016/j.parco.2021.102863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Throughput-oriented streaming applications on massive data sets are a prime candidate for parallelization on wide-SIMD platforms, especially when inputs are independent of one another. Many such applications are represented as a pipeline of compute nodes connected by directed edges. Here, we study applications with irregular dataflow, i.e., those where the number of outputs produced per input to a node is data-dependent and unknown a priori . We consider how to implement such applications on wide-SIMD architectures, such as GPUs, where different nodes of the pipeline execute cooperatively on a single processor. To promote greater SIMD parallelism, irregular application pipelines can utilize queues to gather and compact multiple data items between nodes. However, the decision to introduce a queue between two nodes must trade off benefits to occupancy against costs associated with managing the queue and scheduling the nodes at its endpoints. Moreover, once queues are introduced to an application, their relative sizes impact the frequency with which the application switches between nodes, incurring scheduling and context-switching overhead. This work examines two optimization problems associated with queues. First, given a pipeline with queues between each two nodes and a fixed total budget for queue space, we consider how to choose the relative sizes of inter-node queues to minimize the frequency of switching between nodes. Second, we consider which pairs of successive nodes in a pipeline should have queues between them to maximize overall application throughput. We give an empirically useful approximation to the first problem that allows for an analytical solution and formulate a performance model for the second that directs implementation toward higher-performing strategies. We implemented our analyses and resulting optimizations in applications built using Mercator, a framework we designed to support irregular streaming applications on NVIDIA GPUs. We demonstrate that these optimizations yield meaningful performance improvements for several benchmark Mercator applications.},
  archive      = {J_PARCO},
  author       = {Stephen Timcheck and Jeremy Buhler},
  doi          = {10.1016/j.parco.2021.102863},
  journal      = {Parallel Computing},
  pages        = {102863},
  shortjournal = {Parallel Comput.},
  title        = {Reducing queuing impact in streaming applications with irregular dataflow},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Benchmarking the performance of irregular computations in
AutoDock-GPU molecular docking. <em>PARCO</em>, <em>109</em>, 102861.
(<a href="https://doi.org/10.1016/j.parco.2021.102861">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Irregular applications can be found in different scientific fields. In computer-aided drug design, molecular docking simulations play an important role in finding promising drug candidates. AutoDock is a software application widely used for predicting molecular interactions at close distances. It is characterized by irregular computations and long execution runtimes. In recent years, a hardware-accelerated version of AutoDock , called AutoDock-GPU , has been under active development. This work benchmarks the recent code and algorithmic enhancements incorporated into AutoDock-GPU . Particularly, we analyze the impact on execution runtime of techniques based on early termination. These enable AutoDock-GPU to explore the molecular space as necessary, while safely avoiding redundant computations. Our results indicate that it is possible to achieve average runtime reductions of 50\% by using these techniques. Furthermore, a comprehensive literature review is also provided, where our work is compared to relevant approaches leveraging hardware acceleration for molecular docking.},
  archive      = {J_PARCO},
  author       = {Leonardo Solis-Vasquez and Andreas F. Tillack and Diogo Santos-Martins and Andreas Koch and Scott LeGrand and Stefano Forli},
  doi          = {10.1016/j.parco.2021.102861},
  journal      = {Parallel Computing},
  pages        = {102861},
  shortjournal = {Parallel Comput.},
  title        = {Benchmarking the performance of irregular computations in AutoDock-GPU molecular docking},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards leveraging collective performance with the support
of MPI 4.0 features in MPC. <em>PARCO</em>, <em>109</em>, 102860. (<a
href="https://doi.org/10.1016/j.parco.2021.102860">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Persistent collective communications and communicator splitting according to the underlying hardware topology have recently been voted in the MPI standard. Persistent semantics contains an initialization phase called only once for a specific collective operation, with subsequent recurring invocations. This opens the door to many optimizations requiring heavy setup costs to improve collective performances. Communicator topological splitting offers a standard way to design topological algorithm through the use of sub-communicators mapped to hardware hierarchical levels. Setting these communicators might be too costly to be efficient on a single collective call. However, the persistent semantics allow to create these communicators once at initialization, and use them repeatedly in the multiple collective invocations to have an efficient algorithm. In this paper, we describe the implementation of these two new MPI features in the MPC framework. We first present a naïve and an optimized version of persistent collectives without topology knowledge. Then, after detailing the implementation of hardware topology splitting and the hierarchical levels supported in MPC, we showcase how these two features can be combined to produce efficient topology-aware persistent collective implementations. Experimental results show that the topology-aware algorithms built with these basic blocks offer good performances, independent of the MPI processes binding.},
  archive      = {J_PARCO},
  author       = {Stephane Bouhrour and Thibaut Pepin and Julien Jaeger},
  doi          = {10.1016/j.parco.2021.102860},
  journal      = {Parallel Computing},
  pages        = {102860},
  shortjournal = {Parallel Comput.},
  title        = {Towards leveraging collective performance with the support of MPI 4.0 features in MPC},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MPI detach — towards automatic asynchronous local
completion. <em>PARCO</em>, <em>109</em>, 102859. (<a
href="https://doi.org/10.1016/j.parco.2021.102859">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When aiming for large-scale parallel computing , waiting time due to network latency , synchronization, and load imbalance are the primary opponents of high parallel efficiency. A common approach to hide latency with computation is the use of non-blocking communication. In the presence of a consistent load imbalance, synchronization cost is just the visible symptom of the load imbalance. Tasking approaches as in OpenMP, TBB, OmpSs, or C++20 coroutines promise to expose a higher degree of concurrency, which can be distributed on available execution units and significantly increase load balance. Available MPI non-blocking functionality does not integrate seamlessly into such tasking parallelization . In this work, we present a slim extension of the MPI interface to allow seamless integration of non-blocking communication with available concepts of asynchronous execution in OpenMP and C++. Using our concept allows to span task dependency graphs for asynchronous execution over the full distributed memory application. We furthermore investigate compile-time analysis necessary to transform an application using blocking MPI communication into an application integrating OpenMP tasks with our proposed MPI interface extension.},
  archive      = {J_PARCO},
  author       = {Joachim Protze and Marc-André Hermanns and Matthias S. Müller and Van Man Nguyen and Julien Jaeger and Emmanuelle Saillard and Patrick Carribault and Denis Barthou},
  doi          = {10.1016/j.parco.2021.102859},
  journal      = {Parallel Computing},
  pages        = {102859},
  shortjournal = {Parallel Comput.},
  title        = {MPI detach — towards automatic asynchronous local completion},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). OpenMP application experiences: Porting to accelerated
nodes. <em>PARCO</em>, <em>109</em>, 102856. (<a
href="https://doi.org/10.1016/j.parco.2021.102856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As recent enhancements to the OpenMP specification become available in its implementations, there is a need to share the results of experimentation in order to better understand the OpenMP implementation’s behavior in practice, to identify pitfalls, and to learn how the implementations can be effectively deployed in scientific codes. We report on experiences gained and practices adopted when using OpenMP to port a variety of ECP applications, mini-apps and libraries based on different computational motifs to accelerator-based leadership-class high-performance supercomputer systems at the United States Department of Energy. Additionally, we identify important challenges and open problems related to the deployment of OpenMP. Through our report of experiences, we find that OpenMP implementations are successful on current supercomputing platforms and that OpenMP is a promising programming model to use for applications to be run on emerging and future platforms with accelerated nodes.},
  archive      = {J_PARCO},
  author       = {Seonmyeong Bak and Colleen Bertoni and Swen Boehm and Reuben Budiardja and Barbara M. Chapman and Johannes Doerfert and Markus Eisenbach and Hal Finkel and Oscar Hernandez and Joseph Huber and Shintaro Iwasaki and Vivek Kale and Paul R.C. Kent and JaeHyuk Kwack and Meifeng Lin and Piotr Luszczek and Ye Luo and Buu Pham and Swaroop Pophale and Kiran Ravikumar},
  doi          = {10.1016/j.parco.2021.102856},
  journal      = {Parallel Computing},
  pages        = {102856},
  shortjournal = {Parallel Comput.},
  title        = {OpenMP application experiences: Porting to accelerated nodes},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
