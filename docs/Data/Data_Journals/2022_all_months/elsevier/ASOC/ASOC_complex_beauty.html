<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ASOC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="asoc---909">ASOC - 909</h2>
<ul>
<li><details>
<summary>
(2022). An asymmetric PROMETHEE II for cryptocurrency portfolio
allocation based on return prediction. <em>ASOC</em>, <em>131</em>,
109829. (<a href="https://doi.org/10.1016/j.asoc.2022.109829">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Portfolio allocation, portfolio selection, and portfolio optimization are recognized as three crucial problems in the financial field. Using different criteria in addition to return and risk in the portfolio allocation problem based on the multi-criteria decision-making (MCDM) methods makes it more practical in the real world. The emergence of new and volatile assets such as cryptocurrencies has recently increased the need to use portfolio allocation models. In order to reduce inequalities and alleviate poverty as one of the sustainable development goals, cryptocurrency portfolio construction leads to sustainable income and wealth. This paper proposes a cryptocurrency portfolio allocation model based on the asymmetric Preference Ranking Organization Method for Enrichment Evaluation (PROMETHEE II) method using eight criteria and nine cryptocurrencies . To reduce the uncertainty of the problem, the return prediction obtained from the Auto-Regressive Integrated Moving Average (ARIMA), the Long Short-Term Memory (LSTM), and the Random Forest Regression (RFR) models as return-related criteria and has been used from the SlideVaR, along with the Value at Risk (VaR) and the Conditional Value at Risk (C-VaR) as risk-related criteria to consider investor insight from the market situation. It is also proposed that an asymmetric preference function be proposed to consider gain and loss asymmetry as a behavioral phenomenon in the model. The out-of-sample performance of the proposed model in the last three months of 2021 confirms the superiority of the proposed model in terms of average return (= 0.017) and standard deviation (= 0.036) among other proposed models.},
  archive      = {J_ASOC},
  author       = {Sarfaraz Hashemkhani Zolfani and Hassan Mehtari Taheri and Mahmoud Gharehgozlou and Alireza Farahani},
  doi          = {10.1016/j.asoc.2022.109829},
  journal      = {Applied Soft Computing},
  pages        = {109829},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An asymmetric PROMETHEE II for cryptocurrency portfolio allocation based on return prediction},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive boosted random forest-support vector machine based
classification scheme for speaker identification. <em>ASOC</em>,
<em>131</em>, 109826. (<a
href="https://doi.org/10.1016/j.asoc.2022.109826">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At each integrated work stage, many technologies and algebraic formulations are required to identify the speakers from speech signals. Due to advancements in machine learning and artificial intelligence , speaker recognition technologies are gaining popularity and are being used in a variety of applications. This paper presents a multi-feature adaptive boosted hybrid random forest support vector machine (AB-RFSVM) model that can process real-time, uninterrupted speech with 98 percent accuracy. To build the speaker recognition model, the extracted temporal and spectral speaker-specific information was applied as a feature vector to a suggested hybrid machine learning classifier. The goal of this work is to enhance the RF-SVM classifier’s categorization performance by adaptively boosting the decision of RFSVM. SVM moves around the decision trees positioned in the experimentally discovered subareas around the hyperplane dividing the multi-classes of correctly and incorrectly identified speakers is subject to boosting of classification decisions collected using the RFSVM classifier. The predetermined default configuration value was utilized while building the RFSVM classifier. Finally, the efficacy of the AB-RFSVM method is evaluated against that of other baseline methods using a variety of typical and real-time speaker databases. The experimental results revealed that AB-RFSVM yielded a 99 percent specificity and a loss function of less than 2\%. This paper’s findings show that the hybrid AB-RFSVM classification method is more effective for identifying and verifying speaker data.},
  archive      = {J_ASOC},
  author       = {Karthikeyan V and Suja Priyadharsini S},
  doi          = {10.1016/j.asoc.2022.109826},
  journal      = {Applied Soft Computing},
  pages        = {109826},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Adaptive boosted random forest-support vector machine based classification scheme for speaker identification},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Variable neighborhood search for the discounted 0-1 knapsack
problem. <em>ASOC</em>, <em>131</em>, 109821. (<a
href="https://doi.org/10.1016/j.asoc.2022.109821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The discounted {0, 1} knapsack problem (D{0-1}KP) is a relatively recent variant of the well-known knapsack problem. In the D{0-1}KP a set of items is partitioned into groups of three items and at most one item can be chosen from each group. In addition, a discount relationship is introduced among items in each group. As for the knapsack problem the aim is to maximize the total profit of the selected items while respecting the knapsack capacity constraint. The D{0-1}KP has been considered in recent years by various authors who proposed different (meta-)heuristics to solve it. In this work we propose a new variable neighborhood search (VNS) to solve the D{0-1}KP. We also consider several greedy heuristics to build an initial feasible solution that can be used by VNS as a starting solution. To evaluate proposed approaches the benchmark instances from the literature are considered. We first assess the quality of initial solutions returned by the greedy algorithms . Then, we analyze the capability of VNS to improve these initial solutions. Finally, we evaluate the performance of VNS compared to the state-of-the-art metaheuristics for solving the D{0-1}KP. The results demonstrate the robustness of VNS which converges to near optimal solutions in a reasonable time. This is especially true when VNS is initialized by solutions returned by greedy algorithms based on linear programming. Moreover, the obtained results show that our VNS based approaches are competitive with the best metaheuristics from the literature for the D{0-1}KP.},
  archive      = {J_ASOC},
  author       = {Christophe Wilbaut and Raca Todosijević and Saïd Hanafi and Arnaud Fréville},
  doi          = {10.1016/j.asoc.2022.109821},
  journal      = {Applied Soft Computing},
  pages        = {109821},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Variable neighborhood search for the discounted {0-1} knapsack problem},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Using supervised and one-class automated machine learning
for predictive maintenance. <em>ASOC</em>, <em>131</em>, 109820. (<a
href="https://doi.org/10.1016/j.asoc.2022.109820">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predictive Maintenance (PdM) is a critical area that is benefiting from the Industry 4.0 advent. Recently, several attempts have been made to apply Machine Learning (ML) to PdM, with the majority of the research studies assuming an expert-based ML modeling. In contrast with these works, this paper explores a purely Automated Machine Learning (AutoML) modeling for PdM under two main approaches. Firstly, we adapt and compare ten recent open-source AutoML technologies focused on a Supervised Learning. Secondly, we propose a novel AutoML approach focused on a One-Class (OC) Learning (AutoOneClass) that employs a Grammatical Evolution (GE) to search for the best PdM model using three types of learners (OC Support Vector Machines, Isolation Forests and deep Autoencoders). Using recently collected data from a Portuguese software company client, we performed a benchmark comparison study with the Supervised AutoML tools and the proposed AutoOneClass method to predict the number of days until the next failure of an equipment and also determine if the equipments will fail in a fixed amount of days. Overall, the results were close among the compared AutoML tools, with supervised AutoGluon obtaining the best results for all ML tasks. Moreover, the best supervised AutoML and AutoOneClass predictive results were compared with two manual ML modeling approaches (using a ML expert and a non-ML expert), revealing competitive results.},
  archive      = {J_ASOC},
  author       = {Luís Ferreira and André Pilastri and Filipe Romano and Paulo Cortez},
  doi          = {10.1016/j.asoc.2022.109820},
  journal      = {Applied Soft Computing},
  pages        = {109820},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Using supervised and one-class automated machine learning for predictive maintenance},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Particle swarm optimization with chebychev functional-link
network model for engineering design problems. <em>ASOC</em>,
<em>131</em>, 109819. (<a
href="https://doi.org/10.1016/j.asoc.2022.109819">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, many improved particle swarm optimization (PSO) algorithms have been developed to improve the performance of PSO. These improved algorithms have greatly improved PSO performance, but PSO still has some shortcomings. So, an particle swarm optimization with Chebychev functional-link network model is proposed (APSOCFLN) in this paper. Firstly, in order to make up for the shortcomings of the canonical PSO update search, a novel Chebychev functional-link network (CFLN) elite guidance strategy is proposed. Two different update mechanisms are executed alternately, increasing the diversity of the algorithm population and making the algorithm more capable of jumping out of local optimization . Secondly, in order to better balance the exploration and exploitation of the algorithm, an adaptive probability strategy is proposed. Thirdly, an adaptive weighting strategy is proposed. It will be used for CFLN elite guidance strategy and give different weights to the two alternating update strategies, which can effectively solve the problem of premature convergence of PSO. Fourthly, the APSOCFLN and comparison algorithms are used to solve the practical engineering problems, and the results show that APSOCFLN has high precision, fast convergence , and excellent performance. Finally, the performance of the algorithm is tested with CEC2017 and CEC2022 benchmark functions . The comparative algorithm includes the classical PSO improvement algorithms and the classical other algorithms, and the experimental results show the effectiveness of the proposed strategy and the good performance of the improved algorithm.},
  archive      = {J_ASOC},
  author       = {Hao Liu and Wentao Wang and Xin Cheng and Huifang Zheng},
  doi          = {10.1016/j.asoc.2022.109819},
  journal      = {Applied Soft Computing},
  pages        = {109819},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Particle swarm optimization with chebychev functional-link network model for engineering design problems},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Target-aware u-net with fuzzy skip connections for refined
pancreas segmentation. <em>ASOC</em>, <em>131</em>, 109818. (<a
href="https://doi.org/10.1016/j.asoc.2022.109818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image segmentation is one of the important steps in the computer-aided diagnosis of pancreas diseases. Although some models have been proposed to deal with the task of automatic pancreas segmentation, it is still challenging due to the small size, variable shape and unclear boundary of pancreas. In this paper, we propose a target-aware U-Net (tU-Net) using fuzzy skip connection for pancreas segmentation. Through adding a fuzzy skip connection module into the U-Net architecture, the low-level features can be transformed into the high-level semantic features, which facilitates the segmentation of small and changeable targets of pancreas. Based on the fuzzy feature mapping, we also design a target attention mechanism consists of global average pooling and depthwise convolution. It makes the decoder of the network more sensitive to target features by increasing weights of important channels. The proposed method is evaluated on the NIH dataset of 82 CT volumes, and the pancreas Medical Segmentation Decathlon (MSD) challenge dataset of 281 CT volumes. The proposed model achieves better results comparing with other state-of-the-art models.},
  archive      = {J_ASOC},
  author       = {Yufei Chen and Chang Xu and Weiping Ding and Shichen Sun and Xiaodong Yue and Hamido Fujita},
  doi          = {10.1016/j.asoc.2022.109818},
  journal      = {Applied Soft Computing},
  pages        = {109818},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Target-aware U-net with fuzzy skip connections for refined pancreas segmentation},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Graph ensemble deep random vector functional link network
for traffic forecasting. <em>ASOC</em>, <em>131</em>, 109809. (<a
href="https://doi.org/10.1016/j.asoc.2022.109809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic forecasting is crucial to achieving a smart city as it facilitates public transportation management, autonomous driving , and the resource relocation of the sharing economy. Traffic forecasting belongs to the challenging spatiotemporal forecasting task, which is highly demanding because of the complicated geospatial correlation between traffic nodes, inconsistent and highly non-linear temporal patterns due to various events, and sporadic traffic accidents . Previous graph neural network (GNN) models built for transportation forecasting feature the sophisticated structure and heavy computation cost as they combine the deep neural network and graph machine learning to capture the spatiotemporal dynamics for the whole transportation network. However, it may be more practical for practitioners to perform node-wise forecasting for specific nodes of interest rather than network-wise forecasting. To mitigate the gaps mentioned above, we propose a novel graph ensemble deep random vector functional link network (GEdRVFL) to forecast the future traffic volume by combining the well-performing ensemble deep random vector functional link (EdRVFL) with the graph convolution layer for a specific node and realize the node-wise traffic forecasting. After a comprehensive comparison with the state-of-the-art models, our model beats the others in four out of five cases measured by mean absolute scaled error.},
  archive      = {J_ASOC},
  author       = {Liang Du and Ruobin Gao and Ponnuthurai Nagaratnam Suganthan and David Z.W. Wang},
  doi          = {10.1016/j.asoc.2022.109809},
  journal      = {Applied Soft Computing},
  pages        = {109809},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Graph ensemble deep random vector functional link network for traffic forecasting},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Granular data representation under privacy protection:
Tradeoff between data utility and privacy via information granularity.
<em>ASOC</em>, <em>131</em>, 109808. (<a
href="https://doi.org/10.1016/j.asoc.2022.109808">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information granules describe available experimental evidence at a more abstract level and facilitate the concise characterization of the structure of the numeric data. The utilization of unreliable data collectors poses a key challenge with respect to the privacy of the participants. In order to guarantee data confidentiality , we propose a granular data publishing method under differential privacy . In this study, a two-stage design of information granules considering the requirement of data privacy is proposed. The main idea is to protect individual sensitive pieces of data information against inference attacks and optimize the representation capabilities of information granules in a multi-dimensional data space. In the first stage, a clustering algorithm based on differential privacy is proposed to find some numeric prototypes in a numeric space, which considers sensitive data privacy protection. Second, this paper constructs spherical information granules involving the requirement of differential privacy. Their multi-dimensional and fuzzy granularity characteristics are considered. An improvement of the principle of justifiable granularity is utilized to optimize the bounds of information granules, and a new objective function is established to optimize the information granules. Our work is devoted to tradeoff data privacy and utility by constructing reasonable information granules. Unlike numerical data publishing, the publishing of interval information granules improves data utility in data protection. Experimental results demonstrate the superiority of the proposed granular description method based on differential privacy.},
  archive      = {J_ASOC},
  author       = {Ge Zhang and Xiubin Zhu and Li Yin and Witold Pedrycz and Zhiwu Li},
  doi          = {10.1016/j.asoc.2022.109808},
  journal      = {Applied Soft Computing},
  pages        = {109808},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Granular data representation under privacy protection: Tradeoff between data utility and privacy via information granularity},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A mixed-heuristic quantum-inspired simplified swarm
optimization algorithm for scheduling of real-time tasks in the
multiprocessor system. <em>ASOC</em>, <em>131</em>, 109807. (<a
href="https://doi.org/10.1016/j.asoc.2022.109807">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time task scheduling in multiprocessor (MP) systems has become more critical. As quantum computing advances, scholars have proposed different Quantum-Inspired (QI) Optimization Algorithms to optimize real-time task scheduling problems. In this research, we first take advantage of the Simplified Swarm Optimization Algorithm (SSO) and then propose a Quantum-Inspired Simplified Swarm Optimization (QISSO) to not only overcome the early convergence problem but also enhance the exploration of solution space without premature. Furthermore, we propose the Mixed-Heuristic QISSO for real-time task scheduling in the MP system to improve the scheduling. The proposed MHQISSO achieves the best average percentage of success within the shortest running time in five different size task sets according to two scenarios, Earliest Deadline First (EDF) and Shortest Computational Time First (SCTF).},
  archive      = {J_ASOC},
  author       = {Pei-Chiang Su and Shi-Yi Tan and Zhenyao Liu and Wei-Chang Yeh},
  doi          = {10.1016/j.asoc.2022.109807},
  journal      = {Applied Soft Computing},
  pages        = {109807},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A mixed-heuristic quantum-inspired simplified swarm optimization algorithm for scheduling of real-time tasks in the multiprocessor system},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Implementation of roulette wheel and random selection
methods in a hybrid intelligent system: A comparison study for two
islands and subway distributions considering different router
replacement methods. <em>ASOC</em>, <em>131</em>, 109805. (<a
href="https://doi.org/10.1016/j.asoc.2022.109805">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) and 5G wireless networks have made it possible to connect intelligent devices with each other and to the Internet. Different kind of networks and applications are appearing and they support us in everyday life. The Wireless Mesh Networks (WMNs) have emerged as a good approach for edge computing and last miles networks. They can be applied in different scenarios and areas with difficult terrains. In order to deploy reliable and highly connected WMNs at low cost, we optimize the connectivity of mesh routers and the coverage mesh clients. In our previous work, we designed and implemented a hybrid intelligent system called WMN-PSODGA, which integrates two intelligent algorithms: Particle Swarm Optimization (PSO) and Distributed Genetic Algorithm (DGA). In this work, we implement in our system Two Islands and Subway distributions of mesh clients and evaluate the performance of different router replacement methods considering two selection methods: roulette wheel and random. We compare the simulation results for each selection and router replacement method and find the best scenarios in terms of coverage, connectivity, and load balancing. For each combination, the achieved network connectivity and client coverage are 100\%, but the best scenarios in terms of load balancing are when we combine the random selection method and Constriction Method (CM) for the Two Islands distribution, and the random selection method and Random Inertia Weight Method (RIWM) for the Subway distribution.},
  archive      = {J_ASOC},
  author       = {Admir Barolli and Kevin Bylykbashi and Ermioni Qafzezi and Shinji Sakamoto and Leonard Barolli},
  doi          = {10.1016/j.asoc.2022.109805},
  journal      = {Applied Soft Computing},
  pages        = {109805},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Implementation of roulette wheel and random selection methods in a hybrid intelligent system: A comparison study for two islands and subway distributions considering different router replacement methods},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Inspired lightweight robust quantum q-learning for smart
generation control of power systems. <em>ASOC</em>, <em>131</em>,
109804. (<a href="https://doi.org/10.1016/j.asoc.2022.109804">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous development of zero-carbon power systems , more and more models need to be considered in the system, and the dimension of data provided in the system will be higher and higher. The grid frequency will be difficult to be controlled stably. The existing smart generation control (SGC) methods like proportional–integral–derivative (PID), traditional Q-learning (QL), state–action–reward–state–action (SARSA), sliding mode control (SMC), and fuzzy logic control (FLC) have low-performance problems, the curse of dimensionality, and a slow convergence rate in the zero-carbon power system. This work proposes lightweight robust quantum Q-learning (LRQQL) methods to improve the performance of SGC methods and solve these problems. The LRQQL methods are divided into four methods. Two methods apply the idea of quantum normalization to update the action probability and different action selection methods to provide the action with higher performance. Besides, two lighter methods based on the idea of Grover iteration with the less curse of dimensionality and a faster convergence rate are proposed. The LRQQL methods are simulated in the two-area, four-area, and complex four-area systems. The evaluation indexes verify the feasibility of LRQQL algorithms. The LRQQL methods are more than 25\% smaller than traditional QL in frequency error, more than 40\% smaller than traditional QL in area control error, and more than 40\% faster than the QL and SARSA in convergence rate. Meanwhile, the LRQQL methods possess higher adaptivity than PID, QL, SARSA, SMC, and FLC.},
  archive      = {J_ASOC},
  author       = {Linfei Yin and Xinghui Cao},
  doi          = {10.1016/j.asoc.2022.109804},
  journal      = {Applied Soft Computing},
  pages        = {109804},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Inspired lightweight robust quantum Q-learning for smart generation control of power systems},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning-accelerated optimization algorithm for
controller parameters optimization of doubly-fed induction generators.
<em>ASOC</em>, <em>131</em>, 109800. (<a
href="https://doi.org/10.1016/j.asoc.2022.109800">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a cooperative Gray wolf Optimizer with adaptive differential Evolution (GOE) is proposed for the multimodal controller parameters optimization of doubly-fed induction generators (DFIGs) based on maximum power point tracking (MPPT) strategies. Moreover, the optimization process of the GOE is accelerated by a deep fully connected model (DFCM). The GOE contains a cooperative gray wolf optimizer (GWO) and adaptive differential evolution (ADE). The cooperative GWO contains alpha, beta, delta, and omega wolves to explore and exploit optimization problems and achieves optimization tasks wider and deeper than GWO. The ADE cooperates with the cooperative GWO to solve global optimization over continuous spaces. The simulation results on seven uni-model benchmark functions show that the GOE accelerated by DFCM obtains acceptable fitness values with 39.99\% lesser computation time than the symmetry adapted stochastic search (SASS) algorithm and 80.72\% lesser computation time than the Lévy flights-success-history based adaptive differential evolution with constraint handling technique (COLSHADE) algorithm, which are the winners of the CEC2020 Competition on Real-World Single Objective Constrained Optimization . Furthermore, the simulation results on DFIG with MPPT strategies in three real-world cases verify that the GOE accelerated by DFCM can effectively obtain global optimization solutions for non-smooth problems with 99.51\% lesser average computation time than the SASS algorithm, 99.63\% less than the COLSHADE algorithm, and 89.52\% less than other methods. In addition, the accelerated GOE algorithm by DFCM has the feature of faster convergence.},
  archive      = {J_ASOC},
  author       = {Linfei Yin and Xinghui Cao and Senlin Wang},
  doi          = {10.1016/j.asoc.2022.109800},
  journal      = {Applied Soft Computing},
  pages        = {109800},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Deep learning-accelerated optimization algorithm for controller parameters optimization of doubly-fed induction generators},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-neural network fusion algorithm for fire warning in
tunnels. <em>ASOC</em>, <em>131</em>, 109799. (<a
href="https://doi.org/10.1016/j.asoc.2022.109799">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fire early warning plays a key role in fire-fighting actions for alleviating the potential casualties of the trapped personnel and firefighters . This paper targets to achieve a fast detecting whether fire occurs or not in urban utility tunnels during fire initial stage by using the data-driven artificial intelligence algorithm. To improve the correct forecast rate, an auto-enhanced multi-trend back propagation neural network algorithm is developed based on the two betterments. One is that many neural networks are constructed to a strong multi-neural network for achieving enhanced-fusion prediction. Another is that one special trend extraction part is coupled in the algorithm to enhance the perception of no obvious temperature variation trend during fire initial stage. Finally, two kinds of full-scale tunnel fire tests were conducted to support the ability and effectiveness of the algorithm. The algorithm can successfully detect whether fire occurs or not with a 96.8\% correct forecast rate by learning the temperature data during fire initial stage, even if the maximal range of temperature change is less than 3 °C. In addition, to achieve such a high correct forecast rate, only one sensor is necessary for fire early warning in 60 m long tunnel by using the algorithm.},
  archive      = {J_ASOC},
  author       = {Bin Sun and Zhao-Dong Xu},
  doi          = {10.1016/j.asoc.2022.109799},
  journal      = {Applied Soft Computing},
  pages        = {109799},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-neural network fusion algorithm for fire warning in tunnels},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A discrete differential evolution with local search particle
swarm optimization to direct angle and aperture optimization in IMRT
treatment planning problem. <em>ASOC</em>, <em>131</em>, 109798. (<a
href="https://doi.org/10.1016/j.asoc.2022.109798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intensity-modulated radiation therapy is a well-known technique for treating cancer patients worldwide. A treatment plan in this technique requires decision-making for three main problems: selection of beam angles, intensity map calculation, and leaf sequencing. Previous works investigated these problems sequentially. We present a new integrated framework for simultaneous decision-making of directions, intensities, and aperture shape, called direct angle and aperture optimization, and develop a mixed-integer nonlinear mathematical model for the problem. Due to the nonlinearity and the dimension of the problem, three efficient metaheuristics based on differential evolution (DE) called classic differential evolution (cDE), discrete differential evolution (dDE), and adaptive hybrid discrete differential evolution-particle swarm optimization (ahdDE-PSO) algorithms are designed to solve the problem. Parameters calibration is performed using the Taguchi design of experiments . The performance of the algorithms is evaluated by solving the problem for ten real cases of liver cancer disease from the TROTS data set. The performed ablation study and statistical analysis of computational results demonstrate that ahdDE-PSO is capable of finding high-quality treatment plans.},
  archive      = {J_ASOC},
  author       = {Ali Fallahi and Mehdi Mahnam and Seyed Taghi Akhavan Niaki},
  doi          = {10.1016/j.asoc.2022.109798},
  journal      = {Applied Soft Computing},
  pages        = {109798},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A discrete differential evolution with local search particle swarm optimization to direct angle and aperture optimization in IMRT treatment planning problem},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A two-phase differential evolution for minimax optimization.
<em>ASOC</em>, <em>131</em>, 109797. (<a
href="https://doi.org/10.1016/j.asoc.2022.109797">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimum of a minimax optimization problem is the minimum of maximal outputs in all possible scenarios. A minimax optimization problem includes two decision spaces: the scenario space and the solution space. When optimizing this kind of problem, an algorithm should consider three issues: (1) in the scenario space, how to decide which promising individuals to be optimized; (2) in the solution space, how to avoid discarding promising individuals; (3) how to properly allocate the optimization resources to these two spaces. Bearing these in mind, a two-phase differential evolution algorithm is proposed. To address the first issue, it optimizes a better individual with a higher probability instead of updating the best one directly. The second issue is addressed as follows. On the one hand, individuals with better objective function values are modified less frequently; On the other hand, an archive-based comparison strategy is developed to avoid selecting an offspring that owns a good objective function value but has not been optimized adequately in the scenario space. To properly monitor these two phases, the optimization resources are allocated dynamically. Experiments on benchmark test functions and an open problem in epidemic spreading control over complex networks demonstrate that the proposed method is competitive.},
  archive      = {J_ASOC},
  author       = {Bing-Chuan Wang and Yun Feng and Xian-Bing Meng and Shuqiang Wang},
  doi          = {10.1016/j.asoc.2022.109797},
  journal      = {Applied Soft Computing},
  pages        = {109797},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A two-phase differential evolution for minimax optimization},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neighborhood rough cognitive networks. <em>ASOC</em>,
<em>131</em>, 109796. (<a
href="https://doi.org/10.1016/j.asoc.2022.109796">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rough cognitive network (RCN) is a granularity neural network combining fuzzy cognitive maps with rough set theory , which has the advantages of transparency and interpretability . However, When the existing RCN are applied to the decision-making aspects of practical problems, they exhibit problems such as weak generalization and unstable performance. To solve the above problems, a highly efficient classification decision model neighborhood rough cognitive networks (NRCN) is proposed. It uses a feature selection algorithm based on the neighborhood rough set to minimize the data dimensionality. Moreover, the introductions of sub-neurons and Hellinger distance in proposed model can better discover knowledge and make more reasonable inference decisions. Various open datasets and real financial data are implemented to verify the effectiveness and validity of the proposed method.},
  archive      = {J_ASOC},
  author       = {Xiang Li and Chao Luo},
  doi          = {10.1016/j.asoc.2022.109796},
  journal      = {Applied Soft Computing},
  pages        = {109796},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Neighborhood rough cognitive networks},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Chinese sentence semantic matching based on multi-level
relevance extraction and aggregation for intelligent human–robot
interaction. <em>ASOC</em>, <em>131</em>, 109795. (<a
href="https://doi.org/10.1016/j.asoc.2022.109795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of Internet of Things and cloud computing , intelligent question-answering (QA) has brought great convenience to human’s daily activities. As one of the core technologies, sentence semantic matching (SSM) plays a critical role in a variety of intelligent QA systems . However, existing SSM methods usually first encode sentences on either character or word level, and then model semantic interactions on sentence level. Consequently, they fail to capture the rich interactions on multi-levels (i.e., character, word and sentence levels). In this paper, we propose Chinese sentence semantic matching based on Multi-level Relevance Extraction and Aggregation (MREA) for intelligent QA. MREA can comprehensively capture and aggregate various semantic relevance on character, word and sentence levels respectively based on multiple attention mechanisms . Extensive experiments on two real-world datasets demonstrate that MREA outperforms the best-performing baselines by 0.5\% and 0.89\% w.r.t. ACC. and F 1 F1 respectively, and achieves comparable performance with BERT-based methods.},
  archive      = {J_ASOC},
  author       = {Wenpeng Lu and Pengyu Zhao and Yifeng Li and Shoujin Wang and Heyan Huang and Shumin Shi and Hao Wu},
  doi          = {10.1016/j.asoc.2022.109795},
  journal      = {Applied Soft Computing},
  pages        = {109795},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Chinese sentence semantic matching based on multi-level relevance extraction and aggregation for intelligent human–robot interaction},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Metaheuristics based long short term memory optimization for
sentiment analysis. <em>ASOC</em>, <em>131</em>, 109794. (<a
href="https://doi.org/10.1016/j.asoc.2022.109794">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A tremendous amount of opinionated data is being added to online platforms every day. Social media has become the primary source of collecting user’s opinions about products they have purchased. These online reviews contain important information for the sellers but the information is available in unstructured natural language text. There is a dire need for an automated approach that can extract sentiment from a large number of unstructured reviews. LSTM has shown state-of-the-art results for sentiment analysis in recent years. The performance of LSTM heavily depends on the architectural design . Rather than applying a trial and error approach which can easily mislead the results, an automated optimization technique should be used for architecture related hyperparameter selection. To address this problem, we propose a new framework to optimize the architecture of LSTM using different meta-heuristics. This is the first systematic study of architectural optimization in the context of sentiment analysis using meta heuristics. We have applied Genetic Algorithm (GA), Particle Swarm Optimization (PSO), Differential Evolution (DE), Firefly, and Cat Swarm Optimization (CSO) for LSTM architecture optimization. The problem of training LSTM has been formulated as an optimization problem and the objective is to maximize F-score. Four benchmark datasets for sentiment analysis have been used in our experiments. PSO and DE show remarkable success in improving the F-score and accuracy. Experimental results demonstrate that the optimal configuration obtained for designing the LSTM architecture using our proposed meta-heuristics significantly improves the accuracy of sentiment analysis.},
  archive      = {J_ASOC},
  author       = {Mehtab Kiran Suddle and Maryam Bashir},
  doi          = {10.1016/j.asoc.2022.109794},
  journal      = {Applied Soft Computing},
  pages        = {109794},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Metaheuristics based long short term memory optimization for sentiment analysis},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). A landscape-aware particle swarm optimization for parameter
identification of photovoltaic models. <em>ASOC</em>, <em>131</em>,
109793. (<a href="https://doi.org/10.1016/j.asoc.2022.109793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photovoltaic (PV) systems play a significant role in power systems since they can convert solar energy directly into electricity. Their conversion performance depends mainly on the unknown parameters of the PV model. Due to the multimodal, nonlinear, and multivariate characteristics of solar cells and modules, parameter identification of PV models is still a popular and challenging task in PV systems. However, most of the existing approaches face the problem of falling into local optima, high computational costs, and insufficient utilization of landscape information in the evolutionary process. In this study, a landscape-aware particle swarm optimization algorithm (LaPSO) is proposed to estimate the parameters of the PV system. LaPSO includes two main improvements: (i) A landscape-based adaptive operator selection mechanism is proposed to quantify the landscape modality and assign the most appropriate evolutionary strategy to the current population to improve population quality. (ii) The problem of getting trapped in local optima is alleviated by using the mirrored boundary handling method. The experimental results tested on various PV models demonstrate the excellence of LaPSO in terms of accuracy, stability, and convergence speed. Moreover, LaPSO has shown superior practicality and reliability at different temperatures and irradiances on other PV modules . Consequently, LaPSO is well-suited as an alternative for the parameter identification of solar cells and modules under various practical conditions.},
  archive      = {J_ASOC},
  author       = {Yaxin Li and Kunjie Yu and Jing Liang and Caitong Yue and Kangjia Qiao},
  doi          = {10.1016/j.asoc.2022.109793},
  journal      = {Applied Soft Computing},
  pages        = {109793},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A landscape-aware particle swarm optimization for parameter identification of photovoltaic models},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mathematical modeling of vehicle routing problem in
omni-channel retailing. <em>ASOC</em>, <em>131</em>, 109791. (<a
href="https://doi.org/10.1016/j.asoc.2022.109791">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The biggest challenge that retailers face in satisfying consumer requirements is to ensure an integrated/seamless shopping experience consistent with the purchase, regardless of how the purchase is made. Giant companies have many depots, points of delivery, retail stores, etc. in different cities. This study focused on modeling vehicle routing in a retail distribution network . Goods may be sold in the distribution system addressed in the research model employing two methods: physical and online sales. This study examined the routing problem in the Omni-Channel (OC) retail system, focusing on a multi-objective approach to increase consumer physical convenience (ease of access) using several delivery techniques from six points of delivery. To this end, the optimization of a distribution network was examined through two objective functions. The first objective function minimized the cost of the distribution network, whereas the second maximized customer convenience in terms of the minimum shipment delivery time from the four positions (retail store, intermediate depot, points of delivery, and city distribution center by considering the demand for each product). Two meta-heuristic algorithms, MOGWO and NSGA-II, were used to solve the problem. The results demonstrate that the two-step approach generates smaller objective function values than the second objective function. In addition, the total costs of the two-stage approach were higher than those predicted by the proposed model. Consequently, it was concluded that, in the proposed mathematical model, owing to the integrated optimization of a distribution system and considering the possibility of direct shipment of products to customers, Pareto points are obtained with a lower cost and higher customer satisfaction.},
  archive      = {J_ASOC},
  author       = {Peide Liu and Ayad Hendalianpour and Mohammadreza Feylizadeh and Witold Pedrycz},
  doi          = {10.1016/j.asoc.2022.109791},
  journal      = {Applied Soft Computing},
  pages        = {109791},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Mathematical modeling of vehicle routing problem in omni-channel retailing},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). BIM-aided large-scale group decision support: Optimization
of the retrofit strategy for existing buildings. <em>ASOC</em>,
<em>131</em>, 109790. (<a
href="https://doi.org/10.1016/j.asoc.2022.109790">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of the construction industry, buildings have become the single largest consumer of energy in the world. The retrofitting of existing buildings offers an excellent opportunity to reduce global energy consumption and promote sustainable development. As the retrofit strategy determines the success of the retrofitting process, this paper proposes a decision support framework for retrofitting that integrates the building information modeling (BIM) with large-scale group decision-making, which is a new application of digital technology to the retrofitting of existing buildings. Within this framework, BIM provides massive geometric and non-geometric data for the multi-criteria large-scale group decision-making process. Taking into account the needs of various stakeholder groups and sustainable principle, we establish a comprehensive and innovative evaluation index system for community retrofitting, and use the group best-worst method to determine the criteria weights. The stakeholers evaluate alternative retrofit strategies through distribution linguistic preferences, with a consistency-driven optimization model used to personalize the stakeholers’ numerical evaluation scales. Through k-means clustering and the consensus-reaching process, combined with objective data from BIM, we obtain the ranking of the alternative strategies. Finally, we apply the abovementioned decision support framework to the retrofitting of the Suifeng Garden community in China to demonstrate the rationality and superiority of the proposed approach.},
  archive      = {J_ASOC},
  author       = {Zhen-Song Chen and Li-Ping Yang and Rosa M. Rodríguez and Zhengze Zhu and Witold Pedrycz and Mirosław J. Skibniewski},
  doi          = {10.1016/j.asoc.2022.109790},
  journal      = {Applied Soft Computing},
  pages        = {109790},
  shortjournal = {Appl. Soft. Comput.},
  title        = {BIM-aided large-scale group decision support: Optimization of the retrofit strategy for existing buildings},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Combining affinity propagation with differential evolution
for three-echelon logistics distribution optimization. <em>ASOC</em>,
<em>131</em>, 109787. (<a
href="https://doi.org/10.1016/j.asoc.2022.109787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to alleviate urban congestion, improve vehicle mobility and logistics distribution efficiency, the urban logistics distribution system is regarded as a three-echelon logistics distribution system. In this paper, a mathematical model of the 3-echelon logistics distribution problem (3E-LDP) considering time window constraint is established based on the directed graph , and a double-tier intelligent algorithm solution scheme is proposed, which combines the distance entropy-based Affinity Propagation clustering (DEBAP) algorithm and the crossover and selection-based differential evolution algorithm (CSBDE). First of all, in order to reduce the scale of logistics distribution and improve the utilization rate of logistics distribution facilities, the DEBAP algorithm is proposed in the upper tier to divide the logistics distribution region and optimize the distribution of logistics facilities, and the resulting scheme is passed to the vehicle routing optimization algorithm in the lower tier. Secondly, the vehicle routes at all levels are optimized based on the CSBDE algorithm at the lower tier, and the optimized route scheme is fed back to the DEBAP algorithm at the upper tier, so as to coordinate multi-echelon logistics distribution. Then, a search strategy based on the reachable distribution region and a facility allocation optimization strategy based on the weight of routing length are proposed to improve the efficiency of the algorithm. Based on the above algorithms, the optimization of the three-echelon logistics distribution system is completed in coordination. Finally, the performance of the proposed method is evaluated on the standard benchmark instances of the problem. The experimental results show that the three-echelon logistics model can improve the efficiency of logistics distribution, and the method has the best comprehensive performance, which is better than the most advanced 3E-LDP solution method. It has great potential in practical projects.},
  archive      = {J_ASOC},
  author       = {Haifei Zhang and Hongwei Ge and Jieming Yang and Shuzhi Su and Yubing Tong},
  doi          = {10.1016/j.asoc.2022.109787},
  journal      = {Applied Soft Computing},
  pages        = {109787},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Combining affinity propagation with differential evolution for three-echelon logistics distribution optimization},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A two-stage bayesian learning-based probabilistic fuzzy
interpreter for uncertainty modeling. <em>ASOC</em>, <em>131</em>,
109786. (<a href="https://doi.org/10.1016/j.asoc.2022.109786">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical applications, there are usually complex stochastic and vague uncertainties caused by inherent randomness and unknown dynamics. How to model uncertainty and interpret the modeling result is of significance for practical applications. To address these issues, a new probabilistic fuzzy logic system (PFLS) is proposed based on two-stage Bayesian learning . On the basis of the structure of traditional FLS, the proposed PFLS can be used as probabilistic fuzzy interpreter for complex uncertainty modeling. Specifically, in the training stage, expectation–maximization-based Gaussian mixture model is used to classify given data and learn the corresponding probability distributions, which are further used to generate samples to compensate for the limited given data. Based on Bayesian learning , fuzzy rules are learned by maximizing joint probability distributions of given data and rules. In the later inference stage, Bayesian learning-based probabilistic fuzzy inference is developed to make the activated fuzzy rules best match the input and output data pairs. Through integration with the two-stage Bayesian learning, PFLS can properly handle both vague and stochastic uncertainties, and interpret modeling results with fuzzy rules under maximum likelihood . Experiments based on temperature predictions in complex industrial processes demonstrate the effectiveness of the proposed method.},
  archive      = {J_ASOC},
  author       = {Xian-Bing Meng and Han-Xiong Li and C.L. Philip Chen},
  doi          = {10.1016/j.asoc.2022.109786},
  journal      = {Applied Soft Computing},
  pages        = {109786},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A two-stage bayesian learning-based probabilistic fuzzy interpreter for uncertainty modeling},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). 1D-DGAN-PHM: A 1-d denoising GAN for prognostics and health
management with an application to turbofan. <em>ASOC</em>, <em>131</em>,
109785. (<a href="https://doi.org/10.1016/j.asoc.2022.109785">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of prognostics is closely related to the quality of condition monitoring signals (e.g., temperature, pressure, or vibration signals), which reveal the degradation of the system of interest. However, typical condition monitoring signals include noise and outliers. Disentangling noise from these signals is essential to obtain the actual degradation trajectories. Different denoising methods have been proposed in prognostics. Conventional denoising methods have low complexity but usually do not preserve edge information and do not involve physical considerations. A promising deep learning approach is denoising generative models . This approach is popular in Computer Vision , which has been shown to outperform other classical techniques but has seldom been used in prognostics on 1-D signals. In this paper, we propose the 1-D Denoising Generative Adversarial Network for Prognostics and Health Management (1D-DGAN-PHM). The 1D-DGAN-PHM is trained on synthetic data generated by a custom data generator that infuses physics-of-failure knowledge in paired samples of noisy and noise-free trajectories. The network consists of two components, a denoising generator and a discriminator . The denoising generator aims to learn to denoise a 1-D input signal. The discriminator guides the learning by comparing noise-free signals with signals from the denoising generator. Advantages of the 1D-DGAN-PHM include the physics-of-failure information in the synthetic data generator and the model sophistication. In this work, we apply the 1D-DGAN-PHM to denoise the raw signals derived from NASA’s C-MAPSS simulator of an aircraft turbofan engine . Baseline methods are Moving Average, Median filter , Savitzky–Golay filter, and a denoising autoencoder . The 1D-DGAN-PHM produces smooth trajectories and preserves the initial linear degradation of the signals. The 1D-DGAN-PHM has the most significant improvement in prognosability (on average, 0.73 to 0.81). Data from the 1D-DGAN-PHM resulted in the best MAE (29 to 25 cycles) and RMSE (score of 39 to 36) for a Random Forest . The code is publicly available at 1D-DGAN-PHM .},
  archive      = {J_ASOC},
  author       = {Marcia L. Baptista and Elsa M.P. Henriques},
  doi          = {10.1016/j.asoc.2022.109785},
  journal      = {Applied Soft Computing},
  pages        = {109785},
  shortjournal = {Appl. Soft. Comput.},
  title        = {1D-DGAN-PHM: A 1-D denoising GAN for prognostics and health management with an application to turbofan},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-objective scheduling of a single mobile robot based on
the grey wolf optimization algorithm. <em>ASOC</em>, <em>131</em>,
109784. (<a href="https://doi.org/10.1016/j.asoc.2022.109784">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the last decades, intelligent mobile robots have been recognized as one of the most promising and emerging solutions used for fulfilling material transport demands in intelligent manufacturing systems . One of the most significant characteristics of those demands is their multi-objectivity, where identified objectives might usually conflict. Therefore, obtaining the optimally scheduled robotic-based material transport system that is simultaneously facing several conflicting objectives is a highly challenging task. To address such a challenge, this paper proposes a novel multi-objective Grey Wolf Optimizer (MOGWO) methodology to efficiently schedule material transport systems based on an intelligent single mobile robot. The proposed optimization methodology includes the comprehensive analysis and the mathematical formulation of 13 novel fitness functions combined to form a Pareto front of the multi-objective optimization problem and a novel strategy for optimal exploration of multi-objective search space. Moreover, four metrics, i.e., Generational Distance (GD), Inverted Generational Distance (IGD), Spacing (SP), and Maximum Spread (MS), are employed to quantitively evaluate and compare the effectiveness of the proposed enhanced MOGWO algorithm with three state-of-the-art metaheuristic methods (MOGA, MOAOA , and MOPSO) on 25 benchmark problems. The results achieved through two experimental scenarios indicate that the enhanced MOGWO algorithm outperforms other algorithms in terms of convergence, coverage, and the robust optimal Pareto solution . Finally, transportation paths based on obtained scheduling plans are experimentally corroborated by the mobile robot RAICO (Robot with Artificial Intelligence based Cognition) within a physical model of the intelligent manufacturing environment . The achieved experimental results successfully demonstrate the efficiency of the proposed methodology for optimal multi-objective scheduling of material transport tasks based on a single mobile robotic system .},
  archive      = {J_ASOC},
  author       = {Milica Petrović and Aleksandar Jokić and Zoran Miljković and Zbigniew Kulesza},
  doi          = {10.1016/j.asoc.2022.109784},
  journal      = {Applied Soft Computing},
  pages        = {109784},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-objective scheduling of a single mobile robot based on the grey wolf optimization algorithm},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An elite genetic algorithm for flexible job shop scheduling
problem with extracted grey processing time. <em>ASOC</em>,
<em>131</em>, 109783. (<a
href="https://doi.org/10.1016/j.asoc.2022.109783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a flexible job shop scheduling problem with uncertain processing time. The uncertainty of the processing time is characterized by a generalized grey number. We extract generalized grey numbers from limited information in real-world production, and then extend their operations for scheduling. With generalized grey numbers, the problem is formulated by a mathematical model to minimize the makespan. We develop an elite genetic algorithm for finding excellent solutions. The algorithm employs an elite strategy and neighborhood search method to search for promising individuals on the premise of ensuring population diversity. To assess the performance of the suggested methods, we construct 10 benchmark instances using generalized grey numbers. The results of the experiments demonstrate the effectiveness and competitiveness of the proposed algorithm and characterization.},
  archive      = {J_ASOC},
  author       = {Nanlei Chen and Naiming Xie and Yuquan Wang},
  doi          = {10.1016/j.asoc.2022.109783},
  journal      = {Applied Soft Computing},
  pages        = {109783},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An elite genetic algorithm for flexible job shop scheduling problem with extracted grey processing time},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Risk assessment of complex footbridge based on
dempster–shafer evidence theory using fuzzy matter–element method.
<em>ASOC</em>, <em>131</em>, 109782. (<a
href="https://doi.org/10.1016/j.asoc.2022.109782">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to the landscapes of cities and the requirements of subchannels , the construction of large-span footbridges is complex and extremely risky. These risks may lead to the collapse of a footbridge during construction, resulting in casualties and other catastrophic consequences , delays in projects and significant property losses, and potential safety hazards during follow-up maintenance. At present, China’s urban footbridge construction has not been included in the overall urban construction category, and its risk assessment is static and temporary, mainly relying on the subjective judgment of experts and construction personnel, and the different cases are difficult to learn from each other. To address this issue, a new risk assessment method and a novel system quality management framework are proposed herein. In this system, real-time engineering quality data under 4M1E (Man, Method, Material, Machine, Environment) framework is used to replace traditional risk factors . An improved Dempster–Shafer theory is adopted to effectively combine heterogeneous data from the 4M1E framework and calculate the dynamic total risk index. Finally, the proposed method is verified. The research results show that the new system can predict the risk level of each stage of bridge construction objectively and effectively by using real-time monitoring data, and has high robustness in different project testing.},
  archive      = {J_ASOC},
  author       = {Pengzhen Lu and Yutao Zhou and Ying Wu and Dengguo Li},
  doi          = {10.1016/j.asoc.2022.109782},
  journal      = {Applied Soft Computing},
  pages        = {109782},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Risk assessment of complex footbridge based on Dempster–Shafer evidence theory using fuzzy matter–element method},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust and secured watermarking using ja-fi optimization for
digital image transmission in social media. <em>ASOC</em>, <em>131</em>,
109781. (<a href="https://doi.org/10.1016/j.asoc.2022.109781">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Widespread transmission of digital image in social media has come up with security, confidentiality and authentication issues. Ensuring copyright protection of digital images shared through social media has become inevitable. To address these issues, a robust and secure digital image watermarking scheme using Redundant discrete wavelet transform (RDWT) - Singular value decomposition (SVD) hybrid transform is proposed in this paper. In the proposed scheme, digital image is divided into 4 × 4 non-overlapping blocks, and low information blocks are selected for embedding to ensure higher imperceptibility . For watermark embedding 1-level RDWT is applied on the selected blocks followed by SVD decomposition to make the proposed scheme highly robust against common attacks. One watermark bit is embedded in each left and right singular SVD matrices by adjusting the coefficients. This makes the proposed scheme free from false positive error and achieve high embedding capacity. Before embedding, watermark encryption is done by using a pseudo random key. The pseudo random key is generated adaptively from the cover image by using discrete wavelet transform saliency map , block mean approach and cosine functions . High imperceptibility and robustness is indispensable for the digital images shared through social media. But, these watermarking characteristics are in trade-off. In the proposed scheme, the trade-off is balanced by using optimized scaling factor (embedding strength). Scaling factor is optimized by using the proposed JAYA-Firefly (Ja-Fi) optimization. Experimental results demonstrate that the proposed scheme provides high imperceptibility, robustness, embedding capacity and security. Furthermore, performance comparison with the recent state-of-the-art schemes affirms that the proposed scheme has superior performance.},
  archive      = {J_ASOC},
  author       = {K. Jyothsna Devi and Priyanka Singh and Hiren Kumar Thakkar and Neeraj Kumar},
  doi          = {10.1016/j.asoc.2022.109781},
  journal      = {Applied Soft Computing},
  pages        = {109781},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Robust and secured watermarking using ja-fi optimization for digital image transmission in social media},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cloud service selection based on weighted KD tree nearest
neighbor search. <em>ASOC</em>, <em>131</em>, 109780. (<a
href="https://doi.org/10.1016/j.asoc.2022.109780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The military organization cloud cooperation is a new type of military organization that encapsulates combat resources into services and makes them available as a service. Because of the heterogeneity of the combat resources, the cloud services are different not only in functional properties, but also in non-functional properties. Hence, the idea of cloud service selection, which aims at providing service requester with cloud services that meet their needs for non-functional attributes, has emerged. To this end, this paper proposes a cloud service selection method based on the weighted KD tree nearest neighbor search (WKDTNNS) algorithm for the personalized search of cloud services with different weights in each dimension. Firstly, for the atomic cloud service selection, the KD tree of all atomic cloud services with the quality of service (QoS) as the key is constructed, and WKDTNNS is used to match cloud services for service requests from users. Then, for combined cloud service selection, the KD tree is constructed based on pre-established combined cloud services to select several similar services as seeds, and the WKDTNNS algorithm is applied to optimize the seeds and obtain the final results. Finally, a case study is presented to show the feasibility and effectiveness of the proposed method, the results show that the proposed method could achieve better results than other algorithms, with 26\%–56\% less computation time.},
  archive      = {J_ASOC},
  author       = {Wenhao Bi and Junwen Ma and Xudong Zhu and Weixiang Wang and An Zhang},
  doi          = {10.1016/j.asoc.2022.109780},
  journal      = {Applied Soft Computing},
  pages        = {109780},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Cloud service selection based on weighted KD tree nearest neighbor search},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving online education through automatic learning style
identification using a multi-step architecture with ant colony system
and artificial neural networks. <em>ASOC</em>, <em>131</em>, 109779. (<a
href="https://doi.org/10.1016/j.asoc.2022.109779">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning style is one of the individual differences which play an important role in learning. Being aware of it helps the student to understand their strengths and weaknesses, and the teacher to provide more valuable personalized interventions. Furthermore, learning style-based adaptive educational systems can be designed, which have been shown to increase student satisfaction or learning gain, while reducing the time needed to learn. It is therefore important to have an accurate method for identifying students’ learning styles. Since the traditional approach of filling in dedicated psychological questionnaires has several disadvantages, automatic methods have been proposed, based on investigating student observable behavior in a learning environment. Research done so far generally takes a mono-algorithmic approach to identify learning styles, and the precision rates leave room for improvement. Hence, in this paper we propose a novel hybrid multi-step architecture based on ant colony system and artificial neural networks to increase the precision of learning styles identification. Two different variants are proposed and evaluated with data from 75 students; results show high precision values, outperforming existing automatic approaches for learning style identification. The proposed architecture can be integrated into widely used educational systems (e.g., learning management systems) to provide learners and/or teachers with information about students’ learning styles. In addition, it can be integrated into adaptive educational systems and plugins of learning management systems to automatically identify learning styles and personalize instruction respectively.},
  archive      = {J_ASOC},
  author       = {Jason Bernard and Elvira Popescu and Sabine Graf},
  doi          = {10.1016/j.asoc.2022.109779},
  journal      = {Applied Soft Computing},
  pages        = {109779},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Improving online education through automatic learning style identification using a multi-step architecture with ant colony system and artificial neural networks},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Copy move forgery detection and segmentation using improved
mask region-based convolution network (RCNN). <em>ASOC</em>,
<em>131</em>, 109778. (<a
href="https://doi.org/10.1016/j.asoc.2022.109778">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Copy-move forgery (CMF) is a common image manipulation approach that uses the information from the same sample to manipulate it with the intent of hiding the required content. Several approaches have been designed for the timely detection of CMF; however, accurate identification of manipulated samples is a complicated job due to the similar capturing conditions of the copied content as the patch is taken from the same image. Moreover, the occurrence of several post-processing attacks i.e., noise, blurring, brightness variations, etc. further enhances the difficulties of the detection approaches. In this work, we attempted to cover the limitations of existing methods by proposing a deep learning (DL)-based approach for the accurate detection of CMF. A custom Mask-RCNN model with the DenseNet-41 as the base network is presented which is capable of nominating a better set of image features and presents the complex image transformation effectively. More descriptively, the DenseNet-41 model is used as the base network for deep keypoints extraction which is then localized, segmented, and categorized by the Mask-RCNN model to locate the manipulated area. We have tested the proposed model on three standard databases namely the CoMoFoD, MICC-F2000, and CASIA-v2 databases, and attained a precision of 98.12\%, 99.02\%, and 83.41\%, respectively. We have reported the results for numerous image post-processing attacks and confirmed that the presented work is robust to detect the CMF in the presence of translation, scale variations, rotation, color changes, noise, compression, and blurring in images. We have confirmed through extensive quantitative and qualitative evaluation that the DenseNet-41-based Mask-RCNN model is robust to CMF detection and can assist forensic analyzers to detect forensic manipulations accurately.},
  archive      = {J_ASOC},
  author       = {Tahira Nazir and Marriam Nawaz and Momina Masood and Ali Javed},
  doi          = {10.1016/j.asoc.2022.109778},
  journal      = {Applied Soft Computing},
  pages        = {109778},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Copy move forgery detection and segmentation using improved mask region-based convolution network (RCNN)},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A vector-encirclement-model-based sparrow search algorithm
for engineering optimization and numerical optimization problems.
<em>ASOC</em>, <em>131</em>, 109777. (<a
href="https://doi.org/10.1016/j.asoc.2022.109777">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparrow search algorithm (SSA) is a new global optimization tool with high performance. In order to further improve its global and local search abilities, in this paper, an improved SSA (ISSA) is put forward where the main novelties lie in the producer centralization strategy, the vector encirclement model and the direction selection strategy. The producer centralization strategy is designed to update the position of producer with the hope of improving the global search ability of the producer, while the vector encirclement model and the direction selection strategy are proposed to update the position of scrounger for the purpose of improving the local search ability of scrounger. For the comparison purpose, the performances of the proposed ISSA and the existing excellent algorithms are tested in CEC2017 benchmark functions and 30 real-world constrained optimization problems . The experimental results demonstrate that the proposed ISSA substantially improves the convergence rate, optimization accuracy, stability of the SSA and can solve a wide range of real-world constrained optimization problems successfully with satisfactory performances. Finally, the proposed ISSA is successfully applied in the trajectory optimization of mechanical arms.},
  archive      = {J_ASOC},
  author       = {Jiale Hong and Bo Shen and Jiankai Xue and Anqi Pan},
  doi          = {10.1016/j.asoc.2022.109777},
  journal      = {Applied Soft Computing},
  pages        = {109777},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A vector-encirclement-model-based sparrow search algorithm for engineering optimization and numerical optimization problems},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A deep learning loss based on additive cosine margin:
Application to fashion style and face recognition. <em>ASOC</em>,
<em>131</em>, 109776. (<a
href="https://doi.org/10.1016/j.asoc.2022.109776">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, loss functions based on angular spans improved the performance of deep visual recognition. These losses converted Euclidean cross entropy to angular cross entropy loss. Fashion style recognition deals with the problem of assigning a person’s outfit to a fashion style category. Due to the high similarity between different clothing items and the use of softmax-based loss functions, many of the current methods that address this problem show relatively poor performance and cannot guarantee sufficient inter-class margins in the fashion domain. In this work, we propose an end-to-end method for deep visual recognition by combining a standard CNN architecture with a novel loss function, which we call A dditive C osine M argin L oss (ACML). The proposed function not only projects feature vectors of different classes into different regions of the embedding, but also enforces compactness of the projections within each class. Our experiments were conducted on two public and well-known fashion style recognition datasets FashionStyle14 and HipsterWars, and on the face verification and identification datasets LFW, YTF, and MegaFace. These experiments demonstrate the superiority of the proposed loss function over: (1) existing angular margin-based loss functions (2) state-of-the-art methods for clothing style recognition as well as face analysis tasks.},
  archive      = {J_ASOC},
  author       = {Pendar Alirezazadeh and Fadi Dornaika and Abdelmalik Moujahid},
  doi          = {10.1016/j.asoc.2022.109776},
  journal      = {Applied Soft Computing},
  pages        = {109776},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A deep learning loss based on additive cosine margin: Application to fashion style and face recognition},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multidimensional red fox meta-heuristic for complex
optimization. <em>ASOC</em>, <em>131</em>, 109774. (<a
href="https://doi.org/10.1016/j.asoc.2022.109774">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern applications of computer science need efficient algorithms to solve complex optimization tasks . This necessity is especially well visible in multidimensional problems, where with growing number of optimization variables applied algorithms often loose precision or computing becomes very long. In this paper we present an improved Multidimensional Red Fox Optimization algorithm (MRFO). The initial RFO idea was ameliorated with new approach to local search, with even faster motion of the population toward regions of optimum. Secondly, in the reproduction phase additional mathematical operations addressing the problem of individuals crossing assumed optimization domain were formulated. Compared to RFO, the computational complexity of MRFO grows significantly slower with increasing dimensionality of an optimization task. Numerical results on the well-known COCO BBOB benchmark show that proposed modifications have merit and lead to higher efficacy of MRFO compared to the baseline model . The results are also competitive to DE-best — an efficient Differential Evolution implementation.},
  archive      = {J_ASOC},
  author       = {Mateusz Zaborski and Marcin Woźniak and Jacek Mańdziuk},
  doi          = {10.1016/j.asoc.2022.109774},
  journal      = {Applied Soft Computing},
  pages        = {109774},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multidimensional red fox meta-heuristic for complex optimization},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A personalized classification model using similarity
learning via supervised autoencoder. <em>ASOC</em>, <em>131</em>,
109773. (<a href="https://doi.org/10.1016/j.asoc.2022.109773">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized modeling usually trains a predictive model for a new point using only observations similar to the new point. However, existing methodologies have limitations that do not reflect the target variable in the similarity calculation nor the density of neighbors. Thus, this paper proposes a new personalized modeling method. The proposed methodology transforms the input variables into the latent variables through a supervised autoencoder and calculates the similarity measure between observations in the transformed latent space. The proposed method also considers the neighborhood density around the test point. As a result of the experiments with real datasets, it was found that the proposed method outperformed other benchmark methods and showed the interpretability of the predictive model .},
  archive      = {J_ASOC},
  author       = {Hyunjae Jo and Chi-Hyuck Jun},
  doi          = {10.1016/j.asoc.2022.109773},
  journal      = {Applied Soft Computing},
  pages        = {109773},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A personalized classification model using similarity learning via supervised autoencoder},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Binomial adversarial representation learning for machinery
fault feature extraction and diagnosis. <em>ASOC</em>, <em>131</em>,
109772. (<a href="https://doi.org/10.1016/j.asoc.2022.109772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quality of feature extraction is a key factor in determining the performance of machinery fault diagnosis. The feature extraction of conventional deep learning-based methods has the disadvantages of uncontrollability and low quality. To overcome these disadvantages, we propose a binomial adversarial representation learning (BARL) method. Considering that the binomial distribution can make the representations have smaller intra-class distances (ICDs) and larger cross-class distances (CCDs), the adversarial learning mechanism and autoencoder are combined to learn representations obeying binomial distributions from raw monitoring signals to extract key features containing machine health information. Two case studies on rolling element bearings and gearboxes are carried out to validate the performance of the proposed method. The results show that the diagnosis accuracy of BARL outperformed comparison methods, especially under the condition of insufficient training data. According to quantitative and qualitative analysis, the representations learned by BARL were proven to have smaller ICDs and larger CCDs than the comparison methods, which illustrates the effectiveness of the proposed method.},
  archive      = {J_ASOC},
  author       = {Liang Ma and Yujie Cheng and Yu Ding and Qin Zhao and Zili Wang and Chen Lu},
  doi          = {10.1016/j.asoc.2022.109772},
  journal      = {Applied Soft Computing},
  pages        = {109772},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Binomial adversarial representation learning for machinery fault feature extraction and diagnosis},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-service value chains collaboration for repairperson
resources selection using a many-objective evolutionary algorithm with
adaptive reference vectors. <em>ASOC</em>, <em>131</em>, 109771. (<a
href="https://doi.org/10.1016/j.asoc.2022.109771">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When facing with rising demand for repair services and technical problems, service stations with limited resources suffer a decline in service quality. However, high-quality service is essential for customer retention. The purpose of this paper is to solve the problem by sharing and allocating repairperson resources across multi-service value chains in order to improve the quality of after-sales repair services. Firstly, based on the multi-service value chain collaboration model in a third-party cloud platform environment, a repairperson resources selection model is proposed to balance the multi-service value chain repairperson resources, considering the interests of resource users, resource providers, and the third-party cloud platform simultaneously. Secondly, a many-objective evolutionary algorithm with adaptive reference vectors(EAARV) is designed to solve the resources selection model with an irregular Pareto front . Finally, a case study is conducted to compare the performance of EAARV with seven state-of-the-art evolutionary optimization algorithms for solving many-objective optimization problems and to validate its viability. The experimental results show that EAARV outperforms others in solving the repairperson resources selection problem, and the selection model considering multi-service value chains collaboration is proven to promote the utilization of service resources. The satisfaction rate of repairperson resources with multi-service value chains collaboration is significantly higher than the single-service value chain collaboration. Meanwhile, the parameters of EAARV are analyzed and an ablation experiment is conducted to further evaluate the influence of each component in EAARV on the performance.},
  archive      = {J_ASOC},
  author       = {Pengcheng Liu and Linfu Sun},
  doi          = {10.1016/j.asoc.2022.109771},
  journal      = {Applied Soft Computing},
  pages        = {109771},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-service value chains collaboration for repairperson resources selection using a many-objective evolutionary algorithm with adaptive reference vectors},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Possibility extent and possible alternatives preorder type-2
fuzzy analytical hierarchy process (PE&amp;PAP-AHP) to improve
pharmaceutical r&amp;d productivity. <em>ASOC</em>, <em>131</em>,
109770. (<a href="https://doi.org/10.1016/j.asoc.2022.109770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The major challenges of the pharmaceutical industry are optimizing global expenditure on medicines and maximizing the effectiveness of pharmaceutical products while minimizing the Research and Development (R&amp;D) costs. The commercial success rate mainly causes the decline in R&amp;D productivity across the pharmaceutical industry, the discovery of new drugs, compliance with regulations, and the R&amp;D cycle time. The lack of comprehensive Multi-Criteria Decision Making (MCDM) methodologies leads to ineffective decisions for setting priorities to improve the productivity of pharmaceutical R&amp;D. To increase the precision and accuracy required to improve productivity in Pharmaceutical R&amp;D, in this study, Possibility Extent and Possible Alternatives Preorder Type-2 Fuzzy Analytical Hierarchy Process (PE&amp;PAP-AHP) type-2 fuzzy logic MCDM methodology is developed. Specifically, the type-2 fuzzy geometric mean of PE&amp;PAP-AHP methodology addresses the weakness of traditional methods and correctly reflects the subtle differences in evaluating decision-makers’ opinions. It also constructs fuzzy positive reciprocal matrices, acknowledging the indifference existing among alternatives. PE&amp;PAP-AHP also makes it more accurate during the defuzzification stage of solving the multi-criteria decision-making problem than the type-1 fuzzy approach. It is achieved using two principles: (I) ranking the alternatives by a type-2 fuzzy partial preorder and (II) ranking the alternatives by a type-2 fuzzy total preorder. To compare the results with a type-1 fuzzy, based on the results of the PE&amp;PAP-AHP methodology, the score of the best alternative is 5.2\% more than the second-best alternative, whereas, per the type-1 fuzzy, the score of the best alternative is only 3.6\% more than the second-best alternative.},
  archive      = {J_ASOC},
  author       = {Abbas Safaei and Mohammad T. Khasawneh},
  doi          = {10.1016/j.asoc.2022.109770},
  journal      = {Applied Soft Computing},
  pages        = {109770},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Possibility extent and possible alternatives preorder type-2 fuzzy analytical hierarchy process (PE&amp;PAP-AHP) to improve pharmaceutical R&amp;D productivity},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploiting fuzzy rough mutual information for feature
selection. <em>ASOC</em>, <em>131</em>, 109769. (<a
href="https://doi.org/10.1016/j.asoc.2022.109769">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is one of the important applications of rough set theory . Rough entropy proposed in rough set theory has been applied to feature selection. However, rough entropy is based on binary equivalence relation to divide object sets. Therefore, it applies only to nominal attribute data. To this end, this paper extends rough entropy to fuzzy rough set theory, and then proposes the fuzzy rough entropy in fuzzy approximate space. Fuzzy rough entropy decreases monotonically with the increase of the number of features. On this basis, the concepts of fuzzy joint rough entropy, fuzzy conditional rough entropy and fuzzy rough mutual information are defined. In order to measure the importance of features, inner and outer significance functions are constructed by making use of fuzzy rough mutual information. Furthermore, based on the proposed fuzzy rough entropy model, the corresponding feature selection algorithm is designed. It can directly deal with not only nominal data, but also numerical data and even mixed data. The use of inner and outer heuristic significance functions makes the proposed method select features from two complementary perspectives, so that the reduced feature set has better classification performance. In this method, the redundant features are effectively deleted by the backward redundancy elimination strategy. The proposed algorithm is compared with other algorithms on public data. The experimental results show that the proposed method is adaptive and effective.},
  archive      = {J_ASOC},
  author       = {Zhihong Wang and Hongmei Chen and Zhong Yuan and Xiaoling Yang and Pengfei Zhang and Tianrui Li},
  doi          = {10.1016/j.asoc.2022.109769},
  journal      = {Applied Soft Computing},
  pages        = {109769},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Exploiting fuzzy rough mutual information for feature selection},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sustainable evaluation of energy storage technologies for
wind power generation: A multistage decision support framework under
multi-granular unbalanced hesitant fuzzy linguistic environment.
<em>ASOC</em>, <em>131</em>, 109768. (<a
href="https://doi.org/10.1016/j.asoc.2022.109768">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy storage technology (EST) plays a foundational role for dealing with the intermittency of wind power and accelerating the structural revolution of renewable energy systems . Generally, EST selection is treated as a multiple-criteria group decision-making problem. However, stakeholders are not allowed to express multiple preferences via personalized linguistic distribution assessment and their risk appetites have received less attention in the existing approaches. This study aims at prioritizing ESTs by developing a novel multistage support framework where multi-granular unbalanced hesitant fuzzy linguistic term sets (UHFLTSs) are adopted to depict and quantify stakeholders’ opinions based on personalized semantics and granularities . A sustainable index system is devised in four dimensions (economic, technical, environmental and social) and the extended best-worst method (BWM) under multi-granular UHFLTSs environment is combined with maximum deviation method to determine the hybrid weights of criteria. A novel approach linking multi-granular UHFLTSs with double parameters TOPSIS method integrating risk appetite and optimism preference of stakeholders is further proposed by constructing optimization model, which can simultaneously yield the credible experts’ weights and prioritize the most desirable technology. The application of the proposed framework is demonstrated through an empirical case. Eventually, sensitivity analysis and comparative analysis are implemented to verify the effectiveness and validity of our proposal.},
  archive      = {J_ASOC},
  author       = {Yuanyuan Liang and Yanbing Ju and Peiwu Dong and Luis Martínez and Xiao-Jun Zeng and Ernesto D.R. Santibanez Gonzalez and Mihalis Giannakis and Jinhua Dong and Aihua Wang},
  doi          = {10.1016/j.asoc.2022.109768},
  journal      = {Applied Soft Computing},
  pages        = {109768},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Sustainable evaluation of energy storage technologies for wind power generation: A multistage decision support framework under multi-granular unbalanced hesitant fuzzy linguistic environment},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fixing the inconsistencies of continuous changing operations
in fuzzy spatiotemporal RDF graph. <em>ASOC</em>, <em>131</em>, 109767.
(<a href="https://doi.org/10.1016/j.asoc.2022.109767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy spatiotemporal data models have been used to support spatial and temporal knowledge representation and reasoning in the presence of fuzziness . In the meantime, Resource Description Framework (RDF), the most relevant data representation and exchange standard on Semantic Web, has become a trend for representing fuzzy spatiotemporal data . However, due to the dynamic changes of fuzzy spatiotemporal data, fuzzy spatiotemporal RDF graphs are more likely to violate predefined spatial and temporal constraints than the general RDF graph, which causes data inconsistencies. At present, consistency problems in RDF graphs have been widely studied, but their studies consider only discrete changing operations of fuzzy spatiotemporal data, while researches on consistencies of continuous changing operations are still open issues. In this paper, we study the types of inconsistency caused by continuous changing operations and propose the corresponding fixing rules to the problems of inconsistencies. Then, we propose the corresponding fixing approaches to checking and fixing fuzzy spatiotemporal RDF graphs according to the inconsistent states. Finally, the experimental results show that our proposed algorithms can significantly fix inconsistencies of continuous changing operations in fuzzy spatiotemporal RDF graphs.},
  archive      = {J_ASOC},
  author       = {Luyi Bai and Jinyao Wang and Lin Zhu},
  doi          = {10.1016/j.asoc.2022.109767},
  journal      = {Applied Soft Computing},
  pages        = {109767},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fixing the inconsistencies of continuous changing operations in fuzzy spatiotemporal RDF graph},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SUMLP: A siamese u-shaped MLP-based network for change
detection. <em>ASOC</em>, <em>131</em>, 109766. (<a
href="https://doi.org/10.1016/j.asoc.2022.109766">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote sensing image change detection (CD) technology is an important means to understand the changes of the earth surface. In recent years, many excellent CD methods based on convolutional neural networks (CNN) have been proposed. Although these methods have achieved good results, CD is still a very challenging task. Recently, many visual algorithms based on multi-layer perceptron (MLP) have been proposed and achieved similar or even better results than CNN-based algorithms in many visual fields. Inspired by the success of these MLP-based algorithms, in this paper we propose a siamese U-shaped MLP-based CD network named SUMLP. First, SUMLP uses CycleMLP block as the basic unit of the network and combines the characteristics of the CD task to construct a MLP-based CD network with siamese U-shaped structure. Secondly, to better optimize the CD network, we design a new loss function, weighted cosine cross entropy (WCCE) loss. WCCE loss has two advantages: 1. WCCE loss gives different weights to the changed samples and the unchanged samples, which can cope with the data imbalance problem in the CD task; 2. WCCE loss uses cosine margin to increase the inter class distance and the intra class compactness, so as to better distinguish the changed samples from the unchanged samples. For comprehensively verifying the validity of our proposed method, we carried out many experiments on three public CD datasets: LEVIR-CD dataset, CDD dataset and WHU-CD dataset. On these datasets, SUMLP’s F 1 − s c o r e F1−score are at least 0.33\%, 1.41\% and 3.56\% higher than the other relevant CD methods respectively.},
  archive      = {J_ASOC},
  author       = {Cui Zhang and Liejun Wang and Shuli Cheng and Yongming Li},
  doi          = {10.1016/j.asoc.2022.109766},
  journal      = {Applied Soft Computing},
  pages        = {109766},
  shortjournal = {Appl. Soft. Comput.},
  title        = {SUMLP: A siamese U-shaped MLP-based network for change detection},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An attention-based stacked BiLSTM framework for predicting
remaining useful life of rolling bearings. <em>ASOC</em>, <em>131</em>,
109765. (<a href="https://doi.org/10.1016/j.asoc.2022.109765">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven prognostic techniques have been widely implemented to accurately predicting the remaining useful life (RUL) of high-speed bearings. Accurate RUL estimation attributes to determining underlying relationship between bearing degradation progression and current health status. To achieve this, effective feature compression and optimal feature selection are significant challenges to be overcome. Therefore, in this paper a framework is developed which utilizes the ‘ Stacked Bi-directional Long Short Term Memory ’ (SBiLSTM) with attention mechanism (A-SBiLSTM) to determine the underlying relationship between the health status and RUL of bearing. Bi-directional LSTM is capable of processing the past and the future states simultaneously thereby mining the useful degradation information from time-series data. Additionally, fitness analysis is carried out using feature ranking metrics to select features highly correlated with bearing degradation. The effectiveness and feasibility of the proposed methodology are experimentally validated and generalized on dataset from PRONOSTIA platform. The comparison results based on root mean square error (RMSE), and mean absolute error (MAE) achieved superior performance compared to state-of-art methods. The experimental results revealed that the A-SBiLSTM with attention mechanism and fitness analysis achieved superior performance than other advanced methods for accurate RUL prediction.},
  archive      = {J_ASOC},
  author       = {Maan Singh Rathore and S.P. Harsha},
  doi          = {10.1016/j.asoc.2022.109765},
  journal      = {Applied Soft Computing},
  pages        = {109765},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An attention-based stacked BiLSTM framework for predicting remaining useful life of rolling bearings},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Manufacturing project scheduling considering human factors
to minimize total cost and carbon footprints. <em>ASOC</em>,
<em>131</em>, 109764. (<a
href="https://doi.org/10.1016/j.asoc.2022.109764">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Make-to-order (MTO) or engineer-to-order (ETO) systems produce complex and highly customized products and, therefore, there is a need for advanced project scheduling approaches for production planning in these systems. An important aspect of production scheduling is the assignment of operators with specific human factors to activities in a manufacturing project. This assignment impacts the duration of the activities, the total wage cost of the project and even the energy consumption during production. With increasing concern regarding low-carbon production in manufacturing, the human factors of operators thus cannot be ignored in the decision-making process in production project scheduling. In this context, our study considers an extension of the well-known resource-constrained project scheduling problem for manufacturing. This problem is represented as a bi-objective optimization problem with the conjoint objectives of minimizing the total cost of the project and its carbon footprint. Two variants of a genetic algorithm-based memetic algorithm (MA) are proposed to solve this problem and a set of artificial, realistic project instances are generated to evaluate the proposed solution procedure. Experimental results show that the proposed MA outperforms the well-known non-dominated sorting genetic algorithms (NSGA-II and NSGA-III) and its enhanced approach (ENSGA-II) in terms of both solution quality and computational efficiency. The experiments are conducted on both real-life case study data from an MTO project in the furniture industry and a large set of artificial data instances. Our research allows project managers to select appropriate operators to execute activities based on human factors, wage and power consumption with the objectives of minimum total cost and carbon footprint.},
  archive      = {J_ASOC},
  author       = {Humyun Fuad Rahman and Tom Servranckx and Ripon K. Chakrabortty and Mario Vanhoucke and Sondoss El Sawah},
  doi          = {10.1016/j.asoc.2022.109764},
  journal      = {Applied Soft Computing},
  pages        = {109764},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Manufacturing project scheduling considering human factors to minimize total cost and carbon footprints},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A bearing prognosis framework based on deep wavelet extreme
learning machine and particle filtering. <em>ASOC</em>, <em>131</em>,
109763. (<a href="https://doi.org/10.1016/j.asoc.2022.109763">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bearing prognosis plays an active role in preventing excessive or inadequate maintenance for major equipment. This paper develops a hybrid prognosis framework for bearings based on time-varying 3 σ σ criterion, deep wavelet extreme learning machine (DWELM) and particle filtering (PF). To be specific, a time-varying 3 σ σ criterion is proposed for bearing health monitoring to detect the fault occurrence time (FOT). Then, DWELM is established to evaluate the bearing performance degradation in degradation stage and construct a linear trend health indicator (HI) in a supervised way, termed as DWELM-HI. Compared to the original ELM, DWELM is equipped with more powerful feature representation and nonlinear approximation capabilities to map various nonlinear degradation trend to linear trend by deep structure and wavelet kernel. Additionally, a linear model is adopted to forecast the time evolution of the DWELM-HI. PF is collaboratively utilized to reduce random errors and estimate the probability of residual useful life (RUL). Finally, bearing prognosis is fully conducted on publicly available XJTU-SY bearing dataset to illustrate the effectiveness of the proposed method. The results show that the proposed method can detect an appropriate FOT and accurately estimate the RUL. Moreover, comparisons with other competing methods show that it performs better in bearing prognosis application.},
  archive      = {J_ASOC},
  author       = {Lei Wang and Hongrui Cao and Yang Fu},
  doi          = {10.1016/j.asoc.2022.109763},
  journal      = {Applied Soft Computing},
  pages        = {109763},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A bearing prognosis framework based on deep wavelet extreme learning machine and particle filtering},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A parallel differential evolution with cooperative
multi-search strategy for sizing truss optimization. <em>ASOC</em>,
<em>131</em>, 109762. (<a
href="https://doi.org/10.1016/j.asoc.2022.109762">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing complexity of modern structural design problems requires optimization algorithms to have an acceptable completion time regarding the huge number of design variables. This paper proposes a parallel differential evolution with cooperative multi-search strategies (PDECMS) and the implementation with Compute Unified Device Architecture (CUDA) for improving execution time by leveraging the Graphical Processing Unit (GPU). Three sub-populations with dedicated mutation schemes are used to establish island models, which start searching at distinct initial points. As the evolution process begins, the exchange of knowledge between islands is synchronously conducted via the migration of elite individuals. The PDECMS is used to solve five discrete sizing optimization problems of a truss structure to demonstrate the achieved solution quality, convergence speed, and scalability. It has been found that the computing time of PDECMS was at least two times faster than its serial implementation for the large population size and the attained solution quality was generally agreeable with other methods despite the sacrifice for the enhancement of performance. Numerical results reveal that the accomplishment of optimal solutions with fewer iterations and a shorter time comes from the cooperative multi-search strategy and the use of GPU. This outcome, therefore, shows that the PDECMS is capable of optimally solving multi-variable problems with a large search space.},
  archive      = {J_ASOC},
  author       = {The-Viet Ha and Quoc-Hung Nguyen and Tan-Tien Nguyen},
  doi          = {10.1016/j.asoc.2022.109762},
  journal      = {Applied Soft Computing},
  pages        = {109762},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A parallel differential evolution with cooperative multi-search strategy for sizing truss optimization},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on deep learning applications in wheat phenotyping.
<em>ASOC</em>, <em>131</em>, 109761. (<a
href="https://doi.org/10.1016/j.asoc.2022.109761">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precision farming has become a hot research topic in recent years due to the advancement of sensing technologies, increased computer performance, and advanced deep learning algorithms. As a result, several outstanding studies on deep learning applications to high-throughput phenotyping of wheat, one of the most demanding cereal crops on the planet, have been published. This paper aims to conduct a survey of publications that have used deep learning techniques to address various challenges in wheat production. To accomplish this, we propose an ontology-based knowledge management system that is specifically designed to highlight the publications’ objectives, preprocessing algorithms, deep learning models, frameworks, datasets, and results. The presented ontology is intended to serve as a robust tool for future research in wheat high-throughput phenotyping. Additionally, we compare the performance of deep learning algorithms to that of long-established methods in this field. Compared to traditional machine learning techniques , this study demonstrates that deep learning algorithms provide a more robust, accurate, and cost-effective way of measuring wheat traits.},
  archive      = {J_ASOC},
  author       = {Amirhossein Zaji and Zheng Liu and Gaozhi Xiao and Jatinder S. Sangha and Yuefeng Ruan},
  doi          = {10.1016/j.asoc.2022.109761},
  journal      = {Applied Soft Computing},
  pages        = {109761},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A survey on deep learning applications in wheat phenotyping},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Assessing the embodied CO2 emissions of ICT industry and its
mitigation pathways under sustainable development: A global case.
<em>ASOC</em>, <em>131</em>, 109760. (<a
href="https://doi.org/10.1016/j.asoc.2022.109760">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering the rapid development of the global digital industry and the need for sustainable development and climate change, this paper explores the global ICT-embodied CO 2 emissions changes and intensities from 2000 to 2014, and the driving factors behind ICT-embodied CO 2 emissions changes in 15 countries by using the multi-regional input–output (MRIO) method and structural decomposition analysis (SDA) method. We also use Monte Carlo simulations to forecast the ICT-embodied CO 2 emissions from 2020 to 2050. The results indicate that: (1) After 2009, global ICT’s embodied CO 2 emissions first decline and then increase, and the sector that manufactures computer, electronic, and optical products account for 82.83\% of the global ICT’s embodied CO 2 emissions in 2014; (2) judging from the emission-reduction trends of various countries, CO 2 emissions intensity factors are the main drivers restricting the growth of embodied CO 2 emissions in the ICT sector, while final demand composition factors play a significant role in promoting the increase of ICT’s embodied CO 2 emissions; (3) Australia, Germany , and Indonesia contribute to an increase in ICT’s embodied CO 2 emissions due to sectoral heterogeneity, while Canada, China, Germany , and South Korea have contributed to an increase in ICT’s embodied CO 2 emissions in terms of regional heterogeneity; (4) the drivers have also changed significantly with the impact of the financial crisis; and (5) with the current pattern of development, it is difficult to reach the peak of ICT-embodied CO 2 emissions in most countries before 2050. This paper also provides feasible implementation plans for carbon mitigation in the global ICT industry.},
  archive      = {J_ASOC},
  author       = {Kangyin Dong and Jianda Wang and Farhad Taghizadeh-Hesary},
  doi          = {10.1016/j.asoc.2022.109760},
  journal      = {Applied Soft Computing},
  pages        = {109760},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Assessing the embodied CO2 emissions of ICT industry and its mitigation pathways under sustainable development: A global case},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A bi-objective salp swarm algorithm with sine cosine
operator for resource constrained multi-manned disassembly line
balancing problem. <em>ASOC</em>, <em>131</em>, 109759. (<a
href="https://doi.org/10.1016/j.asoc.2022.109759">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the current popularity of product customization and unsuitability of single-person disassembly lines for large-size products, as well as considering the needs for supporting resources (machines/tools), this paper investigates the resource-constraint mixed-model multi-manned disassembly line balancing problem (RCMMDLBP), which needs to achieve task-worker-workstation assignment and sequencing under the constraints of AND/OR precedence relationship, worker idle, resource availability, and resource quantity limitation at the same time. Besides, the cycle time and the overall number of workers are considered as dual objectives to provide flexible application scenarios for managers. To solve this problem, a mixed-integer programming model is established and the epsilon constraint method is used to obtain the exact solutions for small-scale cases. Simultaneously, due to the NP-hard nature, a multi-objective optimization algorithm called self-adaptive salp swarm algorithm with sine cosine algorithm (SSSASCA) is proposed. The encoding and decoding are specifically designed with repairing and simulated annealing strategies corresponding to the properties of RCMMDLBP. Moreover, Cauchy mutation and Logistic chaotic mapping strategies are introduced to increase the population diversity and help to jump out of local optimum. Finally, computational experiments are performed to show the superiority of the SSSASCA by comparing it with MSSA, NSGAII , and MAOS. The results show that SSSASCA stably achieves better Pareto front solutions in 59/60 RCMMDLBP instances under the four evaluation indexes of NS, DPO , IGD, and HV. In addition, a specific example is applied for the discussion of managerial applications and to illustrate the practicality of the proposed model and solution method.},
  archive      = {J_ASOC},
  author       = {Binghai Zhou and Jingrao Bian},
  doi          = {10.1016/j.asoc.2022.109759},
  journal      = {Applied Soft Computing},
  pages        = {109759},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A bi-objective salp swarm algorithm with sine cosine operator for resource constrained multi-manned disassembly line balancing problem},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reinforcement learning based coarse-to-fine search for the
maximum k-plex problem. <em>ASOC</em>, <em>131</em>, 109758. (<a
href="https://doi.org/10.1016/j.asoc.2022.109758">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The maximum k k -plex problem is a computationally challenging problem, which emerged from graph-theoretic social network studies in the context of community detection. As a relaxation of the traditional maximum clique problem, intended to identify cohesive structures within a graph that are not necessarily fully connected, the aim of this problem is to find the largest set of vertices in a graph in which all vertices are not adjacent to at most k k vertices within this set. This paper introduces an effective hybrid local search algorithm for solving the maximum k k -plex problem that combines a stochastic local search method and a reinforcement learning strategy. The proposed approach includes a number of distinguishing features, including: a new coarse-to-fine strategy to balance the search process, a distance-and-quality reward for actions, and a parameter control mechanism based on reinforcement learning. We conduct a computational analysis of the key components of the proposed algorithm, assessing their impact on the overall performance. Extensive experiments for the maximum k k -plex problem ( k = 2 , 3 , 4 , 5 k=2, 3, 4, 5 ) on 80 benchmark instances from the second DIMACS Challenge demonstrate that the proposed approach competes favourably with the state-of-the-art algorithms from the literature.},
  archive      = {J_ASOC},
  author       = {Yan Jin and John H. Drake and Kun He and Una Benlic},
  doi          = {10.1016/j.asoc.2022.109758},
  journal      = {Applied Soft Computing},
  pages        = {109758},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Reinforcement learning based coarse-to-fine search for the maximum k-plex problem},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Complementary ensemble empirical mode decomposition and
independent recurrent neural network model for predicting air quality
index. <em>ASOC</em>, <em>131</em>, 109757. (<a
href="https://doi.org/10.1016/j.asoc.2022.109757">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Establishing a scientific and effective air quality prediction model is of great scientific value and practical significance for protecting people’s health and promoting social harmony and stability. However, existing prediction models have certain shortcomings in various aspects. To address these shortcomings, this paper combines different methods to achieve better prediction accuracy. Outlier analysis is done for air quality index (AQI) using an isolation forest algorithm. An air quality prediction system that consists of data preprocessing , optimization, prediction, and modification is established. The complementary ensemble empirical mode decomposition (CEEMD), modified particle swarm optimization (MPSO) algorithm, independent recurrent neural network (IndRNN), and nonlinear correction strategy are employed for the prediction. We select five cities with different AQI as the experiment sites, and three experiments are designed to test the accuracy of the prediction model. The results reveal that (1) by using CEEMD data decomposition technology to deal with the non-stationarity and nonlinearity of the original data, the prediction accuracy of the original cyclic neural network model can be improved by about 15\%. (2) The prediction system with the CEEMD-MPSO-IndRNN model as the core prediction module and with a nonlinear error correction strategy has good scalability and robustness for air quality prediction. (3) The performance of the air quality prediction model constructed with systematic thought is better than other comparable models, and it can effectively predict the time series data of different cities and frequencies.},
  archive      = {J_ASOC},
  author       = {Shuxing Chen and Lingfeng Zheng},
  doi          = {10.1016/j.asoc.2022.109757},
  journal      = {Applied Soft Computing},
  pages        = {109757},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Complementary ensemble empirical mode decomposition and independent recurrent neural network model for predicting air quality index},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parallel deep learning with a hybrid BP-PSO framework for
feature extraction and malware classification. <em>ASOC</em>,
<em>131</em>, 109756. (<a
href="https://doi.org/10.1016/j.asoc.2022.109756">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malicious software (Malware) is a key threat to security of digital networks and systems. While traditional machine learning methods have been widely used for malware detection, deep learning (DL) has recently emerged as a promising methodology to detect and classify different malware variants. As the DL training algorithm is oriented on gradient descent optimization, i.e. the Backpropagation (BP) algorithm, several shortcomings are encountered, e.g., local suboptimal solutions and high computational cost. We develop a new DL-based framework for malware detection. In this regard, we introduce a hybrid DL optimization method by exploiting the integration of BP and Particle Swarm Optimization (PSO) algorithms to provide optimal solutions for malware detection. Many hybrid DL optimization methods in the literature are not implemented under a parallel computing setup. In this paper, we develop an efficient distributed parallel computing framework for implementing the proposed DL-based method to improve efficiency and scalability. The experimental results on several benchmark data sets indicate efficacy of the proposed solution in malware detection, which significantly outperforms other machine learning methods in terms of effectiveness, efficiency and scalability.},
  archive      = {J_ASOC},
  author       = {Mohammed Nasser Al-Andoli and Shing Chiang Tan and Kok Swee Sim and Chee Peng Lim and Pey Yun Goh},
  doi          = {10.1016/j.asoc.2022.109756},
  journal      = {Applied Soft Computing},
  pages        = {109756},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Parallel deep learning with a hybrid BP-PSO framework for feature extraction and malware classification},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An adaptive-learning-based genetic algorithm for
collaborative scheduling of distributed operating rooms. <em>ASOC</em>,
<em>131</em>, 109755. (<a
href="https://doi.org/10.1016/j.asoc.2022.109755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve surgical services and hospital performance, collaborative operating room planning and scheduling across a network of hospitals has recently emerged as a new challenge in both healthcare industry and academic community. The paper considers a novel distributed operating room scheduling problem (DORSP), in which elective patients planned on a given day are scheduled for surgeries in the distributed operating rooms of collaborative hospitals. Since hospitals are different in terms of specialization and medical expertise , some complicated surgeries in this problem can only be performed in a subset of collaborative hospitals. Based on the similarities between healthcare delivery systems and production systems, DORSP is modelled as a distributed two-stage no-wait hybrid flow shop scheduling problem with factory eligibility. To deal with the NP-hardness of DORSP, an adaptive-learning-based genetic algorithm (ALBGA) is proposed to generate collaborative surgery schedules. In addition to traditional genetic operators, ALBGA also applies an adaptive learning operator to enhance the search ability by mimicking human learning behaviours. Computational results on both small-sized and large-sized test problems show that ALBGA is competitive among the compared algorithms.},
  archive      = {J_ASOC},
  author       = {Kai Wang and Chunxia Yu and Hu Qin},
  doi          = {10.1016/j.asoc.2022.109755},
  journal      = {Applied Soft Computing},
  pages        = {109755},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An adaptive-learning-based genetic algorithm for collaborative scheduling of distributed operating rooms},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Classification of the wind turbine components based on
importance degrees: A three-way decision perspective. <em>ASOC</em>,
<em>131</em>, 109754. (<a
href="https://doi.org/10.1016/j.asoc.2022.109754">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bad working environment and various complex influencing factors lead to the high failure rate of a wind turbine . It is necessary to decide on a reasonable maintenance strategy for wind turbines. The classification of wind turbine components based on their importance degrees can identify the components which have an important impact on the reliability and maintenance of wind turbines. However, the traditional multi-criteria decision-making method can only provide the importance ranking of components, rather than the importance classification of components. The emergence of the three-way decision (TWD) method makes up for this deficiency. Then we classify the importance degrees of components by the TWD method. Firstly, the decision-theoretic rough sets are introduced into the uncertain linguistic setting to construct uncertain linguistic decision-theoretic rough sets. Secondly, the weights of experts are attained based on the consistency degree of loss functions. Thirdly, conditional probability is attained by the evaluation based on distance from the average solution method. And the classification of wind turbine components is derived based on the minimum-loss principle. Finally, a case study about the classification of the wind turbine components based on importance degrees is employed to certify the practicability of our designed method. The proposed model extends both the theory and practice of TWD and offers a classification helpful to make maintenance strategies for reducing the risk of component failure.},
  archive      = {J_ASOC},
  author       = {Xiang Li and Zeshui Xu and Hai Wang and Enrique Herrera-Viedma and Osman Taylan},
  doi          = {10.1016/j.asoc.2022.109754},
  journal      = {Applied Soft Computing},
  pages        = {109754},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Classification of the wind turbine components based on importance degrees: A three-way decision perspective},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep reinforcement learning based dynamic optimization of
bus timetable. <em>ASOC</em>, <em>131</em>, 109752. (<a
href="https://doi.org/10.1016/j.asoc.2022.109752">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bus timetable optimization is a key issue to reduce operational cost of bus company and improve the transit service quality. Existing methods optimize the timetable offline. However, in practice, the short-term passenger flow may change dramatically from time to time. Timetables generated offline cannot be adjusted in real time to handle the changed passenger flow. In this paper, we propose a Deep Reinforcement Learning based bus Timetable dynamic Optimization method (DRL-TO). In DRL-TO, the problem of bus timetable optimization is formulated as a Markov Decision Process (MDP). A Deep Q-Network (DQN) is applied as the agent to decide whether a bus departs at each minute during the service period. Therefore, departure intervals of bus services are determined in real time in accordance with passenger demand. We identify several new and useful state features for the DQN agent, including the load factor, the carrying capacity utilization rate, passengers’ waiting time and the number of stranded passengers. Considering the interests of both the bus company and passengers, a reward function is designed, which includes metrics of full load rate, empty load rate, passengers’ waiting time, and the number of stranded passengers. Experiments demonstrate that, in comparison to the timetable generated by offline optimization approaches and the manual method, DRL-TO can dynamically determine the departure intervals based on the real-time passenger flow, and generate a timetable with less departure time points (i.e., operational cost) and shorter passengers’ waiting time (i.e., higher quality of service).},
  archive      = {J_ASOC},
  author       = {Guanqun Ai and Xingquan Zuo and Gang Chen and Binglin Wu},
  doi          = {10.1016/j.asoc.2022.109752},
  journal      = {Applied Soft Computing},
  pages        = {109752},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Deep reinforcement learning based dynamic optimization of bus timetable},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive local landscape feature vector for problem
classification and algorithm selection. <em>ASOC</em>, <em>131</em>,
109751. (<a href="https://doi.org/10.1016/j.asoc.2022.109751">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fitness landscape analysis is a data-driven technique to study the relationship between problem characteristics and algorithm performance by characterizing the landscape features in the search space of an optimization problem . However, most of the existing landscape features still face poor in classifying the problems and low accuracy in selecting the most appropriate algorithm for a given problem. In this study, an adaptive local landscape feature vector (ALLFV) is proposed for problem classification and algorithm selection . Specifically, an adaptive discretization scheme is designed to calculate adaptive related parameters and construct the sequence between the fitness values of the search point and its nearest neighbors. By considering the frequencies of the same sequence values, the spatial structural information for the fitness landscape is computed as a feature vector according to the feature vector calculation mechanism. The experimental results tested on various problems demonstrate the excellence of ALLFV in terms of accuracy, stability, and computational cost. Moreover, ALLFV has shown superior practicality and reliability in the application of algorithm selection for numerical optimization problems. Consequently, ALLFV is well suited as an alternative for problem classification, as well as algorithm selection under excessive candidate optimization algorithms and limited prior knowledge of problems.},
  archive      = {J_ASOC},
  author       = {Yaxin Li and Jing Liang and Kunjie Yu and Ke Chen and Yinan Guo and Caitong Yue and Leiyu Zhang},
  doi          = {10.1016/j.asoc.2022.109751},
  journal      = {Applied Soft Computing},
  pages        = {109751},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Adaptive local landscape feature vector for problem classification and algorithm selection},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Forecasting on covid-19 infection waves using a rough set
filter driven moving average models. <em>ASOC</em>, <em>131</em>,
109750. (<a href="https://doi.org/10.1016/j.asoc.2022.109750">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pandemic outbreak of severe acute respiratory syndrome caused by the Coronavirus 2 disease in 2019, also known as SARS-COV-2 and COVID-19, has claimed over 5.6 million lives till now. The highly infectious nature of the Covid-19 virus has resulted into multiple massive upsurges in counts of new infections termed as ‘waves.’ These waves consist of numerous rising and falling counts of Covid-19 infection cases with changing dates that confuse analysts and researchers. Due to this confusion, the detection of emergence or drop of Covid waves is currently a subject of intensive research. Hence, we propose an algorithmic framework to forecast the upcoming details of Covid-19 infection waves for a region. The framework consists of a displaced double moving average ( δ δ DMA) algorithm for forecasting the start, rise, fall, and end of a Covid-19 wave. The forecast is generated by detection of potential dates with specific counts called ‘markers.’ This detection of markers is guided by decision rules generated through rough set theory . We also propose a novel ‘corrected moving average’ ( χ χ SMA) technique to forecast the upcoming count of new infections in a region. We implement our proposed framework on a database of Covid-19 infection specifics fetched from 12 countries, namely: Argentina, Colombia, New Zealand, Australia, Cuba, Jamaica, Belgium, Croatia, Libya, Kenya, Iran, and Myanmar. The database consists of day-wise time series of new and total infection counts from the date of first case till 31st January 2022 in each of the countries mentioned above. The δ δ DMA algorithm outperforms other baseline techniques in forecasting the rise and fall of Covid-19 waves with a forecast precision of 94.08\%. The χ χ SMA algorithm also surpasses its counterparts in predicting the counts of new Covid-19 infections for the next day with the least mean absolute percentage error (MAPE) of 36.65\%. Our proposed framework can be deployed to forecast the upcoming trends and counts of new Covid-19 infection cases under a minimum observation window of 7 days with high accuracy. With no perceptible impact of countermeasures on the pandemic until now, these forecasts will prove supportive to the administration and medical bodies in scaling and allotment of medical infrastructure and healthcare facilities .},
  archive      = {J_ASOC},
  author       = {Saurabh Ranjan Srivastava and Yogesh Kumar Meena and Girdhari Singh},
  doi          = {10.1016/j.asoc.2022.109750},
  journal      = {Applied Soft Computing},
  pages        = {109750},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Forecasting on covid-19 infection waves using a rough set filter driven moving average models},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Task assignment for hybrid scenarios in spatial
crowdsourcing: A q-learning-based approach. <em>ASOC</em>, <em>131</em>,
109749. (<a href="https://doi.org/10.1016/j.asoc.2022.109749">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing popularity of smart devices and spatio-temporal crowdsourcing, a new data gathering and perception approach combined with edge computing have made exceptional development in solving crowdsourcing problems. As a basic component of the spatio-temporal crowdsourcing system, task assignment seeks to arrange suitable workers for tasks. Existing research is mostly concerned with dynamic and static circumstances. On the other hand, dynamic scenarios cannot meet the advanced understanding of workers who arrive dynamically, and static scenarios cannot match the dynamic requirements of real situations. This paper provides a framework for Latency Time Based Task Assignment with Online and Offline (LTB-TAOO). This framework dynamically receives workers and tasks from the perspective of full assignment process. The static assignment method is utilized throughout the job assignment algorithm. A Q-Learning Based Task Algorithm for LTC (QL-LTC) algorithm is proposed to address the problem of latency time compute (LTC) in the LTB-TAOO framework. In order to improve the efficiency and accuracy of the LTB-TAOO framework, a new state transition Q-Learning based task assignment for LTC (NSQL-LTC) algorithm is applied after optimizing the state transition matrix and reward mechanism. Finally, the proposed methods’ effectiveness and efficiency are evaluated by conducting extensive experiments based on real datasets.},
  archive      = {J_ASOC},
  author       = {Mingze Wang and Yingjie Wang and Akshita Maradapu Vera Venkata Sai and Zhaowei Liu and Yang Gao and Xiangrong Tong and Zhipeng Cai},
  doi          = {10.1016/j.asoc.2022.109749},
  journal      = {Applied Soft Computing},
  pages        = {109749},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Task assignment for hybrid scenarios in spatial crowdsourcing: A Q-learning-based approach},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Combining PPO and incremental conductance for MPPT under
dynamic shading and temperature. <em>ASOC</em>, <em>131</em>, 109748.
(<a href="https://doi.org/10.1016/j.asoc.2022.109748">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As solar generation gains an increased importance in a smart grid, an efficient control of a photovoltaic (PV) array has to be considered. However, energy efficiency of a PV array greatly depends on environmental conditions, such as uneven shading, solar irradiance and temperature. Maximum power point tracking (MPPT) algorithms aim to dynamically find an optimal operation voltage in order to compensate for changes in the environment, as well as degradation of solar panels. Besides generating a maximum amount of power, an MPPT controller aims for stability in order to avoid additional losses. Reinforcement Learning (RL) is a flexible training method that can produce a controller for a complex problem without a detailed prior knowledge of the environment. In this work we propose an approach that combines an optimized neural network, trained through deep reinforcement learning (DRL), with a classical closed-loop control. Experimental results suggest that the proposed approach outperforms a recently proposed DRL network both in terms of efficiency and stability. A compact and discrete version of the proposed controller is also evaluated and shown to further increase performance. The implemented algorithms and the RL simulation environment are made available in an open-source repository.},
  archive      = {J_ASOC},
  author       = {Sérgio F. Chevtchenko and Eduardo J. Barbosa and Marcelo C. Cavalcanti and Gustavo M.S. Azevedo and Teresa B. Ludermir},
  doi          = {10.1016/j.asoc.2022.109748},
  journal      = {Applied Soft Computing},
  pages        = {109748},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Combining PPO and incremental conductance for MPPT under dynamic shading and temperature},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neighborhood rough set based ensemble feature selection with
cross-class sample granulation. <em>ASOC</em>, <em>131</em>, 109747. (<a
href="https://doi.org/10.1016/j.asoc.2022.109747">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploring feature significance associated with label is a fundamental task in the architecture of feature selection. Nevertheless, most of the existing schemes are limited by the global feature significance over the entire universe. It follows that some specific characteristics of features implied in sample subspaces may be overlapped. To fill such a gap, a novel ensemble feature selection with cross-class sample granulation is developed. Our method explicitly involves two main phases: (1) cross-class sample granulation — data is separated into multiple granules which are generated by querying the locations of samples in their respective classes, so as to provide local bases; (2) ensemble feature selection — localized evaluations of feature significance are integrated which are induced by leveraging multiple homogeneous fine-granularity measures from those bases, so as to select qualified features. To validate the effectiveness of our proposed method, it is compared with several well-established feature selection schemes in CART, KNN and SVM classification performance. Experimental results on 20 UCI data sets demonstrate that our method is superior as it yields higher accuracy with satisfactory elapsed time.},
  archive      = {J_ASOC},
  author       = {Keyu Liu and Tianrui Li and Xibei Yang and Xin Yang and Dun Liu},
  doi          = {10.1016/j.asoc.2022.109747},
  journal      = {Applied Soft Computing},
  pages        = {109747},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Neighborhood rough set based ensemble feature selection with cross-class sample granulation},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-resources co-scheduling optimization for home
healthcare services under the constraints of service time windows and
green transportation. <em>ASOC</em>, <em>131</em>, 109746. (<a
href="https://doi.org/10.1016/j.asoc.2022.109746">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resource sharing among different communities and medical centers is an effective method to solve the inefficiency of healthcare resource use and unequal distribution of medical resources across regions. This study aims at optimizing the resource arrangement in home health care services by multi-resources co-scheduling. Specifically, we consider several important constraints including cross-distinct income in the constructed model. A Multi-Regions Tabu Search Algorithm is proposed to realize co-scheduling of multi-medical-staff in different communities to improve the calculation speed and obtain a better solution. We take the PuTuo district in Shanghai as an example for empirical analysis to verify the effectiveness of the proposed model and algorithm. Sensitivity analysis is then conducted by changing the service capabilities of communities. Results indicate that the total cost can be effectively reduced by multi-resources co-scheduling under different service capacities. However, the levels of cost reduction are distinct in different situations.},
  archive      = {J_ASOC},
  author       = {Gang Du and Yao Tian and Xiaoling Ouyang},
  doi          = {10.1016/j.asoc.2022.109746},
  journal      = {Applied Soft Computing},
  pages        = {109746},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-resources co-scheduling optimization for home healthcare services under the constraints of service time windows and green transportation},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-supervised reinforcement learning with dual-reward for
knowledge-aware recommendation. <em>ASOC</em>, <em>131</em>, 109745. (<a
href="https://doi.org/10.1016/j.asoc.2022.109745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the recommendation accuracy and offer explanations for recommendations, Reinforcement Learning (RL) has been applied to path reasoning over knowledge graphs. However, in recommendation tasks, most existing RL methods learn the path-finding policy using only a short-term or single reward, leading to a local optimum and losing some potential paths. To address these issues, we propose a Self-Supervised Reinforcement Learning (SSRL) framework combined with dual-reward for knowledge-aware recommendation reasoning over knowledge graphs. Then, we improve Actor–Critic algorithm by using a dual-reward driven strategy, which combines short-term reward with long-term incremental evaluation . The improved algorithm helps the policy guide path reasoning in an overall situation. In addition, to find the most potential paths, in the improved Actor–Critic algorithm, a loss constraint of each sample is used as a reinforced signal to update the gradients. With some improvements against baselines, experimental results demonstrate the effectiveness of our framework.},
  archive      = {J_ASOC},
  author       = {Wei Zhang and Yuanguo Lin and Yong Liu and Huanyu You and Pengcheng Wu and Fan Lin and Xiuze Zhou},
  doi          = {10.1016/j.asoc.2022.109745},
  journal      = {Applied Soft Computing},
  pages        = {109745},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Self-supervised reinforcement learning with dual-reward for knowledge-aware recommendation},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Session-based recommendation: Learning multi-dimension
interests via a multi-head attention graph neural network.
<em>ASOC</em>, <em>131</em>, 109744. (<a
href="https://doi.org/10.1016/j.asoc.2022.109744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a recent study, it was shown that, with batch training of a graph neural network , it is possible to recommend suitable items for users. Although the method has obtained item embedding and considered the complex transitions between items, there is no multi-dimensional focus on the users’ interests and preferences. In this paper, we propose a multi-head attention graph neural network (MAE-GNN) for session-based recommendation by combining a dual-gated graph neural network and multi-head attention mechanisms . MAE-GNN can select important node information and extract users’ interests and preferences from multiple dimensions. Experimental evaluation has been conducted to show that, compared with the state-of-the-art methods, the proposed model has significant improvement in term of P @ K P@K and MRR @ K MRR@K for session-based recommendation.},
  archive      = {J_ASOC},
  author       = {Yao Chen and Qi Xiong and Yina Guo},
  doi          = {10.1016/j.asoc.2022.109744},
  journal      = {Applied Soft Computing},
  pages        = {109744},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Session-based recommendation: Learning multi-dimension interests via a multi-head attention graph neural network},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A deep residual neural network for semiconductor defect
classification in imbalanced scanning electron microscope datasets.
<em>ASOC</em>, <em>131</em>, 109743. (<a
href="https://doi.org/10.1016/j.asoc.2022.109743">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of defects using inspection systems is common in a wide range of corporations such as semiconductor industries. The use of techniques based on deep learning (DL) and, in particular, convolutional neural networks (CNNs), emerges as a powerful tool to classify aesthetic defects and other unwanted anomalies in industrial automation applications marked by their natural complexity and high degree of variability. In this paper, an effective hybrid deep residual neural network approach is presented which merges traditional computer vision techniques to perform an appropriate defect segmentation and a deep residual neural network-grid search-based hyperparameter optimization for defect classification . The proposed model has been compared with other baseline algorithms and with other hybrid methods-based CNNs using different performance metrics such as F1-score, Cohen’s kappa coefficient , confusion matrix and computing time, on imbalanced datasets obtained from scanning electron microscope (SEM) images. The results obtained illustrate that the designed hybrid method provides the best defect classification of defects in semiconductor wafers in terms of F1-score (99.443\%) while consuming the least computational time.},
  archive      = {J_ASOC},
  author       = {Francisco López de la Rosa and José L. Gómez-Sirvent and Rafael Morales and Roberto Sánchez-Reolid and Antonio Fernández-Caballero},
  doi          = {10.1016/j.asoc.2022.109743},
  journal      = {Applied Soft Computing},
  pages        = {109743},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A deep residual neural network for semiconductor defect classification in imbalanced scanning electron microscope datasets},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Increasing-dimension evolution: Make the evolutionary design
of passive filters more efficient. <em>ASOC</em>, <em>131</em>, 109740.
(<a href="https://doi.org/10.1016/j.asoc.2022.109740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary circuit design is a promising way to achieve the automatic synthesis of analog circuits , and passive filters are essential circuits that must be considered. For now, in the evolutionary design of passive filters , the size control of filters under practical difficulty is still an important issue to be studied. This paper proposed a search strategy called Increasing-Dimension Evolution (IDE). The strategy introduces the concepts of exon and intron to control gene expression levels in evolutionary search. Through this strategy, even if the length of the chromosome is fixed, the search engine can effectively search up multiple design spaces and find a small circuit size at low computing costs. We built an effective evolutionary filter design model using the IDE strategy. Experimental results show that the proposed strategy can obtain filter sizes comparable to advanced conventional design methods for several passive filter design tasks with practical difficulties. In addition, the strategy makes the search engine more effective in a given complex task, and this task is difficult to be directly solved using conventional design methods.},
  archive      = {J_ASOC},
  author       = {Hao Lan and Jingsong He},
  doi          = {10.1016/j.asoc.2022.109740},
  journal      = {Applied Soft Computing},
  pages        = {109740},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Increasing-dimension evolution: Make the evolutionary design of passive filters more efficient},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The viability of extended marine predators algorithm-based
artificial neural networks for streamflow prediction. <em>ASOC</em>,
<em>131</em>, 109739. (<a
href="https://doi.org/10.1016/j.asoc.2022.109739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precise streamflow prediction is necessary for better planning and managing available water and future water resources, especially for high altitude mountainous glacier melting affected basins in the climate change context. In the current study, a novel hybridized machine learning method, extended marine predators algorithm (EMPA)-based ANN (ANN-EMPA), is developed for streamflow estimation in the Upper Indus Basin, a key mountainous glacier melt affected basin of Pakistan. The prediction accuracy of the novel metaheuristic algorithm (EMPA) was also compared with several benchmark metaheuristic algorithms, including the marine predators algorithm (MPA), particle swarm optimization (PSO), genetic algorithm (GA), and grey wolf optimization (GWO). The results revealed that the newly developed hybridized ANN-EMPA outperformed the other hybrid ANN methods in streamflow prediction. ANN-EMPA improved the root mean square error , mean absolute error and Nash–Sutcliffe efficiency of ANN-PSO by 4.8, 4.1 and 0.5\%, ANN-GA by 6.2, 5.6 and 0.6\%, ANN-GWO by 3.7, 4.4 and 0.5\%, and ANN-MPA by 3.2, 7.5 and 0.3\%, respectively. Month number (MN) was also examined as input to the best models to assess its impact on the prediction precision. Obtained results showed that MN generally slightly improved the models’ accuracy. Results also showed that temperature-based inputs provided better prediction accuracy than only streamflow as inputs. Therefore, the ANN-EMPA model can be used for streamflow estimation from temperature data only when long-term streamflow data is unavailable.},
  archive      = {J_ASOC},
  author       = {Rana Muhammad Adnan Ikram and Ahmed A. Ewees and Kulwinder Singh Parmar and Zaher Mundher Yaseen and Shamsuddin Shahid and Ozgur Kisi},
  doi          = {10.1016/j.asoc.2022.109739},
  journal      = {Applied Soft Computing},
  pages        = {109739},
  shortjournal = {Appl. Soft. Comput.},
  title        = {The viability of extended marine predators algorithm-based artificial neural networks for streamflow prediction},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An embedded deep fuzzy association model for learning and
explanation. <em>ASOC</em>, <em>131</em>, 109738. (<a
href="https://doi.org/10.1016/j.asoc.2022.109738">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the complementary benefits of embedding a deep learning model as a fully data-driven fuzzy implication operator of a five-layer neuro-fuzzy system for learning and explanations for the predictions of both steady-state and dynamically changing data. In traditional Mandani-type neuro-fuzzy systems, the entailment performed by the implication is realized using the fuzzy implication operator based on the fuzzy rules formed in the rule base during encoding and recall. Given the presence of a group of test data that are significantly different from the training data, the realization of entailments through the use of the implication operator based on the fuzzy rules formed in traditional neuro-fuzzy systems may not be adequate. This paper attempts to adopt a more direct approach by embedding a deep learning model in the neuro-fuzzy system to serve as a fuzzy implication operator, thereby allowing the data-driven learning of fuzzy implication using the deep structure to provide a close correspondence to the real-world entailment of data. In addition, embedding the neuro-fuzzy architecture within the deep learning model allows the comprehension of the learning and explanation of the reasoning of the deep network. The induced fuzzy association rules impart transparency to the deep learning based implication using a common set of semantic meanings, which are amenable to human interpretability . The effectiveness of the proposed model is evaluated on a continuously stirred tank reactor dataset and three financial stock prediction datasets. Experimental results showed that the proposed model outperformed other state-of-the-art techniques based on the four datasets, which contain high levels of uncertainties.},
  archive      = {J_ASOC},
  author       = {Chen Xie and Deepu Rajan and Dilip K. Prasad and Chai Quek},
  doi          = {10.1016/j.asoc.2022.109738},
  journal      = {Applied Soft Computing},
  pages        = {109738},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An embedded deep fuzzy association model for learning and explanation},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A feature selection model for software defect prediction
using binary rao optimization algorithm. <em>ASOC</em>, <em>131</em>,
109737. (<a href="https://doi.org/10.1016/j.asoc.2022.109737">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this digital world, using software has become an important part of daily life and business. The software must be rigorously tested in order to avert a financial crisis. The defect-free software enhances the functionality of the business. Predicting software defects in advance is a crucial task in the software industry. The aim of Software Defect Prediction (SDP) is to locate the possible software bugs. This paper proposes a hybrid feature selection (filter–wrapper) approach based on the multi-criteria decision making (MCDM) method and the Rao optimization method for selecting the more informative features to improve the software defect prediction rate. The proposed work measures the fitness of the candidate solution by using the defect prediction rate and the feature selection ratio. The performance of the proposed method is evaluated using three popular benchmark NASA datasets (PC5, JM1, and KC1) and compared with the state-of-the-art methods. The proposed feature subset selection scheme identifies the most significant feature subset for defect prediction with an average accuracy of 95\% on the benchmark datasets. According to the experimental results, the proposed hybrid approach outperforms the standard strategy in terms of defect prediction rate.},
  archive      = {J_ASOC},
  author       = {Karpagalingam Thirumoorthy and Jerold John Britto J.},
  doi          = {10.1016/j.asoc.2022.109737},
  journal      = {Applied Soft Computing},
  pages        = {109737},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A feature selection model for software defect prediction using binary rao optimization algorithm},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Application of six metaheuristic optimization algorithms and
random forest in the uniaxial compressive strength of rock prediction.
<em>ASOC</em>, <em>131</em>, 109729. (<a
href="https://doi.org/10.1016/j.asoc.2022.109729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The uniaxial compressive strength (UCS) is one of the most important parameters for judging the mechanical behaviour of rock mass in rock engineering design and excavation such as tunnels , subways , drilling, slopes and mines stability. However, an obvious deficiency of traditional experimental operations to obtain UCS is that it suffers from a lack of efficiency and accuracy. Therefore, the prediction of the UCS of rock is of high practical significance in reducing evaluation time and improving the precision of results. At the same time, breaking the universality problem of traditional empirical models and improving the accuracy of artificial intelligence models need to absorb and accommodate more rock samples. Hence, a total of 226 rock samples with five properties were carried out from four published studies and selected to generate a dataset in this investigation, i.e., Granitic, Caliche, Schist, Sandstone and Grade III granitic. Five individual parameters of rock samples consisting of Schmidt hardness rebound number (SHR), P-wave velocity (V p p ), point load strength (Is (50) (50) ), porosity (P n n ), and density (D) were used to predict UCS. In this paper, six metaheuristic optimization algorithms were utilized to improve the performance of the Random Forest (RF) model, i.e., slime mould algorithm (SMA), chameleon swarm algorithm (CSA), transient search optimization (TSO), equilibrium optimizer (EO), social network search (SNS) and student psychology based optimization algorithm (SPBO). Four performance indices , the root mean square error (RMSE), the determination coefficient (R 2 ), Willmott’s index (WI) and the variance accounted for (VAF) were utilized to evaluate the performance of all models in forecasting the UCS of rock. The results of the performance comparison demonstrated that the TSO-RF model has the highest values of R 2 (train: 0.9923 and test: 0.9753), WI (train: 0.9980 and test: 0.9937), and VAF (train: 99.2272\% and test: 97.6852\%), the lowest values of RMSE (train: 3.8313 and test: 6.5968) compared to the other models. The research in this study provided an effective attempt to further improve the accuracy of UCS prediction.},
  archive      = {J_ASOC},
  author       = {Jingze Li and Chuanqi Li and Shaohe Zhang},
  doi          = {10.1016/j.asoc.2022.109729},
  journal      = {Applied Soft Computing},
  pages        = {109729},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Application of six metaheuristic optimization algorithms and random forest in the uniaxial compressive strength of rock prediction},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning modeling of public’s sentiments towards
temporal evolution of COVID-19 transmission. <em>ASOC</em>,
<em>131</em>, 109728. (<a
href="https://doi.org/10.1016/j.asoc.2022.109728">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Public sentiments towards global pandemics are important for public health assessment and disease control. This study develops a modularized deep learning framework to quantify public sentiments towards COVID-19, followed by leveraging the predicted sentiments to model and forecast the daily growth rate of confirmed COVID-19 cases globally, via a proposed G parameter. In the proposed framework, public sentiments are first modeled via a valence dimensional indicator, instead of discrete schemas, and are classified into 4 primary emotional categories: (a) neutral; (b) negative; (c) positive; (d) ambivalent, by using multiple word embedding models and classifiers for text sentiments analyses and classification. The trained model is subsequently applied to analyze large volumes (millions in quantity) of daily Tweets pertaining to COVID-19, ranging from 22 Jan 2020 to 10 May 2020. The results demonstrate that the global community gradually evokes both positive and negative sentiments towards COVID-19 over time compared to the dominant neural emotion at its inception. The predicted time-series sentiments are then leveraged to train a deep neural network (DNN) to model and forecast the G parameter by achieving the lowest possible mean absolute percentage error (MAPE) score of around 17.0\% during the model’s testing step with the optimal model configuration.},
  archive      = {J_ASOC},
  author       = {Ying Wang and Alvin Wei Ze Chew and Limao Zhang},
  doi          = {10.1016/j.asoc.2022.109728},
  journal      = {Applied Soft Computing},
  pages        = {109728},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Deep learning modeling of public’s sentiments towards temporal evolution of COVID-19 transmission},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fitness landscape analysis and niching genetic approach for
hybrid beamforming in RIS-aided communications. <em>ASOC</em>,
<em>131</em>, 109725. (<a
href="https://doi.org/10.1016/j.asoc.2022.109725">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconfigurable intelligent surface (RIS) is a revolutionizing technology to achieve cost-effective communications. The active beamforming at the base station (BS) and the discrete phase shifts at RIS should be jointly designed to customize the propagation environment . However, current phase-shift setting methods ignore the non-separable property of phase shifts, degrading the performance, especially in cases with a large-sized RIS. To understand the problem characteristics related to the phase shifts and further tailor an eligible method with such characteristics, this paper, for the first time, analyzes the fitness landscape of the sum-rate maximization problem (maximizing the sum rate of users in a downlink multi-user multiple-input single-output system assisted by a RIS). Results show that the problem has a severe unstructured and rugged landscape, especially in cases with a large-sized RIS. This observation answers why current methods are ineligible and provides insightful guidance for designing a more intelligent method. With the landscape findings in mind, this paper introduces a niching genetic algorithm to solve the problem. In particular, the niching idea is employed to locate multiple local optima. These local optima act as stepping stones to facilitate approaching the global optima. Simulation results demonstrate that the proposed niching genetic algorithm obtains significant capacity gains over current methods in cases with large-sized RIS.},
  archive      = {J_ASOC},
  author       = {Bai Yan and Qi Zhao and Mengke Li and Jin Zhang and J. Andrew Zhang and Xin Yao},
  doi          = {10.1016/j.asoc.2022.109725},
  journal      = {Applied Soft Computing},
  pages        = {109725},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fitness landscape analysis and niching genetic approach for hybrid beamforming in RIS-aided communications},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). A framework based on heterogeneous ensemble models for
liquid steel temperature prediction in LF refining process.
<em>ASOC</em>, <em>131</em>, 109724. (<a
href="https://doi.org/10.1016/j.asoc.2022.109724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The precise control of liquid steel temperature in the ladle furnace (LF) refining process is vital for stabilizing and improving the quality of liquid steel, necessitating a capable prediction system. To achieve better predictive performance , an effective prediction framework based on heterogeneous ensemble models is proposed in this paper, which mainly consists of three parts: (1) utilizing single models and tree-based ensemble models to constitute the heterogeneous ensemble model; (2) proposing Recursive Feature Increase (RFI) to facilitate the construction of the heterogeneous ensemble model, including Stacking and Majority Voting; (3) proposing a new optimization algorithm , namely Recursive Search Optimization (RSO), to optimize the hyper-parameters of the heterogeneous ensemble model. Through the verification of the collected industrial production data, it is found that the proposed framework in this paper possesses higher fitting and generalization ability , which is of great significance for engineering applications such as liquid steel temperature prediction in the LF refining process.},
  archive      = {J_ASOC},
  author       = {Chao Chen and Nan Wang and Min Chen and Xumei Yan},
  doi          = {10.1016/j.asoc.2022.109724},
  journal      = {Applied Soft Computing},
  pages        = {109724},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A framework based on heterogeneous ensemble models for liquid steel temperature prediction in LF refining process},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-adapting particle swarm optimization for continuous
black box optimization. <em>ASOC</em>, <em>131</em>, 109722. (<a
href="https://doi.org/10.1016/j.asoc.2022.109722">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new version of a hyper-heuristic framework: Generalized Self-Adapting Particle Swarm Optimization with samples archive (M-GAPSO). This framework is based on the authors previous works on hybridization of optimization algorithms and enhancing population based optimization with model based optimization. The paper presents the structure of the proposed framework and analyzes the impact of its modules on the final system performance. M-GAPSO hybridizes Particle Swarm Optimization , Differential Evolution and model based optimizers. A ratio of particular algorithms within a population is regulated by an adaptation scheme. The applicability of the proposed hybrid method to black-box optimization is verified on 24 continuous benchmark functions from the COCO test set and 29 functions from the CEC-2017 test set. On the BBOB test set a hybrid of PSO and DE with adaptation obtained 11 significantly better and 2 significantly worse results on 5 and 20 dimensional functions than the basic DE. Further inclusion of the model based optimizers led to 15 significantly better and 2 significantly worse results compared to the PSO-DE hybrid. On the CEC-2017 test set, M-GAPSO was significantly better than both Red Fox Optimization and Dual Opposition-Based Learning for Differential Evolution (DOBL) on 7 functions in 30 dimensions and 12 functions in 50 dimensions.},
  archive      = {J_ASOC},
  author       = {Michał Okulewicz and Mateusz Zaborski and Jacek Mańdziuk},
  doi          = {10.1016/j.asoc.2022.109722},
  journal      = {Applied Soft Computing},
  pages        = {109722},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Self-adapting particle swarm optimization for continuous black box optimization},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Classifier-based evolutionary multiobjective optimization
for the graph protection problem. <em>ASOC</em>, <em>131</em>, 109721.
(<a href="https://doi.org/10.1016/j.asoc.2022.109721">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a graph-based optimization problem related to epidemics control is studied. This multiobjective optimization problem requires determining which graph nodes to protect in order to limit the number of nodes affected by a threat spreading in the graph. In the paper, a classifier-based evolutionary algorithm is proposed in which population initialization, crossover, mutation and local search can use a previously trained classifier to decide which graph nodes to protect. The classifier is trained on a dataset collected by running an optimization algorithm on small problem instances and it is subsequently reused for solving multiple, larger instances of the same optimization problem. Selecting graph nodes to protect using a previously trained classifier allows the algorithm to find better solutions to the optimization problem compared to an algorithm not using a classifier. In the experiments, several machine learning models were evaluated and a multilayer perceptron (MLP) neural network was selected as the best performing classifier. The proposed optimization method was tested and found to work effectively when the MLP classifier was trained on data collected when solving problem instances with 1000 graph nodes. In tests on problem instances with up to 20000 nodes the proposed method outperformed an evolutionary optimizer not using any classifier-based components thereby showing that knowledge can be transferred from smaller problem instances to larger ones.},
  archive      = {J_ASOC},
  author       = {Krzysztof Michalak},
  doi          = {10.1016/j.asoc.2022.109721},
  journal      = {Applied Soft Computing},
  pages        = {109721},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Classifier-based evolutionary multiobjective optimization for the graph protection problem},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-objective reinforcement learning framework for dynamic
flexible job shop scheduling problem with uncertain events.
<em>ASOC</em>, <em>131</em>, 109717. (<a
href="https://doi.org/10.1016/j.asoc.2022.109717">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The economic benefits for manufacturing companies will be influenced by how it handles potential dynamic events and performs multi-objective real-time scheduling for existing dynamic events. Based on these, we propose a new dynamic multi-objective flexible job shop scheduling problem (DMFJSP) to simulate realistic production environment. Six dynamic events are involved in the problem including job insertion, job cancellation, job operation modification, machine addition, machine tool replacement and machine breakdown. As well as three objectives of longest job processing time (makespan), average machine utilization and average job processing delay rate with a set of constraints are also raised in the study. Then this research designs a novel dynamic multi-objective scheduling algorithm based on deep reinforcement learning . The algorithm uses two deep Q-learning networks and a real-time processing framework to process each dynamic event and generate complete scheduling scheme. In addition, an improved local search algorithm is adopted to further optimize the scheduling results and the idea of combination is used to make the scheduling rules more comprehensive. Experiments on 27 instances show the superiority and stability of our approach compared to each proposed combined rule, well-known scheduling rules and standard deep Q-learning based algorithms. Compared to the current optimal deep Q-learning method, the maximum performance improvement for our three objectives are approximately 57\%, 164\% and 28\%.},
  archive      = {J_ASOC},
  author       = {Hao Wang and Junfu Cheng and Chang Liu and Yuanyuan Zhang and Shunfang Hu and Liangyin Chen},
  doi          = {10.1016/j.asoc.2022.109717},
  journal      = {Applied Soft Computing},
  pages        = {109717},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-objective reinforcement learning framework for dynamic flexible job shop scheduling problem with uncertain events},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A GRASP-VND algorithm to solve the multi-objective fuzzy and
sustainable tourist trip design problem for groups. <em>ASOC</em>,
<em>131</em>, 109716. (<a
href="https://doi.org/10.1016/j.asoc.2022.109716">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design and planning of group tourist itineraries is a current trend. Group planning should be done according to the maximum capacity of the site under current COVID-19 conditions, the transport flow, and the benefits associated with individual preferences. Tourists commonly express the benefits and limitations of travel in vague and imprecise linguistic terms . In this paper, a hybrid algorithm is presented that combines Greedy Randomized Adaptive Search Procedure, Variable Neighborhood Descendent, and Pareto optimality to solve the multi-objective problem of planning sustainable group tourists itineraries under uncertainty. A set of experiments is performed with real-world tourism data from Sucre, Colombia and benchmark instances from the literature to validate the algorithm’s performance. The results are compared with optimal solutions obtained by CPLEX and other algorithms from previous works. Our approach demonstrates superior performance to different multi-target algorithms and builds more realistic routes.},
  archive      = {J_ASOC},
  author       = {José Ruiz-Meza and Julio Brito and Jairo R. Montoya-Torres},
  doi          = {10.1016/j.asoc.2022.109716},
  journal      = {Applied Soft Computing},
  pages        = {109716},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A GRASP-VND algorithm to solve the multi-objective fuzzy and sustainable tourist trip design problem for groups},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Image feature selection embedded distribution differences
between classes for convolutional neural network. <em>ASOC</em>,
<em>131</em>, 109715. (<a
href="https://doi.org/10.1016/j.asoc.2022.109715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks have achieved a great success in feature extraction and classification of images. However, some of the features extracted by convolutional neural networks are with insignificant difference between classes, which not only contribute little to image classification , but also increase the complexity of the classifier. It is important to select features that are helpful for image classification when using convolutional neural network. In view of the existence of class labels of image samples when training classifier, and motivated by the intention that these labels may also play a certain role in feature selection for image classification, we propose a feature selection approach by taking the distribution differences between classes into consideration on the basis of the features extracted by convolutional neural network. To be specific, we use the Gaussian mixture model to approximate the distribution of each feature on each subclass , and select the features significantly contribute to classification by designing a measure of distribution difference according to the numerical characteristics described by Gaussian mixture models. Further, an image classifier can be presented by redesigning the fully connected layers of the convolutional neural network based on the selected features. The proposed feature selection is adopted to image classification, and the experimental results show the effectiveness of the method.},
  archive      = {J_ASOC},
  author       = {Dezheng Liu and Liyong Zhang and Xiaochen Lai and Hui Liu},
  doi          = {10.1016/j.asoc.2022.109715},
  journal      = {Applied Soft Computing},
  pages        = {109715},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Image feature selection embedded distribution differences between classes for convolutional neural network},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). McS-net: Multi-class siamese network for severity of
COVID-19 infection classification from lung CT scan slices.
<em>ASOC</em>, <em>131</em>, 109683. (<a
href="https://doi.org/10.1016/j.asoc.2022.109683">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Worldwide COVID-19 is a highly infectious and rapidly spreading disease in almost all age groups. The Computed Tomography (CT) scans of lungs are found to be accurate for the timely diagnosis of COVID-19 infection. In the proposed work, a deep learning-based P-shot N-ways Siamese network along with prototypical nearest neighbor classifiers is implemented for the classification of COVID-19 infection from lung CT scan slices. For this, a Siamese network with an identical sub-network (weight sharing) is used for image classification with a limited dataset for each class. The feature vectors are obtained from the pre-trained sub-networks having weight sharing. The performance of the proposed methodology is evaluated on the benchmark MosMed dataset having categories zero (healthy control) and numerous COVID-19 infections. The proposed methodology is evaluated on (a) chest CT scans provided by medical hospitals in Moscow, Russia for 1110 patients, and (b) case study of low-dose CT scans of 42 patients provided by Avtaran healthcare in India. The deep learning-based Siamese network (15-shot 5-ways) obtained an accuracy of 98.07\%, the sensitivity of 95.66\%, specificity of 98.83\%, and F1-score of 95.10\%. The proposed work outperforms the COVID-19 infection severity classification with limited scans availability for numerous infection categories.},
  archive      = {J_ASOC},
  author       = {Sakshi Ahuja and Bijaya Ketan Panigrahi and Nilanjan Dey and Arpit Taneja and Tapan Kumar Gandhi},
  doi          = {10.1016/j.asoc.2022.109683},
  journal      = {Applied Soft Computing},
  pages        = {109683},
  shortjournal = {Appl. Soft. Comput.},
  title        = {McS-net: Multi-class siamese network for severity of COVID-19 infection classification from lung CT scan slices},
  volume       = {131},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast-dynamic grey wolf optimizer for solving model order
reduction of bilinear systems based on multi-moment matching technique.
<em>ASOC</em>, <em>130</em>, 109730. (<a
href="https://doi.org/10.1016/j.asoc.2022.109730">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grey Wolf Optimizer (GWO) has been known as one of the most popular and powerful metaheuristic search algorithms. It has great advantages such as simplicity, accuracy, and good convergence rate, but its performance degrades when the global optimum is not zero. To address these issues, in this paper, a new formulation is introduced to change its searching and hunting mechanisms, while the updating structure of wolves is also modified. With these changes, a proper compromise is achieved between exploitation and exploration. Therefore, the proposed algorithm, called Fast-Dynamic GWO (FDGWO), is more accurate with a faster convergence rate compared to GWO. Thirty-eight typical benchmark functions are optimized with FDGWO and compared with a set of efficient metaheuristic search algorithms. The Wilcoxon rank-sum test is used to statistically assess the results. With an overall efficacy of 84.2\%, FDGWO is the most effective among competing algorithms. Then, the performance of FDGWO for ten real-world constrained engineering problems is compared with some highly accurate recent algorithms such as BP- ϵ ϵ MAg-ES and COLSHADE. The results show that while FDGWO performs almost as accurate as these algorithms, but its computational complexity is quite less. Next, a new hybrid method based on FDGWO is proposed for model order reduction (MOR) of bilinear systems. First, the order of reduced system is determined via an iterative approach based on H 2 H2 norm of the error system. The unknown parameters of reduced model are then determined by minimizing a multi-objective fitness function aiming to match the multi-moments of original and reduced bilinear systems. Some stability constraints based on the Volterra series expansion of the states of the bilinear system are added to the optimization problem , which is solved by FDGWO algorithm. Finally, two bilinear test systems are reduced by the proposed hybrid method and compared with the most common bilinear MOR methods.},
  archive      = {J_ASOC},
  author       = {H. Nasiri Soloklo and N. Bigdeli},
  doi          = {10.1016/j.asoc.2022.109730},
  journal      = {Applied Soft Computing},
  pages        = {109730},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fast-dynamic grey wolf optimizer for solving model order reduction of bilinear systems based on multi-moment matching technique},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parallel assembly lines worker assignment and balancing
problem: A mathematical model and an artificial bee colony algorithm.
<em>ASOC</em>, <em>130</em>, 109727. (<a
href="https://doi.org/10.1016/j.asoc.2022.109727">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s competitive world, assembly lines are one of the most important industrial manufacturing systems , which can accommodate the massive increase in customer demands and product range, for the production industry. One possible way to increase the capacity and efficiency of assembly lines is to design a parallel assembly line system, consisting of two or more assembly lines placed next to each other. In the literature, the assembly lines are usually balanced according to tasks with fixed processing times without considering worker–task compatibility. In real-life applications, however, since the processing time of each task may vary according to the capability of each worker, the assignment of tasks to stations in the assembly line depends on the skills of the worker assigned to the related station. Considering the worker and task assignments together for each assembly line will provide a more realistic perspective. This paper, to the best of our knowledge, is the first study that considers the minimization of joint cycle time for the worker assignment and assembly line balancing problem in parallel assembly lines (PALWABP-II). Accordingly, a binary linear mathematical programming (BLP) model is developed and an artificial bee colony (ABC)-based solution approach is proposed for medium and large-sized problems. A new set of test problems is presented to the literature for a computational experiment. In addition, a summary of the literature is presented. An example problem is solved using the BLP model. In order to evaluate the effectiveness of the proposed model and approach, they are compared with the classical particle swarm optimization (PSO) algorithm and ten different priority rules. The computational results on test problems prove the effectiveness of the proposed ABC algorithm for the PALWABP-II.},
  archive      = {J_ASOC},
  author       = {Uğur Özcan and Emel Kızılkaya Aydoğan and Salih Himmetoğlu and Yılmaz Delice},
  doi          = {10.1016/j.asoc.2022.109727},
  journal      = {Applied Soft Computing},
  pages        = {109727},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Parallel assembly lines worker assignment and balancing problem: A mathematical model and an artificial bee colony algorithm},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new decomposition ensemble model for stock price
forecasting based on system clustering and particle swarm optimization.
<em>ASOC</em>, <em>130</em>, 109726. (<a
href="https://doi.org/10.1016/j.asoc.2022.109726">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of stock prices has been a challenge in the securities market, while the stock price time series tend to be non-stationary, non-linear, and highly noisy. At present, the traditional method of decomposition and ensemble can improve the forecasting accuracy , but it increases the computational complexity of forecasting, which may introduce additional forecasting errors. In order to address these problems, this paper proposes a novel decomposition and reconstruction model based on system clustering method (SCM) and particle swarm optimization (PSO). Firstly, the system uses the ensemble empirical mode decomposition (EEMD) technique to pre-process stock prices. Furthermore, the complexity of each modality is then measured using the sample entropy method . In addition, the modes are systematically clustered and reconstructed according to three patterns of short, medium, and long-term market changes. Apart from that, subsequences of four different characteristics at coarse granularity (containing the residual term acquired from the mode decomposition) are obtained, thus reducing the complexity of the prediction calculation. Meanwhile, a PSO optimized long short-term memory (LSTM) neural network or support vector regression (SVR) model is used to predict the sub-series with different characteristics separately. The updated model combines decomposition, forecasting, and ensemble steps with a system clustering approach and the idea of “divide and conquer” from a multi-granularity perspective, which not only changes the working mechanism of traditional decomposition-ensemble forecasting models but also realizes a new theoretical model for forecasting stock prices. According to experimental results, the proposed model has higher forecasting accuracy than other current forecasting methods, while it is more consistent with the dynamic stock market’s physical significance.},
  archive      = {J_ASOC},
  author       = {Yuqi Guo and Jianfeng Guo and Bingzhen Sun and Juncheng Bai and Youwei Chen},
  doi          = {10.1016/j.asoc.2022.109726},
  journal      = {Applied Soft Computing},
  pages        = {109726},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A new decomposition ensemble model for stock price forecasting based on system clustering and particle swarm optimization},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Forecasting crude oil futures prices using
BiLSTM-attention-CNN model with wavelet transform. <em>ASOC</em>,
<em>130</em>, 109723. (<a
href="https://doi.org/10.1016/j.asoc.2022.109723">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a novel hybrid model for forecasting crude oil futures price time series is proposed. The combination of Bidirectional long short-term memory network (BiLSTM), Attention mechanism and Convolution neural network (CNN) is used. Based on the principle of deep learning (DL) and wavelet transform (WT), the time series of crude oil futures price are decomposed and reconstructed into a low-frequency main sequence and several high-frequency noise sequence. Then, the subsequences obtained by decomposition are predicted by BiLSTM-Attention-CNN model in turn. Finally, with several evaluating indicators (RMSE, MAPE, MAE and R 2 ), the forecasting errors of proposed model and other comparative models are evaluated and compared. The experimental results based on two types of crude oil futures showed the novel model outperforms other related comparative models under different training sets lengths and the modification of Diebold–Mariano test (MDM) proved that the loss functions of constructed model are statistically significant in this paper. In general, the innovative combination forecasting model proposed in this paper is a promising technology for government agencies, investors and related enterprises.},
  archive      = {J_ASOC},
  author       = {Yu Lin and Kechi Chen and Xi Zhang and Bin Tan and Qin Lu},
  doi          = {10.1016/j.asoc.2022.109723},
  journal      = {Applied Soft Computing},
  pages        = {109723},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Forecasting crude oil futures prices using BiLSTM-attention-CNN model with wavelet transform},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Area and power optimization approach for mixed polarity
reed–muller logic circuits based on multi-strategy bacterial foraging
algorithm. <em>ASOC</em>, <em>130</em>, 109720. (<a
href="https://doi.org/10.1016/j.asoc.2022.109720">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Area and power optimization have become the primary constraints in chip design. Existing area and power optimization approaches have poor optimization performance and high CPU time in logic circuits with multiple inputs. To solve this problems, we propose a multi-strategy bacterial foraging algorithm (MBFA) for multi-objective optimization, which includes nondominated add procedure, dual-population cooperative procedure, high-quality replication procedure, distributed migration procedure and the termination criterion. In addition, considering the characteristics of mixed polarity Reed–Muller (MPRM) logic circuits such as high dimension and large solution space domain, we propose an area and power optimization approach (APOA) based on XNOR/OR, which uses MBFA to search MPRM circuits with Pareto optimal solutions . Experimental results show that the APOA has better performance in optimizing MPRM circuits area and power.},
  archive      = {J_ASOC},
  author       = {Yuhao Zhou and Zhenxue He and Tao Wang and Zhisheng Huo and Limin Xiao and Xiang Wang},
  doi          = {10.1016/j.asoc.2022.109720},
  journal      = {Applied Soft Computing},
  pages        = {109720},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Area and power optimization approach for mixed polarity Reed–Muller logic circuits based on multi-strategy bacterial foraging algorithm},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Solving a stochastic hierarchical scheduling problem by
VNS-based metaheuristic with locally assisted algorithms. <em>ASOC</em>,
<em>130</em>, 109719. (<a
href="https://doi.org/10.1016/j.asoc.2022.109719">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-end equipment manufacture has features of intensive technology, uncertain process, and large scale. Hence, the scheduling of the High-end equipment manufacture is challenging. Large ships are a type of High-end equipment that is tied to national maritime security. In this paper, we study a stochastic hierarchical scheduling problem with serial-batch processing machines and the deterioration effect in ship manufacture. In the studied problem, the job processing time is uncertain and follows a normal probability distribution. Under the deterioration effect, the actual processing time of jobs is formulated as a function of the start time. The first objective is to maximize the robustness of the manufacturing system . The second objective is to minimize the total inventory cost subjected to the optimization of the first objective. The robustness of the manufacturing system is measured by the worst level of completion probability. The total inventory cost is measured by the difference between the job delivery time and the job completion time. The mathematical model for the studied problem is formulated. Some structural properties are derived to solve the problem. Based on the properties, the optimal sequence for the first objective can be obtained and a heuristic algorithm is designed to optimize the second objective. The considered problem is NP-hard involving several non-linearities. Hence, a variable neighborhood search (VNS) algorithm is developed to solve the problem in a reasonable time, which is integrated with three local search strategies and a heuristic algorithm . Various problem instances are generated and extensive computational experiments verify that the proposed VNS algorithm outperforms other compared algorithms and has strong robustness.},
  archive      = {J_ASOC},
  author       = {Shaojun Lu and Chongyao Ma and Min Kong and Zhiping Zhou and Xinbao Liu},
  doi          = {10.1016/j.asoc.2022.109719},
  journal      = {Applied Soft Computing},
  pages        = {109719},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Solving a stochastic hierarchical scheduling problem by VNS-based metaheuristic with locally assisted algorithms},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). A decomposition-based memetic neural architecture search
algorithm for univariate time series forecasting. <em>ASOC</em>,
<em>130</em>, 109714. (<a
href="https://doi.org/10.1016/j.asoc.2022.109714">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although deep learning has made remarkable progress in time series forecasting, enormous hyperparameters consume a lot of effort to tune. Moreover, to further build the forecasting models with better performance, time series decomposition is usually adopted to mine implicit patterns of the data. Inspired by the time series decomposition, automatically searching for a network architecture after decomposing the time series is proposed. The searching process is non-trivial and has two key challenges: 1) impairment of time series information after decomposing and 2) enlarged search space caused by the huge parameters to be optimized. In this paper, a decomposition-based memetic neural architecture search algorithm is proposed for univariate time series forecasting to address these two challenges. For the first challenge, a general univariate time series forecasting paradigm is designed as the building pipeline of the individual in the proposed algorithm, which considers both the decomposed components and the original series as the compensation information to improve the network representation ability. For the second challenge, with the intrinsic property of representation of individuals in mind, we design a decomposition-based memetic algorithm with a discriminative local search operator to automatically optimize the network configurations . The experimental results on nine benchmarks with four horizons and one application of remaining useful forecasting demonstrate that the discovered architectures by the proposed algorithm achieve competitive performance compared with six methods under aligned settings. Codes and models will be released in https://github.com/EavanLi/dMA-NAS-UTSF .},
  archive      = {J_ASOC},
  author       = {Yifan Li and Jing Liu and Yingzhi Teng},
  doi          = {10.1016/j.asoc.2022.109714},
  journal      = {Applied Soft Computing},
  pages        = {109714},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A decomposition-based memetic neural architecture search algorithm for univariate time series forecasting},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning techniques for suicide and depression
detection from online social media: A scoping review. <em>ASOC</em>,
<em>130</em>, 109713. (<a
href="https://doi.org/10.1016/j.asoc.2022.109713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Psychological health, i.e., citizens’ emotional and mental well-being, is one of the most neglected public health issues. Depression is the most common mental health issue and the leading cause of suicide and self-injurious behavior. Clinical diagnosis of these mental health issues is expensive and also ignored due to social stigma and lack of awareness. Nowadays, online social media has become the preferred mode of communication, which people use to express their thoughts, feelings, and emotions. Hence, user-generated content from online social media can be leveraged for non-clinical mental health assessment and surveillance. Conventional machine learning and NLP techniques have been used for the automated detection of mental health issues using social media data for a very long time now. However, the objective of our research is to study the applications of deep learning techniques for early detection and non-clinical, predictive diagnosis of depression, self-harm, and suicide ideation from online social network content only. To the best of our knowledge, we did not find any systematic literature review that studies the applications of deep learning techniques in this domain. In order to address this research gap, we conducted a systematic literature review (SLR) of 96 relevant research studies published until date that have applied deep learning techniques for detecting depression and suicide or self-harm behavior from social media content. Our work comprehensively covers state-of-the-art w.r.t. techniques, features, datasets, and performance metrics, which can be of great value to researchers. We enumerate all the available datasets in this domain and discuss their characteristics. We also discuss the research gaps, challenges, and future research directions for advancing &amp; catalyzing research in this domain. To the best of our knowledge, our study is the only and the most recent survey for this domain covering the latest research published until date. Based on our learnings from this review, we have also proposed a framework for mental health surveillance. We believe the findings of our work will be beneficial for researchers working in this domain.},
  archive      = {J_ASOC},
  author       = {Anshu Malhotra and Rajni Jindal},
  doi          = {10.1016/j.asoc.2022.109713},
  journal      = {Applied Soft Computing},
  pages        = {109713},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Deep learning techniques for suicide and depression detection from online social media: A scoping review},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comparative study of spark assisted bending process using
teaching–learning based optimization, desirability approach and genetic
algorithm. <em>ASOC</em>, <em>130</em>, 109712. (<a
href="https://doi.org/10.1016/j.asoc.2022.109712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present work deals with the application and comparison of advanced meta-heuristic-based optimization techniques on the micron-thin sheet bending process. Nature-inspired Teaching–Learning Based Optimization Algorithm (TLBO), Genetic Algorithm (GA), and desirability function-based optimization techniques have been used to predict the optimal parametric levels for obtaining desired bend angles. Spark discharges were applied to bend sheets using electro-discharge machining. Process parameters, namely, peak current ( P c Pc ), duty factor ( D f Df ), and gap voltage ( G v Gv ), were varied to obtain the response, i.e., bend angle ( θ b θb ). Box–Behnken design in Response Surface Methodology (RSM) was used to obtain a regression model. Statistical analysis of the developed model was done using analysis of variance (ANOVA), which showed that θ b θb was statistically affected by variation in P c Pc , D f , Df, and G v Gv at a 95\% confidence level. Minimum ( θ b m i n θbmin ) and maximum ( θ b m a x θbmax ) bend angles obtained from the experiments were reported to be θ b m i n = 8 θbmin=8 .57° and θ b m a x = 26 θbmax=26 .48° at P c = 6 Pc=6 A, D f = 30\% Df=30\% and G v = 40 Gv=40 V and P c = 10 Pc=10 A, D f = 50\% Df=50\% and G v = 50 Gv=50 V, respectively. Further, developed model adequacy was inspected using standard error design plots and analysis of residuals. The developed quadratic regression model was used to optimize the desired response ( θ b θb ). The results revealed that the genetic algorithm provided the desired output corresponding to the requirement of bend angle. The values obtained after the optimization of bend angles by performing a confirmatory test were θ b m i n = 8 θbmin=8 .454° and θ b m a x = 28 θbmax=28 .015°. Hence the values obtained were better concerning the initial practical experimental data set .},
  archive      = {J_ASOC},
  author       = {Tanmay Tiwari and Akash Nag and Alokesh Pramanik and Amit Rai Dixit},
  doi          = {10.1016/j.asoc.2022.109712},
  journal      = {Applied Soft Computing},
  pages        = {109712},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A comparative study of spark assisted bending process using teaching–learning based optimization, desirability approach and genetic algorithm},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fuzzy multi-perspective conformance checking for business
processes. <em>ASOC</em>, <em>130</em>, 109710. (<a
href="https://doi.org/10.1016/j.asoc.2022.109710">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conformance checking techniques are widely used to monitor the execution of organization processes and to pinpoint possible violations of the prescribed behavior. State-of-the-art approaches adopt a crisp evaluation of deviations: namely, every step in the execution which is not perfectly compliant with the procedural rules is marked as deviant. However, many real-world processes are driven by decisions taken by human actors, which are often characterized by uncertainty. As a consequence, deviations are often tolerated, within some boundaries. In these contexts, assessing small violations at the same level as significant ones hampers the accuracy of the provided diagnostics. In this work, we propose a novel conformance checking approach which allows to consider actors’ tolerance to violations when assessing the magnitude of detected deviations, taking into account different kinds of deviating behaviors. Experiments conducted on two real-life clinical data sets have shown that taking the extent of deviations into account leads to more fine-grained diagnostics, thus illustrating the value of the approach.},
  archive      = {J_ASOC},
  author       = {Sicui Zhang and Laura Genga and Lukas Dekker and Hongchao Nie and Xudong Lu and Huilong Duan and Uzay Kaymak},
  doi          = {10.1016/j.asoc.2022.109710},
  journal      = {Applied Soft Computing},
  pages        = {109710},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fuzzy multi-perspective conformance checking for business processes},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Prototype augmented network with metric-mixed under limited
samples for mechanical intelligent fault recognition. <em>ASOC</em>,
<em>130</em>, 109709. (<a
href="https://doi.org/10.1016/j.asoc.2022.109709">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Common deep learning methods can effectively extract fault characteristics and make recognition of mechanical faults. Nevertheless, the results are undesirable when sufficient labeled training data are unavailable. Although metric learning methods can conduct fault recognition with limited samples, they cannot get satisfactory results due to the fixed relation metric function of manually selected. To address this problem we proposed a prototype augmented network with metric-mixed under limited samples (PANM). It combines fixed metric function with the network automatically learning metric, which consists of an embedded module, relation module and metric module, respectively Firstly, the class prototypes are augmented via multilayer residual network in the embedded module. Then, in the relation module, the prototypes are concatenated with training features to automatically learn the corresponding relationship for getting relation scores. Next, the metric module is used to measure the fixed spatial distance and normalize as the weights of each score. Finally, fault identification is taken according to the weighted score. The experiments in two datasets indicate that PANM cannot just identify different fault categories; it may identify new untrained classes without modifying the network parameters as well, which demonstrates practical solving ability and good generalization ability of fault recognition under limited samples.},
  archive      = {J_ASOC},
  author       = {Rujie Hou and Jinglong Chen and Shuilong He and Fudong Li and Zitong Zhou},
  doi          = {10.1016/j.asoc.2022.109709},
  journal      = {Applied Soft Computing},
  pages        = {109709},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Prototype augmented network with metric-mixed under limited samples for mechanical intelligent fault recognition},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards improved multifactorial particle swarm optimization
learning of fuzzy cognitive maps: A case study on air quality
prediction. <em>ASOC</em>, <em>130</em>, 109708. (<a
href="https://doi.org/10.1016/j.asoc.2022.109708">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy cognitive map (FCM) is a very simple, efficient, and powerful soft computing tool for modeling and analysis of a complex system. Due to its simplicity and transparency, FCM has been widely utilized in engineering, environment, medicine, and other complex systems. However, it remains challenging to handle dynamic, non-stationary, and noisy time series, such as air quality monitoring data, which is with typical temporal periodicity, cross-interference, low-quality, and great noise. Concerning the above challenges, we propose an improved multifactorial particle swarm optimization learning algorithm of FCM, termed as IMFPSO-FCM. Within the framework of IMFPSO-FCM, the learning of an FCM is regarded as a multitask optimization problem . Every task represents learning local connections of a node, and a single population is adopted to process these tasks simultaneously. The task selection mechanism is used to automatically select appropriate target tasks, thereby suppressing negative transfer and enabling useful information to be transferred between tasks. In addition, a multi-dimensional adaptive inertia weight strategy and a local search strategy are employed to further improve the performance of the model. The performance of IMFPSO-FCM is validated on several public datasets and real-world air quality monitoring datasets. The experimental results demonstrate the performance of the development method and emphasize its practicality.},
  archive      = {J_ASOC},
  author       = {Weiling Liang and Yingjun Zhang and Xiaoqian Liu and Hui Yin and Jingping Wang and Yanyan Yang},
  doi          = {10.1016/j.asoc.2022.109708},
  journal      = {Applied Soft Computing},
  pages        = {109708},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Towards improved multifactorial particle swarm optimization learning of fuzzy cognitive maps: A case study on air quality prediction},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A scheduling algorithm based on reinforcement learning for
heterogeneous environments. <em>ASOC</em>, <em>130</em>, 109707. (<a
href="https://doi.org/10.1016/j.asoc.2022.109707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient application scheduling is critical for achieving high performance in heterogeneous computing environments. For heterogeneous static scheduling problems, applications with a set of distributed tasks are modeled as directed acyclic graphs (DAG). The goal of scheduling is to properly allocate processors to DAG nodes and minimize the average completion time of all DAG applications. Most existing scheduling algorithms cannot fully utilize scheduling information, and are designed to schedule one DAG application at a time. Therefore, this study proposes a scheduling algorithm based on reinforcement learning for heterogeneous computing environments. A convolutional neural network with graph attention is first used to fully process and encode the scheduling information. Then, a fully connected neural network selects an appropriate node from the DAG applications for execution. Finally, a heuristic method is employed to allocate a processor to the selected node based on the earliest finish time and node duplication. This process is then repeated for every DAG node. The proximal policy optimization algorithm is used to tune all network hyperparameters. The training phase employs a reward function suitable for multi-DAG scheduling to ensure optimal performance when multiple DAG applications are scheduled concurrently. Experiments of various scheduling scenarios and types of applications were conducted, and the results show that the proposed algorithm reduces the average termination time of applications by 13.03\% over that of existing algorithms.},
  archive      = {J_ASOC},
  author       = {Ziniu Lin and Chen Li and Lihua Tian and Bin Zhang},
  doi          = {10.1016/j.asoc.2022.109707},
  journal      = {Applied Soft Computing},
  pages        = {109707},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A scheduling algorithm based on reinforcement learning for heterogeneous environments},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A two-stage deep counting for bacterial colonies from
multi-sources. <em>ASOC</em>, <em>130</em>, 109706. (<a
href="https://doi.org/10.1016/j.asoc.2022.109706">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic bacterial colony counting (BCC) from Petri dish images is full of challenges due to commonly exhibited overlapping, occlusion, and inconsistency problems. Modern deep learning methods require sufficient annotated data to identify colonies from a single source and yet usually perform badly on new sources, which makes it difficult to be extended. In this paper, a scalable two-stage deep learning framework is proposed to count bacterial colonies from multi-sources with both generic and specific features. In addition, a novel blending based strategy is proposed to augment the data and raise the robustness by increasing the sample complexity. We also suggest a refinement of the coarse results from existing BCC programmes could save a lot of time and effort for annotation. Four state-of-the-art methods are selected to compare with ours. Our method outperforms others in terms of mean average precision, averaged root-mean-square error and mean absolute percentage error. Hyper-parameters and other settings are also investigated in the experiments, which proved the scalability, robustness and accuracy of the proposed method.},
  archive      = {J_ASOC},
  author       = {Shi-Jian Liu and Pin-Chao Huang and Xing-Sheng Liu and Jin-Jia Lin and Zheng Zou},
  doi          = {10.1016/j.asoc.2022.109706},
  journal      = {Applied Soft Computing},
  pages        = {109706},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A two-stage deep counting for bacterial colonies from multi-sources},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A two-stage genetic algorithm for joint coordination of
spare parts inventory and planned maintenance under uncertain failures.
<em>ASOC</em>, <em>130</em>, 109705. (<a
href="https://doi.org/10.1016/j.asoc.2022.109705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main problem of spare parts management is to maintain the minimal requirement of stock keeping units kept. This research proposes a joint optimization model of multi-item multi-period spare parts inventory management and planned maintenance under uncertain failures in order to balance inventory cost and spare parts availability. This paper presents a Mixed Integer Non-linear Programming formulation of the inventory optimization model under a minimum and maximum inventory policy with stock review intervals. Some studies in the literature have considered aggregating spare parts inventory management as they assume that it will reduce the ordering cost. We consider both independent and aggregate spare parts inventory policies and then combine the formulation with the predictive maintenance interval, which is a replacement action due to uncertain failures under predefined distribution. Furthermore, a novel two-stage Genetic Algorithm is proposed as a sim-heuristic approach to deal with the non-linearity, combinations, and stochasticity of the problem and solve large-scale instances. In the end, we perform a computational study on some instances and a real-world case study to demonstrate the proposed approach’s effectiveness and efficiency. The computational study shows that the independent policy results in lower cost than the aggregate policy, and the proposed Genetic Algorithm performs efficiently for large-scale problems.},
  archive      = {J_ASOC},
  author       = {Vincent F. Yu and Nabila Yuraisyah Salsabila and Nurhadi Siswanto and Po-Hsun Kuo},
  doi          = {10.1016/j.asoc.2022.109705},
  journal      = {Applied Soft Computing},
  pages        = {109705},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A two-stage genetic algorithm for joint coordination of spare parts inventory and planned maintenance under uncertain failures},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Clustering mixed-type data using a probabilistic distance
algorithm. <em>ASOC</em>, <em>130</em>, 109704. (<a
href="https://doi.org/10.1016/j.asoc.2022.109704">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cluster analysis is a broadly used unsupervised data analysis technique for finding groups of homogeneous units in a data set. Probabilistic distance clustering adjusted for cluster size (PDQ), discussed in this contribution, falls within the broad category of clustering methods initially developed to deal with continuous data; it has the advantage of fuzzy membership and robustness. However, a common issue in clustering deals with treating mixed-type data: continuous and categorical, which are among the most common types of data. This paper extends PDQ for mixed-type data using different dissimilarities for different kinds of variables. At first, the PDQ for mixed-type data is defined, then a simulation design shows its advantages compared to some state of the art techniques , and ultimately, it is used on a real data set . The conclusion includes some future developments.},
  archive      = {J_ASOC},
  author       = {Cristina Tortora and Francesco Palumbo},
  doi          = {10.1016/j.asoc.2022.109704},
  journal      = {Applied Soft Computing},
  pages        = {109704},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Clustering mixed-type data using a probabilistic distance algorithm},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A variable-parameter ZNN with predefined-time convergence
for dynamic complex-valued lyapunov equation and its application to AOA
positioning. <em>ASOC</em>, <em>130</em>, 109703. (<a
href="https://doi.org/10.1016/j.asoc.2022.109703">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zeroing neural network (ZNN) is an effective means of handling the dynamic Lyapunov equation . However, the conventional ZNN’s convergence speed relies heavily on its initial value, and it is incapable of tolerating some large time-varying noises. Therefore, a complex-valued variable-parameter predefined-time convergence ZNN (CVPZNN) is proposed for handling the dynamic complex-valued Lyapunov equation (DCVLE) in this work. Unlike the conventional complex-valued ZNN, the CVPZNN model designs a novel predefined-time activation function and two exponentially-decay varying parameters for improving convergence and robustness. Different from traditional variable parameters, the decay time-varying parameters can ensure that the parameters reach a stable value after a period. Besides, in addition to the stability, the predefined-time convergence and robustness of the CVPZNN are theoretically proved. Numerical simulation verifies that CVPZNN not only has a faster convergence rate, but also has stronger robustness under bounded noises compared to other models when finding the solution to the DCVLE. Finally, the design scheme of the CVPZNN is applied to the angle of arrival (AOA) kinematic positioning for validating its feasibility.},
  archive      = {J_ASOC},
  author       = {Yongjun He and Lin Xiao and Fuchun Sun and Yaonan Wang},
  doi          = {10.1016/j.asoc.2022.109703},
  journal      = {Applied Soft Computing},
  pages        = {109703},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A variable-parameter ZNN with predefined-time convergence for dynamic complex-valued lyapunov equation and its application to AOA positioning},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An effective tremor-filtering model in teleoperation:
Three-domain wavelet least square support vector machine. <em>ASOC</em>,
<em>130</em>, 109702. (<a
href="https://doi.org/10.1016/j.asoc.2022.109702">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proper elimination of hand tremors in robot-assisted minimally invasive surgery has become a key concern due to its significant impacts on control precision and surgical success. In this study, a Three-domain Wavelet Least Square Support Vector Machine with Improved Sparrow Search Algorithm (ISSA-TDWLSSVM) model is proposed to forecast and eliminate tremor signals in teleoperation . The multi-domain analysis layer is proposed for redesigning the structure of the LSSVM. The multi-domain analysis layer is divided into three parts, complex-frequency domain, frequency domain, and time domain. The functions corresponding to three domains are the Time series, Mexican hat wavelet, and Gauss–Laplace functions. The other contribution of this study is that a novel wavelet kernel-function is proposed. Meanwhile, an improved sparrow search algorithm is proposed for optimizing the wavelet kernel-function parameter to improve the forecasting accuracy . To prove the generalization ability of the proposed model, the ISSA-TDWLSSVM and existing models are used in three examples. Compared with the existing models, the result showed that the ISSA-TDWLSSVM model has the highest forecasting accuracy . The wavelet kernel function has a good mapping ability. As compared with the LSSVM used in three-axis teleoperation robot, the Accuracy index of the ISSA-TDWLSSVM model is increased by 34.52\%. In a word, an effective model is proposed to eliminate tele-operated tremor signals in this study.},
  archive      = {J_ASOC},
  author       = {Mingzhang Pan and Qiye Yang and Tiecheng Su and Kuihua Geng and Ke Liang},
  doi          = {10.1016/j.asoc.2022.109702},
  journal      = {Applied Soft Computing},
  pages        = {109702},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An effective tremor-filtering model in teleoperation: Three-domain wavelet least square support vector machine},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). A comparison of humans and machine learning classifiers
categorizing emotion from faces with different coverings. <em>ASOC</em>,
<em>130</em>, 109701. (<a
href="https://doi.org/10.1016/j.asoc.2022.109701">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial face coverings such as sunglasses and face masks unintentionally obscure facial expressions, causing a loss of accuracy when humans and computer systems attempt to categorize emotion. With the rise of soft computing techniques interacting with humans, it is important to know not just their accuracy, but also the confusion errors being made—do humans make less random/damaging errors than soft computing? We analyzed the impact of sunglasses and different face masks on the ability to categorize emotional facial expressions in humans and computer systems. Computer systems, represented by VGG19 , ResNet50, and InceptionV3 deep learning algorithms, and humans assessed images of people with varying emotional facial expressions and with four different types of coverings, i.e. unmasked, with a mask covering the lower face, a partial mask with transparent mouth window, and with sunglasses. The first contribution of this work is that computer systems were found to be better classifiers (98.48\%) than humans (82.72\%) for faces without covering ( &gt; &amp;gt; 15\% difference). This difference is due to the significantly lower accuracy in categorizing anger, disgust, and fear expressions by humans ( p ′ s p′s&amp;lt; .001 ). However, the most novel aspect of the work is identifying how soft computing systems make different mistakes to humans on the same data. Humans mainly confuse unclear expressions as neutral emotion, which minimizes affective effects. Conversely, soft techniques often confuse unclear expressions as other emotion categories, which could lead to opposing decisions being made, e.g. a robot categorizing a fearful user as happy. Importantly, the variation in the misclassification can be adjusted by variations in the balance of categories in the training set.},
  archive      = {J_ASOC},
  author       = {Harisu Abdullahi Shehu and Will N. Browne and Hedwig Eisenbarth},
  doi          = {10.1016/j.asoc.2022.109701},
  journal      = {Applied Soft Computing},
  pages        = {109701},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A comparison of humans and machine learning classifiers categorizing emotion from faces with different coverings},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-precision traffic speed predictions via modified
sequence to sequence model and spatial dependency evaluation method.
<em>ASOC</em>, <em>130</em>, 109700. (<a
href="https://doi.org/10.1016/j.asoc.2022.109700">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding spatial–temporal characteristics of urban traffic will help improve the short-term prediction accuracy in traffic control and management. This paper focuses on mining the spatial dependence of urban traffic networks and establishes an ensemble deep learning model to address multi-precision prediction accuracy requirements. The main contributions of this work are summarized as follows. First, based on the Maximal Information Coefficient (MIC), we design a spatial dependence evaluation algorithm for detecting spatial anomalies, key roads, and the most correlated roads to the key roads. Second, an attention-based Sequence to Sequence (Seq2Seq) model with modified residual units (ARS model) is employed to make network-scale short-term traffic predictions . Third, for the key roads, we combine the MIC-based evaluation algorithm and ARS model to present a multi-task learning-based Key road Attention-based Residual Seq2Seq model (KARS model), which can significantly improve the prediction accuracy of key roads. Consequently, the ensemble model, ARS&amp;KARS, can be implemented with elementary traffic speed data to handle uneven accuracy prediction tasks (without extra topology information of road networks). The experimental results show that the proposed ensemble prediction model, ARS&amp;KARS, outperforms the benchmark model in terms of prediction accuracy and can effectively harness the intrinsic spatial dependencies of urban networks.},
  archive      = {J_ASOC},
  author       = {Jiannan Mao and Hao Huang and Weike Lu and Yuting Chen and Lan Liu},
  doi          = {10.1016/j.asoc.2022.109700},
  journal      = {Applied Soft Computing},
  pages        = {109700},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-precision traffic speed predictions via modified sequence to sequence model and spatial dependency evaluation method},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic frequency-based feature selection using discrete
weighted evolution strategy. <em>ASOC</em>, <em>130</em>, 109699. (<a
href="https://doi.org/10.1016/j.asoc.2022.109699">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High dimensional datasets usually suffer from curse of dimensionality which may increase the classification time and decrease the classification accuracy beyond a certain dimensionality. Thus, feature selection is used to discard redundant features for improving classification. Nonetheless, there is not a single feature selection method which could deal with all datasets. Thus, this paper proposes an automatic hybrid feature selection incorporating both filter and wrapper methods called Extended Mutual Congestion-Discrete Weighted Evolution Strategy (EMC-DWES). First, Extended Mutual Congestion (EMC) is proposed as a frequency-based filter ranker to discard irrelevant and redundant features using intrinsic statistics of features. Second, Discrete Weighted Evolution Strategy (DWES) is applied on the remaining features selected by EMC to perform the final automatic feature selection within a wrapper method. DWES clusters the features and applies mutation both to select the most relevant feature in each cluster at a time and to avoid selecting redundant features simultaneously through assigning greater weights to most informative clusters. The performance of EMC-DWES (in maximizing classification accuracy and minimizing the selected subset length) is investigated using benchmark high dimensional medical datasets including Covid-19. Likewise, the superiority of EMC-DWES in comparison with state-of-the-art is also evaluated in all datasets. The implementation of EMC-DWES is available on https://github.com/KhaosResearch/EMC-DWES .},
  archive      = {J_ASOC},
  author       = {Hossein Nematzadeh and José García-Nieto and Ismael Navas-Delgado and José F. Aldana-Montes},
  doi          = {10.1016/j.asoc.2022.109699},
  journal      = {Applied Soft Computing},
  pages        = {109699},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Automatic frequency-based feature selection using discrete weighted evolution strategy},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MPC using an on-line TS fuzzy learning approach with
application to autonomous driving. <em>ASOC</em>, <em>130</em>, 109698.
(<a href="https://doi.org/10.1016/j.asoc.2022.109698">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The control of complex nonlinear systems (such as autonomous vehicles) usually requires models which might be unavailable or inaccurate. In this paper, a novel data-driven Model Predictive Control (MPC) framework is proposed based on a data-driven approach to learn Takagi–Sugeno (TS) fuzzy models for nonlinear systems . To address the data TS modeling, we use the Evolving TS Fuzzy Ellipsoidal Information Granules (TS-EEFIG) approach to obtain a polytopic representation as well as a set of membership functions that allows to use efficient linear control tools to handle complex nonlinear systems. In particular, the formulated approach is applied for the autonomous driving control problem of a racing vehicle. The proposed control uses references provided by an external trajectory planner offering a high driving performance in racing mode. The control-estimation scheme is validated in a simulated racing environment based on a high fidelity vehicle model of a 1/10 scale RC car to show the potential of the proposed approach.},
  archive      = {J_ASOC},
  author       = {Eugenio Alcalá and Iury Bessa and Vicenç Puig and Olivier Sename and Reinaldo Palhares},
  doi          = {10.1016/j.asoc.2022.109698},
  journal      = {Applied Soft Computing},
  pages        = {109698},
  shortjournal = {Appl. Soft. Comput.},
  title        = {MPC using an on-line TS fuzzy learning approach with application to autonomous driving},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Fuzzified deep neural network ensemble approach for
estimating cycle time range. <em>ASOC</em>, <em>130</em>, 109697. (<a
href="https://doi.org/10.1016/j.asoc.2022.109697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because of the high uncertainty associated with predicting the cycle time of a job in a complex manufacturing system , this task is a challenge for production planners. To replace an inaccurate cycle time forecast, the range of cycle time is estimated. To estimate the cycle time range of a job as precisely as possible, a fuzzified deep neural network (FDNN) ensemble approach is proposed in this paper. This approach involves the following steps. First, a deep neural network (DNN) is constructed to predict the cycle time of a job. The parameters of the DNN are then fuzzified to generate a fuzzy cycle time forecast that contains the actual cycle time. In contrast to existing methods that involve fuzzifying multiple parameters simultaneously, which is computationally intensive, the proposed methodology involves fuzzifying parameters independently to facilitate problem-solving. Subsequently, the cycle time ranges estimated by fuzzifying various parameters are aggregated through fuzzy intersection. The proposed FDNN ensemble approach was applied to a real case to validate its effectiveness. The experimental results indicated that the precision of cycle time range estimation was up to 38\% higher with the FDNN ensemble approach than with the fuzzy backpropagation network approach.},
  archive      = {J_ASOC},
  author       = {Tin-Chih Toly Chen and Yu-Cheng Lin},
  doi          = {10.1016/j.asoc.2022.109697},
  journal      = {Applied Soft Computing},
  pages        = {109697},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fuzzified deep neural network ensemble approach for estimating cycle time range},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automated design of heuristics for the container relocation
problem using genetic programming. <em>ASOC</em>, <em>130</em>, 109696.
(<a href="https://doi.org/10.1016/j.asoc.2022.109696">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The container relocation problem is a challenging combinatorial optimisation problem tasked with finding a sequence of container relocations required to retrieve all containers by a given order. Due to the complexity of this problem, heuristic methods are often applied to obtain acceptable solutions in a small amount of time. These include relocation rules (RRs) that determine the relocation moves that need to be performed to efficiently retrieve the next container based on certain yard properties. Such rules are often designed manually by domain experts, which is a time-consuming and challenging task. This paper investigates the application of genetic programming (GP) to design effective RRs automatically. Experimental results show that RRs evolved by GP outperform several existing manually designed RRs. Additional analyses of the proposed approach demonstrate that the evolved rules generalise well across a wide range of unseen problems and that their performance can be further enhanced. Therefore, the proposed method presents a viable alternative to existing manually designed RRs and opens a new research direction in the area of container relocation problems.},
  archive      = {J_ASOC},
  author       = {Marko Đurasević and Mateja Đumić},
  doi          = {10.1016/j.asoc.2022.109696},
  journal      = {Applied Soft Computing},
  pages        = {109696},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Automated design of heuristics for the container relocation problem using genetic programming},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A deep learning based framework for remote sensing image
ground object segmentation. <em>ASOC</em>, <em>130</em>, 109695. (<a
href="https://doi.org/10.1016/j.asoc.2022.109695">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation of very-high-resolution (VHR) remote sensing images is of great significance, in which remote sensing can be applied to numerous fields. However, VHR remote sensing images are taken at different seasons and regions, causing the large intra-class and low inter-class variations of pixels. Thus, the state-of-the-art semantic segmentation network have considerable misclassifications and blurring of object boundaries. To solve the above problems, a deep learning-based semantic segmentation framework (DLSS) of VHR remote sensing images is proposed in this study, which comprising three stages. At the pre-processing stage, a novel data pre-processing method named Image Block Segmentation (IBS) is proposed to coarse segmentation of VHR remote sensing images at the image block scale. At the image segmentation stage, the different strategies are adopted to segment image blocks of different categories for fine segmentation. Through these two stages, this study implements a coarse-to-fine segmentation strategy, which reduces the phenomenon of misclassification by using different network models for low inter class variations of pixels. At the post-processing stage, a novel post-processing method termed Superpixel Cluster (SPC) is proposed to modify the segmentation results. SPC can capture fine details of objects and aggregating continuous pixels with similar characteristics into a set of superpixels, so as to ensure the boundary accuracy and internal consistency of ground object. Extensive experiments, including a comprehensive ablation study, confirm that IBS is capable of effectively reducing the misclassification, and SPC can correct the segmentation results significantly. The experimental results on the Gaofen Image Dataset (GID) suggest that the overall accuracy (OA) of the commonly utilized models combined with DLSS framework can increase, and the average is 2.05\%. The code of DLSS is available at https://github.com/dxj620/Deep-learning-semantic-segementation .},
  archive      = {J_ASOC},
  author       = {Xingjun Dong and Changsheng Zhang and Lei Fang and Yuxiao Yan},
  doi          = {10.1016/j.asoc.2022.109695},
  journal      = {Applied Soft Computing},
  pages        = {109695},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A deep learning based framework for remote sensing image ground object segmentation},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Long-term prediction of multiple types of time-varying
network traffic using chunk-based ensemble learning. <em>ASOC</em>,
<em>130</em>, 109694. (<a
href="https://doi.org/10.1016/j.asoc.2022.109694">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of networking technologies, global Internet traffic is constantly increasing. Moreover, various traffic types associated with a variety of network services and applications co-exist in the network, having diverse volume and seasonality patterns. The knowledge of future patterns of these heterogeneous traffic types is beneficial for the network operators, as it enables proper adjustment of available network resources in near real-time, and allow performing periodical network reconfigurations. In this paper, we propose a chunk-based ensemble learning method for a long-term prediction of multiple network traffic types. Our developed prediction method combines two popular machine learning (ML) approaches: chunk-based learning on data streams and ensemble learning. The proposed method does not require large volumes of training data and is resilient to changes in traffic characteristics. Finally, we create a custom metric called allocation outside blocking threshold (AOBT), which links the problem of network traffic prediction to bandwidth blocking probability in dynamic traffic routing. We compare the performance of our online method to a number of baselines, using the root mean square percentage error (RMSPE) and the proposed AOBT metrics. According to conducted experiments, the proposed streaming approach outperforms the reference ones in RMSPE and AOBT. Depending on the metric and model, chunk-based ensemble learning achieves 5\%–34\% lower prediction errors across traffic types. However, the choice of a specific model depends on the investigated traffic type and applied metric.},
  archive      = {J_ASOC},
  author       = {Aleksandra Knapińska and Piotr Lechowicz and Weronika Węgier and Krzysztof Walkowiak},
  doi          = {10.1016/j.asoc.2022.109694},
  journal      = {Applied Soft Computing},
  pages        = {109694},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Long-term prediction of multiple types of time-varying network traffic using chunk-based ensemble learning},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Incomplete label distribution feature selection based on
neighborhood-tolerance discrimination index. <em>ASOC</em>,
<em>130</em>, 109693. (<a
href="https://doi.org/10.1016/j.asoc.2022.109693">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label distribution learning (LDL), focusing on the relative importance of different labels to the instance, is proposed for solving label ambiguity problem in recent years. However, for label distribution data, the annotation information may be incomplete in the real-world and complete methods cannot be directly used to process these data. In addition, with the exponential growth of data volume, data in all walks of life tend to be high-dimensional, feature selection as an efficient preprocessing technique to reduce the dimension of data. Taking the problems of the incomplete label and high-dimensional data into consideration, an incomplete label distribution feature selection method based on neighborhood-tolerance discrimination index is proposed. The neighborhood-tolerance discrimination index is utilized to explore the distinguishing ability of the feature subset, and then a novel significance metric is constructed to evaluate the importance of features, which considers the correlations between features and labels. Compared with multi-label feature selection algorithms , the proposed algorithm is designed to directly process label distribution data without discretization , which reduces information loss in the process of discretization . Compared to existing label distribution feature selection algorithms , the proposed algorithm can directly process distribution data with missing label, which avoids the interference of noisy information. Furthermore, the superiority of the proposed method over other seven state-of-the-art methods is demonstrated by conducting comprehensive experiments with eight publicly available label distribution datasets on six widely-used metrics. The experimental results show that the proposed algorithm obtains superior performance in 91.67\% of cases against compared algorithms.},
  archive      = {J_ASOC},
  author       = {Wenbin Qian and Ping Dong and Shiming Dai and Jintao Huang and Yinglong Wang},
  doi          = {10.1016/j.asoc.2022.109693},
  journal      = {Applied Soft Computing},
  pages        = {109693},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Incomplete label distribution feature selection based on neighborhood-tolerance discrimination index},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Rule-based models via the axiomatic fuzzy set clustering and
their granular aggregation. <em>ASOC</em>, <em>130</em>, 109692. (<a
href="https://doi.org/10.1016/j.asoc.2022.109692">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rule-based models have become a popular way to represent and analyze the main knowledge residing in data because of the increasing complexity and uncertainty. For extracting semantically sound rules in a multi-view perspective, a novel rule-based model combined with the axiomatic fuzzy set (AFS) algorithm is developed in distributed systems. Using the idea of the AFS algorithm, several clusters and accompanying fuzzy descriptions are formed in terms of data distribution; thereby, the input of rules exhibits well-defined semantics by the logic compound of the predefined linguistic terms . The output of the rule is approximated by the Takagi–Sugeno (T–S) model, in which an extended weighted least squares method is designed to optimize the parameter vectors simultaneously. In virtue of the diversity of these individual results, a granular aggregation procedure incorporates the weighted principle of justifiable granularity to summarize all the local results into compact and meaningful descriptors (information granules). Five experiments considering synthetic and publicly available datasets are carried out to demonstrate the performance of the proposed approach. In addition, the proposed approach is also shown effective in an application involving the credit dataset.},
  archive      = {J_ASOC},
  author       = {Fang Zhao and Gang Li and Hongyue Guo and Lidong Wang},
  doi          = {10.1016/j.asoc.2022.109692},
  journal      = {Applied Soft Computing},
  pages        = {109692},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Rule-based models via the axiomatic fuzzy set clustering and their granular aggregation},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A fixed-time convergent and noise-tolerant zeroing neural
network for online solution of time-varying matrix inversion.
<em>ASOC</em>, <em>130</em>, 109691. (<a
href="https://doi.org/10.1016/j.asoc.2022.109691">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a common mathematical operation , the time-varying matrix inversion (TVMI) is frequently arisen in many complex problems. It has been proved in a large number of studies that the zeroing neural network (ZNN) is a reliable tool to solve TVMI problems. However, the previous reported conventional zeroing neural network (CZNN) models only achieve undesirable exponential convergence or finite-time convergence, and they are difficult to be popularized in practical applications. Therefore, by introducing a novel activation function (NAF), a fixed-time convergence and noise-tolerant zeroing neural network (FTCNTZNN) model for solving TVMI problems is proposed in this paper. Different from existing CZNN models, the proposed FTCNTZNN model possesses both fixed-time convergence and anti-noise properties for TVMI solving. To comprehensively show the superiority of the proposed FTCNTZNN model for solving TVMI, a lot of theoretical demonstrations and comparative simulation experiments have been provided in this work. Firstly, the fixed-time convergence and robustness of the proposed FTCNTZNN model are verified by detailed theoretical analysis in noiseless and noisy environment , respectively. Then, the proposed FTCNTZNN model is applied to solve two different TVMI problems in a variety of situations. In addition, a successful manipulator trajectory tracking application using the proposed FTCNTZNN model in noisy environment further validates its practicability. Both of theoretical analysis and experimental results convincingly verify that the proposed FTCNTZNN model can effectively solve TVMI problems in noiseless and noisy environment.},
  archive      = {J_ASOC},
  author       = {Jie Jin and Jingcan Zhu and Lv Zhao and Lei Chen},
  doi          = {10.1016/j.asoc.2022.109691},
  journal      = {Applied Soft Computing},
  pages        = {109691},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A fixed-time convergent and noise-tolerant zeroing neural network for online solution of time-varying matrix inversion},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unified whale optimization algorithm based multi-kernel SVR
ensemble learning for wind speed forecasting. <em>ASOC</em>,
<em>130</em>, 109690. (<a
href="https://doi.org/10.1016/j.asoc.2022.109690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support vector regression (SVR) is widely used in the field of wind speed forecasting because of its excellent nonlinear learning ability. However, the drawback of SVR is the model selection problem, which has the high complexity O ( K × m 3 ) O(K×m3) including kernel function selection and parameter selection. To solve this problem, this paper proposes a multi-kernel SVR ensemble (MKSVRE) model based on unified optimization and whale optimization algorithm (WOA), where the MKSVRE model is used to solve the kernel function selection problem, and the unified optimization and the WOA are used to solve the parameter selection problem. The proposed model provides an alternative without the need to specifically select a kernel function and thus enhances the adaptability of SVR to diverse data. In addition, the unified optimization takes into account the interactions between models and achieves a global parameter selection. The proposed model is tested by simulations on wind speed data from Shandong Province, China. By comparing the prediction results of the proposed model, the single kernel SVR models, the models before and after optimization, and six other models, the effectiveness of the proposed model is confirmed.},
  archive      = {J_ASOC},
  author       = {Huafeng Xian and Jinxing Che},
  doi          = {10.1016/j.asoc.2022.109690},
  journal      = {Applied Soft Computing},
  pages        = {109690},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Unified whale optimization algorithm based multi-kernel SVR ensemble learning for wind speed forecasting},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Axiomatic framework of entropy measure for type-2 fuzzy sets
with new representation method and its application to product ranking
through online reviews. <em>ASOC</em>, <em>130</em>, 109689. (<a
href="https://doi.org/10.1016/j.asoc.2022.109689">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Type-2 fuzzy sets (T2FSs) have the advantage of representing higher-order uncertainty, they have demonstrated superior performance in several applications. In order to fully measure the uncertainty for T2FSs. In this study, several distribution characteristics of uncertainties within T2FSs are analyzed through type-1 fuzzy sets (T1FSs), and the axiomatic framework of fuzzy entropy and overall entropy of T2FSs is established as well. First, a new representation method for T2FSs is given. On this basis, the axiomatic definitions of fuzzy entropy for T1FSs and T2FSs are constructed by analyzing the distribution characteristics of fuzziness , and the construction theorems and basic properties of fuzzy entropy are studied. Further, the overall entropy of T2FSs is given, on this basis, a novel type-2 fuzzy entropy-based decision-making method is proposed, and applied to the selection of cold medicine through online reviews on AliHealth.cn. Finally, the feasibility and effectiveness of the developed definitions and methods are demonstrated by three comparative analyses.},
  archive      = {J_ASOC},
  author       = {Jindong Qin and Tingting Xu and Pan Zheng},
  doi          = {10.1016/j.asoc.2022.109689},
  journal      = {Applied Soft Computing},
  pages        = {109689},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Axiomatic framework of entropy measure for type-2 fuzzy sets with new representation method and its application to product ranking through online reviews},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimating state of health of lithium-ion batteries based on
generalized regression neural network and quantum genetic algorithm.
<em>ASOC</em>, <em>130</em>, 109688. (<a
href="https://doi.org/10.1016/j.asoc.2022.109688">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to solve the problem of inaccurate estimation of the state of health (SOH) of electric vehicle batteries , this paper proposes a novel SOH estimation algorithm based on particle filter (PF), quantum genetic algorithm (QGA) and generalized regression neural network (GRNN). A denoising method integrating PF and anomaly detection on grouping is proposed to make the network input parameters more stable. To improve estimation accuracy and speed, an optimized GRNN-based SOH estimation model is proposed. Based on the advantages of GRNN with fewer layers and fewer hyperparameters, the Pearson correlation coefficient and QGA are used to optimize its weights to realize the adaptive determination of hyperparameters. The experiment results based on NASA and the real vehicle dataset show that the proposed algorithm has the advantages of high estimation accuracy and low computational cost, which is of great significance to the SOH estimation of electric vehicle batteries under actual operating conditions.},
  archive      = {J_ASOC},
  author       = {Anrong Xue and Wanlin Yang and Xueming Yuan and Binpeng Yu and Chaofeng Pan},
  doi          = {10.1016/j.asoc.2022.109688},
  journal      = {Applied Soft Computing},
  pages        = {109688},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Estimating state of health of lithium-ion batteries based on generalized regression neural network and quantum genetic algorithm},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Defining a deep neural network ensemble for identifying
fabric colors. <em>ASOC</em>, <em>130</em>, 109687. (<a
href="https://doi.org/10.1016/j.asoc.2022.109687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Colors characterize each object around us. For this reason, the study of colors has played a key role in Artificial Intelligence (think, for instance, of image classification , object recognition and segmentation). However, there are some topics about colors still little explored. One of them concerns fabric colors. This is a particular topic since fabrics have some characteristics, such as specific textures, that are not found in other contexts. In this paper, we want to propose a new Convolutional Neural Network (CNN) based model for identifying fabric colors. After introducing this model, we consider three different versions of it and create an ensemble of the corresponding CNNs to get better results. Finally, through a series of experiments, we show that our ensemble is able to improve the state-of-the-art on the identification of fabric colors.},
  archive      = {J_ASOC},
  author       = {Alessia Amelio and Gianluca Bonifazi and Enrico Corradini and Simone Di Saverio and Michele Marchetti and Domenico Ursino and Luca Virgili},
  doi          = {10.1016/j.asoc.2022.109687},
  journal      = {Applied Soft Computing},
  pages        = {109687},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Defining a deep neural network ensemble for identifying fabric colors},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RUL prediction for rolling bearings based on convolutional
autoencoder and status degradation model. <em>ASOC</em>, <em>130</em>,
109686. (<a href="https://doi.org/10.1016/j.asoc.2022.109686">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The remaining useful life (RUL) prediction of rolling bearings plays a key role in improving the safety and reliability assessment for rotating machinery . To accurately describe the degradation degree of bearings and perform RUL prediction, an RUL prediction method of rolling bearing combining Convolutional Autoencoder (CAE) networks and status degradation model is proposed. Firstly, the CAE is used to extract the features from the degraded bearing data; then the status degradation model is built, and the multi-dimensional health status mapping function is used to downscale the extracted features, and the reduced data points are fused with the Euclidean distance to establish the health status index that can characterize the degraded bearing. Finally, the status degradation function in the constructed model and the online update and prediction algorithm are used to adaptively estimate the RUL. The proposed method is validated with PHM datasets for RUL prediction, and its prediction performance is compared with eight prediction methods. The experimental results show that the proposed approach effectively predicts the RUL of rolling bearings and accurately evaluates the degradation degree of the bearing in a future stage.},
  archive      = {J_ASOC},
  author       = {Weiyang Xu and Quansheng Jiang and Yehu Shen and Fengyu Xu and Qixin Zhu},
  doi          = {10.1016/j.asoc.2022.109686},
  journal      = {Applied Soft Computing},
  pages        = {109686},
  shortjournal = {Appl. Soft. Comput.},
  title        = {RUL prediction for rolling bearings based on convolutional autoencoder and status degradation model},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MI-EEG classification using shannon complex wavelet and
convolutional neural networks. <em>ASOC</em>, <em>130</em>, 109685. (<a
href="https://doi.org/10.1016/j.asoc.2022.109685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many classification methods by machine learning and convolutional neural networks (CNN) have been proposed to recognize MI-EEG recently. However, the indescribable properties and individual differences of the MI-EEG signals cause low classification accuracy . In this study, a new MI-EEG classification method was designed to improve classification accuracy by combining Shannon complex wavelets and convolutional neural networks . First, the original MI-EEG was preprocessed using EEGLAB by channel selection and bandpass filtering. Second, the Shannon complex wavelet was used as the time–frequency transform strategy to calculate the time–frequency​ matrix. Finally, an improved Resnet was used to classify the time–frequency​ matrix to complete the MI-EEG identification. BCI competition IV dataset 2b as a public motor imagination dataset was tested to prove the validation of this proposed method. The classification accuracy and kappa value were adopted to prove the superiority of the proposed method by comparing it with the state-of-the-art classification methods. Experimental results showed that the classification accuracy and kappa values are 0.852 and 0.704, respectively, and they are the highest in the state-of-the-art. The parameter influence of wavelet wavelength and interception time on classification accuracy was discussed and optimized. This method can effectively improve classification accuracy and has a wide range of applications in MI-EEG classification.},
  archive      = {J_ASOC},
  author       = {Chang Wang and Yang Wu and Chen Wang and Yu Zhu and Chong Wang and Yanxiang Niu and Zhenpeng Shao and Xudong Gao and Zongya Zhao and Yi Yu},
  doi          = {10.1016/j.asoc.2022.109685},
  journal      = {Applied Soft Computing},
  pages        = {109685},
  shortjournal = {Appl. Soft. Comput.},
  title        = {MI-EEG classification using shannon complex wavelet and convolutional neural networks},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sliding mode disturbance observer and q learning-based
bilateral control for underwater teleoperation systems. <em>ASOC</em>,
<em>130</em>, 109684. (<a
href="https://doi.org/10.1016/j.asoc.2022.109684">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For underwater environments, it is difficult to acquire accurate contact force vectors between the end effecter and the object by multidimensional force sensors . Precise force measurement is the key point for accurate teleoperation tasks. However, existing force estimations are rarely concerned with multidimensional force vector estimations. Therefore, the transparency of the teleoperation system may be attenuated, even resulting in stability or task failure in practical engineering. In this paper, we focus on analyzing the contact force vector in three dimensions. A sliding mode disturbance observer is designed to estimate the contact force. A Q learning process is used to find the optimal multidimensional contact force. Furthermore, a bilateral controller is proposed based on the sliding mode disturbance observer and Q learning-based method for underwater teleoperation systems. The stability is analyzed by Lyapunov functions . Numerical simulations and real robot experiments are performed to verify the effectiveness of the proposed method.},
  archive      = {J_ASOC},
  author       = {Ting Wang and Jian Gao and Ou Xie},
  doi          = {10.1016/j.asoc.2022.109684},
  journal      = {Applied Soft Computing},
  pages        = {109684},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Sliding mode disturbance observer and q learning-based bilateral control for underwater teleoperation systems},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Diversified sine–cosine algorithm based on differential
evolution for multidimensional knapsack problem. <em>ASOC</em>,
<em>130</em>, 109682. (<a
href="https://doi.org/10.1016/j.asoc.2022.109682">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sine–cosine algorithm (SCA) is one of the simplest and efficient stochastic search algorithms in the field of metaheuristics . It has shown its efficacy in solving several real-life applications. However, in some cases, it shows stagnation at local optima and premature convergence issues due to low exploitation ability and insufficient diversity skills. To overcome these issues from the SCA, its enhanced version named ISCA is developed in this paper. The proposed ISCA is designed based on modifying the original search mechanism of the SCA and hybridizing it with a differential evolution (DE) algorithm. The search procedure in the ISCA switches between the modified search mechanism of the SCA and DE based on the evolutionary states of candidate solutions and a parameter called the switch parameter. The modified SCA enhances the exploitation ability and convergence speed, while the DE maintains the diversity of the population to avoid local optimal solutions . The parameters of the ISCA are tuned in such as way that they could balance the exploration and exploitation features. Validation of the ISCA is conducted on a benchmark set of 23 continuous optimization problems through different performance measures , which reveals its effectiveness as a better optimizer for continuous optimization problems . Furthermore, the proposed ISCA is extended to develop its efficient binary version named BISCA for solving multidimensional knapsack problems . A benchmark collection of 49 instances is used for the performance evaluation of the BISCA. Comparison of results produced by the BISCA with other algorithms and previous studies indicates its better search efficiency and verifies it as an effective alternative for solving the MKP.},
  archive      = {J_ASOC},
  author       = {Shubham Gupta and Rong Su and Shitu Singh},
  doi          = {10.1016/j.asoc.2022.109682},
  journal      = {Applied Soft Computing},
  pages        = {109682},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Diversified sine–cosine algorithm based on differential evolution for multidimensional knapsack problem},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-objective green 4-dimensional transportation problems
for damageable items through type-2 fuzzy random goal programming.
<em>ASOC</em>, <em>130</em>, 109681. (<a
href="https://doi.org/10.1016/j.asoc.2022.109681">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As per ECOFYS’s 1 report, road transportation contributes 10.5\% of the GHGE, which is the cause of global warming. With the infrastructural developments, there are several routes between different cities, even in developing countries. In a business, objectives’ goals are always uncertain. With these facts, in this investigation, a multi-objective green four-dimensional transportation problem for damageable items is formulated and solved. Here four objectives — minimization of operational cost, transportation time, carbon emission amount and maximization of retailers’ satisfaction, whose goals are type-2 fuzzy random are considered. There are several connecting paths between sources and destinations with varied traffic congestion and maximum possible velocities for different conveyances. To get a better compromise solution for multi-objectives, the type-2 fuzzy random goal programming method (T2FRGPM) is developed using the Enhanced Karnik-Mendel algorithm for type reduction of type-2 fuzzy set The model is solved by the proposed T2FRGPM and illustrated with some numerical data using Lingo 11.0. A real-life example and several particular models are presented. The effectiveness of the proposed method, the importance of the four-dimensional transportation problem, and the objectives are established. A trade-off between transportation time and carbon emission amount is presented.},
  archive      = {J_ASOC},
  author       = {Md. Samim Aktar and Manoranjan De and Sanat Kumar Mazumder and Manoranjan Maiti},
  doi          = {10.1016/j.asoc.2022.109681},
  journal      = {Applied Soft Computing},
  pages        = {109681},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-objective green 4-dimensional transportation problems for damageable items through type-2 fuzzy random goal programming},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A generic cyber immune framework for anomaly detection using
artificial immune systems. <em>ASOC</em>, <em>130</em>, 109680. (<a
href="https://doi.org/10.1016/j.asoc.2022.109680">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intrusion detection systems play a significant role in computer security. Artificial immune systems are the prime contender in developing an anomaly-based intrusion detection system due to their simplicity. The fundamental goal of this paper is to create a generic framework for an artificial immune system which is fast and accurate in detecting anomalies using artificial immune system concepts. Natural killer cells in the immune system and their quick response to foreign pathogens inspired the adaptation of those cells into an artificial immune system based framework. A natural killer cell-based framework is proposed to improve the accuracy and speed of anomaly detection . The structure of the proposed framework includes major histocompatibility complex class 1 representation, affinity calculation, cell generation, and cell proliferation. This framework addresses the overlapping and hole problem while creating natural killer cells to increase the system’s performance. The negative selection algorithm and the positive selection algorithm generate the cells that enhance the anomaly detection technique and give high precision. The parameter response time introduced in this paper is crucial for an intrusion system to be used in real-time.},
  archive      = {J_ASOC},
  author       = {B.J. Bejoy and G. Raju and Debabrata Swain and Biswaranjan Acharya and Yu-Chen Hu},
  doi          = {10.1016/j.asoc.2022.109680},
  journal      = {Applied Soft Computing},
  pages        = {109680},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A generic cyber immune framework for anomaly detection using artificial immune systems},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dijkstra solution algorithm considering fuzzy accessibility
degree for patch optimization problem. <em>ASOC</em>, <em>130</em>,
109674. (<a href="https://doi.org/10.1016/j.asoc.2022.109674">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most widely used applications for urban public transport passengers, especially for tourists, are route recommendation applications. These applications are generally based on criteria such as the shortest route, the least number of line transfers, and the least travel time. In some recent studies, there are fuzzy models that consider qualitative indicators such as comfort and accessibility in addition to these criteria. In our study, a new model and a new FuzzyDijkstra algorithm based on the Dijkstra algorithm are proposed to produce routes with the shortest path, the least transfer criteria, as well as the highest degree of accessibility. In the calculation of the accessibility degrees of the routes, concepts such as fuzzy stop neighborhoods, fuzzy intensity inside the bus, and fuzzy line accessibility were used. In the proposed algorithm, fuzzy penalty values are used to produce higher ranked routes. The validity of the proposed model and algorithm has been tested using Izmir city public transport network data. Optimal routes were generated for 100 source-target bus stop pairs that were handled randomly in the calculation experiments. Although the indicators such as the average distance traveled by the vehicle and the average number of transfers are approximately the same in the routes produced by the algorithms, it is seen that the FuzzyDijkstra algorithm gives better results compared to others with an average of 11.5\% higher degree of accessibility and an average of 13.3\% less walking distances between the transfer stops. In contrast, the FuzzyDijkstra algorithm used an average of 2.2\% more time to solve. It is clear that this time delay , the actual value of which is less than 0.5 s, will not affect the practical use of the algorithm much.},
  archive      = {J_ASOC},
  author       = {Resmiye Nasiboglu},
  doi          = {10.1016/j.asoc.2022.109674},
  journal      = {Applied Soft Computing},
  pages        = {109674},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dijkstra solution algorithm considering fuzzy accessibility degree for patch optimization problem},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Factors affecting text mining based stock prediction: Text
feature representations, machine learning models, and news platforms.
<em>ASOC</em>, <em>130</em>, 109673. (<a
href="https://doi.org/10.1016/j.asoc.2022.109673">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text mining techniques have demonstrated their effectiveness for stock market prediction and different text feature representation approaches, (e.g., TF–IDF and word embedding), have been adapted to extract textual information from financial news sources. In addition, different machine learning techniques including deep learning have been employed to construct the prediction models. Various combinations of text feature representations and learning models have been applied for stock prediction, but it is unknown which performs the best or which ones can be regarded as the representative baselines for future research. Moreover, since the textual contents in the financial news articles published on different news platforms are somewhat different, the effect of using different news platforms may have an impact on prediction performance so this is also examined in the experiments comparing eight different combinations comprised of two context-free and two contextualized text feature representations, i.e. TF–IDF, Word2vec, ELMo , and BERT , and three learning techniques, i.e. SVM , CNN , and LSTM . The experimental results show that CNN+Word2vec and CNN+BERT perform the best. The textual material is taken from three public news platforms including Reuters, CNBC, and The Motley Fool. We found that the learning models constructed and the news platforms used can certainly affect the prediction of stock prices between different companies.},
  archive      = {J_ASOC},
  author       = {Wei-Chao Lin and Chih-Fong Tsai and Hsuan Chen},
  doi          = {10.1016/j.asoc.2022.109673},
  journal      = {Applied Soft Computing},
  pages        = {109673},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Factors affecting text mining based stock prediction: Text feature representations, machine learning models, and news platforms},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multilayer neuroadaptive force control of electro-hydraulic
load simulators with uncertainty rejection. <em>ASOC</em>, <em>130</em>,
109672. (<a href="https://doi.org/10.1016/j.asoc.2022.109672">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an innovative multilayer neuroadaptive controller is firstly proposed to further improve the output force tracking performance of electro-hydraulic load simulators with uncertainty rejection. Significantly, a highly nonlinear load simulator driven by the single-rod electro-hydraulic actuators is considered, which has universal research significance in relation to the relevant studies. Moreover, smooth endogenous uncertainties, non-smooth endogenous uncertainties in the load pressure dynamics, and exogenous disturbances can all be effectively compensated in a feedforward way, which makes it possess higher load simulation accuracy and wider applicability to working conditions. In detail, multilayer neural networks and extended state observer are employed to estimate endogenous uncertainties and exogenous disturbances , respectively. Specially, the neural network weights are on-line updated via the composite errors comprised of the force tracking and estimate errors, which can increase the resulting learning ability. The closed-loop stability is guaranteed via the strict Lyapunov stability analysis and extensive comparative application results are achieved to validate the high-performance efficacy of the proposed intelligent learning algorithm.},
  archive      = {J_ASOC},
  author       = {Guichao Yang and Jianyong Yao},
  doi          = {10.1016/j.asoc.2022.109672},
  journal      = {Applied Soft Computing},
  pages        = {109672},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multilayer neuroadaptive force control of electro-hydraulic load simulators with uncertainty rejection},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Fuzzy and elitist cuckoo search based microscopic image
segmentation approach. <em>ASOC</em>, <em>130</em>, 109671. (<a
href="https://doi.org/10.1016/j.asoc.2022.109671">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microscopic images have the potential to talk about much precious information about the internal structure of living organisms. But the naked eye is not always efficient enough to explore various hidden information from the microscopic images and here the need for automated image analysis tools comes into the picture. The interval type 2 fuzzy C-Means clustering and cuckoo search-based microscopic image segmentation approach is proposed in this work. The proposed algorithm will be known as the EFECS (Enhanced Fuzzy Elitist Cuckoo Search algorithm) approach that overcomes the dependency on the initial selection of the cluster centers by using the randomness of the EFECS method. EFECS method uses interval type 2 fuzzy membership to update the cluster centers. The proposed EFECS method is compared with some well-known methods to prove its superiority. The results are verified using both qualitative and quantitative manner. Experimental results established the superiority and the real-life applicability of the proposed EFECS algorithm. On average (for 150 images), the proposed approach archives 0.901537 DB index value (5 clusters), 0.629407 XB index value (5 clusters), 2.84774 Dunn index value (5 clusters), and 4.368482 β β index value (7 clusters) that outperforms its nearest competitors CS with 0.904246 DB index value (7 clusters), ACO with 0.763519 XB index value (9 clusters), CS with 2.59191 Dunn index value (5 clusters), and ACO with 4.24919 β β index value (7 clusters) respectively. Moreover, on average, the proposed approach achieves MSE values 297.8501535 (3 clusters), 303.4967502 (5 clusters), 296.6295076 (7 clusters), 311.9109645 (9 clusters) that also outperforms other approaches.},
  archive      = {J_ASOC},
  author       = {Shouvik Chakraborty and Kalyani Mali},
  doi          = {10.1016/j.asoc.2022.109671},
  journal      = {Applied Soft Computing},
  pages        = {109671},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fuzzy and elitist cuckoo search based microscopic image segmentation approach},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Faulty feeder detection based on image recognition of
current waveform superposition in distribution networks. <em>ASOC</em>,
<em>130</em>, 109663. (<a
href="https://doi.org/10.1016/j.asoc.2022.109663">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Faulty feeder detection is essential for maintaining the security and stability of energy supply in distribution networks . However, it is rather difficult to identify a specific faulty feeder owing to small fault currents and complex fault transients . To improve the detection accuracy, this study proposes a faulty-feeder detection method based on image recognition of superimposed zero-sequence currents. A convolutional neural network (CNN) is utilized to recognize the superimposed currents in the same plot, rather than a raw single current, which can realize correlation comparisons between the currents. In addition, the zero-sequence currents of different feeders are superimposed according to a specific sequence, and the CNN can adapt to the changing topologies of distribution networks while conducting correlation comparisons. Because zero-sequence currents decay rapidly over time, an attention learning block is embedded into the CNN to enhance the discriminative capability. A total of 14, 718 sets of experimental data obtained from simulations and practical distribution networks were collected to verify the effectiveness of the proposed method. Comparisons with other traditional methods and learning-based methods adopted in previous studies justify the superiority of the proposed method in terms of detection accuracy and detection efficiency. Therefore, the proposed method can be implemented in real distribution networks for faulty feeder detection.},
  archive      = {J_ASOC},
  author       = {Jiawei Yuan and Zaibin Jiao},
  doi          = {10.1016/j.asoc.2022.109663},
  journal      = {Applied Soft Computing},
  pages        = {109663},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Faulty feeder detection based on image recognition of current waveform superposition in distribution networks},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Blockchain digital technology empowers e-commerce supply
chain sustainable value co-creation decision and coordination
considering online consumer reviews. <em>ASOC</em>, <em>130</em>,
109662. (<a href="https://doi.org/10.1016/j.asoc.2022.109662">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From the perspective of value co-creation, this study adopted Stackelberg game theory to construct traditional e-commerce supply chain and BOCR technology e-commerce supply chain, their optimal decisions and profits are solved under decentralized and centralized decision-making. We anatomized the influence of key factors and compared different models. Then we proposed the investment decision condition, cost-sharing and profit-sharing contract to achieve coordination, then validated conclusions via numerical simulation. Findings: When the producer’s attention to consumer value increases, under decentralized decision-making, optimal sales price and service level decrease, the producer’s optimal profit increases, while the e-commerce platform’s optimal profit will first increase, then decrease; under centralized decision-making, optimal sales price decreases, and optimal service level and overall optimal profit increase. Under decentralized decision-making, in the traditional e-commerce supply chain, optimal decisions and profits first increase, then decrease with increased misrepresentation in favorable product ratings; in the BOCR technology e-commerce supply chain, members can optimize costs and increase profits by extracting more valuable information. The optimal sales price and service level show different size relationships with production cost changes. When investment costs meet specific conditions, using BOCR technology can make members more profitable. The cost-sharing and profit-sharing contract enables e-commerce coordination.},
  archive      = {J_ASOC},
  author       = {Xiaole Wan and Dongqian Yang and Zhengwei Teng},
  doi          = {10.1016/j.asoc.2022.109662},
  journal      = {Applied Soft Computing},
  pages        = {109662},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Blockchain digital technology empowers E-commerce supply chain sustainable value co-creation decision and coordination considering online consumer reviews},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Research on strip crown by uncertain sampling strategy
modified particle swarm optimization with RBF neural network.
<em>ASOC</em>, <em>130</em>, 109661. (<a
href="https://doi.org/10.1016/j.asoc.2022.109661">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The strip crown directly affects the quality of strip. The prediction of strip crown by general machine learning models usually focuses on the production of a single category of strip steel, and the models lack good prediction ability for complex industrial data environments, which will lead to an increase in production costs and a decrease in product quality. Therefore, this paper proposes a new Radial Basis Function (RBF) neural network model, which is optimized by a new uncertain sampling strategy modified PSO algorithm (US-MPSO algorithm). The main feature of the algorithm is to add a new clustering dimension to the particle swarm algorithm (PSO). In this paper, clustering optimization is combined with uncertain sampling strategy to help particle swarm optimization iteration. On the one hand, the algorithm collects the population information of the strip crown as much as possible to help the neural network to converge. On the other hand, it adopts the uncertain sampling strategy to realize the optimal iteration of the samples. Finally, it realizes the improvement of the running speed and accuracy of the algorithm. This paper uses a specific model initialization strategy and combination strategy to combine the optimization algorithm with the RBF neural network. In this paper, four different types of data sets are tested to prove the adaptability of the model for complex industrial environments. The results show that the RBF neural network optimized by the US-MPSO algorithm has better prediction accuracy than the previous RBF neural network. The optimization effect of the algorithm is very significant.},
  archive      = {J_ASOC},
  author       = {Yue Huang and Xiaomin Zhou},
  doi          = {10.1016/j.asoc.2022.109661},
  journal      = {Applied Soft Computing},
  pages        = {109661},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Research on strip crown by uncertain sampling strategy modified particle swarm optimization with RBF neural network},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A self-adaptive gradient-based particle swarm optimization
algorithm with dynamic population topology. <em>ASOC</em>, <em>130</em>,
109660. (<a href="https://doi.org/10.1016/j.asoc.2022.109660">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aggregation of individuals facilitates local information exchange, and the migration of individuals from one population to another leads to a dynamic community structure. In addition, the negative feedback regulation mechanism of organisms helps them in good living conditions. Based on the above knowledge, a novel particle swarm optimization algorithm with a self-organizing topology structure and self-adaptive adjustable parameters is proposed (KGPSO). During the optimization process, the K-Means clustering method periodically divides the particle swarm into multiple distance-based sub-swarms, and the optimal number of sub-swarms is determined by maximizing the Calinski-Harabasz index. This strategy helps maintain the population diversity and gives particles the ability to perceive the surrounding environment. The parameters used to update the particle velocity are adjusted based on the gradient descent of its fitness error, ensuring a dynamic balance between exploration and exploitation. The hyperparameters of KGPSO are tuned by Bayesian optimization method to improve the algorithm performance further. Two benchmark suites are used to evaluate the performance of KGPSO. Both ranking results and Wilcoxon signed-rank tests show that KGPSO performs best among the PSO algorithms tested. Moreover, the excellent optimization capability of KGPSO are proven in the process of X-ray CT image enhancement, making it possible to analyze the structure and motion of heterogeneous granular materials efficiently and robustly. In conclusion, the proposed KGPSO can provide a stable and powerful support for the frontier experimental research of granular materials and expand the research scope.},
  archive      = {J_ASOC},
  author       = {Daren Zhang and Gang Ma and Zhuoran Deng and Qiao Wang and Guike Zhang and Wei Zhou},
  doi          = {10.1016/j.asoc.2022.109660},
  journal      = {Applied Soft Computing},
  pages        = {109660},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A self-adaptive gradient-based particle swarm optimization algorithm with dynamic population topology},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). C-BDCLSTM: A false emotion recognition model in micro blogs
combined char-CNN with bidirectional dilated convolutional LSTM.
<em>ASOC</em>, <em>130</em>, 109659. (<a
href="https://doi.org/10.1016/j.asoc.2022.109659">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, researchers are enthusiastic about the field of sentiment computing. They pay attention to normal emotion recognition, but little to abnormal emotion recognition. In social network, users are more and more abnormal emotions, which is easy to generate in the network public opinion. However, in order to achieve different personal purposes, some users with ulterior motives often express some abnormal emotions (such as false emotion) in social networks. Recognizing false emotion correctly and effectively has great significance in analyzing users’ original views on goods, movies or hot events on various websites as well as the guidance of public opinion. In this paper, we define the false emotion by extending the definition of normal emotion recognition and propose the task of false emotion recognition based on the six-element basic emotion combined with the idea of abnormal emotion detection. We construct a Char-CNN and bidirectional dilated convolutional LSTM combined model (denoted to C-BDCLSTM) for the task of false emotion recognition in micro blogs . This model is divided into RNN and CNN units, in which RNN unit includes embedding layer, BiLSTM layer, dilation layer, attention mechanism layer, and CNN unit includes convolution pooling layer and multiple filters of different sizes. By combined RNN and CNN units, C-BDCLSTM model will learn the six emotions of micro blog comments and the polarity of micro blog content, and then carry out decision-level fusion to finally complete the task of false emotion recognition. Due to the lack of false emotion recognition data set, we specially annotate and provide a data set about the false emotion recognition of micro blog contents and micro blog comments, which includes a total of ten thousand pieces of record. The experiment results demonstrate that C-BDCLSTM outperform other baselines (BiLSTM, Char-CNN, TextRCNN, LSTM-Attention, Transformer). The F1 score of our proposed C-BDCLSTM model is 0.7259 for the six emotions classification on the data set, and the F1 score of the twelve classification including false emotion is 0.6989. In addition, we also propose an evaluation index FFS for false emotion recognition, and the FFS score of our proposed C-BDCLSTM model is 0.7013.},
  archive      = {J_ASOC},
  author       = {Zhiyang Hou and Yajun Du and Wei Li and Jinrong Hu and Hui Li and Xianyong Li and Xiaoliang Chen},
  doi          = {10.1016/j.asoc.2022.109659},
  journal      = {Applied Soft Computing},
  pages        = {109659},
  shortjournal = {Appl. Soft. Comput.},
  title        = {C-BDCLSTM: A false emotion recognition model in micro blogs combined char-CNN with bidirectional dilated convolutional LSTM},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A probabilistic-based approach for automatic identification
and refactoring of software code smells. <em>ASOC</em>, <em>130</em>,
109658. (<a href="https://doi.org/10.1016/j.asoc.2022.109658">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Programmers strive to design programs that are flexible, updateable, and maintainable. However, several factors such as lack of time, high costs, and workload lead to the creation of software with inadequacies known as anti-patterns. To identify and refactor software anti-patterns, many research studies have been conducted using machine learning . Even though some of the previous works were very accurate in identifying anti-patterns, a method that takes into account the relationships between different structures is still needed. Furthermore, a practical method is needed that is trained according to the characteristics of each program. This method should be able to identify anti-patterns and perform the necessary refactorings. This paper proposes a framework based on probabilistic graphical models for identifying and refactoring anti-patterns. A graphical model is created by extracting the class properties from the source code . As a final step, a Bayesian network is trained, which determines whether anti-patterns are present or not based on the characteristics of neighboring classes. To evaluate the proposed approach, the model is trained on six different anti-patterns and six different Java programs. The proposed model has identified these anti-patterns with a mean accuracy of 85.16 percent and a mean recall of 79\%. Additionally, this model has been used to introduce several methods for refactoring, and it has been shown that these refactoring methods will ultimately create a system with less coupling and higher cohesion.},
  archive      = {J_ASOC},
  author       = {Raana Saheb-Nassagh and Mehrdad Ashtiani and Behrouz Minaei-Bidgoli},
  doi          = {10.1016/j.asoc.2022.109658},
  journal      = {Applied Soft Computing},
  pages        = {109658},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A probabilistic-based approach for automatic identification and refactoring of software code smells},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive mutant particle swarm optimization based precise
cargo airdrop of unmanned aerial vehicles. <em>ASOC</em>, <em>130</em>,
109657. (<a href="https://doi.org/10.1016/j.asoc.2022.109657">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emerging unmanned system technologies and smart logistics have motivated logistics enterprises to use unmanned aerial vehicles (UAVs) for last-mile cargo delivery through the air so as to benefit from its flexibility and low cost. It is useful to deliver cargoes by airdrops from fixed-wing UAVs. However, wind and parameter errors of the UAV could make the cargo deviate from the desired landing point. To improve the accuracy of airdrop methods, this paper presents the Continuously Computed Release Point under conditions of strong wind (SW-CCRP) airdrop strategy to transport the cargo to a given position by a fixed-wing UAV. In this strategy, a set of differential equations are used to model the cargo motion and wind perturbations are considered. Based on the established motion model and the kinematic relationships between the cargo and the target position, the expected release point can be accurately predicted in real time. In order to satisfy the precision requirement, the precision assignment is studied to determine the permissible parameter error ranges. In view of that the conventional precision assignment methods are difficult to be applied in the airdrop system because of its complexity and strong nonlinearity , an adaptive mutant particle swarm optimization (AMPSO) algorithm is proposed to solve this problem, in which the adaptive inertia weight can balance the global and local search. In addition, the mutation factor of the AMPSO is able to avoid premature convergence and stagnation. Finally, two specific test scenarios are designed to validate the effectiveness of the proposed approaches.},
  archive      = {J_ASOC},
  author       = {An Zhang and Han Xu and Wenhao Bi and Shuangfei Xu},
  doi          = {10.1016/j.asoc.2022.109657},
  journal      = {Applied Soft Computing},
  pages        = {109657},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Adaptive mutant particle swarm optimization based precise cargo airdrop of unmanned aerial vehicles},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CodnNet: A lightweight CNN architecture for detection of
COVID-19 infection. <em>ASOC</em>, <em>130</em>, 109656. (<a
href="https://doi.org/10.1016/j.asoc.2022.109656">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of Convolutional Neural Network (CNN) on the detection of COVID-19 infection has yielded favorable results. However, with excessive model parameters, the CNN detection of COVID-19 is low in recall, highly complex in computation. In this paper, a novel lightweight CNN model, CodnNet is proposed for quick detection of COVID-19 infection. CodnNet builds a more effective dense connections based on DenseNet network to make features highly reusable and enhances interactivity of local and global features. It also uses depthwise separable convolution with large convolution kernels instead of traditional convolution to improve the range of receptive field and enhances classification performance while reducing model complexity. The 5-Fold cross validation results on Kaggle’s COVID-19 Dataset showed that CodnNet has an average precision of 97.9\%, recall of 97.4\%, F1score of 97.7\%, accuracy of 98.5\%, mAP of 99.3\%, and mAUC of 99.7\%. Compared to the typical CNNs, CodnNet with fewer parameters and lower computational complexity has achieved better classification accuracy and generalization performance . Therefore, the CodnNet model provides a good reference for quick detection of COVID-19 infection.},
  archive      = {J_ASOC},
  author       = {Jingdong Yang and Lei Zhang and Xinjun Tang and Man Han},
  doi          = {10.1016/j.asoc.2022.109656},
  journal      = {Applied Soft Computing},
  pages        = {109656},
  shortjournal = {Appl. Soft. Comput.},
  title        = {CodnNet: A lightweight CNN architecture for detection of COVID-19 infection},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CLUSTMOSA: Clustering for GPS trajectory data based on
multi-objective simulated annealing to develop mobility application.
<em>ASOC</em>, <em>130</em>, 109655. (<a
href="https://doi.org/10.1016/j.asoc.2022.109655">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobility analysis is the core idea of many applications such as vehicle navigation, trajectory analysis, POI recommendation, and traffic flow analysis. These applications collect huge spatio-temporal information represented as trajectories of a moving object such as a vehicle or people using Global Positioning System enabled devices. Various techniques are evolved to process, manage and extract useful information from trajectories. Among these techniques, clustering plays an important and integral role in developing various mobility applications. Popular traditional clustering techniques such as DBSCAN, K-means, OPTICS, hierarchical clustering , and DJ-clustering are used for this purpose. However, these techniques suffer from major issues such as entrapping in local optima and being less effective in varying densities. Further, these methods have low search capability in search space, work upon single criteria optimization , and are less scalable for the big dataset. To overcome these issues, a new multi-objective criterion-based evolutionary clustering termed CLUSTMOSA is proposed. It exploits the search capability of archived multi-objective simulated annealing (AMOSA) to cluster the dataset. It stabilizes the exploratory and exploitative behavior of the solution. In this paper, three clustering evaluation metrics are simultaneously exploited as objective functions of CLUSTMOSA. Also, a new segmentation method is presented using bearing measurement for trajectory data . It helps to eliminate multiple waypoints localized over the straight roads and prevents multiple cluster formations for the same segment. To investigate the performance, the proposed CLUSTMOSA, along with a new segmentation method using bearing measurement is compared with the state-of-art methods of trajectory data mining. The extensive experiments and analysis prove the superiority of our clustering model over state-of-art approaches.},
  archive      = {J_ASOC},
  author       = {Sumanto Dutta and Animesh Das and Bidyut Kr. Patra},
  doi          = {10.1016/j.asoc.2022.109655},
  journal      = {Applied Soft Computing},
  pages        = {109655},
  shortjournal = {Appl. Soft. Comput.},
  title        = {CLUSTMOSA: Clustering for GPS trajectory data based on multi-objective simulated annealing to develop mobility application},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybridizing machine learning with metaheuristics for
preventing convergence failures in mechanical models based on
compression field theories. <em>ASOC</em>, <em>130</em>, 109654. (<a
href="https://doi.org/10.1016/j.asoc.2022.109654">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some materials, such as reinforced concrete (RC), introduce non-linear constitutive relationships into structural models. The characterization of their structural load–strain response is usually approached by using iterative strategies, such as Newton-type methods. However, these iterative strategies may not predict the non-linear structural response of RC elements (beams) due to convergence problems (non-consistent elements). In this work we propose a novel solution to overcome the convergence failures of RC structural elements subjected to shear force modeled by Compression Field Theories (CFTs). First, a Coral Reef Optimization with Substrate Layers (CRO-SL) metaheuristic is used to solve a fitting problem between numerical and experimental results on a set of real beams tested in shear, for which the system is solvable. Then, the outputs of the CRO-SL, plus the mechanical and geometric parameters of the RC beams , are used to train different Machine Learning (ML) regression methods . These regressors are then able to predict the tensile strains of the non-consistent RC elements. The characterization of such strains allows modifying the parameterization of the system of equations, overcoming thus the convergence problem of Newton-type methods in these cases. Experiments over a set of 72 real RC beams have shown the good performance of our approach. In them we have carried out a comparison among different ML regressors including Multi-Layer perceptrons , Support Vector Regression and Random Forest , plus feature reduction techniques such as PCA.},
  archive      = {J_ASOC},
  author       = {Alejandro M. Hernández-Díaz and Jorge Pérez-Aracil and David Casillas-Perez and Emiliano Pereira and Sancho Salcedo-Sanz},
  doi          = {10.1016/j.asoc.2022.109654},
  journal      = {Applied Soft Computing},
  pages        = {109654},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Hybridizing machine learning with metaheuristics for preventing convergence failures in mechanical models based on compression field theories},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An ensemble multi-swarm teaching–learning-based optimization
algorithm for function optimization and image segmentation.
<em>ASOC</em>, <em>130</em>, 109653. (<a
href="https://doi.org/10.1016/j.asoc.2022.109653">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent optimization algorithms are widely utilized to deal with complex optimization problems in various areas. However, a single intelligent optimization algorithm cannot handle well more and more complex optimization problems . The ensemble strategy can integrate several different operators and algorithms by using some appropriate strategies and maybe obtain better optimization performance . In this paper, a new ensemble multi-swarm method based on teaching–learning-based optimization (EMTLBO) was proposed by integrating three different algorithms including the original teaching–learning-based optimization algorithm, its variant with neighborhood search and the variant with differential evolution. In EMTLBO, a new evaluating mechanism based on the fitness-based and diversity-based metrics (FDEM) for each sub-swarm was proposed to evaluate the optimization performance after a continuous generation interval. Moreover, an algorithm matching mechanism based on ranking for sub-swarms (AMM) is adapted to re-divide the population into three sub-swarms and match a suitable algorithm for each sub-swarm so as to increase the whole optimization performance. Furthermore, the experimental results on CEC2014 and CEC2017 test suits verify the feasibility and optimization performance of EMTLBO. Finally, the proposed algorithm is extended to optimize the segmentation thresholds of images and the segmentation performances on different benchmark images show that EMTLBO has good performance in most cases.},
  archive      = {J_ASOC},
  author       = {Ziqi Jiang and Feng Zou and Debao Chen and Siyu Cao and Hui Liu and Wei Guo},
  doi          = {10.1016/j.asoc.2022.109653},
  journal      = {Applied Soft Computing},
  pages        = {109653},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An ensemble multi-swarm teaching–learning-based optimization algorithm for function optimization and image segmentation},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Forgery detection in medical images with distinguished
recognition of original and tampered regions using density-based
clustering technique. <em>ASOC</em>, <em>130</em>, 109652. (<a
href="https://doi.org/10.1016/j.asoc.2022.109652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Telemedicine is one of the most significant part of the medical field. It enables transfer of medical images over the internet which offers telediagnosis facility. Due to transfer of medical images from different channels, detection of their authenticity is a crucial research concern. Copy-move forgery is one of the most popular technique for image manipulation. We propose a method for copy-move forgery detection in medical images. Our method apply boundary extraction followed by Laplacian blob detection from the image to identify regions with similar properties. Further, we utilize Good Features To Track (GFTT) and BinBoost techniques for keypoint extraction and descriptor computation, respectively. Similar descriptors are identified using Hamming distance-based nearest neighbor search. Clustering over keypoints is performed using Ant Colony Density-based Clustering (ACDC) technique. We employ Fast Sample Consensus (FSC) technique for selection of correct matches and removal of imprecise keypoints. Further, we use correlation map generation for localization of manipulated regions. Experimental outcomes display that our technique can efficaciously identify tampered medical images even when manipulated images are sustaining various geometrical and post-processing attacks. Proposed technique can also efficaciously distinguish between original and tampered region within forged medical images using Haralick texture features.},
  archive      = {J_ASOC},
  author       = {Anuja Dixit and Rahul Dixit},
  doi          = {10.1016/j.asoc.2022.109652},
  journal      = {Applied Soft Computing},
  pages        = {109652},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Forgery detection in medical images with distinguished recognition of original and tampered regions using density-based clustering technique},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Recursive grouping and dynamic resource allocation method
for large-scale multi-objective optimization problem. <em>ASOC</em>,
<em>130</em>, 109651. (<a
href="https://doi.org/10.1016/j.asoc.2022.109651">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For large-scale multi-objective optimization problems (LSMOPs), the core problem is to overcome the curse of dimensionality. Cooperate coevolution has been proven to overcome this difficulty to a certain extent, which decomposes the decision variables into a number of groups and optimizes them in a cooperative coevolutionary manner, so a good decomposition method is particularly important. However, existing decomposition methods are usually computationally expensive. In this paper, a method for detecting the interaction of decision variables in LSMOPs is proposed. It first transforms a multi-objective optimization problem into a single-objective problem. Then, recursive grouping is applied, which can detect the relationship between a decision variable and the other ones recursively and put all interacting decision variables into the same group to get better grouping results with fewer function evaluations. Once groups are determined, by analyzing the contribution of each group to the problem, the group with higher contribution will be allocated more function evaluations to perform optimization. Experimental results show that the proposed framework has competitive performance compared with four state-of-the-art algorithms.},
  archive      = {J_ASOC},
  author       = {Jin Liu and Ruochen Liu and Xilong Zhang},
  doi          = {10.1016/j.asoc.2022.109651},
  journal      = {Applied Soft Computing},
  pages        = {109651},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Recursive grouping and dynamic resource allocation method for large-scale multi-objective optimization problem},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Compression and reinforce variation with convolutional
neural networks for hyperspectral image classification. <em>ASOC</em>,
<em>130</em>, 109650. (<a
href="https://doi.org/10.1016/j.asoc.2022.109650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Hyperspectral images (HSI), dimensionality reduction methods (DRM) play a critical role in reducing the input data dimension and complexity. As much as the deep learning methods (DLM) have presented very aggressive achievements, preprocessing methods and DRM are very important to enhance the learning of DLMs. This study introduces a novel DRM called Compression and Reinforced Variation (CRV), which is used to reduce the input data dimension. The CRV minimizes the gap between the big and small related data in each class and omits the noise and redundant data. It selects the most informative features and normalizes them to enhance data distribution before inserting them into the learning model. The learning model of this study is multi-hybrid deep learning (MHDL) model to improve the extraction of multi-class HSI and spectral–spatial features. MHDL is a novel classification model that includes hybrid layers of conventional neural networks and batch normalization to avoid overfitting, normalizing the training, and extracting the spectral–spatial features for HSI. The proposed CRV provided highly efficient methods for reducing the HSI dimension and improving the classification accuracy of the MHDL model. In contrast to other conventional DRMs, CRV gave the highest accuracy in the shortest time. CRV-MHDL was also compared to seven existing classification models for three distinct datasets, and the findings demonstrated that the CRV-MHDL outperforms all of them by more than 2\%. The code of this study is available at this link: https://github.com/DalalAL-Alimi/CRV .},
  archive      = {J_ASOC},
  author       = {Dalal AL-Alimi and Zhihua Cai and Mohammed A.A. Al-qaness and Abdelghani Dahou and Eman Ahmed Alawamy and Sakinatu Issaka},
  doi          = {10.1016/j.asoc.2022.109650},
  journal      = {Applied Soft Computing},
  pages        = {109650},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Compression and reinforce variation with convolutional neural networks for hyperspectral image classification},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). De-noising of salt and pepper noise using deep
learning-based alpha-guided grey wolf optimization. <em>ASOC</em>,
<em>130</em>, 109649. (<a
href="https://doi.org/10.1016/j.asoc.2022.109649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The real images are undermined by salt and pepper noise due to uproarious sensors or communication errors. In this paper, a hybrid SAR image noise reduction using the adaptive pulse-coupled neural network (APCNN) which is optimized by an alpha-guided grey wolf optimizer (AgGWO) in the shearlet transform domain has been proposed. The shearlet transform is utilized to decompose the input SAR image. After the completion of AgGWO optimization, PCNN filtering strategy has been utilized to supplant the noisy pixels into related information pixel components, from which a restoration of the noise reduced images can be obtained. This proposed methodology efficiently resolves the difficulties that emerge from the basic PCNN parameter determination problem. In this methodology, the noisy pixels are secluded well from the image and original noiseless pixels are reestablished well, which can prompt better conservation of edges of an image. This proposed APCNN-AgGWO method has also been compared with other existing noise reduction methods and it yields superior de-noising impact, in terms of structural similarity index measure (SSIM) of 98.46\%, peak signal-to-noise ratio (PSNR) of 39.49\%, and standard deviation (STD) of 38.64\%.},
  archive      = {J_ASOC},
  author       = {Raja J. and Moorthi K. and Aruna Rajendran},
  doi          = {10.1016/j.asoc.2022.109649},
  journal      = {Applied Soft Computing},
  pages        = {109649},
  shortjournal = {Appl. Soft. Comput.},
  title        = {De-noising of salt and pepper noise using deep learning-based alpha-guided grey wolf optimization},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-type features separating fusion learning for speech
emotion recognition. <em>ASOC</em>, <em>130</em>, 109648. (<a
href="https://doi.org/10.1016/j.asoc.2022.109648">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech Emotion Recognition (SER) is a challengeable task to improve human–computer interaction. Speech data have different representations, and choosing the appropriate features to express the emotion behind the speech is difficult. The human brain can comprehensively judge the same thing in different dimensional representations to obtain the final result. Inspired by this, we believe that it is reasonable to have complementary advantages between different representations of speech data. Therefore, a Hybrid Deep Learning with Multi-type features Model (HD-MFM) is proposed to integrate the acoustic, temporal and image information of speech. Specifically, we utilize Convolutional Neural Network (CNN) to extract image information from the spectrogram of speech. Deep Neural Network (DNN) is used for extracting the acoustic information from the statistic features of speech. Then, Long Short-Term Memory (LSTM) is chosen to extract the temporal information from the Mel-Frequency Cepstral Coefficients (MFCC) of speech. Finally, three different types of speech features are concatenated together to get a richer emotion representation with better discriminative property. Considering that different fusion strategies affect the relationship between features, we consider two fusion strategies in this paper named separating and merging. To evaluate the feasibility and effectiveness of the proposed HD-MFM, we perform extensive experiments on EMO-DB and IEMOCAP of SER. The experimental results show that the separating method has more significant advantages in feature complementarity. The proposed HD-MFM obtains 91.25\% and 72.02\% results on EMO-DB and IEMOCAP. The obtained results indicate the proposed HD-MFM can make full use of the effective complementary feature representations by separating strategy to further enhance the performance of SER.},
  archive      = {J_ASOC},
  author       = {Xinlei Xu and Dongdong Li and Yijun Zhou and Zhe Wang},
  doi          = {10.1016/j.asoc.2022.109648},
  journal      = {Applied Soft Computing},
  pages        = {109648},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-type features separating fusion learning for speech emotion recognition},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Non-parameter clustering algorithm based on saturated
neighborhood graph. <em>ASOC</em>, <em>130</em>, 109647. (<a
href="https://doi.org/10.1016/j.asoc.2022.109647">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering algorithms play a very important role in the field of data mining and machine learning . However existing clustering methods are sensitive to parameters and outliers. The commonly used clustering methods are restricted by problem of parameter selection that different algorithms need to input one or more different parameters. For overcoming these drawbacks, we propose a non-parameter clustering algorithm based on saturated neighborhood graph known as NPCSNG. NPCSNG algorithm uses mathematic method to preprocess the data set, and then uses the characteristics of SNG adaptive clustering to cluster the data, so as to achieve the purpose of non-parameter clustering. NPCSNG has three main advantages: (1) it does not need to manually set any parameters due to the use of adaptive saturated neighborhood graph ; (2) it significantly improves the clustering performance as well as the model robustness, making NPCSNG a more practical approach for real-world scenarios; (3) it can easily adapt to data-sets with complex manifold structure. NPCSNG algorithm solves the problem of parameter selection of clustering algorithm and it broadens the idea of clustering by using the characteristics of graphs.},
  archive      = {J_ASOC},
  author       = {Jinghui Zhang and Lijun Yang and Yong Zhang and Dongming Tang and Tao Liu},
  doi          = {10.1016/j.asoc.2022.109647},
  journal      = {Applied Soft Computing},
  pages        = {109647},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Non-parameter clustering algorithm based on saturated neighborhood graph},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SLMGAN: Single-layer metasurface design with symmetrical
free-form patterns using generative adversarial networks. <em>ASOC</em>,
<em>130</em>, 109646. (<a
href="https://doi.org/10.1016/j.asoc.2022.109646">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The metasurfaces offering the required spectral responses have ushered in a revolution of manipulating the light in a prescribed manner. A single-layer metasurface design is more appealing than a multi-layer one due to the fabrication complexities. To date, various research groups have explored on architected metasurfaces with general shapes of cubes, crosses, or octothorpes, while a few works utilized evolutionary algorithms to search for metasurfaces with free-form patterns, which relied on the quality of the initial guess. In this paper, a solution is presented to replace the intuition-based approach with generative adversarial networks . The constructed generative networks mathematically formulate the virtual mappings between the pairs of optical spectra and symmetrical patterns with user-defined geometric structures. When fed a time sequence of spectra, the designed networks assimilate the physical property and generate on-demand patterns to match the desired responses. The output patterns are proved to yield matching optical responses with an average accuracy of 0.9. Generative Adversarial Networks are firstly applied to single-layer metasurface designs with symmetrical free-form patterns for desired optical spectra in an inverse-design system.},
  archive      = {J_ASOC},
  author       = {Manna Dai and Yang Jiang and Feng Yang and Xinxing Xu and Weijiang Zhao and My Ha Dao and Yong Liu},
  doi          = {10.1016/j.asoc.2022.109646},
  journal      = {Applied Soft Computing},
  pages        = {109646},
  shortjournal = {Appl. Soft. Comput.},
  title        = {SLMGAN: Single-layer metasurface design with symmetrical free-form patterns using generative adversarial networks},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Small-world spiking neural network with anti-interference
ability based on speech recognition under interference. <em>ASOC</em>,
<em>130</em>, 109645. (<a
href="https://doi.org/10.1016/j.asoc.2022.109645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The external interference can hamper the normal function of neuromorphic hardware under complex noise environment. Therefore, the study of brain-like models with anti-interference ability is a crucial issue. A bio-brain has the advantage of self-adaptability. The existing brain-like models are lack of bio-interpretability. Drawing from the advantage of bio-brain, the purpose of this paper is to investigate the anti-interference ability of brain-like models with bio-interpretability. In this study, we construct a spiking neural network with a small-world topology (SWSNN) as a brain-like model, in which Izhikevich neuron models and synaptic plasticity models with time-delay are used to represent the nodes and edges of the network, respectively. Then, the anti-interference ability of our SWSNN against different external noise is investigated, and its mechanism is explored. Further, by taking the speech recognition task as the case study, we verify the anti-interference ability of the SWSNN. Our simulation results indicate that: (i) The anti-interference ability of SWSNN is better than that of SNNs with other topologies. (ii) The discussion of neural information processing of the SWSNN under interference implies that the dynamic regulation of synaptic plasticity is an intrinsic factor of the anti-interference, and the topology is a factor that affects the anti-interference at the level of performance. (iii) Taking the speech recognition task as a case study, the SWSNN under different external noises still have almost the same high speech recognition accuracy, compared with the SWSNN without interference, and SWSNN yields better anti-interference ability than SNNs with other topologies in terms of the speech recognition accuracy. In addition, the anti-interference ability of our SWSNN framework is superior to that of existing liquid state machine (LSM) framework. Our simulation results lay a preliminary foundation for the neuromorphic hardware with robustness under complex noise environment.},
  archive      = {J_ASOC},
  author       = {Lei Guo and Qi Zhao and Youxi Wu and Guizhi Xu},
  doi          = {10.1016/j.asoc.2022.109645},
  journal      = {Applied Soft Computing},
  pages        = {109645},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Small-world spiking neural network with anti-interference ability based on speech recognition under interference},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evolutionary optimization of thermo-physical properties of
MWCNT-Fe3O4/water hybrid nanofluid using least-squares support vector
regression-based models. <em>ASOC</em>, <em>130</em>, 109644. (<a
href="https://doi.org/10.1016/j.asoc.2022.109644">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decisions on optimizing design and operating parameters are challenging when using hybrid nanofluids (HNFs). A procedure is proposed and implemented for predicting and optimizing the thermal conductivity and dynamic viscosity of MWCNT-Fe 3 O 4 /water HNF. The procedure involves using precise least-squares support vector regression (LSSVR) models, multi-objective genetic optimization of thermal properties, and automated selection of optimal design conditions. Tuned parameters are the volume fractions of nanoparticles and the operating temperature. The cross-validated and carefully optimized LSSVR models for thermal conductivity and dynamic viscosity showed excellent performances, with testing mean percentage errors of −0.246 and −0.103\%, and relative root mean square errors of 1.325 and 2.165\%, respectively. By assigning equal importance to the two response parameters, an HNF with volume fractions of 0.302 (Fe 3 O 4 ) and 0.183\% (MWCNT), operating at 55 °C, is highlighted as the optimal design within the considered range of tuned parameters. This corresponds to a particle mixing proportion (PMP) of 0.605, and the corresponding values of thermal conductivity and dynamic viscosity are 0.803 W/m K and 0.625 mPa s, respectively.},
  archive      = {J_ASOC},
  author       = {Muhammed A. Hassan and Mohamed Abubakr Hassan and Debjyoti Banerjee and Hussien Hegab},
  doi          = {10.1016/j.asoc.2022.109644},
  journal      = {Applied Soft Computing},
  pages        = {109644},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Evolutionary optimization of thermo-physical properties of MWCNT-Fe3O4/water hybrid nanofluid using least-squares support vector regression-based models},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The role of input selection and climate pre-classification
on the performance of neural networks irradiance models. <em>ASOC</em>,
<em>130</em>, 109643. (<a
href="https://doi.org/10.1016/j.asoc.2022.109643">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Network (NN) models are widely accepted in the derivation of solar radiation models due to their ability to adapt to various geographic and environmental conditions. Despite this, it is unclear what training variables are required to enhance the precision of the NN model or which of them could be considered redundant; therefore, this paper intends to clarify this issue by investigating if the Köppen climate classification could be used to substitute climatic measurements. To this end, We analyzed a variety of NN architectures using 20 years of data from 1629 weather stations belonging to three different climate types (Climate A, B, and C). We found that Köppen climate sub-classification had a limited effect on the models’ performance when the information of all data types was processed together, resulting in barely noticeable improvements from 1.2\% to 2.5\%. However, if data were pre-classified according to climate type, the climate sub-classification input induced significant differences. Improvements up to 14\% in the precision of the models were found for Climates B and A; moreover, temperature and relative humidity daily measurements could be replaced by Köppen climate information. Cross-validation analysis, using the same amount of data for all climate types, allowed us to confirm our findings for Climates A and B and revealed that data pre-classification according to climate type for Climate C, systematically increased errors from 10\% to 24\%, so replacing actual climatological measurements was not possible for this climate type. Revealing such patterns would facilitate the derivation of models for scenarios of limited information on temperature and relative humidity in some locations and reveals the usefulness of soft computing to go beyond understanding climate complexity.},
  archive      = {J_ASOC},
  author       = {Omar Rodriguez-Abreo and Ilse Cervantes},
  doi          = {10.1016/j.asoc.2022.109643},
  journal      = {Applied Soft Computing},
  pages        = {109643},
  shortjournal = {Appl. Soft. Comput.},
  title        = {The role of input selection and climate pre-classification on the performance of neural networks irradiance models},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intelligent candlestick forecast system for financial
time-series analysis using metaheuristics-optimized multi-output machine
learning. <em>ASOC</em>, <em>130</em>, 109642. (<a
href="https://doi.org/10.1016/j.asoc.2022.109642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The effective prediction of stock market prices and trends is a critical topic in financial research for investors and stakeholders who wish to increase their return on investment . Motivated by highly unstable stock market targets and the continuous trading system that has been launched by Taiwan’s stock market, this work develops an intelligent candlestick forecast system (ICFS), which combines the advantages of three forecasting techniques — single-point, interval value, and trend forecasting. The ICFS is simple and intuitive, using a sliding-window metaheuristic-optimized multi-output least squares support vector regression hybrid model scheme to forecast simultaneously four types of price information that are represented on a candlestick chart. Three parameter-free metaheuristic algorithms, namely teaching-learning-based optimization (TLBO), symbiotic organisms search (SOS), and forensic-based investigation (FBI), are in turn used to optimize the hyperparameters of the multi-output least squares support vector regression (MLSSVR) model, to increase its accuracy and stability in predicting stock prices. Benchmark data from relevant studies are used to compare the forecast performances of previously developed and the three proposed hybrid models. Among all tested models, the FBI-MLSSVR greatly outperforms the others in forecasting Standard &amp; Poor’s (S&amp;P) and National Association of Securities Dealers Automated Quotations (NASDAQ) indexes, Taiwan’s exchange-traded funds, and major listed construction companies. A floating dollar-cost averaging strategy for maximizing returns while minimizing investment risks is proposed and compared with traditional dollar-cost averaging and the buy-and-hold strategy. The profitability of the predictions made using the proposed system is verified against actual stock market operations. The ICFS is packaged as a visualized expert system and independent application program for the convenience of users, who can intuitively run it and interpret its forecasts. Therefore, this study is highly practical by providing stakeholders with an easy-to-use and accurate predictive tool.},
  archive      = {J_ASOC},
  author       = {Jui-Sheng Chou and Ngoc-Mai Nguyen and Chih-Pin Chang},
  doi          = {10.1016/j.asoc.2022.109642},
  journal      = {Applied Soft Computing},
  pages        = {109642},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Intelligent candlestick forecast system for financial time-series analysis using metaheuristics-optimized multi-output machine learning},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Application of artificial bee colony programming techniques
for predicting the compressive strength of recycled aggregate concrete.
<em>ASOC</em>, <em>130</em>, 109641. (<a
href="https://doi.org/10.1016/j.asoc.2022.109641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of recycled aggregate concrete (RAC) in the construction industry can help to prevent irreparable environmental damages and to mitigate the depletion rate of natural resources. However, the quality of the RAC should be investigated before its practical applications. Compressive strength of the RAC ( f RAC ′ fRAC′ ) is one of the most crucial design parameters, which is measured by time-consuming and cost-extensive experiments. One solution to restrict the number of experiments and achieve reliable f RAC ′ fRAC′ estimation is through employing machine learning methods, Artificial Bee Colony Expression Programming (ABCEP) is a newly proposed automatic regression technique that is used in this study to predict the f RAC ′ fRAC′ . For comparison purposes, four extensions of artificial bee colony programming techniques (i.e., Artificial Bee Colony Programming (ABCP), quick Artificial Bee Colony Programming (qABCP), Quick semantic Artificial Bee Colony Programming (qsABCP), and Semantic Artificial Bee Colony Programming (sABCP)) were also served. To analyze the results, the average and best performances of all algorithms, regression analysis, execute run times, Wilcoxon signed-rank test, and the behavior of algorithms dealing with the local optima were investigated. The results show that the ABCEP method is the most effective technique, with the average root mean squared error of 10.36 MPa compared to 16.23 MPa, 10.82 MPa, 17.71 MPa, and 14.20 MPa for the developed ABCP-, qABCP-, qsABCP-, and sABCP-based models, respectively, in colony size of 30. In addition, the run time of this algorithm is remarkably less than the other algorithms.},
  archive      = {J_ASOC},
  author       = {Seyed Amirhossein Moghaddas and Masood Nekoei and Emadaldin Mohammadi Golafshani and Ali Behnood and Mehrdad Arashpour},
  doi          = {10.1016/j.asoc.2022.109641},
  journal      = {Applied Soft Computing},
  pages        = {109641},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Application of artificial bee colony programming techniques for predicting the compressive strength of recycled aggregate concrete},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design of fractional comprehensive learning PSO strategy for
optimal power flow problems. <em>ASOC</em>, <em>130</em>, 109638. (<a
href="https://doi.org/10.1016/j.asoc.2022.109638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal reactive power dispatch (ORPD) is one of the paramount issue for the researchers during the investigation of power system performance in dynamic load scenarios. In this paper, a new nature inspired computing paradigm based on fractional order comprehensive learning particle swarm optimization (FO-CLPSO) is designed and implemented for solving the reactive power dispatch problems. The objective of the study is to improve the power system efficiency by reducing line losses, enhancing bus voltage profiles and reducing the operating cost of the system for different load factors. The decision variables for the fitness evaluation are the tap changer settings, generator bus voltages, fixed capacitors and flexible AC transmission systems (FACTS). The operation, validity and scalability of the FO-CLPSO are tested on standard IEEE 30 bus and IEEE-57 bus systems. The exploitation and exploration for FO-CLPSO are further extended using different fractional orders for minimization problems in ORPD to critically analyze the performance by comparing with several state of art counterpart methodologies. The stability, consistency, robustness and reliability of FO-CLPSO for the solution of ORPD problems is also substantiated through detailed statistical analyses including the development of empirical cumulative distribution functions, probability plots, box plot illustrations and histograms both for precision and complexity metrics.},
  archive      = {J_ASOC},
  author       = {Yasir Muhammad and Muhammad Asif Zahoor Raja and Muhammad Altaf and Farman Ullah and Naveed Ishtiaq Chaudhary and Chi-Min Shu},
  doi          = {10.1016/j.asoc.2022.109638},
  journal      = {Applied Soft Computing},
  pages        = {109638},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Design of fractional comprehensive learning PSO strategy for optimal power flow problems},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-class imbalanced enterprise credit evaluation based on
asymmetric bagging combined with light gradient boosting machine.
<em>ASOC</em>, <em>130</em>, 109637. (<a
href="https://doi.org/10.1016/j.asoc.2022.109637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing research on multi-class imbalanced enterprise credit evaluation modeling has been built on data-level imbalance processing methods and single classifier approaches. Using the one-versus-one (OVO) decomposition and fusion method to dispose multi-class classification, this paper proposes two new credit evaluation ensemble models by combining the asymmetric bagging (AB) and the light gradient boosting machine (LightGBM). Based on a multi-class imbalanced dataset of Chinese enterprises that issue corporate bonds from 2014 through 2020, this study conducts a series of empirical experiments for multi-class imbalanced enterprise credit evaluation. The experimental results demonstrate that our proposed models can significantly outperform the benchmark models , which integrate the OVO and one-versus-all decomposition and fusion method respectively with the random under sampling LightGBM, random over sampling LightGBM, synthetic minority over sampling technique LightGBM and the AB decision tree . In addition, the proposed models can carry out analysis on feature importance, which provides decision-making basis for enterprise stakeholders.},
  archive      = {J_ASOC},
  author       = {Jie Sun and Jie Li and Hamido Fujita},
  doi          = {10.1016/j.asoc.2022.109637},
  journal      = {Applied Soft Computing},
  pages        = {109637},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-class imbalanced enterprise credit evaluation based on asymmetric bagging combined with light gradient boosting machine},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-criteria framework for addressing digitalization
solutions of medical system under interval-valued t-spherical fuzzy
information. <em>ASOC</em>, <em>130</em>, 109635. (<a
href="https://doi.org/10.1016/j.asoc.2022.109635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the help of Internet technology, digital reform of the medical system has gradually sprung up and begun to reconstruct the medical and health industry chain and service model, which has brought great change to the medical industry. At present, there are many digitalization solutions of medical system on the market. However, there are many differences in the technical standards, functions, prices and service objects of these solutions, and the objective environment is uncertain. At the same time, decision-makers often have subjective uncertainty when making choices. Therefore, it is difficult for decision-makers to choose the most satisfactory one from many digitalization solutions. To solve these problems, this study proposes the IVT-SFS weighted Muirhead mean (IVTSFWMM) operator, and establishes the evaluation and decision-making method of digitalization solutions of medical system based on this operator. Then we apply this method to cases and select the best performing solution from the four existing digitalization solutions of medical system in the market to prove the effectiveness of the method. The advantage of the method proposed in this study is that it can express subjective uncertainty when the decision-maker gives the evaluation information in the form of interval-valued fuzzy numbers, and the interaction between any number of indicators can be considered when aggregating indicators. The results show that the method proposed in this paper can effectively express the fuzzy evaluation information in complex environments, and provide suggestions for system designers to provide decision support for the evaluation and selection of intelligent medical solutions.},
  archive      = {J_ASOC},
  author       = {Zaoli Yang and Tingting Zhang and Harish Garg and K. Venkatachalam},
  doi          = {10.1016/j.asoc.2022.109635},
  journal      = {Applied Soft Computing},
  pages        = {109635},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-criteria framework for addressing digitalization solutions of medical system under interval-valued T-spherical fuzzy information},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exact and heuristic approaches for the root sequence index
allocation problem. <em>ASOC</em>, <em>130</em>, 109634. (<a
href="https://doi.org/10.1016/j.asoc.2022.109634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In mobile wireless networks, the Root Sequence Index (RSI) is used to allocate uplink channels between the user equipment and the base station . The assignment of RSIs close-in-range to neighbor radios may cause collisions leading to failures on service establishment and performance degradation . In this paper, we model the RSI allocation as a generalization of the classical Graph Coloring Problem , indicating that there must be a minimum distance for the assigned colors of two neighbors. For the RSI allocation, a maximal distance is also needed. We develop methods for allocating the RSI, while minimizing the risk of collisions, for two different operation modes found on carrier-grade networks. Both exact and heuristic methods are explored and compared. We test the proposed approaches on instances obtained from real-life context.},
  archive      = {J_ASOC},
  author       = {Mariana A. Londe and Carlos E. Andrade and Luciana S. Pessoa},
  doi          = {10.1016/j.asoc.2022.109634},
  journal      = {Applied Soft Computing},
  pages        = {109634},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Exact and heuristic approaches for the root sequence index allocation problem},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving the bi-LSTM model with XGBoost and attention
mechanism: A combined approach for short-term power load prediction.
<em>ASOC</em>, <em>130</em>, 109632. (<a
href="https://doi.org/10.1016/j.asoc.2022.109632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short term power load forecasting plays an important role in the management and development of power systems with a focus on the reduction in power wastes and economic losses. In this paper, we construct a novel, short-term power load forecasting method by improving the bidirectional long short-term memory (Bi-LSTM) model with Extreme Gradient Boosting (XGBoost) and Attention mechanism . Our model differs from existing methods in the following three aspects. First, we use the weighted grey relational projection algorithm to distinguish the holidays and non-holidays in the data preprocessing . Secondly, we add the Attention mechanism to the Bi-LSTM model to improve the validity and accuracy of prediction. Thirdly, XGBoost is a newly-developed, well-performing prediction model, which is used together with the Attention mechanism to optimize the Bi-LSTM model. Therefore, we develop a novel, combined power load prediction model “Attention-Bi-LSTM + XGBoost” with the weight determination theory-error reciprocal method. Using two power market datasets, we evaluate our prediction method by comparing it with two benchmark models and four other models. With our prediction method, the MAPE, MAE , and RMSE for the Singapore’s power market are 0.387, 43.206, and 54.357, respectively; and those for the Norway’s power market are 0.682, 96.278, and 125.343, respectively. The test results are smaller than the results for six other models. This indicates that our prediction method outperforms the LSTM, Bi-LSTM, Attention-RNN, Attention-LSTM, Attention-Bi-LSTM, and XGBoost in effectiveness, accuracy, and practicability.},
  archive      = {J_ASOC},
  author       = {Yeming Dai and Qiong Zhou and Mingming Leng and Xinyu Yang and Yanxin Wang},
  doi          = {10.1016/j.asoc.2022.109632},
  journal      = {Applied Soft Computing},
  pages        = {109632},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Improving the bi-LSTM model with XGBoost and attention mechanism: A combined approach for short-term power load prediction},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). IM-NKA: A natural killer cell algorithm for earthquake
prediction based on extremely imbalanced precursor data. <em>ASOC</em>,
<em>130</em>, 109629. (<a
href="https://doi.org/10.1016/j.asoc.2022.109629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Earthquake prediction plays a vital role in reducing the risk of earthquakes to human beings. However, the precursor seismic data is extremely imbalanced, resulting in unsatisfactory performances of standard algorithms on earthquake prediction. In this paper, we propose a Natural Killer cell Algorithm inspired by the Induction and phenotype discrimination Mechanism of natural killer cells (IM-NKA) for earthquake prediction. IM-NKA first generates induction pathogens (synthetic samples) in the hyper-sphere area around each pathogen (selected minority instance), called NKI. After balancing the dataset, the IM-NKA generates the phenotype detectors. Then, the IM-NKA is used to predict earthquakes with a magnitude larger than 3.5 in the next day. The experiment consists of two parts: the first part compares the NKI with four oversampling methods and demonstrates that using NKI as an oversampling method can effectively improve the quality of synthetic samples for unbalanced earthquake prediction; the second part compares the performance of IM-NKA with eight different classifiers. The experiment results show that the performance of earthquake prediction using IM-NKA also significantly outperforms other classifiers.},
  archive      = {J_ASOC},
  author       = {Dongmei Wang and Yiwen Liang and Xinmin Yang},
  doi          = {10.1016/j.asoc.2022.109629},
  journal      = {Applied Soft Computing},
  pages        = {109629},
  shortjournal = {Appl. Soft. Comput.},
  title        = {IM-NKA: A natural killer cell algorithm for earthquake prediction based on extremely imbalanced precursor data},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ordinary differential equation based neural network coupled
with random forest in the quality assessment of hand hygiene processes.
<em>ASOC</em>, <em>130</em>, 109627. (<a
href="https://doi.org/10.1016/j.asoc.2022.109627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We describe a novel approach for quality assessment of hand hygiene process based on combination of ordinary differential equation (ODE) neural network and random forest . The continuous-time recurrent neural network (RNN) with ODE hidden nodes is utilized. Unlike traditional continuous-time RNNs, the ODE network in this scheme applies an input-dependent varying time-constant models referred as liquid time-constant (LTC) RNN. It expresses stable and bounded behavior and yields superior expressivity. The random forest is attractive for findings of multiple trees in classification. It is built from multiple LTC networks, each network is corresponding to each tree. The experimental results showed that the proposed approach attains the recognition accuracy of 98.9\% for single handwashing step and 78\% for the whole handwashing process.},
  archive      = {J_ASOC},
  author       = {Ho Dac Quan and Huynh Duc Khai and Hieu Trung Huynh},
  doi          = {10.1016/j.asoc.2022.109627},
  journal      = {Applied Soft Computing},
  pages        = {109627},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Ordinary differential equation based neural network coupled with random forest in the quality assessment of hand hygiene processes},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A deep learning refinement strategy based on efficient
channel attention for atrial fibrillation and atrial flutter signals
identification. <em>ASOC</em>, <em>130</em>, 109552. (<a
href="https://doi.org/10.1016/j.asoc.2022.109552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Atrial fibrillation (AF) and atrial flutter (AFL) are the most frequent arrhythmias recently. However, given both similar physiological features, visually evaluating electrocardiogram as the most traditional diagnosis scheme is taxing and error-prone. In this work, we specifically design two network modules based on bidirectional long short term memory (BiLSTM) and gate recurrent unit (BiGRU) for automatic AF and AFL detection. Motivated from Efficient Channel Attention network , we aim to reformulate BiLSTM and BiGRU with a feature recalibration approach that enables the model to adaptively focus more on the relevant feature representations and suppress irrelevant parts while appropriately capturing cross-channel interaction for learning effective channel attention. The results lead to consistent performance gains than several published researches with an accuracy of 99.2\% and 99.3\% across the two publicly available data sets while demonstrating the effectiveness of both modules. In particular, various derivative gradient values of sample ECG segments are visualized to improve interpretability . To our knowledge, this work offers the first empirical investigation of existing BiLSTM and BiGRU refinements for a better performance gain, showing great potential for many computer vision tasks .},
  archive      = {J_ASOC},
  author       = {Jibin Wang and Xiaotai Wu},
  doi          = {10.1016/j.asoc.2022.109552},
  journal      = {Applied Soft Computing},
  pages        = {109552},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A deep learning refinement strategy based on efficient channel attention for atrial fibrillation and atrial flutter signals identification},
  volume       = {130},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Time series prediction via elastic net regularization
integrating partial autocorrelation. <em>ASOC</em>, <em>129</em>,
109640. (<a href="https://doi.org/10.1016/j.asoc.2022.109640">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new elastic net regularization integrating partial autocorrelation coefficients (AEN-PAC) model for time series prediction. This model solves the inaccuracy of variable selection and parameter estimation caused by ignoring the dependence of time series in the adaptive elastic net. The proposed AEN-PAC model adds the partial autocorrelation coefficient to the penalty term of the adaptive elastic net, so that the influence of time on the data series can be well explained. Further, we prove a theorem to demonstrate that our method encourages grouping effects. Then, we convert the optimization problem of the proposed AEN-PAC model into an adaptive lasso model and propose an effective algorithm to solve it. Finally, we conduct a simulation study and empirical analysis on two time series sets. Simulation study shows that the proposed AEN-PAC model selects variable more correctly, compared with other models including Adaptive Elastic Net(AEN), Adaptive Lasso(AL), Elastic Net(EN), and Lasso. In addition, from the perspective of parameter estimation, the parameters estimated by our new model are closer to the real model. For Alibaba stock data and Nike stock data, the prediction errors are 7.07172 and 3.94916 respectively, which are smaller than other models. The results indicating that the proposed AEN-PAC model performs better in time series prediction.},
  archive      = {J_ASOC},
  author       = {Yanya Xing and Dongxi Li and Chenlong Li},
  doi          = {10.1016/j.asoc.2022.109640},
  journal      = {Applied Soft Computing},
  pages        = {109640},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Time series prediction via elastic net regularization integrating partial autocorrelation},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Software and hardware co-design and implementation of
intelligent optimization algorithms. <em>ASOC</em>, <em>129</em>,
109639. (<a href="https://doi.org/10.1016/j.asoc.2022.109639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve the operating efficiency of the algorithm, some intelligent optimization algorithms are considered to be implemented on hardware. However, the existing design scheme has the problem of poor versatility. Therefore, this paper proposes a general software–hardware co-design scheme of intelligent optimization algorithms . In the design scheme, the initialization module and fitness module of the algorithm are deployed on the Advanced RISC Machines (ARM) for execution to increase the flexibility of the program. The update module of the algorithm is deployed on the Field Programmable Gate Array (FPGA) for execution to realize the hardware acceleration . The data between ARM and FPGA is transferred through Advanced eXtensible Interface (AXI) bus. In this paper, the PSO , BA , WOA , GWO, CMAES and EO algorithms are implemented with the proposed design scheme. And the six algorithms are tested on thirteen benchmark functions of different types. The experimental results prove the feasibility of the design scheme. In addition, by comparing with software and other implementation methods in execution time, resource occupancy and convergence, the effectiveness and superiority of the proposed scheme are proved.},
  archive      = {J_ASOC},
  author       = {Zonglin Fu and Shu-Chuan Chu and Junzo Watada and Chia-Cheng Hu and Jeng-Shyang Pan},
  doi          = {10.1016/j.asoc.2022.109639},
  journal      = {Applied Soft Computing},
  pages        = {109639},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Software and hardware co-design and implementation of intelligent optimization algorithms},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A type-3 fuzzy control for current sharing and voltage
balancing in microgrids. <em>ASOC</em>, <em>129</em>, 109636. (<a
href="https://doi.org/10.1016/j.asoc.2022.109636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the current sharing and voltage balancing problems of direct current microgrids (DC-MGs) consisting of distributed generation units (DGUs) connected by a communication network. The main challenge is that the DC-MG model is prone to unknown dynamic models and external disturbances . Moreover, the voltage at each DGU’s point of coupling (PC) has to converge to its desired value while the information of the DGU filter current is exchanged with the nearest neighbors. To this end, the suggested distributed control algorithm benefits from an interval type-3 fuzzy logic system (IT3FLS). To enhance the accuracy of the approximation , a learning strategy is designed based on a correntropy unscented Kalman filter (CUKF) with a fuzzy kernel size. Utilizing the approximation technique and merging the consensus-based secondary control policy with the proposed type-3 fuzzy (T3F) controller result in the balanced voltages of the closed-loop DC-MG. The convergence of the trajectories of the DC-MG is ensured and the effects of approximation error signals are investigated via the proposed method. Furthermore, the robustness of the voltages and currents against unknown uncertainties admits the efficiency of the suggested learning-based control policy. The simulation results also confirm the appropriate transient response and the robustness of trajectories, thus the suggested controller can be implemented for practical cases.},
  archive      = {J_ASOC},
  author       = {Amin Taghieh and Ardashir Mohammadzadeh and Chunwei Zhang and Nasreen Kausar and Oscar Castillo},
  doi          = {10.1016/j.asoc.2022.109636},
  journal      = {Applied Soft Computing},
  pages        = {109636},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A type-3 fuzzy control for current sharing and voltage balancing in microgrids},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A systematic literature review on traditional to artificial
intelligence based socio-behavioral disorders diagnosis in india:
Challenges and future perspectives. <em>ASOC</em>, <em>129</em>, 109633.
(<a href="https://doi.org/10.1016/j.asoc.2022.109633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {: Socio-behavioral disorders(SBD), a subtype of neurodevelopmental disorders (NDDs) characterized by social and behavioral abnormalities, is a significant mental health concern requiring immediate attention. Phenotypic knowledge, biological understanding and the tools developed are all from western countries. Numerous researches have been conducted that have scrutinized the performance accuracy of traditional-based SBD tools developed in western culture. However, very little information is available for low or middle-income countries. In middle-income countries like India, there is a shortage of resources, trained professionals and a lack of knowledge regarding which tools are effective for a particular target group owing to which most of the cases go undetected and undiagnosed until adolescence. Motivated by the earlier discussion, this study’s objective is to consider all the pathways from traditional to Artificial Intelligence (AI) tools developed for diagnosing SBD in the Indian population. This research work expounds on the systematic study and analysis of various conventional and fuzzy-based expert systems introduced between 1925–2021. PRISMA guidelines were used to select the articles published on the web of science, SCOPUS, and EMBASE to identify relevant Indian studies. A total of 148 papers are considered impactful for SBD prediction using traditional or fuzzy-based techniques. This survey deliberated the work done by the different researchers, highlighting the limitations in the existing literature and the performance comparison of tools based on various parameters such as accuracy, sensitivity, specificity, target audience, along with their pros and cons. Some investigations have been designed, and the solutions to those were explored. : Results of this study indicated that most validated SBD tools present many barriers to use in the Indian population. Thus, to overcome these implications, an Artificial Intelligence(AI) framework, MRI M M MM TL, based on MRI multimodality transfer learning techniques(TL), is proposed to be implemented for the early detection of SBD subjects.},
  archive      = {J_ASOC},
  author       = {Mehak Mengi and Deepti Malhotra},
  doi          = {10.1016/j.asoc.2022.109633},
  journal      = {Applied Soft Computing},
  pages        = {109633},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A systematic literature review on traditional to artificial intelligence based socio-behavioral disorders diagnosis in india: Challenges and future perspectives},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multimodal brain tumor detection using multimodal deep
transfer learning. <em>ASOC</em>, <em>129</em>, 109631. (<a
href="https://doi.org/10.1016/j.asoc.2022.109631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {MRI brain image analysis, including brain tumor detection , is a challenging task. MRI images are multimodal, and in recent years, multimodal medical image analysis has gotten more attention. Modes refer to data from multiple sources which are semantically correlated and sometimes provide complementary information to each other. In this paper, modalities in MRI brain images refer to the different planes of view (axial, sagittal, and coronal planes) in which MRI images are taken. In most cases, in the literature on multimodal data analysis, it is assumed that all modalities for all samples are available. While, in medical image analysis, this assumption is not valid, and only some modalities might be available for each sample. The knowledge transfer between and within modalities is considered to tackle this challenge in MRI brain image segmentation . For knowledge transfer, domain adaptation is an important step that deals with the problem of having different distributions between the training and test sets. These challenges have not been considered in recent multimodal brain image analysis studies. This paper proposed a new multimodal deep transfer learning for MRI brain image analysis. The main differences of the proposed approach, with respect to the other multimodal brain image analysis, are 1) proposing a new multimodal feature encoder and 2) proposing a new multimodal adaptation technique to handle the different distribution between the training and test sets. We applied it to IBSR and Figshre brain tumor datasets to evaluate the proposed approach. The results confirm that the proposed approach significantly outperforms the other comparable approaches.},
  archive      = {J_ASOC},
  author       = {Parvin Razzaghi and Karim Abbasi and Mahmoud Shirazi and Shima Rashidi},
  doi          = {10.1016/j.asoc.2022.109631},
  journal      = {Applied Soft Computing},
  pages        = {109631},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multimodal brain tumor detection using multimodal deep transfer learning},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Remaining useful life prediction of rolling bearing under
limited data based on adaptive time-series feature window and multi-step
ahead strategy. <em>ASOC</em>, <em>129</em>, 109630. (<a
href="https://doi.org/10.1016/j.asoc.2022.109630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the remaining useful life (RUL) of rolling bearings can effectively prevent the breakdown of rotating machinery systems and catastrophic accidents. Most existing RUL prediction methods require massive run-to-failure datasets for modeling. However, it is difficult to obtain these rolling bearing datasets, and for newly or recently deployed rolling bearings , the degradation data are limited with no failure data. Meanwhile, the distribution difference of degradation data of bearings under different working conditions is great, and it is a challenge to employ existing methods to predict RUL. According to the investigation, the health indicators of rolling bearings related to RUL increase exponentially with time. Motivated by this, a novel rolling bearing RUL prediction approach under limited data is proposed in this study. First, a first prediction time (FPT) identification method is developed to obtain the appropriate FPT. Then, the degradation factor is derived mathematically and used to adaptively compress the time-series feature window to better capture the degradation trends of rolling bearings. Subsequently, a stacked bidirectional long short-term memory network (SBiLSTM) is designed to predict and smoothen sequential data. Combined with the degradation factor and SBiLSTM, a multi-step ahead rolling prediction method is presented to predict RUL. Finally, several experiments are conducted on rolling bearings, and the mean absolute percentage error of the proposed method for three representative rolling bearings are 6.77\%, 18.92\%, and 8.95\%, which are superior to other methods. Accordingly, this study contributes to revealing future degradation trends of rolling bearings mathematically, and providing a new idea for implementing other mechanical system prognostics under limited data.},
  archive      = {J_ASOC},
  author       = {Weili Kong and Hai Li},
  doi          = {10.1016/j.asoc.2022.109630},
  journal      = {Applied Soft Computing},
  pages        = {109630},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Remaining useful life prediction of rolling bearing under limited data based on adaptive time-series feature window and multi-step ahead strategy},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A fuzzy approach to support decision-making in the triage
process for suspected COVID-19 patients in brazil. <em>ASOC</em>,
<em>129</em>, 109626. (<a
href="https://doi.org/10.1016/j.asoc.2022.109626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Triage is a fundamental process in hospitals and emergency care units, as it allows for the classification and prioritization of patient care based on the severity of their clinical conditions. In Brazil , the triage of suspected COVID-19 cases is performed using a specific protocol, which involves manual steps, requiring the completion of four different forms, by four health care professionals. Aiming to investigate the possibility of improving the triage processes in Brazil, this article proposes the use of computational techniques for decision-making based on fuzzy inference systems . We argue that fuzzy set theory is appropriate to the problem because it allows the use of natural language to express the patient’s symptoms, making it easier for health care professionals. After modelling the problem in a fuzzy system we applied a pilot test. The model includes symptoms that health professionals currently use to analyse COVID-19 cases. The results suggest that the model presents convergence with the sample data, highlighting its potential application in supporting triage for the classification of the severity of COVID-19 cases. Among the benefits of the proposed model, we emphasize contributions as the reduction of the time and number of professionals required for triage as well as the reduction of exposure of health care professionals and other patients suspected of carrying the virus. In this context, this research provides an opportunity to obtain social contributions regarding the services in public hospitals improvement.},
  archive      = {J_ASOC},
  author       = {Nadya Regina Galo ( PhD ) and Marcos Paulino Roriz Junior ( PhD ) and Rodrigo Pinheiro Tóffano Pereira ( PhD )},
  doi          = {10.1016/j.asoc.2022.109626},
  journal      = {Applied Soft Computing},
  pages        = {109626},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A fuzzy approach to support decision-making in the triage process for suspected COVID-19 patients in brazil},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). SUFEMO: A superpixel based fuzzy image segmentation method
for COVID-19 radiological image elucidation. <em>ASOC</em>,
<em>129</em>, 109625. (<a
href="https://doi.org/10.1016/j.asoc.2022.109625">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 causes an ongoing worldwide pandemic situation. The non-discovery of specialized drugs and/or any other kind of medicines makes the situation worse. Early diagnosis of this disease will be certainly helpful to start the treatment early and also to bring down the dire spread of this highly infectious virus. This article describes the proposed novel unsupervised segmentation method to segment the radiological image samples of the chest area that are accumulated from the COVID-19 infected patients. The proposed approach is helpful for physicians, medical technologists , and other related experts in the quick and early diagnosis of COVID-19 infection. The proposed approach will be the SUFEMO (SUperpixel based Fuzzy Electromagnetism-like Optimization). This approach is developed depending on some well-known theories like the Electromagnetism-like optimization algorithm , the type-2 fuzzy logic, and the superpixels. The proposed approach brings down the processing burden that is required to deal with a considerably large amount of spatial information by assimilating the notion of the superpixel. In this work, the EMO approach is modified by utilizing the type 2 fuzzy framework. The EMO approach updates the cluster centers without using the cluster center updation equation. This approach is independent of the choice of the initial cluster centers. To decrease the related computational overhead of handling a lot of spatial data, a novel superpixel-based approach is proposed in which the noise-sensitiveness of the watershed-based superpixel formation approach is dealt with by computing the nearby minima from the gradient image . Also, to take advantage of the superpixels, the fuzzy objective function is modified. The proposed approach was evaluated using both qualitatively and quantitatively using 310 chest CT scan images that are gathered from various sources. Four standard cluster validity indices are taken into consideration to quantify the results. It is observed that the proposed approach gives better performance compared to some of the state-of-the-art approaches in terms of both qualitative and quantitative outcomes. On average, the proposed approach attains Davies–Bouldin index value of 1.812008792, Xie–Beni index value of 1.683281, Dunn index value 2.588595748, and β β index value 3.142069236 for 5 clusters. Apart from this, the proposed approach is also found to be superior with regard to the rate of convergence . Rigorous experiments prove the effectiveness of the proposed approach and establish the real-life applicability of the proposed method for the initial filtering of the COVID-19 patients.},
  archive      = {J_ASOC},
  author       = {Shouvik Chakraborty and Kalyani Mali},
  doi          = {10.1016/j.asoc.2022.109625},
  journal      = {Applied Soft Computing},
  pages        = {109625},
  shortjournal = {Appl. Soft. Comput.},
  title        = {SUFEMO: A superpixel based fuzzy image segmentation method for COVID-19 radiological image elucidation},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A deep matching model for detecting reviews mismatched with
products in e-commerce. <em>ASOC</em>, <em>129</em>, 109624. (<a
href="https://doi.org/10.1016/j.asoc.2022.109624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reviews of products in e-commerce are great value to both firms and customers. However, these reviews are not always genuine. Fake reviews can stymie firms and customers. Many studies have focused on detecting fake reviews. This paper addresses another kind of fake review on e-commerce websites called mismatched reviews where the content of reviews seems to be genuine, but they actually do not match the reviewed products. These reviews can harm the user experience in online shopping and damage the reputation of e-commerce websites. This paper develops a deep matching network to detect mismatched reviews, called MIRD, to calculate matching scores between the content of reviews and the reviewed products. MIRD encodes both reviews and products to the representation vectors and subsequently calculates a score in a latent space to measure how well the two vectors match. Experiments conducted on Yelp and Amazon datasets show that MIRD can recognize mismatched reviews well. Compared with the baseline models , MIRD obtains an 8\% performance improvement on the two datasets. The experimental results demonstrate that our efforts to detect mismatched reviews are feasible and effective.},
  archive      = {J_ASOC},
  author       = {Jiangtao Qiu and Siyu Wang},
  doi          = {10.1016/j.asoc.2022.109624},
  journal      = {Applied Soft Computing},
  pages        = {109624},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A deep matching model for detecting reviews mismatched with products in e-commerce},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Comparison of neural network, gaussian regression, support
vector machine, long short-term memory, multi-gene genetic programming,
and m5 trees methods for solving civil engineering problems.
<em>ASOC</em>, <em>129</em>, 109623. (<a
href="https://doi.org/10.1016/j.asoc.2022.109623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, it was investigated that how machine learning (ML) methods show performance in different problems having different characteristics. Six ML approaches including Artificial neural networks (ANN), gaussian process regression (GPR), support vector machine regression (SVMR), long short-term memory (LSTM), multi-gene genetic programming (MGGP) and M5 model tree (M5Tree) were utilized to analyze three independent civil engineering problems belonging to construction management, geotechnical engineering , and hydrological engineering sub-disciplines. Mean absolute percentage error (MAPE), root mean square error (RMSE), coefficient of determination (R 2 ), relative root means square error (RRMSE), Nash–Sutcliffe efficiency (NSE), Kling–Gupta efficiency (KGE), and overall index of model performance (OI) criteria were used to evaluate the performances of the models. Besides performance criteria, the relative performances of the six ML models were assessed using Taylor diagram, Violin diagram and One-Tailed Wilcoxon Signed-Rank Test. For each of the problem considered in this study, the effectiveness of the input parameters on the output parameter has been defined using the Relief Method and Correlation Coefficient. The results show that ANN and MGGP models yielded the most successful estimations for three different problems considered. The best prediction was achieved by MGGP model for hydrological engineering problem. For the construction management, geotechnical engineering problems, the best results were obtained using the ANN model. All models were reliable to solve the geotechnical engineering and hydrological engineering problems while LSTM and SVMR models are not reliable to solve the construction management problem. The most and least effective input parameters on output parameter were contract cost (CC) and work definition number (WDN) for the managerial data set. On the other hand, the most and least effective input parameters on the output parameters for the experimental and natural data sets have been obtained as width of the pile (B), rotation degree (R) and minimum temperature ( T min Tmin ), streamflow (Q) data, respectively. The number of data and data selection have a significant effect on the homogeneity of the data set and its representativeness of the problem. The error values obtained in test stage are affected from this condition. The equations to calculate the outputs of each of the problem considered were obtained using MGGP and M5Tree models.},
  archive      = {J_ASOC},
  author       = {Erdal Uncuoglu and Hatice Citakoglu and Levent Latifoglu and Savas Bayram and Mustafa Laman and Mucella Ilkentapar and A. Alper Oner},
  doi          = {10.1016/j.asoc.2022.109623},
  journal      = {Applied Soft Computing},
  pages        = {109623},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Comparison of neural network, gaussian regression, support vector machine, long short-term memory, multi-gene genetic programming, and m5 trees methods for solving civil engineering problems},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DPb-MOPSO: A dynamic pareto bi-level multi-objective
particle swarm optimization algorithm. <em>ASOC</em>, <em>129</em>,
109622. (<a href="https://doi.org/10.1016/j.asoc.2022.109622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particle Swarm Optimization (PSO) system based on the distributed architecture over multiple sub-swarms is very efficient for static multi-objective optimization but has not been considered for solving dynamic multi-objective problems (DMOPs). Tracking the most effective solutions over time and ensuring good exploitation and exploration are the main challenges of solving DMOP. This study proposes a Dynamic Pareto bi-level Multi-Objective Particle Swarm Optimization (DPb-MOPSO) algorithm including two parallel optimization levels. At the first level, all solutions are managed in a single search space. When a dynamic change is successfully detected in the objective values, the Pareto ranking operator is used to enable multiple sub-swarm’ subdivisions and processing which drives the second level of enhanced exploitation. A dynamic handling strategy based on random detectors is used to track the changes in the objective function due to time-varying parameters. A response strategy consisting in reevaluating all unimproved solutions and replacing them with newly generated ones is also implemented. The DPb-MOPSO system is tested on DMOPs with different types of time-varying Pareto Optimal Set (POS) and Pareto Optimal Front (POF). Inverted generational distance (IGD), mean inverted generational distance (MIGD), hypervolume difference (HVD), Robust IGD (RIGD), and Robust General Distance (RGD) metrics are used to assess the DPb-MOPSO performance. Quantitative results are analyzed using Friedman’s analysis of variance, and the Wilcoxon sum ranks test, while the stability is analyzed using Lyapunov’s theorem. The DPb-MOPSO is more robust than several dynamic multi-objective evolutionary algorithms in solving 21 complex problems over a range of changes in both the POS and POF. On IGD and HVD, DPb-MOPSO can solve 8/13 and 8/13 of the 13 UDF and ZJZ functions with moderate changes. DPb-MOPSO can resolve 7/8 FDA and DMOP benchmarks with severe changes to the MIGD, and 6/8 with moderate changes. DPb-MOPSO assumes 7/8, 6/8, and 5/8 for solving FDA, and dMOP functions on IGD and 6/8, 5/8, and 5/8 on HVD metrics considering severe, moderate, and slight environmental changes respectively. Also, it is the winner for solving 8 DMOPs based on RIGD, and RGD metrics.},
  archive      = {J_ASOC},
  author       = {Ahlem Aboud and Nizar Rokbani and Raja Fdhila and Abdulrahman M. Qahtani and Omar Almutiry and Habib Dhahri and Amir Hussain and Adel M. Alimi},
  doi          = {10.1016/j.asoc.2022.109622},
  journal      = {Applied Soft Computing},
  pages        = {109622},
  shortjournal = {Appl. Soft. Comput.},
  title        = {DPb-MOPSO: A dynamic pareto bi-level multi-objective particle swarm optimization algorithm},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Camera view planning based on generative adversarial
imitation learning in indoor active exploration. <em>ASOC</em>,
<em>129</em>, 109621. (<a
href="https://doi.org/10.1016/j.asoc.2022.109621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Actively exploring unknown indoor environments using an RGB-D camera is a challenging task, especially when utilizing the feature-based visual simultaneous localization and mapping (vSLAM) methods. The existence of low-texture scenes, such as narrow corridors and white walls, may lead to frequent tracking failure of indoor features. To avoid tracking failure, while simultaneously ensuring adequate exploration, a novel active vSLAM framework with camera view planning based on generative adversarial imitation learning (GAIL) is proposed to actively adjust the orientation of the camera during robot motion. First, the Oriented FAST and Rotated BRIEF-SLAM2 (ORB-SLAM2) method is modified to reconstruct a three-channel navigation map that contains information about obstacles and explored areas. Second, a large number of view planning behaviors of human beings are collected in different indoor environments as the expert demonstration. Last, to make the robot imitate the human searching behaviors, the structures of the actor, critic, and discriminator networks are designed, and the GAIL method is used to train the camera view planning policy. Simulation results on a public dataset of indoor environments show that the proposed GAIL-SLAM framework improves the exploration coverage ratio of unknown environments by an average of 53.08\% (34.21\% for traditional vs. 87.29\% for our proposed). Meanwhile, the number of effective exploration steps before the occurrence of tracking failure increases by 405\% (73 for traditional vs. 369 for our proposed) on average, indicating that the rate of tracking failure is effectively reduced.},
  archive      = {J_ASOC},
  author       = {Xu-Yang Dai and Qing-Hao Meng and Sheng Jin and Yin-Bo Liu},
  doi          = {10.1016/j.asoc.2022.109621},
  journal      = {Applied Soft Computing},
  pages        = {109621},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Camera view planning based on generative adversarial imitation learning in indoor active exploration},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Uncertainty-wise software anti-patterns detection: A
possibilistic evolutionary machine learning approach. <em>ASOC</em>,
<em>129</em>, 109620. (<a
href="https://doi.org/10.1016/j.asoc.2022.109620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Code smells (a.k.a. anti-patterns) are manifestations of poor design solutions that can deteriorate software maintainability and evolution. Existing works did not take into account the issue of uncertain class labels, which is an important inherent characteristic of the smells detection problem. More precisely, two human experts may have different degrees of uncertainty about the smelliness of a particular software class not only for the smell detection task but also for the smell type identification one. Unluckily, existing approaches usually reject and/or ignore uncertain data that correspond to software classes (i.e. dataset instances) with uncertain labels. Throwing away and/or disregarding the uncertainty factor could considerably degrade the detection/identification process effectiveness. From a solution approach viewpoint, there is no work in the literature that proposed a method that is able to detect and/or identify code smells while preserving the uncertainty aspect. The main goal of our research work is to handle the uncertainty factor, issued from human experts, in detecting and/or identifying code smells by proposing an evolutionary approach that is able to deal with anti-patterns classification with uncertain labels. We suggest Bi-ADIPOK, as an effective search-based tool that is capable to tackle the previously mentioned challenge for both detection and identification cases. The proposed method corresponds to an EA (Evolutionary Algorithm) that optimizes a set of detectors encoded as PK-NNs (Possibilistic K-nearest neighbors) based on a bi-level hierarchy, in which the upper level role consists on finding the optimal PK-NNs parameters, while the lower level one is to generate the PK-NNs. A newly fitness function has been proposed fitness function PomAURPC-OVA_dist (Possibilistic modified Area Under Recall Precision Curve One-Versus-All _distance, abbreviated PAURPC_d in this paper). Bi-ADIPOK is able to deal with label uncertainty using some concepts stemming from the Possibility Theory. Furthermore, the PomAURPC-OVA_dist is capable to process the uncertainty issue even with imbalanced data . We notice that Bi-ADIPOK is first built and then validated using a possibilistic base of smell examples that simulates and mimics the subjectivity of software engineers opinions. The statistical analysis of the obtained results on a set of comparative experiments with respect to four relevant state-of-the-art methods shows the merits of our proposal. The obtained detection results demonstrate that, for the uncertain environment, the PomAURPC-OVA_dist of Bi-ADIPOK ranges between 0.902 and 0.932 and its IAC lies between 0.9108 and 0.9407, while for the certain environment, the PomAURPC-OVA_dist lies between 0.928 and 0.955 and the IAC ranges between 0.9477 and 0.9622. Similarly, the identification results, for the uncertain environment, indicate that the PomAURPC-OVA_dist of Bi-ADIPOK varies between 0.8576 and 0.9273 and its IAC is between 0.8693 and 0.9318. For the certain environment, the PomAURPC-OVA_dist lies between 0.8613 and 0.9351 and the IAC values are between 0.8672 and 0.9476. With uncertain data, Bi-ADIPOK can find 35\% more code smells than the second best approach (i.e., BLOP). Furthermore, Bi-ADIPOK has succeeded to reduce the number of false alarms (i.e., misclassified smelly instances) by 12\%. In addition, our proposed approach can identify 43\% more smell types than BLOP and reduces the number of false alarms by 32\%. The same results have been obtained for the certain environment, demonstrating Bi-ADIPOK’s ability to deal with such environment.},
  archive      = {J_ASOC},
  author       = {Sofien Boutaib and Maha Elarbi and Slim Bechikh and Carlos A. Coello Coello and Lamjed Ben Said},
  doi          = {10.1016/j.asoc.2022.109620},
  journal      = {Applied Soft Computing},
  pages        = {109620},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Uncertainty-wise software anti-patterns detection: A possibilistic evolutionary machine learning approach},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). EGMM: An evidential version of the gaussian mixture model
for clustering. <em>ASOC</em>, <em>129</em>, 109619. (<a
href="https://doi.org/10.1016/j.asoc.2022.109619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Gaussian mixture model (GMM) provides a simple yet principled framework for clustering, with properties suitable for statistical inference. In this paper, we propose a new model-based clustering algorithm , called EGMM (evidential GMM), in the theoretical framework of belief functions to better characterize cluster-membership uncertainty. With a mass function representing the cluster membership of each object, the evidential Gaussian mixture distribution composed of the components over the powerset of the desired clusters is proposed to model the entire dataset. The parameters in EGMM are estimated by a specially designed Expectation–Maximization (EM) algorithm. A validity index allowing automatic determination of the proper number of clusters is also provided. The proposed EGMM is as simple as the classical GMM, but can generate a more informative evidential partition for the considered dataset. The synthetic and real dataset experiments show that the proposed EGMM performs better than other representative clustering algorithms. Besides, its superiority is also demonstrated by an application to multi-modal brain image segmentation .},
  archive      = {J_ASOC},
  author       = {Lianmeng Jiao and Thierry Denœux and Zhun-ga Liu and Quan Pan},
  doi          = {10.1016/j.asoc.2022.109619},
  journal      = {Applied Soft Computing},
  pages        = {109619},
  shortjournal = {Appl. Soft. Comput.},
  title        = {EGMM: An evidential version of the gaussian mixture model for clustering},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semi-sparse residual recurrent neural network via dictionary
representation for throat microphone quality enhancement. <em>ASOC</em>,
<em>129</em>, 109618. (<a
href="https://doi.org/10.1016/j.asoc.2022.109618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Throat microphone (TM) speech can be used for communication in noisy environment as it collects signals directly from human skin, but it should be improved in clarity and intelligibility due to the severe loss of high-frequency components. As recovery directly by neural networks is not sufficient to achieve satisfactory performance, we propose a dictionary representation based neural network to address this issue. Specifically, a magnitude spectrum dictionary of air-conducted speech is computed via sparse non-negative matrix factorization (SNMF), and then it is used to represent the transformed speech in hidden layer of the network. Meanwhile, a compensating dictionary is adopted to improve the representation accuracy. A memory efficient Semi-sparse Residual Recurrent Neural Network (SResRNN) with interactive mechanism and a special ResNet is employed to generate the coefficients on the dictionaries. Lastly, a three-layer neural network using a special initialization scheme is constructed as the recovery model. In the experiments, the model is compared with other five recovering models, and different criteria are adopted to measure the performance, the objective and subjective results can demonstrate the superiority of our proposed model.},
  archive      = {J_ASOC},
  author       = {Dongjing Shan and Desheng Li},
  doi          = {10.1016/j.asoc.2022.109618},
  journal      = {Applied Soft Computing},
  pages        = {109618},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Semi-sparse residual recurrent neural network via dictionary representation for throat microphone quality enhancement},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Discrete subspace structure constrained human motion capture
data recovery. <em>ASOC</em>, <em>129</em>, 109617. (<a
href="https://doi.org/10.1016/j.asoc.2022.109617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, low-rank matrix completion (LRMC) has shown a promising performance in human motion capture (mocap) data recovery, which assumes that the input data is low-rank. However, for most mocap data comprising multiple different activities, only using LRMC to restore the data may result in erroneous results, since the low-rank assumption is not necessarily satisfied. The current method solves this problem in a two-stage manner by combining the LRMC and subspace clustering. But it ignores the fact that the processes of recovering and clustering depend on each other, and so is sub-optimal. In this paper, we propose a novel discrete subspace structure (DSS) constrained approach to recover human mocap data, which jointly optimizing the tasks of subspace clustering and the LRMC. The proposed DSS algorithm learns different subspaces’ indicators such that the mocap recovery problem is divided into several LRMC subproblems , where each matrix of the points drawn from a single subspace is low-rank. As a byproduct, we can obtain the temporal clustering results of mocap data. To better approximate the low-rank property, we utilize the t t th power of Schatten p-norm to approximate the rank instead of the nuclear norm . Moreover, we add two regularization terms to take care of the noise effect and temporal stability of mocap data. The obtained model comes down to a non-convex optimization problem , which we solve tactically and efficiently by employing the alternating direction method of multipliers (ADMM). Experiments on the CMU dataset and the HDM05 dataset validate the effectiveness of the proposed algorithm in both mocap data recovery and temporal subspace clustering.},
  archive      = {J_ASOC},
  author       = {Wenyu Hu and Xuefang Zhu and Tinghua Wang and Yun Yi and Gaohang Yu},
  doi          = {10.1016/j.asoc.2022.109617},
  journal      = {Applied Soft Computing},
  pages        = {109617},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Discrete subspace structure constrained human motion capture data recovery},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data-driven prediction of building energy consumption using
an adaptive multi-model fusion approach. <em>ASOC</em>, <em>129</em>,
109616. (<a href="https://doi.org/10.1016/j.asoc.2022.109616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops an adaptive multi-model fusion approach to predict building energy consumption, aiming to give useful suggestions for better energy control. The building energy benchmarking dataset of Chicago in 2017 is selected as the case study, where 9 features are selected as the input variables aiming to estimate the weather normalized site energy use intensity of buildings. The training dataset is clustered using the K-means algorithm and sub-models are trained based on the clustered data using the XGBoost algorithm. The sub-models are then fused by assigning a weight considering both the model reliability and the matching degree and adopting a screening algorithm to weed out the unmatching sub-models, where the influence of the threshold in the screening algorithm is studied. The root mean square error of the estimation results from a fused model is found to be 13.42 which achieves a 7.6\% amelioration compared with a single model. Moreover, the adaptive multi-model fusion approach is also proved to outperform both the two-stage clustering-based regression method and the linear fusion method. Benefiting from proper treatment of samples in the fuzzy zones between clusters and the screening algorithm in the fusion process, the method proposed in our paper eventually serves as more advanced guidance in the analysis and control of building energy performance .},
  archive      = {J_ASOC},
  author       = {Penghui Lin and Limao Zhang and Jian Zuo},
  doi          = {10.1016/j.asoc.2022.109616},
  journal      = {Applied Soft Computing},
  pages        = {109616},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Data-driven prediction of building energy consumption using an adaptive multi-model fusion approach},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Online state-of-health estimation of lithium-ion battery
based on relevance vector machine with dynamic integration.
<em>ASOC</em>, <em>129</em>, 109615. (<a
href="https://doi.org/10.1016/j.asoc.2022.109615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The lithium-ion battery’s state of health (SOH) is one of the essential parameters of the battery management system . An accurate state of health estimation of the battery pack helps to improve the service life of the overall battery pack. Given the poor generalization ability of a single data-driven model during SOH online estimation and the lack of uncertainty expression ability in the estimation results, this paper proposes an online SOH estimation method of lithium-ion battery based on bat algorithm optimized relevance vector machine (BA-RVM) with dynamic integration. Firstly, we perform feature extraction and select equal voltage drop discharge time as an indirect health factor. Secondly, we establish the integration model, take the wavelet kernel relevance vector machine (RVM) as the sub-model, and use the bat algorithm (BA) to optimize its kernel parameters to improve the estimation accuracy of the sub-model. Then we use the online monitoring data to update the weights of the sub-models continuously and dynamically integrate the output of the sub-models to improve the accuracy of SOH online estimation further. Finally, the correctness and effectiveness of the method are verified based on battery data from NASA and compared with other data-driven methods. The experimental results show that compared with the method based on a single data-driven model, this method has higher accuracy and more vital generalization ability , and the estimation results have specific uncertainty expression ability.},
  archive      = {J_ASOC},
  author       = {Zewang Chen and Songyuan Zhang and Na Shi and Fusheng Li and Youren Wang and Jiang Cui},
  doi          = {10.1016/j.asoc.2022.109615},
  journal      = {Applied Soft Computing},
  pages        = {109615},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Online state-of-health estimation of lithium-ion battery based on relevance vector machine with dynamic integration},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). A practical regularity model based evolutionary algorithm
for multiobjective optimization. <em>ASOC</em>, <em>129</em>, 109614.
(<a href="https://doi.org/10.1016/j.asoc.2022.109614">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is well known that domain knowledge helps design efficient problem solvers. The regularity model based multiobjective estimation of distribution algorithm (RM-MEDA) is such a method that uses the regularity property of continuous multiobjective optimization problems (MOPs). However, RM-MEDA may fail to work when dealing with complicated MOPs. This paper aims to propose some practical strategies to improve the performance of RM-MEDA. We empirically study the modeling and sampling components of RM-MEDA that influence its performance. After that, some new components, including the population partition, modeling, and offspring generation procedures, are designed and embedded in the regularity model. The experimental study suggests that the new components are more efficient than those in RM-MEDA when using the regularity model. The improved version has also been verified on various complicated benchmark problems, and the experimental results have shown that the new version outperforms five state-of-the-art multiobjective evolutionary algorithms .},
  archive      = {J_ASOC},
  author       = {Wanpeng Zhang and Shuai Wang and Aimin Zhou and Hu Zhang},
  doi          = {10.1016/j.asoc.2022.109614},
  journal      = {Applied Soft Computing},
  pages        = {109614},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A practical regularity model based evolutionary algorithm for multiobjective optimization},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic multi-objective optimization and fuzzy AHP for
copper removal process of zinc hydrometallurgy. <em>ASOC</em>,
<em>129</em>, 109613. (<a
href="https://doi.org/10.1016/j.asoc.2022.109613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve the production efficiency and reduce the production cost of copper removal process (CRP), it is necessary to control the addition rate of zinc powder in CRP. In this study, the control of zinc powder addition rate is modeled as a dynamic multi-objective optimization problem (DMOP). A Pareto set which contains multiple control schemes is obtained by using multi-objective state transition algorithm based on decomposition, and then a new fuzzy multi-criteria decision-making (MCDM) is proposed to select the best control scheme. In the MCDM, according to the real-world requirements of CRP, four criteria are adopted to evaluate these schemes, and the fuzzy analytic hierarchy process (AHP) is adopted to determine the criteria weights according to a fuzzy comparison matrix. Furthermore, the nonlinear mixed integer programming model is established to guarantee consistency of the fuzzy comparison matrix. Experimental results of an industrial plant in China have demonstrated the effectiveness and superiority of the proposed method in terms of the cost, reaction rate, stability of outlet copper ion concentration, etc.},
  archive      = {J_ASOC},
  author       = {Xiaojun Zhou and Yan Sun and Zhaoke Huang and Chunhua Yang and Gary G. Yen},
  doi          = {10.1016/j.asoc.2022.109613},
  journal      = {Applied Soft Computing},
  pages        = {109613},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dynamic multi-objective optimization and fuzzy AHP for copper removal process of zinc hydrometallurgy},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Study of selected methods for balancing independent data
sets in k-nearest neighbors classifiers with pawlak conflict analysis.
<em>ASOC</em>, <em>129</em>, 109612. (<a
href="https://doi.org/10.1016/j.asoc.2022.109612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The article is devoted to the issue of classification based on independent data sets. More specifically, the impact of using different methods for balancing data sets on the classification quality in an approach that uses Pawlak conflict analysis is investigated. The newly proposed method for classification based on independent data sets assumes applying algorithms for imbalanced classification separately to all fragmented sets. The following algorithms are considered: SMOTE, random over-sampling, TOMEK links, Near Miss, random under-sampling and a combination of SMOTE and TOMEK links. For balanced data sets — decision tables, conflict analysis is used, and coalitions of tables are created. Then the aggregated table for each coalition is defined, and a modified k k -nearest neighbors algorithm is used to determine the decision vectors . The majority voting method is used to fuse decision vectors. Experimental results showed that the proposed approach, in most cases, gives much better results than without using methods for imbalanced data . In addition, the proposed approach achieves better results than other methods known from the literature applied to dispersed data. It was noticed that for dispersed and independent data, the best results are generated by the over-sampling approach, especially by the SMOTE, the random over-sampling and the SMOTE and TOMEK methods.},
  archive      = {J_ASOC},
  author       = {Małgorzata Przybyła-Kasperek},
  doi          = {10.1016/j.asoc.2022.109612},
  journal      = {Applied Soft Computing},
  pages        = {109612},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Study of selected methods for balancing independent data sets in k-nearest neighbors classifiers with pawlak conflict analysis},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design and implementation of discrete jaya and discrete PSO
algorithms for automatic collaborative learning group composition in an
e-learning system. <em>ASOC</em>, <em>129</em>, 109611. (<a
href="https://doi.org/10.1016/j.asoc.2022.109611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the design and implementation of two discrete metaheuristic algorithms for automatic student collaborative group creation in an e-learning system by grouping students of different knowledge levels to enhance the overall effectiveness of the online learning process. Their purpose is to compose collaborative student groups automatically, aiming to improve the effectiveness of the collaborative learning process in distance education. The parameters used for student grouping are obtained from a pre-test. Then, the particle swarm optimization (PSO) and Jaya algorithms are implemented to automatically compose collaborative learning groups considering three parameters: the level of student’s knowledge shown in the pre-test (pre-test score), student’s learning experience with each topic, and the time students spent doing the pre-test (pre-test time). Besides the first two parameters examined in some recent approaches, the third parameter is introduced to provide additional information about the student’s knowledge. Aiming to apply PSO and Jaya to address the observed problem from real teaching practice, discrete PSO and discrete Jaya algorithms are developed to deal with discrete data. Multiple scenarios are applied for both algorithms with different hyperparameter settings to estimate the impact of the algorithm’s settings on the quality of solutions and the convergence rate. Finally, recommendations for algorithm preference and tuning are drawn. The discrete Jaya algorithm converged to the optimal solution in all scenarios, i.e., with all hyperparameter settings. In contrast, the discrete PSO algorithm found the optimum only in some of the tested scenarios. Overall, the discrete Jaya algorithm surpasses discrete PSO, particularly regarding solution quality and robustness concerning algorithm-specific parameters setting. Therefore, the proposed DJaya algorithm can be used for creating collaborative student groups in distance education systems.},
  archive      = {J_ASOC},
  author       = {Nebojsa Gavrilovic and Tatjana Sibalija and Dragan Domazet},
  doi          = {10.1016/j.asoc.2022.109611},
  journal      = {Applied Soft Computing},
  pages        = {109611},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Design and implementation of discrete jaya and discrete PSO algorithms for automatic collaborative learning group composition in an e-learning system},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient evolutionary optimization using predictive
auto-scaling in containerized environment. <em>ASOC</em>, <em>129</em>,
109610. (<a href="https://doi.org/10.1016/j.asoc.2022.109610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving complex real-world optimization problems is a computationally demanding task. To solve it efficiently and effectively, one must possess expert knowledge in various fields (problem domain knowledge, optimization, parallel and distributed computing) and appropriate expensive software and hardware resources. In this regard, we present a cloud-native, container-based distributed optimization framework that enables efficient and cost-effective optimization over platforms such as Amazon ECS/EKS, Azure AKS, and on-premise Kubernetes . The solution consists of dozens of microservices scaled out using a specially developed PETAS Auto-scaler based on predictive analytics . Existing schedulers, whether Kubernetes or commercial, do not take into account the specifics of optimization based on evolutionary algorithms . Therefore, their performance is not optimal in terms of results’ delivery time and cloud infrastructure costs. The proposed PETAS Auto-scaler elastically maintains an adequate number of worker pods following the exact pace dictated by the demands of the optimization process. We evaluate the proposed framework’s performance using two real-world computationally demanding optimizations. The first use case belongs to the manufacturing domain and involves optimization of the transportation pallets for train parts. The second use case belongs to the field of automated machine learning and includes neural architecture search and hyperparameter optimization. The results indicate an IaaS cost savings of up to 49\% can be achieved, with almost unchanged result delivery time.},
  archive      = {J_ASOC},
  author       = {Milos Ivanovic and Visnja Simic},
  doi          = {10.1016/j.asoc.2022.109610},
  journal      = {Applied Soft Computing},
  pages        = {109610},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Efficient evolutionary optimization using predictive auto-scaling in containerized environment},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interval neutrosophic stochastic dynamical systems driven by
brownian motion. <em>ASOC</em>, <em>129</em>, 109609. (<a
href="https://doi.org/10.1016/j.asoc.2022.109609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic and neutrosophic theory are effective tools for modeling real-world phenomena and natural dynamical systems , where inputs are often affected by stochastic noises and outputs often contain both randomness and indeterminacy . In this work, we present a new type of stochastic differential equations (SDE) driven by an one-dimensional Brownian motion that can be considered as an efficient tool to describe the uncertain behavior of dynamical systems operating in interval neutrosophic environments with stochastic noises. After introducing some basic foundations on neutrosophic arithmetic, neutrosophic calculus and neutrosophic stochastic process , we define the new form of interval neutrosophic stochastic differential equations taking values in neutrosophic environment. Under some suitable conditions, the unique existence result of stochastic solution is obtained based on the use of Picard successive approximation . We also introduce an efficient numerical algorithm, namely Euler–Maruyama method, to solve the numerical solution of proposed problem and further demonstrate the effectiveness of the numerical method by solving some examples in stochastic biological systems such as stochastic logistic growth model, stochastic Lotka–Volterra predator–prey model, and stochastic SARS model, respectively.},
  archive      = {J_ASOC},
  author       = {Nguyen Thi Kim Son and Nguyen Phuong Dong and Hoang Viet Long and Raghvendra Kumar and Ishaani Priyadarshini},
  doi          = {10.1016/j.asoc.2022.109609},
  journal      = {Applied Soft Computing},
  pages        = {109609},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Interval neutrosophic stochastic dynamical systems driven by brownian motion},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Scalability of knowledge distillation in incremental deep
learning for fast object detection. <em>ASOC</em>, <em>129</em>, 109608.
(<a href="https://doi.org/10.1016/j.asoc.2022.109608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual recognition requires incremental learning to scale its underlying deep learning models with continuous data growth. The existing scalability challenge is maintaining the balance between effectiveness (accuracy) and efficiency (computational requirements) due to the rapidly increasing storage demand, computational time, and memory usage for processing both the old and new data. This paper aims to investigate the scalability of the incremental deep learning approach for visual recognition, specifically for fast object detection applications. The experimental study demonstrates knowledge retention and computational expense of training-at-once, compared to incremental learning with knowledge transfer and distillation. The experiment was based on a state-of-the-art object detector, which was extended to incorporate knowledge transfer and distillation to benchmark three training approaches, namely, training-at-once, transfer learning without, and with distillation. The experimental results and analysis examined the pros and cons of each training approach while adjusting some key parameters, focusing on comparing the accuracy of new classes, knowledge retention of old classes, data storage, computation time, and memory usage. Training-at-once (the baseline) yielded the highest accuracy of both new and old classes, at the expense of the largest storage and memory usage. Compared to the baseline, both transfer learning approaches saved the storage requirement by −73\% but with an increased computation time of ＋53\%. Transfer learning with distillation was important for knowledge retention, maintaining 96\% accuracy with old classes, which indicates its ability to handle long-term incremental learning. Compared to using distillation, transfer learning without distillation was able to achieve slightly better accuracy with new classes (−53\% compared to −60\%), less memory usage (−65\% compared to ＋26\%), but at the expense of forgetting old classes (−100\%). This study confirmed that distillation loss could help balance the accuracy of old and new object classes while maintaining all the benefits of incremental learning. The experiments using varied key parameters across all training approaches confirmed that training batch size and number of assigned classes play an important role in maintaining the accuracy of new classes, retaining the knowledge of old classes, and reducing the computational cost.},
  archive      = {J_ASOC},
  author       = {Elizabeth Irenne Yuwono and Dian Tjondonegoro and Golam Sorwar and Alireza Alaei},
  doi          = {10.1016/j.asoc.2022.109608},
  journal      = {Applied Soft Computing},
  pages        = {109608},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Scalability of knowledge distillation in incremental deep learning for fast object detection},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stochastic simulated annealing for directed feedback vertex
set. <em>ASOC</em>, <em>129</em>, 109607. (<a
href="https://doi.org/10.1016/j.asoc.2022.109607">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The minimum feedback vertex set problem consists in finding the minimum set of vertices that should be removed in order to make the graph acyclic. This is a well known NP-hard optimization problem with applications in various fields, such as VLSI chip design, bioinformatics and transaction processing . In this paper, we explore the complementary problem in directed graphs , i.e., how to construct the maximum directed acyclic graph (max-DAG). We show that the max-DAG problem is Poly-APX complete, which implies that even trying to obtain approximation algorithms for this problems is likely to be unfeasible. In light of these considerations, we introduce a new algorithmic solution, based on Simulated Annealing (SA), which combines techniques such as kernelization, efficient data-structures, novel heuristics to initialize the search process, a global re-structuring procedure, and a neighbor re-ordering technique to speed-up the local search step. We present an extensive experimental study that validates the key design and implementation choices undertaken in our proposal and compares it to state of the art SA-based solutions Galinier et al. (2013) and Tang et al. (2017). The proposed algorithm provides significant performance gains by obtaining feedback vertex sets up to 13.3 × × closer to the optimal solution in a wide variety of synthetic and real-world graphs.},
  archive      = {J_ASOC},
  author       = {Luís M.S. Russo and Daniel Castro and Aleksandar Ilic and Paolo Romano and Ana D. Correia},
  doi          = {10.1016/j.asoc.2022.109607},
  journal      = {Applied Soft Computing},
  pages        = {109607},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Stochastic simulated annealing for directed feedback vertex set},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analysis of the socioeconomic impact due to COVID-19 using a
deep clustering approach. <em>ASOC</em>, <em>129</em>, 109606. (<a
href="https://doi.org/10.1016/j.asoc.2022.109606">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the main problems that countries are currently having is being able to measure the impact of the pandemic in other areas of society (for example, economic or social). In that sense, being able to combine variables about the behavior of COVID-19 with other variables in the environment, to build models about its impact, which help the decision-making of national authorities, is a current challenge. In this sense, this work proposes an approach that allows monitoring the socioeconomic behavior of the regions/departments of a country (in this case, Colombia) due to the effect of COVID-19. To do this, an approach is proposed in which the behavior of the infected is initially predicted, and together with other context variables (climate, economics and socials) determines the current socioeconomic situation of a region. This classification of a region, with the pattern that characterizes it, is a fundamental input for those who make decisions. Thus, this work presents an approach based on machine learning techniques to identify regions with similar socioeconomic behaviors due to COVID-19, so they should eventually have similar public policies. The proposed hybrid model initially consists of a time series prediction model of infected, to which are added several context variables (climate, socioeconomic, incidence of COVID-19 at the level of deaths, suspects, etc.) in an unsupervised learning model, to determine the socioeconomic impact in the regions. Particularly, the unsupervised model groups similar regions together, and the pattern of each group describes the socioeconomic similarities between them, to help decision-makers in the process of defining policies to be implemented in the regions. The experiments showed the ability of the hybrid model to follow the evolution of the regions after 4 weeks. The quality metrics for the predictive model were around the values of 0.35 for MAPE and 0.68 for R 2 R2 , and in the case of the clustering model were around the values of 0.3 for the Silhouette index and 0.6 for the Davies–Boulding index. The hybrid model allowed determining things like some regions that initially belonged to a group with a very low incidence of positive cases and very unfavorable socioeconomic conditions, became part of groups with moderately high incidences. Our preliminary results are very satisfactory since they allow studying the evolution of the socioeconomic impact in each region/department.},
  archive      = {J_ASOC},
  author       = {Yullys Quintero and Douglas Ardila and Jose Aguilar and Santiago Cortes},
  doi          = {10.1016/j.asoc.2022.109606},
  journal      = {Applied Soft Computing},
  pages        = {109606},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Analysis of the socioeconomic impact due to COVID-19 using a deep clustering approach},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ensemble methods based on characterization of dynamism for
dynamic multi-objective optimization. <em>ASOC</em>, <em>129</em>,
109605. (<a href="https://doi.org/10.1016/j.asoc.2022.109605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic multi-objective optimization problems involve multiple conflicting and time-dependent objectives that change continuously depending on the environment. Therefore, effectively tracking the movement of the Pareto-optimal front and the Pareto-optimal set (PS) using a single strategy is difficult. In this study, we propose an ensemble method called EMCD, which is based on the characterization of dynamism. EMCD selects different strategies to generate new populations depending on the characteristics of environmental changes. In our proposed algorithm, historical information is used to locate new populations when the current and historical environmental changes are similar. Otherwise, EMCD establishes whether the PS has changed. If the PS changes, individuals from the population of the new environment are generated by using a set of knee points based on the two previous consecutive populations. If not, new populations are generated by using the perturbation-based approach. In addition, we use an adaptive diversity introduction strategy to ensure the solvability of our proposed algorithm in dynamic environments. To verify the effectiveness of EMCD, we compare its performance to that of three state-of-the-art algorithms on fourteen benchmark problems. The experimental results show that EMCD outperforms the comparison algorithms on most of the benchmark problems.},
  archive      = {J_ASOC},
  author       = {Chuwen Jiang and Fangzhen Ge and Debao Chen and Huaiyu Liu},
  doi          = {10.1016/j.asoc.2022.109605},
  journal      = {Applied Soft Computing},
  pages        = {109605},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Ensemble methods based on characterization of dynamism for dynamic multi-objective optimization},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feature fusion based ensemble method for remaining useful
life prediction of machinery. <em>ASOC</em>, <em>129</em>, 109604. (<a
href="https://doi.org/10.1016/j.asoc.2022.109604">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The signal analysis features and deep representation features have been widely utilized to predict the Remaining Useful Life (RUL) of machinery. However, existing studies rarely fuse these features for RUL prediction to explore their complementarity. Therefore, this paper proposes a Feature Fusion based Ensemble Method (FFEM) that makes full use of the characteristics of signal analysis features and deep representation features. First, features are extracted by signal analysis and deep learning methods , respectively. The time-domain features, frequency-domain features, and time–frequency​ domain features are extracted by different signal analysis methods, while the deep representation features are from the bidirectional long short-term memory networks. Then, an improved random subspace method is proposed, which fuses different types of features based on group-based sparse learning to use the complementarity among features. Furthermore, accurate and diverse base learners are generated and the aggregation strategy, mean rule, is adopted for predicting RUL. To validate the proposed FFEM, experiments on the run-to-failure datasets of bearings are conducted, and the experimental results verify that the proposed method greatly improves the RUL prediction performance and surpasses other existing ensemble learning methods.},
  archive      = {J_ASOC},
  author       = {Gang Wang and Hui Li and Feng Zhang and Zhangjun Wu},
  doi          = {10.1016/j.asoc.2022.109604},
  journal      = {Applied Soft Computing},
  pages        = {109604},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Feature fusion based ensemble method for remaining useful life prediction of machinery},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Twitter conversations predict the daily confirmed COVID-19
cases. <em>ASOC</em>, <em>129</em>, 109603. (<a
href="https://doi.org/10.1016/j.asoc.2022.109603">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As of writing this paper, COVID-19 (Coronavirus disease 2019) has spread to more than 220 countries and territories. Following the outbreak, the pandemic’s seriousness has made people more active on social media, especially on the microblogging platforms such as Twitter and Weibo. The pandemic-specific discourse has remained on-trend on these platforms for months now. Previous studies have confirmed the contributions of such socially generated conversations towards situational awareness of crisis events. The early forecasts of cases are essential to authorities to estimate the requirements of resources needed to cope with the outgrowths of the virus. Therefore, this study attempts to incorporate the public discourse in the design of forecasting models particularly targeted for the steep-hill region of an ongoing wave. We propose a sentiment-involved topic-based latent variables search methodology for designing forecasting models from publicly available Twitter conversations. As a use case, we implement the proposed methodology on Australian COVID-19 daily cases and Twitter conversations generated within the country. Experimental results: (i) show the presence of latent social media variables that Granger-cause the daily COVID-19 confirmed cases, and (ii) confirm that those variables offer additional prediction capability to forecasting models. Further, the results show that the inclusion of social media variables introduces 48.83\%–51.38\% improvements on RMSE over the baseline models . We also release the large-scale COVID-19 specific geotagged global tweets dataset, MegaGeoCOV , to the public anticipating that the geotagged data of this scale would aid in understanding the conversational dynamics of the pandemic through other spatial and temporal contexts.},
  archive      = {J_ASOC},
  author       = {Rabindra Lamsal and Aaron Harwood and Maria Rodriguez Read},
  doi          = {10.1016/j.asoc.2022.109603},
  journal      = {Applied Soft Computing},
  pages        = {109603},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Twitter conversations predict the daily confirmed COVID-19 cases},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Clustering-based interval prediction of electric load using
multi-objective pathfinder algorithm and elman neural network.
<em>ASOC</em>, <em>129</em>, 109602. (<a
href="https://doi.org/10.1016/j.asoc.2022.109602">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval prediction of electric load has aroused widespread concern by the power industry because of variability and uncertainty. To quantify the potential uncertainty associated with prediction, this paper proposes a clustering-based approach to construct prediction intervals (PIs) for electric load data. The singular spectrum analysis (SSA) and k-means clustering are firstly performed to decompose the original data due to the high volatility and nonlinearity of load data. Then, we improve the multi-objective pathfinder algorithm (MOPATH) by using crowding degree of population in order to prevent premature, and further utilize the Elman neural network (ELMAN) optimized by IMOPATH to obtain the subseries PIs of electric load data. In addition, the interval width, coverage probability and deviation are used as three optimization objectives . Finally, the IMOPATH, as an ensemble approach, is applied to ensemble the three PIs together and achieves the final PIs. To verify the performance of the SSA-IMOPATH-ELMAN approach, the proposed approach is compared with 41 models. The forecasting outcomes indicate that PIs of the proposed approach have higher coverage probability, narrower width and lower deviation degree than other benchmark models . Moreover, the proposed approach has good performance on robustness and sensibility.},
  archive      = {J_ASOC},
  author       = {Feng Jiang and Qiannan Zhu and Jiawei Yang and Guici Chen and Tianhai Tian},
  doi          = {10.1016/j.asoc.2022.109602},
  journal      = {Applied Soft Computing},
  pages        = {109602},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Clustering-based interval prediction of electric load using multi-objective pathfinder algorithm and elman neural network},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modeling of true triaxial strength of rocks based on
optimized genetic programming. <em>ASOC</em>, <em>129</em>, 109601. (<a
href="https://doi.org/10.1016/j.asoc.2022.109601">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The strength of a rock is the main factor affecting the stability of an engineered rock mass. As laboratory testing requires sophisticated equipment and considerable time to determine rock strength, prediction models are needed for establishing rock strength criteria. Genetic programming (GP) is a soft computing technology often used to address rock mechanics and engineering challenges. However, GP also has limitations, such as a long running time, complex individual growth without a corresponding fitness improvement, and difficulty in finding the optimal solution. Therefore, we conducted this study by applying a dynamic restriction on individual size, local search of the neighborhood of the optimal individual, and multithreaded evaluation to optimize GP and guarantee the accuracy of the results and to build a prediction model for the true triaxial strength involving different rock types. The results showed that the restriction dynamically changes to restrict the redundant bloat of strength individuals without a corresponding fitness improvement; using local search rules can effectively find individuals with high fitness, so the strength predicted by the system was in good agreement with the measured strength. We also found the predicted strength was suitable for fitting the rock strength criteria. Using this multithreaded evaluation sped up the operation of the algorithm and produced accurate predictions; and for complex problems, increasing the threads had a more pronounced effect on the runtime and fitness improvements. Based on the Sobol global sensitivity analysis, we analyzed the influence of each prediction parameter on the true triaxial strength of rocks. Combined with the statistical assessment indices involving sum of the absolute error, mean, a 10- index , and regression determination coefficient, the predictions of the optimized GP model that we established in this study were more accurate than those of multiple regression analysis.},
  archive      = {J_ASOC},
  author       = {Beichen Yu and Dongming Zhang and Bin Xu and Yubing Liu and Honggang Zhao and Chongyang Wang},
  doi          = {10.1016/j.asoc.2022.109601},
  journal      = {Applied Soft Computing},
  pages        = {109601},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Modeling of true triaxial strength of rocks based on optimized genetic programming},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pattern classification based on regional models.
<em>ASOC</em>, <em>129</em>, 109592. (<a
href="https://doi.org/10.1016/j.asoc.2022.109592">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a supervised setting, the global classification paradigm leverages the whole training data to produce a single class discriminative model. Alternatively, the local classification approach builds multiple base classifiers , each of them using a small subset of the training data. In this paper, we take a path to stand in-between the global and local approaches. We introduce a two-level clustering-based method in which base classifiers operate on a larger portion of the input space than in the traditional local paradigm. In particular, we first obtain a grained input representation by employing a Self-Organizing Map (SOM) to the inputs. We then apply a clustering algorithm (e.g., K-Means) to the SOM units to define input regions — a subset of input samples associated with a specific cluster of SOM units. We refer to this approach as regional classification . We demonstrate the effectiveness of regional classification on several benchmarks. Also, we study the impact of (1) adopting linear and nonlinear base classifiers (e.g., least squares support vector machines) and (2) using cluster validation indexes to determine the optimal number of clusters. Based on the experiments, the regional classification approach achieves competitive performance compared to its global and local counterparts, especially when equipped with linear base classifiers.},
  archive      = {J_ASOC},
  author       = {Rômulo B.P. Drumond and Renan F. Albuquerque and Guilherme A. Barreto and Amauri H. Souza},
  doi          = {10.1016/j.asoc.2022.109592},
  journal      = {Applied Soft Computing},
  pages        = {109592},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Pattern classification based on regional models},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A binary tree seed algorithm with selection-based local
search mechanism for huge-sized optimization problems. <em>ASOC</em>,
<em>129</em>, 109590. (<a
href="https://doi.org/10.1016/j.asoc.2022.109590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tree seed algorithm (TSA) is a recently proposed metaheuristic algorithm for solving continuous optimization problems . In order to use TSA in binary optimization problems , the SimLogicTSA method was developed by adding logic gates and Jaccard’s similarity measure to this algorithm by Cinar and Kiran. Although SimLogicTSA is generally successful in small, medium, and large size problems, it has not been successful in the huge-sized problems by stucking into local minima. To overcome this problem, a new local search mechanism called enhanced local search module (ELSM) is proposed and the SimLogicTSA-ELSM algorithm is suggested by implementing the ELSM mechanism to the original SimLogicTSA algorithm. The proposed ELSM mechanism consists of a swap operator and logic-based gates. To analyze the contribution of the ELSM mechanism to the algorithm, firstly, the original SimLogicTSA and SimLogicTSA-ELSM algorithms were compared on the Cap and M* problem sets. The obtained results showed that the proposed algorithm produced more successful results than the original SimLogicTSA. Then, the proposed SimLogicTSA-ELSM is compared with many state-of-art algorithms in the literature by using different performance metrics on Cap and M* problem sets. The results show that SimLogicTSA-ELSM outperforms the compared algorithms in nearly all cases. Especially, the performance of the SimLogicTSA-ELSM stands out in huge-sized problems.},
  archive      = {J_ASOC},
  author       = {Murat Karakoyun and Ahmet Ozkis},
  doi          = {10.1016/j.asoc.2022.109590},
  journal      = {Applied Soft Computing},
  pages        = {109590},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A binary tree seed algorithm with selection-based local search mechanism for huge-sized optimization problems},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Handling class imbalance in COVID-19 chest x-ray images
classification: Using SMOTE and weighted loss. <em>ASOC</em>,
<em>129</em>, 109588. (<a
href="https://doi.org/10.1016/j.asoc.2022.109588">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Healthcare systems worldwide have been struggling since the beginning of the COVID-19 pandemic. The early diagnosis of this unprecedented infection has become their ultimate objective. Detecting positive patients from chest X-ray images is a quick and efficient solution for overloaded hospitals. Many studies based on deep learning (DL) techniques have shown high performance in classifying COVID-19 chest X-ray images. However, most of these studies suffer from a class imbalance problem mainly due to the limited number of COVID-19 samples. Such a problem may significantly reduce the efficiency of DL classifiers. In this work, we aim to build an accurate model that assists clinicians in the early diagnosis of COVID-19 using balanced data. To this end, we trained six state-of-the-art convolutional neural networks (CNNs) via transfer learning (TL) on three different COVID-19 datasets. The models were developed to perform a multi-classification task that distinguishes between COVID-19, normal, and viral pneumonia cases. To address the class imbalance issue, we first investigated the Weighted Categorical Loss (WCL) and then the Synthetic Minority Oversampling Technique (SMOTE) on each dataset separately. After a comparative study of the obtained results, we selected the model that achieved high classification results in terms of accuracy, sensitivity, specificity, precision, F1 score, and AUC compared to other recent works. DenseNet201 and VGG-19 claimed the best scores. With an accuracy of 98.87\%, an F1_Score of 98.21\%, a sensitivity of 98.86\%, a specificity of 99.43\%, a precision of 100\%, and an AUC of 99.15\%, the WCL combined with CheXNet outperformed the other examined models.},
  archive      = {J_ASOC},
  author       = {Ekram Chamseddine and Nesrine Mansouri and Makram Soui and Mourad Abed},
  doi          = {10.1016/j.asoc.2022.109588},
  journal      = {Applied Soft Computing},
  pages        = {109588},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Handling class imbalance in COVID-19 chest X-ray images classification: Using SMOTE and weighted loss},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Wind power forecasting based on variational mode
decomposition and high-order fuzzy cognitive maps. <em>ASOC</em>,
<em>129</em>, 109586. (<a
href="https://doi.org/10.1016/j.asoc.2022.109586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate wind power forecasting can effectively reduce the adverse effects of wind power forecasting errors on wind power grid integration and power dispatch. However, current wind power forecasting technology, such as the method based on machine learning , belongs to the black box model and is not solvable. Variational mode decomposition (VMD) is a decomposition technique based on the time–frequency characteristics of the original time series, which has a mathematical theoretical foundation. Besides, fuzzy cognitive map (FCMs) is a kind of soft computing method with strong knowledge representation and reasoning ability. Therefore, to enhance the forecasting accuracy of wind power, in this paper, a novel time series forecasting method based on improved VMD (IVMD) and high-order FCM (HFCM), namely IVMD HFCM HFCM is proposed. IVMD can effectively extract the features in the raw time series depending on the time–frequency characteristics of the time series. Then, the subseries obtained by IVMD are modeled and forecasted by HFCM, and the Bayesian ridge regression method is adopted to learn the weight of HFCM. Finally, the differential evolution (DE) algorithm is used to get the optimal hyperparameters of IVMD HFCM HFCM . The performance of IVMD HFCM HFCM is verified by comparing it with that of state-of-the-art methods on ten publicly available datasets. Moreover, the proposed IVMD HFCM HFCM is compared with the existing HFCM based method on ten actual wind power datasets. The results show that the IVMD HFCM HFCM can effectively improve the accuracy of wind power forecasting and reduce the forecasting error. Besides, the IVMD HFCM HFCM can also effectively explore the fluctuations of wind power.},
  archive      = {J_ASOC},
  author       = {Baihao Qiao and Jing Liu and Peng Wu and Yingzhi Teng},
  doi          = {10.1016/j.asoc.2022.109586},
  journal      = {Applied Soft Computing},
  pages        = {109586},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Wind power forecasting based on variational mode decomposition and high-order fuzzy cognitive maps},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An adaptive framework to select the coordinate systems for
evolutionary algorithms. <em>ASOC</em>, <em>129</em>, 109585. (<a
href="https://doi.org/10.1016/j.asoc.2022.109585">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many evolutionary algorithms usually utilize the fixed original coordinate system to search and cannot effectively match different function landscapes. To solve this issue, this paper proposes an adaptive framework, named STCS, to select the coordinate systems for evolutionary algorithms . In STCS, the eigen coordinate system is constructed by an archive-based covariance matrix , which can capture the feature of the function landscape. What is more, the selection process of the original coordinate system and the eigen coordinate system is defined as a Markov decision process and is controlled by reinforcement learning algorithm. STCS is applied to three popular evolutionary algorithms, i.e., differential evolution, particle swarm optimization , and teaching–learning-based optimization. The experimental results on IEEE CEC2013, IEEE CEC2014, and IEEE CEC2017 test suites demonstrate that STCS is efficient and competitive.},
  archive      = {J_ASOC},
  author       = {Weifeng Gao and Qianlong Dang and Maoguo Gong},
  doi          = {10.1016/j.asoc.2022.109585},
  journal      = {Applied Soft Computing},
  pages        = {109585},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An adaptive framework to select the coordinate systems for evolutionary algorithms},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MLP-based learnable window size for bitcoin price
prediction. <em>ASOC</em>, <em>129</em>, 109584. (<a
href="https://doi.org/10.1016/j.asoc.2022.109584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past few years, Bitcoin price prediction has been changed to a big challenge for investors on cryptocurrencies . In this regard, Neural Networks as a strong structure for regression analysis would play an important role to make a precise prediction. While several leading researches in this field considered the features affecting the price of bitcoin by a fixed number of past days, a new method entitled Learnable Window Size (LWS) is presented for smartening the number of days intended to predict the price of Bitcoin the next day. This paper implements a primary deep neural network , based on the observed Bitcoin price trend in the past days and its fluctuations, to predict the best window size. Then, the secondary deep neural network predicts the price of Bitcoin according to the predicted window of the first step. The dataset of this paper is included Google, Blockchain , and Bitcoin market data. Evaluations have shown that based on the Prediction Hardship Factor (PHF), a new criterion which has been proposed to describe the degree of difficulty of prediction, this method has been able to get the minimum error under a normal situation which is superior in comparison to the well-known methods such as Support Vector Regression and ARIMA.},
  archive      = {J_ASOC},
  author       = {Shahab Rajabi and Pardis Roozkhosh and Nasser Motahari Farimani},
  doi          = {10.1016/j.asoc.2022.109584},
  journal      = {Applied Soft Computing},
  pages        = {109584},
  shortjournal = {Appl. Soft. Comput.},
  title        = {MLP-based learnable window size for bitcoin price prediction},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An evidence theory-based large group FMEA framework
incorporating bounded confidence and its application in supercritical
water gasification system. <em>ASOC</em>, <em>129</em>, 109580. (<a
href="https://doi.org/10.1016/j.asoc.2022.109580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supercritical water gasification (SCWG) is an advanced technology for sewage sludge treatment , which can effectively remove hazardous substances in it and realize the resource utilization of sludge. Given the harsh operating environment and complex operating process, it is particularly critical for SCWG system to adopt failure mode and effects analysis (FMEA) to ensure its reliability and security. In particular, the risk management process of SCWG system needs to include two considerations: the evaluation process requires the participation of a large number of team members (TMs) with different professional knowledge and operational skills, and the cross-correspondence between the factors within the system cannot be ignored in the analysis process. Thus, an FMEA framework is established to meet practical needs, which can model TMs’ personality traits and reflect the interdependencies between factors. First, assessments in the form of probability linguistic term sets (PLTSs) are converted into mass functions due to the excellence of evidence theory in information aggregation. Second, a bounded confidence-based clustering method is developed to consider TMs’ willingness to interact during clustering. Additionally, evidence conflicts are managed using a new discounting method that captures TMs’ stubbornness. Besides, the cross-correspondence between factors is analyzed by an evidence theory-based DEMATEL method. Further considering TMs’ bounded rationality, regret theory (RT) is used to distinguish and prioritize failure modes (FMs). Finally, a case study of an SCWG system is successfully solved by applying the proposed framework. The effectiveness and superiority are subsequently demonstrated by a series of analyses and discussions.},
  archive      = {J_ASOC},
  author       = {Zhengmin Liu and Yawen Bi and Peide Liu},
  doi          = {10.1016/j.asoc.2022.109580},
  journal      = {Applied Soft Computing},
  pages        = {109580},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An evidence theory-based large group FMEA framework incorporating bounded confidence and its application in supercritical water gasification system},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A nonlinear model and an algorithm for identifying cancer
driver pathways. <em>ASOC</em>, <em>129</em>, 109578. (<a
href="https://doi.org/10.1016/j.asoc.2022.109578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The identification of driver pathways has attracted considerable attention in recent years due to the high significance of driver pathways in cancer related studies. In most identification methods, the linear measurement is adopted for evaluating exclusivity, and some preset parameters are introduced to balance the contributions of different measurements. However, both the linear measurement and the preset parameters may exert negative effects on the applications of these methods. In this study, a nonlinear function is devised to measure exclusivity, and a parameter free nonlinear maximum weight submatrix (NMWS) identification model is proposed by considering coverage, exclusivity and connectivity. A competitive co-evolution algorithm (CCA) is also put forward for solving the presented NMWS model. Experimental results on both real biological data and simulated one were used compare the identification performance of the presented method with that of seven state of the art ones. The pathway detected by the presented method not only contains more genes enriched in a known signaling pathway , but also has a stronger connectivity in Protein–Protein Interaction (PPI) network. Simultaneously, the high efficiency of the presented method makes it practical in realistic applications. All of which have been confirmed through a large number of experiments.},
  archive      = {J_ASOC},
  author       = {Jingli Wu and Xiaorong Chen and Gaoshi Li and Zheng Deng and Kai Zhu},
  doi          = {10.1016/j.asoc.2022.109578},
  journal      = {Applied Soft Computing},
  pages        = {109578},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A nonlinear model and an algorithm for identifying cancer driver pathways},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evolutionary algorithm based approach for solving
transportation problems in normal and pandemic scenario. <em>ASOC</em>,
<em>129</em>, 109576. (<a
href="https://doi.org/10.1016/j.asoc.2022.109576">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, COVID-19 pandemic has posed certain challenges to transportation companies due to the restrictions imposed by different countries during the lockdown. These restrictions cause delay and/ or reduction in the number of trips of vehicles, especially, to the regions with higher restrictions. In a pandemic scenario, regions are categorized into different groups based on the levels of restrictions imposed on the movement of vehicles based on the number of active cases (i.e., number of people infected by COVID-19), number of deaths, population, number of COVID-19 hospitals, etc. The aim of this study is to formulate and solve a fixed-charge transportation problem (FCTP) during this pandemic scenario and to obtain transportation scheme with minimum transportation cost in minimum number of trips of vehicles moving between regions with higher levels of restrictions. For this, a penalty is imposed in the objective function based on the category of the region(s) where the origin and destination are situated. However, reduction in the number of trips of vehicles may increase the transportation cost to unrealistic bounds and so, to keep the transportation cost within limits, a constraint is imposed on the proposed model. To solve the problem, the Genetic Algorithm (GA) has been modified accordingly. For this purpose, we have designed a new crossover operator and a new mutation operator to handle multiple trips and capacity constraints of vehicles. For numerical illustration, in this study, we have solved five example problems considering three levels of restrictions, for which the datasets are generated artificially. To show the effectiveness of the constraint imposed for reducing the transportation cost, the same example problems are then solved without the constraint and the results are analyzed. A comparison of results with existing algorithms proves that our algorithm is effective. Finally, some future research directions are discussed.},
  archive      = {J_ASOC},
  author       = {Amiya Biswas and Sankar Kumar Roy and Sankar Prasad Mondal},
  doi          = {10.1016/j.asoc.2022.109576},
  journal      = {Applied Soft Computing},
  pages        = {109576},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Evolutionary algorithm based approach for solving transportation problems in normal and pandemic scenario},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interval type-2 fuzzy c-means forecasting model for fuzzy
time series. <em>ASOC</em>, <em>129</em>, 109574. (<a
href="https://doi.org/10.1016/j.asoc.2022.109574">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fuzzy time-series (FTS) prediction model is based on fuzzy theory, which handles uncertain and fuzzy data. Owing to its good interpretability and prediction accuracy, the model based on the fuzzy C-means (FCM) clustering algorithm is most widely used. However, the fuzzy parameter m m in the FCM algorithm is an empirical value that leads to uncertainty in classification results , which can negatively affect predictions. This study proposes a new model, IT2-FCM-FTS, that uses the interval type-2 (IT2) FCM algorithm instead of the traditional FCM to divide the sample domain and improve the performance of the FTS model. To verify the reliability of the proposed model, five datasets and four evaluation indices are used to compare the prediction results of the proposed model with the traditional ARIMA model and the one based on FCM. The results show that the proposed model is superior to both in terms of prediction accuracy.},
  archive      = {J_ASOC},
  author       = {Yue Yin and Yehua Sheng and Jiarui Qin},
  doi          = {10.1016/j.asoc.2022.109574},
  journal      = {Applied Soft Computing},
  pages        = {109574},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Interval type-2 fuzzy C-means forecasting model for fuzzy time series},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An outward search to increase population diversity for
optimization algorithms. <em>ASOC</em>, <em>129</em>, 109572. (<a
href="https://doi.org/10.1016/j.asoc.2022.109572">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outward search (OS) is a new scheme proposed to provide diverse forms for improving convergence in evolutionary algorithms . Rather than using new functionalities, OS is performed using the differential-vector equations of an evolutionary algorithm. Three OS schemes are recommended in this study to obtain solutions that improve the performance of an evolutionary algorithm. The first one uses the original equations of the algorithm to generate either an OS solution or a candidate solution. The second utilizes the original equations to produce an OS solution and a candidate solution simultaneously for one individual. The last employs equations of another algorithm to create an OS solution for the studied algorithm. Three bio-inspired algorithms were examined using the CEC2015 benchmark suite to compare the respective performances of the proposed OS schemes. The results of the comparison indicate that searching regions outward from the current area outperformed examining oppositional locations obtained by opposition-based learning.},
  archive      = {J_ASOC},
  author       = {Hsing-Chih Tsai},
  doi          = {10.1016/j.asoc.2022.109572},
  journal      = {Applied Soft Computing},
  pages        = {109572},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An outward search to increase population diversity for optimization algorithms},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Process monitoring of nonlinear uncertain systems based on
part interval stacked autoencoder and support vector data description.
<em>ASOC</em>, <em>129</em>, 109570. (<a
href="https://doi.org/10.1016/j.asoc.2022.109570">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chemical process measurement may cause inaccuracy and uncertainty in some parts of the measurement data due to equipment aging and environmental conditions, such as temperature, humidity, gas pressure, gas flow , and other related factors. Uncertain data of this kind commonly fluctuate in an interval centered on the true value. Given the uncertain characteristics of some parts of the measurement data, the certain of some parts, and the nonlinearity of the industrial process, the present paper proposes a novel algorithm of process monitoring and fault diagnosis called Part Interval Stacked Autoencoder and Support Vector Data Description (PISAE–SVDD). The loss function of Stacked Autoencoder (SAE) is improved in this algorithm. In certain measurement data, the reconstruction error value is the mean square error of the original input data and output data. By contrast, uncertain measurement data provide a certain allowable range for reconstruction error value. The error value of measurement data is considered as zero within this range. The reconstruction error value of measurement data beyond the allowable range is calculated in the same way as for certain measurement data. At the same time, the characteristic information of the industrial process is extracted through the strong nonlinear characterization ability of SAE. Support Vector Data Description is then used to obtain the control limit of the fluctuation range of the normal working condition based on the SAE feature information data extracted from normal samples. This approach is adopted to realize the process monitoring of the industrial process with partial uncertain measurement. To detect fault, this algorithm was applied to the numerical simulation, the Tennessee Eastman process, and the process in industrial wastewater treatment plants , and then compared with other advanced algorithms. The results indicate the excellence and high efficiency of the PISAE–SVDD algorithm in the field of process monitoring.},
  archive      = {J_ASOC},
  author       = {Qiqi Wu and Weipeng Lu and Xuefeng Yan},
  doi          = {10.1016/j.asoc.2022.109570},
  journal      = {Applied Soft Computing},
  pages        = {109570},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Process monitoring of nonlinear uncertain systems based on part interval stacked autoencoder and support vector data description},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mutual gain adaptive network for segmenting brain stroke
lesions. <em>ASOC</em>, <em>129</em>, 109568. (<a
href="https://doi.org/10.1016/j.asoc.2022.109568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain stroke, an acute vascular disease, can lead to brain damage. As the incidence rate continues to increase, it becomes urgent and yet significantly to develop automatic tools for segmenting brain stroke lesions, for helping radiologists to detect brain stroke both effectively and accurately. Deep learning models, though have advanced this task, they are still suffering from the huge size variation and ambiguous boundaries of stroke lesions, both substantially degrading the segmentation performance . In this paper, we proposed an effective and generic learning network, called mutual gain adaptive network, to enhance the network’s ability on dealing with size variation and distinguishing ambiguous boundaries, for advancing deep neural networks in brain stroke lesion segmentation . The main contribution is that 1) a mutual gain adaptive similarity (MGAS) block and 2) a global context-awareness (GCA) block. MGAS block aims at capturing both short- and long-range spatial dependencies, for better encoding global contexts by leveraging feature similarity, to enhance feature activation for segmenting stroke lesions with different sizes. GCA block is designed to supply global context for low-semantic features, for facilitating the restoration of pixel localization to distinguish ambiguous boundaries. Our network is assessed in a publicly available dataset, e.g. Anatomical Tracings of Lesions After Stroke (ATLAS). Extensive experimental results show that it is better than state-of-the-art methods.},
  archive      = {J_ASOC},
  author       = {Boyu Huang and Guanru Tan and Haowen Dou and Zhihan Cui and Youyi Song and Teng Zhou},
  doi          = {10.1016/j.asoc.2022.109568},
  journal      = {Applied Soft Computing},
  pages        = {109568},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Mutual gain adaptive network for segmenting brain stroke lesions},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-adjusting multilayer nonlinear coupled mapping for
low-resolution face recognition. <em>ASOC</em>, <em>129</em>, 109566.
(<a href="https://doi.org/10.1016/j.asoc.2022.109566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical surveillance scenes, effective recognition of low-resolution (LR) images is an urgent issue. At present, the improvement of methods for LR image recognition tasks mainly focuses on how to effectively extract information from LR images. This paper explores a novel self-adjusting multilayer nonlinear coupled mapping (SMNCM) network. The proposed SMNCM includes two main components, the multilayer nonlinear coupled mapping (MNCM) module, which is the feature extractor, and the self-adjusting feature fusion (SaFF) module. In the MNCM module, the LR template image set and multiple different high-resolution template image sets are used to construct a pyramid-like multicoupled mapping feature extraction network . In the SaFF module, the fusion weights of multiple features and the other parameters are collaboratively learned for the purpose of correct classification by the gradient learning network. To achieve this goal, a new gradient optimization model for fusion weights and other parameters is constructed. The features fused by the learned weights and the multiple features of the MNCM module are more suitable for classification tasks . Experimental results indicate that on the five databases, our proposed method outperforms the state-of-the-art approaches for LR face recognition. The ablation experiment suggests that each module in the proposed method can contribute to improving the LR image recognition performance.},
  archive      = {J_ASOC},
  author       = {Jihong Pei and Yebin Chen and Yang Zhao and Chao Wang and Xuan Yang},
  doi          = {10.1016/j.asoc.2022.109566},
  journal      = {Applied Soft Computing},
  pages        = {109566},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Self-adjusting multilayer nonlinear coupled mapping for low-resolution face recognition},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Instance elimination strategy for non-convex
multiple-instance support vector machine. <em>ASOC</em>, <em>129</em>,
109564. (<a href="https://doi.org/10.1016/j.asoc.2022.109564">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple-instance support vector machine (SVM) is a classic and effective algorithm to address the classification of bags. However, training multiple-instance SVM is expensive. To deal with this issue, the safe screening rule is introduced to solve optimization problem , which can significantly mitigate the storage burden by identifying inactive instances. Specifically, an instance elimination strategy is designed for the inner solver of a signal concave–convex procedure (CCCP). Then, between the iterations of CCCP, due to the label of instance may change, to cope with this difficulty, a dual screening method with variational inequalities (DVI) is used to identify the part of inactive instances. To further speed up the solution efficiency, a smart dual coordinate descent method (SDCDM) is introduced for the inner solver, which skips over many updates that result in no change to the current iteration. Experiments on 35 benchmark datasets significantly exhibit the outstanding performance of the proposed strategy.},
  archive      = {J_ASOC},
  author       = {Min Yuan and Yitian Xu},
  doi          = {10.1016/j.asoc.2022.109564},
  journal      = {Applied Soft Computing},
  pages        = {109564},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Instance elimination strategy for non-convex multiple-instance support vector machine},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An ensemble meta-estimator to predict source code
testability. <em>ASOC</em>, <em>129</em>, 109562. (<a
href="https://doi.org/10.1016/j.asoc.2022.109562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unlike most other software quality attributes , testability cannot be evaluated solely based on the characteristics of the source code . The effectiveness of the test suite and the budget assigned to the test highly impact the testability of the code under test. The size of a test suite determines the test effort and cost, while the coverage measure indicates the test effectiveness. Therefore, testability can be measured based on the coverage and number of test cases provided by a test suite, considering the test budget. This paper offers a new equation to estimate testability regarding the size and coverage of a given test suite. The equation has been used to label 23, 000 classes belonging to 110 Java projects with their testability measure. The labeled classes were vectorized using 262 metrics. The labeled vectors were fed into a family of supervised machine learning algorithms , regression, to predict testability in terms of the source code metrics. Regression models predicted testability with an R 2 of 0.68 and a mean squared error of 0.03, suitable in practice. Fifteen software metrics highly affecting testability prediction were identified using a feature importance analysis technique on the learned model. The proposed models have improved mean absolute error by 38\% due to utilizing new criteria, metrics, and data compared with the relevant study on predicting branch coverage as a test criterion. As an application of testability prediction, it is demonstrated that automated refactoring of 42 smelly Java classes targeted at improving the 15 influential software metrics could elevate their testability by an average of 86.87\%.},
  archive      = {J_ASOC},
  author       = {Morteza Zakeri-Nasrabadi and Saeed Parsa},
  doi          = {10.1016/j.asoc.2022.109562},
  journal      = {Applied Soft Computing},
  pages        = {109562},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An ensemble meta-estimator to predict source code testability},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SeNPIS: Sequential network pruning by class-wise importance
score. <em>ASOC</em>, <em>129</em>, 109558. (<a
href="https://doi.org/10.1016/j.asoc.2022.109558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decade, pattern recognition and decision making from images has mainly focused on the development of deep learning architectures, with different types of networks such as sequential, residual and parallel. Although the depth and size varies between models, they all have in common that they can contain multiple filters or neurons that are not important for the purpose of prediction, and that do negatively impact the size of the model and their inference times. Therefore, it is advantageous to use pruning methods that, while largely maintaining the initial performance of the classifier, significantly reduce its size and FLOPs . In parameter reduction, the decision rule is generally based on mathematical criteria, e.g. the amplitude of the weights, but not on the actual impact of the filter or neuron on the classifier performance for each of the classes. Therefore, we propose SeNPIS as a method that involves both filter and neuron selection based on a class-wise importance score, and network resizing to increase parameter reduction and FLOPs in sequential CNN networks. Several tests were performed to compare SeNPIS with other representative state-of-the-art methods, for the CIFAR-10 and Scene-15 datasets. It was found that for similar values of accuracy, and even in some cases with a slight increase in accuracy, SeNPIS significantly reduces the number of parameters by up to an additional 23.5\% (i.e., a 51.05\% reduction with SeNPIS versus a 27.53\% reduction with Gradient) and FLOPs by up to an additional 26.6\% (i.e., a 74.82\% reduction with SeNPIS versus a 48.16\% reduction with Weight) compared to the Weight, Taylor, Gradient and LRP methods.},
  archive      = {J_ASOC},
  author       = {César G. Pachón and Dora M. Ballesteros and Diego Renza},
  doi          = {10.1016/j.asoc.2022.109558},
  journal      = {Applied Soft Computing},
  pages        = {109558},
  shortjournal = {Appl. Soft. Comput.},
  title        = {SeNPIS: Sequential network pruning by class-wise importance score},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A reinforcement learning approach for multi-fleet aircraft
recovery under airline disruption. <em>ASOC</em>, <em>129</em>, 109556.
(<a href="https://doi.org/10.1016/j.asoc.2022.109556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An airline scheduler plans flight schedules with efficient resource utilization. However, unpredictable airline disruptions, such as temporary closures of an airports , cause schedule perturbations. Therefore, recovering disrupted flight schedules is essential for airlines. Many previous studies have relied on copies of flight arcs, which could affect the quality of solutions, and have not addressed the key measure of airlines’ on-time performance as their objective. To fill these research gaps, we propose Q-learning and Double Q-learning algorithms using the reinforcement learning approach for aircraft recovery to support airline operations. We present an artificial environment of daily flight schedules and the Markov decision process for aircraft recovery. The proposed approach is first compared with existing algorithms on the benchmark instance. In comparison with other algorithms, the developed Q-learning and Double Q-learning algorithms obtain high-quality solutions within the proper computation time. To verify that the proposed approach can be applicable to a real-world case and can adapt to realistic conditions, we employ a domestic flight schedule from one of the airlines in South Korea. We evaluate the reinforcement learning approach on a set of experiments carried out on real-world data. Computational experiments show that reinforcement learning algorithms recover disrupted flight schedules effectively, and that our approaches flexibly adapt to various objectives and realistic conditions.},
  archive      = {J_ASOC},
  author       = {Junhyeok Lee and Kyungsik Lee and Ilkyeong Moon},
  doi          = {10.1016/j.asoc.2022.109556},
  journal      = {Applied Soft Computing},
  pages        = {109556},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A reinforcement learning approach for multi-fleet aircraft recovery under airline disruption},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-heterogeneous sensor data fusion method via
convolutional neural network for fault diagnosis of wheeled mobile
robot. <em>ASOC</em>, <em>129</em>, 109554. (<a
href="https://doi.org/10.1016/j.asoc.2022.109554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wheeled mobile robots usually operate in a variety of human–robot coexisting environments. It is vital to improve their safety and reliability by investigating fault diagnosis methods . Multi-sensor data can provide a comprehensive description of a robot’s running state. However, wheeled mobile robots are generally equipped with multi-heterogeneous sensors, and extracting high-level fault features from multi-heterogeneous sensor data is difficult. This study proposes a novel channel-wise convolutional neural network with feature augmentation (CWCNN-FA) for the fault diagnosis of wheeled mobile robots. First, the proposed CWCNN-FA directly uses multi-heterogeneous sensor data as the input. Then, the channel-wise convolution mechanism is introduced to independently extract the heterogeneous fault features from the multi-channel input, which prevents these features from being mixed by the conventional convolution mechanism. Moreover, a feature augmentation layer was developed to highlight important features by adaptively weighting the multi-heterogeneous feature maps. Finally, all the feature maps were fed into the fully connected layer to perform data fusion and fault classification. Comparison experiments were conducted between CWCNN-FA and several commonly used fault diagnosis methods to verify the validity of the proposed method. The experimental results revealed that the proposed CWCNN-FA exhibits superior performance in terms of fault diagnosis accuracy and robustness.},
  archive      = {J_ASOC},
  author       = {Zhaoming Miao and Fengyu Zhou and Xianfeng Yuan and Yingxiang Xia and Ke Chen},
  doi          = {10.1016/j.asoc.2022.109554},
  journal      = {Applied Soft Computing},
  pages        = {109554},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-heterogeneous sensor data fusion method via convolutional neural network for fault diagnosis of wheeled mobile robot},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generative focused feedback residual networks for image
steganalysis and hidden information reconstruction. <em>ASOC</em>,
<em>129</em>, 109550. (<a
href="https://doi.org/10.1016/j.asoc.2022.109550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image steganalysis is the process of detecting the presence of hidden information in an image. Existing image steganalysis methods cannot fully extract hidden image information even if the presence of hidden information is successfully detected, resulting in either poor detection performance or inability to reconstruct hidden information. This paper proposes a generative image steganalysis algorithm based on focused feedback residual convolutional neural network for simultaneous detection and extraction of hidden information. First, a possible stego image was processed by a preprocessing network consisting of several convolutional layers and two fresh focus modules, and several enhanced feature maps were output. Then, the resulting enhanced feature maps were fetched into both a classification network and a reconstruction network. The classification network identified whether the feature maps came from a stego image or a simple cover image. The reconstruction network, consisting of some layers of convolutional units, pixel shufflers and feedback residual modules, completed the reconstruction of hidden information. Experimental results show that the proposed image steganalysis algorithm can obtain state-of-the-art results in terms of detection rate and hidden information reconstruction compared with classical rich models and several recent deep learning-based methods.},
  archive      = {J_ASOC},
  author       = {Zhengliang Lai and Xishun Zhu and Jianhua Wu},
  doi          = {10.1016/j.asoc.2022.109550},
  journal      = {Applied Soft Computing},
  pages        = {109550},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Generative focused feedback residual networks for image steganalysis and hidden information reconstruction},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An interactive dual-branch network for hard palate
segmentation of the oral cavity from CBCT images. <em>ASOC</em>,
<em>129</em>, 109549. (<a
href="https://doi.org/10.1016/j.asoc.2022.109549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic and accurate segmentation of the hard palate from Cone Beam and Computed Tomography (CBCT) images is a fundamental task for the insertion of orthodontic mini-implants. U-Net and its variants fail to handle it well when facing the hard palate with diversity of shape. Further, hard palate has low-density soft tissues and high-density hard bones so as to exhibit different intensity of regions in CBCT images, which may result in mis-segmentation or missing-segmentation. Motivated by these challenges, a novel Interactive Dual-Branch Network (IDBNet) is presented to achieve automatic and accurate segmentation of the hard palate in the oral cavity from CBCT images. Specifically, we introduce the designs for hard palate segmentation as follows: (1) Dual-branch encoder–decoder is developed for hard palate with the ability of data expansion and extracting multi-scale interactive features. (2) Channel map interaction module is proposed to reinforce the cross-channel information communication between different level features, thereby enhancing feature representations for variable hard palate. (3) Guide map interaction module is designed to model the similarities and differences of dual-branch hard palate boundaries. Owing to the remarkable designs, our IDBNet has the ability to gradually mine ambiguous hard palate affected by different intensity of regions. Moreover, we collected an in-house dataset with 30 challenging cases, which contained 2260 CBCT slices. Among them, 70\% for training and 30\% for testing are considered. Five-fold cross-validation experiments on this dataset demonstrate that our method outperforms the Res-UNet method by 8.05\% of mean Dice score and 7.97\% of structure measure. The utilization of our proposed segmentation approach for hard palate of the oral cavity warrants further investigation on implantable area, which could aid in formulating clinical plans on the insertion regions of palatal mini-implants.},
  archive      = {J_ASOC},
  author       = {Ke Zou and Tianjin Tao and Xuedong Yuan and Xiaojing Shen and Wenli Lai and Hu Long},
  doi          = {10.1016/j.asoc.2022.109549},
  journal      = {Applied Soft Computing},
  pages        = {109549},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An interactive dual-branch network for hard palate segmentation of the oral cavity from CBCT images},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FUME: An air quality decision support system for cities
based on CEP technology and fuzzy logic. <em>ASOC</em>, <em>129</em>,
109536. (<a href="https://doi.org/10.1016/j.asoc.2022.109536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Air pollution has become one of the most important problems in urban areas, and governments are applying regulations in an attempt to fulfill the recommendations of Air Quality (AQ) standards to reduce the pollution. In this paper, we present FUME, a decision support system to process heterogeneous and real-time data to propose daily recommendations following an action protocol based on AQ standards. This approach considers past, current and future environmental situations (AQ and atmospheric stability). FUME is implemented by combining Fuzzy Logic (FL) and Complex Event Processing (CEP) technology. In particular, we propose a Fuzzy Inference System (FIS) to improve the decision-making process by recommending the actions for four different sources of pollution: traffic, industry, domestic and agriculture. The FUME approach is applied to a specific case study: the city of Puertollano (Ciudad Real, Spain), where the pollution levels of PM 10 are, on numerous occasions, above the World Health Organization (WHO) recommendations.},
  archive      = {J_ASOC},
  author       = {Enrique Brazález and Hermenegilda Macià and Gregorio Díaz and María_Teresa Baeza_Romero and Edelmira Valero and Valentín Valero},
  doi          = {10.1016/j.asoc.2022.109536},
  journal      = {Applied Soft Computing},
  pages        = {109536},
  shortjournal = {Appl. Soft. Comput.},
  title        = {FUME: An air quality decision support system for cities based on CEP technology and fuzzy logic},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian neuroevolution using distributed swarm optimization
and tempered MCMC. <em>ASOC</em>, <em>129</em>, 109528. (<a
href="https://doi.org/10.1016/j.asoc.2022.109528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The major challenge of Bayesian neural networks has been in developing effective sampling methods that address deep neural networks and big data-related problems. As an alternative to gradient-based training methods, neuro-evolution features evolutionary algorithms that provide a black-box approach to learning in neural networks . Neuroevolution employs evolutionary and swarm optimization methods to provide an alternative where the training algorithm is not constrained to the architecture of the network and has the potential to reduce local-minima and vanishing gradient problems. Bayesian neural networks use variational inference and Markov chain Monte Carlo (MCMC) sampling methods. Tempered MCMC is a powerful MCMC method that can take advantage of a parallel computing environment and efficient proposal distributions. In this paper, we present a synergy of neuroevolution and Bayesian neural networks where operators in particle swarm optimization (PSO) are used for forming efficient proposals in tempered MCMC sampling. The results show that the proposed method provides better prediction accuracy when compared to random-walk proposal distribution in MCMC for both time-series and pattern classification problems. The results also show substantial computational time reduction compared to gradient-based proposals while generating comparable accuracy performance. The Bayesian neuroevolution framework can be further introduced to models that do not have gradient information .},
  archive      = {J_ASOC},
  author       = {Arpit Kapoor and Eshwar Nukala and Rohitash Chandra},
  doi          = {10.1016/j.asoc.2022.109528},
  journal      = {Applied Soft Computing},
  pages        = {109528},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Bayesian neuroevolution using distributed swarm optimization and tempered MCMC},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cricketer’s tournament-wise performance prediction and squad
selection using machine learning and multi-objective optimization.
<em>ASOC</em>, <em>129</em>, 109526. (<a
href="https://doi.org/10.1016/j.asoc.2022.109526">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The selection of a proper squad for a competition is vital in any sport, and cricket is no different. The diversity of squad formation is vital because those in charge of squad formation must consider all characteristics of the players. The squad must be broad and diverse enough for any event that lasts a long time since the squad must be competent in every situation, regardless of whether the side is playing at home or against. We aim to make the procedure as computationally efficient as possible. Machine Learning algorithms appear to have gone a long way in anticipating a system based on the information gained from the provided data. The article attempts to forecast player performance for a future tournament while considering most important characteristics of a cricket player. The prediction appears more accurate than an approximation . Several machine learning algorithms are utilized and analyzed to select the best one to use in our proposed work. The second phase employs Multi-objective optimization (MOO) techniques to perceive optimum squads from a list of players based on anticipated performance and some additional attributes. However, the problem appears to have certain conflicting aspects that may be handled by Multi-objective evolutionary algorithms (MOEA). Finally, a comparison is made between well-known MOEAs, and the results suggest that NSGA-II performs better for the problem.},
  archive      = {J_ASOC},
  author       = {Devopriya Tirtho and Shafin Rahman and Md. Shahriar Mahbub},
  doi          = {10.1016/j.asoc.2022.109526},
  journal      = {Applied Soft Computing},
  pages        = {109526},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Cricketer’s tournament-wise performance prediction and squad selection using machine learning and multi-objective optimization},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sliding window and dual-channel CNN (SWDC-CNN): A novel
method for synchronous prediction of coal and electricity consumption in
cement calcination process. <em>ASOC</em>, <em>129</em>, 109520. (<a
href="https://doi.org/10.1016/j.asoc.2022.109520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a representative of the process industry, the cement industry consumes a large amount of coal and electricity resources . This is mainly due to the irrational energy scheduling caused by the rough production and independent statistics of each energy consumption indicator within the cement industry. The synchronous accurate prediction of energy consumption can provide a more resultful scheme for the production control process and energy scheduling. However, due to the time delay , variables coupling, and uncertainty of production, it is difficult to synchronously forecast multiple indicators. In this paper, a data-driven prediction method combining Sliding Window and Dual-Channel Convolutional Neural Network (SWDC-CNN) is proposed to achieve synchronous prediction of coal and electricity consumption in the next 5 min. The sliding window method is designed to extract time-varying delay characteristics of time series data to overcome its influence on energy consumption prediction. The effect of redundant parameters between weakly correlated variables on energy prediction is reduced by designing a dual-channel structure. We experimented and compared with excellent models Support Vector Machine (SVM), eXtreme Gradient Boosting (XGBoost), Recurrent Neural Network (RNN), Long Short Term Memory (LSTM), and Gate Recurrent Unit (GRU) on an actual cement production data in Shanxi Province, China. Experimental results show that the proposed SWDC-CNN model has good performance, the highest prediction accuracy, and can meet the expected requirements.},
  archive      = {J_ASOC},
  author       = {Xin Shi and Gaolu Huang and Xiaochen Hao and Yue Yang and Ze Li},
  doi          = {10.1016/j.asoc.2022.109520},
  journal      = {Applied Soft Computing},
  pages        = {109520},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Sliding window and dual-channel CNN (SWDC-CNN): A novel method for synchronous prediction of coal and electricity consumption in cement calcination process},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Quantum assimilation-based data augmentation for state of
health prediction of lithium-ion batteries with peculiar degradation
paths. <em>ASOC</em>, <em>129</em>, 109515. (<a
href="https://doi.org/10.1016/j.asoc.2022.109515">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lithium-ion batteries with more rapid capacity loss or “peculiar degradation paths” are usually hard to completely avoid in production given complex electrochemical systems and diverse failure mechanisms. These “abnormal” batteries typically account for only a small proportion in production, and their degradation paths may be very different from most “normal” batteries in the existing dataset. Therefore, it is difficult to accurately predict their subsequent capacity degradation trends using models trained by the existing dataset. To solve this problem, this paper proposes a novel data augmentation technique based on quantum assimilation to accurately predict the state of health of lithium-ion batteries with peculiar degradation paths. The quantum assimilation algorithm has the outstanding advantage of revealing the distribution of the samples by constructing the potential energy surface of the existing data with a nonlinear Gaussian wave function, which provides a novel feature space for data augmentation . The early-cycle data of newly emerged abnormal samples can also be located on this potential energy surface, and the possible degradation increment of each subsequent cycle can be inferred based on the principle that particles tend to gather at the position with the lowest potential energy. Based on this, possible degradation paths of abnormal samples can be generated to enhance the training dataset and the machine learning model trained using it can better predict the abnormal lithium-ion batteries. The proposed method is verified on an actual lithium-ion battery dataset with mean percentage error of the prediction results less than 0.5\%, which is at least 44\% lower than that of the other four conventional methods.},
  archive      = {J_ASOC},
  author       = {Haotian Gao and Kunsong Lin and Yuxuan Cui and Yunxia Chen},
  doi          = {10.1016/j.asoc.2022.109515},
  journal      = {Applied Soft Computing},
  pages        = {109515},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Quantum assimilation-based data augmentation for state of health prediction of lithium-ion batteries with peculiar degradation paths},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Algorithmically-guided discovery of viral epitopes via
linguistic parsing: Problem formulation and solving by soft computing.
<em>ASOC</em>, <em>129</em>, 109509. (<a
href="https://doi.org/10.1016/j.asoc.2022.109509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective identification of detailed biochemical features at the protein level has the potential to boost genome-based Virology and Vaccinology, by enhancing detection of viruses’ weak spots. Precise mapping of such sensitive sites, also known as the epitopes identification problem , constitutes a grand computational challenge: solving it may lead to an improved vaccine efficacy against existing as well as future viral strains. We consider the open-ended challenge of discovering unmapped epitopes. We introduce a spatial-linguistic approach, in which the relevant proteins’ sequences are considered as alphabetical strings with a linked, known 3D structure. The explicit aim is to correctly parse them into meaningful tokens/subsets with respect to the chemical space, to be associated with the virus’ epitopes. The problem is then translated into seeking an effective tokenizer /word-splitter, adhering to prescribed biochemical criteria and satisfying spatial constraints, whose output specifies subsequences that accurately map the epitopes. We devise three competing procedures, namely two chemistry-driven, parameterized heuristics as well as a constrained Subset Selection problem-solver. The heuristics require tuning, which we conduct by Evolution Strategies, whereas we employ a Genetic Algorithm as the latter problem-solver. Empirical results are presented herein for detecting epitopes of influenza A(H3N2), exhibiting an improvement with respect to the baseline reference when applied to experimental Hemagglutination Inhibition data. Finally, we discuss the potential of the proposed approach with respect to the recent SARS-CoV-2 coronavirus, in the effort to further develop and improve effective vaccines and fight the COVID-19 pandemic.},
  archive      = {J_ASOC},
  author       = {Ofer M. Shir and Assaf Israeli and Assaf Caftory and Guy Zepko and Itai Bloch},
  doi          = {10.1016/j.asoc.2022.109509},
  journal      = {Applied Soft Computing},
  pages        = {109509},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Algorithmically-guided discovery of viral epitopes via linguistic parsing: Problem formulation and solving by soft computing},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An effective iterative greedy algorithm for distributed
blocking flowshop scheduling problem with balanced energy costs
criterion. <em>ASOC</em>, <em>129</em>, 109502. (<a
href="https://doi.org/10.1016/j.asoc.2022.109502">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increase in production levels, a pattern of industrial production has shifted from a single factory to multiple factories, resulting in a distributed production model. The distributed flowshop scheduling problem (DPFSP) is of great research significance as a frequent pattern in real production activities. In this paper, according to real-world scenarios, we have added blocking constraints and sequence-dependent setup times (SDST) to the DFSP and proposed a distributed blocking flowshop scheduling problem with sequence-dependent setup times (DBFSP_SDST). In a distributed environment, the allocation of resources and utilization have become an urgent problem to be solved. In addition, scheduling problems related to resource conservation have also attracted increasing attention. Therefore, we study DBFSP_SDST and consider minimizing the energy consumption cost of the critical factory (critical factory is the factory with maximum energy consumption cost) under resource balance. To tackle this problem, an effective iterated greedy algorithm based on a learning-based variable neighborhood search algorithm (VNIG) is proposed. In VNIG, an efficient construction heuristic is well designed. Two different local searches based on the characteristics of the proposed problem are developed to enhance the local exploitation by neighborhood searching. A learning-based selection variable neighborhood search strategy is designed to avoid the solution trapping in local optima. By conducting extensive simulation experiments, the proposed VNIG shows superior performance compared with artificial chemical reaction optimization (CRO, 2017), the discrete artificial bee colony algorithm (DABC, 2018), the iterative greedy algorithm with a variable neighborhood search scheme (IGR, 2021), and the evolution strategy approach (ES, 2022).},
  archive      = {J_ASOC},
  author       = {Xue Han and Yuyan Han and Biao Zhang and Haoxiang Qin and Junqing Li and Yiping Liu and Dunwei Gong},
  doi          = {10.1016/j.asoc.2022.109502},
  journal      = {Applied Soft Computing},
  pages        = {109502},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An effective iterative greedy algorithm for distributed blocking flowshop scheduling problem with balanced energy costs criterion},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Clustering ensemble based on approximate accuracy of the
equivalence granularity. <em>ASOC</em>, <em>129</em>, 109492. (<a
href="https://doi.org/10.1016/j.asoc.2022.109492">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering ensemble deals with the inconsistent parts of base clusterings while maintaining consistency in the clustering results . The cluster core samples generally have more consistent neighbor relationship in base clusterings than the cluster edge samples, and these two types of samples have different contributions to the determination of the underlying data structure . In addition, in clustering ensemble, some samples that are equivalent in base clusterings can be merged into equivalence granularity to reduce the size of input data. Based on these ideas and combined with rough set theory , we propose a novel clustering ensemble algorithm based on the approximate accuracy of equivalence granularity . We initially define the clustering equivalence relation, extract the consistent results of base clusterings based on this relation, and upgrade the clustering ensemble from the sample level to the equivalence granularity level. Afterward, we use the approximate accuracy of the rough set to quantify the contribution of equivalence granularity in discovering the underlying data structure , divide the equivalence granularities into core and edge equivalence granularities, and implement different clustering processing strategies. The visual experiments on four synthetic data sets and comparison experiments with 14 state-of-the-art clustering ensemble algorithms on 21 data sets respectively prove the rationality and excellent performance of our proposed algorithm.},
  archive      = {J_ASOC},
  author       = {Xia Ji and Shuaishuai Liu and Lei Yang and Wanli Ye and Peng Zhao},
  doi          = {10.1016/j.asoc.2022.109492},
  journal      = {Applied Soft Computing},
  pages        = {109492},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Clustering ensemble based on approximate accuracy of the equivalence granularity},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A self-adapting algorithm for many-objective optimization.
<em>ASOC</em>, <em>129</em>, 109484. (<a
href="https://doi.org/10.1016/j.asoc.2022.109484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An increase in computing power available from modern processors and GPUs has allowed more complex design optimization problems to be solved. This increase in complexity typically results in a difficult optimization problem with a highly non-linear objective function topology. In this work a robust optimization algorithm is presented capable of efficiently traversing higher-dimensional objective function space to find Pareto optimal solutions . It is well known that no single optimization algorithm performs best for all problems. Therefore, the developed method, a many-objective hybrid optimizer (MOHO), uses five constitutive algorithms and actively switches among them throughout the optimization process to accelerate the convergence, avoid local minima and arrive at a diverse set of optimal designs. MOHO monitors the progress made by each of the five algorithms and allows the best performing algorithm more attempts at finding the optimum. The MOHO algorithm was tested on 13 unconstrained and five constrained analytical test problems, of up to 15 objectives, from the DTLZ and WFG test suite. The MOHO algorithm performed, on average, better than the five constitutive algorithms in 52\% of the unconstrained DTLZ+WFG problems and in 70\% of the constrained DTLZ test problems.},
  archive      = {J_ASOC},
  author       = {Sohail Reddy and George S. Dulikravich},
  doi          = {10.1016/j.asoc.2022.109484},
  journal      = {Applied Soft Computing},
  pages        = {109484},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A self-adapting algorithm for many-objective optimization},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Prediction of nonlinear structural response under wind loads
using deep learning techniques. <em>ASOC</em>, <em>129</em>, 109424. (<a
href="https://doi.org/10.1016/j.asoc.2022.109424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The wind actions on buildings are continuous in nature and could range from a few minutes to more than hours. Such long duration high intensity winds can push the structure to enter post elastic structural range and cause nonlinear behavior . Therefore, unlike performance-based earthquake engineering, where the structural simulations require seismic loads acting for a few seconds, the simulations for performance-based wind engineering (PBWE) requires wind load models acting for much longer durations. However, the nonlinear 3D model of a tall building will contain thousands of connections and structural members making it a complex finite element model . Dynamic time history analysis of such a model under loads lasting for hours can be tedious and often fail to achieve convergence. Using data-driven techniques that utilizes limited numerical and field data to obtain accurate structural responses under long duration loads is an exciting alternative. Deep learning techniques have been extensively used in the studies for structural health monitoring and earthquake engineering. However, the implementation of such data-driven techniques is very limited and has the potential for exploration in problems related to wind dynamics on tall buildings. This paper aims to predict the nonlinear structural response of tall buildings under sustained durations of wind loads using deep learning models. A Long Short-term Memory (LSTM) architecture is used to assess the efficiency of data-driven methods to replace computationally intensive 3D finite element analyses. The architecture will be tested on a 150 m tall building for response predictions under long duration wind loads. The robustness of the architecture will be further evaluated with predicting the acceleration response history of a scaled aeroelastic model based on experimental studies conducted at the Wind Simulation and Testing Laboratory (WiST) at Iowa State University.},
  archive      = {J_ASOC},
  author       = {Smrithi Preetha Hareendran and Alice Alipour},
  doi          = {10.1016/j.asoc.2022.109424},
  journal      = {Applied Soft Computing},
  pages        = {109424},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Prediction of nonlinear structural response under wind loads using deep learning techniques},
  volume       = {129},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Soft computing for intelligent edge computing.
<em>ASOC</em>, <em>128</em>, 109628. (<a
href="https://doi.org/10.1016/j.asoc.2022.109628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ASOC},
  author       = {Mohammad Mehedi Hassan and Md. Rafiul Hassan and Victor Hugo C. de Albuquerque and Witold Pedrycz},
  doi          = {10.1016/j.asoc.2022.109628},
  journal      = {Applied Soft Computing},
  pages        = {109628},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Soft computing for intelligent edge computing},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sustainable material selection with crisp and ambiguous data
using single-valued neutrosophic-MEREC-MARCOS framework. <em>ASOC</em>,
<em>128</em>, 109546. (<a
href="https://doi.org/10.1016/j.asoc.2022.109546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many industries around the globe are opting for environment-friendly and intelligent solutions. In this regard, the materials and manufacturing sectors have also evolved beyond the fundamental requirements for industrial applications by incorporating sustainable practices into their operations. To promote carbon-neutral growth for sustainable production, green materials that can be reused and recycled have gained significant importance. Previous work on material selection has relied on parameters that either take crisp or ambiguous inputs. However, criteria based on the core concept of sustainability, such as environmental considerations, require uncertain or indeterminate expert assessments solved using single-valued neutrosophic sets (SVNSs). For this reason, sustainable material selection necessitates the development of a unique framework to evaluate both crisp and ambiguous data concurrently without losing any information. In this work, a novel integrated framework combining method based on the removal effects of criteria (MEREC) and measurement alternatives and ranking based on compromise solution (MARCOS) under the SVNSs environment is developed to assist designers in solving real-time engineering problems, taking inputs from three decision-makers. To demonstrate the applicability of the proposed framework, a case study for the material selection of a lightweight aircraft wing spar is considered. The criteria assessment factors used for the material selection are economic, structural, damage-tolerance, manufacturing, and environmental impact. To underline the advantages of the proposed methodology, a comparative analysis is carried out with distinct integrated frameworks. Furthermore, the findings of sensitivity analysis indicate that the suggested technique is an effective, efficient, and practical decision-making tool. The excellent correlation of the Spearman coefficient of the proposed approach with interactive and multiple attribute decision making (TODIM) and complex proportional assessment (COPRAS) under SVNSs shows the legitimacy of the obtained ranking. The material selection tool is practical because it is developed using MATLAB and may be adapted to other applications with more criteria and alternatives.},
  archive      = {J_ASOC},
  author       = {R. Sami Ul Haq and M. Saeed and N. Mateen and F. Siddiqui and M. Naqvi and J.B. Yi and S. Ahmed},
  doi          = {10.1016/j.asoc.2022.109546},
  journal      = {Applied Soft Computing},
  pages        = {109546},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Sustainable material selection with crisp and ambiguous data using single-valued neutrosophic-MEREC-MARCOS framework},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiobjective evolutionary computation for high-order
genetic interactions. <em>ASOC</em>, <em>128</em>, 109538. (<a
href="https://doi.org/10.1016/j.asoc.2022.109538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A number of research works support the relationship between Single Nucleotide Polymorphisms (SNPs) and neurodegenerative diseases (e.g. Alzheimer’s or Parkinson’s Disease). It has been proven that these neurodegenerative diseases are mainly caused by the interaction of different SNPs. The complexity of identifying genetic interactions increases exponentially with two factors: (i) the number of SNPs contained in the biological dataset under study and (ii) the number of SNPs involved in the interaction. Therefore, this paper proposes the application of two of the most successful multiobjective evolutionary algorithms to solve this problem: a Reference-point based Many-objective Fast Non-dominated Sorting Genetic Algorithm (NSGA-III) and a Multiobjective Evolutionary Algorithm based on Decomposition with Dynamical Resource Allocation (MOEA/D-DRA). These algorithms have been tested with four datasets (including a real dataset about Bipolar Disorder with 425, 574 SNPs) and three interaction sizes: 2, 5, and 8 loci. In addition, they have been compared against well-known and relevant approaches published in the literature, in both multiobjective and biological terms. The results clearly show the advantages of the approach based on NSGA-III . Particularly, NSGA-III improves the results obtained by other algorithms in multiobjective terms (by means of Hypervolume and Set Coverage indicators) and in biological terms (by means of Power, Recall, Precision, and F-measure metrics). Moreover, it reveals new 2 and 5 loci interactions over a Bipolar Disorder real dataset. Therefore, NSGA-III represents a relevant approach to detect high-order genetic interactions.},
  archive      = {J_ASOC},
  author       = {José M. Granado-Criado and Álvaro Rubio-Largo and Sergio Santander-Jiménez and Miguel A. Vega-Rodríguez},
  doi          = {10.1016/j.asoc.2022.109538},
  journal      = {Applied Soft Computing},
  pages        = {109538},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multiobjective evolutionary computation for high-order genetic interactions},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Electroencephalograph-based emotion recognition using
convolutional neural network without manual feature extraction.
<em>ASOC</em>, <em>128</em>, 109534. (<a
href="https://doi.org/10.1016/j.asoc.2022.109534">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalograph (EEG) based emotion recognition has been studied for a long time with the rapid development of brain–computer interface and electrode techniques. This paper introduces a new EEG-based emotion recognition model built with the convolutional neural network (CNN) to classify three emotions: positive, neutral, and negative. The proposed method adjusts the convolution kernels of the CNN to adapt to the EEG input signals. Unlike the manual feature extraction used in the traditional methods, the proposed method constructs the CNN with direct EEG data input, which ensures the integrity of information utilization and achieves better accuracy at 86.10\% on average. In addition, based on the research on full-channel and full-band data, four different profiles of 4, 6, 9, and 12 channels and five frequency bands are selected to study the critical factors that affect the recognition results.},
  archive      = {J_ASOC},
  author       = {Jian-Guo Wang and Hui-Min Shao and Yuan Yao and Jian-Long Liu and Hua-Ping Sun and Shi-Wei Ma},
  doi          = {10.1016/j.asoc.2022.109534},
  journal      = {Applied Soft Computing},
  pages        = {109534},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Electroencephalograph-based emotion recognition using convolutional neural network without manual feature extraction},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Combining physics-based and data-driven techniques for
reliable hybrid analysis and modeling using the corrective source term
approach. <em>ASOC</em>, <em>128</em>, 109533. (<a
href="https://doi.org/10.1016/j.asoc.2022.109533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Upcoming technologies like digital twins , autonomous, and artificial intelligent systems involving safety–critical applications require accurate, interpretable, computationally efficient, and generalizable models. Unfortunately, the two most commonly used modeling approaches, physics-based modeling (PBM) and data-driven modeling (DDM) struggle to satisfy all these requirements. In the current work, we demonstrate how a hybrid approach combining the best of PBM and DDM can result in models that can outperform both of them. We do so by combining partial differential equations based on first principles describing partially known physics with a black box DDM, in this case, a deep neural network model compensating for the unknown physics. The novelty of the work is in the theoretical contribution of presenting a sound mathematical argument for why the approach should work. The argument is backed by an array of experiments involving a two-dimensional heat diffusion problem with unknown source terms. The hybrid approach demonstrates the method’s superior performance in accuracy and generalizability . Additionally, it is shown how the DDM part can be interpreted within the hybrid framework to make the overall approach reliable. The approach, as we see, will be a door opener for underutilized DDMs in high stake applications.},
  archive      = {J_ASOC},
  author       = {Sindre Stenen Blakseth and Adil Rasheed and Trond Kvamsdal and Omer San},
  doi          = {10.1016/j.asoc.2022.109533},
  journal      = {Applied Soft Computing},
  pages        = {109533},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Combining physics-based and data-driven techniques for reliable hybrid analysis and modeling using the corrective source term approach},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bi-objective service composition and optimal selection for
cloud manufacturing with QoS and robustness criteria. <em>ASOC</em>,
<em>128</em>, 109530. (<a
href="https://doi.org/10.1016/j.asoc.2022.109530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important part of cloud manufacturing, service composition and optimal selection (SCOS) has attracted many scholars’ attentions. Although there are a large number of researches devoted to this field, plenty of challenges still remain, such as the difficulties of coping with real-life uncertainties and improving efficiency in making decisions. To this end, a bi-objective service composition and optimal selection (BoSCOS) problem which takes both QoS and robustness into account is firstly studied in this paper, its mathematical model is established after the two criteria are constructed. Then, a strengthened multi-objective gray wolf optimizer (SMOGWO) is developed to solve the above model with high efficiency, in which three improvement strategies are introduced to the original MOGWO : (1) the opposition based learning (OBL) strategy is adopted to improve the quality of initial population; (2) a leader update strategy is designed to explore better search leaders and balance the exploitation and exploration abilities; (3) an improved archiving strategy is developed to retain all possible dominant individuals, so as to improve the population diversity based on the Pareto dominance. Finally, the effectiveness of the proposed algorithm is verified on 8 BoSCOS problems with different scales and 17 benchmark functions , results show that the improvement strategies are effective and SMOGWO is superior to its competitors in terms of convergence and population diversity.},
  archive      = {J_ASOC},
  author       = {Yifan Gao and Bo Yang and Shilong Wang and Zhengping Zhang and Xiaoli Tang},
  doi          = {10.1016/j.asoc.2022.109530},
  journal      = {Applied Soft Computing},
  pages        = {109530},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Bi-objective service composition and optimal selection for cloud manufacturing with QoS and robustness criteria},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fusing visual and textual content for knowledge graph
embedding via dual-track model. <em>ASOC</em>, <em>128</em>, 109524. (<a
href="https://doi.org/10.1016/j.asoc.2022.109524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale knowledge graphs are usually incomplete. Knowledge graph embedding has achieved encouraging performance in alleviating the incompleteness of knowledge graphs. There are approaches to leverage the multi-modal content, such as text description and images, to improve the performance of knowledge graph embedding. However, due to the heterogeneity across different modalities, current methods are not effective to fuse the multi-modal content and network structure information to learn the embedding. In this work, a dual-track model DuMF for knowledge graph embedding enhancement is proposed. The model includes two tracks to fuse multi-modal content and network structure respectively. In each track, the expressiveness of joint features is improved by the bilinear method, and meanwhile the task-specific important features are learned by deliberate attention. Finally, the fused features are generated by the gating network. To extensively evaluate the model, two challenging datasets are enriched with additional multi-modal data. Experimental results show that DuMF is superior to baselines in link prediction. The flexibility of the model is promising for the further improvement of model performance.},
  archive      = {J_ASOC},
  author       = {Yancong Li and Xiaoming Zhang and Fang Wang and Bo Zhang and Feiran Huang},
  doi          = {10.1016/j.asoc.2022.109524},
  journal      = {Applied Soft Computing},
  pages        = {109524},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fusing visual and textual content for knowledge graph embedding via dual-track model},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intuitionistic fuzzy rule-base evidential reasoning with
application to the currency trading system on the forex market.
<em>ASOC</em>, <em>128</em>, 109522. (<a
href="https://doi.org/10.1016/j.asoc.2022.109522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the application of the intuitionistic fuzzy rule-base evidential reasoning ( I F R B E R IFRBER ) to the development of a new optimized automated trading system ( A T S ATS ) for the Forex market is presented. The used I F R B E R IFRBER approach represents the intuitionistic fuzzy sets in the framework of the evidence theory that allows us to avoid the revealed drawbacks of the I F S IFS operational laws and enhance the overall performance of the I F R B E R IFRBER approach. It is shown that the I F R B E R IFRBER approach extracts from an analyzed system considerably more of useful for the decision making information than the usual fuzzy rule-base evidential reasoning ( F R B E R FRBER ). Then based on the I F R B E R IFRBER , a new approach to make the justified transaction buying and selling decisions was proposed. This approach was used to develop a new optimized A T S ATS for the Forex market. It is shown that due to the ability of a new approach to use more of useful information that present implicitly in the problem formulation than the proposed earlier usual fuzzy rule-base evidential reasoning method, the developed A T S ATS provides a considerably more profitable and comfortable (with a higher percent of winning trades and with low risks) trading than the earlier developed A T S ATS .},
  archive      = {J_ASOC},
  author       = {Krzysztof Kaczmarek and Ludmila Dymova and Pavel Sevastjanov},
  doi          = {10.1016/j.asoc.2022.109522},
  journal      = {Applied Soft Computing},
  pages        = {109522},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Intuitionistic fuzzy rule-base evidential reasoning with application to the currency trading system on the forex market},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Structural rule-based modeling with granular computing.
<em>ASOC</em>, <em>128</em>, 109519. (<a
href="https://doi.org/10.1016/j.asoc.2022.109519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to analyze the dynamic behaviors of complex systems in the era of big data, a new rule-based modeling approach is proposed in this paper. This approach considers structural information mining and granular computing (GrC) in rule-based modeling, it also aims at utilizing granular fuzzy intervals to reflect systems’ behaviors on uncertainty. Major contributions can be summarized as three points. First, using DBSCAN’s advantages in clustering arbitrarily-shaped data, DBSCAN is applied to extract structural information as the basis of rules in complex systems. Second, GrC is leveraged for rule formation and effective rule-based modeling, e.g. granules constructed in input space to refine structural DBSCAN clusters, granular intervals constructed in output space with the principle of justifiable granulating to reflect system dynamic behaviors. Third, experimental analysis based on three different design scenarios was studied on both synthetic data and publicly available datasets. Through comparative discussion, the proposed approach can outperform the conventional rule-based models, specifically having an improvement ratio of 0.18\% to 1.48\% on the proposed comprehensive indicator. Therefore, it can be concluded that the proposed approach has the feasibility and advantages of reflecting the structural and uncertainty characteristics of system dynamic analysis.},
  archive      = {J_ASOC},
  author       = {Tinghui Ouyang},
  doi          = {10.1016/j.asoc.2022.109519},
  journal      = {Applied Soft Computing},
  pages        = {109519},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Structural rule-based modeling with granular computing},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Large-scale complex ontology matching through anchor-based
semantic partitioning technique and confidence matrix based evolutionary
algorithm. <em>ASOC</em>, <em>128</em>, 109516. (<a
href="https://doi.org/10.1016/j.asoc.2022.109516">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ontology presents a field knowledge by defining the meaning of domain concepts and relations among them. To conduct the inter-operability between two heterogeneous ontologies, we need to determine a number of entity correspondences, the so-called Ontology Matching (OM). Traditional OM techniques dedicate to find the simple correspondences which cannot sufficiently express the diverse kinds of heterogeneity, and therefore, complex correspondences are required, which maps one or multiple entities from one ontology to those from the other. Due to the semantic complexity, automatically discovering large-scale simple and complex correspondences has become a challenge. To face this challenge, in this work, an Anchor-based Semantic Partitioning Technique (ASPT) is first presented to divide the large-scale ontologies into several semantic segments, whose computational complexity is lower than the existing ontology partitioning algorithms. Then, a Pattern-based Similarity Measure (PSM) is used to distinguish both simple and complex correspondences. Finally, a Confidence Matrix based Evolutionary Algorithm (CM-EA) is proposed to efficiently match the ontology segments. We compare our proposal with EA-based matching technique and state-of-the-art ontology matching systems on OAEI’s Complex track, and the experimental results show that our approach is able to efficiently match large-scale complex ontologies.},
  archive      = {J_ASOC},
  author       = {Xingsi Xue and Pei-Wei Tsai and Junfeng Chen},
  doi          = {10.1016/j.asoc.2022.109516},
  journal      = {Applied Soft Computing},
  pages        = {109516},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Large-scale complex ontology matching through anchor-based semantic partitioning technique and confidence matrix based evolutionary algorithm},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predicting population size and termination criteria in
metaheuristics: A case study based on spotted hyena optimizer and crow
search algorithm. <em>ASOC</em>, <em>128</em>, 109513. (<a
href="https://doi.org/10.1016/j.asoc.2022.109513">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proper configuration of a metaheuristic requires specific and advanced knowledge, for instance to decide an appropriate population size, to effectively set probability parameters , or to define a correct termination criterion. During the last years there is a trend to let the metaheuristic to autonomously self-control the internal configuration . In this way, by using learning mechanisms, the algorithm is able to learn from the solving process and automatically adapt its configuration in order to improve their performance. Following this research trend, in this paper we explore the ability to autonomously predict population size and termination criteria. The population prediction allows the metaheuristic to dynamically vary the population size during solving time. In this regard, a suitable number of agents is used for each part of the process in order to efficiently explore the space of solutions. On the other hand, predicting the termination criteria is useful as well, the smart usage of resources in the optimization field can bring several advantages in solving complex industrial problems. In this regard, since the number of iterations is estimated during solving time, the proposed architecture avoids useless processing time that does not lead to any solution improvement. We illustrate interesting results using the spotted hyena optimizer and crow search algorithm solving 24 benchmarks functions and the multidimensional knapsack problem , where the proposed approach notably competes with several state-of-the-art optimization algorithms .},
  archive      = {J_ASOC},
  author       = {Emanuel Vega and Ricardo Soto and Broderick Crawford and Javier Peña and Pablo Contreras and Carlos Castro},
  doi          = {10.1016/j.asoc.2022.109513},
  journal      = {Applied Soft Computing},
  pages        = {109513},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Predicting population size and termination criteria in metaheuristics: A case study based on spotted hyena optimizer and crow search algorithm},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Comprehensive analysis of pathways in coronavirus 2019
(COVID-19) using an unsupervised machine learning method. <em>ASOC</em>,
<em>128</em>, 109510. (<a
href="https://doi.org/10.1016/j.asoc.2022.109510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The World Health Organization (WHO) introduced “Coronavirus disease 19” or “COVID-19” as a novel coronavirus in March 2020. Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) requires the fast discovery of effective treatments to fight this worldwide crisis. Artificial intelligence and bioinformatics analysis pipelines can assist with finding biomarkers, explanations, and cures. Artificial intelligence and machine learning methods provide powerful infrastructures for interpreting and understanding the available data. On the other hand, pathway enrichment analysis, as a dominant tool, could help researchers discover potential key targets present in biological pathways of host cells that are targeted by SARS-CoV-2. In this work, we propose a two-stage machine learning approach for pathway analysis. During the first stage, four informative gene sets that can represent important COVID-19 related pathways are selected. These “representative genes” are associated with the COVID-19 pathology. Then, two distinctive networks were constructed for COVID-19 related signaling and disease pathways. In the second stage, the pathways of each network are ranked with respect to some unsupervised scorning method based on our defined informative features. Finally, we present a comprehensive analysis of the top important pathways in both networks. Materials and implementations are available at: https://github.com/MahnazHabibi/Pathway .},
  archive      = {J_ASOC},
  author       = {Golnaz Taheri and Mahnaz Habibi},
  doi          = {10.1016/j.asoc.2022.109510},
  journal      = {Applied Soft Computing},
  pages        = {109510},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Comprehensive analysis of pathways in coronavirus 2019 (COVID-19) using an unsupervised machine learning method},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TSVM-m3: Twin support vector machine based on multi-order
moment matching for large-scale multi-class classification.
<em>ASOC</em>, <em>128</em>, 109506. (<a
href="https://doi.org/10.1016/j.asoc.2022.109506">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For multi-class classification, many existing methods, such as multiple weighted linear loss twin support vector machine (MWLTSVM), construct multiple decision hyperplanes by minimizing the positive points loss’s first-order moment (mean), which may lead to sensitivity to outliers. Also, when faced with a large-scale classification problem, how to speed up the process of solving the optimization model is also a challenge. An alternative is to use rectangular kernel technology (RKT) to reduce computational complexity . However, RKT is based on the uniform point selection method, which can be proven to be ineffective in improving classifier performance. To address these problems, a novel classifier under the structure of “one-versus-rest” for multi-class classification is proposed in this paper, named twin support vector machine based on multi-order moment matching (TSVM-M 3 ). When constructing the decision hyperplanes , TSVM-M 3 takes the first-order and second-order moments (mean and variance) of positive points loss into consideration and implements this by introducing an adjusting factor into the objective function. A theoretical analysis of the robustness of the proposed TSVM-M 3 is also provided. Meanwhile, a novel RKT based on the density-dependent data selection method is proposed for large-scale classification. We demonstrate that the proposed RKT can benefit from reducing modeling error. Experimental results show the effectiveness of the proposed TSVM-M 3 .},
  archive      = {J_ASOC},
  author       = {Wenwen Qiang and Hongjie Zhang and Jingxing Zhang and Ling Jing},
  doi          = {10.1016/j.asoc.2022.109506},
  journal      = {Applied Soft Computing},
  pages        = {109506},
  shortjournal = {Appl. Soft. Comput.},
  title        = {TSVM-m3: Twin support vector machine based on multi-order moment matching for large-scale multi-class classification},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A centroid opposition-based coral reefs algorithm for
solving an automated guided vehicle routing problem with a recharging
constraint. <em>ASOC</em>, <em>128</em>, 109504. (<a
href="https://doi.org/10.1016/j.asoc.2022.109504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated guided vehicles (AGVs) have been utilized extensively in material handling systems. In this paper, a synchronization problem of task scheduling and AGV routing is studied on a shop floor with reconfigurable machine tools. The objective is to minimize the maximum completion time (i.e., makespan) of all products. Studying scheduling and routing problems simultaneously, we propose a centroid opposition-based coral reefs optimization (COCRO) algorithm combined with a heuristic. The developed heuristic uses the Dijkstra algorithm to extract collision-free paths. To test the performance of the proposed algorithm, its results are compared to the results of the algorithm used in the literature recently. The results indicate the superiority of the COCRO algorithm. Finally, the performance of the system under different circumstances is analyzed. Based on the results, it can be claimed that reconfigurable machines reduce production time by up to 35\%. Furthermore, the capacity of AGVs has a more significant role than the number of AGVs in the production time. Also, comparing four widely used types of batteries (i.e., sealed GEL, AGM pure-lead, Lithium, and flooded lead-acid), the result confirms the superiority of Lithium batteries .},
  archive      = {J_ASOC},
  author       = {Ehsan Manafi and Reza Tavakkoli-Moghaddam and Mehdi Mahmoodjanloo},
  doi          = {10.1016/j.asoc.2022.109504},
  journal      = {Applied Soft Computing},
  pages        = {109504},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A centroid opposition-based coral reefs algorithm for solving an automated guided vehicle routing problem with a recharging constraint},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feature-preserved convolutional neural network for 3D mesh
recognition. <em>ASOC</em>, <em>128</em>, 109500. (<a
href="https://doi.org/10.1016/j.asoc.2022.109500">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D polygonal mesh is an efficient 3D data representation in computer graphics . Meanwhile, deep neural computing has achieved state-of-the-art results in visual recognition. However, it still remains a great challenge for convolution neural networks to learn effective mesh representations, especially due to the difficulty in effective downsampling of the irregular mesh structures. In this paper, we propose a new convolutional neural network for 3D mesh recognition by introducing an effective feature-preserved mesh pooling mechanism, which is then referred to as feature-preserved convolutional neural network or FPCNN. Specifically, the overall FPCNN framework consists of stacks of mesh convolution/pooling layers, and we address the problem of preserving the shape priors as follows: (1) we introduce the neighbor edges’ information to devise a 7-dimensional vector as the input feature to describe the shapes of meshes in a more intuitive way; and (2) we propose a new edge collapse operation in which the collapsing cost is composed of the quadric error and the dihedral angle . With the proposed pooling operation, we are able to determine the edge collapsing order and calculate the optimal positions of newly generated vertices in the mesh pooling process, thus maintaining effective mesh shape structures. Experimental results on popular mesh classification/segmentation datasets demonstrate that the proposed method outperforms previous methods in terms of classification/segmentation accuracy and feature preservation performance.},
  archive      = {J_ASOC},
  author       = {Yaqian Liang and Fazhi He and Xiantao Zeng and Baosheng Yu},
  doi          = {10.1016/j.asoc.2022.109500},
  journal      = {Applied Soft Computing},
  pages        = {109500},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Feature-preserved convolutional neural network for 3D mesh recognition},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Global temperature reconstruction of equipment based on the
local temperature image using TRe-GAN. <em>ASOC</em>, <em>128</em>,
109498. (<a href="https://doi.org/10.1016/j.asoc.2022.109498">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During contemporary industrial design and production, traditional numerical simulation is incapable of predicting the temperature field of undetectable surfaces with high accuracy, rapidity and board applicability. In this paper, we present a temperature reconstruction generative adversarial network (TRe-GAN), which can rapidly predict the temperature field of all equipment surfaces through one readily observable two-dimensional temperature image rather than specific thermodynamic parameters . Compared with previous surface temperature prediction networks, TRe-GAN reconstructs surface temperature field via vertex temperatures instead of surface texture, which innovatively incorporates both computer vision semantics and heat transfer semantics. Conditions inputs and an optimization output module were designed to strengthen vertex association and mitigate over-fitting. An orthogonal experimental design scheme considering heat transfer theory is employed to construct reliable data sets representative enough for heat transfer phenomenons. Model details, such as loss function and normalized scheme, are discussed to improve the overall temperature accuracy for thousands of nodes (MAPE = 0.93K). TRe-GAN trained in numerical-simulation data performs well in predicting the global temperature field of the measured experimental data (MAPE=0.89\%), which proves that our network effectively avoids over-fitting and can predict measured data from easily available simulated data. Therefore, TRe-GAN has great application potential in producing or designing industrial equipment and target characteristics prediction on the battlefield.},
  archive      = {J_ASOC},
  author       = {Jincheng Chen and Feiding Zhu and Yuge Han and Zhendao Xu and Qing Chen and Dengfeng Ren},
  doi          = {10.1016/j.asoc.2022.109498},
  journal      = {Applied Soft Computing},
  pages        = {109498},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Global temperature reconstruction of equipment based on the local temperature image using TRe-GAN},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Smoke detection in video using convolutional neural networks
and efficient spatio-temporal features. <em>ASOC</em>, <em>128</em>,
109496. (<a href="https://doi.org/10.1016/j.asoc.2022.109496">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fire detection in its early stages is of a great importance in different environmental related applications. Among the visual signs of fire, smoke appears earlier than the flames in many cases, and quickly reaches the environment. Thus, it can be used for early detection of fire using machine vision techniques. Existing approaches have tried to do it either by traditional machine learning methods applying various combinations of color, texture, and motion features, or by deep learning-based methods that can automatically capture the smoke features from images. However, the former approaches face number of challenges due to the transparent nature of smoke and its variant visual appearance in different environments, and the later ones are not able to capture motion characteristics of smoke, so, their efficiency in various environmental conditions is still problematic and often cause false alarms. In this study, we aim to introduce a hybrid approach that is based on deep learning , spatio, and spatio-temporal characteristics of the smoke. Doing so, we use all the strengths of these techniques to detect the smoke as accurately as possible. The proposed method consists of four stages: 1) moving pixels are extracted from input images by an efficient motion detection scheme; 2) the extracted moving areas are given individually to a tailored convolutional neural network to identify candidate smoke regions; 3) an efficient combination of spatial and spatio-temporal features is extracted from each candidate region based on the distinct characteristics of smoke; 4) a support vector machine classifier is used to further classify real smoke from non-smoke regions using the extracted features. The proposed method is implemented using Python programming language , and extensive experiments conducted on “Visor”, “Bilkent”, and “Yuan” benchmark datasets which show it has high performance and accuracy. The results also indicate that its reliability is far better than the competitors in terms of false alarm rate . The average accuracy and false positive rates obtained on 10 testing videos are 97.63\% and 3.8\%, respectively. Also, the proposed method is able to detect both white and black smokes which, to our best knowledge, has not been addressed in any of the related researches.},
  archive      = {J_ASOC},
  author       = {Mahdi Hashemzadeh and Nacer Farajzadeh and Milad Heydari},
  doi          = {10.1016/j.asoc.2022.109496},
  journal      = {Applied Soft Computing},
  pages        = {109496},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Smoke detection in video using convolutional neural networks and efficient spatio-temporal features},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Time series classification based on temporal features.
<em>ASOC</em>, <em>128</em>, 109494. (<a
href="https://doi.org/10.1016/j.asoc.2022.109494">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Along with the widespread application of Internet of things technology , time series classification have been becoming a research hotspot in the field of data mining for massive sensing devices generate time series all the time. However, how to accurately classify time series based on intuitively interpretable features is still a huge challenge. For this, we proposed a new Time Series Classification method based on Temporal Features (TSC-TF). TSC-TF firstly generates some temporal feature candidates through time series segmentation . And then, TSC-TF selects temporal feature according the importance measures with the help of a random forest . Finally, TSC-TF trains a fully convolutional network to obtain high accuracy. Experiments on various datasets from the UCR time series classification archive demonstrate the superiority of our method. Besides, we have released the codes and parameters to facilitate the community research.},
  archive      = {J_ASOC},
  author       = {Cun Ji and Mingsen Du and Yupeng Hu and Shijun Liu and Li Pan and Xiangwei Zheng},
  doi          = {10.1016/j.asoc.2022.109494},
  journal      = {Applied Soft Computing},
  pages        = {109494},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Time series classification based on temporal features},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spectral richness PSO algorithm for parameter identification
of dynamical systems under non-ideal excitation conditions.
<em>ASOC</em>, <em>128</em>, 109490. (<a
href="https://doi.org/10.1016/j.asoc.2022.109490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes a new Particle Swarm Optimization (PSO) algorithm specifically designed for parameter identification of physical systems. The key feature of the proposed algorithm is that it takes into consideration the Spectral Richness of the signal used for exciting the system during the identification procedure. The Spectral Richness is essentially the number of spectral lines in the Fast Fourier Transform of a signal, and if this number is large, the variability of the parameter estimates produced by well-known PSO algorithms is small. However, low values of Spectral Richness may cause large variability of the parameter estimates. The proposed approach, which is termed as the Spectral Richness Particle Swarm Optimization (SR-PSO) algorithm, reduces the variability of the parameter estimates when using an excitation signal with a low value of Spectral Richness compared with state-of-the-art PSO algorithms, and maintains the same performance if the Spectral Richness is high. In a first case study, a set of real-time experiments applying excitation signals with different levels of Spectral Richness have been performed on a servomechanism in order to obtain several data sets. The acquired data from each excitation signal has been used to perform a parameter identification process using various algorithms including the classic PSO, the Linear Variable Weight Particle Swarm Optimization (LVW-PSO), the Linear Variable Constriction Factor Particle Swarm Optimization (LVCF-PSO), the state-of-the-art Fractional Order Regulated Particle Swarm Optimization (FOR-PSO) and the proposed Spectral Richness Particle Swarm Optimization (SR-PSO). The pertinence of the parameter estimates is also evaluated by designing and experimentally applying a model-based feedback control to the servomechanism . The proposed SR-PSO algorithm is also tested in a thermoelectric cooler model using numerical simulations. It is shown that the values of the identified parameters heavily depends on the kind of excitation signal applied to this system.},
  archive      = {J_ASOC},
  author       = {Ricardo Cortez and Rubén Garrido and Efrén Mezura-Montes},
  doi          = {10.1016/j.asoc.2022.109490},
  journal      = {Applied Soft Computing},
  pages        = {109490},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Spectral richness PSO algorithm for parameter identification of dynamical systems under non-ideal excitation conditions},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Client selection based weighted federated few-shot learning.
<em>ASOC</em>, <em>128</em>, 109488. (<a
href="https://doi.org/10.1016/j.asoc.2022.109488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of technology, clients have a large amount of personal data. Human beings are paying more and more attention to the privacy and security of this part of data. Clients do not want to share private data, which directly leads to the existence of data islands. Especially in few-shot scenarios, due to the insufficient amount of personal data, constructing an effective few-shot model is difficult. To solve the above problems, we propose Federated Few-shot Learning (FedFSL) in this paper. We utilize Federated Learning (FedL) to ensure the privacy and security issues of joint training. Moreover, the global model obtained by FedL has the characteristics of universally applicable to all clients. That universality satisfies the scenario of universally applicable to all meta tasks in the few-shot meta-learning stage. What is more, to obtain a more effective global federated universal few-shot model, we respectively proposed Weighted FedL (WFedL) and Client Selection based FedL (CSFedL) strategies. WFedL takes into account the difference between clients performance when building the global model and assigns different weights to different clients. CSFedL considers the malicious participation of clients, and we propose an adaptive client selection strategy to mitigate the impact caused by malicious participation. Extensive federated experiments on CIFAR-10 and CIFAR-100 show the advantage of proposed WFedL, CSFedL and combined Client Selection based WFedL (CSWFedL). We further verify the performance improvement of FedFSL on miniImagenet and propose our overall framework Client Selection based WFedFSL (CSWFedFSL). The best performance of CSWFedFSL is higher than both the few-shot baseline and FedFSL, and CSWFedFSL protects clients data privacy in the few-shot scenario.},
  archive      = {J_ASOC},
  author       = {Xinlei Xu and Saisai Niu and Zhe Wang and Dongdong Li and Hai Yang and Wenli Du},
  doi          = {10.1016/j.asoc.2022.109488},
  journal      = {Applied Soft Computing},
  pages        = {109488},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Client selection based weighted federated few-shot learning},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An edge computing based anomaly detection method in IoT
industrial sustainability. <em>ASOC</em>, <em>128</em>, 109486. (<a
href="https://doi.org/10.1016/j.asoc.2022.109486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the evolving Internet of Things (IoT) technology has been widely used in various industrial scenarios, whereby massive sensor data involving both normal data and anomalous data are generated. However, the anomalies involved might have a great impact on the industrial sustainability. Actually, in most scenarios, it is of vital importance to detect the anomalies and processed accordingly in real time. In previous work, some methods, which analyze the collected industrial sensor data on cloud computing center to detect anomalies , casually increase both the transmission pressure of bandwidth and the computing pressure on cloud center. By contrast, some other methods based on edge computing detect anomalies on edge nodes, but they only take the anomalies of sensor data from single-source time series into account and ignore the correlation anomalies between the data from multi-source time series. In this paper, we first present an anomaly detection model in distributed edge computing . Then, the Edge Computing based Anomaly Detection Algorithm (ECADA), which can detect the anomalies from both single-source time series or multi-source time series is proposed. Finally, we conduct a series comparison experiments in order to demonstrate the effectiveness of the algorithm proposed in the paper. And the experimental results demonstrate that both the anomalies from single-source time series and the anomalies from multi-source time series can be accurately detected by the proposed algorithm. Specifically, it performs more efficient and effective when there exist the anomalies of new type.},
  archive      = {J_ASOC},
  author       = {Xiang Yu and Xianfei Yang and Qingji Tan and Chun Shan and Zhihan Lv},
  doi          = {10.1016/j.asoc.2022.109486},
  journal      = {Applied Soft Computing},
  pages        = {109486},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An edge computing based anomaly detection method in IoT industrial sustainability},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-robot cooperative exploration algorithm considering
working efficiency and working load. <em>ASOC</em>, <em>128</em>,
109482. (<a href="https://doi.org/10.1016/j.asoc.2022.109482">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cooperative exploration in unknown environment is a tough task for the multi-robot system. The imbalance of individual workload caused by the weak autonomous cooperation ability will affect the working efficiency of the multi-robot system. In this paper, a two-objective cooperative exploration algorithm (TOCEA) is proposed, where the working efficiency and working load at the individual and system levels are both considered. There are three parts in the proposed algorithm, namely, frontier detection, target point selection and exploration decision. First, based on the analysis of the frontier characteristics, the accumulation of local frontiers is used to replace the method of traversal search, which greatly improves the exploration efficiency. Second, each robot plays as an equal role to select their candidate target points from the individual level, and uses the maximum area criterion to select the final target points. Finally, the robot target points are clustered to reduce the repeated exploration of the robots, which is essential for reduce the path length and exploration time. Significantly, the whole exploration process is completely based on the autonomous cooperation of the robots. The experimental results performed on three different platforms illustrate that the TOCEA shows improvements in terms of working efficiency, cooperation performance and applicable fields.},
  archive      = {J_ASOC},
  author       = {Meng Zhao and Hui Lu and Shi Cheng and Siyi Yang and Yuhui Shi},
  doi          = {10.1016/j.asoc.2022.109482},
  journal      = {Applied Soft Computing},
  pages        = {109482},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-robot cooperative exploration algorithm considering working efficiency and working load},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). CRT-net: A generalized and scalable framework for the
computer-aided diagnosis of electrocardiogram signals. <em>ASOC</em>,
<em>128</em>, 109481. (<a
href="https://doi.org/10.1016/j.asoc.2022.109481">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrocardiogram (ECG) signals play critical roles in the clinical screening and diagnosis of many types of cardiovascular diseases. Despite the fact that deep neural networks have greatly facilitated the computer-aided diagnosis (CAD) in many clinical tasks, the variability and complexity of ECG in practical scenarios still pose significant challenges in diagnostic performance and clinical applications, especially under the current demand of medical cloud computing and remote diagnosis. In this paper, we propose a generalized and scalable framework for the clinical recognition of ECG. Considering the fact that hospitals generally record ECG signals in the form of graphic waves of 2-D images, we first extract the graphic waves of 12-lead images into numerical 1-D ECG signals by a proposed bi-directional connected method. Subsequently, a novel deep neural network, named CRT-Net, is designed to explore waveform features, morphological characteristics, and time-domain features of ECG by embedding convolution neural network (CNN), recurrent neural network (RNN), and transformer module in a scalable deep model, which is especially suitable in clinical scenarios with different lengths of ECG signals captured from different devices. The proposed framework is first evaluated on two widely investigated public repositories, demonstrating superior performance to the state-of-the-art. We also evaluate the effectiveness of the developed framework on clinically collected ECG images from a local hospital. Moreover, based on the proposed algorithms, we have developed a cloud-based ECG system for the computer-aided diagnosis of different cardiovascular diseases.},
  archive      = {J_ASOC},
  author       = {Jingyi Liu and Zhongyu Li and Xiayue Fan and Xuemeng Hu and Jintao Yan and Bolin Li and Qing Xia and Jihua Zhu and Yue Wu},
  doi          = {10.1016/j.asoc.2022.109481},
  journal      = {Applied Soft Computing},
  pages        = {109481},
  shortjournal = {Appl. Soft. Comput.},
  title        = {CRT-net: A generalized and scalable framework for the computer-aided diagnosis of electrocardiogram signals},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Maximum number of generations as a stopping criterion
considered harmful. <em>ASOC</em>, <em>128</em>, 109478. (<a
href="https://doi.org/10.1016/j.asoc.2022.109478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary algorithms have been shown to be very effective in solving complex optimization problems . This has driven the research community in the development of novel, even more efficient evolutionary algorithms. The newly proposed algorithms need to be evaluated and compared with existing state-of-the-art algorithms, usually by employing benchmarks. However, comparing evolutionary algorithms is a complicated task, which involves many factors that must be considered to ensure a fair and unbiased comparison. In this paper, we focus on the impact of stopping criteria in the comparison process. Their job is to stop the algorithms in such a way that each algorithm has a fair opportunity to solve the problem. Although they are not given much attention, they play a vital role in the comparison process. In the paper, we compared different stopping criteria with different settings, to show their impact on the comparison results. The results show that stopping criteria play a vital role in the comparison, as they can produce statistically significant differences in the rankings of evolutionary algorithms. The experiments have shown that in one case an algorithm consumed 50 times more evaluations in a single generation, giving it a considerable advantage when max gen was used as the stopping criterion, which puts the validity of most published work in question.},
  archive      = {J_ASOC},
  author       = {Miha Ravber and Shih-Hsi Liu and Marjan Mernik and Matej Črepinšek},
  doi          = {10.1016/j.asoc.2022.109478},
  journal      = {Applied Soft Computing},
  pages        = {109478},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Maximum number of generations as a stopping criterion considered harmful},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A methodology for dam parameter identification combining
machine learning, multi-objective optimization and multiple decision
criteria. <em>ASOC</em>, <em>128</em>, 109476. (<a
href="https://doi.org/10.1016/j.asoc.2022.109476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physical and mechanical parameter identification could provide useful information for dam health monitoring. Traditional methods for parameter identification commonly use subjective weights to convert multi-objective problems into single-objective problems, which may result in unreasonable identification results. In recent years, multi-objective optimization algorithms have been applied to avoid introduction of subjective weights in parameter identification. Since multi-objective optimization algorithms produce a massive number of Pareto solutions , how to select acceptable parameters from the Pareto solutions is an intractable problem, and effective decision criteria for selecting acceptable solutions is required. In this paper, a methodology combining machine learning , multi-objective optimization, and multiple decision criteria is proposed to effectively improve efficiency and credibility of parameter identification for dams. A surrogate model constructed using the Support Vector Machine (SVM) based on grid search and cross-validation is employed to replace time-consuming finite element calculations in the process of parameter identification. Multiple decision criteria incorporating influencing factors of parameter identification (such as the membership degree of identified parameters with respect to designed ones, fitting error of monitoring data, and the degree of overfitting) are devised to compare Pareto solutions derived from multi-objective optimization and determine the optimal one. Parameter identification of an actual gravity dam is implemented to illustrate and verify the proposed methodology. It is shown that the results yielded with the proposed methodology are superior to those produced by traditional methods in terms of robustness of reasonable parameter identification, prediction accuracy of monitoring data, and reasonable physical meaning of material parameters.},
  archive      = {J_ASOC},
  author       = {Weiye Li and Zhenyu Wu},
  doi          = {10.1016/j.asoc.2022.109476},
  journal      = {Applied Soft Computing},
  pages        = {109476},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A methodology for dam parameter identification combining machine learning, multi-objective optimization and multiple decision criteria},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimal inspection and advance payment policy for
deteriorating items using differential evolution metaheuristic.
<em>ASOC</em>, <em>128</em>, 109475. (<a
href="https://doi.org/10.1016/j.asoc.2022.109475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The deterioration of items such as fruits, eatables, etc. may influence the adjacent units and intercept the supply. In many circumstances, the existence of a spoiled unit accelerates the deterioration process. The degradation effect can be mitigated by removing the affected unit. This research investigation explores an impact of frequent inspection on the spoiling items in an inventory system and can be used as a step forward to reduce food wastage due to mutual spoilage. In many business transactions, the retailer has the ability to make judgments regarding advance payment. The present work attempts to develop a lot-sizing model for price-sensitive demand under the premise of partial advance payment and deterioration rate as a function of inspection frequency. We suggest an optimal prepayment strategy from the retailer’s point of view. A mixed-integer programming problem is formulated and solved by using a genetic algorithm (GA) and differential evolution (DE) algorithm based on different mutation strategies. It is established that DE performs better in comparison to GA. Based on some statistical measures, we have selected the mutation scheme which is most suitable for the proposed problem. The inventory-related measures are established for the proposed problem and used to present a numerical simulation and optimal inventory policy. The numerical findings show that the ideal inspection and prepayment strategy boost profitability by reducing spoilage. The managerial insights are discussed that may be beneficial in decision-making for inspection and advance payment.},
  archive      = {J_ASOC},
  author       = {Madhu Jain and Praveendra Singh},
  doi          = {10.1016/j.asoc.2022.109475},
  journal      = {Applied Soft Computing},
  pages        = {109475},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Optimal inspection and advance payment policy for deteriorating items using differential evolution metaheuristic},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Security-constrained optimal placement of PMUs using crow
search algorithm. <em>ASOC</em>, <em>128</em>, 109472. (<a
href="https://doi.org/10.1016/j.asoc.2022.109472">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For precise power system monitoring , a major focus is on involvement of the latest technology based on phasor measurement units (PMUs). As the sole system monitor, state estimator plays an important role in the security of power system operations . Optimal placement of PMUs (OPP) with numerical observability ensures reliable state estimation. For economical and efficient utilization, there is a need to optimize the placement of PMUs in the power system network. A new approach called Crow Search Algorithm (CSA) devised by others, has been used to solve an OPP problem. The performance of this new approach is compared to the dominant method for an optimization problem — binary integer linear programming (BILP). Comparison studies have also been carried out with particle swarm optimization (PSO) method. The major constraints such as topological, numerical observability conditions with and without zero-injection buses (ZIBs) are considered. Contingencies and limitation of measurement channels in a PMU device are also incorporated as constraints. The main advantage of using the CSA is that it provides multiple location sets for same optimal number of PMUs (optimal number same as obtained by BILP). While BILP method provides only one set of locations for the optimal number of PMUs obtained. This becomes advantageous in planning stage for power engineers for placing PMUs. Test systems considered for the case studies are of varied sizes such as IEEE 14-bus, IEEE 30-bus, IEEE 57-bus and 72-bus practical equivalent system of Indian southern region power grid.},
  archive      = {J_ASOC},
  author       = {Teena Johnson and Tukaram Moger},
  doi          = {10.1016/j.asoc.2022.109472},
  journal      = {Applied Soft Computing},
  pages        = {109472},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Security-constrained optimal placement of PMUs using crow search algorithm},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Application of multilayer perceptron with data augmentation
in nuclear physics. <em>ASOC</em>, <em>128</em>, 109470. (<a
href="https://doi.org/10.1016/j.asoc.2022.109470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks have become popular in many fields of science since they serve as promising, reliable and powerful tools. In this work, we study the effect of data augmentation on the predictive power of neural network models for nuclear physics data. We present two different data augmentation techniques, and we conduct a detailed analysis in terms of different depths, optimizers, activation functions and random seed values to show the success and robustness of the model. Using the experimental uncertainties for data augmentation for the first time, the size of the training data set is artificially boosted and the changes in the root-mean-square error between the model predictions on the test set and the experimental data are investigated. Our results show that the data augmentation decreases the prediction errors, stabilizes the model and prevents overfitting. The extrapolation capabilities of the MLP models are also tested for newly measured nuclei in AME2020 mass table, and it is shown that the predictions are significantly improved by using data augmentation.},
  archive      = {J_ASOC},
  author       = {Hüseyin Bahtiyar and Derya Soydaner and Esra Yüksel},
  doi          = {10.1016/j.asoc.2022.109470},
  journal      = {Applied Soft Computing},
  pages        = {109470},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Application of multilayer perceptron with data augmentation in nuclear physics},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hierarchical tri-level optimization model for effective use
of by-products in a sugarcane supply chain network. <em>ASOC</em>,
<em>128</em>, 109468. (<a
href="https://doi.org/10.1016/j.asoc.2022.109468">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing a solution algorithm for tri-level facility location–allocation problem is always challenging due to the inherent complexity of these problems. The proposed sugarcane supply chain network is a tri-level modeling approach formulated based on the static Stackelberg game between producer, distribution center, sugarcane industry, compost unit, biorefinery unit and market in the framework. The network emphasizes the use of massive amount of the by-products generated in the sugarcane industry. These by-products are excellent raw materials for compost unit and biorefinery units. In such cases decisions are made in the hierarchy. By reviewing the proposed algorithms in the past, it has been realized that the shortcomings of the algorithm could be improved by introducing some efficient search mechanism in the algorithms. In this context, a strong local search mechanism based on social engineering optimizer is developed to intensify search space more carefully. Two-hybrid algorithms, GASEO based on Genetic algorithm and social engineering optimizer, and KASEO based on Keshtel algorithm and social engineering optimizer is proposed. To appraise the performance of the proposed algorithm, we pervasively discussed the parameter tuning using Taguchi approach. The ANOVA and Tukey post-hoc test ensures that the performance of the proposed GASEO is appreciable over other algorithms.},
  archive      = {J_ASOC},
  author       = {Vivek Kumar Chouhan and Shahul Hamid Khan and Mostafa Hajiaghaei-Keshteli},
  doi          = {10.1016/j.asoc.2022.109468},
  journal      = {Applied Soft Computing},
  pages        = {109468},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Hierarchical tri-level optimization model for effective use of by-products in a sugarcane supply chain network},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Incremental non-dominated sorting algorithms based on
irreducible domination graphs. <em>ASOC</em>, <em>128</em>, 109466. (<a
href="https://doi.org/10.1016/j.asoc.2022.109466">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-Dominated Sorting process, NDS, plays an important role in Pareto based Evolutionary Multi-Objective Optimization Algorithms and it is one of the most time consuming tasks, mainly when steady-state Evolutionary Algorithms are considered, i.e. algorithms in which the updating of the Pareto layers must be accomplished every time a new solution is generated. In this paper we present a general framework to carry out the NDS process and three implementations based on a modification of the Irreducible Domination Graph structure, I D G IDG , presented in Alberto and Mateo (2004) for accomplishing this task. The proposed algorithms are compared with other NDS algorithms designed specifically for the incremental update of the Pareto layers. The experiments carried out show that the proposed algorithms reduce, in general, the time needed as well as the number of Pareto comparisons when compared with the competitors.},
  archive      = {J_ASOC},
  author       = {P.M. Mateo and D. Lahoz and I. Alberto},
  doi          = {10.1016/j.asoc.2022.109466},
  journal      = {Applied Soft Computing},
  pages        = {109466},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Incremental non-dominated sorting algorithms based on irreducible domination graphs},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An adaptive and altruistic PSO-based deep feature selection
method for pneumonia detection from chest x-rays. <em>ASOC</em>,
<em>128</em>, 109464. (<a
href="https://doi.org/10.1016/j.asoc.2022.109464">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pneumonia is one of the major reasons for child mortality especially in income-deprived regions of the world. Although it can be detected and treated with very less sophisticated instruments and medication, Pneumonia detection still remains a major concern in developing countries. Computer-aided based diagnosis (CAD) systems can be used in such countries due to their lower operating costs than professional medical experts. In this paper, we propose a CAD system for Pneumonia detection from Chest X-rays, using the concepts of deep learning and a meta-heuristic algorithm. We first extract deep features from the pre-trained ResNet50, fine-tuned on a target Pneumonia dataset. Then, we propose a feature selection technique based on particle swarm optimization (PSO), which is modified using a memory-based adaptation parameter, and enriched by incorporating an altruistic behavior into the agents. We name our feature selection method as adaptive and altruistic PSO (AAPSO). The proposed method successfully eliminates non-informative features obtained from the ResNet50 model, thereby improving the Pneumonia detection ability of the overall framework. Extensive experimentation and thorough analysis on a publicly available Pneumonia dataset establish the superiority of the proposed method over several other frameworks used for Pneumonia detection. Apart from Pneumonia detection, AAPSO is further evaluated on some standard UCI datasets, gene expression datasets for cancer prediction and a COVID-19 prediction dataset. The overall results are satisfactory, thereby confirming the usefulness of AAPSO in dealing with varied real-life problems. The supporting source codes of this work can be found at https://github.com/rishavpramanik/AAPSO .},
  archive      = {J_ASOC},
  author       = {Rishav Pramanik and Sourodip Sarkar and Ram Sarkar},
  doi          = {10.1016/j.asoc.2022.109464},
  journal      = {Applied Soft Computing},
  pages        = {109464},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An adaptive and altruistic PSO-based deep feature selection method for pneumonia detection from chest X-rays},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Classification of diabetic retinopathy with feature
selection over deep features using nature-inspired wrapper methods.
<em>ASOC</em>, <em>128</em>, 109462. (<a
href="https://doi.org/10.1016/j.asoc.2022.109462">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic retinopathy (DR) is the most common cause of blindness in middle-aged people. It shows that an automatic image evaluation system is needed in the diagnosis of this disease due to the low number of scans. It is critical to meet this need that these systems are large-scale, cost-effective, and minimally invasive screening programs. With the use of deep learning techniques, it has become possible to develop these systems faster. In this study, a new approach based on feature selection with wrapper methods used for fundus images is presented that can be used for the classification of diabetic retinopathy. The fundus images used in the approach were improved with image processing techniques, thus eliminating unnecessary dark areas in the image. In this new approach, the most effective features are selected by wrapping methods over 512 deep features obtained from EfficientNet and DenseNet models. Binary Bat Algorithm (BBA), Equilibrium Optimizer (EO), Gravity Search Algorithm (GSA), and Gray Wolf Optimizer (GWO) were chosen as wrappers for the proposed approach. Selected features are classified by support vector machines and random forest machine learning methods. Considering the performance of this new approach, it gives the highest value of 96.32 accuracy and 0.98 kappa. These performance values were obtained with a minimum of 250 selected features. The Asia Pacific Tele-Ophthalmology Society (APTOS) dataset used to obtain these values was taken from a competition organized by Kaggle. The highest kappa value in this competition was reported as 0.93. This parameter clearly demonstrates the success of our approach.},
  archive      = {J_ASOC},
  author       = {Murat Canayaz},
  doi          = {10.1016/j.asoc.2022.109462},
  journal      = {Applied Soft Computing},
  pages        = {109462},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Classification of diabetic retinopathy with feature selection over deep features using nature-inspired wrapper methods},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel artificial neural network improves multivariate
feature extraction in predicting correlated multivariate time series.
<em>ASOC</em>, <em>128</em>, 109460. (<a
href="https://doi.org/10.1016/j.asoc.2022.109460">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing multivariate time series prediction schemes are inefficient in extracting intermediate features. This paper proposes an artificial neural network called Feature Path Efficient Multivariate Time Series Prediction (FPEMTSP) to predict the next element of the main time series in the presence of several secondary time series. We propose to generate all the possible combinations of the secondary time series and extract multivariate features by doing the Cartesian product of the main and the secondary time series features. Our calculations prove that the FPEMTSP’s complexity and network size are acceptable. We have considered a few internal parameters in FPEMTSP that can be configured to improve the prediction accuracy and adjust the network size. We trained and evaluated FPEMTSP using two public datasets. Our evaluation revealed the optimal values for the internal parameters and showed that FPEMTSP surpasses the existing schemes in terms of prediction accuracy and the number of correctly predicted steps.},
  archive      = {J_ASOC},
  author       = {Parinaz Eskandarian and Jamshid Bagherzadeh Mohasefi and Habibollah Pirnejad and Zahra Niazkhani},
  doi          = {10.1016/j.asoc.2022.109460},
  journal      = {Applied Soft Computing},
  pages        = {109460},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A novel artificial neural network improves multivariate feature extraction in predicting correlated multivariate time series},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Broad fuzzy cognitive map systems for time series
classification. <em>ASOC</em>, <em>128</em>, 109458. (<a
href="https://doi.org/10.1016/j.asoc.2022.109458">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series classification (TSC) is a crucial and challenging problem in sequential analysis. However, most of the existing best-performing methods are time-consuming, even if coping with small-scale datasets. Broad learning systems (BLS) have shown low time complexity and high accuracy in handling various tasks and have been applied to many fields. However, none of the BLS-based methods is suitable to tackle TSC due to (1) unsuitable structure in capturing temporal information of time series; (2) low interpretability in representing the evolving relations among states along time. Thus, this paper develops a broad fuzzy cognitive map system (BFCMS) to address time series classification efficiently, which consists of the sparse autoencoder (SAE) based feature extraction block, the high-order fuzzy cognitive map (HFCM) based spatiotemporal information aggregation block, and one multilayer perceptron (MLP) based prediction layer. The feature extraction block is designed to capture the underlying core evolving patterns, and the spatiotemporal information aggregation block is developed to model the underlying causal relationships and contextual dependencies. These two blocks are designed to overcome the limitations of BLS. MLP is applied to map the feature representation to the label of time series based on the aggregated feature representations from these two blocks. In addition, BFCMS develops three incremental learning strategies for fast updating in broad expansion without a retraining procedure if the model deems to be expanded. We compared BFCMS with other state-of-the-art baselines on 26 datasets. The experimental results demonstrate the superiority of BFCMS. Concretely, BFCMS achieves a lower training cost with on-par classification accuracy .},
  archive      = {J_ASOC},
  author       = {Kai Wu and Kaixin Yuan and Yingzhi Teng and Jing Liu and Licheng Jiao},
  doi          = {10.1016/j.asoc.2022.109458},
  journal      = {Applied Soft Computing},
  pages        = {109458},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Broad fuzzy cognitive map systems for time series classification},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). An anti-attack method for emotion categorization from
images. <em>ASOC</em>, <em>128</em>, 109456. (<a
href="https://doi.org/10.1016/j.asoc.2022.109456">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion categorization has become an important area of research due to the increasing number of intelligent systems, such as robots interacting with humans. This includes deep learning models, which have performed remarkably well on many classification-based tasks. However, due to their homogeneous representation of knowledge, the deep learning models are vulnerable to different kinds of attacks. The hypothesis is that emotions displayed in facial images are more than patterns of pixels. Thus, the objective of this work is to propose a novel heterogeneous facial landmark-based emotion categorization (LEmo) method that will show robustness to distractor and adversarial attacks . Moreover, we compared the proposed LEmo method with seven state-of-the-art methods, including neural networks , (i.e. the residual neural network (ResNet), the Visual Geometry Group (VGG), and the Inception-ResNet models), emotion categorization tools (i.e. Py-Feat and LightFace), as well as anti-attack-based methods (i.e. Adv-Network and DLP-CNN). To test the robustness of the LEmo method, three different types of adversarial attacks, and a distractor attack were launched at the data. Unlike other methods that have exhibited large performance decreases (up to 79\%), the LEmo method was strongly resistant to all attacks, achieving high accuracy with only little ( &amp;lt; 9.3\%) or no decrease with different changes made to the images of CK+ and the KDEF databases. Furthermore, the LEmo method has shown a considerably lower execution time compared to all other methods.},
  archive      = {J_ASOC},
  author       = {Harisu Abdullahi Shehu and Will N. Browne and Hedwig Eisenbarth},
  doi          = {10.1016/j.asoc.2022.109456},
  journal      = {Applied Soft Computing},
  pages        = {109456},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An anti-attack method for emotion categorization from images},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Growing deep echo state network with supervised learning for
time series prediction. <em>ASOC</em>, <em>128</em>, 109454. (<a
href="https://doi.org/10.1016/j.asoc.2022.109454">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multilayer echo state networks (ESNs) are powerful on learning hierarchical temporal representation. However, how to determine the depth of multilayer ESNs is still an open issue. In this paper, we propose a novel approach to automatically determine the depth of a multilayer ESN, named growing deep ESN (GD-ESN). First, an incremental hierarchical structure is proposed, where the recurrent layers and the pre-trained feedforward layers are alternately added to the network one by one. Then, a control scheme is designed for the growth of the network based on the newly defined averaged mutual information and the full rank criterion. Finally, the proposed GD-ESN is evaluated on both benchmark datasets and real-world applications. The experimental results show the effectiveness of the proposed method.},
  archive      = {J_ASOC},
  author       = {Ying Li and Fanjun Li},
  doi          = {10.1016/j.asoc.2022.109454},
  journal      = {Applied Soft Computing},
  pages        = {109454},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Growing deep echo state network with supervised learning for time series prediction},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MAB-OS: Multi-armed bandits metaheuristic optimizer
selection. <em>ASOC</em>, <em>128</em>, 109452. (<a
href="https://doi.org/10.1016/j.asoc.2022.109452">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristic algorithms are derivative-free optimizers designed to estimate the global optima for optimization problems . Keeping balance between exploitation and exploration and the performance complementarity between the algorithms have led to the introduction of quite a few metaheuristic methods. In this work, we propose a framework based on Multi-Armed Bandits (MAB) problem, which is a classical Reinforcement Learning (RL) method, to intelligently select a suitable optimizer for each optimization problem during the optimization process. This online algorithm selection technique leverages on the convergence behavior of the algorithms to find the right balance of exploration–exploitation by choosing the update rule of the algorithm with the most estimated improvement in the solution. By performing experiments with three armed-bandits being Harris Hawks Optimizer (HHO), Differential Evolution (DE), and Whale Optimization Algorithm (WOA), we show that the MAB Optimizer Selection (named as MAB-OS) framework has the best overall performance on different types of fitness landscapes in terms of both convergence rate and the final solution. The data and codes used for this work are available at: https://github.com/BaratiLab/MAB-OS .},
  archive      = {J_ASOC},
  author       = {Kazem Meidani and Seyedali Mirjalili and Amir Barati Farimani},
  doi          = {10.1016/j.asoc.2022.109452},
  journal      = {Applied Soft Computing},
  pages        = {109452},
  shortjournal = {Appl. Soft. Comput.},
  title        = {MAB-OS: Multi-armed bandits metaheuristic optimizer selection},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reinforcement learning based adaptive PID controller design
for control of linear/nonlinear unstable processes. <em>ASOC</em>,
<em>128</em>, 109450. (<a
href="https://doi.org/10.1016/j.asoc.2022.109450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Control of unstable process is challenging owing to its dynamic nature, output multiplicities and stability issues. This research work focuses to develop a generic data driven modified Proximal Policy Optimization (m-PPO) reinforcement learning based adaptive PID controller (RL-PID) for the control of open loop unstable processes. The RL agent acting as the supervisor explores and identifies optimal gains for the PID controller to ensure desired servo and regulatory performance. Adaptive modifications in terms of inclusion of action repeat, modified reward function and early stopping criterion are incorporated to the m-PPO algorithm to handle the unbounded output nature of unstable processes. Effect of m-PPO algorithm is proven in terms of reward earned by the RL agent. Servo and regulatory performance of the proposed RL-PID controller is compared with that of classical PID controller, Deep Discriminant Policy Gradient based PID controller and Advantage Actor Critic based PID controller on various linear, non linear, multivariable unstable systems including unstable jacketed CSTR process and Unmanned Aerial Vehicle in simulation environment. Validation of the proposed controller is also done in real time level control process station, a laboratory level experimental test rig . It is observed that the proposed RL-PID performs satisfactorily better than the other controllers in both qualitative and quantitative metrics. The striking feature of this control scheme is that it eliminates the need of process modeling and pre-requisite knowledge on process dynamics and controller tuning . The proposed controller is a data driven generic approach that can be directly applied to any industrial process.},
  archive      = {J_ASOC},
  author       = {T. Shuprajhaa and Shiva Kanth Sujit and K. Srinivasan},
  doi          = {10.1016/j.asoc.2022.109450},
  journal      = {Applied Soft Computing},
  pages        = {109450},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Reinforcement learning based adaptive PID controller design for control of linear/nonlinear unstable processes},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Solving the number of cross-dock open doors optimization
problem by combination of NSGA-II and multi-objective simulated
annealing. <em>ASOC</em>, <em>128</em>, 109448. (<a
href="https://doi.org/10.1016/j.asoc.2022.109448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chain stores use cross-dock to deliver goods to their branches by outbound trucks. Considering that the total demand of each branch is less than the truck capacity, a vehicle routing problem (VRP) is employed for the cross-dock. Although the number of cross-dock doors is constant, that of open outbound doors can affect the cross-dock performance. In this paper, new multi-objective scheduling and VRP is presented for cross-dock that simultaneously determines the routing, sequencing, and scheduling of the unloading operation of outbound trucks and the number of outbound open doors. Given that there is an NP-hard problem, four metaheuristic algorithms are proposed, and non-dominated sorting genetic algorithm-II and multi-objective simulated annealing are combined in two ways to solve the problem.},
  archive      = {J_ASOC},
  author       = {Arash Motaghedi-Larijani},
  doi          = {10.1016/j.asoc.2022.109448},
  journal      = {Applied Soft Computing},
  pages        = {109448},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Solving the number of cross-dock open doors optimization problem by combination of NSGA-II and multi-objective simulated annealing},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Perception-guided generative adversarial network for
end-to-end speech enhancement. <em>ASOC</em>, <em>128</em>, 109446. (<a
href="https://doi.org/10.1016/j.asoc.2022.109446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single channel speech enhancement has reached a great progress recently with the development of deep learning . However, it is still a challenging problem to achieve promising performance on unseen noisy conditions. The introduction of generative adversarial networks (GAN) could be helpful to alleviate the mismatch between seen training conditions and unseen testing conditions, where the generator performs as a speech denoiser to produce cleaned speech to fool the clean/noisy discriminator . In GAN, the design of the discriminator plays an important role to guide the generator towards an adequate goal. In this paper, we improve the well-known time domain framework, Speech Enhancement GAN (SEGAN), by introducing a perception-guided discriminator. The discriminator is able to quantitatively evaluate the quality of speech to be strongly related to human listening. New adversarial structures and training recipe have been proposed, studied and evaluated on the widely used dataset composed of the voice bank corpus and the DEMAND dataset. Experimental results show the superiority of our method with respect to the state-of-the-art baselines on obtaining higher or competitive scores of commonly used metrics of speech enhancement (STOI = = 0.944, SSNR = = 12.20, CSIG = = 3.99, CBAK = = 3.59, PESQ = = 2.81, and CVOL = = 3.36).},
  archive      = {J_ASOC},
  author       = {Yihao Li and Meng Sun and Xiongwei Zhang},
  doi          = {10.1016/j.asoc.2022.109446},
  journal      = {Applied Soft Computing},
  pages        = {109446},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Perception-guided generative adversarial network for end-to-end speech enhancement},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Simultaneous optimization of cluster head selection and
inter-cluster routing in wireless sensor networks using a 2-level
genetic algorithm. <em>ASOC</em>, <em>128</em>, 109444. (<a
href="https://doi.org/10.1016/j.asoc.2022.109444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In cluster-based sensor networks, at each cluster, sensor nodes send the collected data to a cluster head which aggregates and forwards them to a sink node. Data transmission from a cluster head to the sink node can be done in a multi-hop fashion through other cluster heads. Hence, two problems need to be addressed in this regard: Selection of cluster heads, and optimal multi-hop routing. In previous studies, these two problems have been solved separately in two independent phases. This paper proposes a novel approach to solve them simultaneously in order to increase the network lifetime. In the proposed scheme, the cluster head’s role in transmitting the inter-cluster traffic is considered during the cluster head selection process. In other words, cluster heads are selected in a way which reduces the energy consumption for transmitting data from a cluster head to the sink node. To achieve this goal, the genetic algorithm is used in two levels. The first-level genetic algorithm selects the cluster heads while the second-level one considers multi-hop routing among them. Simulation of the proposed method and comparison of its results with three previously proposed schemes which solve the problems separately indicate the superiority of the proposed optimization scheme in improving the lifetime of the network.},
  archive      = {J_ASOC},
  author       = {Marjan Kaedi and Ali Bohlooli and Rambod Pakrooh},
  doi          = {10.1016/j.asoc.2022.109444},
  journal      = {Applied Soft Computing},
  pages        = {109444},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Simultaneous optimization of cluster head selection and inter-cluster routing in wireless sensor networks using a 2-level genetic algorithm},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel intelligent technique for energy management in smart
home using internet of things. <em>ASOC</em>, <em>128</em>, 109442. (<a
href="https://doi.org/10.1016/j.asoc.2022.109442">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This manuscript proposes a hybrid method for energy management system (EMS) in smart home using internet of things (IoT). The proposed hybrid method is hybrid wrapper of both Sailfish Optimizer (SFO) and Adaptive Neuro-Fuzzy Interference System (ANFIS). Commonly called as SFOANFIS method. The proposed method optimally manages the power and resources of distribution system (DS). In the proposed method, every household appliance are connected with cloud internet of things has particular internet protocol (IP) addresses, for reducing the growth of demand response (DR) in home EMS (HEMS), the internet of things based communication system is used in DS. From every household appliance, the centralized server collects the gathered demand response data. The collected data is managed by SFOANFIS method. Similarly, the DS based internet of things increases the flexibility of these networks provides the optimal use of presented resources. Then, the proposed method fulfils the overall supply and energy demand. The performance of proposed method is implemented on MATLAB site and compared with different existing algorithms like ANFIS and advanced salp swam optimization algorithm (ANFASO), Sailfish Optimizer, squirrel optimization with gravitational search-aided​ neural network (SOGSNN) methods.},
  archive      = {J_ASOC},
  author       = {P. Rajesh and Francis H Shajin and G. Kannayeram},
  doi          = {10.1016/j.asoc.2022.109442},
  journal      = {Applied Soft Computing},
  pages        = {109442},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A novel intelligent technique for energy management in smart home using internet of things},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-objective quantum-inspired genetic algorithm for
workflow healthcare application scheduling with hard and soft deadline
constraints in hybrid clouds. <em>ASOC</em>, <em>128</em>, 109440. (<a
href="https://doi.org/10.1016/j.asoc.2022.109440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the use of quantum cloud computing for different applications has been increasing. For instance, weather forecasting, financial modeling, healthcare, and automation are geographically distributed in practice. These applications are workflows and consist of compute-intensive dependent tasks with precedence constraints. However, workflow processing on quantum-based cloud services still faces issues in the literature regarding makespan and energy consumption. This study presents the Multi-objective Quantum-inspired Genetic Algorithm (MQGA) to address the problems of workflow scheduling in the hybrid cloud , attempting to reduce makespan and energy consumption simultaneously. The proposed algorithm relies on the concept and principle of quantum mechanics, which explores the computational power of quantum computing . It adopted a qubit to represent the individual chromosome for better population diversity. It also uses a quantum rotation gate to lead the schedule to better convergence and avoids classical genetic operators. The simulation results show that the proposed algorithm can effectively reduce energy consumption by 23.36\% and makespan 20\% on average.},
  archive      = {J_ASOC},
  author       = {Mehboob Hussain and Lian-Fu Wei and Fakhar Abbas and Amir Rehman and Muqadar Ali and Abdullah Lakhan},
  doi          = {10.1016/j.asoc.2022.109440},
  journal      = {Applied Soft Computing},
  pages        = {109440},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-objective quantum-inspired genetic algorithm for workflow healthcare application scheduling with hard and soft deadline constraints in hybrid clouds},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Metapath and syntax-aware heterogeneous subgraph neural
networks for spam review detection. <em>ASOC</em>, <em>128</em>, 109438.
(<a href="https://doi.org/10.1016/j.asoc.2022.109438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spam Review Detection is a subclass of text classification that aims to distinguish genuine reviews from spam reviews (e.g., irrelevant reviews, deceptive reviews, machine-generated reviews, and non-review messages). Previous studies have focused on review text analysis, abnormal behavior detection, and intrinsic relationship identification. However, these methods ignore different fraudulent camouflages and writing styles. In this paper, we instead design a Spam detection model M etapath-based S ubgraph A ggregated N eural N etwork ( Spam-MSANN ) integrating three metapath-based subgraphs (i.e. User-Item Subgraph, Review Subgraph, and User-Review-Item Subgraph) and syntactic information to enhance the relevant representation of the review information with subgraph aggregation operations. Experimental results on benchmarking datasets (i.e. YelpCHI and Amazon) demonstrate that our Spam-MSANN model significantly improves the state-of-the-art models. Specifically, Spam-MSANN outperforms 11 of the 12 advanced benchmark models on these two datasets, which further manifests that the fusion of different metapath-based subgraphs and syntactic information is adequate for the spam review detection task.},
  archive      = {J_ASOC},
  author       = {Zhiqiang Zhang and Yuhang Dong and Haiyan Wu and Haiyu Song and Shengchun Deng and Yanhong Chen},
  doi          = {10.1016/j.asoc.2022.109438},
  journal      = {Applied Soft Computing},
  pages        = {109438},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Metapath and syntax-aware heterogeneous subgraph neural networks for spam review detection},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Uncertainty awareness in transmission line fault analysis: A
deep learning based approach. <em>ASOC</em>, <em>128</em>, 109437. (<a
href="https://doi.org/10.1016/j.asoc.2022.109437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the expansion of the modern power system , it is of increasing significance to analyze the faults in the transmission lines. As the transmission line is the most exposed element of a power system , it is prone to different types of environmental as well as measurement uncertainties. This uncertainties influence the sampled signals and negatively affects the fault detection and classification performance. Therefore, an unsupervised deep learning framework named deep belief network is presented in this paper for fault detection and classification of power transmission lines . The proposed framework learns the beneficial feature information from the uncertainty affected signals with a unique two stage learning strategy. This strategy enables the proposed framework to extract lower level fault-oriented information which may remain unobserved for other alternative approaches. The efficacy of the proposed framework has been examined on the IEEE-39 bus benchmark topology. The in-depth accuracy assessment with different accuracy metrics along with exclusive case studies such as the influence of noise, measurement error as well as line and source parameter variations will be conducted in this paper to justify the real-world applicability of the proposed framework. Furthermore, the relative performance assessment with the cutting-edge rival techniques is also presented in this paper to verify if the proposed framework attains a state-of-the-art classification performance or not.},
  archive      = {J_ASOC},
  author       = {Shahriar Rahman Fahim and S M Muyeen and Mohammad Abdul Mannan and Subrata K. Sarker and Sajal K. Das and Nasser Al-Emadi},
  doi          = {10.1016/j.asoc.2022.109437},
  journal      = {Applied Soft Computing},
  pages        = {109437},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Uncertainty awareness in transmission line fault analysis: A deep learning based approach},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The effect of different sampling method integrated in NSGA
II optimization on performance and emission of diesel/hydrogen dual-fuel
CI engine. <em>ASOC</em>, <em>128</em>, 109434. (<a
href="https://doi.org/10.1016/j.asoc.2022.109434">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in computational tools and techniques have enabled engineers to tackle single-step and iterative complex computer-aided engineering (CAE) problems. They have also helped develop CAE optimization techniques capable of driving design parameters towards regions where selected system characteristics can be further improved. The present work was conducted in two steps; In the first step, the effects of adding hydrogen to diesel fuel in a turbocharged direct injection (TDI) compression ignition (CI) Audi engine was analyzed through 1D simulation in AVL BOOST. With no significant modifications to the engine, the analysis was carried out at 1900 rpm and 2500 rpm under 0.8 MPa nominal loading conditions. Hydrogen was injected with air at 30 L/min through the intake manifold before the turbocharger . The present work considered all the engine components that are thermodynamically involved in the combustion process . The second analysis step coupled the simulated model with modeFRONTIER to study the optimum parameter values for engine performance and emission and determined the effects of various input variables on these parameters. Optimization was carried out by adopting hybrid algorithms to design experiments and the non-dominated sorting genetic algorithm II (NSGA_II). The response level predictive capability of the Taguchi and SOBOL methods increases the convergence speed of the NSGA_II. The results from the first analysis step indicated that the hydrogen diesel blend reduced brake specific fuel consumption (BSFC), engine power and torque, CO 2 and NO x x emissions, and increased entropy. The results from the second step suggested that in multivariable optimization, the peak pressure and NOx emissions were affected mainly, by combustion initiation time and the hydrogen added to the diesel fuel, respectively. Finally, it was found that hydrogen injection at 20 mg/min resulted in the best engine performance and emission .},
  archive      = {J_ASOC},
  author       = {Hadis Derikvand and Mohammad Shafiey Dehaj and Hadi Taghavifar},
  doi          = {10.1016/j.asoc.2022.109434},
  journal      = {Applied Soft Computing},
  pages        = {109434},
  shortjournal = {Appl. Soft. Comput.},
  title        = {The effect of different sampling method integrated in NSGA II optimization on performance and emission of diesel/hydrogen dual-fuel CI engine},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Correlation-based feature selection using bio-inspired
algorithms and optimized KELM classifier for glaucoma diagnosis.
<em>ASOC</em>, <em>128</em>, 109432. (<a
href="https://doi.org/10.1016/j.asoc.2022.109432">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reduced computational time and cost, reduced skilled professional resources, and diagnostic accuracy have made medical diagnosis using computer aided systems (CAD) increasingly popular and can be comfortably employed in the diagnosis of many acute and chronic diseases in ophthalmology, cardiology, cancer detection, etc. There seems to be a growing necessity for the computational algorithms to be robust enough, to identify the abnormality in each of the cases, aiding in early diagnosis. In this paper, a glaucoma diagnostic approach based on the wrapper method employing bio-inspired algorithms, and a Kernel-Extreme Learning Machine (KELM) classifier is proposed. The bio-inspired algorithms are deployed to select feature sub-sets, generating three feature sub-sets from the pre-processed fundus images by adopting a correlation-based feature selection (CFS) approach. The selected features are utilized to train the salp-swarm optimization based KELM, which finds the optimal parameters of the KELM classifier network. The proposed methodology is evaluated on the public and private retinal fundus datasets containing 7280 images. The experimental outcome revealed that the system is able to attain a maximum overall accuracy of 99.61\% with 99.89\% sensitivity and 100\% specificity. A 5-fold cross validation showed 98.78\% accuracy ensuring a bias-free classification. Further, by experimenting on degraded images (Gaussian, salt-pepper noise images) of the original dataset, the model achieved extreme robustness with 99.3\% accuracy. The proposed method is compared with other similar methods, which showed the efficiency of our method. The framework proposed can aid in making clinical decisions for various pathologies like lung infection, diabetic retinopathy, etc.},
  archive      = {J_ASOC},
  author       = {Kishore Balasubramanian and Ananthamoorthy N.P.},
  doi          = {10.1016/j.asoc.2022.109432},
  journal      = {Applied Soft Computing},
  pages        = {109432},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Correlation-based feature selection using bio-inspired algorithms and optimized KELM classifier for glaucoma diagnosis},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Information fusion-based genetic algorithm with long
short-term memory for stock price and trend prediction. <em>ASOC</em>,
<em>128</em>, 109428. (<a
href="https://doi.org/10.1016/j.asoc.2022.109428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information fusion is one of the critical aspects in diverse fields of applications; while the collected data may provide certain perspectives, a fusion of such data can be a useful way of exploring, expanding, enhancing, and extracting meaningful information for a better organization of the targeted domain. A nature-inspired evolutionary approach, namely, genetic algorithm (GA) is adopted for a variety of applications including stock market prediction. The complex, highly fluctuating financial market-related problems require optimized models for reliable forecasting. Also, it can be observed that stock market etiquettes are generally non-linear in nature and therefore, a broader understanding and analysis of such market behaviors necessitate the collection and fusion of relevant information based on different associated factors. In this article, we propose an information fusion-based GA approach with inter-intra crossover and adaptive mutation (ICAN) for stock price and trend prediction. Inspired by the genetic diversity and survival capability of various organisms, our proposed approach aims to optimize parameters of a long short-term memory prediction model, and selects a set of features; to address these problems of interest, we integrate inter-chromosome as well as conditional intra-chromosome crossover operations along with adaptive mutation to diversify the potential chromosome solutions. We illustrate the step-by-step procedure followed by GA with ICAN and evaluate its performance for one-day-ahead stock price and trend prediction. GA with ICAN-based optimization results in an average reduction of 43\%, 27\%, and 26\% using mean squared error , mean absolute error , and mean absolute percentage error, respectively, as compared to the existing GA-based optimization approaches; further, an average improvement of 61\% is encountered using R 2 2 score. We also compare our work with Ant Lion Optimization approach and demonstrate the significance of GA with ICAN-based optimization. We analyze statistical significance, as well as convergence functions, for GA with ICAN and discuss remarkable performance enhancement; we provide necessary concluding remarks with potential future research directions.},
  archive      = {J_ASOC},
  author       = {Ankit Thakkar and Kinjal Chaudhari},
  doi          = {10.1016/j.asoc.2022.109428},
  journal      = {Applied Soft Computing},
  pages        = {109428},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Information fusion-based genetic algorithm with long short-term memory for stock price and trend prediction},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Situational awareness and deficiency warning system in a
smart distribution network based on stacking ensemble learning.
<em>ASOC</em>, <em>128</em>, 109427. (<a
href="https://doi.org/10.1016/j.asoc.2022.109427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting defects and knowing the network conditions are important issues in distribution system operation. A comprehensive defect warning system considering different internal and external affecting parameters could help the operator to better manage and protect the network. A method based on ensemble learning is presented in this paper to determine the system’s status and implement a warning scheme for defects. The employed learning method is a stacking-based approach that includes two main layers. In the structure of the proposed method, the first level consists of support vector machine , random forest , and XGBoost classifiers as basic models. Also, in the next layer, referred to as the meta-classifier, a support vector machine is used as the final classifier. To identify the states of the system, voltages and currents in certain buses have been used as the system’s parameters. Weather-related effects are the other crucial factors that affect system conditions, which are included in the models. Four distinct modes are defined to specify different states of the system that actually represent the warning levels. The proposed models are evaluated using the extracted data from a modified IEEE 123-bus test system, including PVs. The obtained results are compared with several individual models, and the effect of noise on the input data has also been considered. The evaluations show highly appropriate outcomes of the proposed model in predicting different system states and achieving better results than individual methods.},
  archive      = {J_ASOC},
  author       = {Ali Ghaemi and Amin Safari and Hadi Afsharirad and Hossein Shayeghi},
  doi          = {10.1016/j.asoc.2022.109427},
  journal      = {Applied Soft Computing},
  pages        = {109427},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Situational awareness and deficiency warning system in a smart distribution network based on stacking ensemble learning},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An ensemble learning strategy for panel time series
forecasting of excess mortality during the COVID-19 pandemic.
<em>ASOC</em>, <em>128</em>, 109422. (<a
href="https://doi.org/10.1016/j.asoc.2022.109422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantifying and analyzing excess mortality in crises such as the ongoing COVID-19 pandemic is crucial for policymakers. Traditional measures fail to take into account differences in the level, long-term secular trends, and seasonal patterns in all-cause mortality across countries and regions. This paper develops and empirically investigates the forecasting performance of a novel, flexible and dynamic ensemble learning with a model selection strategy (DELMS) for the seasonal time series forecasting of monthly respiratory disease death data across a pool of 61 heterogeneous countries. The strategy is based on a Bayesian model averaging (BMA) of heterogeneous time series methods involving both the selection of the subset of best forecasters (model confidence set), the identification of the best holdout period for each contributed model, and the determination of optimal weights using out-of-sample predictive accuracy . A model selection strategy is also developed to remove the outlier models and to combine the models with reasonable accuracy in the ensemble. The empirical outcomes of this large set of experiments show that the accuracy of the BMA approach is significantly improved with DELMS when selecting a flexible and dynamic holdout period and removing the outlier models. Additionally, the forecasts of respiratory disease deaths for each country are highly accurate and exhibit a high correlation (94\%) with COVID-19 deaths in 2020.},
  archive      = {J_ASOC},
  author       = {Afshin Ashofteh and Jorge M. Bravo and Mercedes Ayuso},
  doi          = {10.1016/j.asoc.2022.109422},
  journal      = {Applied Soft Computing},
  pages        = {109422},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An ensemble learning strategy for panel time series forecasting of excess mortality during the COVID-19 pandemic},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interval type-2 fuzzy development of FUCOM and activity
relationship charts along with MARCOS for facilities layout evaluation.
<em>ASOC</em>, <em>128</em>, 109414. (<a
href="https://doi.org/10.1016/j.asoc.2022.109414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new interval type-2 fuzzy (IT2F) multiple attribute decision making (MADM) model for evaluating facility layout alternatives. To this end, The Full Consistency Method (FUCOM) is extended to IT2F sets, and the mathematical model of IT2F-FUCOM is proposed. IT2F-FUCOM method requires a manageable number of pairwise comparisons and can deal with imprecision and uncertainty. Furthermore, the Activity Relationship Charts (ARCs), which are powerful instruments to articulate preferences regarding closeness between departments in the facility design, are also modeled through IT2F sets. The proposed IT2F-ARCs are incorporated into the decision hierarchy as a cost-type criterion, a novel integration between ARCs and the MADM is provided. Finally, the state-of-the-art IT2F MADM method of Measurement Alternatives and Ranking according to the Compromise Solution (MARCOS) is utilized to rank the alternatives. A real-life case study is conducted in order to demonstrate the applicability of the proposed model.},
  archive      = {J_ASOC},
  author       = {İlker Gölcük and Esra Duygu Durmaz and Ramazan Şahin},
  doi          = {10.1016/j.asoc.2022.109414},
  journal      = {Applied Soft Computing},
  pages        = {109414},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Interval type-2 fuzzy development of FUCOM and activity relationship charts along with MARCOS for facilities layout evaluation},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A decomposition-based many-objective evolutionary algorithm
with adaptive weight vector strategy. <em>ASOC</em>, <em>128</em>,
109412. (<a href="https://doi.org/10.1016/j.asoc.2022.109412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary multi-objective optimization methods have become increasingly popular in finding a representative set of Pareto optimal solutions for multi-objective optimization problems (MOPs). As an important multi-objective optimization method, MOEA/D has been successfully applied to resolve various of MOPs. However, there still exist two issues in MOEA/D. First, the distribution of result set is greatly limited in complex Pareto Front (PF) shapes. Second, the effectiveness is relatively poor for solving many-objective optimization problems (MaOPs). Although many researchers attempt to improve MOEA/D, these two issues have not been solved well. This paper proposes a modified MOEA/D method called MOEA/D-VW which involves three optimization strategies . First, an adaptive weight vector adjustment strategy is adopted to fine-tune the subproblems , thus changing the evolution direction of the subpopulation. Second, a weight vector initialization strategy with preference parameters is added into MOEA/D-VW. Third, a modified crossover operator is leveraged to generate new population with good diversity and overcome the problem of high computational cost. Experiments are carried out on the set of 23 continuous optimization problems. The experimental results show that the performance and the distribution of the Pareto Set (PS) of MOEA/D-VW are effectively improved. Meanwhile, the experimental results demonstrate that the modified crossover operator can effectively reduce the computational cost of MOEA/D-VW.},
  archive      = {J_ASOC},
  author       = {Xin Chen and Jiacheng Yin and Dongjin Yu and Xulin Fan},
  doi          = {10.1016/j.asoc.2022.109412},
  journal      = {Applied Soft Computing},
  pages        = {109412},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A decomposition-based many-objective evolutionary algorithm with adaptive weight vector strategy},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A wavelet-based deep learning pipeline for efficient
COVID-19 diagnosis via CT slices. <em>ASOC</em>, <em>128</em>, 109401.
(<a href="https://doi.org/10.1016/j.asoc.2022.109401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quick diagnosis of the novel coronavirus (COVID-19) disease is vital to prevent its propagation and improve therapeutic outcomes. Computed tomography (CT) is believed to be an effective tool for diagnosing COVID-19, however, the CT scan contains hundreds of slices that are complex to be analyzed and could cause delays in diagnosis. Artificial intelligence (AI) especially deep learning (DL), could facilitate and speed up COVID-19 diagnosis from such scans. Several studies employed DL approaches based on 2D CT images from a single view, nevertheless, 3D multiview CT slices demonstrated an excellent ability to enhance the efficiency of COVID-19 diagnosis. The majority of DL-based studies utilized the spatial information of the original CT images to train their models, though, using spectral–temporal information could improve the detection of COVID-19. This article proposes a DL-based pipeline called CoviWavNet for the automatic diagnosis of COVID-19. CoviWavNet uses a 3D multiview dataset called OMNIAHCOV. Initially, it analyzes the CT slices using multilevel discrete wavelet decomposition (DWT) and then uses the heatmaps of the approximation levels to train three ResNet CNN models . These ResNets use the spectral–temporal information of such images to perform classification. Subsequently, it investigates whether the combination of spatial information with spectral–temporal information could improve the diagnostic accuracy of COVID-19. For this purpose, it extracts deep spectral–temporal features from such ResNets using transfer learning and integrates them with deep spatial features extracted from the same ResNets trained with the original CT slices. Then, it utilizes a feature selection step to reduce the dimension of such integrated features and use them as inputs to three support vector machine (SVM) classifiers. To further validate the performance of CoviWavNet, a publicly available benchmark dataset called SARS-COV-2-CT-Scan is employed. The results of CoviWavNet have demonstrated that using the spectral–temporal information of the DWT heatmap images to train the ResNets is superior to utilizing the spatial information of the original CT images. Furthermore, integrating deep spectral–temporal features with deep spatial features has enhanced the classification accuracy of the three SVM classifiers reaching a final accuracy of 99.33\% and 99.7\% for the OMNIAHCOV and SARS-COV-2-CT-Scan datasets respectively. These accuracies verify the outstanding performance of CoviWavNet compared to other related studies. Thus, CoviWavNet can help radiologists in the rapid and accurate diagnosis of COVID-19 diagnosis.},
  archive      = {J_ASOC},
  author       = {Omneya Attallah and Ahmed Samir},
  doi          = {10.1016/j.asoc.2022.109401},
  journal      = {Applied Soft Computing},
  pages        = {109401},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A wavelet-based deep learning pipeline for efficient COVID-19 diagnosis via CT slices},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). From diversity to consensus: Impacts of opinion evolution
and psychological behaviours in failure mode and effect analysis.
<em>ASOC</em>, <em>128</em>, 109399. (<a
href="https://doi.org/10.1016/j.asoc.2022.109399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Failure mode and effect analysis (FMEA) is a preventive risk management tool, and has been widely applied across various industries. Most existing FMEA methods are concentrated on obtaining a complete risk ranking of failure modes. However, in some situations, it may be enough to divide failure modes into several ordinal classifications. Moreover, the consensus issue needs to be taken seriously because multiple FMEA experts have different risk assessments due to their diverse knowledge backgrounds. Meanwhile, bounded confidences, opinion evolution and psychological behaviours of FMEA experts also play key roles in the consensus-reaching process. Therefore, this paper integrates a classification consensus-based model with bounded confidences and opinion evolution, from the perspective of prospect theory into FMEA. First, FMEA experts provide risk assessments by prospect theory. Then, a novel consensus-reaching process is developed, in which a dual feedback adjustment mechanism based on opinion evolution and bounded confidences is designed. Finally, a case study and a comparative analysis are provided to show the application value of the proposal. The classification consensus-based proposal enriches the theory system of FMEA, and has a good reference value for solving the reliability management problems in the aerospace, automobile manufacturing and other fields.},
  archive      = {J_ASOC},
  author       = {Yan Zhu and Chuanhao Fan and Hengjie Zhang},
  doi          = {10.1016/j.asoc.2022.109399},
  journal      = {Applied Soft Computing},
  pages        = {109399},
  shortjournal = {Appl. Soft. Comput.},
  title        = {From diversity to consensus: Impacts of opinion evolution and psychological behaviours in failure mode and effect analysis},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A binary tournament competition algorithm for solving
partial differential equation constrained optimization via finite
element method. <em>ASOC</em>, <em>128</em>, 109394. (<a
href="https://doi.org/10.1016/j.asoc.2022.109394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sometimes, in a tournament competition to form a single team from two teams, 50\% players are selected from the union of both teams according to their performance (fitness). Considering this idea, the aim of this article is to design an algorithm based on binary tournament process using two different types of metaheuristic algorithms . Here, at first, four swarms of populations are considered. The first two swarms are updated by Gaussian quantum behaved particle swarm optimization (GQPSO) algorithm and other two swarms are updated by weighted quantum behaved particle swarm optimization (WQPSO) algorithm considering second strategy among six strategies of existing binary tournamenting process. Thereafter, a swarm is formed from the updated solutions found from GQPSO and also from WQPSO algorithms. Finally, an algorithm is selected randomly with equal probability to update the final swarm. To test the effectiveness of the proposed algorithm, it is applied on partial differential equation (PDE) constrained optimization problems transforming these into bound constrained optimization problems using finite element discretization method and the obtained results are compared with the parent algorithms, WQPSO and GQPSO numerically. Also, the results are compared with a number of existing metaheuristic algorithms . Finally, to check the significance of the results and also to draw the fruitful conclusion, nonparametric statistical tests are performed.},
  archive      = {J_ASOC},
  author       = {Nirmal Kumar and Sanat Kumar Mahato and Asoke Kumar Bhunia},
  doi          = {10.1016/j.asoc.2022.109394},
  journal      = {Applied Soft Computing},
  pages        = {109394},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A binary tournament competition algorithm for solving partial differential equation constrained optimization via finite element method},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Architecture reduction of a probabilistic neural network by
merging k-means and k-nearest neighbour algorithms. <em>ASOC</em>,
<em>128</em>, 109387. (<a
href="https://doi.org/10.1016/j.asoc.2022.109387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic neural network (PNN) has a sizable structure since it requires all training records in the activation of its hidden layer. This fact makes it suffer from the problem of the curse of dimensionality. Therefore, an hypotheses can be easily formulated that in order to manage large data classification tasks , it is recommended to minimise its inner design. In this paper, we directly address this issue: the method for the PNN’s architecture reduction is elaborated. It is organised as follows. First, a k-means data clustering is conducted and the obtained centres are stored. Next, one selects a single nearest neighbour to the determined centres considering each class separately. The pattern neurons of a PNN are then established using both (i) the cluster centres and (ii) the records closest to the obtained centroids . The algorithm is applied to the classification tasks of seven repository data sets. The utilised PNN is trained by means of four training techniques with different kernel functions in each case. A 10–fold cross validation method is applied to assess the performance of the original and reduced networks. The obtained results are also compared with those provided by existing methods in the literature. It is shown that in the majority classification cases, it is possible to achieve a higher accuracy of the reduced PNN compared to the original network and the approaches introduced in the literature.},
  archive      = {J_ASOC},
  author       = {Maciej Kusy and Piotr A. Kowalski},
  doi          = {10.1016/j.asoc.2022.109387},
  journal      = {Applied Soft Computing},
  pages        = {109387},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Architecture reduction of a probabilistic neural network by merging k-means and k-nearest neighbour algorithms},
  volume       = {128},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Incremental learning-inspired mating restriction strategy
for evolutionary multiobjective optimization. <em>ASOC</em>,
<em>127</em>, 109430. (<a
href="https://doi.org/10.1016/j.asoc.2022.109430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prior knowledge from the problem property can boost the evolutionary multiobjective optimization (EMO). The existing machine learning model for knowledge mining in the EMO has led to enhanced performance on multiobjective optimization problems with complicated Pareto fronts (MOPs-cPF), but the high computational cost resulting from model training should not be taken as a natural expense. To overcome this drawback, this paper proposes an incremental learning-inspired mating restriction strategy (ILMR) for solving MOP-cPF efficiently. In ILMR, a mating restriction is implemented based on an incremental learning model that establishes the mating pool for each solution in the population and incrementally updates as the population evolves. Specifically, it consists of two interdependent parts, i.e., a learning module and a forgetting module. In one evolutionary cycle , the learning module is used to learn new knowledge from the high-quality offspring solutions, while the forgetting module is utilized to remove the information provided by relatively poor solutions in the population. Moreover, a multiobjective evolutionary algorithm with ILMR, named MEILM, is proposed and compared with six state-of-the-art algorithms on a variety of MOP-cPF. The experimental results show that there are significant improvements benefitting from the proposed mating restriction strategy.},
  archive      = {J_ASOC},
  author       = {Tingrui Liu and Liguo Tan and Xin Li and Shenmin Song},
  doi          = {10.1016/j.asoc.2022.109430},
  journal      = {Applied Soft Computing},
  pages        = {109430},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Incremental learning-inspired mating restriction strategy for evolutionary multiobjective optimization},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-objective evolutionary algorithm with interval based
initialization and self-adaptive crossover operator for large-scale
feature selection in classification. <em>ASOC</em>, <em>127</em>,
109420. (<a href="https://doi.org/10.1016/j.asoc.2022.109420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) is an important data pre-processing technique in classification. In most cases, FS can improve classification accuracy and reduce feature dimension, so it can be regarded as a multi-objective optimization problem. Many evolutionary computation techniques have been applied to FS problems and achieved good results. However, an increase in data dimension means that search difficulty also greatly increases, and EC algorithms with insufficient search ability maybe only find sub-optimal solutions in high probability. Moreover, an improper initial population may negatively affect the convergence speed of algorithms. To solve the problems highlighted above, this paper proposes MOEA-ISa: a multi-objective evolutionary algorithm with interval based initialization and self-adaptive crossover operator for large-scale FS. The proposed interval based initialization can limit the number of selected features for solution to improve the distribution of the initial population in the target space and reduce the similarity of the initial population in the decision space. The proposed self-adaptive crossover operator can determine the number of nonzero genes in offspring according to the similarity of parents, and it combines with the feature weights obtained by ReliefF method to improve the quality of offspring. In the experiments, the proposed algorithm was compared with six other algorithms on 13 benchmark UCI datasets and two benchmark LIBSVM datasets, and an ablation experiment was performed on MOEA-ISa. The results show that MOEA-ISa’s performance is better than the six other algorithms for solving large-scale FS problems, and the proposed interval based initialization and self-adaptive crossover operator can effectively improve the performance of MOEA-ISa. The source code of MOEA-ISa is available on GitHub at https://github.com/xueyunuist/MOEA-ISa .},
  archive      = {J_ASOC},
  author       = {Yu Xue and Xu Cai and Ferrante Neri},
  doi          = {10.1016/j.asoc.2022.109420},
  journal      = {Applied Soft Computing},
  pages        = {109420},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-objective evolutionary algorithm with interval based initialization and self-adaptive crossover operator for large-scale feature selection in classification},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An adaptive differential evolution algorithm based on belief
space and generalized opposition-based learning for resource allocation.
<em>ASOC</em>, <em>127</em>, 109419. (<a
href="https://doi.org/10.1016/j.asoc.2022.109419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential evolution (DE) algorithm is prone to premature convergence and local optimization in solving complex optimization problems . In order to solve these problems, the belief space strategy, generalized opposition-based learning strategy and parameter adaptive strategy are introduced into DE to propose an improved adaptive DE algorithm, namely ACDE/F in this paper. In the ACDE/F, the idea of cultural algorithm and different mutation strategies are introduced into belief space to balance the global exploration ability and local optimization ability. A generalized opposition-based learning strategy is designed to improve the convergence speed of local optimization and increase the population diversity. A parameter adaptive adjustment strategy is developed to reasonably adjust the mutation factor and crossover factor to avoid to fall into local optimum. In order to test and verify the optimization performance of the ACDE/F, the unimodal functions and multimodal functions from CEC 2005 and CEC 2017 are selected in here. The experiment results show that the ACDE/F has better optimization performance than the DE with different strategies, WMSDE, DE2/F, GOAL-RNADE and DE/best/1. In addition, the actual gate allocation problem is selected to verify the practical application ability of the ACDE/F. The ACDE/F obtains the maximum allocation rate and average allocation rate of 98\% and 96.8\%, respectively. Therefore, the experimental results show that the ACDE/F can effectively solve the gate allocation problem and obtain ideal gate allocation results.},
  archive      = {J_ASOC},
  author       = {Wu Deng and Hongcheng Ni and Yi Liu and Huiling Chen and Huimin Zhao},
  doi          = {10.1016/j.asoc.2022.109419},
  journal      = {Applied Soft Computing},
  pages        = {109419},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An adaptive differential evolution algorithm based on belief space and generalized opposition-based learning for resource allocation},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An improved variable neighborhood search for parallel drone
scheduling traveling salesman problem. <em>ASOC</em>, <em>127</em>,
109416. (<a href="https://doi.org/10.1016/j.asoc.2022.109416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parallel drone scheduling traveling salesman problem (PDSTSP) is a typical optimization problem of the truck-drone hybrid delivery system and hardly solved by using meta-heuristics. In this study, an improved variable neighborhood search (IVNS) is presented to minimize the completion time of all vehicles for serving all delivery tasks. Three methods based on the longest processing time (LPT) rule and two reduced variable neighborhood search (RVNS) algorithms are used to produce an initial solution. Then IVNS based on a shaking method and an adaptive RVNS is used to improve the initial solution. 20 neighborhood structures are proposed, 14 of which are used to assign customers between the truck and drones. A number of experiments are conducted on 90 instances. The results reveal that IVNS is very competitive for PDSTSP and obtains state-of-the-art solutions of 12 instances.},
  archive      = {J_ASOC},
  author       = {Deming Lei and Xiang Chen},
  doi          = {10.1016/j.asoc.2022.109416},
  journal      = {Applied Soft Computing},
  pages        = {109416},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An improved variable neighborhood search for parallel drone scheduling traveling salesman problem},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fuzzy rule dropout with dynamic compensation for wide
learning algorithm of TSK fuzzy classifier. <em>ASOC</em>, <em>127</em>,
109410. (<a href="https://doi.org/10.1016/j.asoc.2022.109410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper extends our recent work about dropout for the design of Takagi–Sugeno–Kang(TSK) fuzzy classifiers, i.e., fuzzy-knowledge-out, to the generalized concept, i.e., fuzzy rule dropout with dynamic compensation . This extension is motivated by very complicated firing patterns of all pieces of knowledge in human brain, i.e., binary or continuous or both random ways for different situations. Our theoretical analysis indicates that this generalized concept can encapsulate various random dropouts of fuzzy rules with more match of human cognitive behavior, more capabilities of both generalization and co-adaptation avoidance. Based on this concept, we develop a wide learning algorithm of a TSK fuzzy classifier. Experimental results about the thirteen datasets demonstrate that with high interpretability guarantee, TSK fuzzy classifiers designed by means of fuzzy rule dropout with dynamic compensation outperform the comparative methods , especially in the sense of testing accuracy.},
  archive      = {J_ASOC},
  author       = {Bin Qin and Fu-lai Chung and Yusuke Nojima and Hisao Ishibuchi and Shitong Wang},
  doi          = {10.1016/j.asoc.2022.109410},
  journal      = {Applied Soft Computing},
  pages        = {109410},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fuzzy rule dropout with dynamic compensation for wide learning algorithm of TSK fuzzy classifier},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evolutionary multiobjective overlapping community detection
based on similarity matrix and node correction. <em>ASOC</em>,
<em>127</em>, 109397. (<a
href="https://doi.org/10.1016/j.asoc.2022.109397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The method of overlapping community detection based on fuzzy clustering is sensitive to the initialization of community centers, which easily traps in local optima and leads to node misclassification . This paper proposes an evolutionary multiobjective algorithm based on similarity matrix and node correction to detect overlapping communities to solve the above problems. Firstly, the algorithm determines a similarity community for each node by setting the similarity threshold. Then, the central nodes are found more accurately through the similarity distribution of the similarity communities. Secondly, under the framework of the evolutionary multiobjective algorithm, the similarity communities of the central nodes are used as the initial communities to obtain the nonoverlapping communities. In addition, the algorithm proposes a correction strategy for the noncentral nodes based on the similarity communities. The correction strategy obtains the adjacent nodes of each node’s similarity community. It then uses each adjacent node’s community to correct the nonoverlapping community. Finally, the algorithm adjusts the noncentral nodes’ correction strategy. This correction strategy corrects the overlapping nodes according to the number of each overlapping node’s labels. It takes the separation operation to further correct overlapping nodes to obtain the corrected overlapping communities. This paper uses seventeen real networks and a variety of synthetic networks with different parameters to verify the proposed algorithm’s effectiveness. And the proposed algorithm achieves higher accuracy of community detection in most networks than four state-of-the-art overlapping community detection algorithms .},
  archive      = {J_ASOC},
  author       = {Ronghua Shang and Kejia Zhao and Weitong Zhang and Jie Feng and Yangyang Li and Licheng Jiao},
  doi          = {10.1016/j.asoc.2022.109397},
  journal      = {Applied Soft Computing},
  pages        = {109397},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Evolutionary multiobjective overlapping community detection based on similarity matrix and node correction},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analysis and improvements on feature selection methods based
on artificial neural network weights. <em>ASOC</em>, <em>127</em>,
109395. (<a href="https://doi.org/10.1016/j.asoc.2022.109395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ASOC},
  author       = {Nattane Luíza da Costa and Márcio Dias de Lima and Rommel Barbosa},
  doi          = {10.1016/j.asoc.2022.109395},
  journal      = {Applied Soft Computing},
  pages        = {109395},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Analysis and improvements on feature selection methods based on artificial neural network weights},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Solving constrained optimization problems via multifactorial
evolution. <em>ASOC</em>, <em>127</em>, 109392. (<a
href="https://doi.org/10.1016/j.asoc.2022.109392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a new paradigm in the field of evolutionary computation, multifactorial evolution has become more and more popular since its inception. It attempts to solve multiple optimization problems simultaneously using a single evolving population. Due to the implicit knowledge transfer, multifactorial evolution exhibits the potential to solve complex optimization problems . This paper tries to take advantage of multifactorial evolution to solve constrained optimization problems (COPs). To this end, we derive two different optimization problems from the considered COP. Theoretical analysis reveals that the optima of these two problems are exactly identical to the feasible optima of the original COP. Thus, the advantages of knowledge transfer can be used adequately. In addition, these two problems focus more on the objective function and the constraints, respectively. By solving them concurrently, we can achieve the balance between constraints and objective function, which is of essential importance in constrained evolutionary optimization . Moreover, a multifactorial differential evolution is developed, which can leverage the merits of multifactorial evolution and differential evolution effectively. To tackle complex COPs, a diversity strategy is designed for population diversity maintenance. Extensive experiments on benchmark test sets and engineering optimization problems have demonstrated the effectiveness of the proposed method.},
  archive      = {J_ASOC},
  author       = {Bing-Chuan Wang and Zhi-Zhong Liu and Wu Song},
  doi          = {10.1016/j.asoc.2022.109392},
  journal      = {Applied Soft Computing},
  pages        = {109392},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Solving constrained optimization problems via multifactorial evolution},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A kernel-free fuzzy reduced quadratic surface ν-support
vector machine with applications. <em>ASOC</em>, <em>127</em>, 109390.
(<a href="https://doi.org/10.1016/j.asoc.2022.109390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The kernel-free support vector machine (SVM) models are recently developed and studied to overcome some drawbacks induced by the kernel-based SVM models. To further improve the classification accuracy and computational efficiency of existing kernel-free quadratic surface support vector machine (QSSVM) models, a novel kernel-free ν ν -fuzzy reduced QSSVM model is proposed. The proposed model utilizes a reduced quadratic surface for nonlinear binary classification as well as reducing the effect of outliers in the data set. Some theoretical properties are rigorously studied, especially, the effects of the parameter ν ν on the dual feasibility and the number of support vectors. Computational experiments are conducted on some public benchmark data sets to indicate the superior performance of the proposed model over some well-known binary classification models. The numerical results also favors the higher training efficiency of the proposed model over those of other kernel-free SVM models. Moreover, the proposed model is successfully applied to the prodromal detection of Alzheimer’s Disease with good performance, by using the data from the Alzheimer’s Disease Neuroimaging Initiative (ADNI) database.},
  archive      = {J_ASOC},
  author       = {Zheming Gao and Yiwen Wang and Min Huang and Jian Luo and Shanshan Tang},
  doi          = {10.1016/j.asoc.2022.109390},
  journal      = {Applied Soft Computing},
  pages        = {109390},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A kernel-free fuzzy reduced quadratic surface ν-support vector machine with applications},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A framework of LR fuzzy AHP and fuzzy WASPAS for health care
waste recycling technology. <em>ASOC</em>, <em>127</em>, 109388. (<a
href="https://doi.org/10.1016/j.asoc.2022.109388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Migration from a linear to a circular economy (CE) has become inevitable to reduce waste by making reusable products and materials. The present health care waste (HCW) management development has also been reformed due to this change. Since there is a strong connection between HCW management and CE, in this study, the HCW recycling technology selection problem has been addressed, modeled, and solved using the MCDM technique for the first time. In this paper, we present a new group decision-making process (GDMP) by combining the analytical hierarchy process (AHP) and weighted aggregated sum product assessment (WASPAS) under a fuzzy environment. LR fuzzy numbers (LRFNs) are employed to convey and model the linguistic judgments made by decision-makers (DMs). Novel LR fuzzy geometric mean, defuzzification method for the LRFNs, and LR fuzzy consistency checking method have been introduced here. The proposed technique is then applied to select optimal HCW recycling technology by considering nine selection criteria and four recycling alternatives based on the expert’s judgment. The proposed approach elicits an effective way of reusing the disposable HCW in conjunction with CE with the help of GDMP. To confirm the reasonableness, practicality, and applicability of the proposed methodology, an illustrative case study on several district hospitals in Tripura, India, has been performed. The validity, consistency, and robustness of the proposed approach have been checked through comparative and sensitivity analyses. The computational complexity of the proposed method has also been investigated and compared with some existing techniques. The research findings show that the proposed model has identified Red2Green as the best HCW recycling technology in the socio-economic perspective of Tripura, India.},
  archive      = {J_ASOC},
  author       = {Sayanta Chakraborty and Apu Kumar Saha},
  doi          = {10.1016/j.asoc.2022.109388},
  journal      = {Applied Soft Computing},
  pages        = {109388},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A framework of LR fuzzy AHP and fuzzy WASPAS for health care waste recycling technology},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep reinforcement learning with a critic-value-based branch
tree for the inverse design of two-dimensional optical devices.
<em>ASOC</em>, <em>127</em>, 109386. (<a
href="https://doi.org/10.1016/j.asoc.2022.109386">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In optical engineering , designing a device or a system with the desired property is an important but challenging task. It is relatively straightforward to compute the physical properties of a given design; however, there is no general method for the reverse, i.e., designing with desired properties. To address this problem with a computational method, this paper proposes a deep reinforcement learning-based inverse design framework consisting of two methods: Inverse DEsign Agent (IDEA) and Critic-Value-based Branch Tree (CVBT) algorithm. IDEA is a deep reinforcement learning model based on the Advantage Actor–Critic (A2C) method using a deep learning simulator as a replacement for a real environment, significantly reducing training time compared to conventional methods. The CVBT algorithm suggests several design candidates using the critic values of IDEA, while conventional methods propose only one candidate. In this study, the proposed framework was applied to a two-dimensional optical device design problem. Experimental results with untrained target properties demonstrated that the proposed model, IDEA-CVBT, achieved state-of-the-art performance in terms of accuracy and stability. For instance, in a scenario with a binary type design, IDEA-CVBT exhibited an accuracy of 91.5\%, while conventional deep reinforcement models showed 36.1\% and 7.4\% accuracies. Extensive analyses verified that IDEA-CVBT can be employed as an assistance system for engineers since IDEA-CVBT suggests several appropriate candidates that satisfy target properties.},
  archive      = {J_ASOC},
  author       = {Hyo-Seok Hwang and Minhyeok Lee and Junhee Seok},
  doi          = {10.1016/j.asoc.2022.109386},
  journal      = {Applied Soft Computing},
  pages        = {109386},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Deep reinforcement learning with a critic-value-based branch tree for the inverse design of two-dimensional optical devices},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Controlling mixed-mode fatigue crack growth using deep
reinforcement learning. <em>ASOC</em>, <em>127</em>, 109382. (<a
href="https://doi.org/10.1016/j.asoc.2022.109382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mechanical discontinuity embedded in a material determines the bulk mechanical, physical, and chemical properties. Under external forces, mechanical discontinuity undergo spatiotemporal propagation; thereby altering various properties of the material. This paper is a proof-of-concept development and deployment of a reinforcement learning framework, based on deep deterministic policy gradient, to precisely control both the direction and rate of the fatigue crack growth . The ability to control mechanical discontinuity in essence determines the key material properties. The desired control is relatively hard to achieve considering the large, continuous state and action spaces along with the exponential relationship between crack growth and stress cycle. The reinforcement-learning scheme is capable of learning an optimal and computational tractable control strategy. In the proposed approach, the reinforcement learning framework is integrated into an OpenAI-Gym-based environment that implements the mechanistic equations governing the fatigue crack growth . The learning agent does not explicitly know about the underlying physics, nonetheless, the learning agent can infer the control strategy by continuously interacting the numerical environment. The paper formulates an adaptive reward function involving reward shaping that can be generalized to similar control problems to improve the training efficiency. The reinforcement learning framework can successfully control the fatigue crack growth in a material despite the complexity of the propagation/growth pathway determined by multiple goal points. The paper provides the mathematical/physical basis of the reward function and the effect of neural network size and architecture and the state and action space that boosts the training speed while preserving the stability of the RL agents for the desired control problem.},
  archive      = {J_ASOC},
  author       = {Yuteng Jin and Siddharth Misra},
  doi          = {10.1016/j.asoc.2022.109382},
  journal      = {Applied Soft Computing},
  pages        = {109382},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Controlling mixed-mode fatigue crack growth using deep reinforcement learning},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data augmentation based estimation for the censored
composite quantile regression neural network model. <em>ASOC</em>,
<em>127</em>, 109381. (<a
href="https://doi.org/10.1016/j.asoc.2022.109381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Composite quantile regression neural network (CQRNN) model has been widely applied to explore complex patterns among variables, but few researchers consider its possible applications in censoring problems (left censoring, right censoring, and interval censoring might occur in the responses y y ). In this paper, we propose an iterative estimation method based on the data augmentation algorithm for censored CQRNN model. Firstly the censored data are imputed through a data augmentation process, then we update the CQRNN model with the imputed data, finally the updated CQRNN model is employed to make predictions. Simulation studies and real data application illustrate that the proposed method outperforms the existing censored methods in terms of mean absolute error and root mean squared error , meanwhile producing very close results to those of the uncensoring case. The proposed method can be easily adapted to deal with different censoring types including left censoring, right censoring, and interval censoring, remedying the defect that the available censored methods are only suitable for right censoring type.},
  archive      = {J_ASOC},
  author       = {Ruiting Hao and Huanfeng Zheng and Xiaorong Yang},
  doi          = {10.1016/j.asoc.2022.109381},
  journal      = {Applied Soft Computing},
  pages        = {109381},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Data augmentation based estimation for the censored composite quantile regression neural network model},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Arabic sentiment analysis using dependency-based rules and
deep neural networks. <em>ASOC</em>, <em>127</em>, 109377. (<a
href="https://doi.org/10.1016/j.asoc.2022.109377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growth of social platforms in recent years and the rapid increase in the means of communication through these platforms, a significant amount of textual data is available that contains an abundance of individuals’ opinions. Sentiment analysis is a task that supports companies and organizations to evaluate this textual data with the intention of understanding people’s thoughts concerning services or products. Most previous research in Arabic sentiment analysis relies on word frequencies, lexicons, or black box methods to determine the sentiment of a sentence. It should be noted that these approaches do not take into account the semantic relations and dependencies between words. In this work, we propose a framework that incorporates Arabic dependency-based rules and deep learning models. Dependency-based rules are created by using linguistic patterns to map the meaning of words to concepts in the dependency structure of a sentence. By examining the dependent words in a sentence, the general sentiment is revealed. In the first stage of sentiment classification, the dependency grammar rules are used. If the rules are unsuccessful in classifying the sentiment, the algorithm then applies deep neural networks (DNNs). Three DNN models were employed, namely LSTM , BiLSTM, and CNN , and several Arabic benchmark datasets were used for sentiment analysis. The performance results of the proposed framework show a greater improvement in terms of accuracy and F1 score and they outperform the state-of-the-art approaches in Arabic sentiment analysis.},
  archive      = {J_ASOC},
  author       = {Arwa Diwali and Kia Dashtipour and Kawther Saeedi and Mandar Gogate and Erik Cambria and Amir Hussain},
  doi          = {10.1016/j.asoc.2022.109377},
  journal      = {Applied Soft Computing},
  pages        = {109377},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Arabic sentiment analysis using dependency-based rules and deep neural networks},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intrusion detection technique based on flow aggregation and
latent semantic analysis. <em>ASOC</em>, <em>127</em>, 109375. (<a
href="https://doi.org/10.1016/j.asoc.2022.109375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional network intrusion detection systems cannot identify new burgeoning invasive activities due to the inconspicuous features of malicious behaviors and the enormous increase of data transmitted via different devices. For the inconspicuous features, a novel aggregated flow-based inspection is suggested to amplify features of malicious behaviors. With regards to the enormous amount of data, a new data analysis method is introduced for efficiently classifying network traffic in this paper, which utilized the topic model to construct a doc-word matrix from statistical features and then analyzes latent semantic information to determine whether an aggregated flow is malicious. The performance of the proposed technique is evaluated using CIC-IDS2017, UNSW-NB15, and NSL-KDD datasets, with the results indicating that our technique achieves higher performance than other competing methods. Additionally, the ROC curves demonstrate that the proposed technique is capable of accurate classification even at a low sample rate .},
  archive      = {J_ASOC},
  author       = {Junrui Wu and Wenyong Wang and Lisheng Huang and Fengjun Zhang},
  doi          = {10.1016/j.asoc.2022.109375},
  journal      = {Applied Soft Computing},
  pages        = {109375},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Intrusion detection technique based on flow aggregation and latent semantic analysis},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Packer classification based on association rule mining.
<em>ASOC</em>, <em>127</em>, 109373. (<a
href="https://doi.org/10.1016/j.asoc.2022.109373">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting packer programs is a key step in the defense against malicious programs and plays a key role in cyber security defenses. One challenge with packer classification is that many features have been used and their individual significance is unknown. An effective approach for building classifiers without requiring prior knowledge of feature significance is to use associative classification (AC) algorithms, which combine association rules and classification. This work considers many different AC algorithms for the challenge of packer detection. Novel variations of many of these algorithms are also developed to address challenges related to having many features of varying types. The effectiveness of the classifiers produced by these algorithms is evaluated, including over time as packers and malware evolve.},
  archive      = {J_ASOC},
  author       = {Khanh Huu The Dam and Thomas Given-Wilson and Axel Legay and Rosana Veroneze},
  doi          = {10.1016/j.asoc.2022.109373},
  journal      = {Applied Soft Computing},
  pages        = {109373},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Packer classification based on association rule mining},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Capacitated production planning by parallel genetic
algorithm for a multi-echelon and multi-site TFT-LCD panel manufacturing
supply chain. <em>ASOC</em>, <em>127</em>, 109371. (<a
href="https://doi.org/10.1016/j.asoc.2022.109371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Capacitated production planning of thin-film transistor liquid crystal display (TFTLCD) manufacturing is challenging to optimize owing to its complex sequential operations of array, cell and module plants, which constitute a multi-echelon supply chain. To address this issue, this study proposes a capacitated production planning model for such multi-echelon and multi-site supply chain in the TFTLCD manufacturing industry. Major domain characteristics, such as simultaneous allocation for capacity and transportation, multiple simultaneous resources, glass substrate slicing economics, capacity transformation, and the trade-off between inventories and backorders, are incorporated to maximize the profit of supply chain. To deal the high problem complexity, a parallel programming-based genetic algorithm accompanied with a repair operator is developed to gain the result rapidly. Experiment results indicate that the proposed algorithm outperforms the other benchmark algorithms. The impact of demand uncertainty is also investigated to quantify the information value of the demand. The contribution of the present study lies on the extension of existing literature by proposing a generalized mathematical model for the capacitated production planning problem in the multi-echelon TFTLCD-PM SC, with consideration of key characteristics in such industry. Further, this study improved a regular GA by designing a repair operator and employing a parallel computation architecture to solve a large-scale problem in finite time.},
  archive      = {J_ASOC},
  author       = {Kung-Min Wang and Kung-Jeng Wang and Chou-Cheng Chen},
  doi          = {10.1016/j.asoc.2022.109371},
  journal      = {Applied Soft Computing},
  pages        = {109371},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Capacitated production planning by parallel genetic algorithm for a multi-echelon and multi-site TFT-LCD panel manufacturing supply chain},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Power fluctuation mitigation strategy for microgrids based
on an LSTM-based power forecasting method. <em>ASOC</em>, <em>127</em>,
109370. (<a href="https://doi.org/10.1016/j.asoc.2022.109370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid penetration of renewable generation systems and active loads, the stability and reliability of modern power systems face several challenges owing to power fluctuations caused by renewable intermittency and load uncertainty. Power fluctuations are more significant in islanded microgrids that possess low inertia. Therefore, this study proposes a novel cost-effective proactive control strategy to mitigate power fluctuations of an islanded microgrid. The proposed strategy produces an early acting control reference for generators based on an improved ultra-short-term power fluctuation forecasting algorithm to significantly increase the fluctuation compensation capacity of the generators. Moreover, the size, workload, and cost of the energy storage system reduce. A combined LSTM neural network structure is employed to achieve accurate power fluctuation forecasting. The effectiveness of the proposed method is verified on an islanded hybrid AC/DC microgrid simulation platform.},
  archive      = {J_ASOC},
  author       = {Luo Zhao and Xinan Zhang and Xiuyan Peng},
  doi          = {10.1016/j.asoc.2022.109370},
  journal      = {Applied Soft Computing},
  pages        = {109370},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Power fluctuation mitigation strategy for microgrids based on an LSTM-based power forecasting method},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Digital annealer for quadratic unconstrained binary
optimization: A comparative performance analysis. <em>ASOC</em>,
<em>127</em>, 109367. (<a
href="https://doi.org/10.1016/j.asoc.2022.109367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital Annealer (DA) is a computer architecture designed for tackling combinatorial optimization problems formulated as quadratic unconstrained binary optimization (QUBO) models. In this paper, we present the results of an extensive computational study to evaluate the performance of DA in a systematic way in comparison to multiple state-of-the-art solvers for different problem classes. We examine pure QUBO models, as well as QUBO reformulations of three constrained problems, namely quadratic assignment, quadratic cycle partition, and selective graph coloring , with the last two being new applications for DA. For the selective graph coloring problem, we also present a size reduction heuristic that significantly increases the number of eligible instances for DA. Our experimental results show that despite being in its development stage, DA can provide good-quality solutions quickly and in that regard rivals the state of the art particularly for large instances. Moreover, as opposed to established solvers, within its limit on the number of decision variables, DA’s solution times are not affected by the increase in instance size. These findings illustrate that DA has the potential to become a successful technology in tackling combinatorial optimization problems .},
  archive      = {J_ASOC},
  author       = {Oylum Şeker and Neda Tanoumand and Merve Bodur},
  doi          = {10.1016/j.asoc.2022.109367},
  journal      = {Applied Soft Computing},
  pages        = {109367},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Digital annealer for quadratic unconstrained binary optimization: A comparative performance analysis},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MOMEA: Multi-objective mutation-based evolutionary algorithm
for the alignment of protein networks. <em>ASOC</em>, <em>127</em>,
109366. (<a href="https://doi.org/10.1016/j.asoc.2022.109366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The alignment of protein networks between different species has become a topic of considerable interest in recent years. To perform such alignments between two protein networks, it is necessary to consider the biological functions in which proteins are involved and the structure of the networks topology . Due to the existing complexity of using both topological and biological similarity during the alignment process, many current tools sacrifice the biological similarity of their solutions in order to improve their topological score. This happens because they try to combine these two objectives that are conflicting into a single objective, which leads to the need to subjectively decide about the weight to be given to each one. To remedy this situation, we present MOMEA , a Multi-Objective Mutation-based Evolutionary Algorithm that uses intelligent mutation operators and a dominance-based approach to generate a variety of alignments. Instead of considering a single objective that relates both similarities, MOMEA analyzes the topological and biological similarities as different objectives. The generated results are high-quality and varied non-dominated alignments, i.e., located in a wide area of the solution space. Finally, to demonstrate the effectiveness of this proposal, data from live organisms have been used in order to perform comparisons with several popular biological tools and with the unique existing multi-objective approach in the scientific literature. Comparison results are good and confirm a positive performance of MOMEA compared to all the other tools.},
  archive      = {J_ASOC},
  author       = {Irene Carrasco-Santano and Miguel A. Vega-Rodríguez},
  doi          = {10.1016/j.asoc.2022.109366},
  journal      = {Applied Soft Computing},
  pages        = {109366},
  shortjournal = {Appl. Soft. Comput.},
  title        = {MOMEA: Multi-objective mutation-based evolutionary algorithm for the alignment of protein networks},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on unsupervised learning for wearable sensor-based
activity recognition. <em>ASOC</em>, <em>127</em>, 109363. (<a
href="https://doi.org/10.1016/j.asoc.2022.109363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human Activity Recognition (HAR) is an essential task in various applications such as pervasive healthcare, smart environment, and security and surveillance. The need to develop accurate HAR systems has motivated researchers to propose various recognition models, feature extraction methods, and datasets. A lot of comprehensive surveys have been done on vision-based HAR, while few surveys have been done on sensor-based HAR. The few existing surveys on sensor-based HAR have focused on reviewing various feature extraction methods, the adoption of deep learning in activity recognition, and existing wearable acceleration sensors, among other areas. In recent times, state-of-the-art HAR models have been developed using wearable sensors due to the numerous advantages it offers over other modalities. However, one limitation of wearable sensors is the difficulty of annotating datasets during or after collection, as it tends to be laborious, time-consuming, and expensive. For this reason, recent state-of-the-art activity recognition models are being proposed using fully unlabelled datasets, an approach which is described as unsupervised learning . However, no existing sensor-based HAR surveys have focused on reviewing this recent adoption. To this end, this survey contributes by reviewing the evolution of activity recognition models, collating various types of activities, compiling over thirty activity recognition datasets, and reviewing the existing state-of-the-art models to leveraging fully unlabelled datasets in activity recognition. Also, this survey is the first attempt at a comprehensive review on the adoption of unsupervised learning in wearable sensor-based activity recognition. This will give researchers in this area a solid background and knowledge of the existing state-of-the-art models and an insight into the grand research areas that can still be explored.},
  archive      = {J_ASOC},
  author       = {Ayokunle Olalekan Ige and Mohd Halim Mohd Noor},
  doi          = {10.1016/j.asoc.2022.109363},
  journal      = {Applied Soft Computing},
  pages        = {109363},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A survey on unsupervised learning for wearable sensor-based activity recognition},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A content-based recommender system with consideration of
repeat purchase behavior. <em>ASOC</em>, <em>127</em>, 109361. (<a
href="https://doi.org/10.1016/j.asoc.2022.109361">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing popularity of online shopping and information explosion, personalized recommender systems for e-commerce become more and more necessary, which helps customers find the desired products efficiently among variety of categories based on their previous behavior such as buying pattern and rating history. However, most recommender systems for e-commerce adopt binary (purchase/non-purchase) or subjective weighting methods to represent the customer preferences, which is hard to predict their profiles precisely since rapid change in tastes. Therefore, this study focuses on the application of transactional data . A personalized recommender system for e-commerce (PROSE) is proposed in order to enhance the quality of recommendations by integrating the architecture of traditional content-based recommender system with a new component called feedback adjuster, which is designed to make customer implicit feedback reflects the reality of preferences as possible through taking into consideration their behavior of repeat purchase. The computational results indicate that the proposed algorithm is able to outperform other algorithms.},
  archive      = {J_ASOC},
  author       = {R.J. Kuo and Hong-Ruei Cheng},
  doi          = {10.1016/j.asoc.2022.109361},
  journal      = {Applied Soft Computing},
  pages        = {109361},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A content-based recommender system with consideration of repeat purchase behavior},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Large-scale group decision-making for prioritizing
engineering characteristics in quality function deployment under
comparative linguistic environment. <em>ASOC</em>, <em>127</em>, 109359.
(<a href="https://doi.org/10.1016/j.asoc.2022.109359">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quality function deployment (QFD) is a well-known tool for quality management . With its systematic operation mechanism for translating customer requirements (CRs) into corresponding engineering characteristics (ECs), QFD highly facilitates product/service design and improvement. However, the evolution of the decision-making environment has made the quantification within the traditional QFD operation could hardly able to meet the demanded efficiency as well as the accuracy of the generated results. To cope with the problem, an enhanced large-scale group decision-making method that integrates proportional hesitant fuzzy linguistic term sets (PHFLTSs) and the cumulative prospect theory (CPT) is put forward by this study to determine the ranking priority of ECs in doing QFD. To facilitate QFD team members carry out an easier and more accurate evaluation, they would use comparative linguistic expressions in making judgments, and the comparative linguistic expressions are subsequently transformed into hesitant fuzzy linguistic term sets (HFLTSs). The obtained HFLTSs are transformed into PHFLTSs based on the statistical method under a group decision-making environment for preventing information loss, and, at the same time, improving calculation accuracy. Taking decision-makers’ heterogeneity and risk attitudes into consideration, the CPT method is adopted and extended under the PHFL environment to prioritize the ECs in QFD operation. To illustrate how the proposed large-scale group decision-making-based QFD method is to be applied, a case study about solar photovoltaic cell development is presented. Furthermore, a comparative analysis is conducted to exhibit the effectiveness of the proposed QFD method.},
  archive      = {J_ASOC},
  author       = {Qiang Yang and Zhen-Song Chen and Catherine Y.P. Chan and Witold Pedrycz and Luis Martínez and Mirosław J. Skibniewski},
  doi          = {10.1016/j.asoc.2022.109359},
  journal      = {Applied Soft Computing},
  pages        = {109359},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Large-scale group decision-making for prioritizing engineering characteristics in quality function deployment under comparative linguistic environment},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Natural language report of the composting process status
using linguistic perception. <em>ASOC</em>, <em>127</em>, 109357. (<a
href="https://doi.org/10.1016/j.asoc.2022.109357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper presents an automated system to report the evolution of a process in natural language expressions, analyzing wireless sensor data with process patterns by the linguistic description of complex phenomena approach. An implemented system generates reports of the composting process using the temperature measured in the core of a compost pile regarding the temperature pattern during the composting phases. The linguistic reports include sentences about the current status, trend, and behavior of the composting process . The automated system posts each linguistic report via a messaging app, such as Twitter , allowing instant and continuous communication with authorized users on mobile devices . The resulting expressions show that this real-time linguistic report system is a suitable and practical framework to inform users of the process evolution, in preference and complement to a database or graph tools, supporting the users to make decisions for processes that require proper data-interpretation-based supervision.},
  archive      = {J_ASOC},
  author       = {Andrea de Anda-Trasviña and Alejandra Nieto-Garibay and Joaquín Gutiérrez},
  doi          = {10.1016/j.asoc.2022.109357},
  journal      = {Applied Soft Computing},
  pages        = {109357},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Natural language report of the composting process status using linguistic perception},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feature selection for online streaming high-dimensional
data: A state-of-the-art review. <em>ASOC</em>, <em>127</em>, 109355.
(<a href="https://doi.org/10.1016/j.asoc.2022.109355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge discovery for data streaming requires online feature selection to reduce the complexity of real-world datasets and significantly improve the learning process. This is achieved by selecting highly relevant subsets and minimising irrelevant and redundant features. However, researchers have difficulties in addressing various forms of data. The goal of this article is to present a state-of-the-art review of feature subset selection based on the data form for the high-dimensional data used in online streaming. Through a systematic literature review assessing journal and conference papers from the past five years, detailed discussions on traditional feature selection and online feature selection were presented. Subsequently, a taxonomy of the challenges related to OFS provides a comprehensive review of state-of-the-art OFS and the benchmark methods. Several data forms were identified based on the extensive review: group stream, multi-label, capricious, imbalance, and feature drift. Using critical analysis, the evaluation metrics of online feature selection methods were compared from the perspectives of threshold initialisation, accuracy, high dimensionality , running time, relevancy , and redundancy for the optimal feature subset. An online feature selection framework was derived to illustrate the relationship between the application area, data form, online feature selection methods, evaluation metrics , and tools. Finally, the findings and potential directions for future research were thoroughly discussed. It is suggested that future researchers explore the derived framework and aim to advance each method.},
  archive      = {J_ASOC},
  author       = {Ezzatul Akmal Kamaru Zaman and Azlinah Mohamed and Azlin Ahmad},
  doi          = {10.1016/j.asoc.2022.109355},
  journal      = {Applied Soft Computing},
  pages        = {109355},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Feature selection for online streaming high-dimensional data: A state-of-the-art review},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-objective missile boat scheduling problem using an
integrated approach of NSGA-II, MOEAD, and data envelopment analysis.
<em>ASOC</em>, <em>127</em>, 109353. (<a
href="https://doi.org/10.1016/j.asoc.2022.109353">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During peacetime, the missile boat squadron possesses rapidly deployable capacities for crisis response. The squadron conducts maritime reconnaissance and patrolling, safeguarding maritime safety and engaging in humanitarian assistance and disaster relief in the surrounding waters of Taiwan and the Asia Pacific region. To help the Navy efficiently schedule missile boats, this study models the problem as a multi-objective optimization and seeks to develop an integrated approach to optimizing the scheduling problem of a missile boat squadron. We applied a second-generation nondominated sorting genetic algorithm (NSGAII) and a multi-objective evolutionary algorithm based on decomposition (MOEAD) to search the approximated Pareto-optimal set for the problem efficiently. Then, a data envelopment analysis was used to identify super-efficiency solutions among these and rank them. An appropriate solution was then determined based on the relative efficiency instead of the decision-maker preferences. The results were substantiated using 20 datasets and reflected that the NSGAII can provide super-efficient solutions on the input-oriented model, and MOEAD demonstrated precedence in forming super-efficiency solutions in the output-oriented model.},
  archive      = {J_ASOC},
  author       = {Chun-Chih Chiu and Chyh-Ming Lai},
  doi          = {10.1016/j.asoc.2022.109353},
  journal      = {Applied Soft Computing},
  pages        = {109353},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-objective missile boat scheduling problem using an integrated approach of NSGA-II, MOEAD, and data envelopment analysis},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-input with multi-function activated weights and
structure determination neuronet for classification problems and
applications in firm fraud and loan approval. <em>ASOC</em>,
<em>127</em>, 109351. (<a
href="https://doi.org/10.1016/j.asoc.2022.109351">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neuronets trained by a weights-and-structure-determination (WASD) algorithm are known to resolve the shortcomings of traditional back-propagation neuronets such as slow training speed and local minimum. A multi-input multi-function activated WASD neuronet (MMA-WASDN) model is introduced in this paper, combined with a novel multi-function activated WASD (MA-WASD) algorithm, for handling binary classification problems. Using multiple power activation functions , the MA-WASD algorithm finds the optimal weights and structure of the MMA-WASDN and uses cross-validation to address bias and prevent being stuck in local optima during the training process. As a result, neuronets trained with the MA-WASD algorithm have higher precision and accuracy than neuronets trained with traditional WASD algorithms. Applications on firm fraud and loan approval classification validate our MMA-WASDN model in order to demonstrate its outstanding learning and predicting performance. Since these applications use real-world datasets that include strings and missing values, an algorithmic method for preparing data is also suggested to make them manageable from the MMA-WASDN. A comparison of the MMA-WASDN model to five other high-performing neuronet models is included, as well as a MATLAB package that is publicly available through GitHub to support and promote the findings of this research.},
  archive      = {J_ASOC},
  author       = {Theodore E. Simos and Vasilios N. Katsikis and Spyridon D. Mourtas},
  doi          = {10.1016/j.asoc.2022.109351},
  journal      = {Applied Soft Computing},
  pages        = {109351},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-input with multi-function activated weights and structure determination neuronet for classification problems and applications in firm fraud and loan approval},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Attention-based frequency-aware multi-scale network for
sequential recommendation. <em>ASOC</em>, <em>127</em>, 109349. (<a
href="https://doi.org/10.1016/j.asoc.2022.109349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The key problem of sequential recommendation is how to capture user sequential patterns and enrich user sequential representations from historical interactions, mainly due to the uncertainty of user behavior and the limited information. The RNN-based methods capture the long- and short-term level patterns. The CNN-based methods treat the representation of the user’s historical interaction as an “image”, and discover the point-level patterns, union-level patterns and union-level with skip once. The attention-based methods mine the focus-level patterns. However, all the previous methods have only studied how to capture users’ sequential patterns in the time domain. In many cases, if we only consider the time domain information, these methods will have trouble in mining the user’s sequential patterns. To solve this problem, we consider the frequency domain to capture frequency-level patterns for the first time. Because a non-periodic historical behavior sequence in the time domain may be brutal to reflect the user’s intention but much more accessible in the frequency domain. In light of this, we propose a novel A ttention-based F requency-aware M ulti-scale N etwork ( AFMN ) for Sequential Recommendation. We introduce Fourier transform to decompose the simple embedding vector, the representation of the user’s historical interaction, into a multi-frequency embedding vector to enrich the user’s behavior sequence representation. The frequency-aware attention layers adaptively focus on the important frequency components and output a refined multi-frequency embedding vector. Given the multi-frequency embedding vector, we develop a non-local attention module to aggregate attribute-level and item-level features of the previous L items. Empirical results on four public benchmark datasets show that our method can achieve a significant improvement over the state-of-the-art baselines.},
  archive      = {J_ASOC},
  author       = {Yichi Zhang and Guisheng Yin and Hongbin Dong and Liguo Zhang},
  doi          = {10.1016/j.asoc.2022.109349},
  journal      = {Applied Soft Computing},
  pages        = {109349},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Attention-based frequency-aware multi-scale network for sequential recommendation},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Using hill climb modular assembler encoding and differential
evolution to evolve modular neuro-controllers of an autonomous
underwater vehicle acting as a magnetic anomaly detector. <em>ASOC</em>,
<em>127</em>, 109347. (<a
href="https://doi.org/10.1016/j.asoc.2022.109347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order for any construction to arise on the sea bottom, the area around has to be carefully cleaned from all dangerous objects including ferromagnetic objects like ammunition or the remains of sea mines. Magnetic anomaly detectors (MAD) which are composed of a set of magnetometers are applied to detect such objects. The combined signal of all the magnetometers moving near the sea bottom is a base for detecting anomalies in the Earth magnetic field produced by ferromagnetic objects. To carry the magnetometers, underwater vehicles can be used. However, in order for the vehicles to be able to fulfill the role of MAD, they have to move near the sea bottom in a tight swarm formation. In the paper, a modular neuro-evolutionary controller is presented which leads each swarm member along a desired trajectory , with the time synchronization, and at the certain distance from the sea bottom. In order to design the controller, two neuro-evolutionary algorithms were applied, i.e. Hill Climb Modular Assembler Encoding (HCMAE) and Differential Evolution (DE). During tests carried out in simulation conditions, initially in 2D and then also in a 3D environment, under the influence of sea current, neuro-controllers evolved by HCMAE and DE were compared with algorithmic and PID-like controllers. The tests showed that the solutions proposed in the paper are more effective than the reference solutions and proved that even in unfavorable underwater conditions it is possible to precisely keep the trajectory specified both spatially and temporally.},
  archive      = {J_ASOC},
  author       = {Tomasz Praczyk},
  doi          = {10.1016/j.asoc.2022.109347},
  journal      = {Applied Soft Computing},
  pages        = {109347},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Using hill climb modular assembler encoding and differential evolution to evolve modular neuro-controllers of an autonomous underwater vehicle acting as a magnetic anomaly detector},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Support vector machine regression to predict gas diffusion
coefficient of biochar-amended soil. <em>ASOC</em>, <em>127</em>,
109345. (<a href="https://doi.org/10.1016/j.asoc.2022.109345">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measurement of gas diffusion coefficient (Dp) of biochar-amended soil (BAS) under varying conditions is essential for assessing the adsorption capacity and water/gas diffusion in compacted BAS. However, there is no established equation of Dp available on this topic. Also, the factors influencing gas diffusion in BAS have not been properly studied and remain unclear. Various machine learning models were employed in this paper to learn and predict the Dp of BAS based on experimental data. Six factors (i.e., degree of compaction (DOC), biochar content (BC), soil air content (SAC), gravimetric water content (GWC), degree of saturation (DS), and porosity) are considered for testing the prediction models. The epsilon radial basis function support vector regression model showed better accuracy and predictive performance ( R = 0 . 9925 R=0.9925 ) than other models and was further improved by applying the feature selection technique using the multiple linear regression and tree-based models ( R = 0 . 9937 R=0.9937 ). The results reveal that SAC, DS, and porosity are the main predictor variables . The SAC proved to be the most influential predictor variable based on the estimated p p -value. Furthermore, the optimal Dp was established for the various DOC and BC, which could be useful in designing engineered landfill covers. The accurate model prediction and relative importance of the predictor variables could significantly minimize the experimental work volume required to determine Dp, thereby saving time and cost.},
  archive      = {J_ASOC},
  author       = {Chikezie Chimere Onyekwena and Qiang Xue and Qi Li and Yong Wan and Song Feng and Happiness Ijeoma Umeobi and Hongwei Liu and Bowen Chen},
  doi          = {10.1016/j.asoc.2022.109345},
  journal      = {Applied Soft Computing},
  pages        = {109345},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Support vector machine regression to predict gas diffusion coefficient of biochar-amended soil},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Prediction of blasting induced air-overpressure using a
radial basis function network with an additional hidden layer.
<em>ASOC</em>, <em>127</em>, 109343. (<a
href="https://doi.org/10.1016/j.asoc.2022.109343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blasting operations are the most conventional and frequently used rock breakage approach in the field of Civil and Mining Engineering. However, the side effects induced by blasting may cause severe damages to surrounding areas. Air-overpressure (AOp) is one of the side effects induced by blasting operations, which is defined as the air pressure wave generated by blasting operation that exceeds normal atmospheric pressure. It can result in potential structural damage and glass breaking and therefore needs to be well predicted and subsequently minimized. In this study, 76 sets of blasting data were collected to develop a predictive model to estimate AOp value. However, due to the small size of dataset, it is hard to determine the complexity of the model. Therefore, for the purpose of developing a machine learning model with appropriate complexity, a radial basis function network with an additional second hidden layer (RBF-2) is proposed, which is trained by incremental design principle and modified Levenberg–Marquardt algorithm. The performance of the proposed RBF-2 is compared with those of five other machine learning techniques , i.e., multilayer perceptron (MLP), RBF, MLP optimized by genetic algorithm (GA-MLP), multi adaptive regression spline (MARS) and random forest (RF). The results demonstrate that the proposed RBF-2 network outperforms other models with RMSE of 2.02/1.98, MAPE of 1.32\%/1.40\%, and R R of 0.9828/0.9735 in training/testing stage. Findings revealed that the proposed RBF-2 network emerged as the most efficient, powerful and robust technique in predicting blast induced AOp compared with other machine learning models.},
  archive      = {J_ASOC},
  author       = {Ruixuan Zhang and Yuefeng Li and Yilin Gui and Jian Zhou},
  doi          = {10.1016/j.asoc.2022.109343},
  journal      = {Applied Soft Computing},
  pages        = {109343},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Prediction of blasting induced air-overpressure using a radial basis function network with an additional hidden layer},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mixed-model assembly line balancing problem considering
preventive maintenance scenarios: MILP model and cooperative
co-evolutionary algorithm. <em>ASOC</em>, <em>127</em>, 109341. (<a
href="https://doi.org/10.1016/j.asoc.2022.109341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering preventive maintenance (PM) scenarios in assembly line balancing (ALB) problem has been proven to be an effective way to promote line efficiency. However, previous research only focused on the single-model assembly line and ignored the mixed-model assembly line, resulting in the line cannot meet the growing customization needs of customers. This paper addresses the mixed-model ALB considering PM scenarios (MALB_PMs). A mixed-integer mathematical formulation is proposed to optimize the cycle time and task alteration. The cooperative co-evolutionary algorithm is introduced to simplify the large-scaled cases via the powerful divide-and-conquer architecture and is enhanced with four improvements. An archive is generated to save complete solutions with better performance and evaluate the fitness of solutions. A mixed-model variable step-size decoding method is designed to speed up the decoding process of the algorithm. One inter-population crossover operator is designed to enhance the communication among sub-problems. Four objective-oriented neighbor search operators are proposed to promote the convergence performance of the algorithm. Finally, three small-scale instances are employed to illustrate the application of the mathematical model, and 39 cases are designed to test the performance of the developed algorithm. Experiment results demonstrate that the proposed mathematical formulation can obtain the Pareto solutions of small-scaled instances; The developed algorithm outperforms other algorithms on three criteria; The Pareto front obtained by this algorithm is closer to the True Pareto front .},
  archive      = {J_ASOC},
  author       = {Kai Meng and Qiuhua Tang and Lixin Cheng and Zikai Zhang},
  doi          = {10.1016/j.asoc.2022.109341},
  journal      = {Applied Soft Computing},
  pages        = {109341},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Mixed-model assembly line balancing problem considering preventive maintenance scenarios: MILP model and cooperative co-evolutionary algorithm},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). A genetic algorithm with jumping gene and heuristic
operators for traveling salesman problem. <em>ASOC</em>, <em>127</em>,
109339. (<a href="https://doi.org/10.1016/j.asoc.2022.109339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the problems of slow convergence speed, low solution quality, and easily falling into a local optimum in solving traveling salesman problem (TSP) with genetic algorithm (GA), a genetic algorithm with jumping gene and heuristic operators (GA-JGHO) is proposed, which contains five modifications: (1) an improved roulette selection of combined fitness function is proposed to maintain population diversity and strengthen the exploitation ability, which is helpful to overcome the low population diversity with the standard roulette selection; (2) a bidirectional heuristic crossover (BHX) operator is proposed, which aims to increase the possibility of the potential offspring produced by crossover operation; (3) the combination mutation operator is presented to balance the exploration and exploitation ability; (4) a jumping gene operator is designed, which is beneficial to expand the searching space and reduce the possibility of falling into a local optimum; (5) a unique operator is added to avoid the occurrence of nimiety identical individuals in the population. Besides, the local search operator is integrated to enhance exploitation ability. Moreover, a large number of instances from TSPLIB and a real-world path optimization problem of the cruise robot are selected to verify the validity of the modifications and the potential of GA-JGHO. Experimental results and statistical analyses demonstrate that GA-JGHO performs better in quality stability, accuracy, and convergence speed compared with the other six algorithms.},
  archive      = {J_ASOC},
  author       = {Panli Zhang and Jiquan Wang and Zhanwei Tian and Shengzhi Sun and Jianting Li and Jingnan Yang},
  doi          = {10.1016/j.asoc.2022.109339},
  journal      = {Applied Soft Computing},
  pages        = {109339},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A genetic algorithm with jumping gene and heuristic operators for traveling salesman problem},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hierarchical attention-based context-aware network for red
tide forecasting. <em>ASOC</em>, <em>127</em>, 109337. (<a
href="https://doi.org/10.1016/j.asoc.2022.109337">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chlorophyll forecasting is helpful for understanding characteristics of red tides, thus enabling early warning. In practice, it is formulated as a time series forecasting problem, which aims to predict the future chlorophyll concentration with the observation of various exogenous factors (e.g., PH, turbidity, etc.) and corresponding historical chlorophyll. However, existing methods hardly satisfy the chlorophyll forecasting because the interaction in observed data are complicated and changeable. In this work, we propose a fine-grained hierarchical attention-based context-aware network. The model consists of two hierarchical attention networks , with one named EF-net focusing on exogenous factors and the other named TF-net executing on chlorophyll. EF-net introduces factor-level and sequence-level attention to learn exogenous factors and time steps that are beneficial to prediction. TF-net firstly conducts context-aware attention to capture the interaction in historical time series from EF-net. Then a specially designed contextual long short-term memory network employs the interactive information to benefit the accuracy for chlorophyll. To suppress noisy information, we employ a gated fusion method to fuse the outputs of EF-net and TF-net. Experiments with two real world data sets show that our proposed model achieves 16.02\%, 10.65\%, and 22.45\% improvements in average MAE , RMSE , and MAPE in seven-step-ahead predictions compared with baseline methods . Visualization of attention weights shows that sea surface temperature, air temperature, standard atmospheric pressure , and PH are significant for chlorophyll prediction.},
  archive      = {J_ASOC},
  author       = {Xiaoyu He and Suixiang Shi and Xiulin Geng and Lingyu Xu},
  doi          = {10.1016/j.asoc.2022.109337},
  journal      = {Applied Soft Computing},
  pages        = {109337},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Hierarchical attention-based context-aware network for red tide forecasting},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Rotating machinery faults detection method based on deep
echo state network. <em>ASOC</em>, <em>127</em>, 109335. (<a
href="https://doi.org/10.1016/j.asoc.2022.109335">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to develop an accurate and efficient end-to-end fault detection model trained by small-scale data for the rotating machinery . The echo state network (ESN) is promising thanks to the training process by linear regression, but it struggles in mining spatial information. Thus, a deep ESN based on fixed convolution kernels (FCK-DESN) is proposed. The Prewitt, the Sobel, and the Gaussian lowpass filters are designed as the fixed convolution kernels for spatial feature extraction without training. The one hidden layer autoencoder is built to compress the dimensionality and improve the applicability. Based on the pre-process modules, the ESN could realize pattern recognition under complex conditions. The fault detection approach is then constructed based on the time–frequency information provided by the smoothed pseudo-Wigner–Ville distribution. Case studies of a rotor-bearing system and a diesel engine show that the proposed FCK-DESN approach has better recognition rates than popular deep learning methods with high efficiency and lower data size requirements, which has more practical significance.},
  archive      = {J_ASOC},
  author       = {Xin Li and Fengrong Bi and Lipeng Zhang and Jiewei Lin and Xiaobo Bi and Xiao Yang},
  doi          = {10.1016/j.asoc.2022.109335},
  journal      = {Applied Soft Computing},
  pages        = {109335},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Rotating machinery faults detection method based on deep echo state network},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive dynamic surrogate-assisted evolutionary computation
for high-fidelity optimization in engineering. <em>ASOC</em>,
<em>127</em>, 109333. (<a
href="https://doi.org/10.1016/j.asoc.2022.109333">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surrogate-assisted evolutionary computation have received much more attention in the field of optimization because of its ability to reduce effectively the CPU cost. However, as the dimension of the search space increases, the number of samples required to construct the global accurate surrogate model will increase exponentially. In order to improve the computational efficiency for achieving high-precision optimization in high-dimensional search space, an adaptive dynamic surrogate-assisted evolutionary computation approach based on variable search region is presented in this paper. The basic idea of the present method is to abandon the high accurate approximation of surrogate model on the global search space which requires a large number of samples, but focus on the search of the smaller local region where the optimal solution is located. Then refine the samples to construct a higher-precision local surrogate model on the smaller local search region, which moves with the movement of the current optimal solution. Numerical experiments show that the highly accurate optimal solution can be obtained by less than five times of adaptation. It is also applied successfully to the aerodynamic shape design optimization of transonic airfoil and wing, and the results show that present adaptive approach greatly improves the computational efficiency by about ten times compared with the traditional static global approximation surrogate model.},
  archive      = {J_ASOC},
  author       = {Zhili Tang and Liang Xu and Shaojun Luo},
  doi          = {10.1016/j.asoc.2022.109333},
  journal      = {Applied Soft Computing},
  pages        = {109333},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Adaptive dynamic surrogate-assisted evolutionary computation for high-fidelity optimization in engineering},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A neural network compression method based on
knowledge-distillation and parameter quantization for the bearing fault
diagnosis. <em>ASOC</em>, <em>127</em>, 109331. (<a
href="https://doi.org/10.1016/j.asoc.2022.109331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Condition monitoring and fault diagnosis have been critical for the optimal scheduling of machines, improving the system reliability and the reducing maintenance cost . In recent years, various of methods based on the deep learning method have made the great progress in the field of the mechanical fault diagnosis. However, there is a conflict between the massive parameters of the fault diagnosis networks and the limited computing resource of the embedded platforms. It is difficult to deploy the trained network on the small scale embedded platforms (like field programmable gate array (FPGA)) in the actual industrial situations. This seriously hinders the practical process of the intelligent fault diagnosis method . To address this problem, a new neural network compression method based on knowledge-distillation (K-D) and parameter quantization is proposed in this paper. In the proposed method, a large scale deep neural network with multiple convolutional layers and fully-connected layers is designed and trained as the teacher network. Then a small scale network with just one convolutional layer and one fully-connected layer is designed as the student network. When training the student network, the K-D process is conducted to improve the accuracy of the student network. After the training process, the parameter quantization is conducted to further compress the scale of the student network. Experimental results on the field programmable gate array (FPGA) are presented to demonstrate the effectiveness of the proposed method. The results show that the proposed method can greatly compress the scales of the fault diagnosis networks for over 10 times at the cost of the minimal loss of the accuracy.},
  archive      = {J_ASOC},
  author       = {Mengyu Ji and Gaoliang Peng and Sijue Li and Feng Cheng and Zhao Chen and Zhixiong Li and Haiping Du},
  doi          = {10.1016/j.asoc.2022.109331},
  journal      = {Applied Soft Computing},
  pages        = {109331},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A neural network compression method based on knowledge-distillation and parameter quantization for the bearing fault diagnosis},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Variable speed multi-task allocation for mobile crowdsensing
based on a multi-objective shuffled frog leaping algorithm.
<em>ASOC</em>, <em>127</em>, 109330. (<a
href="https://doi.org/10.1016/j.asoc.2022.109330">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-task studies of mobile crowdsensing, the possibility that a user may adopt another travel mode when completing the current task to the next is ignored. In addition, existing methods tend to allocate more tasks to the users with high reputation, which causes that few tasks will be assigned to new users with low reputation. In order to cover these shortages, a constrained multi-objective optimization model of variable speed multi-task allocation is established, which aims to maximize the user rewards and minimize the task completion time simultaneously. Meanwhile, the maximum number of fully paid tasks positively correlated with reputation is set for each user. To solve the constructed model, a three-stage multi-objective shuffled frog leaping algorithm is proposed, which introduces an objective anchored hybrid initialization operator based on heuristic information , a region mining strategy for the archive individuals, a discrete leaping rule to enhance the interaction of individual information and a constraint handling operator to reduce the loss of individual information. The performance of the proposed algorithm is evaluated by comparing it with five state-of-the-art algorithms on both real-world and synthetic instances. Experimental results show that the proposed algorithm can find a set of Pareto optimal allocation solutions with better convergence and distributions.},
  archive      = {J_ASOC},
  author       = {Xiaoning Shen and Qingzhou Chen and Hongli Pan and Liyan Song and Yinan Guo},
  doi          = {10.1016/j.asoc.2022.109330},
  journal      = {Applied Soft Computing},
  pages        = {109330},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Variable speed multi-task allocation for mobile crowdsensing based on a multi-objective shuffled frog leaping algorithm},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Environmentally sound short-term hydrothermal generation
scheduling using intensified water cycle approach. <em>ASOC</em>,
<em>127</em>, 109327. (<a
href="https://doi.org/10.1016/j.asoc.2022.109327">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an intensified water cycle approach (IWCA) to realize an environmentally sound optimal generation schedule for short-term hydrothermal systems over a day’s time horizon considering the conflicting economic and environmental aspects of thermal units. The equality constraints of the active power balance and full utilization of the available amount of water are handled independently using proportional sharing heuristics. The global solution accuracy and convergence rate of stochastic algorithms are significantly affected by parameter-tuning, exploration, and exploitation strategies. For intensifying the algorithm, opposition-based learning and local search are integrated with a chaotically tuned water cycle algorithm based on the natural flow of water toward the sea to balance exploration and exploitation. The numerical results show an improvement in the unified operating cost obtained from the price penalty factor to include the impact of gaseous pollutants and in the convergence performance metrics over the existing methods. The competence of the proposed approach is confirmed through illustrations of standard benchmark problems (unimodal, multimodal, and fixed dimension multimodal) and standard hydrothermal test systems. The performance of the proposed algorithm is substantiated through statistical significance tests, which include convergence curves, whisker box plots, and Wilcoxon signed-rank test.},
  archive      = {J_ASOC},
  author       = {Ashok Kumar and J.S. Dhillon},
  doi          = {10.1016/j.asoc.2022.109327},
  journal      = {Applied Soft Computing},
  pages        = {109327},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Environmentally sound short-term hydrothermal generation scheduling using intensified water cycle approach},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A three-dimensional ant colony optimization algorithm for
multi-compartment vehicle routing problem considering carbon emissions.
<em>ASOC</em>, <em>127</em>, 109326. (<a
href="https://doi.org/10.1016/j.asoc.2022.109326">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A three-dimensional ant colony optimization algorithm (TDACO) is proposed to solve the multi-compartment vehicle routing problem (MCVRP) arising in many industries, such as petrol station replenishment , cold chain logistics, and waste collection. The objective of this problem to be minimized is the total transportation cost including the consideration of carbon emissions (TC_CE). In TDACO, a new three-dimensional pheromone concentration matrix is first presented to learn and accumulate the valuable information from excellent individuals or ants. Then, to make the algorithm have high-quality search in the initial stage, five heuristic rules are designed to initialize the pheromone concentration matrix and construct the initial population or colony. In addition, the vehicle capacity rate and carbon emissions are brought into the state transition rule to reasonably guide the global search towards the promising solutions or regions. Moreover, an adaptive local search with the speed-up search strategy and the first move strategy is devised to perform effective exploitation from the promising regions. Finally, comparative experiments on benchmark problem instances with different scales are conducted, and the superior performance of the proposed TDACO is verified.},
  archive      = {J_ASOC},
  author       = {Ning Guo and Bin Qian and Jing Na and Rong Hu and Jian-Lin Mao},
  doi          = {10.1016/j.asoc.2022.109326},
  journal      = {Applied Soft Computing},
  pages        = {109326},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A three-dimensional ant colony optimization algorithm for multi-compartment vehicle routing problem considering carbon emissions},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fuzzy time series model based on red–black trees for stock
index forecasting. <em>ASOC</em>, <em>127</em>, 109323. (<a
href="https://doi.org/10.1016/j.asoc.2022.109323">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasting data is still an extensively investigated area of research specially in stock markets. The subjectivity of the elements that influence the market oscillation is the main challenge that any forecasting model faces . In this context, existing fuzzy models have attempted to increase forecasting accuracy in financial markets over the years. Fuzzy returns of the phenomenon under investigation helps to mitigate the subjective part of the financial market, specially regarding the human feeling influence over it. Although there are several data structures that can help to define the proper clusters from the universe of discourse of a fuzzy model, this paper proposes a novel fuzzy model from which the universe of discourse is based on a red–black tree (RBT) data structure so as to increase the possibilities of obtaining better predictions. The RBT data structure is a binary search three data structure that promotes a better balance, which allows a better accuracy in the forecasting results. The proposed model is compared to well known fuzzy models in the literature showing better forecasting results.},
  archive      = {J_ASOC},
  author       = {Thiago Henrique Barbosa de Carvalho Tavares and Bruno Pérez Ferreira and Eduardo Mazoni Andrade Marçal Mendes},
  doi          = {10.1016/j.asoc.2022.109323},
  journal      = {Applied Soft Computing},
  pages        = {109323},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fuzzy time series model based on red–black trees for stock index forecasting},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Classification rule mining based on pareto-based
multiobjective optimization. <em>ASOC</em>, <em>127</em>, 109321. (<a
href="https://doi.org/10.1016/j.asoc.2022.109321">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel classification rule mining model based on Pareto-based Multiobjective Optimization called CRM-PM. The process of rule extraction is a challenging classification task in data mining since it has several constraints and conflicting objectives such as accuracy and comprehensibility . In this study, this task is accepted as a multi-objective optimization problem. Classification accuracy and misclassification ratio are assigned as evaluation criteria. The candidate solutions are generated in the direction of a proposed strategy to determine optimal ranges of the attributes that form the rules. The proposed approach is applied on eight benchmark datasets (Iris Plants, Wine Quality, Glass Identification, Stat log (Heart), Haberman’s Survival, E-coli, Wisconsin Breast Cancer, and Pima Indians Diabetes) included in the University of California at Irvine machine learning repository. Furthermore, CRM-PM is run in three different validation modes: cross-validation, training without test data, and training with random splitting. Regarding experimental results, it can be said that the presented method has a promising capability for classification, and it achieves comparative or superior results.},
  archive      = {J_ASOC},
  author       = {Tahir Sağ and Humar Kahramanlı Örnek},
  doi          = {10.1016/j.asoc.2022.109321},
  journal      = {Applied Soft Computing},
  pages        = {109321},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Classification rule mining based on pareto-based multiobjective optimization},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DTLMV2—a real-time deep transfer learning mask classifier
for overcrowded spaces. <em>ASOC</em>, <em>127</em>, 109313. (<a
href="https://doi.org/10.1016/j.asoc.2022.109313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Through the commencement of the COVID-19 pandemic, the whole globe is in disarray and debating on unique approaches to stop this viral transmission. Masks are being worn by people all around the world as one of the preventative measures to avoid contracting this sickness. Although some people are following and adopting this precaution, others are not, despite official recommendations from the administration and public health organisations has been announced. In this paper DTLMV2 (Deep Transfer Learning MobileNetV2 for the objective of classification) is proposed - A face mask identification model that can reliably determine whether an individual is wearing a mask or not is suggested and implemented in this work. The model architecture employs the peruse of MobileNetV2, a lightweight Convolutional Neural Network (CNN) that requires less computing power and can be readily integrated into computer vision and mobile systems. The computer vision with MobileNet is required to formulate a low-cost mask detection system for a group of people in open spaces that can assist in determining whether a person is wearing a mask or not, as well as function as a surveillance system since it is effective on both real-time pictures and videos. The face recognition model obtained 97.01\% accuracy on validation data, 98\% accuracy on training data and 97.45\% accuracy on testing data.},
  archive      = {J_ASOC},
  author       = {Meenu Gupta and Gopal Chaudhary and Dhruvi Bansal and Shashwat Pandey},
  doi          = {10.1016/j.asoc.2022.109313},
  journal      = {Applied Soft Computing},
  pages        = {109313},
  shortjournal = {Appl. Soft. Comput.},
  title        = {DTLMV2—A real-time deep transfer learning mask classifier for overcrowded spaces},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). 2D self-organized ONN model for handwritten text
recognition. <em>ASOC</em>, <em>127</em>, 109311. (<a
href="https://doi.org/10.1016/j.asoc.2022.109311">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Convolutional Neural Networks (CNNs) have recently reached state-of-the-art Handwritten Text Recognition (HTR) performance. However, recent research has shown that typical CNNs’ learning performance is limited since they are homogeneous networks with a simple (linear) neuron model. With their heterogeneous network structure incorporating non-linear neurons, Operational Neural Networks (ONNs) have recently been proposed to address this drawback. Self-ONNs are self-organized variations of ONNs with the generative neuron model that can generate any non-linear function using the Taylor approximation . In this study, in order to improve the state-of-the-art performance level in HTR, the 2D Self-organized ONNs (Self-ONNs) in the core of a novel network model are proposed. Moreover, deformable convolutions, which have recently been demonstrated to tackle variations in the writing styles better, are utilized in this study. The results over the IAM English dataset and HADARA80P Arabic dataset show that the proposed model with the operational layers of Self-ONNs significantly improves Character Error Rate (CER) and Word Error Rate (WER). Compared with its counterpart CNNs, Self-ONNs reduce CER and WER by 1.2\% and 3.4\% in the HADARA80P and 0.199\% and 1.244\% in the IAM dataset. The results over the benchmark IAM demonstrate that the proposed model with the operational layers of Self-ONNs outperforms recent deep CNN models by a significant margin while the use of Self-ONNs with deformable convolutions demonstrates exceptional results.},
  archive      = {J_ASOC},
  author       = {Hanadi Hassen Mohammed and Junaid Malik and Somaya Al-Maadeed and Serkan Kiranyaz},
  doi          = {10.1016/j.asoc.2022.109311},
  journal      = {Applied Soft Computing},
  pages        = {109311},
  shortjournal = {Appl. Soft. Comput.},
  title        = {2D self-organized ONN model for handwritten text recognition},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep imbalanced regression using cost-sensitive learning and
deep feature transfer for bearing remaining useful life estimation.
<em>ASOC</em>, <em>127</em>, 109271. (<a
href="https://doi.org/10.1016/j.asoc.2022.109271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) techniques have revolutionized the landscape of prognostic and health management (PHM), with the capability to learn discriminative representations from “big data”. However, realistic industry data often show imbalanced distributions, which greatly weakens the method relying on manually balanced datasets. To fill the research gap of bearing remaining useful life (RUL) estimation with imbalanced data , a novel framework is proposed to learn imbalanced regression using cost-sensitive learning and deep feature transfer (CSL-DFT), which introduces the idea of discretization and makes full use of techniques of imbalanced learning. Our CSL-DFT includes these main points: discretization &amp; label distribution smoothing, deep feature transfer via CORrelation ALignment (CORAL), and cost-sensitive learning via class-balanced re-weighting. Considering this is the first application of deep imbalanced regression (DIR) in RUL prediction, a variety of imbalanced bearing training sets are designed based on experimental data, and verified the effectiveness of CSL-DFT. Comparison with other methods further shows its superior performance and rationality of design.},
  archive      = {J_ASOC},
  author       = {Yifei Ding and Minping Jia and Jichao Zhuang and Peng Ding},
  doi          = {10.1016/j.asoc.2022.109271},
  journal      = {Applied Soft Computing},
  pages        = {109271},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Deep imbalanced regression using cost-sensitive learning and deep feature transfer for bearing remaining useful life estimation},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Investigation of benchmark dataset for many-objective
multi-skill resource constrained project scheduling problem.
<em>ASOC</em>, <em>127</em>, 109253. (<a
href="https://doi.org/10.1016/j.asoc.2022.109253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper presents a redefinition of Multi-Skill Resource-Constrained Project Scheduling Problem (MS-RCPSP) as a many-objective optimization problem . In effect, it brings the problem closer to real-world applications. Five objectives have been defined: cost, duration, average cash flow, average usage of resources and skill overuse. To summarize MS-RCPSP usage, the paper presents a short survey (years 2015–2021) of multi- and many-objective MS–RCPSP solving methods. Moreover, results of investigation of many-objective MS–RCPSP for classic (greedy algorithm, Unified Non-dominated Sorting Genetic Algorithm III (U-NSGA-III)), single objective (decomposition-based) Differential Evolution And Greedy (DEGR) and state-of-the-art Non-dominated Tournament Genetic Algorithm (NTGA2) have been presented. Additionally, results are analysed using multi-objective quality measures (such as Pareto Front Size (PFS), Purity or Inverted Generational Distance (IGD)) to verify the efficiency of the used methods. The paper answers 4 research questions that investigate 5-objective MS-RCPSP domains, approximations of Pareto Fronts, relations between objectives and efficiency of NTGA2 compared to other methods. Finally, the paper is concluded with a summary and propositions for future work.},
  archive      = {J_ASOC},
  author       = {Paweł B. Myszkowski and Maciej Laszczyk},
  doi          = {10.1016/j.asoc.2022.109253},
  journal      = {Applied Soft Computing},
  pages        = {109253},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Investigation of benchmark dataset for many-objective multi-skill resource constrained project scheduling problem},
  volume       = {127},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Chest x-ray analysis empowered with deep learning: A
systematic review. <em>ASOC</em>, <em>126</em>, 109319. (<a
href="https://doi.org/10.1016/j.asoc.2022.109319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chest radiographs are widely used in the medical domain and at present, chest X-radiation particularly plays an important role in the diagnosis of medical conditions such as pneumonia and COVID-19 disease. The recent developments of deep learning techniques led to a promising performance in medical image classification and prediction tasks. With the availability of chest X-ray datasets and emerging trends in data engineering techniques, there is a growth in recent related publications. Recently, there have been only a few survey papers that addressed chest X-ray classification using deep learning techniques. However, they lack the analysis of the trends of recent studies. This systematic review paper explores and provides a comprehensive analysis of the related studies that have used deep learning techniques to analyze chest X-ray images. We present the state-of-the-art deep learning based pneumonia and COVID-19 detection solutions, trends in recent studies, publicly available datasets, guidance to follow a deep learning process, challenges and potential future research directions in this domain. The discoveries and the conclusions of the reviewed work have been organized in a way that researchers and developers working in the same domain can use this work to support them in taking decisions on their research.},
  archive      = {J_ASOC},
  author       = {Dulani Meedeniya and Hashara Kumarasinghe and Shammi Kolonne and Chamodi Fernando and Isabel De la Torre Díez and Gonçalo Marques},
  doi          = {10.1016/j.asoc.2022.109319},
  journal      = {Applied Soft Computing},
  pages        = {109319},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Chest X-ray analysis empowered with deep learning: A systematic review},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A dual-stage advanced deep learning algorithm for long-term
and long-sequence prediction for multivariate financial time series.
<em>ASOC</em>, <em>126</em>, 109317. (<a
href="https://doi.org/10.1016/j.asoc.2022.109317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-term and long-sequence prediction for multivariate time series (MTS) data is an important and challenging problem. The key to solving this problem is learning the long-term dependency period in a time series. Different attention-based models like RNN variants and transformers are actively researched to provide short-term and long-term predictions for a time series. These attention-based models consider time series as sequential data. They are not designed to learn the different characteristics (trends, seasonality, and irregularity) of a time series. The complex temporal patterns of data prohibit these models from finding a reliable period of dependency. This paper proposes a dual-stage advanced deep learning framework (DST2V-TRANSFORMER), which exploits moving average smoothing, the percentage change in data, and time embedding to improve transformers for time series forecasting. In the first stage, data is smoothened using the moving average method , and to learn the periodic and non-periodic temporal patterns in time series, a vector representation for time is added as a feature to the data. This preprocessed data is passed through a transformer to learn temporal correlation and find the reliable period of dependency. The DST2V-TRANSFORMER achieves state-of-the-art efficiency and accuracy, with at least a 49\% relative improvement in error on seven MTS datasets from the financial domain.},
  archive      = {J_ASOC},
  author       = {Preeti and Rajni Bala and Ram Pal Singh},
  doi          = {10.1016/j.asoc.2022.109317},
  journal      = {Applied Soft Computing},
  pages        = {109317},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A dual-stage advanced deep learning algorithm for long-term and long-sequence prediction for multivariate financial time series},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-output spatio-temporal air pollution forecasting using
neural network approach. <em>ASOC</em>, <em>126</em>, 109316. (<a
href="https://doi.org/10.1016/j.asoc.2022.109316">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-step ahead pollution forecasting has an essential role in mitigating health risks. Multi-Input and Multi-Output (MIMO) multi-step forecasting is valuable, especially for long-term pollution forecasting. Multi-output pollution forecasting results help comprehend the overall idea of a particular location’s air quality level for a better environmental decision-making process. The traditional single output forecasting techniques include each step’s errors and ignore its prediction values for multi-step ahead forecasting. The proposed Multi-Output Long Short-Term Memory Auto-Encoder (M-LSTMA) with the MIMO approach accumulates each step prediction value to conduct multi-step forecasting in light of this challenge. In addition to that, the proposed model utilized a multiple imputation approach to handle the missing values of the dataset and employed both the climate and spatial attributes to improve forecasting results. Overall, the results demonstrate that the M-LSTMA model improves forecasting accuracy more significantly than the baseline models , proving its efficiency for long-term Spatio-temporal forecasting.},
  archive      = {J_ASOC},
  author       = {K. Krishna Rani Samal and Korra Sathya Babu and Santos Kumar Das},
  doi          = {10.1016/j.asoc.2022.109316},
  journal      = {Applied Soft Computing},
  pages        = {109316},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-output spatio-temporal air pollution forecasting using neural network approach},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Forecasting daily covid-19 cases in the world with a hybrid
ARIMA and neural network model. <em>ASOC</em>, <em>126</em>, 109315. (<a
href="https://doi.org/10.1016/j.asoc.2022.109315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of models to predict disease cases is common in epidemiology and related areas, in the context of Covid-19, both ARIMA and Neural Network models can be applied for purposes of optimized resource management, so the aim of this study is to capture the linear and non-linear structures of daily Covid-19 cases in the world by using a hybrid forecasting model. In summary, the proposed hybrid system methodology consists of two steps. In the first step, an ARIMA model is used to analyze the linear part of the problem. In the second step, a neural network model is developed to model the residuals of the ARIMA model, which would be the non-linear part of it. The neural network model was superior to the ARIMA when considering the capture of weekly seasonality and in two weeks, the combination of models with the capture of seasonality in two weeks provided a mixed model with good error metrics, that allows actions to be premeditated with greater certainty, such as increasing the number of nurses in a location, or the acceleration of vaccination campaigns to diminish a possible increase in the number of cases.},
  archive      = {J_ASOC},
  author       = {Lucas Rabelo de Araújo Morais and Gecynalda Soares da Silva Gomes},
  doi          = {10.1016/j.asoc.2022.109315},
  journal      = {Applied Soft Computing},
  pages        = {109315},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Forecasting daily covid-19 cases in the world with a hybrid ARIMA and neural network model},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fault analysis of photovoltaic based DC microgrid using deep
learning randomized neural network. <em>ASOC</em>, <em>126</em>, 109314.
(<a href="https://doi.org/10.1016/j.asoc.2022.109314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The implementation of solar photovoltaic (PV) based Direct Current (DC) microgrid is limited due to lack of well-defined protection standards. These low voltage DC distribution networks are facing implementation challenges especially under multi-distributed generations subjected to various events such as PV arc faults , load switching faults, PV partial shading, change in PV irradiance and DC cable faults, etc. Thus a new deep learning neural network model is proposed for the accurate fault classification and distance calculation for an effective monitoring and protection coordination of photovoltaic based DC microgrid . The proposed model is the combination of an Adaptive variational mode decomposition (AVMD) and deep minimum variance random vector functional link network (DRVFLN). The optimal parameters of AVMD are selected using chaotic sine–cosine firefly algorithm (CSCFA) and efficient weighted kurtosis index (EWKU). Further, a novel non-iterative DRVFLN network is applied for accurate fault classification and location. In the DRVFLN direct connections are present from preceding layers to the forward layers of the network like random vector functional link network. These connections help to reduce the model complexity and also regularize the randomization . Further, the denoising criterion is also introduced in this network where the uncorrupted input can be recovered from the corrupted versions by using the autoencoder to obtained better results than the traditional networks. The performances of various models are evaluated using some performance index such as overall accuracy and sensitivity. Results conclude that the proposed AVMD-DRVFLN model classified the faults with an accuracy and sensitivity of 100\% for all the events. The model performance is also tested and validated against the unwanted noise by considering different signal-to-noise ratio to ensure the robustness of the proposed model. Results conclude that the proposed model correctly classified the faults against such incorporation of noise. Similarly, the performances of various models for the estimation of fault distance are validated by computing the relative error. Results conclude that the proposed AVMD-DRVFLN model produces promising result in terms of relative error(which is less than 5\%) for all the events. Comparisons with some existing models like extreme learning machine , support vector machine , random vector functional link network and deep extreme learning machine are included to validate the efficacy of the proposed AVMD-DRVFLN model. Results conclude that proposed method outperforms all the other methods. The effectiveness of the proposed AVMD-DRVFLN model for fault classification and distance estimation is established through rigorous case studies in MATLAB augmented by some real time test results.},
  archive      = {J_ASOC},
  author       = {Ravi Kumar Jalli and S.P. Mishra and P.K. Dash and Jyotirmayee Naik},
  doi          = {10.1016/j.asoc.2022.109314},
  journal      = {Applied Soft Computing},
  pages        = {109314},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fault analysis of photovoltaic based DC microgrid using deep learning randomized neural network},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Weighted random k satisfiability for k=1, 2 (r2SAT) in
discrete hopfield neural network. <em>ASOC</em>, <em>126</em>, 109312.
(<a href="https://doi.org/10.1016/j.asoc.2022.109312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current studies on non-systematic satisfiability in Discrete Hopfield Neural Network are able to avoid production of repetitive final neuron states which improves the quality of global solutions retrieved. This finding has made it possible to obtain diverse final neuron states without additional modifications in Discrete Hopfield Neural Network . However, non-systematic satisfiability exhibited a drawback for neglecting the distribution of positive and negative literals in the logical structure as a neuron representation. Thus, this paper considers a new class of non-systematic satisfiability logic named Weighted Random k Satisfiability for k = 1 , 2 k=1, 2 with an inclusive of weighted ratio of negative literals. A logic phase is proposed as an organized layer to assign the distribution of negative literals unbiasedly by using Genetic Algorithm . The performance of Genetic Algorithm in producing the right structure of Weighted Random k Satisfiability will be compared with exhaustive search . Additionally, the training capability of Discrete Hopfield Neural Network to minimize the cost function will be investigated by embedding state of the art metaheuristics . Overall analysis demonstrated the effect of different ratios of negative literals and advanced training algorithm positively impacted the synaptic weight management and production of global minima solutions.},
  archive      = {J_ASOC},
  author       = {Nur Ezlin Zamri and Siti Aishah Azhar and Mohd. Asyraf Mansor and Alyaa Alway and Mohd Shareduwan Mohd Kasihmuddin},
  doi          = {10.1016/j.asoc.2022.109312},
  journal      = {Applied Soft Computing},
  pages        = {109312},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Weighted random k satisfiability for k=1, 2 (r2SAT) in discrete hopfield neural network},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pigeon-inspired fuzzy multi-objective task allocation of
unmanned aerial vehicles for multi-target tracking. <em>ASOC</em>,
<em>126</em>, 109310. (<a
href="https://doi.org/10.1016/j.asoc.2022.109310">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a pigeon-inspired fuzzy multi-objective optimization algorithm is proposed for task allocation of multiple unmanned aerial vehicles tracking multiple ground targets in urban environment. Firstly, a multi-objective integer programming of task allocation, involving minimum total flight distance, best task allocation balance and minimum completion time, is established. Secondly, fuzzy two-phase optimization based on the relaxed order of desirable satisfactory degrees is proposed to formulate mixed integer programming regarding the linguistic importance preference of objectives. Then, an adaptive pigeon-inspired algorithm combined with auction mechanism is proposed to solve the optimization model. The position of pigeon is defined as the bidding price given by unmanned aerial vehicle for target. To satisfy the constraints and avoid existence of inferior pigeons, the auction mechanism is designed to decode the pigeon position into a feasible task allocation scheme. Finally, by comparing with the conventional particle swarm optimization , simulations validate the effectiveness and efficiency of the proposed method.},
  archive      = {J_ASOC},
  author       = {Chaofang Hu and Ge Qu and Yuting Zhang},
  doi          = {10.1016/j.asoc.2022.109310},
  journal      = {Applied Soft Computing},
  pages        = {109310},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Pigeon-inspired fuzzy multi-objective task allocation of unmanned aerial vehicles for multi-target tracking},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Forecasting the economic indices of the high-tech industries
in china using the grey multivariable convolution model. <em>ASOC</em>,
<em>126</em>, 109301. (<a
href="https://doi.org/10.1016/j.asoc.2022.109301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliable output forecasts are critical for decision-making and planning in high-tech industries. Several endogenous and exogenous factors could influence the output dynamics, and thereby a univariate model that only incorporates historical data and single method improvement is typically insufficient to generate accurate projections. In this paper, a novel grey multivariable convolution model is designed from a collaborative optimization perspective. The core innovations of this study can be summarized as follows. Initially, a collaborative framework integrating background value optimization, data preprocessing , and model structure improvement is constructed, which overcomes the internal deficiencies of the conventional grey models . Secondly, the Particle Swarm Optimization algorithm is selected to determine the optimal values of the damping accumulation parameters to enhance the adaptability and flexibility of the proposed model. Further, for validation purposes, experiments on forecasting the output of high-tech industries considering R&amp;D investments are conducted from the national and provincial levels, among which six competing models are involved. Moreover, Monte-Carlo Simulation, incorporated with probability density analysis and statistical analysis, is introduced to evaluate the robustness of the newly-designed model. It can be demonstrated from the empirical results that the novel model is a reliable and promising method for predicting the economic indices of the high-tech industries with enhanced forecasting capability.},
  archive      = {J_ASOC},
  author       = {Song Ding and Zui Tao and Jiaqi Hu},
  doi          = {10.1016/j.asoc.2022.109301},
  journal      = {Applied Soft Computing},
  pages        = {109301},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Forecasting the economic indices of the high-tech industries in china using the grey multivariable convolution model},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Commentary on “on the optimal placement of cameras for
surveillance and the underlying set cover problem” [applied soft
computing, vol. 74, 2019, pages 133–153]. <em>ASOC</em>, <em>126</em>,
109299. (<a href="https://doi.org/10.1016/j.asoc.2022.109299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a survey article, Kritter et al. (2019) state that the optimal camera placement problem finds application in photogrammetry among many other research areas. They affirm that it has its roots in the set cover problem, which is one of Karp’s original NP NP -complete problems. They claim that photogrammetry’s optimal camera placement problem can trivially transform into the set cover problem. This article points out the mistake of such an idea by contrasting the mathematical definitions and goals of these two research areas. The document recalls the bundle adjustment method to achieve an accurate three-dimensional reconstruction. Then, the article recaps the idea of Kritter et al. (2019) that the research community based the analysis of camera placement on the visibility problem. Later, the paper presents network design in photogrammetry as an optimization problem based on a scheme of four design stages/questions that photogrammetrists attempt to satisfy. We finish the document by clarifying why it is not possible to reduce the optimal camera placement to the set cover problem by pointing out the mistakes made by Kritter et al. (2019) in the survey.},
  archive      = {J_ASOC},
  author       = {Gustavo Olague and CICESE Research Center},
  doi          = {10.1016/j.asoc.2022.109299},
  journal      = {Applied Soft Computing},
  pages        = {109299},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Commentary on “On the optimal placement of cameras for surveillance and the underlying set cover problem” [Applied soft computing, vol. 74, 2019, pages 133–153]},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DDU-net: A dual dense u-structure network for medical image
segmentation. <em>ASOC</em>, <em>126</em>, 109297. (<a
href="https://doi.org/10.1016/j.asoc.2022.109297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image segmentation is one of the important steps in medical image analysis and has a wide range of applications and research values in medical research and practice. However, it is still a challenging task due to the characteristics of medical images with diverse lesion scales, blurred structural boundaries and numerous modalities. To address these challenges, we design a simple yet powerful dual dense u-structured network (called DDU-Net) for medical image segmentation . Specifically, we first construct dual encoders with the densely connected, where the first encoder uses DenseNet, whose backbone network is pre-trained on ImageNet, as a fixed feature extractor, and the second encoder uses a network structure similar to the first encoder. Both encoders try to encode information on the input image, and each layer is directly connected to the next layer in a feed-forward manner. This approach not only greatly reduces the number of parameters in the network, but also makes it easier to train with smaller samples. We then design up-sampling paths applicable to the dual encoder structure, and construct deeper decoders through densely connected convolutional layers , fusing the low to high level multi-scale semantic information learned by the two encoders. Finally, we employ a multiple loss function that combines boundary and content information to make DDU-Net more focus on the accuracy of boundary delineation to improve the overall segmentation performance . We have conducted comprehensive experiments on five different medical image segmentation datasets, including skin lesion segmentation , nuclei segmentation, lung segmentation, gland segmentation and vessel segmentation (IoU metrics for DDU-Net are 0.790, 0.860, 0.925, 0.812 and 0.696 respectively). Compared to baseline U-Net and other state-of-the-art methods, DDU-Net achieves competitive segmentation performance in both qualitative and quantitative evaluation .},
  archive      = {J_ASOC},
  author       = {Junlong Cheng and Shengwei Tian and Long Yu and Shijia Liu and Chaoqing Wang and Yuan Ren and Hongchun Lu and Min Zhu},
  doi          = {10.1016/j.asoc.2022.109297},
  journal      = {Applied Soft Computing},
  pages        = {109297},
  shortjournal = {Appl. Soft. Comput.},
  title        = {DDU-net: A dual dense U-structure network for medical image segmentation},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FIEMA, a system of fuzzy inference and emission analytics
for sustainability-oriented chemical process design. <em>ASOC</em>,
<em>126</em>, 109295. (<a
href="https://doi.org/10.1016/j.asoc.2022.109295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the quest to achieve sustainable development goals, developments in sustainability-oriented chemical process design are key to innovation in the chemical industry, especially important for processes aiming for sustainable fuels. One of the greatest challenges is the difficulty of modeling the highly complex interactions among the design variables, such as catalyst technology attributes, and greenhouse gas emissions. Most of the computational aids crucial to deal with the complexity of chemical processes require data that is either unavailable or uncertain at an early stage of design. The multistage integrated system for sustainable design proposed in this paper boosts these computational aids by applying data science techniques to allow uncertainty to be handled more efficiently, thereby facilitating the modeling of the interactions between the properties of new materials or processes and sustainability indicators. In this system, current data connectivity methods are used to find paths of correlation among catalysts properties and greenhouse gas emissions. The key feature of the proposed system relies on the integration through multiple stages of Fuzzy Inference systems and a data-driven technique for Emissions Analytics, FIEMA. 1 The algorithm in FIEMA provides a semi-supervised learning approach to emission analytics: it determines data clusters by a C-means algorithm and subsequently builds fuzzy sets for multiple stages of input–output inference. The proposed FIEMA system was demonstrated in an effort to determine the optimal configurations of the properties of catalysts to minimize the probability of associated greenhouse gas emissions for a methanol production process. The results showed the potential of this approach to reduce the search space of catalyst material designs by suggesting promising configurations for oxygen storage capacity, mechanical strength, lifetime, size, and poisoning level. The research impacts of this study contribute to the development of clean fuels by a computationally-efficient system for early design, and by the determination of catalysts development paths that assure an actual reduction of the life-cycle emissions.},
  archive      = {J_ASOC},
  author       = {Alexander Guzman-Urbina and Kakeru Ouchi and Hajime Ohno and Yasuhiro Fukushima},
  doi          = {10.1016/j.asoc.2022.109295},
  journal      = {Applied Soft Computing},
  pages        = {109295},
  shortjournal = {Appl. Soft. Comput.},
  title        = {FIEMA, a system of fuzzy inference and emission analytics for sustainability-oriented chemical process design},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Applications of dynamic feature selection and clustering
methods to medical diagnosis. <em>ASOC</em>, <em>126</em>, 109293. (<a
href="https://doi.org/10.1016/j.asoc.2022.109293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning methods are commonly used for disease and cancer diagnosis. The model performance can be improved via feature selection, feature reduction, and clustering methods . Although these supplementary techniques have certain advantages, they cannot necessarily guarantee better performance. The objective of this study is to improve the performance of classification methods used for medical diagnosis of various diseases. We propose a dynamic feature selection method based on the merits of both principal component analysis and Wrapper feature selection methods. It is a novel multi-objective feature selection method based on a customized genetic algorithm that is guided by eigenvalues of the features and feedbacks of various classifiers’ output. To reinforce classification learning and further enhancement of their performance, we utilize a dynamic selection of three clustering methods including K-means, fuzzy c-means, and particle swarm optimization . We also investigated the performance of two deep learning classifiers on the proposed methods. To show the impacts of combination of the proposed methods, we analyze the results of applying 12 machine learning and two deep learning classifiers to 30 imbalanced medical datasets. According to our extensive computational experiments and the statistical tests, the proposed dynamic feature selection and clustering methods perform significantly better than existing methods. The proposed methods not only improve the average of performance measures by 5\% but also are more accurate than best performing classification methods in the literature used for the same datasets.},
  archive      = {J_ASOC},
  author       = {Mohammad Mahdi Ershadi and Abbas Seifi},
  doi          = {10.1016/j.asoc.2022.109293},
  journal      = {Applied Soft Computing},
  pages        = {109293},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Applications of dynamic feature selection and clustering methods to medical diagnosis},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Speaker verification using attentive multi-scale
convolutional recurrent network. <em>ASOC</em>, <em>126</em>, 109291.
(<a href="https://doi.org/10.1016/j.asoc.2022.109291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a speaker verification method by an Attentive Multi-scale Convolutional Recurrent Network (AMCRN). The proposed AMCRN can acquire both local spatial information and global sequential information from the input speech recordings. In the proposed method, logarithm Mel spectrum is extracted from each speech recording and then fed to the proposed AMCRN for learning speaker embedding. Afterwards, the learned speaker embedding is fed to the back-end classifier (such as cosine similarity metric) for scoring in the testing stage. The proposed method is compared with state-of-the-art methods for speaker verification. Experimental data are three public datasets that are selected from two large-scale speech corpora (VoxCeleb1 and VoxCeleb2). Experimental results show that our method exceeds baseline methods in terms of equal error rate and minimal detection cost function, and has advantages over most of baseline methods in terms of computational complexity and memory requirement. In addition, our method generalizes well across truncated speech segments with different durations, and the speaker embedding learned by the proposed AMCRN has stronger generalization ability across two back-end classifiers.},
  archive      = {J_ASOC},
  author       = {Yanxiong Li PhD and Zhongjie Jiang and Wenchang Cao and Qisheng Huang},
  doi          = {10.1016/j.asoc.2022.109291},
  journal      = {Applied Soft Computing},
  pages        = {109291},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Speaker verification using attentive multi-scale convolutional recurrent network},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An optimal control policy in fighting COVID-19 and
infectious diseases. <em>ASOC</em>, <em>126</em>, 109289. (<a
href="https://doi.org/10.1016/j.asoc.2022.109289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When an outbreak starts spreading, policymakers have to make decisions that affect the health of their citizens and the economy. Some might induce harsh measures, such as a lockdown. Following a long, harsh lockdown, the recession forces policymakers to rethink reopening. To provide an effective strategy, here we propose a control strategy model. Our model assesses the trade-off between social performance and limited medical resources by determining individuals’ propensities. The proposed strategy also helps decision-makers to find optimal lockdown and exit strategies for each region. Moreover, the financial loss is minimized. We use the public sentiment information during the pandemic to determine the percentage of individuals with high-risk behavior and the percentage of individuals with low-risk behavior. Hence, we propose an online platform using fear-sentiment information to estimate the personal protective equipment (PPE) burn rate overtime for the entire population. In addition, a study of a COVID-19 dataset for Los Angeles County is performed to validate our model and its results. The total social cost reduces by 18\% compared with a control strategy where susceptible individuals are assumed to be homogeneous. We also reduce the total social costs by 26\% and 22\% compared to other strategies that consider the health-care cost or the social performance cost, respectively.},
  archive      = {J_ASOC},
  author       = {Hamid R. Sayarshad},
  doi          = {10.1016/j.asoc.2022.109289},
  journal      = {Applied Soft Computing},
  pages        = {109289},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An optimal control policy in fighting COVID-19 and infectious diseases},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-objective search group algorithm for engineering
design problems. <em>ASOC</em>, <em>126</em>, 109287. (<a
href="https://doi.org/10.1016/j.asoc.2022.109287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a new multi-objective version of the Search Group Algorithm (SGA) called the Multi-Objective Search Group Algorithm (MOSGA). The MOSGA is the combination of the conventional SGA integrated with an elitist non-dominated sorting technique, enabling it to define Pareto optimal solutions via mutation, offspring generation, and selection. The Pareto archive with a selection mechanism is used to preserve and enhance the convergence and diversity of solutions. The MOSGA is validated on twenty-five prominent case studies, including nineteen unconstrained multi-objective benchmark problems, six constrained multi-objective benchmark problems, and five multi-objective engineering design problems to validate its capability and effectiveness. The statistical results are compared to the outcomes of other well-regarded algorithms using the same performance metrics. The comparative results show that MOGSA is robust and superior in handling a wide variety of multi-objective problems.},
  archive      = {J_ASOC},
  author       = {Truong Hoang Bao Huy and Perumal Nallagownden and Khoa Hoang Truong and Ramani Kannan and Dieu Ngoc Vo and Nguyen Ho},
  doi          = {10.1016/j.asoc.2022.109287},
  journal      = {Applied Soft Computing},
  pages        = {109287},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-objective search group algorithm for engineering design problems},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multimodal learning model based on video–audio–chat feature
fusion for detecting e-sports highlights. <em>ASOC</em>, <em>126</em>,
109285. (<a href="https://doi.org/10.1016/j.asoc.2022.109285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ASOC},
  author       = {Gang-Min Park and Hye-In Hyun and Hyuk-Yoon Kwon},
  doi          = {10.1016/j.asoc.2022.109285},
  journal      = {Applied Soft Computing},
  pages        = {109285},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multimodal learning model based on video–audio–chat feature fusion for detecting e-sports highlights},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). A three-way decision method with prospect theory to
multi-attribute decision-making and its applications under hesitant
fuzzy environments. <em>ASOC</em>, <em>126</em>, 109283. (<a
href="https://doi.org/10.1016/j.asoc.2022.109283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, various uncertain information can be found in real world, and it is imperative to explore viable countermeasures for uncertain decision-making problems. Hesitant fuzzy set (HFS) theory is an efficient expression of uncertain information. Thus, the solution of hesitant fuzzy multi-attribute decision-making (HF-MADM) problems acts as a key topic in decision sciences. The purpose of this paper is to build a model with ranking and classification functions to reasonably solve HF-MADM problems, preferably aiming at the following situations: (1) decision-makers (DMs) are not risk-averse in all situations. (2) Decision results with acceptance, rejection or deferment are more important than merely ranking when there are many objects involved. First, prospect theory (PT) is used to quantify the psychology of DMs with gains and losses. Taking into account the particularity of HF environments, the gain and loss values of objects are estimated via using the flow of HF Preference Ranking Organization method for Enrichment Evaluations (HF-PROMETHEE). Subsequently, the concept of relative outcome matrices is proposed. Second, by means of three-way decision (TWD), a TWD model based on PT is established in HF environments. Third, the comparative analysis of ranking and classification is respectively constructed. The rationality and validity of the proposed model can be verified via the results of Spearman correlation coefficients with other ranking methods are greater than 0.75, and the classification error rate (CER) indicator is 33.61\% smaller than other existing classification methods. Finally, parameter experiments and case experiments under different data sets are constructed. The consistent optimal results under different parameters demonstrate the stability of the proposed model. Under the four different datasets, the CER values of 14.44\%, 11.11\%, 4.72\% and 7.41\% show that the proposed model is better than the other existing methods.},
  archive      = {J_ASOC},
  author       = {Jiajia Wang and Xueling Ma and Zeshui Xu and Witold Pedrycz and Jianming Zhan},
  doi          = {10.1016/j.asoc.2022.109283},
  journal      = {Applied Soft Computing},
  pages        = {109283},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A three-way decision method with prospect theory to multi-attribute decision-making and its applications under hesitant fuzzy environments},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multimodal feature fusion and exploitation with dual
learning and reinforcement learning for recipe generation.
<em>ASOC</em>, <em>126</em>, 109281. (<a
href="https://doi.org/10.1016/j.asoc.2022.109281">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recipes belong to long paragraphs with a cooking logic. To recipes from images and food names is more challenging in VQA (Visual Question Answering) due to the gap between images and texts. Although multimodal feature fusion , as a typical solver in VQA, is adopted in most situations for enhancing the accuracy, fused features obtained in this way can hardly provide guidance for keeping logic in produced texts. In this paper, ingredients are introduced to enhancing the relationship between food images and recipes, since they can reflect the cooking logic to a great extent, and dual learning is adopted to provide a complementary view by reconstructing ingredients from produced recipes. In order to make a full exploitation of ingredients for producing effective recipes, ingredients are fused into images and food names with an attention mechanism in the forward flow, and in the backward flow, a reconstructor is designed to reproduce ingredients from recipes. In addition, reinforcement learning is employed to guide ingredient reconstruction for preserving effective features in fused information explicitly. Extensive experiments demonstrate that more attention is allocated for producing effective recipes, and ablative study shows the reasonability of different components in the proposed method.},
  archive      = {J_ASOC},
  author       = {Mengyang Zhang and Guohui Tian and Huanbing Gao and Shaopeng Liu and Ying Zhang},
  doi          = {10.1016/j.asoc.2022.109281},
  journal      = {Applied Soft Computing},
  pages        = {109281},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multimodal feature fusion and exploitation with dual learning and reinforcement learning for recipe generation},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A soft-computing based approach to overlapped cells analysis
in histopathology images with genetic algorithm. <em>ASOC</em>,
<em>126</em>, 109279. (<a
href="https://doi.org/10.1016/j.asoc.2022.109279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning methods have shown great significance for medical image processing in recent years, including radiography, magnetic resonance imaging, nuclear medicine, and histopathology. Learning-based methods help to detect the target patterns when the network is well-trained. However, the gap between detected patterns and clinical decisions is still enormous, and soft-computing methods could help to improve the decisions based on the specific features of the problem. In this paper, the target is to detect the immunohistochemistry (IHC) positive cells in lymphoma histopathology images. We use a deep learning network to detect the positive cells in pixel level , and results show the proposed residual U-Net structure outperforms the baseline models . In the failure cases, they mainly occur when two cells are overlapped in predicted masks, which is the drawback of learning-based methods. Hence, a soft-computing based method is proposed to use ellipse formulation to represent a cellular pattern, and use genetic algorithm (GA) to determine an optimal decision of overlapped ellipses. We use two datasets: 36 images with ground truth from pathologists’ annotation, and 43 images with overlapped cells (cropped from failed predictions). A series of experiments show that the proposed deep learning model could detect most of IHC-positive cells in the proposed dataset, and our soft-computing method could detect 86.04\% of the overlapped cells and the proposed GA outperforms the baseline methods .},
  archive      = {J_ASOC},
  author       = {Hao Wu and Keona Ka Ying Pang and Grantham Kwok Hung Pang and Rex Kwok Him Au-Yeung},
  doi          = {10.1016/j.asoc.2022.109279},
  journal      = {Applied Soft Computing},
  pages        = {109279},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A soft-computing based approach to overlapped cells analysis in histopathology images with genetic algorithm},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An effective method based on simulated annealing for
automatic generation control of power systems. <em>ASOC</em>,
<em>126</em>, 109277. (<a
href="https://doi.org/10.1016/j.asoc.2022.109277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a novel hybrid Simulated Annealing-Genetic Algorithm (hSA-GA) is proposed. In the hSA-GA, population-based SA is used and each solution in the population is improved using the local search operator. The information exchange between the improved solutions is provided by the crossover operator . A new selection operator is used to ensure the balance between intensification and diversification. The hSA-GA is tested first on nine benchmark functions . Then it is used for tuning proportional–integral–derivative (PID) parameters for automatic generation control (AGC) of multi-area interconnected power systems . Firstly, PID parameters are determined with hSA-GA on a two-area interconnected non-reheating thermal system (System-1) in two different generator time constants. Secondly, to demonstrate the effect of supplementary control in AGC systems, the system is simulated with hSA-GA tuned PID controller and without controller. Additionally, the performance of the proposed hSA-GA is observed on AGC system of two area thermal power system with governor dead-band (GDB) nonlinearity (System-2). Transient responses of Δ f 1 Δf1 , Δ f 2 Δf2 and Δ P t i e ΔPtie obtained for both System-1 and System-2 are compared with studies on the same systems in the literature and it is seen that hSA-GA exhibits better control performance on power systems than compared studies. The proposed algorithm shows the best performance in System-1 (when T g = 0 . 08 Tg=0.08 ). Accordingly, settling times of Δ f 1 Δf1 , Δ f 2 Δf2 and Δ P t i e ΔPtie are reduced to 2.33 s, 3.783 s and 3.11 s, respectively. Finally, the non-linear two area thermal power system is tested with a load varying between ± ± 50\% for 180 s to validation of proposed algorithm and results are compared relevant studies.},
  archive      = {J_ASOC},
  author       = {Abdulsamed Tabak and İlhan İlhan},
  doi          = {10.1016/j.asoc.2022.109277},
  journal      = {Applied Soft Computing},
  pages        = {109277},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An effective method based on simulated annealing for automatic generation control of power systems},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Attention-based gating optimization network for multivariate
time series prediction. <em>ASOC</em>, <em>126</em>, 109275. (<a
href="https://doi.org/10.1016/j.asoc.2022.109275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series prediction is helpful for scientific decision-making and reliable assessments in numerous fields. Capturing time series nonlinear change rules with increasing dependency complexity among multivariate time series remains challenging. We propose an attention-based gating optimization network (AGON) to solve this issue. To relieve the conflict between external and target factors, the AGON divides the original time series into external factors and target factor for two parallel encoder inputs. One encoder employs feature-perceived attention to distinguish external factors’ contributions and limit the impact of low-contributing factors on high-level semantics. The other leverages long short term memory (LSTM) to establish the temporal dependencies of the target factor. In the decoder phase, fine-grained denoising attention is designed to assign an attention weight vector instead of a single scalar to filter fine-grained harmful noise in the hidden state to the uttermost. Finally, information fusion LSTM is introduced to maintain the output balance between external and target factors. An extensive experiment of three fields of energy, environment, and finance (wind speed, PM2.5, four stock datasets) is presented. AGON is able to achieve 38\%, 37\%, and 46\% improvements in the average MAE , RMSE , and MAPE results over state-of-the-art methods across all three datasets and three-step-ahead forecasting, which implies that AGON can be very competitive and holds versatility for diverse industries’ multivariate time series even if the dataset presents strong fluctuation and a nonlinear changing tendency.},
  archive      = {J_ASOC},
  author       = {Xiulin Geng and Xiaoyu He and Lingyu Xu and Jie Yu},
  doi          = {10.1016/j.asoc.2022.109275},
  journal      = {Applied Soft Computing},
  pages        = {109275},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Attention-based gating optimization network for multivariate time series prediction},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiple imputation method of missing credit risk assessment
data based on generative adversarial networks. <em>ASOC</em>,
<em>126</em>, 109273. (<a
href="https://doi.org/10.1016/j.asoc.2022.109273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Credit risk assessment is critical for loan approval and risk management of banks. However, the problem of missing credit risk data may greatly reduce the effectiveness of the assessment model. Therefore, constructing a data imputation method for accurate missing data prediction is quite beneficial. Typically, building an effective imputation model is very challenging due to the high missing rate and complex arbitrary missing pattern of datasets in credit risk assessment. In this paper, a novel imputation method named as Multiple Generative Adversarial Imputation Networks (MGAIN) is proposed. Specifically, we first randomly select multiple attribute subsets instead of the whole attributes such that more complete samples can be generated. Then, the missing data in each attribute are imputed by using generative adversarial imputation networks (GAIN) which fully considers the relationships among missing values by combining neural network and adversarial learning. The proposed subset selection and multiple imputation strategy not only simplify the network structure of GAIN but also reduce the demand for data. Finally, a weighted average method is presented to synthesize multiple results of each missing attribute value to further improve the accuracy. The experimental results on real-world data demonstrate that the proposed method is superior to other popular imputation methods.},
  archive      = {J_ASOC},
  author       = {Feng Zhao and Yan Lu and Xinning Li and Lina Wang and Yingjie Song and Deming Fan and Caiming Zhang and Xiaobo Chen},
  doi          = {10.1016/j.asoc.2022.109273},
  journal      = {Applied Soft Computing},
  pages        = {109273},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multiple imputation method of missing credit risk assessment data based on generative adversarial networks},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fuzzy multi-attribute information fusion approach for
finance investment selection with the expert reliability. <em>ASOC</em>,
<em>126</em>, 109270. (<a
href="https://doi.org/10.1016/j.asoc.2022.109270">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finance investment selection is important for an investment company in financial decision making. Multiple experts should be invited to make investment selection. The dependability of the investment results can be affected by the original decision information and the experts’ reliability. However, experts are not all knowledgeable and express their opinions with different forms of preference. In order to consider the influences of experts and keep the original information in the information aggregation process, this paper proposes a fuzzy information fusion approach with the expert reliability for investment selection. First, we analyze the influence of the reliability of the experts and constructed the experts’ reliability based on the similarity between experts. Second, power average operator combined with experts’ reliability is used to integrate the experts’ preference. The original information could be preserved under the greatest extent. Then, a fuzzy information fusion approach is developed for investment selection with the aim of demonstrating its effectiveness by retaining experts’ original views and risk preference information based the expert reliability. Finally, an investment selection example is applied to confirm in advance whether the decision maker selected is reliable and suitable for scheme selection. Moreover, it demonstrates the effectiveness of the proposed approach and applicability of it.},
  archive      = {J_ASOC},
  author       = {Yanhong Li and Gang Kou and Guangxu Li and Mohammed A. Hefni},
  doi          = {10.1016/j.asoc.2022.109270},
  journal      = {Applied Soft Computing},
  pages        = {109270},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fuzzy multi-attribute information fusion approach for finance investment selection with the expert reliability},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Two model-free schemes for solving kinematic tracking
control of redundant manipulators using CMAC networks. <em>ASOC</em>,
<em>126</em>, 109267. (<a
href="https://doi.org/10.1016/j.asoc.2022.109267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kinematic tracking control of robotic manipulators is a basic and vital issue in robotics. However, how to achieve the control of robotic manipulators with unknown kinematic models remains challenging. Existing studies show that cerebellum, a pivotal region of brain, plays a major role in human motion control, which motivates us to devise two schemes based on cerebellum model articulation controller (CMAC) for the tracking control of redundant manipulators with unknown kinematic models in this article. The first scheme is based on a CMAC network and a gradient neural dynamics (GND) algorithm. The CMAC network is utilized to generate approximate joint angle commands for the manipulator. By using the Jacobian matrix of the manipulator which is estimated by the GND algorithm, task space error is transformed into joint space error, which is taken as the teaching signal for training the CMAC. For the second scheme, another CMAC network replaces the GND algorithm to achieve the estimation of the Jacobian matrix of the manipulator. The effectiveness and robustness of the proposed control schemes are verified by both simulations and physical experiments.},
  archive      = {J_ASOC},
  author       = {Ning Tan and Chaoyuan Li and Peng Yu and Fenglei Ni},
  doi          = {10.1016/j.asoc.2022.109267},
  journal      = {Applied Soft Computing},
  pages        = {109267},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Two model-free schemes for solving kinematic tracking control of redundant manipulators using CMAC networks},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An efficient hyper-parameter optimization method for
supervised learning. <em>ASOC</em>, <em>126</em>, 109266. (<a
href="https://doi.org/10.1016/j.asoc.2022.109266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervised learning is an important tool for data mining and knowledge discovery. The hyper-parameter in learning models usually has a significant impact on the generalization performance of supervised learning model. Although some state-of-the-art hyper-parameter optimizers, such as cross-validation (CV) and its improvements, have been widely used in many applications, there still exist some limitations including the low efficiency and the error variation from data partition . To address these issues, we propose the sign similarity to distinguish between over-fitting and under-fitting in supervised learning. On this basis, the minimal symmetric similarity criterion (MSSC) is proposed to optimize hyper-parameters. It provides an equivalent condition of well-fitting, i.e., the well-fitted hyper-parameter should have a minimal symmetric similarity. Compared with CV, the criterion is more efficient and could avoid error variation as the symmetric similarity is based on the whole data set without partition. The reasonableness of the proposed MSSC is proved for well-posed learning problems. Also, corresponding assumptions are explained by means of theoretical analysis and empirical verification. Both theoretical analysis and experimental results indicate that the efficiency of MSSC is significantly higher than popular optimizers like 10-CV. Experimental results demonstrate that MSSC is comparable with or outperforms the state-of-the-art optimizers in three kinds of learning tasks from the statistical perspective.},
  archive      = {J_ASOC},
  author       = {Ying Shi and Hui Qi and Xiaobo Qi and Xiaofang Mu},
  doi          = {10.1016/j.asoc.2022.109266},
  journal      = {Applied Soft Computing},
  pages        = {109266},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An efficient hyper-parameter optimization method for supervised learning},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A surrogate-assisted evolutionary algorithm with hypervolume
triggered fidelity adjustment for noisy multiobjective integer
programming. <em>ASOC</em>, <em>126</em>, 109263. (<a
href="https://doi.org/10.1016/j.asoc.2022.109263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although surrogate-assisted evolutionary algorithms (SAEAs) have been widely developed to address computationally expensive multi-objective optimization problems (MOPs), they still encounter difficulties in solving the expensive and noisy combinatorial MOPs. To this end, we propose a novel SAEA to handle this kind of problem. In the proposed algorithm, the averaging method is used to denoise. To balance the conflict between the time cost and the effect of noises, multi-fidelity surrogate models are constructed according to the averaged evaluation results. The number of independent repeated evaluations represents the fidelity level of surrogate models . In the optimization process, the hypervolume indicator is employed as a trigger to determine whether the fidelity level should be increased. In addition, a lightweight local search method , the semi-variable neighborhood search, is proposed to improve the global search efficiency of the proposed algorithm in discrete decision spaces. Experimental results show that our proposed algorithm achieves competitive performance on most benchmark problems.},
  archive      = {J_ASOC},
  author       = {Shulei Liu and Handing Wang and Wen Yao},
  doi          = {10.1016/j.asoc.2022.109263},
  journal      = {Applied Soft Computing},
  pages        = {109263},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A surrogate-assisted evolutionary algorithm with hypervolume triggered fidelity adjustment for noisy multiobjective integer programming},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). New model for occupational health and safety risk
assessment based on fermatean fuzzy linguistic sets and CoCoSo approach.
<em>ASOC</em>, <em>126</em>, 109262. (<a
href="https://doi.org/10.1016/j.asoc.2022.109262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, occupational health and safety management has gained more and more importance by organizations around the world because it positively impacts on the productivity, competitiveness and reputation. The occupational health and safety risk assessment (OHSRA) is a critical activity to identify and evaluate the most serious work-related hazards for corrective actions. In this study, a new OHSRA model using Fermatean fuzzy linguistic sets (FFLSs) and combined compromise solution (CoCoSo) approach is proposed for the risk evaluation and prioritization of occupational hazards. Specifically, the scientific contributions of this study are as follows: The FFLSs are used to cope with the complex and vague risk evaluations obtained from experts; the CoCoSo approach is utilized to determine the risk priority of the identified occupational hazards; an extended block-wise rating the attribute weighting method is introduced for specifying risk criteria weights. Finally, the applicability and effectiveness of the proposed OHSRA model are demonstrated by an occupational risk assessment example along with simulation experiments and a comprehensive comparative analysis. The major advantages of the proposed model are higher flexibility in handling experts’ intricate and fuzzy assessment information and effective in providing a reliable risk ranking of occupational hazards with high discriminability .},
  archive      = {J_ASOC},
  author       = {Qin-Yu Chen and Hu-Chen Liu and Jing-Hui Wang and Hua Shi},
  doi          = {10.1016/j.asoc.2022.109262},
  journal      = {Applied Soft Computing},
  pages        = {109262},
  shortjournal = {Appl. Soft. Comput.},
  title        = {New model for occupational health and safety risk assessment based on fermatean fuzzy linguistic sets and CoCoSo approach},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Annual dilated convolutional LSTM network for time charter
rate forecasting. <em>ASOC</em>, <em>126</em>, 109259. (<a
href="https://doi.org/10.1016/j.asoc.2022.109259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time charter rates must be predicted accurately to assist sensible decisions in the global, highly volatile shipping market. Time charter rates are affected by multiple factors, such as second-hand ship prices, order book, Libor interest rate, etc. However, not all factors convey predictive features to anticipate the future of time charter rates. Therefore, extracting predictive features from multiple driving time series from the shipping market is crucial for forecasting purposes. Accordingly, this paper proposes a novel convolutional recurrent neural network for time charter rates forecasting under the multi-variate phenomenon. The proposed network first extracts features from the monthly time series using a novel convolutional filter , the annual dilated filter. The annual dilated convolutional filter can extract the predictive features effectively and impose a sparse input structure to prevent overfitting. Then, a recurrent neural network learns the temporal information from the convoluted features. An extensive comparison study with many baseline models , including the persistence (Naïve I), statistical models, and the state-of-art networks, is conducted on the time charter rates of six kinds of ships. The empirical results demonstrate the proposed model’s superiority in forecasting the time charter rates.},
  archive      = {J_ASOC},
  author       = {Jixian Mo and Ruobin Gao and Jiahui Liu and Liang Du and Kum Fai Yuen},
  doi          = {10.1016/j.asoc.2022.109259},
  journal      = {Applied Soft Computing},
  pages        = {109259},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Annual dilated convolutional LSTM network for time charter rate forecasting},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Experimental evaluation of stochastic configuration
networks: Is SC algorithm inferior to hyper-parameter optimization
method? <em>ASOC</em>, <em>126</em>, 109257. (<a
href="https://doi.org/10.1016/j.asoc.2022.109257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To overcome the pitfalls of Random Vector Functional Link (RVFL), a network called Stochastic Configuration Networks (SCN) has been proposed. By constraining and adaptively selecting the range of randomized parameters using the Stochastic Configuration (SC) algorithm, SCN claims to be potent in building an incremental randomized learning system according to residual error minimization. The SC has three variants depending on how the range of output weights are updated. In this work, we first relate the SCN to appropriate literature. Subsequently, we show that the major parts of the SC algorithm can be replaced by a generic hyper-parameter optimization method to obtain overall better results.},
  archive      = {J_ASOC},
  author       = {Minghui Hu and P.N. Suganthan},
  doi          = {10.1016/j.asoc.2022.109257},
  journal      = {Applied Soft Computing},
  pages        = {109257},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Experimental evaluation of stochastic configuration networks: Is SC algorithm inferior to hyper-parameter optimization method?},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Performance analysis of distance metrics on the exploitation
properties and convergence behaviour of the conventional firefly
algorithm. <em>ASOC</em>, <em>126</em>, 109255. (<a
href="https://doi.org/10.1016/j.asoc.2022.109255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nature of the distance metric used to compare the span between two fireflies in conventional firefly algorithm can significantly enhance the exploitation properties of the algorithm and improve its convergence towards the optimum solution. Therefore, this research proposes several variants of the firefly algorithm based on different distance relations like Minkowski distance , Canberra distance, and Angular Cosine distance. To compare the performance of these variants, benchmark non-linear and non-convex objective functions are solved under the varying nature of the medium absorption coefficient and attractiveness constant. It is observed from detail analysis of results that Canberra distance provides optimal results for almost all of the benchmark functions . Furthermore, the importance of the distance metric for real-world optimization problems with very large or small magnitude of decision variables is also presented by solving a practical hydro thermal scheduling problem. It is also presented that the optimal set of parameters for a particular distance criterion may not always be optimal and better convergence results can be achieved by varying the distance metric to measure the length between the fireflies.},
  archive      = {J_ASOC},
  author       = {Sheroze Liaquat and Muhammad Fahad Zia and Omer Saleem and Zeeshan Asif and Mohamed Benbouzid},
  doi          = {10.1016/j.asoc.2022.109255},
  journal      = {Applied Soft Computing},
  pages        = {109255},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Performance analysis of distance metrics on the exploitation properties and convergence behaviour of the conventional firefly algorithm},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Gated tree-structured RecurNN for detecting biomedical event
trigger. <em>ASOC</em>, <em>126</em>, 109251. (<a
href="https://doi.org/10.1016/j.asoc.2022.109251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is critical to deeply mine semantic features for information extraction. Tree-structured model is a linguistically attractive option due to its linguistic representations of sentence syntactic structure. Tree-LSTM has been introduced to represent tree-structured network topologies for the syntactic properties. To alleviate the limitation of the Tree-LSTM, we work towards addressing the issue by developing gated mechanism variants for the tree-structured network. The gated mechanism is more complex and diverse for the tree-structured model. We apply Child-Sum Tree-LSTM and Child-Sum Tree-GRU for recognizing biomedical event triggers, and develop two new gated mechanism variants incorporating peephole connection and coupled mechanism into the tree-structured model. The experimental results showed the advantage of gated units. The Child-Sum Tree-LSTM achieved the best results among the gated tree-structured models, and the performance of variants is nearly the same as Child-Sum Tree-LSTM . However, Child-Sum Tree-GRU and Child-Sum Tree-coupled reach reduction in computation time.},
  archive      = {J_ASOC},
  author       = {Lei Wang and Han Cao and Liu Yuan},
  doi          = {10.1016/j.asoc.2022.109251},
  journal      = {Applied Soft Computing},
  pages        = {109251},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Gated tree-structured RecurNN for detecting biomedical event trigger},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Consensus progress for large-scale group decision making in
social networks with incomplete probabilistic hesitant fuzzy
information. <em>ASOC</em>, <em>126</em>, 109249. (<a
href="https://doi.org/10.1016/j.asoc.2022.109249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision-making situations have been dramatically impacted by the development of the economy and technology. Large-scale group decision making (LSGDM) in social networks has become one of the hot topics in the decision-making field. In this paper, we develop a novel framework to reach consensus in social networks for LSGDM with incomplete probabilistic hesitant fuzzy information. In this framework, an expert clustering method based on interpretive structural modeling (ISM) is designed to classify experts. The trust propagation and aggregation operators for probabilistic hesitant fuzzy are explored to achieve indirect trust assessment and weights of experts. Then, an iterative algorithm that checks the personal decision level of experts is presented to estimate the missing values in incomplete probabilistic hesitant fuzzy decision matrices . Also, a consensus process is investigated to eliminate opinion conflict using trust feedback adjustment (TFA) and weight feedback adjustment (WFA). Lastly, a case study is presented to demonstrate the application of the proposed method. The comparison analysis and discussion are established to verify the advantages and effectiveness of the proposed consensus framework for LSGDM in social networks.},
  archive      = {J_ASOC},
  author       = {Yanling Lu and Yejun Xu and Enrique Herrera-Viedma},
  doi          = {10.1016/j.asoc.2022.109249},
  journal      = {Applied Soft Computing},
  pages        = {109249},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Consensus progress for large-scale group decision making in social networks with incomplete probabilistic hesitant fuzzy information},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Short-term wind power probabilistic forecasting using a new
neural computing approach: GMC-DeepNN-PF. <em>ASOC</em>, <em>126</em>,
109247. (<a href="https://doi.org/10.1016/j.asoc.2022.109247">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing penetration of renewable energy in power generation , the increasing uncertainty of renewable energy has significant influence on the stability of energy system . In order to handle the system uncertainty as well as satisfying the energy demand and supply, a short-term wind power probabilistic forecasting under uncertainty using the Gaussian mixed clustering-Deep neural network probabilistic forecasting (GMC-DeepNN-PF) is proposed. To illustrate the applicability of the proposed method, a case study of a wind power data set from Kaggle is presented and comparisons among four different data situations and four different forecasting models are shown in this paper. The raw wind power data is firstly pre-processed based on Gaussian Mixture Model reducing data defects. After that, the cleaned data is extended for more information which can improve the output accuracy and time as a property is added to forecasting model. According to DeepNN-PF, deep conventional neural network concatenated with T distribution is then utilized for forecasting using extended data. The simulations and comparisons demonstrate the advancement of the proposed method.},
  archive      = {J_ASOC},
  author       = {Qianchao Wang and Lei Pan and Haitao Wang and Xinchao Wang and Ying Zhu},
  doi          = {10.1016/j.asoc.2022.109247},
  journal      = {Applied Soft Computing},
  pages        = {109247},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Short-term wind power probabilistic forecasting using a new neural computing approach: GMC-DeepNN-PF},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Human action prediction in collaborative environments based
on shared-weight LSTMs with feature dimensionality reduction.
<em>ASOC</em>, <em>126</em>, 109245. (<a
href="https://doi.org/10.1016/j.asoc.2022.109245">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As robots are progressing towards being ubiquitous and an indispensable part of our everyday environments, such as home, offices, healthcare, education, and manufacturing shop floors, efficient and safe collaboration and cohabitation become imperative. Given that, such environments could benefit greatly from accurate human action prediction. In addition to being accurate, human action prediction should be computationally efficient, in order to ensure a timely reaction, and capable of dealing with changing environments, since unstructured interaction and collaboration with humans usually do not assume static conditions. In this paper, we propose a model for human action prediction based on motion cues and gaze using shared-weight Long Short-Term Memory networks (LSTMs) and feature dimensionality reduction. LSTMs have proven to be a powerful tool in processing time series data , especially when dealing with long-term dependencies; however, to maximize their performance, LSTM networks should be fed with informative and quality inputs. Given that, in this paper, we furthermore conducted an extensive input feature analysis based on (i) signal correlation and their strength to act as stand-alone predictors, and (ii) a multilayer perceptron inspired by the autoencoder architecture. We validated the proposed model on a publicly available MoGaze 1 dataset for human action prediction, as well as on a smaller dataset recorded in our laboratory. Our model outperformed alternatives, such as recurrent neural networks , a fully connected LSTM network, and the strongest stand-alone signals (baselines), and can run in real-time on a standard laptop CPU. Since eye gaze might not always be available in a real-world scenario, we have implemented and tested a multi-layer perceptron for gaze estimation from more easily obtainable motion cues, such as head orientation and hand position. The estimated gaze signal can be utilized during inference of our LSTM-based model, thus making our action prediction pipeline suitable for real-time practical applications.},
  archive      = {J_ASOC},
  author       = {Tomislav Petković and Luka Petrović and Ivan Marković and Ivan Petrović},
  doi          = {10.1016/j.asoc.2022.109245},
  journal      = {Applied Soft Computing},
  pages        = {109245},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Human action prediction in collaborative environments based on shared-weight LSTMs with feature dimensionality reduction},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spatial area determination problem: Definition and solution
method based on memetic algorithm. <em>ASOC</em>, <em>126</em>, 109243.
(<a href="https://doi.org/10.1016/j.asoc.2022.109243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial area determination problem is defined herein as an optimization problem in which it is required to determine both the location and shape of a spatial area, given some constraints on the area (e.g., size) while maximizing or minimizing an objective function defined on spatial data (e.g., risk, cost, safety, security, etc.). The spatial area determination problem can be found in various domains such as hydrographic survey planning, conservation planning, military planning, etc., and it recently attracts research attention. Currently, there is no formal definition of the problem and the related solution methods are very limited. In this paper, first, the spatial area determination problem is defined and formulated, and then a solution method based on a Memetic Algorithm is developed to solve the problem. To deal with the constraints of the problem and to enhance the robustness of the traditional Memetic Algorithm , several innovations in the proposed Memetic Algorithm are introduced. Unlike the traditional Memetic Algorithm, the proposed Memetic Algorithm employs three crossover operators , two mutation operators , and a local search operator. In addition, the proposed Memetic Algorithm has a mechanism to automatically restart its search process if it gets stuck in the local optima. Moreover, parameters of the proposed Memetic Algorithm are systematically tuned by the Taguchi experimental design method to maximize its performance. The outperformance of the proposed Memetic Algorithm is validated through 18 test instances, 24 T-tests, and a Friedman test against four popular optimization algorithms , namely Simulated Annealing, Particle Swarm Optimization , Genetic Algorithm , and traditional Memetic Algorithm. The results indicate that, on average, the proposed Memetic Algorithm provided 36.5\%, 43.3\%, 20.4\%, and 22.4\% better solution, compared to Simulated Annealing, Particle Swarm Optimization , Genetic Algorithm , and the traditional Memetic Algorithm, respectively.},
  archive      = {J_ASOC},
  author       = {Son Duy Dao and Antoine Mallégol and Patrick Meyer and Mehrdad Mohammadi and Sophie Loyer},
  doi          = {10.1016/j.asoc.2022.109243},
  journal      = {Applied Soft Computing},
  pages        = {109243},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Spatial area determination problem: Definition and solution method based on memetic algorithm},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reward criteria impact on the performance of reinforcement
learning agent for autonomous navigation. <em>ASOC</em>, <em>126</em>,
109241. (<a href="https://doi.org/10.1016/j.asoc.2022.109241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In reinforcement learning, an agent takes action at every time step (follows a policy) in an environment to maximize the expected cumulative reward. Therefore, the shaping of a reward function plays a crucial role in an agent’s learning. Designing an optimal reward function is not a trivial task. In this article, we propose a reward criterion using which we develop different reward functions. The reward criterion chosen is based on the percentage of positive and negative rewards received by an agent. This reward criteria further gives rise to three different classes, ‘Balanced Class, ’ ‘Skewed Positive Class, ’ and ‘Skewed Negative Class.’ We train a Deep Q-Network agent on a point-goal based navigation task using the different reward classes. We also compare the performance of the proposed classes with a benchmark class. Based on the experiments, the skewed negative class outperforms the benchmark class by achieving very less variance. On the other hand, the benchmark class converges relatively faster than the skewed negative class.},
  archive      = {J_ASOC},
  author       = {Aveen Dayal and Linga Reddy Cenkeramaddi and Ajit Jha},
  doi          = {10.1016/j.asoc.2022.109241},
  journal      = {Applied Soft Computing},
  pages        = {109241},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Reward criteria impact on the performance of reinforcement learning agent for autonomous navigation},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A tabu search based approach for the heterogeneous fleet
vehicle routing problem with three-dimensional loading constraints.
<em>ASOC</em>, <em>126</em>, 109239. (<a
href="https://doi.org/10.1016/j.asoc.2022.109239">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies a particular integration of the Heterogeneous Fleet Vehicle Routing Problem with three-dimensional loading constraints (3L-HFVRP), which considers rectangular-shaped items to be delivered to customers and loading constraints to be satisfied. The resolution of this problem consists of assigning a loading plan to each used vehicle, while minimizing the total transportation cost. Clearly, the 3L-HFVRP is a combination of Heterogeneous Fleet Vehicle Routing Problem (HFVRP) and Three Dimensional Single Container Loading Problem (3D-SCLP). In order to solve this problem, we propose a hybrid meta-heuristic approach based on a developed Tabu Search (TS) algorithm for the routing aspect and a modified Extreme Point based First Fit Decreasing (EP-FFD) heuristic for the loading sub-problem. New procedures have been proposed in the framework of this approach. Afterwards, numerical experiments on available sets of benchmark instances show that our new approach outperforms the current best algorithm for several instances. Indeed, the different experiments performed showed that our algorithm was able to find good solutions on 76\% of the cases, which confirms the efficiency and performance of our approach in terms of solution quality.},
  archive      = {J_ASOC},
  author       = {Youssef Meliani and Yasmina Hani and Sâad Lissane Elhaq and Abderrahman El Mhamedi},
  doi          = {10.1016/j.asoc.2022.109239},
  journal      = {Applied Soft Computing},
  pages        = {109239},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A tabu search based approach for the heterogeneous fleet vehicle routing problem with three-dimensional loading constraints},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The applications of MCDM methods in COVID-19 pandemic: A
state of the art review. <em>ASOC</em>, <em>126</em>, 109238. (<a
href="https://doi.org/10.1016/j.asoc.2022.109238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Likened to the economic calamity of World War Two, the COVID-19 pandemic has sparked fears of a deep economic crisis, killed more than six million people worldwide and had a ripple effect on all aspects of life. MCDM (multi-criteria decision making) methods have become increasingly popular in modeling COVID-19 problems owing to the multi-dimensionality of this crisis and the complexity of health and socio-economic systems. This paper is aimed to review 72 papers published in 37 leading peer-reviewed journals indexed in Web of Science that used MCDM methods in different areas of COVID-19 pandemic. In this paper, data retrieval follows the PRISMA protocol for systematic literature reviews. 35 countries have contributed to this multidisciplinary research and India is identified as the leading country in this field followed by Turkey and China. Also 36 articles, namely 50\% of papers are presented in the form of international cooperation. “ Applied Soft Computing ” is the journal with the highest number of articles whereas “Journal of infection and public health” and “ Operations Management Research ” are ranked in the second place. The results indicate that AHP (including fuzzy AHP) is the most popular MCDM method applied in 37.5\% of papers followed by TOPSIS and VIKOR . This review reveals that the use of MCDM methods is one of the most attractive research areas in the field of COVID-19. As a result, one of the main purposes of this work is to identify diverse applications of MCDM methods in the COVID-19 pandemic. Most studies i.e. 69\% (49 papers) of the papers combined various fuzzy sets with MCDM methods to overcome the problem of uncertainty and ambiguity while analyzing information. Nevertheless, the main drawback of those papers has been the lack of theoretical justifications. In fact, fuzzy MCDM methods impose heavy computational load and there is no general consensus on the clear advantage of fuzzy methods over crisp methods in terms of the solution quality. We hope the researchers who applied fuzzy MCDM methods to COVID-19-related research understand the theoretical basis of MCDM methods and the serious challenges associated with basic operations of fuzzy numbers to avoid potential disadvantages. This paper contributes to the body of knowledge via suggesting a deep vision to critique the fuzzy MCDM methods from mathematical perspective.},
  archive      = {J_ASOC},
  author       = {Alireza Sotoudeh-Anvari},
  doi          = {10.1016/j.asoc.2022.109238},
  journal      = {Applied Soft Computing},
  pages        = {109238},
  shortjournal = {Appl. Soft. Comput.},
  title        = {The applications of MCDM methods in COVID-19 pandemic: A state of the art review},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Rethinking transition relationship between co-occurring
items in graph neural networks for session-based recommendation.
<em>ASOC</em>, <em>126</em>, 109231. (<a
href="https://doi.org/10.1016/j.asoc.2022.109231">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-based recommendation aims to recommend items based on anonymous behavior sequences. A session is generally modeled as a sequential structure or graph structure to extract its session-level representation. However, directly modeling a session as a sequence ignores the co-occurrence relationship between pairwise items, and current graph-based methods do not consider information transition directions sufficiently when calculating the similarity of co-occurring items. In this paper, we propose a novel approach, dubbed I tem T ransition R elationship G raph N eural N etworks (ITR-GNN), to model different transition relationships between co-occurring items in an effective way, for better extracting user intents of current sessions. In ITR-GNN, session sequences are modeled as directed unweighted graphs, and two different transition relationships between a pair of co-occurring items are distinguished by two different concatenations of their latent vectors, according to the direction of the edge between them. In addition, we notice that the data used for session-based recommendation contain many noisy labels, degrading recommendation effects. Thereby, we introduce a label distillation strategy to learn improved soft labels and replace potential noisy labels through a teacher–student network. Experimental results on three benchmark datasets demonstrate that the ITR-GNN outperforms state-of-the-art methods. Source code is available at https://github.com/cyq002/ITR-GNN .},
  archive      = {J_ASOC},
  author       = {Yongqi Cai and Jianwu Li},
  doi          = {10.1016/j.asoc.2022.109231},
  journal      = {Applied Soft Computing},
  pages        = {109231},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Rethinking transition relationship between co-occurring items in graph neural networks for session-based recommendation},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian network safety risk analysis for the dam–foundation
system using monte carlo simulation. <em>ASOC</em>, <em>126</em>,
109229. (<a href="https://doi.org/10.1016/j.asoc.2022.109229">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gravity dams are mostly located in alpine and gorge regions with complex terrain and geological conditions, facing challenges of large peak flows , developed weak structural planes, high-stress levels, etc. The determination of failure risks of different failure modes in gravity dams is closely related to structural characteristics, materials properties, and loading conditions. However, the failure risks in the traditional risk analysis methods are usually calculated based on the expert evaluation methods and statistical data, ignoring the uniqueness of dam characteristics, and leading to an unreasonable risk assessment. Therefore, an improved probabilistic risk analysis method for the dam–foundation system using Bayesian network (BN) and Monte Carlo simulation is proposed in this study, which considers the combined action of overtopping, foundation stability, and structural failure. Based on the Monte-Carlo method, the risk analysis of overtopping is proposed by considering the influences of peak flows and maximum wind speeds, and the dam–foundation system is developed by establishing response surface equations of performance functions. Then, the BN safety risk analysis method for gravity dams is formed. This improved method is applied in the GD gravity dam project and finds that the system risk is 2.10 × 10 −3 . The most critical failure factor is the foundation instability, and the importance and sensitivity analysis also proved it, implying the validity and reasonability of the proposed method. Thus, the BN safety risk analysis method for gravity dams enables an improved and more reliable estimate of dam risk.},
  archive      = {J_ASOC},
  author       = {Xiang Lu and Chen Chen and Zefa Li and Jiankang Chen and Liang Pei and Kun He},
  doi          = {10.1016/j.asoc.2022.109229},
  journal      = {Applied Soft Computing},
  pages        = {109229},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Bayesian network safety risk analysis for the dam–foundation system using monte carlo simulation},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A data-driven decision-making framework for personnel
selection based on LGBWM and IFNs. <em>ASOC</em>, <em>126</em>, 109227.
(<a href="https://doi.org/10.1016/j.asoc.2022.109227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For any organization, personnel selection is regarded as one of the most critical and complex issues in human resource management. Due to the fuzziness and ambiguity in personnel selection, it was usually tackled by utilizing multi-criteria decision-making (MCDM) methods. Previously developed MCDM methods for personnel selection have principally depended on experts’ preferences, which may lead to the bias and deviation caused by human cognitive limitations. With the development of information technology, many human resource (HR) data have accumulated within some organizations, making it possible to discover meaningful patterns in HR data based on data analytics algorithms (DAAs). These patterns do not depend on experts’ judgement and can objectively reflect the performance of personnel in several aspects. Thus, it is promising that integrating objective patterns obtained from HR data and experts’ judgement can make personnel selection more systematic and scientific. To tackle this complex scenario, we propose a data-driven decision-making framework that combines DAAs and MCDM method. The proposed framework can explore the underlying patterns in HR data and also consider experts’ judgement during the selection process. In this framework, a data-driven competency-based method is designed to mine out valuable information in HR data. In addition, for assisting multiple experts, a linear group best–worst​ method (LGBWM) is proposed to calculate the weights of criteria, and intuitionistic fuzzy numbers (IFNs) are used to help experts express their preferences. A personnel evaluation and selection (PLEAS) decision support system is also designed and developed to implement the framework better. In order to illustrate the effectiveness of the proposed framework, a real-world case is conducted in a Chinese state-owned company, and the results demonstrate that our proposed framework is valid for solving data-driven personnel selection problems.},
  archive      = {J_ASOC},
  author       = {Jiting Li and Renjie He and Tao Wang},
  doi          = {10.1016/j.asoc.2022.109227},
  journal      = {Applied Soft Computing},
  pages        = {109227},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A data-driven decision-making framework for personnel selection based on LGBWM and IFNs},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Routing and scheduling optimization for UAV assisted
delivery system: A hybrid approach. <em>ASOC</em>, <em>126</em>, 109225.
(<a href="https://doi.org/10.1016/j.asoc.2022.109225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a joint-optimization framework for UAV-routing and UAV-route scheduling problems associated with the UAV-assisted delivery system. The mixed-integer linear programming (MILP) models for UAV-routing and UAV-route scheduling problems are proposed considering the effect of incidental processes and the varying payload on travel time. A hybrid genetic and simulated annealing (HGSA) algorithm is proposed for the UAV-routing problem to minimize travel time. In HGSA, genetic algorithm (GA) employs a novel stochastic crossover operator to search for the optimal global position of customers, whereas simulated annealing (SA) utilizes local search operators to avoid the local optima. A UAV-Oriented MinMin (UO-MinMin) algorithm is also proposed to minimize the makespan of the UAV-route scheduling problem. It employs a UAV-oriented view to generate the route-scheduling order with minimal computational efforts without affecting the quality of the makespan. A Monte Carlo simulation-based sensitivity analysis is conducted to evaluate the impact of the hybridization probability of GA and SA in the proposed HGSA algorithm. To assess the performance of the HGSA algorithm, a set P of 24 benchmark instances is adopted and adjusted to meet the constraints of the UAV-Assisted delivery system. The proposed HGSA outperforms the state-of-the-art algorithms such as genetic algorithm (GA), Particle Swarm Optimization &amp; Simulated Annealing algorithm (PSO-SA), Differential Evolution &amp; Simulated Annealing (DE-SA), and Harris-hawks optimization (HHO). For all 24 instances, the aerial routes generated by HGSA have been used to evaluate the effectiveness of the UO-MinMin algorithm for different numbers of UAVs. The proposed UO-MinMin algorithm outperforms the base algorithms such as minimum completion time (MCT) and opportunistic load balancing (OLB).},
  archive      = {J_ASOC},
  author       = {Mohammad Sajid and Himanshu Mittal and Shreya Pare and Mukesh Prasad},
  doi          = {10.1016/j.asoc.2022.109225},
  journal      = {Applied Soft Computing},
  pages        = {109225},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Routing and scheduling optimization for UAV assisted delivery system: A hybrid approach},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Aggressive maneuvering of a quadcopter via differential
flatness-based fuzzy controllers: From tuning to experiments.
<em>ASOC</em>, <em>126</em>, 109223. (<a
href="https://doi.org/10.1016/j.asoc.2022.109223">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the rapid development in contemporary technology has brought nano quadcopters with high agility. This paper presents a new differential flatness-based Single Input Fuzzy Logic Controller (SFLC) structure for aggressive maneuvering control alongside its real-world application on Crazyflie 2.1 nano quadcopter. We propose both Type-1 and Interval Type-2 SFLCs as the primary controllers in the flight control system, which are built on the concept of differential flatness. We investigate how the design parameters of SFLCs shape the characteristics of the fuzzy mapping through a geometric approach by analyzing the region and level of aggressiveness/smoothness. Based on the analysis, we present simple tuning guidelines and then design fuzzy logic-based flight control systems, which were implemented as onboard real-time controllers. Finally, we evaluate the performance of SFLCs in comparison with their crisp differential flatness-based nonlinear counterparts for four trajectories with distinct dynamics and shapes in the real world. The presented comparative experimental results clearly show the performance improvements when the proposed T1 and IT2 SFLCs are deployed for real-time aggressive maneuvering.},
  archive      = {J_ASOC},
  author       = {Cagri Guzay and Tufan Kumbasar},
  doi          = {10.1016/j.asoc.2022.109223},
  journal      = {Applied Soft Computing},
  pages        = {109223},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Aggressive maneuvering of a quadcopter via differential flatness-based fuzzy controllers: From tuning to experiments},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Long-term forecasting of monthly mean reference
evapotranspiration using deep neural network: A comparison of training
strategies and approaches. <em>ASOC</em>, <em>126</em>, 109221. (<a
href="https://doi.org/10.1016/j.asoc.2022.109221">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prediction of reference evapotranspiration (ET 0 ) remains a challenge, especially with forward multi-step forecasting. The bottleneck facing current research is the limitation of the span of the forecasting time horizons, which can be rather disappointing, especially when long-term forecasting is desired. In this study, an explainable model structure, represented by a one-dimensional convolutional neural network (CNN-1D) was compared to the long short-term memory network (LSTM) and gated recurrent unit network (GRU), both formulated with black-box model method. The comparison included the application of different forecasting strategies (iterated vs. multiple-input–multiple-output (MIMO)) and approaches (direct vs. indirect). This study was conducted at four stations scattered across the Peninsular Malaysia. From the results of this study, the explainable CNN-1D model generally performed poorer than its black-box counterparts at most of the stations. The type of model and its structure, forecasting strategy and approach formed a complex relationship to indicate that there is no one-for-all solution in the case of the long-term prediction of monthly mean ET 0 . Despite that, the GRU-based models stood out as the most well-suited option for the task, with the MIMO forecasting strategy being favoured over the iterated strategy. At the four stations, the average mean absolute error (MAE), root mean square error (RMSE), mean percentage error (MAPE) and the Kling–Gupta efficiency (KGE) of the best GRU models were 0.182 mm/day, 0.260 mm/day, 4.972\% and 0.747, respectively. It was found that the prediction residual of the best GRU models did not possess a clear trend as the forecasting horizon was lengthened. The results implied that theoretically, the forecasting time horizon could be extended over to a longer temporal scale without any deterioration in the model performance. This finding is positive as it brings about the possibility of allocating the water budget with higher confidence. Nevertheless, the LSTM and GRU models developed in this study, were believed to have more tremendous potential if they were to be designed with purpose (such as the integration of optimisation algorithm), instead of being a mere black-box structure.},
  archive      = {J_ASOC},
  author       = {Min Yan Chia and Yuk Feng Huang and Chai Hoon Koo and Jing Lin Ng and Ali Najah Ahmed and Ahmed El-Shafie},
  doi          = {10.1016/j.asoc.2022.109221},
  journal      = {Applied Soft Computing},
  pages        = {109221},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Long-term forecasting of monthly mean reference evapotranspiration using deep neural network: A comparison of training strategies and approaches},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SLOVA: Uncertainty estimation using single label one-vs-all
classifier. <em>ASOC</em>, <em>126</em>, 109219. (<a
href="https://doi.org/10.1016/j.asoc.2022.109219">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks present impressive performance, yet they cannot reliably estimate their predictive confidence, limiting their applicability in high-risk domains. We show that applying a multi-label one-vs-all loss reveals classification ambiguity and reduces model overconfidence. The introduced SLOVA (Single Label One-Vs-All) model redefines typical one-vs-all predictive probabilities to a single label situation, where only one class is the correct answer. The proposed classifier is confident only if a single class has a high probability and other probabilities are negligible. Unlike the typical softmax function , SLOVA naturally detects out-of-distribution samples if the probabilities of all other classes are small. The model is additionally fine-tuned with exponential calibration, which allows us to precisely align the confidence score with model accuracy. We verify our approach on three tasks. First, we demonstrate that SLOVA is competitive with the state-of-the-art on in-distribution calibration. Second, the performance of SLOVA is robust under dataset shifts. Finally, our approach performs extremely well in the detection of out-of-distribution samples. Consequently, SLOVA is a tool that can be used in various applications where uncertainty modeling is required.},
  archive      = {J_ASOC},
  author       = {Bartosz Wójcik and Jacek Grela and Marek Śmieja and Krzysztof Misztal and Jacek Tabor},
  doi          = {10.1016/j.asoc.2022.109219},
  journal      = {Applied Soft Computing},
  pages        = {109219},
  shortjournal = {Appl. Soft. Comput.},
  title        = {SLOVA: Uncertainty estimation using single label one-vs-all classifier},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Physics-informed deep learning: A promising technique for
system reliability assessment. <em>ASOC</em>, <em>126</em>, 109217. (<a
href="https://doi.org/10.1016/j.asoc.2022.109217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based models for system prognostics and health management have received significant attention in the reliability and safety fields. However, limited progress has been achieved in the usage of deep learning for system reliability assessment. This paper aims to bridge this gap and explore the interface between deep learning and system reliability assessment by expanding and adapting recent advances in physics-informed deep neural networks . Particularly, we present a novel deep learning-based system reliability assessment and develop a physics-informed generative adversarial network-based approach to facilitate uncertainty quantification and propagation as well as enable measurement data fusion and incorporation into system reliability assessment. Three numerical examples employing a dual-processor computer system are used to demonstrate the proposed approach. Results show that the proposed approach has comparable performance to the widely used Runge–Kutta method and Monte Carlo simulation in handling deterministic scenarios. When dealing with probabilistic scenarios, the proposed approach is 16.5 times more computationally efficient than Monte Carlo simulation in uncertainty quantification and is effective in fusing measurement data for the system’s reliability assessment. The proposed approach offers a novel perspective and builds a link between deep learning and system reliability assessment for computational alleviation and data assimilation challenges.},
  archive      = {J_ASOC},
  author       = {Taotao Zhou and Enrique Lopez Droguett and Ali Mosleh},
  doi          = {10.1016/j.asoc.2022.109217},
  journal      = {Applied Soft Computing},
  pages        = {109217},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Physics-informed deep learning: A promising technique for system reliability assessment},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A clinical study on atrial fibrillation, premature
ventricular contraction, and premature atrial contraction screening
based on an ECG deep learning model. <em>ASOC</em>, <em>126</em>,
109213. (<a href="https://doi.org/10.1016/j.asoc.2022.109213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is still a challenge to develop an electrocardiography (ECG) interpreter based on ECG basic characteristics because of the uncertainty of ECG delineation. Based on the clinical investigation in this study, ECG devices generated interpretations of Atrial Fibrillation (AF), Premature Ventricular Contraction (PVC), and Premature Atrial Contraction (PAC) have high ratios of false-positive errors. An ECG interpretation gap exists between ECG devices and cardiologists . This study aimed to develop an ECG interpreter to improve the performance of AF, PVC, and PAC based on clinical ECGs. This study first adopted a deep learning model to delineate ECG features such as P, QRS, and T waves based on 1160 8–10-s lead I or lead II ECG signals from a clinically-used 12-lead ECG device whose ECG device interpretation is AF as a training dataset. Second, a sliding window with 3-RR intervals in length is applied to the raw ECG to examine the delineated features in the window, and the ECG interpretation is then determined based on the experiences of cardiologists. The results indicate the following: (1) This delineator achieves good performance on P-, QRS-, and T- wave delineation with a sensitivity/specificity of 0.94/0.98, 1.00/0.99, and 0.97/0.98, respectively, in 48 10-s test ECGs mixed with true-positive AF and false-positive AF ECGs. (2) As compared to ECG-device generated interpretations, the precision of the detection of AF, PVC, and PAC in this study was increased from 0.77 to 0.86, 0.76 to 0.84, and 0.82 to 0.87 in 188 10-s test ECGs. Finally, (3) the F1 measure, which is a measure of the accuracy of test data but takes false-positive and false-negative into account, on the detection of AF, PVC, and PAC were 0.92, 0.91, and 0.83, respectively. In conclusion, this study overcomes the difficulties of ECG P-wave discrimination between true-positive AF and false-positive AF which are not documented well in previous research and improves the precision of ECG devices’ interpretation. We believe that this study can facilitate clinical applications of ECG, and bridge the gap between machines’ ECG interpretation and cardiologists.},
  archive      = {J_ASOC},
  author       = {Jianyuan Hong and Hua-Jung Li and Chung-chi Yang and Chih-Lu Han and Jui-chien Hsieh},
  doi          = {10.1016/j.asoc.2022.109213},
  journal      = {Applied Soft Computing},
  pages        = {109213},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A clinical study on atrial fibrillation, premature ventricular contraction, and premature atrial contraction screening based on an ECG deep learning model},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A framework for predicting the remaining useful life of
machinery working under time-varying operational conditions.
<em>ASOC</em>, <em>126</em>, 109164. (<a
href="https://doi.org/10.1016/j.asoc.2022.109164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remaining useful life (RUL) prediction can provide additional capabilities to condition-based maintenance (CBM) and predictive maintenance (PdM) for the reliability and service life of a system. Time-varying operational conditions, such as the altitude, Mach number , and throttle resolver angle of an aero-engine, could result in two main challenges for RUL predictions: varying degradation rates and abrupt jumps in the amplitude of sensor readings. Our study addresses these two challenges in the data pre-processing stage, through operational condition features and the multi-operational condition-based normalization method (MOC-based Normalization). In the framework of our model, first, two density-based clustering algorithms are integrated to be a new classifier for operational conditions clustering and identification in an unsupervised manner . Then, operational condition features consisting of operational condition labels and an operational condition factor are conducted. In the meantime, the proposed MOC-based Normalization recalibrates the upward or downward abrupt jumps of sensor readings at the operational conditions change-points. Sensor data features and operational condition features are combined in the last step of the data pre-processing stage. On this basis, the RUL representation model is trained with the combined features through a gated recurrent unit (GRU)-based network with only two layers in the hidden layer. Experiments on benchmark datasets have been conducted. The results show that the MOC-based Normalization efficiently mitigates the jumps on sensor readings, and the operational condition features improve the prognostic model. Approximately 10\% RMSE improvements over the top-three state-of-the-art algorithms are achieved in the RUL prediction under time-varying operational conditions.},
  archive      = {J_ASOC},
  author       = {Zhiyao Zhang and Xiaohui Chen and Enrico Zio},
  doi          = {10.1016/j.asoc.2022.109164},
  journal      = {Applied Soft Computing},
  pages        = {109164},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A framework for predicting the remaining useful life of machinery working under time-varying operational conditions},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fuzzy clustering for multiview data by combining latent
information. <em>ASOC</em>, <em>126</em>, 109140. (<a
href="https://doi.org/10.1016/j.asoc.2022.109140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiview data has become very important because it is often possible to obtain multiple representations for the same set of objects. From the perspective of soft partition, this paper proposes a novel fuzzy clustering method for multiview data by combining the latent information or the membership matrices from the classical Fuzzy C-means (FCM) in each view. Considering that multiview data are generated from the same latent subspace, to assist the membership matrix in one view to explore more complementary information from other views, the proposed approach first aligns the set of membership matrices from FCMs in different views to a consensus matrix. To this end, a new objective function of fuzzy clustering is formulated and the optimization method of membership matrices is provided. Then, the optimized latent information or the membership matrix for each view is concatenated into a tensor and the final clustering is derived with the help of tensor decomposition to further exploit high order correlations between different views. To balance the importance of each view, the weighted-view version of the proposed method is also developed. In addition, we analyze the convergence of proposed methods and their computational complexity . Three experimental indices NMI, F-measure and ACC demonstrate that the proposed approach is superior to the latest multiview fuzzy clustering algorithms .},
  archive      = {J_ASOC},
  author       = {Huiqin Wei and Long Chen and C.L. Philip Chen and Junwei Duan and Ruizhi Han and Li Guo},
  doi          = {10.1016/j.asoc.2022.109140},
  journal      = {Applied Soft Computing},
  pages        = {109140},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fuzzy clustering for multiview data by combining latent information},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). L2-loss nonparallel bounded support vector machine for
robust classification and its DCD-type solver. <em>ASOC</em>,
<em>126</em>, 109125. (<a
href="https://doi.org/10.1016/j.asoc.2022.109125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study a new classification methodology to enhance the robustness and convergence of the nonparallel support vector machine (NPSVM), namely L2-Loss nonparallel bounded SVM (L2-NPBSVM). We first define a L2-Loss and an adjustable hinge loss for NPSVM. Then, using the two loss functions, we propose the L2-NPBSVM algorithm. Both the L2-loss and the adjustable hinge loss are insensitive to the feature noise around the decision boundary. In addition, the L2-Loss can make full use of the margin distribution information in the training samples. The margin distribution is more important than margin maximization for generalization performance . Furthermore, an additional regularization term is added into the objective functions of L2-NPBSVM. It can ensure the global solution and stability of optimization problems . Thus, the classification performance of L2-NPBSVM can be further improved. In addition, in order to shorten the training time, the dual coordinate descent (DCD) algorithm is described and analyzed to optimize L2-NPBSVM. Numerical experiments on different datasets demonstrate that our L2-NPBSVM has the advantages of strong robustness, strong generalization ability and fast convergence.},
  archive      = {J_ASOC},
  author       = {Liming Liu and Ping Li and Maoxiang Chu and Zixuan Zhai},
  doi          = {10.1016/j.asoc.2022.109125},
  journal      = {Applied Soft Computing},
  pages        = {109125},
  shortjournal = {Appl. Soft. Comput.},
  title        = {L2-loss nonparallel bounded support vector machine for robust classification and its DCD-type solver},
  volume       = {126},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A shuffled cellular evolutionary grey wolf optimizer for
flexible job shop scheduling problem with tree-structure job precedence
constraints. <em>ASOC</em>, <em>125</em>, 109235. (<a
href="https://doi.org/10.1016/j.asoc.2022.109235">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Along with the growing demands for customized products and small batch production , the flexible job shop manufacturing environment becomes increasingly popular. Efficient flexible job shop scheduling plays a crucial role in making quick responses to production orders with low volume and high variety. When producing complex assembly products that are comprised of multiple and multilevel intermediate parts organized as tree-structure Bills-Of-Materials (BOMs), jobs get restricted by hierarchical precedence constraints due to dependencies between manufactured parts. To cope with this condition, this paper formulates a flexible job shop scheduling problem with job precedence constraints (FJSSP-JPC). A novel shuffled cellular evolutionary grey wolf optimizer (SCEGWO) is proposed to solve FJSSP-JPC with the objective of minimizing makespan. Schedule solutions are encoded as elaborately designed triple-vectors involving the information of job sequencing, grouped operation sequencing and machine assignment, while the satisfactions of job precedence constraints are guaranteed by binary sort tree-based repair mechanism. In SCEGWO, each individual interacts with its topological cellular neighborhood by conducting a micro discrete variant of grey wolf optimizer (GWO), causing that the whole population is decomposed into multiple subpopulations which communicate by the neighborhood overlapping. Extensive experimental results demonstrate that the components of SCEGWO are effective and the proposed SCEGWO outperforms other competing algorithms significantly on the addressed problem.},
  archive      = {J_ASOC},
  author       = {Zhenwei Zhu and Xionghui Zhou and Diansong Cao and Ming Li},
  doi          = {10.1016/j.asoc.2022.109235},
  journal      = {Applied Soft Computing},
  pages        = {109235},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A shuffled cellular evolutionary grey wolf optimizer for flexible job shop scheduling problem with tree-structure job precedence constraints},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Edge preserving range image smoothing using hybrid locally
kernel-based weighted least square. <em>ASOC</em>, <em>125</em>, 109234.
(<a href="https://doi.org/10.1016/j.asoc.2022.109234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose the hybrid locally kernel-based weighted least square (HKLS) method to reduce the noise of the range images captured from the Microsoft Kinect sensor. Although removing the noise of Kinect sensor is inevitable in mobile robot applications, preserving the main structures of an indoor scene is a key point of the smoothing methods for range data. Our method uses a situation estimation module to apply an appropriate method for denoising the input data. In this paper, situations are classified into two categories including flat regions and edge regions. The locally kernel-based weighted least square method is used for the edge regions that have significant changes in the surface normals and the weight of each point is assigned with the Gaussian mixture model . The Bilateral filtering is applied for the flat regions with no sharp change in surface normals. We provided a solution for the noise data issue and proof of uncertainty reduction in presence of noise data. There is a fusion module for assigning the proportion of each method according to the different situations. We evaluated our method on the NYUv2 dataset that contains different RGB-D indoor scenes with other state-of-the-art methods. We achieved the value of 49.48 for the Z-MAE and 0.502 for the N-MAE error metrics.},
  archive      = {J_ASOC},
  author       = {Tahereh Bahraini and Taha Hamedani and Seyed Mohammad Hosseini and Hadi Sadoghi Yazdi},
  doi          = {10.1016/j.asoc.2022.109234},
  journal      = {Applied Soft Computing},
  pages        = {109234},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Edge preserving range image smoothing using hybrid locally kernel-based weighted least square},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Graph based ensemble classification for crime report
prediction. <em>ASOC</em>, <em>125</em>, 109215. (<a
href="https://doi.org/10.1016/j.asoc.2022.109215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Criminology and crime analysis are growing areas of research dealing with huge amount of past crime reports. Classification analysis identifies the crime patterns among the reports and predicts the crime category of new reports. As different classifiers classify a data set with different accuracy, so ensemble classification is the appropriate choice for many applications. The present work demonstrates a graph based ensemble classification approach to predict crime reports more accurately than the individual classifiers . Initially, the crime reports are graphically modelled to find a set of maximal independent subset of features and subsequently, decision tree based classifiers are designed using these subsets. Next, a graph is constructed with generated decision trees as nodes and the same method is applied to find out a set of maximal independent subsets of decision trees, each of which is considered as an initial ensemble classifier . Finally, these classifiers are ensemble using the traditional Boolean algebra properties to generate the final ensemble classifier . The developed model may be helpful for crime analysis by the law enforcement agencies for controlling the criminal activities in the country. Extensive experiments are conducted for evaluating the performance of the proposed method on several crime data sets. The superior performance demonstrates the effectiveness of the developed ensemble classification model and indicates its wide potential applications in crime domain.},
  archive      = {J_ASOC},
  author       = {Asit Kumar Das and Priyanka Das},
  doi          = {10.1016/j.asoc.2022.109215},
  journal      = {Applied Soft Computing},
  pages        = {109215},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Graph based ensemble classification for crime report prediction},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cuckoo search algorithm with fuzzy logic and gauss–cauchy
for minimizing localization error of WSN. <em>ASOC</em>, <em>125</em>,
109211. (<a href="https://doi.org/10.1016/j.asoc.2022.109211">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The location of the sensor node is critical in wireless sensor networks (WSN) as the information acquired by the sensor node may be worthless without knowing its source. However, high accurate positioning of sensor nodes remains a big challenge. To overcome the barrier, an improved cuckoo search algorithm with fuzzy logic and Gauss–Cauchy strategy (ICS-FG) is proposed, that integrates the meta-heuristic algorithm with the traditional method. To regulate the dynamic adjustment of parameters, our study proposes a fuzzy logic based on population diversity. The proposed Gauss–Cauchy strategy significantly improve the algorithm’s search accuracy while enhancing its robustness when evaluated on several selected benchmark functions and locating unknown nodes in WSN. Experimental results obtained from well-known benchmark functions demonstrate the advance of the ICS-FG approach over the parallel compact cuckoo search algorithm (pcCS), improved adaptive genetic algorithm (IAGA), and other remarkable methods. By quantitative assessment , the proposed ICS-FG approach achieves a lower positioning error than pcCS, IAGA, and other state-of-the-art algorithms.},
  archive      = {J_ASOC},
  author       = {Xianfeng Ou and Meng Wu and Yuanyuan Pu and Bing Tu and Guoyun Zhang and Zhi Xu},
  doi          = {10.1016/j.asoc.2022.109211},
  journal      = {Applied Soft Computing},
  pages        = {109211},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Cuckoo search algorithm with fuzzy logic and Gauss–Cauchy for minimizing localization error of WSN},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pinball transfer support matrix machine for roller bearing
fault diagnosis under limited annotation data. <em>ASOC</em>,
<em>125</em>, 109209. (<a
href="https://doi.org/10.1016/j.asoc.2022.109209">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a classical matrix classification technology, support matrix machine (SMM) takes the matrix as the input element, so that the structure information between matrix samples is maximized to establish an accurate classification model . However, in practical industrial practice, it is difficult to collect enough annotation samples for SMM to find the optimal hyperplane . To solve this issue, a new pinball transfer support matrix machine (PTSMM) method is proposed in this paper. In the case of limited annotation sample, PTSMM trains a model using a large amount of labeled source domain data , and then fine-tunes the prior model using a small amount of target domain data , so as to obtain an optimal model for target domain. Besides, the pinball attribute is applied to the objective function to make the direct distance of the hyperplane larger, which weakens the influence of noise on the hyperplane. The two different roller bearing experiment results show that PTSMM effectively uses the samples of source domain and target domain for modeling, and the diagnostic accuracy is more than 4\% higher than SMM and its improved algorithms.},
  archive      = {J_ASOC},
  author       = {Haiyang Pan and Li Sheng and Haifeng Xu and Jinyu Tong and Jinde Zheng and Qingyun Liu},
  doi          = {10.1016/j.asoc.2022.109209},
  journal      = {Applied Soft Computing},
  pages        = {109209},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Pinball transfer support matrix machine for roller bearing fault diagnosis under limited annotation data},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep transfer learning for the recognition of types of face
masks as a core measure to prevent the transmission of COVID-19.
<em>ASOC</em>, <em>125</em>, 109207. (<a
href="https://doi.org/10.1016/j.asoc.2022.109207">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of face masks in public places has emerged as one of the most effective non-pharmaceutical measures to lower the spread of COVID-19 infection. This has led to the development of several detection systems for identifying people who do not wear a face mask. However, not all face masks or coverings are equally effective in preventing virus transmission or illness caused by viruses and therefore, it appears important for those systems to incorporate the ability to distinguish between the different types of face masks. This paper implements four pre-trained deep transfer learning models (NasNetMobile, MobileNetv2, ResNet101v2, and ResNet152v2) to classify images based on the type of face mask (KN95, N95, surgical and cloth) worn by people. Experimental results indicate that the deep residual networks (ResNet101v2 and ResNet152v2) provide the best performance with the highest accuracy and the lowest loss.},
  archive      = {J_ASOC},
  author       = {Ricardo Mar-Cupido and Vicente García and Gilberto Rivera and J. Salvador Sánchez},
  doi          = {10.1016/j.asoc.2022.109207},
  journal      = {Applied Soft Computing},
  pages        = {109207},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Deep transfer learning for the recognition of types of face masks as a core measure to prevent the transmission of COVID-19},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-attention representation network partial domain
adaptation for COVID-19 diagnosis. <em>ASOC</em>, <em>125</em>, 109205.
(<a href="https://doi.org/10.1016/j.asoc.2022.109205">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The outbreak of COVID-19 threatens the safety of all human beings. Rapid and accurate diagnosis of patients is the effective way to prevent the rapid spread of COVID-19. The current computer-aided diagnosis of COVID-19 requires extensive labeled data for training, and this undoubtedly increases human and material resources costs. Domain adaptation (DA), an existing promising approach, can transfer knowledge from rich labeled pneumonia datasets for COVID-19 diagnosis and classification. However, due to the differences in feature distribution and task semantic between pneumonia and COVID-19, negative transfer may reduce the performance in diagnosis COVID-19 and pneumonia. Furthermore, the training data is usually mixed with many noise samples in practice, and this also poses new challenges for domain adaptation. As a kind of domain adaptation, partial domain adaptation (PDA) can well avoid outlier samples in the source domain and achieve good classification performance in the target domain. However, the existing PDA methods all learn a single feature representation; this can only learn local information about the inputs and ignore other important information in the samples. Therefore multi-attention representation network partial domain adaptation (MARPDA) is proposed in this paper to overcome the above shortcomings of PDA. In MARPDA, we construct the multiple representation networks with attention to acquire the image representation and effectively learn knowledge from different feature spaces. We design the sample-weighted strategy to achieve partial data transfer and address the negative transfer of noise data during training. MARPDA adapts to complex application scenarios and learns fine-grained features of the image from multiple representations. We apply the model to classify pneumonia and COVID-19 respectively, and evaluate it in qualitative and quantitative manners. The experimental results show that our classification accuracy is higher than that of the existing state-of-the-art methods. The stability and reliability of the proposed method are validated by the confusion matrix and the performance curves experiments. In summary, our method has better performance for diagnosis COVID-19 compared to the existing state-of-the-art methods.},
  archive      = {J_ASOC},
  author       = {Chunmei He and Lanqing Zheng and Taifeng Tan and Xianjun Fan and Zhengchun Ye},
  doi          = {10.1016/j.asoc.2022.109205},
  journal      = {Applied Soft Computing},
  pages        = {109205},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-attention representation network partial domain adaptation for COVID-19 diagnosis},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An adaptive differential evolution with extended historical
memory and iterative local search. <em>ASOC</em>, <em>125</em>, 109203.
(<a href="https://doi.org/10.1016/j.asoc.2022.109203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-decomposition methods are designed to tackle high-dimensional problems as a whole. These methods often utilize different effective approaches or are integrated with some optimization components to enhance the performance. The non-decomposition method SHADE-ILS, SHADE with iterative local search, adopts a historical memory that stores successful information of control parameters to make better guidance for parameters’ adaptation. In order to achieve more about this successful information and improve the adaptation, a modified version, an adaptive differential evolution with extended historical memory (mSHADE), is proposed and the Solis and Wets method is applied in the new algorithm. Besides, a permanent record is designed to increase the diversity to prevent the algorithm from stagnant. Finally, specially designed to tackle high-dimensional problems, we combine mSHADE with iterative local search. The proposed algorithm is tested on CEC’2010, SOCO’2011 and CEC’2013 large-scale global optimization benchmarks, and compared with seven state-of-the-art algorithms. The results show that our proposed algorithm is competitive for high-dimensional problems.},
  archive      = {J_ASOC},
  author       = {Caifeng Chen and Yuan Yan and Qunfeng Liu},
  doi          = {10.1016/j.asoc.2022.109203},
  journal      = {Applied Soft Computing},
  pages        = {109203},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An adaptive differential evolution with extended historical memory and iterative local search},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A similarity measure-based pythagorean fuzzy additive ratio
assessment approach and its application to multi-criteria sustainable
biomass crop selection. <em>ASOC</em>, <em>125</em>, 109201. (<a
href="https://doi.org/10.1016/j.asoc.2022.109201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the modern world, the selection of an optimal sustainable biomass crop type for biofuel production can be assumed as a multi-criteria decision-making problem due to numerous conflicting criteria. Therefore, uncertainty usually arises in sustainable biomass crop selection problems, and the Pythagorean fuzzy set, an extension of the intuitionistic fuzzy set, has been shown as a prolific tool to tackle uncertain and ambiguous information. Thus, the aim of the paper is to introduce an extended additive ratio assessment methodology to assess the sustainable biomass crop selection problem on Pythagorean fuzzy sets. In this method, a new Pythagorean fuzzy similarity measure is proposed. Afterward, a weighting procedure is developed based on the introduced similarity measure and score function to compute the criteria significance degrees. The computational process of the developed framework is illustrated using a case study of sustainable biomass crop selection with uncertain information, which verifies the feasibility and efficacy of the developed approach. Further, this work makes comparative and sensitivity analyses to confirm the steadiness and robustness of the presented method. The results illustrate that the developed method is a useful, practical, and valuable way to rank the sustainable biomass crop alternatives with uncertainty.},
  archive      = {J_ASOC},
  author       = {Arunodaya Raj Mishra and Pratibha Rani and Fausto Cavallaro and Abbas Mardani},
  doi          = {10.1016/j.asoc.2022.109201},
  journal      = {Applied Soft Computing},
  pages        = {109201},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A similarity measure-based pythagorean fuzzy additive ratio assessment approach and its application to multi-criteria sustainable biomass crop selection},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic binary and ternary change detection in SAR images
based on evolutionary multiobjective optimization. <em>ASOC</em>,
<em>125</em>, 109200. (<a
href="https://doi.org/10.1016/j.asoc.2022.109200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In most of the previous works, changed and unchanged regions are detected by analyzing the changes of backscattering coefficients for SAR images , which is termed as binary change detection. In fact, due to the increase and decrease of backscattering coefficients , the changed regions can be further analyzed as two kinds of changes, which is termed as ternary change detection. In this paper, a change detection method based on evolutionary multiobjective optimization is proposed to automatically perform binary and ternary change detection of multitemporal SAR images . First, the log-likelihood function of the Gaussian mixture model and the Bhattacharyya distance are designed as two objectives, respectively. In particular, a novel measurement method based on Bhattacharyya distance is designed for the ternary change detection task. Not only the separability between each two classes is maximized, but also the Bhattacharyya distance between two changed classes and unchanged class is kept closer to obtain a more balanced classification performance. Then a multiobjective optimization method based on non-dominated sorting is used to optimize these two objectives simultaneously. In the proposed approach, chromosome ranking and perturbation probability selection operators are designed to make high-quality solutions with a high probability of being exploited and improve the performance of the algorithm. In addition, a one-step local search strategy based on the expectation–maximization method is integrated into the proposed algorithm to accelerate the convergence. Experimental results on simulated and real-world datasets demonstrate the effectiveness and robustness of the proposed algorithm.},
  archive      = {J_ASOC},
  author       = {Wencheng Han and Hao Li and Maoguo Gong},
  doi          = {10.1016/j.asoc.2022.109200},
  journal      = {Applied Soft Computing},
  pages        = {109200},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Automatic binary and ternary change detection in SAR images based on evolutionary multiobjective optimization},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fuzzy fault tree analysis of chlorine gas release hazard in
chlor-alkali industry using α-cut interval-based similarity aggregation
method. <em>ASOC</em>, <em>125</em>, 109199. (<a
href="https://doi.org/10.1016/j.asoc.2022.109199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In chemical industries, the release of toxic gases and chemicals is always a serious concern as it has the potential to harm human life and the environment, leading to significant losses. Risk assessment in chemical industries is essential to identify and prevent such type of unwanted hazards. Conventional fault tree analysis has been used effectively to identify the system failure causes and evaluate the system reliability, but it requires quantitative historical failure data of system components. In many real-world applications, it can be difficult to obtain precise and sufficient quantitative failure data of system components. This research paper proposes a novel fuzzy set theory-based fault tree analysis to evaluate system failure probability by utilizing the available qualitative data such as expert opinions/views when quantitative historical failure data of system components is unavailable or insufficient. To aggregate the different opinions of selected experts, a new similarity aggregation method is developed by using interval distance-based similarity measure function. The proposed fuzzy fault tree analysis applies system fault tree, α α -cut intervals of fuzzy membership functions , and interval arithmetic operations . To validate the applicability and effectiveness of proposed approach, the basic event probabilities in fault tree analysis of chlorine release from storage and filling facility are generated using proposed approach and then compared with the known probabilities. Further, importance analysis is performed to evaluate the contribution of each basic event in top event “chlorine release” occurrence that would help the decision makers to identify the risk factor of chlorine release. The obtained results may be helpful for decision makers to decide whether and where to take protective actions in the risk management process .},
  archive      = {J_ASOC},
  author       = {Mohit Kumar and Kulbir Singh},
  doi          = {10.1016/j.asoc.2022.109199},
  journal      = {Applied Soft Computing},
  pages        = {109199},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fuzzy fault tree analysis of chlorine gas release hazard in chlor-alkali industry using α-cut interval-based similarity aggregation method},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast convolutional neural network with iterative and
non-iterative learning. <em>ASOC</em>, <em>125</em>, 109197. (<a
href="https://doi.org/10.1016/j.asoc.2022.109197">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional Neural Networks (CNNs) have achieved potentially good results for image classification . Due to their learning capabilities such networks are explored and implemented in real world applications . However, when it comes to training a CNN on large datasets without transfer learning , it takes long time and resources, due to the iterative process of weight update in fully connected layer. The backpropagation algorithm used to train the entire network suffers from slow convergence, getting trapped in a local minimum, not guaranteed to find global minimum and being hypersensitive to the learning rate set-up. Therefore, in this paper we propose a novel architecture of convolutional neural network with a non-iterative radial basis function-based classification layer which makes it more efficient for image classification tasks. This is a partially parameter free direct learning approach, which is highly beneficial in real-world applications as well as learning associated with large datasets. The proposed approach has been evaluated on four benchmark datasets such as CIFAR-10, MNIST, Digit and CE-MRI. It has achieved the accuracy scores of 99.8\%, 99.8\%, 98.4\% and 98.3\% on MNIST, Digit, CE-MRI and CIFAR-10 datasets respectively, when ResNet18 was used as backbone. Experimental results have illustrated that the proposed architecture is much better as it requires less parameter tuning, does not require handcrafted features and achieves same or higher accuracy in relatively lesser time than the standard CNN. Statistical significance tests were carried out to prove the efficiency of the proposed approach.},
  archive      = {J_ASOC},
  author       = {Toshi Sinha and Brijesh Verma},
  doi          = {10.1016/j.asoc.2022.109197},
  journal      = {Applied Soft Computing},
  pages        = {109197},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fast convolutional neural network with iterative and non-iterative learning},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A2AE: Towards adaptive multi-view graph representation
learning via all-to-all graph autoencoder architecture. <em>ASOC</em>,
<em>125</em>, 109193. (<a
href="https://doi.org/10.1016/j.asoc.2022.109193">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-view graph is a fundamental data model, which is used to describe complex networks in the real world. Learning the representation of multi-view graphs is a vital step for understanding complex systems and extracting knowledge accurately. However, most existing methods focus on a certain view or simply add multiple views together, which prevents them from making the best of the rich relational information in multiple views and ignores the importance of different views. In this paper, a novel all-to-all graph autoencoder is proposed for multi-view graph representation learning, namely A2AE. The all-to-all model first embeds the attribute multi-view graph into compact representations by semantic fusing the view-specific compact representations from multi-encoders, and then multi-decoders are trained to reconstruct graph structure and attributes. Finally, a self-training clustering module is attached for clustering tasks .},
  archive      = {J_ASOC},
  author       = {Dengdi Sun and Dashuang Li and Zhuanlian Ding and Xingyi Zhang and Jin Tang},
  doi          = {10.1016/j.asoc.2022.109193},
  journal      = {Applied Soft Computing},
  pages        = {109193},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A2AE: Towards adaptive multi-view graph representation learning via all-to-all graph autoencoder architecture},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Variable neighborhood-based cuckoo search for production
routing with time window and setup times. <em>ASOC</em>, <em>125</em>,
109191. (<a href="https://doi.org/10.1016/j.asoc.2022.109191">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Major corporations compete over the strengths of their supply chains. Integrating production and distribution operations helps improve supply chain connectedness and responsiveness beyond the standalone optimization norms. This study proposes an original Mixed-Integer Linear Programming (MILP) formulation for the Production scheduling-based Routing Problem with Time Window and Setup Times (PRP-TWST). For this purpose, the identical parallel machine scheduling is integrated with the vehicle routing problem. Considering the highly intractable solution spaces of the integrated problem, hybrid metaheuristics based on the Variable Neighborhood Search (VNS), Particle Swarm Optimization (PSO), and Cuckoo Search (CS) algorithms are developed to solve the PRP-TWST problem. Extensive numerical experiments are conducted to evaluate the effectiveness of the developed algorithms considering the total delay time as the objective function. The results are supportive of the VNS-based CS algorithm’s effectiveness; the developed metaheuristics can be considered strong benchmarks for further developments in the field. This study is concluded by suggesting directions for modeling and managing integrated operations in the supply chain context.},
  archive      = {J_ASOC},
  author       = {Gen-Han Wu and Chen-Yang Cheng and Pourya Pourhejazy and Bai-Lyn Fang},
  doi          = {10.1016/j.asoc.2022.109191},
  journal      = {Applied Soft Computing},
  pages        = {109191},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Variable neighborhood-based cuckoo search for production routing with time window and setup times},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Context-aware reinforcement learning for course
recommendation. <em>ASOC</em>, <em>125</em>, 109189. (<a
href="https://doi.org/10.1016/j.asoc.2022.109189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online course recommendation is an extremely relevant ingredient for the efficiency of e-learning. The current recommendation methods cannot guarantee the effectiveness and accuracy of course recommendation, especially when a user has enrolled in many different courses. Because these methods fail to distinguish the most relevant historical courses, which can contribute to predicting the target course that indeed reflects the user’s interests from her sequential learning behaviors. In this paper, we propose a context-aware reinforcement learning method, named Hierarchical and Recurrent Reinforcement Learning (HRRL), to efficiently reconstruct user profiles for course recommendation. The key ingredient of our scheme is the novel interaction between an attention-based recommendation model and a profile reviser with Recurrent Reinforcement Learning (RRL) that exploits temporal context. To this aim, a contextual policy gradient with approximation is proposed for RRL. By employing RRL in hierarchical tasks of revising user profiles, the proposed HRRL model enables reliable convergence in revising policy learning and improves the recommendation accuracy. We demonstrate the effectiveness of our proposed method by experiments on two open online courses datasets. Empirical results show that HRRL significantly outperforms state-of-the-art baselines.},
  archive      = {J_ASOC},
  author       = {Yuanguo Lin and Fan Lin and Lvqing Yang and Wenhua Zeng and Yong Liu and Pengcheng Wu},
  doi          = {10.1016/j.asoc.2022.109189},
  journal      = {Applied Soft Computing},
  pages        = {109189},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Context-aware reinforcement learning for course recommendation},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-objective centralised agent-based optimisation
approach for vehicle routing problem with unique vehicles.
<em>ASOC</em>, <em>125</em>, 109187. (<a
href="https://doi.org/10.1016/j.asoc.2022.109187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by heterogeneous service suppliers in crowd shipping routing problems, vehicles’ similarity assumption is questioned in the well-known logistical Vehicle Routing Problems (VRP) by considering different start/end locations, capacities, as well as shifts in the Time Window variant (VRPTW). In order to tackle this problem, a new agent-based metaheuristic architecture is proposed to capture the uniqueness of vehicles by modelling them as agents while governing the search with centralised agent cooperation. This cooperation aims to generate near optimum routes by minimising the number of vehicles used, total travelled distance, and total waiting times. The innovative architecture encapsulates three individual core modules in a flexible metaheuristic implementation. First, the problem is modelled by an agent-based module that includes its components in representing, evaluating, and altering solutions. A second metaheuristic module is then designed and integrated, followed by a multi-objective module introduced to sort solutions generated by the metaheuristic module based on Pareto dominance. Tests on benchmark instances were run, resulting in better waiting times, with an average reduction of 2.21-time units, at the expense of the other objectives. Benchmark instances are modified to tackle the unique vehicle’s problem by randomising locations, capacities, and operating shifts and tested to justify the proposed model’s applicability.},
  archive      = {J_ASOC},
  author       = {Anees Abu-Monshar and Ammar Al-Bazi},
  doi          = {10.1016/j.asoc.2022.109187},
  journal      = {Applied Soft Computing},
  pages        = {109187},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-objective centralised agent-based optimisation approach for vehicle routing problem with unique vehicles},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Dynamic memory intelligent algorithm used for prediction of
thermal error reliability of ball screw system. <em>ASOC</em>,
<em>125</em>, 109183. (<a
href="https://doi.org/10.1016/j.asoc.2022.109183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The thermal error of machine tools is one of the main factors affecting the machining accuracy of machine tools. Most of the existed literatures do not consider the randomness of the influencing factors of thermal error, there are still difficulties in accurate prediction and compensation of thermal error. Therefore, the new prediction models with higher accuracy and reliability are urgently needed. Through simulating the dynamic process of memory loss of the human brain after receiving external excitation, a new dynamic time-varying memory intelligent algorithm with external excitation is proposed in this paper. Furthermore, a novel random dynamic time-varying memory intelligent algorithm with external excitation is proposed considering the randomness of factors in this paper. Considering the randomness of factors affecting thermal error, the proposed models are used for the prediction of reliability of thermally-deduced positioning accuracy for machine tool ball screw system under external excitation caused by manufacturing process alternations of machine tools. Finally, the effectiveness of the proposed models is verified by the experiment. Because the presented model can consider the randomness of factors affecting thermal error and the impact and hysteresis phenomenon caused by the alternations of multiple processes, it is suitable for the accurate prediction of the dynamic characteristics under the alternation of arbitrary excitation considering the reliability.},
  archive      = {J_ASOC},
  author       = {Tie-jun Li and Ting-ying Sun and Yi-min Zhang and Shang-yi Cui and Chun-yu Zhao},
  doi          = {10.1016/j.asoc.2022.109183},
  journal      = {Applied Soft Computing},
  pages        = {109183},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dynamic memory intelligent algorithm used for prediction of thermal error reliability of ball screw system},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). COVID-19 ICU demand forecasting: A two-stage prophet-LSTM
approach. <em>ASOC</em>, <em>125</em>, 109181. (<a
href="https://doi.org/10.1016/j.asoc.2022.109181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent literature has revealed a growing interest in methods for anticipating the demand for medical items and personnel at hospital, especially during turbulent scenarios such as the COVID-19 pandemic. In times like those, new variables appear and affect the once known demand behavior. This paper investigates the hypothesis that the combined Prophet-LSTM method results in more accurate forecastings for COVID-19 hospital Intensive Care Units (ICUs) demand than both standalone models, Prophet and LSTM (Long Short-Term Memory Neural Network). We also compare the model to well-established demand forecasting benchmarks. The model is tested to a representative Brazilian municipality that serves as a medical reference to other cities within its region. In addition to traditional time series components, such as trend and seasonality, other variables such as the current number of daily COVID-19 cases, vaccination rates, non-pharmaceutical interventions, social isolation index, and regional hospital beds occupation are also used to explain the variations in COVID-19 hospital ICU demand. Results indicate that the proposed method produced Mean Average Errors (MAE) from 13\% to 45\% lower than well established statistical and machine learning forecasting models, including the standalone models.},
  archive      = {J_ASOC},
  author       = {Dalton Borges and Mariá C.V. Nascimento},
  doi          = {10.1016/j.asoc.2022.109181},
  journal      = {Applied Soft Computing},
  pages        = {109181},
  shortjournal = {Appl. Soft. Comput.},
  title        = {COVID-19 ICU demand forecasting: A two-stage prophet-LSTM approach},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Type-2 fuzzy blended improved d-s evidence theory based
decision fusion for face recognition. <em>ASOC</em>, <em>125</em>,
109179. (<a href="https://doi.org/10.1016/j.asoc.2022.109179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data acquisition from (single/multiple) sensors can efficiently be combined by exploiting neural networks (NN) for accurate supervising of pattern recognition especially for biometric face recognition. In case where information obtained from the different sensor shows highly conflicting, the classical Dempster’s combination rule may give rise counter-intuitive result. This paper presents type-2 fuzzy blended improved Evidence D-S ( T2FI E - D S T2FIE-DS DLF ) combination rule for multi sensor data fusion which minimizes paradoxes of Dempster–Shafer (D-S) combination rule. Different textural facial image (using LBP and LTP) with genetically algorithm based G2DLDA methods are employed to generate feature vector corresponding to a face image. Multiple Basic Probability Assignments (BPA) corresponding to a class with respect to different feature vectors can be combined by using Vertical Slice Centroid Type reduction (VCTR) and the mass function using evidence theory is calculated to find the score for the class. The class having the maximum score is conceived as the class of input test face image. Our T2FI E - D S E-DS DLF method is evaluated with two popular classifiers — radial basis function (RBF) neural network, and support vector machines (SVM). The numerical examples presented shows the effectiveness of our method. Moreover, to validate the efficiency of our T2FI E - D S E-DS DLF method, we have compared our method with some state-of-the-art methods.},
  archive      = {J_ASOC},
  author       = {Manas Ghosh and Aniruddha Dey and Sayan Kahali},
  doi          = {10.1016/j.asoc.2022.109179},
  journal      = {Applied Soft Computing},
  pages        = {109179},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Type-2 fuzzy blended improved D-S evidence theory based decision fusion for face recognition},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Video frame prediction with dual-stream deep network
emphasizing motions and content details. <em>ASOC</em>, <em>125</em>,
109170. (<a href="https://doi.org/10.1016/j.asoc.2022.109170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video frame prediction is both challenging and critical for computer vision . Though the research on predicting video frames has gradually shifted from pixel-law based methods to motion based ones, existing predictors often generate ambiguous future frames, especially for long-term predictions. This paper proposes a composed model to generate future frames with more details. First, to further exploit motion information, we design a single motion decoder to strengthen the efficiency of the motion encoder in the original motion-content network (MCnet). Second, to alleviate prediction ambiguousness, we use both edges with and without semantic meanings from the holistically-nested edge detection (HED) module as content details. Third, based on the conclusion that the mean squared error (MSE) loss and the traditional generative adversarial learning framework cause the unsatisfied predictions of MCnet, we design a composite loss function that can guide our model to simultaneously focus on motions and content details. Also, based on the abovementioned conclusion, we finally embed our model in an improved generative adversarial network , which further enhances its performance. Experimental results on the benchmark KTH and UCF101 datasets show that our model outperforms the state-of-the-art predictors, such as the basic MCnet, the predictive neural network (PredNet), and the PredNet with a reduced-gate convolutional network (rgc-PredNet), in terms of peak signal to noise ratio (PSNR) and structural similarity index measure (SSIM), especially for long-term video frame prediction.},
  archive      = {J_ASOC},
  author       = {Qingming Huang and Zhongxiao Li and Liying Zheng and Tianyi Yang},
  doi          = {10.1016/j.asoc.2022.109170},
  journal      = {Applied Soft Computing},
  pages        = {109170},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Video frame prediction with dual-stream deep network emphasizing motions and content details},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A predictive intelligence approach for low-light
enhancement. <em>ASOC</em>, <em>125</em>, 109168. (<a
href="https://doi.org/10.1016/j.asoc.2022.109168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images captured in low-light scenes often suffer from poor contrast, severe loss of details and a lot of noise. These issues mentioned above can degrade the performance of some computer vision tasks such as object detection and recognition. The Retinex theory , which decomposes low-light images into reflection and illumination components, is an effective tool for predicting high-light images. Most Retinex-based methods cannot deal with noise reduction and over-smoothing simultaneously. In this paper, we propose a predictive intelligence approach of a multi-task framework to enhance the low-light image. The framework is composed of four coarse recovery sub-networks and three cross refinement sub-networks. Firstly, we use the LIME method to pre-process the low-light image and input the results to the coarse recovery sub-networks as priori knowledges along with the original low-light image. The residual connection and mixed-domain attention module are embedded in each coarse recovery sub-network so that the feature map processed by the attention mechanism is merged with the feature map from the main branch to improve the ability of predicting local bright color patches and effectively control the number of noises. The refinement sub-networks take the output of the coarse sub-networks as input and feed them into U-Net architectures in cross manner. The refinement sub-networks establish a multi-task framework with a cross-task distillation module that can significantly improve the predictive ability of the whole network. Extensive experiments demonstrate that our method achieves 4.1 in MOS, 19.82 in PSNR, 0.8470 in SSIM, 3.0271 in NIQE, and improves by more than 5\% in both subjective metrics and objective metrics compared to state-of-the-art alternatives.},
  archive      = {J_ASOC},
  author       = {Hua Zou and Xiao Lin and Huanhuan Wu and Yeh-Cheng Chen},
  doi          = {10.1016/j.asoc.2022.109168},
  journal      = {Applied Soft Computing},
  pages        = {109168},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A predictive intelligence approach for low-light enhancement},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A binary dandelion algorithm using seeding and chaos
population strategies for feature selection. <em>ASOC</em>,
<em>125</em>, 109166. (<a
href="https://doi.org/10.1016/j.asoc.2022.109166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) is an important pre-processing step in data mining and pattern recognition. It can effectively compress the dimensionality of the feature space to reduce computation time and improve classification performance. The meta-heuristic algorithm-based feature selection method by finding the optimal set of features in the solution space has been widely used. However, this method is prone to trap into local optimality in a sufficiently large solution space. In this paper, we first propose a binary dandelion algorithm (BDA) to improve classification accuracy . In addition, to improve the performance of the algorithm, a binary dandelion algorithm using an improved seeding strategy and chaotic populations (SBDA) is proposed in this paper. Firstly, the strategy of optimizing the seeding radius by using the vibrational function and the historical optimal population increases the complexity of the search process and improves the search performance of the algorithm in the solution space. Secondly, when generating seeds, chaotic populations are generated using chaotic operators, which improves the ability of the algorithm to jump out of the local optimum and improves the stability of the algorithm. In this paper, 15 well-established datasets collected from the UCI machine learning database were adopted to compare four variants of BDA using only chaotic population improvement and in the next experiments, both mechanisms are verified to be effective in improving the performance of the algorithm. In addition, this paper compares the proposed BDA algorithm and SBDA algorithm with eight other classical algorithms. The experimental results show that SBDA can obtain fewer features with higher classification accuracy in most cases.},
  archive      = {J_ASOC},
  author       = {Yuxin Zhao and Junwei Dong and Xiaobo Li and Hui Chen and Shaolang Li},
  doi          = {10.1016/j.asoc.2022.109166},
  journal      = {Applied Soft Computing},
  pages        = {109166},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A binary dandelion algorithm using seeding and chaos population strategies for feature selection},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). WCCI/GECCO 2020 competition on evolutionary computation in
the energy domain: An overview from the winner perspective.
<em>ASOC</em>, <em>125</em>, 109162. (<a
href="https://doi.org/10.1016/j.asoc.2022.109162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary computation is attracting attention in the energy domain as an alternative to tackle inherent mathematical complexity of some problems related to high-dimensionality, non-linearity, non-convexity, multimodality, or discontinuity of the search space. In this context, the research community launched the 2020 ”Competition on Evolutionary Computation in the Energy Domain: Smart Grid Applications” and an associated simulation framework to evaluate the performance of state-of-the-art evolutionary algorithms solving real-world problems. The competition includes two testbeds : (1) Day-ahead energy resource management problem in smart grids under uncertain environments; and (2) Bi-level optimization of end-users’ bidding strategies in local energy markets. This paper describes the general framework of the competition, the two testbeds , and the evolutionary algorithms that participated. A special section is dedicated to the winner approach, CUMDANCauchy++ , a cellular Estimation Distribution Algorithm (EDA). A thorough analysis of the results reveals that, led by CUMDANCauchy++ , the top three algorithms form a block of approaches all based on cellular EDAs. Moreover, for testbed 2, in which CUMDANCauchy++ did not achieve the best performance, the winner approach is also based on EDAs. The outcomes of the competition show that CUMDANCauchy++ is an effective algorithm solving both testbeds, and EDAs emerge as an algorithm class with promising performance for solving smart grid applications.},
  archive      = {J_ASOC},
  author       = {Ansel Y. Rodríguez-González and Fernando Lezama and Yoan Martínez-López and Julio Madera and Joao Soares and Zita Vale},
  doi          = {10.1016/j.asoc.2022.109162},
  journal      = {Applied Soft Computing},
  pages        = {109162},
  shortjournal = {Appl. Soft. Comput.},
  title        = {WCCI/GECCO 2020 competition on evolutionary computation in the energy domain: An overview from the winner perspective},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). A deep selective learning network for cross-domain
recommendation. <em>ASOC</em>, <em>125</em>, 109160. (<a
href="https://doi.org/10.1016/j.asoc.2022.109160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past two decades, recommendation system has been successfully applied to many e-commerce companies and is a ubiquitous part of today online entertainment. However, many single-domain recommendations suffer from the sparsity problems due to a lack of sufficient interactive data. In fact, user behaviors from different domains are usually relevant. Therefore, cross-domain ideas have been proposed to help alleviate the data sparsity issue in traditional single-domain recommender systems . Motivated by this, we design a deep selective learning network (DSLN) in this paper, for the scenario when domains have minimum or no common users DSLN firstly exploits reviews to profile the preference of users and characteristic of items. Then it selects useful user or item information from the auxiliary domain and transfers it to the target domain to solve the negative transfer problem, even though there may be no overlapping users or items between these two domains. In DSLN model, the selection of useful information is realized by the de-noising auto-encoder (DAE), which is shared between the auxiliary and target domains. By minimizing the reconstruction error of the DAE, on the one hand, only the useful information can be selected from the auxiliary domain; on the other hand, the latent representation of users and items in two domains can be learned. Our experiments on three cross-domain scenarios with different sparsity of Amazon review dataset show that, our proposed model gains 0.58\% to 18.16\% relative improvement compared to single-domain recommendation models, and from 1.05\% to 19.4\% relative improvement compared to cross-domain recommendation models.},
  archive      = {J_ASOC},
  author       = {Huiting Liu and Qian Liu and Peipei Li and Peng Zhao and Xindong Wu},
  doi          = {10.1016/j.asoc.2022.109160},
  journal      = {Applied Soft Computing},
  pages        = {109160},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A deep selective learning network for cross-domain recommendation},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interactive portfolio optimization model based on rough
fundamental analysis and rational fuzzy constraints. <em>ASOC</em>,
<em>125</em>, 109158. (<a
href="https://doi.org/10.1016/j.asoc.2022.109158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on mean–variance portfolio optimization (MVPO) has made significant progress in the application of advanced solution algorithms or multiple criteria decision-making methods to achieve superior outcomes. However, there is little specific guidance on how to approach individually preferred optimization bounded by rationality. Therefore, the main goal of this study is to extend MVPO research by incorporating an investor’s preferences and rational expectations during optimizations. Using a set of equities from the Taiwan stock market, this study proposes an interactive MVPO model guided by personal risk-return preferences and bounded by rational fuzzy constraints. Furthermore, this study adopts a rule-based bipolar model to prioritize candidate equities and support the interactive optimization process. This hybrid model is an early attempt to investigate bounded rationality in MVPO, which integrates multiple rule-based decision-making with multiple objective decision-making. The obtained portfolio outperformed two benchmark indexes in 2020, suggesting the feasibility of this approach.},
  archive      = {J_ASOC},
  author       = {Kao-Yi Shen and Huai-Wei Lo and Gwo-Hshiung Tzeng},
  doi          = {10.1016/j.asoc.2022.109158},
  journal      = {Applied Soft Computing},
  pages        = {109158},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Interactive portfolio optimization model based on rough fundamental analysis and rational fuzzy constraints},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploring the mutual influence among the social innovation
factors amid the COVID-19 pandemic. <em>ASOC</em>, <em>125</em>, 109157.
(<a href="https://doi.org/10.1016/j.asoc.2022.109157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From the triple bottom line, the social aspect has received relatively limited attention during the Corona Virus Disease (COVID-19) pandemic, particularly in the emerging economies. Social innovation factors help improve the sustainability performance of the companies. This study develops a social innovation decision framework and analyses the interrelationships among social innovation factors considering the COVID-19 situation. For this purpose, the Decision-Making Trial and Evaluation Laboratory (DEMATEL) is extended by integrating the Z numbers and rough fuzzy set theory into its computational procedure. Z-numbers address the uncertainty of the decision and experts’ confidence in the evaluation and rough numbers are used for aggregating the experts’ opinions. On this basis, the mutual influence of social innovation factors and the influence weights of these factors are investigated. The results suggest that a quick response to market demand for sustainable products is the most influential factor in attaining social sustainability innovation during the pandemic. This article is concluded by providing insights for industrial experts and decision-makers to understand the underpinnings of social sustainability innovation during unforeseen situations.},
  archive      = {J_ASOC},
  author       = {Hadi Badri Ahmadi and Huai-Wei Lo and Pourya Pourhejazy and Himanshu Gupta and James J.H. Liou},
  doi          = {10.1016/j.asoc.2022.109157},
  journal      = {Applied Soft Computing},
  pages        = {109157},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Exploring the mutual influence among the social innovation factors amid the COVID-19 pandemic},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Scheduling unrelated parallel machines with preventive
maintenance and setup time: Multi-sub-colony artificial bee colony.
<em>ASOC</em>, <em>125</em>, 109154. (<a
href="https://doi.org/10.1016/j.asoc.2022.109154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study unrelated parallel machine scheduling problem (UPMSP) with preventive maintenance (PM) and sequence dependent setup times (SDST) is investigated. A multi-sub-colony artificial bee colony (MABC) is proposed to minimize makespan and total tardiness simultaneously, in which initial population is generated by heuristics. s s employed bee sub-colonies are obtained by division and all these sub-colonies except the worst one are learned by s − 1 s−1 onlooker bee sub-colonies, diversified combinations of global search and neighborhood searches are adopted in employed bee phase and onlooker bee phase and two elimination processes are applied. A number of experiments are conducted. Computational results demonstrate that new strategies of MABC are effective and MABC has great advantages in solving UPSMP with PM and SDST.},
  archive      = {J_ASOC},
  author       = {Deming Lei and Hai Yang},
  doi          = {10.1016/j.asoc.2022.109154},
  journal      = {Applied Soft Computing},
  pages        = {109154},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Scheduling unrelated parallel machines with preventive maintenance and setup time: Multi-sub-colony artificial bee colony},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial bee optimization aided joint user association and
resource allocation in HCRAN. <em>ASOC</em>, <em>125</em>, 109152. (<a
href="https://doi.org/10.1016/j.asoc.2022.109152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous cloud radio access network (HCRAN) is a versatile network that leverages the heterogeneous base-station (BS) deployment scheme of Heterogeneous Networks (HetNets) and the centralized baseband signal processing functionalities of cloud RAN (CRAN). Due to dissimilarities between the traditional mobile systems and HCRAN, the currently available power-efficient networking mechanisms of traditional mobile systems cannot fully support HCRAN. Thus, these mechanisms are not feasible for the efficient reduction of energy consumption in HCRAN. In this paper, a multi-carrier orthogonal frequency division multiplexing (OFDMA) based joint user association and resource allocation problem is solved to optimize the HCRAN energy efficiency. The joint user association and resource allocation is a complex problem because the resource allocation to users depends on the RRH - User association. Therefore, a new mechanism is used to generate the initial random solution in the modified Artificial Bee Colony (ABC) algorithm and proposed to address the joint user association and resource allocation problem without decomposing it into two sub-problems. Simulation results show that the ABC algorithm provides a better energy efficiency improvement compared to the existing algorithms.},
  archive      = {J_ASOC},
  author       = {Sivasagar Somesula and Nitin Sharma and Alagan Anpalagan},
  doi          = {10.1016/j.asoc.2022.109152},
  journal      = {Applied Soft Computing},
  pages        = {109152},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Artificial bee optimization aided joint user association and resource allocation in HCRAN},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Embedded draw-down constraint reward function for deep
reinforcement learning. <em>ASOC</em>, <em>125</em>, 109150. (<a
href="https://doi.org/10.1016/j.asoc.2022.109150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Money management, also known as asset allocation, is constantly at the forefront of research in the trading and investing fields. Since Markowitz established the current portfolio theory in 1952, it has drawn many experts to this intriguing topic. The Kelly criteria are one of the brightest stars among these new techniques. It provides an elegant solution for players and investors to get the best bidding fraction and maximize their logarithm worth over time. However, it ignores the fact that each investor has a different risk tolerance, and the proportion was calculated using the Kelly criterion without taking into account the downside risk. This paper attempts to develop a risk prediction model using a probability-based method and adjust the reward function of deep reinforcement learning to account for the downside risk. To summarize, rather than a naive reward function that solely optimizes the return, the improved deep reinforcement learning may consider an investor’s risk tolerance. Finally, we solely analyze the scenario of a single asset and employ DXY, GBP/USD, and EUR/USD as the underlying training and validation data sets. The outcome demonstrates that the adjustment to the reward mechanism produces an interesting performance. When the required MDD (Maximum draw-down) is greater than 3\%, the likelihood is on average greater than 70\%.},
  archive      = {J_ASOC},
  author       = {Jimmy Ming-Tai Wu and Sheng-Hao Lin and Jia-Hao Syu and Mu-En Wu},
  doi          = {10.1016/j.asoc.2022.109150},
  journal      = {Applied Soft Computing},
  pages        = {109150},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Embedded draw-down constraint reward function for deep reinforcement learning},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fuzzy vector reinforcement learning algorithm for generation
control of power systems considering flywheel energy storage.
<em>ASOC</em>, <em>125</em>, 109149. (<a
href="https://doi.org/10.1016/j.asoc.2022.109149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To reduce carbon emissions, the proportion of renewable energy in power systems is increased. However, the volatility and uncertainty of renewable energy cause power deviations. To reduce frequency deviations caused by power deviations, a fuzzy vector reinforcement learning (FVRL) is developed for the generation control of power systems considering flywheel energy storage systems (FESSs). The FVRL algorithm consists of two independent fuzzy controls, two independent Q-learnings (QLs), and vector operation . Area control error and control performance standard 1 index are the inputs of one QL; the input of the other QL is the output power of the FESS. Fuzzy control fuzzifies the inputs of QL and provides the row number of the Q-table. Vector operation is acted for the output values of two QLs; the amplitude of the obtained vector is the final power regulation command of automatic generation control. The FVRL, proportional–integral, five reinforcement learnings, and deep Q-network are compared in two cases. Case studies show that the proposed FVRL obtains the lowest frequency deviation, the lowest area control error, the lowest generation cost, and the highest control performance standard 1 index.},
  archive      = {J_ASOC},
  author       = {Linfei Yin and Yu Li},
  doi          = {10.1016/j.asoc.2022.109149},
  journal      = {Applied Soft Computing},
  pages        = {109149},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fuzzy vector reinforcement learning algorithm for generation control of power systems considering flywheel energy storage},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Explainable anomaly detection framework for predictive
maintenance in manufacturing systems. <em>ASOC</em>, <em>125</em>,
109147. (<a href="https://doi.org/10.1016/j.asoc.2022.109147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To conduct preemptive essential maintenance, predictive maintenance detects the risk of unexpected shutdowns in a manufacturing system , thereby ensuring operational continuity. Traditional methods that heavily rely on the domain knowledge of expert engineers to detect any abnormal status in processing facilities are extremely time-consuming and domain-dependent. Conversely, recently studied data-driven approaches without much domain knowledge have yielded fairly good performance. However, most only identify whether the current status is normal or abnormal and do not offer any explanations or analyses. In this paper, we propose a real-time explainable anomaly detection framework for predictive maintenance in a manufacturing system . Various well-known anomaly detection algorithms are investigated to construct a framework suitable for shutdown prognosis. In addition, model interpretation techniques are also employed to provide a reasonable explanation for a detected shutdown. The experimental results on a real-world dataset derived from a chemical process show that the proposed framework could identify abnormal signs early and derive significant causes for each detected shutdown.},
  archive      = {J_ASOC},
  author       = {Heejeong Choi and Donghwa Kim and Jounghee Kim and Jina Kim and Pilsung Kang},
  doi          = {10.1016/j.asoc.2022.109147},
  journal      = {Applied Soft Computing},
  pages        = {109147},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Explainable anomaly detection framework for predictive maintenance in manufacturing systems},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). A deep hypersphere approach to high-dimensional anomaly
detection. <em>ASOC</em>, <em>125</em>, 109146. (<a
href="https://doi.org/10.1016/j.asoc.2022.109146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The term of Curse of Dimensionality implicitly expresses the challenge for anomaly detection in a high-dimensional space. Because the distribution of anomalies in the high-dimensional spatial data is usually too sparse to provide sufficient information for detecting anomalies . In addition, irrelevant attributes may be seen as noise in the input data, which masks the true anomalies, so that it is difficult to choose a subspace of the input data that highlights the relevant attributes. In this case, the task becomes even harder if one aims at learning a compact boundary to distinguish anomalies from normal data. To address this issue, we proposed a detection method using the combination of an autoencoder and a hypersphere. In addition, an angle kernel and a radius kernel are also derived in order to learn a compact boundary of distinguishing anomalous and normal instances. Results show that our method outperforms the state-of-the-art detection methods in anomalous detection accuracy and the ability of learning a compact boundary. Moreover, our method also addresses the issue of blurred boundary in searching normal data in high dimensional dataset and when the information is insufficient due to a limited number of potential anomalies . We find that the measurement of angle similarity between data points during searching gains more advantages for learning a compact boundary than using the measurement of distance similarity. Since angle similarity is not only helpful for flexibly controlling search in normal data region, but also tightens the searched region of anomalies nearby the boundary. We also find that noise in data as a negative factor can deteriorate detection accuracy much more quickly than dimensionality does. Our findings indicate that the determination of hypersphere radius relies more on data dimensionality in a high-dimensional space than that in a low-dimensional space. However, in a low-dimensional space the radius is more likely correlated with data volume.},
  archive      = {J_ASOC},
  author       = {Jian Zheng and Hongchun Qu and Zhaoni Li and Lin Li and Xiaoming Tang},
  doi          = {10.1016/j.asoc.2022.109146},
  journal      = {Applied Soft Computing},
  pages        = {109146},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A deep hypersphere approach to high-dimensional anomaly detection},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feature space transformation of user-clicks and deep
transfer learning framework for fraudulent publisher detection in online
advertising. <em>ASOC</em>, <em>125</em>, 109142. (<a
href="https://doi.org/10.1016/j.asoc.2022.109142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept drift is a challenge in click fraud detection wherein frequent changes in the actual status label of publishers complicate the identification of publishers’ fraudulent behavior. However, using transfer learning by leveraging the knowledge from previously learned domains to newer domains can make these differences more accessible while saving training time and improving the model’s performance. But the absence of other user-click datasets available publicly poses complexity in using transfer learning . Therefore, to use transfer learning towards predicting the publisher’s conduct concerning change in their labels, this work aims to transform 1D user-click non-image features into a 2D graphical image. The work proposes a deep convolution neural network-based transfer learning (DCNNTr) framework that utilizes different pre-trained Deep Convolutional Neural Network (DCNN) models as powerful feature extractors that leverage prior learnings to avert learning from scratch. The robust features extracted by the feature extractors help identify the conduct of publishers and classify them as fraudulent or non-fraudulent from 2D graphical images using machine learning models. By leveraging the weighted layers in extracting features, DCNN models utilize their special properties of being computationally efficient and locally focused. We evaluated the designed model on the FDMA2012 user-click dataset using precision, recall, F1-score, and AUC. Current work uniquely transforms the time series user-click non-image data into an image form. The experimental results demonstrate that features extracted with DenseNet121 followed by GTB have identified the fraudulent publishers with an average precision score of 79.8\%.},
  archive      = {J_ASOC},
  author       = {Deepti Sisodia and Dilip Singh Sisodia},
  doi          = {10.1016/j.asoc.2022.109142},
  journal      = {Applied Soft Computing},
  pages        = {109142},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Feature space transformation of user-clicks and deep transfer learning framework for fraudulent publisher detection in online advertising},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-local search-based general variable neighborhood
search for distributed flow shop scheduling in heterogeneous
multi-factories. <em>ASOC</em>, <em>125</em>, 109138. (<a
href="https://doi.org/10.1016/j.asoc.2022.109138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous multi-factories in different regions bring a challenge to managers in distributed production scheduling. This paper studies a distributed flow shop scheduling problem in heterogeneous multi-factories (DHFSP) with different processing capabilities of machines and electricity prices in multi-factories. The mixed-integer linear programming model (MILP) of the DHFSP is established, where different time-of-use electricity prices and states of machines (running and idle) are integrated. The proposed MILP model is based on position and time-indexed variables where the position of a job in the sequence is modeled and the time horizon is discretized into time slots. Every job on a machine corresponds to a series of position and time-indexed decision variables A multi-local search-based general variable neighborhood search (MGVNS) is presented to address the DHFSP. The earliest due date rule and a distributed version of NEH (Nawaz–Enscore–Ham) are combined to generate a promising initial solution. Four efficient greedy local search methods that move jobs between heterogeneous multi-factories and within the critical factory are presented. The properties of DHFSP are used to reduce the computing time of objectives. A right-shifting procedure is presented to save the electricity cost by considering the total electricity cost consumed by the processing of the jobs and the idle state of the machine between two adjacent jobs. The experiments and investigation are provided on large-sized instances to demonstrate the effectiveness and efficiency of MGVNS. The effectiveness of initialization, accelerated methods, right-shifting procedure, and local search methods are also significant. From the managerial insights, the proposed model can be extended to many real scenarios, such as semiconductor or automobile production, by integrating specific production constraints. The proposed model and scheduling methods provide an economical way to generate efficient schedules to balance the production efficiency and cost.},
  archive      = {J_ASOC},
  author       = {Weishi Shao and Zhongshi Shao and Dechang Pi},
  doi          = {10.1016/j.asoc.2022.109138},
  journal      = {Applied Soft Computing},
  pages        = {109138},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-local search-based general variable neighborhood search for distributed flow shop scheduling in heterogeneous multi-factories},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic environment prediction on unmanned mobile
manipulator robot via ensemble convolutional randomization networks.
<em>ASOC</em>, <em>125</em>, 109136. (<a
href="https://doi.org/10.1016/j.asoc.2022.109136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to improve the prediction for dynamic environments on unmanned mobile manipulator robot system. When it comes to a simple prediction task, the mobile manipulator robot is undesirable to spend lots of time training a complex neural network . In this paper, the structure of randomization-based neural networks with the convolutional layer named conv-RNet is tested, which reveals that conv-RNet seems to be better than randomization-based neural network with the fully connected layer in terms of accuracy, parameters and computational complexity . Based on the conv-RNet, an ensemble learning architecture named Ensemble convolutional randomization-based neural networks (EC-RNet) is proposed to further optimize the network performance. Here, three problems are mainly solved to optimize this ensemble architecture. The first is how to extract local feature information and decrease the computational complexity . The convolutional layer is used to filter the input to extract features. For producing the fixed number of the hidden layer nodes , the convolutional operation could extract more abundant feature information while maintaining few parameters and low computational complexity than a fully connected operation. The second is how to calculate the number of component learners. Little probability event is used to build a relationship between the number of component learners and the data number in each component dataset. For a given component data, the minimum number of component learners will be determined by this relationship. The third is how to combine the results of component learners to obtain the final result. The confidence level is introduced as the weight to measure the relationship between component results and final results. The combination of component results attaching to different confidence levels is used to calculate the final result. On CIFAR-10, MNIST handwritten digits dataset, and UCI dataset, EC-RNet achieves high accuracy, low computational complexity, and few parameters. Moreover, Experiments on above three datasets show that the proposed EC-RNet+RVFL structure outperforms the proposed EC-RNet+ELM structure. In the real world, the EC-RNet is deployed on the mobile robot and achieves more reliable performance.},
  archive      = {J_ASOC},
  author       = {Yingpeng Dai and Junzheng Wang and Jing Li},
  doi          = {10.1016/j.asoc.2022.109136},
  journal      = {Applied Soft Computing},
  pages        = {109136},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dynamic environment prediction on unmanned mobile manipulator robot via ensemble convolutional randomization networks},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning uncertainty with artificial neural networks for
predictive process monitoring. <em>ASOC</em>, <em>125</em>, 109134. (<a
href="https://doi.org/10.1016/j.asoc.2022.109134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inability of artificial neural networks to assess the uncertainty of their predictions is an impediment to their widespread use. We distinguish two types of learnable uncertainty: model uncertainty due to a lack of training data and noise-induced observational uncertainty. Bayesian neural networks use solid mathematical foundations to learn the model uncertainties of their predictions. The observational uncertainty can be calculated by adding one layer to these networks and augmenting their loss functions. Our contribution is to apply these uncertainty concepts to predictive process monitoring tasks to train uncertainty-based models to predict the remaining time and outcomes. Our experiments show that uncertainty estimates allow more and less accurate predictions to be differentiated and confidence intervals to be constructed in both regression and classification tasks . These conclusions remain true even in early stages of running processes. Moreover, the deployed techniques are fast and produce more accurate predictions. The learned uncertainty could increase users’ confidence in their process prediction systems, promote better cooperation between humans and these systems, and enable earlier implementations with smaller datasets.},
  archive      = {J_ASOC},
  author       = {Hans Weytjens and Jochen De Weerdt},
  doi          = {10.1016/j.asoc.2022.109134},
  journal      = {Applied Soft Computing},
  pages        = {109134},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Learning uncertainty with artificial neural networks for predictive process monitoring},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic forecasting of the shanghai stock exchange index
movement using multiple types of investor sentiment. <em>ASOC</em>,
<em>125</em>, 109132. (<a
href="https://doi.org/10.1016/j.asoc.2022.109132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Direction forecasting of stock market movements using the market investor sentiment is a significant subject in the research area of financial market. In this study, a novel integrated machine learning approach LightGBM-NSGA-II-SW is proposed for stock index prediction and simulation trading by combing the LightGBM (Light Gradient Boosting Machine), NSGA-II (Non dominated Sorting Genetic Algorithm-II), and SW (Sliding Window) methods. For the proposed method, first, three types of investor sentiments, including the individual, institutional, and foreign investor sentiment, are utilized as features to forecast the movement direction of the Shanghai Stock Exchange (SSE) index, and simulation trading is executed based on the direction prediction signal. Then, LightGBM is employed as the classifier for stock index direction prediction, while NSGA-II is essential for hyper-parameter optimization by incorporating multiple objectives that include the hit ratio, accumulated return, and maximum drawdown. In addition, the sliding window method is utilized to prepare the training and testing periods for realizing dynamic prediction and simulation trading of the SSE index. Finally, the proposed method generates an average hit ratio of 60.34\%, an annual accumulated return of 28.43\%, an average maximum drawdown of 8.35\%, and a Sharpe ratio value of 3.24. The performances of the proposed method are substantially superior to the results produced by the benchmarks. Furthermore, the relative importance of the sentiment features of three types investors are comprehensively investigated, and the essential investor sentiment features for forecasting the SSE index direction in different periods are explored. Experimental results demonstrate that the proposed methodology could provide beneficial references for investors to make decisions more rationally, and it could be applied as an effective monitor of the market investor sentiment for market regulation and policymaking in the Chinese security market.},
  archive      = {J_ASOC},
  author       = {Shangkun Deng and Chongyi Xiao and Yingke Zhu and Yu Tian and Zonghua Liu and Tianxiang Yang},
  doi          = {10.1016/j.asoc.2022.109132},
  journal      = {Applied Soft Computing},
  pages        = {109132},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dynamic forecasting of the shanghai stock exchange index movement using multiple types of investor sentiment},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hyperspectral image change detection based on active
convolutional neural network and spatial–spectral affinity graph
learning. <em>ASOC</em>, <em>125</em>, 109130. (<a
href="https://doi.org/10.1016/j.asoc.2022.109130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The high spectral resolution of hyperspectral image (HSI) provides the possibility to capture the subtle changes associated with land-cover dynamic evolution process. Supervised deep leaning approaches have been extensively applied to HSI change detection task. However, their success is attributed to the large amount of annotated training samples. Moreover, the large receptive field in the convolutional layer and the presence of the pooling layer reduces the spatial resolution of the deepest FCN layer which will make the predicted change map tends to lack fine object boundary details. In order to boost the HSI change detection performance in a reduced labor of annotating data and enhance the object boundary details of the change map, in this paper, we propose a novel HSI change detection method that integrates both iterative active learning and affinity graph learning into a unified framework. The proposed method consists of two major branches, a unary HSI change detection network branch which learns the pixel-wise change probability, and a pairwise HSI affinity graph learning branch that learns the pairwise affinity of the hyperspectral difference image to refine the coarse probabilities through a random walk connection. To actively select the most informative unlabeled samples , we also propose an HSI change detection active learning strategy based on the spectral property of HSI difference image and the refined change probabilities. The procedures are conducted iteratively to obtain better change detection results progressively. Experimental results show that the proposed method can extract accurate subtle change information while properly preserving the edges and textures of the HSIs with significantly fewer labeled data.},
  archive      = {J_ASOC},
  author       = {Ruoxi Song and Yining Feng and Chengdi Xing and Zhenhua Mu and Xianghai Wang},
  doi          = {10.1016/j.asoc.2022.109130},
  journal      = {Applied Soft Computing},
  pages        = {109130},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Hyperspectral image change detection based on active convolutional neural network and spatial–spectral affinity graph learning},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Solving multi-objective pickup and delivery with time
windows using mediocre evolutionary distributed microservices
re-optimization algorithm. <em>ASOC</em>, <em>125</em>, 109128. (<a
href="https://doi.org/10.1016/j.asoc.2022.109128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pickup and delivery problem with time windows (PDPTW) is an important problem to be solved. This is due to its resemblance to real-life services such as food delivery, courier service, curbside pickup service, and dial-a-ride, among others. However, the research on multi-objective pickup and delivery problems with time windows (MOPDPTW) remains scarce even after many years. The MOPDPTW objective is to achieve the optimal solution on both the number of vehicle and total travelled distance. It is challenging to obtain optimal results, the recurring optimal results that has least difference in magnitude and broader Pareto sets at the same time. Hence, an algorithm that can fulfil these requirements are highly sought after. This paper presents a mediocre evolutionary distributed microservices re-optimization algorithm (MEDMRA) to solve the MOPDPTW. The combination of the re-optimize algorithm and mediocre evolutionary algorithm escape the local optimal, optimized results and produce broader Pareto value. We compare our results using Li &amp; Lim instances. Our results outperform the latest published hybrid algorithms and competitive with the best-known solutions.},
  archive      = {J_ASOC},
  author       = {Thau-Soon Khoo and Mohammad Babrdel Bonab},
  doi          = {10.1016/j.asoc.2022.109128},
  journal      = {Applied Soft Computing},
  pages        = {109128},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Solving multi-objective pickup and delivery with time windows using mediocre evolutionary distributed microservices re-optimization algorithm},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-supervised learning for fair recommender systems.
<em>ASOC</em>, <em>125</em>, 109126. (<a
href="https://doi.org/10.1016/j.asoc.2022.109126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven recommender algorithms are widely used in many systems, such as e-commerce recommender systems and movie recommendation systems. However, these systems could be affected by data bias, which leads to unfair recommendations for different groups of users. To address this problem, we propose a group rank fair recommender (GRFRec) method to mitigate the unfairness of recommender algorithms. We design a self-supervised learning framework to enhance user representation from both global and local views for fair results. In addition, adversarial learning is introduced to eliminate group-specific information and results in an unbiased user-item representation space, which avoids some groups suffering from unfair treatment in recommender results. Experimental results on three real-world datasets demonstrate that GRFRec can not only significantly improve fairness but also attain better results on the recommendation accuracy.},
  archive      = {J_ASOC},
  author       = {Haifeng Liu and Hongfei Lin and Wenqi Fan and Yuqi Ren and Bo Xu and Xiaokun Zhang and Dongzhen Wen and Nan Zhao and Yuan Lin and Liang Yang},
  doi          = {10.1016/j.asoc.2022.109126},
  journal      = {Applied Soft Computing},
  pages        = {109126},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Self-supervised learning for fair recommender systems},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Anticipatory transport system with hybrid linear and
nonlinear forecasting using streaming wafer process data. <em>ASOC</em>,
<em>125</em>, 109122. (<a
href="https://doi.org/10.1016/j.asoc.2022.109122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In semiconductor plants, autonomous vehicle systems (AVSs) are designed to transfer wafer lots using several hundreds of vehicles. To minimize the idleness of production machines, vehicles must be quickly assigned and sent to the required location in advance. Currently, owing to uncertainties that exit in production processing, simple deterministic heuristic approaches are the ones that are predominantly used when making decisions regarding lot discharging and recharging of production machines. However, to obtain better solutions that reflect the near-future states of production machines and AVSs, more sophisticated approaches are required. To address this, we propose a hybrid predictive algorithm using which a delivery vehicle can be sent in advance to minimize the production machine idle time. To predict the remaining processing time, we combine a latent variable regression and an artificial neural network to model and generalize the linear and the nonlinear patterns of wafer takt times . We then use dynamic time warping to identify the best matching pattern for the wafers being processed, thereby accurately estimating the remaining processing time. The experimental results demonstrated the superior performance of the proposed method in comparison to the existing ones in terms of accuracy. Finally, based on the results of field applications, we found that the proposed method can improve the operational efficiency of AVSs by allowing fast wafer transfer and maximize production throughput by reducing machine idle time.},
  archive      = {J_ASOC},
  author       = {Donggun Yoo and Wooseok Kim and Sangho Park and Bora Oh and Haejoong Kim and Sangmin Lee},
  doi          = {10.1016/j.asoc.2022.109122},
  journal      = {Applied Soft Computing},
  pages        = {109122},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Anticipatory transport system with hybrid linear and nonlinear forecasting using streaming wafer process data},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An adaptive anti-noise gear fault diagnosis method based on
attention residual prototypical network under limited samples.
<em>ASOC</em>, <em>125</em>, 109120. (<a
href="https://doi.org/10.1016/j.asoc.2022.109120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning networks are widely used to realize the intelligent diagnosis of gear faults. However, the problem of the insufficient number of typical fault samples and strong noise often occur in practical applications. Thence, this paper proposes an adaptive anti-noise gear fault diagnosis method based on attention residual prototypical network (ARPN) under the limited sample. In order to maximize the characterization of implicit classification information under fewer samples, frequency slice wavelet transform is applied to convert the vibration signal into a time–frequency image. Then, the Bayesian optimization algorithm is introduced to automatically adjust hyperparameters to meet different application conditions. And the feature embedding stage combined with the improved Non-Local-Pooling-Attention module is constructed to capture the effective feature information better under strong noise conditions. Finally, the internal principle of the proposed model is analyzed based on the visualization process. Meanwhile, the initial application of an interpretable deep learning network in the classification of gear health status has been realized. The ARPN is verified on the Connecticut standard gear data set and the data set collected actually by the laboratory. The results show that the diagnostic accuracy of the ARPN is higher and has stronger recognition ability under different loads.},
  archive      = {J_ASOC},
  author       = {Hongchun Sun and Changdong Wang and Xu Cao},
  doi          = {10.1016/j.asoc.2022.109120},
  journal      = {Applied Soft Computing},
  pages        = {109120},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An adaptive anti-noise gear fault diagnosis method based on attention residual prototypical network under limited samples},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A temporal–spatial network embedding model for ICT supply
chain market trend forecasting. <em>ASOC</em>, <em>125</em>, 109118. (<a
href="https://doi.org/10.1016/j.asoc.2022.109118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Market trend forecasting for the information and communication technology (ICT) supply chain strengthens external regulation. The existing models treat the influence weight and time granularity equally, ignoring the timeliness and accuracy of trading information, which influences the result of prediction. In addition, these methods do not consider the topological and sector hierarchical relationship of enterprises. In this work, a Temporal–Spatial hybrid market trend forecasting model (TSMTF) is proposed. First, in time domain instead of modeling time-varying transaction amount, transaction event probability prediction is modeled by Hawkes​ process. Furthermore, the attention mechanism is used to optimize the accuracy of weight allocation. Second, in spacial domain, the topological dependency relation between the different enterprises with transaction information, share information, and sector information is constructed by network embedding. The experimental results show that the model is superior to other baseline algorithms in ICT data sets. The effectiveness and applicability of this method are verified by ablation experiments and examples of products in the communication industry, and the model provides a practical tool for the external management of ICT supply chain market supervision.},
  archive      = {J_ASOC},
  author       = {Xinshuai Li and Limin Pan and Yanru Zhou and Zhouting Wu and Senlin Luo},
  doi          = {10.1016/j.asoc.2022.109118},
  journal      = {Applied Soft Computing},
  pages        = {109118},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A Temporal–Spatial network embedding model for ICT supply chain market trend forecasting},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DeepEvap: Deep reinforcement learning based ensemble
approach for estimating reference evapotranspiration. <em>ASOC</em>,
<em>125</em>, 109113. (<a
href="https://doi.org/10.1016/j.asoc.2022.109113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precision agriculture aims to increase crop yield by employing an efficient resource management scheme, such as estimating irrigation requirements. Reference evapotranspiration ( E T 0 ET0 ), defined as the process of water loss from the soil and reference plant, is one of the indispensable components on which crop irrigation requirement depends. It is mainly calculated by using empirical models. However, these models require a large climate dataset that is sometimes unavailable in data-scarce regions. The present study focuses on the estimation of E T 0 ET0 values by using three climate parameters as input variables i.e., minimum temperature ( T m i n Tmin ), maximum temperature ( T m a x Tmax ), and solar radiation ( R s Rs ). Moreover, to consider the effect of time-varying characteristics of the E T 0 ET0 process, deep reinforcement learning (DRL) based ensemble approach, DeepEvap, is introduced to estimate E T 0 ET0 values. The whole modeling procedure of the proposed ensemble model incorporates three phases. In phase I, the data preprocessing technique is performed on the meteorological data to clean the existing impurities as it affects the performance of any machine learning (ML) based approach. In phase II, four different deep neural network-based models are used to build the estimation model of E T 0 ET0 and calculate the prediction results. In phase III, the DRL approach is used to ensemble the prediction results of these four models. The meteorological dataset of two stations of India: Ludhiana and Patiala, is selected to validate the proposed approach. The results of the conducted study depict that: (a) The proposed DeepEvap approach is competitive for E T 0 ET0 prediction by achieving a coefficient of determination ( R 2 R2 ) = 0.96. It significantly outperforms four baseline models ; (b) The proposed technique also integrates four deep neural network models and works better than existing ensemble approaches.},
  archive      = {J_ASOC},
  author       = {Gitika Sharma and Ashima Singh and Sushma Jain},
  doi          = {10.1016/j.asoc.2022.109113},
  journal      = {Applied Soft Computing},
  pages        = {109113},
  shortjournal = {Appl. Soft. Comput.},
  title        = {DeepEvap: Deep reinforcement learning based ensemble approach for estimating reference evapotranspiration},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FCF: Feature complement fusion network for detecting
COVID-19 through CT scan images. <em>ASOC</em>, <em>125</em>, 109111.
(<a href="https://doi.org/10.1016/j.asoc.2022.109111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 spreads and contracts people rapidly, to diagnose this disease accurately and timely is essential for quarantine and medical treatment. RT-PCR plays a crucial role in diagnosing the COVID-19, whereas computed tomography (CT) delivers a faster result when combining artificial assistance. Developing a Deep Learning classification model for detecting the COVID-19 through CT images is conducive to assisting doctors in consultation. We proposed a feature complement fusion network (FCF) for detecting COVID-19 through lung CT scan images. This framework can extract both local features and global features by CNN extractor and ViT extractor severally, which successfully complement the deficiency problem of the receptive field of the other. Due to the attention mechanism in our designed feature complement Transformer (FCT), extracted local and global feature embeddings achieve a better representation. We combined a supervised with a weakly supervised strategy to train our model, which can promote CNN to guide the VIT to converge faster. Finally, we got a 99.34\% accuracy on our test set, which surpasses the current state-of-art popular classification model. Moreover, this proposed structure can easily extend to other classification tasks when changing other proper extractors.},
  archive      = {J_ASOC},
  author       = {Shu Liang and Rencan Nie and Jinde Cao and Xue Wang and Gucheng Zhang},
  doi          = {10.1016/j.asoc.2022.109111},
  journal      = {Applied Soft Computing},
  pages        = {109111},
  shortjournal = {Appl. Soft. Comput.},
  title        = {FCF: Feature complement fusion network for detecting COVID-19 through CT scan images},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). A two-stage granular consensus model for minimum adjustment
and minimum cost under pythagorean fuzzy linguistic information.
<em>ASOC</em>, <em>125</em>, 109110. (<a
href="https://doi.org/10.1016/j.asoc.2022.109110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Group decision-making is an everyday evaluation activity in which a panel of decision-makers offers their preferences for obtaining the final results to solve decision problems. In the evaluation process, negotiation is essential for consensus reaching, usually realized by constructing an optimization-based consensus model in terms of a single optimization criterion , such as the amount of adjustment, the number of experts, and the cost of adjustment. Therefore, developing a comprehensive and practical consensus optimization model is crucial to achieving consensus efficiency and exploring a more desirable optimal result. This study concentrates on designing a two-stage consensus optimization model combining minimum adjustment and minimum cost under Pythagorean fuzzy linguistic preference information for realizing the consensus of the group decision-making problems in a complex and uncertain environment. In addition, the granulation of linguistic terms is carried out to reflect the uncertainty of decision-making information and promote consensus reaching within the optimal adaptability ranges of experts’ opinions. The designed model satisfies the need for minimum costs for the mediator and considers experts’ adjustment amount to shorten the time consumption, retain initial preference, and maximize the balance between the minimum amount of adjustment and the minimum cost. Finally, a case of evaluating container ships is presented to demonstrate the designed consensus model’s practicality and effectiveness for risk evaluation by conducting comparative analyses.},
  archive      = {J_ASOC},
  author       = {Lidong Wang and Xueqin Liu and Yanjun Wang},
  doi          = {10.1016/j.asoc.2022.109110},
  journal      = {Applied Soft Computing},
  pages        = {109110},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A two-stage granular consensus model for minimum adjustment and minimum cost under pythagorean fuzzy linguistic information},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel multi-scale based deep convolutional neural network
for detecting COVID-19 from x-rays. <em>ASOC</em>, <em>125</em>, 109109.
(<a href="https://doi.org/10.1016/j.asoc.2022.109109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic has posed an unprecedented threat to the global public health system, primarily infecting the airway epithelial cells in the respiratory tract. Chest X-ray (CXR) is widely available, faster, and less expensive therefore it is preferred to monitor the lungs for COVID-19 diagnosis over other techniques such as molecular test, antigen test, antibody test, and chest computed tomography (CT). As the pandemic continues to reveal the limitations of our current ecosystems, researchers are coming together to share their knowledge and experience in order to develop new systems to tackle it. In this work, an end-to-end IoT infrastructure is designed and built to diagnose patients remotely in the case of a pandemic, limiting COVID-19 dissemination while also improving measurement science. The proposed framework comprises six steps. In the last step, a model is designed to interpret CXR images and intelligently measure the severity of COVID-19 lung infections using a novel deep neural network (DNN). The proposed DNN employs multi-scale sampling filters to extract reliable and noise-invariant features from a variety of image patches. Experiments are conducted on five publicly available databases, including COVIDx, COVID-19 Radiography, COVID-XRay-5K, COVID-19-CXR, and COVIDchestxray, with classification accuracies of 96.01\%, 99.62\%, 99.22\%, 98.83\%, and 100\%, and testing times of 0.541, 0.692, 1.28, 0.461, and 0.202 s, respectively. The obtained results show that the proposed model surpasses fourteen baseline techniques. As a result, the newly developed model could be utilized to evaluate treatment efficacy, particularly in remote locations.},
  archive      = {J_ASOC},
  author       = {Mohan Karnati and Ayan Seal and Geet Sahu and Anis Yazidi and Ondrej Krejcar},
  doi          = {10.1016/j.asoc.2022.109109},
  journal      = {Applied Soft Computing},
  pages        = {109109},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A novel multi-scale based deep convolutional neural network for detecting COVID-19 from X-rays},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An active learning method with entropy weighting subspace
clustering for remote sensing image retrieval. <em>ASOC</em>,
<em>125</em>, 109107. (<a
href="https://doi.org/10.1016/j.asoc.2022.109107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing volume of high-resolution satellite imagery made image retrieval a demanding research field in the remote sensing (RS) community. The RS data are often complex, with varied temporal and spatio-spectral properties, and are unlabeled, and the process of labeling is relatively expensive. Therefore, developing sophisticated models for retrieving relevant images from RS databases is necessary, especially when few labeled samples are available. Motivated by this fact, we propose a new cluster-guided active learning (CG-AL) framework for remote sensing image retrieval (RSIR). The CG-AL-RSIR utilizes an entropy weighting K-Means subspace (EWKMS) clustering algorithm for influencing an active learning (AL) framework using a support vector machine (SVM). The AL framework efficiently selects the most informative samples for labeling depending on a weighted entropy uncertainty sampling (WtEUS). A bag-of-visual-words representation of the scale-invariant feature transform (SIFT) image descriptors is extracted for the retrieval. The EWKMS clustering addresses the high dimensionality of the RSI dataset efficiently in obtaining quality clusters for labeling The CG-AL-RSIR resulted in an overall accuracy of up to 94.14\% and 92.48\% for the UCM and SIRI-WHU datasets, respectively, and an ANMRR value of 0.290 for UCM and 0.326 for SIRI-WHU datasets, utilizing less number of labeled samples.},
  archive      = {J_ASOC},
  author       = {Sudha S.K. and Aji S.},
  doi          = {10.1016/j.asoc.2022.109107},
  journal      = {Applied Soft Computing},
  pages        = {109107},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An active learning method with entropy weighting subspace clustering for remote sensing image retrieval},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Memetic binary differential evolution to solve wind–thermal
profit based unit commitment problem. <em>ASOC</em>, <em>125</em>,
109105. (<a href="https://doi.org/10.1016/j.asoc.2022.109105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the utilization of renewable energy sources (RESs) has gained popularity all over the world due to its numerous benefits. The RESs are a good choice as a cleaner power producer with economic benefits. Power generation from wind energy is rapidly growing all over the world as compared to other RESs. Literature review reveals that a combinatorial, mixed integers (binary and real) optimization problem also known as profit based unit commitment problem (PBUCP) has been solved for only thermal generating units without using RESs. These days, the PBUCP with the integration of RESs has gained intention. In this paper, the PBUCP is solved with the integration of wind generating units in a single objective framework, wherein objective is profit maximization, as well as multi-objective framework, wherein objectives are profit maximization and emissions minimization. A memetic binary differential evolution (MBDE) algorithm is proposed to solve the wind–thermal​ PBUCP. The proposed MBDE algorithm is a blending of binary differential evolution (BDE) and binary search optimizer (BSO). The proposed hybridization improves the global searching capability of the BDE algorithm while maintaining the effective exploitation capability of the BSO. The proposed BSO makes binary perturbations to ameliorate the performance of the BDE algorithm. The achievement of the proposed algorithms has been tested on two hybrid power systems that comprise wind generating units and thermal generating units. In order to know the impacts of wind power generation on thermal power generation, the results of the wind–thermal PBUCP are compared with the results of the thermal PBUCP in the single and multi-objective framework. The best results of the proposed algorithms are collated with the best results of already applied well known algorithms and are found superior.},
  archive      = {J_ASOC},
  author       = {Jatinder Singh Dhaliwal and J.S. Dhillon},
  doi          = {10.1016/j.asoc.2022.109105},
  journal      = {Applied Soft Computing},
  pages        = {109105},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Memetic binary differential evolution to solve wind–thermal profit based unit commitment problem},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards fast approximations for the hypervolume indicator
for multi-objective optimization problems by genetic programming.
<em>ASOC</em>, <em>125</em>, 109103. (<a
href="https://doi.org/10.1016/j.asoc.2022.109103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypervolume (HV) has become one of the most popular indicators to assess the quality of Pareto front approximations . However, the best algorithm for computing these values has a computational complexity of O ( N k / 3 polylog ( N ) ) O(Nk/3polylog(N)) for N N candidate solutions and k k objectives. In this study, we propose a regression-based approach to learn new mathematical expressions to approximate the HV value and improve at the same time their computational efficiency. In particular, Genetic Programming is used as the modeling technique, because it can produce compact and efficient symbolic models. To evaluate this approach, we exhaustively measure the deviation of the new models against the real HV values using the DTLZ and WFG benchmark suites. We also test the new models using them as a guiding mechanism within the indicator-based algorithm SMS-EMOA. The results are very consistent and promising since the new models report very low errors and a high correlation for problems with 3, 4, and 5 objectives. What is more striking is the execution time achieved by these models, which in a direct comparison against standard HV calculation achieved extremely high speedups of close to 100X for a single front and over 1000X for all the HV contributions in a population, speedups reach over 10X in full runs of SMS-EMOA compared with the standard Monte Carlo approximations of the HV, particularly for large population sizes. Finally, the evolved models generalize across multiple complex problems, using only two problems to train the problems from the DTLZ benchmark and performing efficiently and effectively on all remaining DTLZ and WFG benchmark problems.},
  archive      = {J_ASOC},
  author       = {Cristian Sandoval and Oliver Cuate and Luis C. González and Leonardo Trujillo and Oliver Schütze},
  doi          = {10.1016/j.asoc.2022.109103},
  journal      = {Applied Soft Computing},
  pages        = {109103},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Towards fast approximations for the hypervolume indicator for multi-objective optimization problems by genetic programming},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A modified convolutional neural network architecture for
diabetic retinopathy screening using SVDD. <em>ASOC</em>, <em>125</em>,
109102. (<a href="https://doi.org/10.1016/j.asoc.2022.109102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic diabetic retinopathy diagnostic methods are proposed to facilitate the examination process and act as the physician’s helper. Most of the traditional convolution neural network (CNN) algorithms use only spatial features for image category recognition. This approach may not be optimal for the screening diabetic retinopathy because the retinal images have generally the same feature maps with minor differences in spatial domain. We propose a new high level image understanding using a modified CNN architecture mixed with modified support vector domain description (SVDD) as a classifier. This new innovative architecture uses two pathways extracting features of the retinal images in both spatial and spectral domains . The standard pre-trained AlexNet is chosen for modification to avoid the time complexity of the training algorithms . In spite the advantages of the modified AlexNet with two pathways configuration and standard SVDD classification, the different SVDD kernel functions affect the performance of the proposed algorithm. By using the appropriate transformed data into two or three dimensional feature spaces , the proposed SVDD can obtain more flexible and more accurate image descriptions. Also, we compared the performance of our approach with that of the commonly used as classification methods such as K-Means, subtractive and FCM clustering. Our proposed architecture achieves more than 98\% precision and sensitivity for two class classification.},
  archive      = {J_ASOC},
  author       = {Ali Karsaz},
  doi          = {10.1016/j.asoc.2022.109102},
  journal      = {Applied Soft Computing},
  pages        = {109102},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A modified convolutional neural network architecture for diabetic retinopathy screening using SVDD},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A differential evolution based henry gas solubility
optimizer for dynamic performance optimization problems of PRO system.
<em>ASOC</em>, <em>125</em>, 109097. (<a
href="https://doi.org/10.1016/j.asoc.2022.109097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a promising renewable energy resource , pressure retarded osmosis (PRO) is developing rapidly. Under the fluctuating environmental condition, fewer oscillations and higher convergence speeds are necessary for a stable operation of the PRO system and higher energy extraction. Metaheuristic algorithms are potential techniques for PRO at an accelerating rate, but the balance between the exploitation and exploration process is an inherent challenge in real-time efficiency and accuracy. In this work, a differential evolution (DE) based henry gas solubility optimization (EHO) is proposed for the scaled-up PRO module based on experimental data with respect to varying operational situations. In EHO, the DE mechanism and levy flight technique are applied to enhance the reliability and effectiveness of the classic HGSO strategy . The most advanced intelligent algorithms, including DFOA, GWO and WOA, are conducted for competitive research for verification purposes. Moreover, the superiority of the proposed algorithm has been evaluated and validated in complex operational environments under variations in temperature, draw concentrations and flow rates levels. The modelling results indicate that compared with the classic HGSO method, the proposed method leads to an improvement of the extracted specific energy of the PRO system by an astonishing 84.21\%, 111.11\% and 175.03\%, respectively.},
  archive      = {J_ASOC},
  author       = {Yingxue Chen and Linfeng Gou and Huihui Li},
  doi          = {10.1016/j.asoc.2022.109097},
  journal      = {Applied Soft Computing},
  pages        = {109097},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A differential evolution based henry gas solubility optimizer for dynamic performance optimization problems of PRO system},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A simplified non-equidistant grey prediction evolution
algorithm for global optimization. <em>ASOC</em>, <em>125</em>, 109081.
(<a href="https://doi.org/10.1016/j.asoc.2022.109081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grey prediction evolution algorithm, which is receiving more and more attention, considers the population sequence of evolutionary algorithms as an equidistant time series. In fact, the average fitness value of each generation population decreases at a variable speed during almost any evolution process. Therefore, the population sequence with the property of variable speed evolution should be modeled more properly as a non-equidistant time series. Along this way, this paper proposes a novel evolutionary algorithm based on a non-equidistant grey model , called simplified non-equidistant grey prediction evolution algorithm. The proposed algorithm is identified by its reproduction operator which is developed by the following three steps. Firstly, a non-equidistant grey model based on the average fitness value of each generation population is modeled. Secondly, the interval in the fitting stage of the non-equidistant grey model is simplified to an approximately equidistant time interval. Finally, a simplified reproduction operator which employs a parameter to preserve the non-equidistant nature in the prediction stage of the non-equidistant grey model is developed. The comprehensive performance of the proposed algorithm is evaluated on CEC2014 and CEC2019, as well as six engineering constrained design problems. Experimental results show that the proposed algorithm ranks first in CEC2014 and CECE2019 benchmark functions . The proposed algorithm can achieve a better solution with fewer computational overhead than some state-of-the-art algorithms on six engineering constrained design problems. The Matlab code of this paper is available on https://github.com/Zhongbo-Hu/Prediction-Evolutionary-Algorithm-HOMEPAGE .},
  archive      = {J_ASOC},
  author       = {XiYang Xiang and QingHua Su and Gang Huang and ZhongBo Hu},
  doi          = {10.1016/j.asoc.2022.109081},
  journal      = {Applied Soft Computing},
  pages        = {109081},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A simplified non-equidistant grey prediction evolution algorithm for global optimization},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A neural network boosting regression model based on XGBoost.
<em>ASOC</em>, <em>125</em>, 109067. (<a
href="https://doi.org/10.1016/j.asoc.2022.109067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The boosting model is a kind of ensemble learning technology, including XGBoost and GBDT , which take decision trees as weak classifiers and achieve better results in classification and regression problems . The neural network has an excellent performance on image and voice recognition , but its weak interpretability limits on developing a fusion model. By referring to principles and methods of traditional boosting models, we proposed a Neural Network Boosting (NNBoost) regression, which takes shallow neural networks with simple structures as weak classifiers. The NNBoost is a new ensemble learning method, which obtains low regression errors on several data sets. The target loss function of NNBoost is approximated by the Taylor expansion . By inducing the derivative form of NNBoost, we give a gradient descent algorithm. The structure of deep learning is complex, and there are some problems such as gradient disappearing, weak interpretability, and parameters difficult to be adjusted. We use the integration of simple neural networks to alleviate the gradient vanishing problem which is laborious to be solved in deep learning, and conquer the overfitting of a learning algorithm. Finally, through testing on some experiments, the correctness and effectiveness of NNBoost are verified from multiple angles, the effect of multiple shallow neural network fusion is proved, and the development path of boosting idea and deep learning is widened to a certain extent.},
  archive      = {J_ASOC},
  author       = {Jianwei Dong and Yumin Chen and Bingyu Yao and Xiao Zhang and Nianfeng Zeng},
  doi          = {10.1016/j.asoc.2022.109067},
  journal      = {Applied Soft Computing},
  pages        = {109067},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A neural network boosting regression model based on XGBoost},
  volume       = {125},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A robust method for load-carrying capacity assessment of
semirigid steel frames considering fuzzy parameters. <em>ASOC</em>,
<em>124</em>, 109095. (<a
href="https://doi.org/10.1016/j.asoc.2022.109095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The non-probabilistic approach based on fuzzy logic has been applied in analyzing and assessing steel structures. However, there is still a dearth of studies on the behavior of nonlinear inelastic semirigid frame structures in the presence of fuzzy uncertainty. Moreover, accurate fuzzy analysis of structures often involves high computation cost. In this paper, a robust method for the prediction of the load-carrying capacity of semirigid steel frame structures defined with fuzzy parameters is proposed. For the analysis purpose, the nonlinear inelastic analysis taking account of both material and geometrical nonlinearities is adopted to estimate the ultimate load factor (ULF 1 ) of the structure. Columns and beams are modeled by the beam–column element with a refined plastic hinge at two ends, and the beam-to-column connections are defined by zero-length semirigid joints . Innovatively, a fuzzy estimation procedure named the Moving Extrema Method (MEM) is developed to efficiently capture the variation of ULF due to fuzziness in the structural properties and applied loads. Applications to three semirigid steel frames having a relatively large number of fuzzy parameters are conducted. Numerical results show that the proposed MEM can predict the fuzzy ULF with relatively high accuracy and reasonable computation volume. More insights on the effect of the fuzzy structural parameters on the ULF are also presented.},
  archive      = {J_ASOC},
  author       = {Hoang-Anh Pham and Viet-Hung Truong},
  doi          = {10.1016/j.asoc.2022.109095},
  journal      = {Applied Soft Computing},
  pages        = {109095},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A robust method for load-carrying capacity assessment of semirigid steel frames considering fuzzy parameters},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). QDS-COVID: A visual analytics system for interactive
exploration of millions of COVID-19 healthcare records in brazil.
<em>ASOC</em>, <em>124</em>, 109093. (<a
href="https://doi.org/10.1016/j.asoc.2022.109093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 is responsible for the deaths of millions of people around the world. The scientific community has devoted its knowledge to finding ways that reduce the impact and understand the pandemic. In this work, the focus is on analyzing electronic health records for one of the largest public healthcare systems globally, the Brazilian public healthcare system called Sistema Único de Saúde (SUS). SUS collected more than 42 million flu records in a year of the pandemic and made this data publicly available. It is crucial, in this context, to apply analysis techniques that can lead to the optimization of the health care resources in SUS. We propose QDS-COVID, a visual analytics prototype for creating insights over SUS records. The prototype relies on a state-of-the-art datacube structure that supports slicing and dicing exploration of charts and Choropleth maps for all states and municipalities in Brazil . A set of analysis questions drives the development of the prototype and the construction of case studies that demonstrate the potential of the approach. The results include comparisons against other studies and feedback from a medical expert.},
  archive      = {J_ASOC},
  author       = {Juan Carlos Carbajal Ipenza and Noemi Maritza Lapa Romero and Melina Loreto and Nivan Ferreira Júnior and João Luiz Dihl Comba},
  doi          = {10.1016/j.asoc.2022.109093},
  journal      = {Applied Soft Computing},
  pages        = {109093},
  shortjournal = {Appl. Soft. Comput.},
  title        = {QDS-COVID: A visual analytics system for interactive exploration of millions of COVID-19 healthcare records in brazil},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Network self attention for forecasting time series.
<em>ASOC</em>, <em>124</em>, 109092. (<a
href="https://doi.org/10.1016/j.asoc.2022.109092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, attention mechanism has become a hot research topic. Its ability to assign global dependencies from input to output makes it widely used. Meanwhile, although there are some forecasting methods for time series, how to mine more information of time series and make more accurate predictions of it is still an open question. To address this issue, we propose network self attention to mine more information of time series. And we propose a novel forecasting model for time series, in which the similarity scores are learned by a recurrent neural network (RNN) based on network self attention. The similarity scores of nodes in network that is converted from time series by visibility algorithm are learned by RNN at the first step. Afterwards, the final network attention value is calculated. Finally, the prediction of time series is made with the final network attention value. To test the ability of our method to forecast time series, we make predictions of construction cost index (CCI), M1 and M3 datasets. Experiment results indicate that our method can make better predictions for some time series compared to other methods. Meanwhile, robustness test indicates that our method is of good robustness.},
  archive      = {J_ASOC},
  author       = {Yuntong Hu and Fuyuan Xiao},
  doi          = {10.1016/j.asoc.2022.109092},
  journal      = {Applied Soft Computing},
  pages        = {109092},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Network self attention for forecasting time series},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stock price index forecasting using a multiscale modelling
strategy based on frequency components analysis and intelligent
optimization. <em>ASOC</em>, <em>124</em>, 109089. (<a
href="https://doi.org/10.1016/j.asoc.2022.109089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interaction and uncertainty of stock market is exactly critical for traders and investors. Stock price prediction is a hot topic of research due to the returns and risks that coexist in financial markets. But grasping the complex fluctuations of stock price is a highly challenging task that attracts a lot of attention from researchers. To introduce a reliable forecasting model, a multiscale modelling strategy is proposed based on the machine learning method and the econometric model. On the basis of recognizing different frequency components of time series, the optimized support vector machine is used to realize the nonlinear features of stock prices. Owing to the advantages of statistical models for low frequency sub-series, it is more appropriate to capture the linear features. In this study, three stock closing price series of different industrial companies in China were used as the sample data. The multiscale strategy plays a significantly positive role in enhancing forecasting performance through horizontal comparison analysis. The statistical significance of the proposed model was examined through the Diebold Mariano test. In addition, the sensitivity of forecasting results to optimization methods was also discussed in-depth. The comparisons and discussion at multiple levels indicate the accuracy and practicality of the multiscale forecasting model.},
  archive      = {J_ASOC},
  author       = {Ranran Li and Teng Han and Xiao Song},
  doi          = {10.1016/j.asoc.2022.109089},
  journal      = {Applied Soft Computing},
  pages        = {109089},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Stock price index forecasting using a multiscale modelling strategy based on frequency components analysis and intelligent optimization},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). A two-stage genetic programming framework for stochastic
resource constrained multi-project scheduling problem under new project
insertions. <em>ASOC</em>, <em>124</em>, 109087. (<a
href="https://doi.org/10.1016/j.asoc.2022.109087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a novel hyper-heuristic based two-stage genetic programming framework (HH-TGP) to solve the Stochastic Resource Constrained Multi-Project Scheduling Problem under New Project Insertions (SRCMPSP-NPI). It divides the evolution of genetic programming into generation and selection stages, and then establishes a multi-state combination scheduling mode with multiple priority rules (PRs) for the first time to realize resource constrained project scheduling under both stochastic activity duration and new project insertion. In the generation stage, based on a modified attribute set for multi-project scheduling, NSGA-II is hybridized to evolve a non-dominated PR set for forming a selectable PR set. While in the selection stage, the whole decision-making process is divided into multiple states based on the completion activity duration, and a weighted normalized evolution process with two crossovers, two mutations and four local search operators to match the optimal PR for each state from the PR set. Under the existing benchmark, HH-TGP is compared with the existing methods to verify its effectiveness.},
  archive      = {J_ASOC},
  author       = {HaoJie Chen and Jian Zhang and Rong Li and Guofu Ding and Shengfeng Qin},
  doi          = {10.1016/j.asoc.2022.109087},
  journal      = {Applied Soft Computing},
  pages        = {109087},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A two-stage genetic programming framework for stochastic resource constrained multi-project scheduling problem under new project insertions},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An application of real coded self-organizing migrating
genetic algorithm on a two-warehouse inventory problem with type-2
interval valued inventory costs via mean bounds optimization technique.
<em>ASOC</em>, <em>124</em>, 109085. (<a
href="https://doi.org/10.1016/j.asoc.2022.109085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hybrid meta-heuristic algorithms play significant role for solving highly non-linear and non-convex optimization problems in uncertain environment because any hybrid algorithm is more efficient and robust as well as takes less computational cost than the basic algorithms. The objective of this work is to implement hybrid real coded Self-organizing Migrating Genetic Algorithm (RCSOMGA) in inventory control problems with Type-2 interval uncertainty. To achieve this goal, in this work, a two-warehouse inventory problem is modelled for deteriorating commodities under preservation technology with Type-2 interval valued inventory costs . Then the corresponding Type-2 interval valued average profit of the proposed model is obtained using interval mathematics. Thereafter, using Type-2 interval order relations, mean bounds optimization technique is established to maximize the average profit. To illustrate the proposed model, six numerical examples are considered and solved by the hybrid algorithm RCSOMGA. Also, the same numerical examples are solved by some of the state-of-the-art meta-heuristic algorithms and the obtained results are compared with the results obtained by RCSOMGA. Then ANOVA and non-parametric statistical tests are carried out to show the significance of hybrid RCSOMGA. Numerical comparison and statistical analysis of the computational results demonstrate that hybrid RCSOMGA outperforms than other existing algorithms. Finally, sensitivity analyses are carried out to establish the impacts of the inventory parameters on the optimal policy of the proposed model and the work is concluded with some managerial insights.},
  archive      = {J_ASOC},
  author       = {Md Sadikur Rahman and Avijit Duary and Ali Akbar Shaikh and Asoke Kumar Bhunia},
  doi          = {10.1016/j.asoc.2022.109085},
  journal      = {Applied Soft Computing},
  pages        = {109085},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An application of real coded self-organizing migrating genetic algorithm on a two-warehouse inventory problem with type-2 interval valued inventory costs via mean bounds optimization technique},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-granularity relabeled under-sampling algorithm for
imbalanced data. <em>ASOC</em>, <em>124</em>, 109083. (<a
href="https://doi.org/10.1016/j.asoc.2022.109083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The imbalanced classification problem turns out to be one of the important and challenging problems in data mining and machine learning . The performances of traditional classifiers will be severely affected by many data problems, such as class imbalanced problem, class overlap and noise. When the number of one class in the data set is larger than other classes, class imbalanced problem will inevitably occur. Therefore, many researchers are committed to solving the problem of category imbalance and improving the overall classification performances of the classifier. The Tomek-Link algorithm was only used to clean data when it was proposed. In recent years, there have been reports of combining Tomek-Link algorithm with sampling technique. The Tomek-Link sampling algorithm can effectively reduce the class overlap on data, remove the majority instances that are difficult to distinguish, and improve the algorithm classification accuracy . However, the Tomek-Links under-sampling algorithm only considers the boundary instances that are the nearest neighbors to each other globally and ignores the potential local overlapping instances. When the number of minority instances is small, the under-sampling effect is not satisfactory, and the performance improvement of the classification model is not obvious. Therefore, on the basis of Tomek-Link, a multi-granularity relabeled under-sampling algorithm (MGRU) is proposed. This algorithm fully considers the local information of the data set in the local granularity subspace, and detects the local potential overlapping instances in the data set. Then, the overlapped majority instances are eliminated according to the global relabeled index value, which effectively expands the detection range of Tomek-Links. The simulation results show that when we select the optimal global relabeled index value for under-sampling, the classification accuracy and generalization performance of the proposed under-sampling algorithm are significantly better than other baseline algorithms.},
  archive      = {J_ASOC},
  author       = {Qi Dai and Jian-wei Liu and Yang Liu},
  doi          = {10.1016/j.asoc.2022.109083},
  journal      = {Applied Soft Computing},
  pages        = {109083},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-granularity relabeled under-sampling algorithm for imbalanced data},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive search space to generate a per-instance genetic
algorithm for the permutation flow shop problem. <em>ASOC</em>,
<em>124</em>, 109079. (<a
href="https://doi.org/10.1016/j.asoc.2022.109079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces, H H A B S HHABS , a new hyper-heuristic for permutation-based problems. It is a high-level local search that generates tailored genetic algorithms for considered problem instances. The motivation of this work is to reduce the time needed to design a dedicated genetic algorithm for a new instance increasing the chance to explore undiscovered search spaces. It uses three search spaces to build genetic algorithms . In the first one, standard blind operators are used. In the second one, problem-oriented ones are used and finally, in the last one, knowledge extracted during the search process is taken into consideration through diversification and intensification strategies. H H A B S HHABS ’s solving process explores the three search spaces starting from the standard one and jumps to the next search spaces until it gets the best found solution so far, for the given instance, or all search spaces are covered. Extensive experiments have been conducted on the well-known PFSP . The performance comparison, on the Taillard instances, against state-of-the-art algorithms verified the reliability of the proposed organization of the search space on its performance. Besides, it allowed us to classify instances into easy, medium and difficult.},
  archive      = {J_ASOC},
  author       = {Sarra Zohra Ahmed Bacha and Karima Benatchba and Fatima Benbouzid-Si Tayeb},
  doi          = {10.1016/j.asoc.2022.109079},
  journal      = {Applied Soft Computing},
  pages        = {109079},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Adaptive search space to generate a per-instance genetic algorithm for the permutation flow shop problem},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards an effective model for lung disease classification:
Using dense capsule nets for early classification of lung diseases.
<em>ASOC</em>, <em>124</em>, 109077. (<a
href="https://doi.org/10.1016/j.asoc.2022.109077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine Learning and computer vision have been the frontiers of the war against the COVID-19 Pandemic. Radiology has vastly improved the diagnosis of diseases, especially lung diseases, through the early assessment of key disease factors. Chest X-rays have thus become among the commonly used radiological tests to detect and diagnose many lung diseases. However, the discovery of lung disease through X-rays is a significantly challenging task depending on the availability of skilled radiologists . There has been a recent increase in attention to the design of Convolution Neural Networks (CNN) models for lung disease classification. A considerable amount of training dataset is required for CNN to work, but the problem is that it cannot handle translation and rotation correctly as input. The recently proposed Capsule Networks (referred to as CapsNets) are new automated learning architecture that aims to overcome the shortcomings in CNN. CapsNets are vital for rotation and complex translation. They require much less training information, which applies to the processing of data sets from medical images, including radiological images of the chest X-rays. In this research, the adoption and integration of CapsNets into the problem of chest X-ray classification have been explored. The aim is to design a deep model using CapsNet that increases the accuracy of the classification problem involved. We have used convolution blocks that take input images and generate convolution layers used as input to capsule block. There are 12 capsule layers operated, and the output of each capsule is used as an input to the next convolution block. The process is repeated for all blocks. The experimental results show that the proposed architecture yields better results when compared with the existing CNN techniques by achieving a better area under the curve (AUC) average. Furthermore, DNet checks the best performance in the ChestXray-14 data set on traditional CNN, and it is validated that DNet performs better with a higher level of total depth.},
  archive      = {J_ASOC},
  author       = {Faizan Karim and Munam Ali Shah and Hasan Ali Khattak and Zoobia Ameer and Umar Shoaib and Hafiz Tayyab Rauf and Fadi Al-Turjman},
  doi          = {10.1016/j.asoc.2022.109077},
  journal      = {Applied Soft Computing},
  pages        = {109077},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Towards an effective model for lung disease classification: Using dense capsule nets for early classification of lung diseases},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey: Optimization and applications of evidence fusion
algorithm based on dempster–shafer theory. <em>ASOC</em>, <em>124</em>,
109075. (<a href="https://doi.org/10.1016/j.asoc.2022.109075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since Dempster–Shafer evidence theory was proposed, it has been widely and successfully used in many fields including risk analysis , fault diagnosis, wireless sensor networks , health prognosis, image processing , and target tracking, etc. However, many counter-intuitive results of data fusion will be obtained when evidence fused is highly conflicting. So far, this is still an open issue. To address this issue, many methods have been proposed, but they have not been comprehensively summarized in recent years. In this paper, a detailed survey is set forth about the optimization and application of evidence fusion algorithms based on Dempster–Shafer theory. Firstly, the principle of Dempster–Shafer evidence theory is introduced comprehensively. Then, the existing researches on modifying combination rule and pre-processed pieces of evidence to solve the counter-intuitive problem are reviewed in detail. Next, the performance of these studies is demonstrated, deeply analyzed, and discussed through experiments on general examples. And finally, the application of Dempster–Shafer evidence theory in different fields is critically summarized. What is more, analysis of the current status and the development trend of the research on evidence theory are concluded, which can provide a more comprehensive understanding of the development of the Dempster–Shafer evidence theory.},
  archive      = {J_ASOC},
  author       = {Kaiyi Zhao and Li Li and Zeqiu Chen and Ruizhi Sun and Gang Yuan and Jiayao Li},
  doi          = {10.1016/j.asoc.2022.109075},
  journal      = {Applied Soft Computing},
  pages        = {109075},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A survey: Optimization and applications of evidence fusion algorithm based on Dempster–Shafer theory},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). High-utility itemsets mining based on binary particle swarm
optimization with multiple adjustment strategies. <em>ASOC</em>,
<em>124</em>, 109073. (<a
href="https://doi.org/10.1016/j.asoc.2022.109073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an essential data mining task , high-utility itemset mining (HUIM) has attracted a lot of research. With the increase of dataset size, traditional exact HUIM algorithms are faced with exponential growth search space, which is unacceptable for some algorithms. As HUIM can be treated as a combinatorial optimization problem , Evolutionary Computation (EC) based HUIM approaches have been proposed and shown promise performance in mining HUIs. However, the existing EC-based HUIM approaches usually only find part of the HUIs in a limitation time or discovering all the HUIs is usually time-consuming. In this study, an improved binary particle swarm optimization for HUIM (HUIM-IBPSO) is proposed with multiple adjustment strategies to address these problems. In HUIM-IBPSO, a particle movement direction adjustment strategy is presented to keep the same HUIs during the evolution process. In order to utilize the repeated HUIs more efficiently and enhance the search ability, the strategy of local exploration is proposed in HUIM-IBPSO. A restart strategy for the population is developed in HUIM-IBPSO with the purpose to avoid the premature convergence before discovering any HUIs. To mine HUIs more efficiently, particle modify strategy and fitness value hash strategy are introduced in HUIM-IBPSO. A comprehensive comparison with five state-of-the-art EC-based HUIM algorithms and three precise HUIM algorithms on real datasets shows that the designed model outperforms them in terms of the number of HUIs found, the speed at which they converge, and the duration of execution (runtime).},
  archive      = {J_ASOC},
  author       = {Wei Fang and Qiang Zhang and Hengyang Lu and Jerry Chun-Wei Lin},
  doi          = {10.1016/j.asoc.2022.109073},
  journal      = {Applied Soft Computing},
  pages        = {109073},
  shortjournal = {Appl. Soft. Comput.},
  title        = {High-utility itemsets mining based on binary particle swarm optimization with multiple adjustment strategies},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning view-specific labels and label-feature dependence
maximization for multi-view multi-label classification. <em>ASOC</em>,
<em>124</em>, 109071. (<a
href="https://doi.org/10.1016/j.asoc.2022.109071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view multi-label learning tasks often appear in various critical data classification scenarios. Each training sample has multiple heterogeneous data views associated with multiple labels in this learning framework simultaneously. Nevertheless, most existing methods do not consider that a single view cannot fully predict all unknown labels caused by non-aligned views, which leads to insufficient consideration of the relationship between the features and labels of each view, and the learning effect is not ideal. In this paper, we develop a novel method that uses view-specific labels and label-feature dependence maximization. Concretely, we first assume that each view and its corresponding label space have a smooth local structure. In this way, the view-specific label learning model is constructed, enhancing the consistency and complementarity of label space information. Then, multiple multi-label classifiers are constructed by maximizing label-feature dependence. Finally, the linear classification model is extended to the nonlinear, and the prediction stage is combined with the contribution weight of each view. The results of several benchmark datasets show that our proposed method is significantly more effective than the state-of-the-art methods.},
  archive      = {J_ASOC},
  author       = {Dawei Zhao and Qingwei Gao and Yixiang Lu and Dong Sun},
  doi          = {10.1016/j.asoc.2022.109071},
  journal      = {Applied Soft Computing},
  pages        = {109071},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Learning view-specific labels and label-feature dependence maximization for multi-view multi-label classification},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Diversity based imbalance learning approach for software
fault prediction using machine learning models. <em>ASOC</em>,
<em>124</em>, 109069. (<a
href="https://doi.org/10.1016/j.asoc.2022.109069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Software fault prediction (SFP) target is to distinguish between faulty and non-faulty modules. The prediction model’s performance is vulnerable to the class imbalance issue in SFP. The existing oversampling approaches generate relatively identical synthetic data, which results in over-generalization and less diverse data. Moreover, many undesirable noisy modules are introduced while generating synthetic data. In this study, we propose the Weighted Average Centroid based Imbalance Learning Approach (WACIL), an effective synthetic over-sampling technique to mitigate the imbalance issue. The WACIL first finds borderline instances, then generates pseudo-data of them through a weighted average centroid concept and filters out inappropriate noise data through a filtration process . We conducted experiments on 24 PROMISE and NASA projects and compared them with some of the existing sampling approaches using K-Nearest Neighbors (KNN), Logistic Regression (LR), Naive Bayes (NB), Support Vector Machine (SVM), Decision Tree (DT) and Deep Neural Network (DNN) as classification models . WACIL achieves superior results in terms of Fall Out Rate (FOR), F-measure and Area Under Curve (AUC) and obtains comparable results in terms of Recall and G-mean compared to the competitive approaches. The statistical analysis indicates that WACIL’s ability to outperform the other over-sampling techniques is significant under the statistical Wilcoxon signed rank test and matched pairs rank biserial correlation coefficient effect size. Hence, WACIL is advisable as a competent choice to deal with the imbalance issue in SFP.},
  archive      = {J_ASOC},
  author       = {Pravali Manchala and Manjubala Bisi},
  doi          = {10.1016/j.asoc.2022.109069},
  journal      = {Applied Soft Computing},
  pages        = {109069},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Diversity based imbalance learning approach for software fault prediction using machine learning models},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic random distribution learning rate for neural
networks training. <em>ASOC</em>, <em>124</em>, 109058. (<a
href="https://doi.org/10.1016/j.asoc.2022.109058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The learning rate is the most crucial hyper-parameter of a neural network that has a significant impact on its performance. In this article, a novel learning rate setting idea termed randomness distribution learning rate (RDLR) is presented to regulate the learning rate value. The proposed RDLR shifts the learning rate from deterministic to random and sets the value based on the state of the network. The RDLR uses the distance between neurons rather than the covariance matrix to get the redundancy of the network, as well as the Monte Carlo method, and to simplify the neuron to a point to reduce calculation costs. The proposed algorithms do not regulate the learning rate value of each epoch but rather the mathematical expectation and distribution of the learning rate during the training process. The neural network can jump out of the local minimum or unstable area using our algorithms and obtain the minimum point of the area in gradient space. The RDLR algorithms reduce the impact of tiny changes in learning rate value and streamline the tuning process of neural networks. The RDLR saves calculation costs and can work independently or cooperate with the traditional algorithms. In conjunction with traditional learning rate algorithms, the RDLR can set the same learning rate strategy for all layers in a neural network or keep the same mathematical expectation of the learning rate of each layer while adjusting their impulse. The experiments show that the RDLR can improve the performance of a neural network while keeping other hyper-parameters not changed. It is a novel method for adjusting the training process by dynamically changing the random distribution of the learning rate. Our algorithm can monitor the state of the neural network and keep injecting randomness into the neural network training based on the redundancy of the neurons. Furthermore, our algorithm does not require any additional hyper-parameters. The experiments show that our RDLR can improve the performance of multiple structure neural networks in various tasks when applied to a variety of loss functions and data augment methods.},
  archive      = {J_ASOC},
  author       = {Xueheng Hu and Shuhuan Wen and H.K. Lam},
  doi          = {10.1016/j.asoc.2022.109058},
  journal      = {Applied Soft Computing},
  pages        = {109058},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dynamic random distribution learning rate for neural networks training},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intuitionistic fuzzy modelling-based integrated framework
for performance analysis of juice clarification unit. <em>ASOC</em>,
<em>124</em>, 109056. (<a
href="https://doi.org/10.1016/j.asoc.2022.109056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current work seeks to propose an Intuitionistic Fuzzy (IF) modelling based integrated framework for analysing the performance issues of a Juice Clarification Unit (JCU) in a sugar mill industry. IF-Lambda Tau approach based mathematical modelling has been developed using AND/OR gate transitions expression for both membership and non-membership functions. Membership and non-membership function-based reliability parameters have been tabulated at different spreads. Availability of the considered system shows decreasing trend with the increase in spread values. Furthermore, for improving the system’s availability, risk analysis has been carried by implementing IF-Failure Mode &amp; Effect analysis (IF-FMEA) approach. IF Hybrid Weighted Euclidean Distance (IFHWED) based IF-FMEA output scores for all listed failure causes has been tabulated for identifying the most critical failure causes responsible for decrease in system’s availability. IF-Technique for Order of Preference by Similarity to Ideal Solution (IF-TOPSIS) approach was also applied within IF-FMEA approach, and the obtained ranking results are compared for effective decision making of critical failure causes. The proposed IF modelling based integrated framework is highly capable in considering the indeterminacy/hesitation effect involved in the collected raw data/information beside the presence of vagueness/fuzziness, which is missing with the well existed fuzzy set theory based models. The capability of considering the indeterminacy/ hesitation effect in the raw data/information with proposed model results in high accuracy in the performance evaluation of the considered system, and will be further useful for developing an optimum maintenance schedule. Sensitivity analysis has also been carried out to evaluate the robustness of proposed integrated framework.},
  archive      = {J_ASOC},
  author       = {Dinesh Kumar Kushwaha and Dilbagh Panchal and Anish Sachdeva},
  doi          = {10.1016/j.asoc.2022.109056},
  journal      = {Applied Soft Computing},
  pages        = {109056},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Intuitionistic fuzzy modelling-based integrated framework for performance analysis of juice clarification unit},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel behavioral three-way decision model with application
to the treatment of mild symptoms of COVID-19. <em>ASOC</em>,
<em>124</em>, 109055. (<a
href="https://doi.org/10.1016/j.asoc.2022.109055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Coronavirus Disease 2019 (COVID-19) has popularized since late December 2019. In present, it is still highly transmissible and has severe impact on the public health and global economy. Due to the lack of specific drug and the appearance of different variants, the selection of the antiviral therapy to treat the patients with mild symptom is of vital importance. Hence, in this paper, we propose a novel behavioral Three-Way Decision (3WD) model and apply it to the medicine selection decision. First, a new relative utility function is constructed by considering the risk-aversion behavior and regret-aversion behavior of human beings. Second, based on the relative utility function, some new rules are defined to calculate the thresholds and conditional probabilities in 3WD and some corresponding theorems are explored and proved. Next, a new information fusion mechanism in the framework of evidential reasoning algorithm is developed. Then, the decision results are obtained based on the Bayesian decision procedure and the principle of maximum utility. Finally, an example with large-scale data set and an example about medicine selection for COVID-19 are provided to show the implementation process and effectiveness of the proposed method. Comparative analysis and sensitivity analysis are also performed to illustrate the superiority and the robustness of the current proposal.},
  archive      = {J_ASOC},
  author       = {Shi-Fan He and Ying-Ming Wang and Xiaohong Pan and Kwai-Sang Chin},
  doi          = {10.1016/j.asoc.2022.109055},
  journal      = {Applied Soft Computing},
  pages        = {109055},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A novel behavioral three-way decision model with application to the treatment of mild symptoms of COVID-19},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Recognition of cancer mediating biomarkers using rough
approximations enabled intuitionistic fuzzy soft sets based similarity
measure. <em>ASOC</em>, <em>124</em>, 109052. (<a
href="https://doi.org/10.1016/j.asoc.2022.109052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, gene expression analysis has become crucial in studying microarray and provides several techniques related to computational biology and bioinformatics. This article introduces a novel Intuitionistic fuzzy set under rough multigranulation approximation based feature extraction from microarray gene expression dataset. The proposed model identifies cancer mediating human biomarkers using an Intuitionistic fuzzy soft set based similarity measure. Firstly, Intuitionistic fuzzy rough reduct is devised in the microarray datasets preceded by an entropy based pre-processing step. Intuitionistic fuzzy rough reduct produces the feature sets from the microarray datasets through roughness and accuracy measures that are differentially expressed in a cancerous state. Rough multigranulation approximations reduce the dimensions of the microarray datasets. Thereafter, a weighted similarity measure is designed using the intuitionistic fuzzy soft set for the classification of biomarkers having significant expression patterns from the normal state to the carcinogenic state. The proposed method is demonstrated on six microarray datasets and is validated with different performance metrics resulting in better effectiveness than the state-of-the-art methods.},
  archive      = {J_ASOC},
  author       = {Swarup Kr Ghosh and Anupam Ghosh and Siddhartha Bhattacharyya},
  doi          = {10.1016/j.asoc.2022.109052},
  journal      = {Applied Soft Computing},
  pages        = {109052},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Recognition of cancer mediating biomarkers using rough approximations enabled intuitionistic fuzzy soft sets based similarity measure},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-task nonparallel support vector machine for
classification. <em>ASOC</em>, <em>124</em>, 109051. (<a
href="https://doi.org/10.1016/j.asoc.2022.109051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Direct multi-task twin support vector machine (DMTSVM) explores the shared information between multiple correlated tasks, then it produces better generalization performance . However, it contains matrix inversion operation when solving the dual problems, so it costs much running time. Moreover, kernel trick cannot be directly utilized in the nonlinear case. To effectively avoid above problems, a novel multi-task nonparallel support vector machine (MTNPSVM) including linear and nonlinear cases is proposed in this paper. By introducing ε ε -insensitive loss instead of square loss in DMTSVM, MTNPSVM effectively avoids matrix inversion operation and takes full advantage of the kernel trick. Theoretical implication of the model is further discussed. To further improve the computational efficiency, the alternating direction method of multipliers (ADMM) is employed when solving the dual problem. The computational complexity and convergence of the algorithm are provided. In addition, the property and sensitivity of the parameter in model are further explored. The experimental results on fifteen benchmark datasets and twelve image datasets demonstrate the validity of MTNPSVM in comparison with the state-of-the-art algorithms. Finally, it is applied to real Chinese Wine dataset, and also verifies its effectiveness.},
  archive      = {J_ASOC},
  author       = {Zongmin Liu and Yitian Xu},
  doi          = {10.1016/j.asoc.2022.109051},
  journal      = {Applied Soft Computing},
  pages        = {109051},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-task nonparallel support vector machine for classification},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pricing path-dependent exotic options with flow-based
generative networks. <em>ASOC</em>, <em>124</em>, 109049. (<a
href="https://doi.org/10.1016/j.asoc.2022.109049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we aim to significantly reduce the computational time for pricing path-dependent exotic options using a flow-based generative model called RealNVP (Dinh et al., 2016). The flow-based generative network learns simulated large-scale two-dimensional random states based on two stochastic volatility (SV) models. As a result, the generative network can efficiently simulate the random states within a short time. Furthermore, they can provide explicit probability density functions for the SV models due to the unique advantage of flow-based generative models. These lead to fairly exact option prices being achieved by simulating random states with the network or integrating option payoffs for the network-based density. Finally, we compare the network-based prices with those of naive Monte-Carlo simulation in terms of accuracy and time cost to show the superior performance of the proposed method.},
  archive      = {J_ASOC},
  author       = {Hyun-Gyoon Kim and Se-Jin Kwon and Jeong-Hoon Kim and Jeonggyu Huh},
  doi          = {10.1016/j.asoc.2022.109049},
  journal      = {Applied Soft Computing},
  pages        = {109049},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Pricing path-dependent exotic options with flow-based generative networks},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ant colony optimization equipped with an ensemble of
heuristics through multi-criteria decision making: A case study in
ensemble feature selection. <em>ASOC</em>, <em>124</em>, 109046. (<a
href="https://doi.org/10.1016/j.asoc.2022.109046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ant Colony Optimization (ACO) is a probabilistic and approximation metaheuristic algorithm to solve complex combinatorial optimization problems . ACO algorithm is inspired by the behavior of a colony of real ants and uses their pheromone trials to find optimal solutions. Since the beginning of the ACO algorithm, many researchers have tried to improve the performance and stability of the algorithm by using various methodologies. Resolving the exploitation/exploration dilemma by an efficient procedure is critical in improving the ACO. One of the critical parameters in ACO is selecting the heuristic that can affect the movements of ants. So far, the use of several heuristics in ACO has not been studied. We believe that using multiple heuristics instead of a single heuristic can improve the ACO algorithm. For this matter, we have proposed an ACO algorithm based on the ensemble of heuristics using a Multi-Criteria Decision-Making (MCDM) procedure. It means that the movement of the ants is defined based on the judgment of multiple experts (criteria). The idea is based on the hypothesis that different heuristics give us more information about the subsequent nodes, and the variety of these methods examines the different aspects to achieve better and optimal solutions in ACO. In this paper, we have applied our proposed method to the ensemble feature selection task to evaluate the performance of the proposed method. Blending several feature selection methods is regular to tackle the feature selection problem, and also efficiently combining feature selection methods is still challenging. Some well-known ensemble feature selection and primary feature selection methods have been compared with Ant-MCDM on twelve datasets to evaluate the performance of the proposed method in the feature selection task.},
  archive      = {J_ASOC},
  author       = {Amin Hashemi and Mehdi Joodaki and Nazanin Zahra Joodaki and Mohammad Bagher Dowlatshahi},
  doi          = {10.1016/j.asoc.2022.109046},
  journal      = {Applied Soft Computing},
  pages        = {109046},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Ant colony optimization equipped with an ensemble of heuristics through multi-criteria decision making: A case study in ensemble feature selection},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cryptocurrency malware detection in real-world environment:
Based on multi-results stacking learning. <em>ASOC</em>, <em>124</em>,
109044. (<a href="https://doi.org/10.1016/j.asoc.2022.109044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cryptocurrency mining malware (CryptocMal) has been proliferating due to its high profitability and anonymity. There are many studies using machine learning methods to build CryptocMal detectors and other malware detectors. However, these detection methods tend to test their performance on small datasets only, and such testing conditions make researchers often doubt the real-world performance of these machine learning methods. Some deep learning methods that do not require expert knowledge of malware further reinforce this suspicion. In this paper, different from previous studies, the heuristic rule features set for the machine learning model are designed based on CryptocMal characteristics. Furthermore, the heuristic rule features are integrated as a domain knowledge component in an ensemble learning framework, called CMalHunt. CMalHunt utilized the stacking method to combine results of domain knowledge features, behavior features and binary bytes features. Through integrating classification models with different feature types, the experimental results show that CMalHunt significantly outperforms the baseline machine learning models. These results also validate our conjecture about feature types integration, indicating that each feature can play a role in the CryptocMal detection task. This paper is informative for real-world applications of machine learning in malware identification and malware family classification.},
  archive      = {J_ASOC},
  author       = {Rui Zheng and Qiuyun Wang and Zhuopang Lin and Zhengwei Jiang and Jianming Fu and Guojun Peng},
  doi          = {10.1016/j.asoc.2022.109044},
  journal      = {Applied Soft Computing},
  pages        = {109044},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Cryptocurrency malware detection in real-world environment: Based on multi-results stacking learning},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Regularization-free multicriteria optimization of polymer
viscoelasticity model. <em>ASOC</em>, <em>124</em>, 109040. (<a
href="https://doi.org/10.1016/j.asoc.2022.109040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a multiobjective optimization (MOP) method for nonlinear regression analysis which is capable of simultaneously minimizing the model order and estimating parameter values without the need of exogenous regularization constraints. The method is introduced through a case study in polymer rheology modeling. Prevailing approaches in this field tackle conflicting optimization goals as a monobjective problem by aggregating individual regression errors on each dependent variable into a single weighted scalarization function. In addition, their supporting deterministic numerical methods often rely on assumptions which are extrinsic to the problem, such as regularization constants and restrictions on parameter distribution, thereby introducing methodology inherent biases into the model. Our proposed non-deterministic MOP strategy, on the other hand, aims at finding the Pareto-front of all optimal solutions with respect not only to individual regression errors, but also to the number of parameters needed to fit the data, automatically reducing the model order. The evolutionary computation approach does not require arbitrary constraints on objective weights, regularization parameters or other exogenous assumptions to handle the ill-posed inverse problem . The article discusses the method rationales, implementation, simulation experiments, and comparison with other methods, with experimental evidences that it can outperform state-of-art techniques. While the discussion focuses on the study case, the introduced method is general and immediately applicable to other problem domains.},
  archive      = {J_ASOC},
  author       = {Francisco José Monaco and Roman Denysiuk and Alexandre Claudio Botazzo Delbem and António Gaspar-Cunha},
  doi          = {10.1016/j.asoc.2022.109040},
  journal      = {Applied Soft Computing},
  pages        = {109040},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Regularization-free multicriteria optimization of polymer viscoelasticity model},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Segmentation of waterbodies in remote sensing images using
deep stacked ensemble model. <em>ASOC</em>, <em>124</em>, 109038. (<a
href="https://doi.org/10.1016/j.asoc.2022.109038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying surface water resources is considered as one of the principal applications of remote sensing image analysis that plays a crucial role in controlling optimal use of these resources, and preventing floods and crises such as drought. Traditional machine learning methods for extracting waterbodies require complex spectral analysis and selection of features based on previous knowledge. Although applying deep learning-based approaches, which has been considered in recent years, has eliminated the necessity of extracting manual features, they require too many training data and computational resources to achieve high performance. Consequently, each presented deep architecture can detect some of the existing patterns in the predefined conditions. This paper trains and optimizes three robust deep architectures, presented in various fields, using surface water data, and combines their results to achieve a robust model for detecting surface water. To this end, a deep hybrid architecture called ”deep stacked ensemble model” is employed on the outputs of three independent deep sub-models and extracts the final segmentation mask of the water areas more accurately. We evaluated our proposed model on a water body detection dataset provided by artificial intelligence crowd landsat (AIcrowd 1 LNDST) challenge. The proposed technique improves the semantic segmentation performance and surpasses state-of-the-art results.},
  archive      = {J_ASOC},
  author       = {Kaveh Moradkhani and Abdolhossein Fathi},
  doi          = {10.1016/j.asoc.2022.109038},
  journal      = {Applied Soft Computing},
  pages        = {109038},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Segmentation of waterbodies in remote sensing images using deep stacked ensemble model},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ARNN-QA: Adaptive recurrent neural network with feature
optimization for incremental learning-based question answering system.
<em>ASOC</em>, <em>124</em>, 109029. (<a
href="https://doi.org/10.1016/j.asoc.2022.109029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evolution of internet services has raised many information retrieval systems , and the use of intelligent services for the Question Answering (QA) systems has been on ascending. QA system identifies the accurate answers briefly, and the answers are identified through natural language expressions. Developing intelligent techniques for QA has been an abiding issue, and it has been studied for over years. Though, different QA models focus on common-sense and general questions in open fields, which are incompetent in solving the more complex professional questions. Moreover, QA models are the most emerging area in computer science nowadays. It is more significant as it includes more deep learning derived questions. However, the existing models suffer from question retrieval under the incremental learning system. Hence, this paper introduces the QA system based on feature extraction, feature optimization, and learning. Initially, the text input is subjected to feature extraction, in which word to vector is used. Further, optimal feature selection is employed using the Sail Fish-based Whale Optimization Algorithm (SF-WOA). Once the feature optimization is done, the question-answering learning is developed by the Adaptive Recurrent Neural Network (A-RNN). As this is the incremental learning system, the proposed architecture adaptively adjusts the weight for the new incoming question by the proposed SF-WOA, so that it can learn new questions other than the trained data. The performance of the suggested SF-WOA-RNN in terms of remembrance is 8.2\%, 6.9\%, 4.5\%, and 4.5\% progressed than GWO-RNN WOA-RNN, PSO-RNN, and SFO-RNN, respectively while considering test case 1. Finally, the experiments are tested with a set of open-source datasets and prove that the suggested model is effective and holds better answers than the traditional models.},
  archive      = {J_ASOC},
  author       = {M. Therasa and G. Mathivanan},
  doi          = {10.1016/j.asoc.2022.109029},
  journal      = {Applied Soft Computing},
  pages        = {109029},
  shortjournal = {Appl. Soft. Comput.},
  title        = {ARNN-QA: Adaptive recurrent neural network with feature optimization for incremental learning-based question answering system},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feature-filter: Detecting adversarial examples by filtering
out recessive features. <em>ASOC</em>, <em>124</em>, 109027. (<a
href="https://doi.org/10.1016/j.asoc.2022.109027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have achieved state-of-the-art performance in numerous tasks involving complex analysis of raw data, such as self-driving systems and biometric recognition systems. However, recent works have shown that DNNs are under threat from adversarial example attacks. The adversary can easily change the outputs of DNNs by adding small well-designed perturbations to inputs. Adversarial example detection is fundamental for robust DNN-based services. From a human-centric perspective, this paper divides image features into dominant features comprehensible to humans and recessive features incomprehensible to humans yet exploited by DNNs. Based on this perspective, the paper proposes a new viewpoint that imperceptible adversarial examples are the product of recessive features misleading neural networks , and that the adversarial attack enriches these recessive features. The imperceptibility of the adversarial examples indicates that the perturbations enrich recessive features but hardly affect dominant features. Therefore, adversarial examples are sensitive to filtering out recessive features, while benign examples are immune to such operations. Inspired by this idea, we propose a label-only adversarial detector that is referred to as a feature-filter. The feature-filter utilizes the discrete cosine transform (DCT) to approximately separate recessive features from dominant features and obtain a filtered image. A comprehensive user study demonstrates that the DCT-based filter can reliably filter out recessive features from the test image. By comparing only the DNN’s prediction labels on the input and its filtered version, the feature-filter can detect imperceptible adversarial examples in real time with high accuracy and few false-positives.},
  archive      = {J_ASOC},
  author       = {Hui Liu and Bo Zhao and Minzhi Ji and Yuefeng Peng and Jiabao Guo and Peng Liu},
  doi          = {10.1016/j.asoc.2022.109027},
  journal      = {Applied Soft Computing},
  pages        = {109027},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Feature-filter: Detecting adversarial examples by filtering out recessive features},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Weighted fuzzy rough sets-based tri-training and its
application to medical diagnosis. <em>ASOC</em>, <em>124</em>, 109025.
(<a href="https://doi.org/10.1016/j.asoc.2022.109025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The theory of fuzzy rough sets is an effective soft computing paradigm for dealing with vague, uncertain, or imprecise data. However, most existing fuzzy rough sets-based methods may suffer from robustness since all samples are considered equally and also these methods are designed to cater for supervised or unsupervised learning . In this paper, we propose a weighted fuzzy rough sets-based multi-view tri-training model for partially labeled data. Specifically, considering the negative effect of noise, we first use a technique of data editing to filter potentially possible noises, and then a gradient descent algorithm is employed to optimize the weight of each sample with the objective of maximizing high-order weighted fuzzy dependency, based on which a robust weighted fuzzy rough set model is developed for labeled data. Moreover, we introduce the robust weighted fuzzy rough sets into tri-training and propose multi-view-based robust tri-training for partially labeled data by exploring data representations in the original view, the transformed view of principal component analysis, and the granular view after discretization . Extensive experiments conducted on UCI benchmark and medical diagnosis data sets show that the proposed model achieves favorable results in both supervised and semi-supervised scenarios.},
  archive      = {J_ASOC},
  author       = {Jinming Xing and Can Gao and Jie Zhou},
  doi          = {10.1016/j.asoc.2022.109025},
  journal      = {Applied Soft Computing},
  pages        = {109025},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Weighted fuzzy rough sets-based tri-training and its application to medical diagnosis},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Training of the feed forward artificial neural networks
using dragonfly algorithm. <em>ASOC</em>, <em>124</em>, 109023. (<a
href="https://doi.org/10.1016/j.asoc.2022.109023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most important parts of an artificial neural network (ANN) which affects performance is training algorithms . Training algorithms optimize the weights and biases of the ANN according to the inputs–outputs pattern. Two types of training algorithms are widely used: Gradient methods and meta-heuristic methods. Gradient methods are effective in training the ANN. But they have some disadvantages. The main disadvantage of gradient methods is premature convergence. Secondly, the performance of gradient methods highly depends on the initial parameters and positions. Thirdly, they can easily get stuck in local optima. To overcome these disadvantages, this article presents a new hybrid algorithm (DA-MLP) to train the feed-forward multilayer neural networks (MLP) using the dragonfly algorithm. The dragonfly algorithm optimizes the weights and biases of the MLP. In the experiments, one real-world problem in the civil engineering area and eight classification datasets were used. To verify the success of the DA-MLP algorithm, the results of the DA-MLP algorithm were compared with the results of four algorithms (the BAT-MLP based on the bat optimization algorithm , the SMS-MLP based on the states of matter search optimization algorithm , the PSO-MLP based on the particle swarm optimization algorithm, and the backpropagation (BP) algorithm). The experimental study showed that the DA-MLP algorithm is more efficient than the other algorithms.},
  archive      = {J_ASOC},
  author       = {Şaban Gülcü},
  doi          = {10.1016/j.asoc.2022.109023},
  journal      = {Applied Soft Computing},
  pages        = {109023},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Training of the feed forward artificial neural networks using dragonfly algorithm},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiobjective multi verse optimization algorithm to solve
dynamic economic emission dispatch problem with transmission loss
prediction by an artificial neural network. <em>ASOC</em>, <em>124</em>,
109021. (<a href="https://doi.org/10.1016/j.asoc.2022.109021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To overcome the drawback of using only one B-loss coefficient for a widely varying demand pattern that occurs during the entire period of a dynamic economic emission dispatch model, this research work presents a new approach to integrating artificial neural network-based loss prediction into the dynamic economic emission dispatch model. The trained neural network will predict the transmission loss only once during each interval of the dispatch period. The novelty of the work lies in employing a trained neural network to replace the existing procedure of solving complex power flow equations or B-loss coefficients during every iteration. A potent multiobjective multiverse optimization algorithm along with an effective constraint handling mechanism is employed to solve the highly complicated dynamic economic emission dispatch model. A fuzzy membership-based approach is adopted to help the decision-maker select one optimal solution from the Pareto Optimal solutions during each hour of the dispatch period. The proposed algorithm is tested on four systems of varying complexity including a large-scale IEEE 118 bus power system with fifty-four thermal generators. The results obtained are compared with 16 state-of-the-art algorithms to prove the competitive behavior of the algorithm. For an IEEE 30 bus system, the proposed algorithm results in a saving of 92.92$ in fuel cost and a reduction of emission levels by 0.0375 tons per day. The total time taken by the algorithm is faster than the well-known non dominated sorted genetic algorithm II and multiobjective particle swarm optimization algorithm by 30 times and 7.6 times respectively.},
  archive      = {J_ASOC},
  author       = {Arunachalam Sundaram},
  doi          = {10.1016/j.asoc.2022.109021},
  journal      = {Applied Soft Computing},
  pages        = {109021},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multiobjective multi verse optimization algorithm to solve dynamic economic emission dispatch problem with transmission loss prediction by an artificial neural network},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Knowledge transfer for labeling unknown fuzzy sets using
grammar-guided genetic algorithms. <em>ASOC</em>, <em>124</em>, 109019.
(<a href="https://doi.org/10.1016/j.asoc.2022.109019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy Logic Systems have been popular in fields such as control, knowledge representation, and modeling. They involve linguistic information to represent a human perception in the form of Fuzzy Sets. Those systems are advantageous in cases where it is desired to have some interpretability . However, there are some processes, such as optimization, where the membership function related to a fuzzy set is modified. Therefore the linguistic label associated with them is unattached to the original meaning. This proposal aims to make linguistically-interpretable fuzzy sets from previously established ones but with modified parameters, thus maintaining the context of the knowledge of the domain application and the knowledge designer. The presented approach relies in the use of linguistic modifiers, which are operations linked to linguistic terms that apply on fuzzy sets, such as very , above , more-or-less , etc. A methodology using Grammar-Guided Genetic Algorithms is proposed to find the best linguistic modifier candidates to approximate the fuzzy set with modified parameters to guarantee a coherent and readable grammar structure at diverse levels of interpretability and accuracy. The obtained results support the feasibility of the proposed methodology with convex membership functions such as Gaussian, Triangular, and Trapezoidal.},
  archive      = {J_ASOC},
  author       = {Raul Navarro-Almanza and Mauricio A. Sanchez and Guillermo Licea and Juan R. Castro},
  doi          = {10.1016/j.asoc.2022.109019},
  journal      = {Applied Soft Computing},
  pages        = {109019},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Knowledge transfer for labeling unknown fuzzy sets using grammar-guided genetic algorithms},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). A parallel algorithm based on quantum annealing and
double-elite spiral search for mixed-integer optimal control problems in
engineering. <em>ASOC</em>, <em>124</em>, 109018. (<a
href="https://doi.org/10.1016/j.asoc.2022.109018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many engineering processes can be summarized as mixed-integer optimal control problems (MIOCPs) owing to the needs for optimizing mixed-integer dynamic control policies. However, MIOCP is a challenging NP-hard problem with great computational complexity , resulting in slow convergence or premature convergence by most current heuristics. Accordingly, this study explores a new and effective hybrid Quantum Annealing-Double-Elite Spiral Search (QA-DESS) algorithm to address this issue. To be specific, QA algorithm specializes in solving integer optimization with high efficiency due to the unique quantum-tunnelling-based annealing mechanism. For the optimization of continuous decisions, a DESS algorithm which adopts adaptive Cauchy mutation and double-elite evolutionary mechanism to enhance global searching is designed. The hybrid QA-DESS algorithm integrates the strengths of such algorithms to better balance the exploration and exploitation abilities. The overall evolution performs to find the optimal mixed-integer decisions by interactive parallel computing of QA and DESS. Simulation results on benchmark functions and practical engineering MIOCPs verify that the proposed optimization algorithm is more excel at finding promising results than other 7 heuristics (including traditional and state-of-the-art algorithms).},
  archive      = {J_ASOC},
  author       = {Zhe Liu and Shurong Li and Yulei Ge},
  doi          = {10.1016/j.asoc.2022.109018},
  journal      = {Applied Soft Computing},
  pages        = {109018},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A parallel algorithm based on quantum annealing and double-elite spiral search for mixed-integer optimal control problems in engineering},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intelligent fuzzy controller design: Disturbance rejection
cases. <em>ASOC</em>, <em>124</em>, 109015. (<a
href="https://doi.org/10.1016/j.asoc.2022.109015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a modified fuzzy gain scheduling (GS) Proportional–Integral–Derivative (PID) controller where the output of the integral term of PID, u i ui , heuristically used as the scheduling variable is discussed. Then, it is demonstrated that u i ui can effectively represent the inaccessible low-frequency disturbances that alter the system operating point. In addition, since GS design involves time-consuming multiple runs of nonlinear optimization tasks, a fast hybrid method using PSO-GA and classical fminsearch is worked out. Interpolation of the designs, for GS build up, is carried out using an adaptive neuro-fuzzy inference system (ANFIS) to provide PID continuous gain surfaces. The algorithm is applied to the speed control of a combined cycle power plant under unmeasured bounded load disturbances. The simulation outputs indicate that the design quality is effectively preserved in case of small perturbations where the achievements are also superior to the responses of some published methods. In the case of large perturbations, the fuzzy scheduling PID (FSPID) supersedes successfully two other optimally designed regulators. Therefore, it is concluded that the proposed approach renders a better transient response in facing both small and large stepwise load disturbances. The findings have been verified under various working loads through extensive simulations.},
  archive      = {J_ASOC},
  author       = {M. Moradi and S. Seyedtabaii},
  doi          = {10.1016/j.asoc.2022.109015},
  journal      = {Applied Soft Computing},
  pages        = {109015},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Intelligent fuzzy controller design: Disturbance rejection cases},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Transfer learning of fuzzy classifiers for optimized joint
representation of simulated and measured data in anomaly detection of
motor phase currents. <em>ASOC</em>, <em>124</em>, 109013. (<a
href="https://doi.org/10.1016/j.asoc.2022.109013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The generation of simulation data from physical models trying to mimic parts of the real-world process as accurately as possible has received much attention in industry during the last years. A proper augmentation of simulation data with (available or recordable) real-measured data is an intrinsic challenge to increase the performance of machine learning models. In this paper, we propose a joint representation learning approach based on an optimized transfer of fuzzy classifiers from original simulated data (as source task) to real-measured data (as target task). This is particularly done for binary classification tasks under the scope of anomaly detection of phase currents in electrical machines, where only anomaly-free real-measured data can be collected in advance (so, only in the simulated data anomaly samples are present). Our approach combines distribution matching between simulated and real-measured data on the basis of fuzzy rule activation levels with a weighted error term representing the classification loss between anomaly-free and anomaly data. Both are realized on a local basis per rule, which yields good flexibility during optimization with respect to the actual local distributions and their positions in the target task and is particularly possible for fuzzy classifiers due to the local geometric interpretation of the rules. We demonstrate how to find a feasible initial solution for the numerical optimization process. Results on data sets from the application showed significantly improved classification accuracies of up to 25\% compared to several conventional fuzzy classifiers training variants and also compared to various renowned machine learning classifiers, while a respectful (slightly worse) performance compared to the two top performers (SVMs and deep MLPs) were achieved. However, a large performance gap between conventional fuzzy classifiers and these ML-based top performers could nearly be closed and due to the local geometric interpretation of the internal fuzzy partitions, explainable insights into the model transfer could be yielded to experts.},
  archive      = {J_ASOC},
  author       = {Edwin Lughofer and Patrick Zorn and Edmund Marth},
  doi          = {10.1016/j.asoc.2022.109013},
  journal      = {Applied Soft Computing},
  pages        = {109013},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Transfer learning of fuzzy classifiers for optimized joint representation of simulated and measured data in anomaly detection of motor phase currents},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A modified grey wolf optimization with cuckoo search
algorithm for load frequency controller design of hybrid power system.
<em>ASOC</em>, <em>124</em>, 109011. (<a
href="https://doi.org/10.1016/j.asoc.2022.109011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel strategy by consolidating the Modified Grey wolf optimization algorithm and the Cuckoo search algorithm , termed as MGWO-CS algorithm. The superiority of the proposed modified hybrid algorithm over the original algorithm in terms of implementation time and solution quality is compared by taking several benchmark test functions. Further, the genuine utilization of the proposed algorithm is tried by designing a TID controller for frequency regulation of a two-area power system with the application of a photovoltaic system . The matchless quality of the MGWO-CS based TID controller is presented by contrasting with some current methods. Finally, the robustness of the hybrid algorithm-based controller is tested in a multi-area multi-source hybrid power system with the PV-Thermal environment and it is observed that the proposed hybrid algorithm based TID controller is more effective for the load frequency control of the hybrid system compared to the conventional controller .},
  archive      = {J_ASOC},
  author       = {Rajendra Kumar Khadanga and Amit Kumar and Sidhartha Panda},
  doi          = {10.1016/j.asoc.2022.109011},
  journal      = {Applied Soft Computing},
  pages        = {109011},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A modified grey wolf optimization with cuckoo search algorithm for load frequency controller design of hybrid power system},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ensemble wind speed prediction system based on envelope
decomposition method and fuzzy inference evaluation of predictability.
<em>ASOC</em>, <em>124</em>, 109010. (<a
href="https://doi.org/10.1016/j.asoc.2022.109010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an indispensable part of the current global power system , wind energy has always been the focus of research over the world. In the production process of wind power, wind speed is a crucial factor and the requirements for wind speed prediction accuracy are increasing in practical applications. Therefore, as the main contribution of this paper, a novel decomposition-recognition-integration-prediction system (DRIPS) is proposed based on a newly developed predictive difficulty index (PDI) that synthesizes complexity, chaos, and long-term dependence of time series data . PDI comprehensively quantifies the basic characteristics and prediction difficulty of the series, filling the gap in the existing intuitionistic evaluation method. To verify the predictive ability and effectiveness of DRIPS, we select two American on-shore wind sites (Nolan and Kern) as the site of the experiments. At each site, the 10-minute-interval wind speed for three months in 2018 is collected as experimental samples. The simulation results show that DRIPS can provide excellent performance in the accuracy of wind speed prediction. In terms of deterministic prediction and uncertainty prediction, DRIPS performs less than 2\% on the mean absolute percentage error for point prediction and less than 0.5 on the predictive interval score for interval prediction. Such performance is significantly better than that of the common prediction models such as BP, SVM , etc. Moreover, By comparing the experimental results of different integration strategies, the integration strategy based on PDI can improve the prediction accuracy significantly.},
  archive      = {J_ASOC},
  author       = {Yuyang Gao and Jianzhou Wang and Xiaobo Zhang and Ranran Li},
  doi          = {10.1016/j.asoc.2022.109010},
  journal      = {Applied Soft Computing},
  pages        = {109010},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Ensemble wind speed prediction system based on envelope decomposition method and fuzzy inference evaluation of predictability},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Limit surface/states searching algorithm with a deep neural
network and monte carlo dropout for nuclear power plant safety
assessment. <em>ASOC</em>, <em>124</em>, 109007. (<a
href="https://doi.org/10.1016/j.asoc.2022.109007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For decades, efforts have been made to enhance the realism of risk assessment methods for nuclear power plants (NPPs) by augmenting the number of representative scenarios. The common issue though is that each scenario should be simulated individually by computationally demanding physical models such as thermal-hydraulic system codes. To address this problem, this research proposes an algorithm that identifies the success or failure of each scenario with a minimized number of simulations. The algorithm seeks to locate the limit surface/states that distinguishes success and failure regions and impels the physical models to simulate only the scenarios where the consequence is close to the given failure criterion. To this end, the algorithm is an iterative process that estimates the LS by a metamodel, samples the scenarios close to the estimated LS, simulates the sampled scenarios, and trains the metamodel with accumulated simulation results. A deep neural network (DNN) is employed as the metamodel for predicting the consequence of each scenario, and Monte Carlo dropout informs the predictive uncertainty. Referring to this uncertainty, the DNN metamodel meticulously ‘sails’ across the scenario space to accurately pinpoint the LS. We name the proposed algorithm the deep neural network-based searching algorithm of informative limit surfaces and states, or Deep-SAILS. Combining the simulation results of risk-sensitive scenarios (close to the LS) and the ability of the trained DNN metamodel to reasonably predict the non-simulated scenarios, Deep-SAILS identified the success or the failure of tens of thousands of dynamic scenarios of loss of coolant accidents at more than 99\% accuracy with only thousands of simulations.},
  archive      = {J_ASOC},
  author       = {Junyong Bae and Jong Woo Park and Seung Jun Lee},
  doi          = {10.1016/j.asoc.2022.109007},
  journal      = {Applied Soft Computing},
  pages        = {109007},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Limit surface/states searching algorithm with a deep neural network and monte carlo dropout for nuclear power plant safety assessment},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-population biogeography-based optimization algorithm
and its application to image segmentation. <em>ASOC</em>, <em>124</em>,
109005. (<a href="https://doi.org/10.1016/j.asoc.2022.109005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In view of the shortcomings of Worst opposition learning and Random-scaled differential mutation Biogeography-Based Optimization (WRBBO) in solving complex optimization problems , such as insufficient search ability and low search efficiency, an improved WRBBO, Multi-population BBO (MPBBO) is proposed. Firstly, a multi-population strategy is adopted: the whole sorted population is divided into 3 different subgroups (high-level, median-level and low-level) through golden section to get some population diversity. Secondly, an aptitude-based teaching approach is proposed to be beneficial to each subgroup’s development: a sinusoidal-scaled differential mutation operator is performed on the high-level subgroup to mostly get stronger exploration and reduce the computing cost, a heuristic crossover with dynamic fine adjustment is hybridized with a horizontal crossover and a vertical one to form a multi-crossover on the median-level subgroup to mainly get stronger exploitation, and a best agent guiding strategy is used on the low-level subgroup to improve the search ability. Finally, an information sharing way is adopted: all the individuals in 3 subgroups share information by merging and sorting them. The experimental results on the complex functions from CEC-2013 and CEC-2017 test sets show that MPBBO obtains stronger search ability and higher efficiency than WRBBO and quite a few other state-of-the-art algorithms. MPBBO is applied to image segmentation with fast and robust fuzzy c-means (FRFCM), and the results show that FRFCM-MPBBO has more significant advantages than its comparison methods.},
  archive      = {J_ASOC},
  author       = {Xinming Zhang and Shaochen Wen and Doudou Wang},
  doi          = {10.1016/j.asoc.2022.109005},
  journal      = {Applied Soft Computing},
  pages        = {109005},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-population biogeography-based optimization algorithm and its application to image segmentation},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A spatio-temporal graph-guided convolutional LSTM for
tropical cyclones precipitation nowcasting. <em>ASOC</em>, <em>124</em>,
109003. (<a href="https://doi.org/10.1016/j.asoc.2022.109003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time and accurate Tropical Cyclone (TC) precipitation nowcasting plays an important role in disaster prevention and mitigation. The strong ability of deep learning has been proved in many precipitation nowcasting studies. However, few deep learning solutions focus on the precipitation caused by TC, which has complex patterns and is potential for disasters. In this paper, we develop a novel framework for TC precipitation nowcasting. To effectively utilize the TC information, we design a multi-source information fusion mechanism between precipitation and TC. More importantly, we propose a Graph-guided Spatio-Temporal Module (GSTM), which designs a construction scheme of dynamic reasoning graphs to capture the spatio-temporal relationship between intra-frame and inter-frame. It is also the first attempt to introduce the graph concept into precipitation nowcasting. We utilize the TC and precipitation data from 2017 to 2019 in the Northwest Pacific Ocean and divide the data into training (3524 sequences), validation (352 sequences), and test set (705 sequences) at a ratio of 10:1:2. Extensive experiments demonstrate that compared with the Convolution LSTM model, our model obtains a significant improvement by 2.74\%, 4.24\%, 6.29\%, 5.78\% in F1-score when the precipitation intensity is 5, 10, 20, 30 mm/h, respectively. Meanwhile, we select three typical TC precipitation cases for visual analysis, which proves that our model has excellent perception ability in the details of TC spatial distribution and can deal with different TC scenarios effectively. The effectiveness of our model indicates that the method based on deep learning has strong applicability and development prospects in the TC precipitation nowcasting, providing infinite possibilities and potential for this field.},
  archive      = {J_ASOC},
  author       = {Xuying Yang and Feng Zhang and Peng Sun and Xiaofan Li and Zhenhong Du and Renyi Liu},
  doi          = {10.1016/j.asoc.2022.109003},
  journal      = {Applied Soft Computing},
  pages        = {109003},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A spatio-temporal graph-guided convolutional LSTM for tropical cyclones precipitation nowcasting},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Implementation of intelligent navigational techniques for
inter-collision avoidance of multiple humanoid robots in complex
environment. <em>ASOC</em>, <em>124</em>, 109001. (<a
href="https://doi.org/10.1016/j.asoc.2022.109001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past few decades, research in humanoid robots has been amplified rapidly. This paper displays the attainment of an optimum steering angle to avoid hurdles and reach the target with minimum effort. To achieve this objective, three steps optimization procedure is considered. A hybridization of regression analysis (RA), cell decomposition (CD), and whale optimization algorithm (WOA) are designed and implemented in humanoid NAO for prime trajectory with the least computational cost. RA supplies the first set of steering angles to CD based on the training in the given workspace. CD provides a second set of steering angles to WOA, which results in an optimum steering angle based on its characteristics of hunting prey. The proposed RA-CD-WOA algorithm is evaluated in simulated and experimental workspaces for a single NAO. The proposed algorithm and its standalone algorithms are compared for several iterations, demonstrating the requirement for hybridization. It is also examined for multiple NAOs on a common platform that may lead to a deadlock condition during navigation. To elude this condition, the dining philosopher controller is integrated with the base algorithm , which results in prioritizing a NAO and solving the problem. Further, the RA-CD-WOA algorithm is compared with an existing technique that displays its robustness and effectiveness for robot navigation .},
  archive      = {J_ASOC},
  author       = {Abhishek Kumar Kashyap and Dayal R. Parhi},
  doi          = {10.1016/j.asoc.2022.109001},
  journal      = {Applied Soft Computing},
  pages        = {109001},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Implementation of intelligent navigational techniques for inter-collision avoidance of multiple humanoid robots in complex environment},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AP-TLB-IGWO: Adult-pup teaching–learning based interactive
grey wolf optimizer for numerical optimization. <em>ASOC</em>,
<em>124</em>, 109000. (<a
href="https://doi.org/10.1016/j.asoc.2022.109000">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bio-inspired optimization technique acts as the fundamental backbone of any AI assisted expert system and Grey wolf optimizer (GWO) is a noteworthy example of one such technique. GWO is new in nature but gaining its popularity due to its better exploration and avoidance of stagnation at local minima. However it needs a more intelligent and balanced exploration and exploitation management procedure. Also for the problems with nonzero solution in the search space GWO needs extra attention as it has a tendency of convergence at the origin of the coordinate system. In order to mitigate these challenges and for the better representation of the existing system, an adult-pup teaching–learning based interactive grey wolf optimization (AP-TLB-IGWO) algorithm is proposed in this paper. With a new structural framework, the proposed algorithm focuses on better generalization, search procedure and diversification. Here both the adult wolves and the pups act as the search agents. They both concurrently and independently explore the entire search space for optimal results. Energy driven hunting procedure is introduced in the update equation of GWO. Information sharing takes place between adult and pup wolves and prospective agents are identified. The performance of the proposed technique is tested on 23 well known classical benchmark functions , CEC2014 problem set, CEC2017 problem set and five real world optimization problems and compared with several established optimization techniques. The experimental results and related analysis proved that the proposed AP-TLB-IGWO is providing significantly promising results in comparison with existing techniques.},
  archive      = {J_ASOC},
  author       = {Nabanita Banerjee and Sumitra Mukhopadhyay},
  doi          = {10.1016/j.asoc.2022.109000},
  journal      = {Applied Soft Computing},
  pages        = {109000},
  shortjournal = {Appl. Soft. Comput.},
  title        = {AP-TLB-IGWO: Adult-pup teaching–learning based interactive grey wolf optimizer for numerical optimization},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Application of dimensional analysis and multi-gene genetic
programming to predict the performance of tunnel boring machines.
<em>ASOC</em>, <em>124</em>, 108997. (<a
href="https://doi.org/10.1016/j.asoc.2022.108997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An accurate prediction of tunnel boring machine (TBM) performance is one of the complex and crucial issues encountered frequently in tunnel construction, which is the aim of the present study. An improved methodology using dimensional analysis (DA) and multi-gene genetic programming (MGGP) is proposed to obtain a practical and accurate model which can predict TBM performance. Three dimensionless parameters are introduced by applying DA to predict TBM performance more efficiently. These parameters can represent TBM and rock features. The MGGP, as a powerful technique for developing a practical correlation model, was adopted to develop highly accurate models using GPTIPS (Genetic Programming Toolbox for the Identification of Physical Systems). A well-known database of a hard rock mechanized tunneling project of the Queens water conveyance tunnel was used to evaluate the performance of the proposed methodology. The performances of the developed models were examined and compared with other reported models using three statistical criteria. Regarding the sum of squared deviations (SSD), the developed model yielded 21.7\% better results than the best existing model. Moreover, it was found that the presented dimensionless parameters have physical meaning and are much better parameters to develop a model for TBM performance prediction.},
  archive      = {J_ASOC},
  author       = {Majid Kazemi and Reza Barati},
  doi          = {10.1016/j.asoc.2022.108997},
  journal      = {Applied Soft Computing},
  pages        = {108997},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Application of dimensional analysis and multi-gene genetic programming to predict the performance of tunnel boring machines},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A probabilistic neural network for uncertainty prediction
with applications to manufacturing process monitoring. <em>ASOC</em>,
<em>124</em>, 108995. (<a
href="https://doi.org/10.1016/j.asoc.2022.108995">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling the uncertainty from data is an essential quest in the learning of neural network models but has not been well addressed. A probabilistic neural network with Gaussian-mixture distributed parameters is developed in this work to provide an efficient and high-fidelity solution for learning multimodal uncertainties in neural networks. An adaptive Gaussian mixture scheme is adopted to refine the Gaussian mixture probability distributions and ensure the fidelity of uncertainty propagation in both linear and nonlinear transformations through the network. As its predictive distribution can be inferred analytically, this probabilistic network can be trained efficiently using a backpropagation method based on gradient descent . The proposed network not only achieves a state-of-the-art performance when benchmarked on a series of public datasets but also improves the accuracy and uncertainty quantification quality in two manufacturing process monitoring schemes. In a tool wear monitoring scheme for machining, it reduced the root mean square error (RMSE) by 44\% and narrowed the confidence intervals of tool wear prediction by 35\% compared to a neuro-fuzzy model. In a porosity monitoring system for additive manufacturing , the proposed network improved the porosity detection accuracy by 2\% to 93.6\% and quantified confidence intervals that were not available in conventional deep learning models . All these successes prove that the proposed probabilistic neural network can be a promising solution to address practical problems subject to significant uncertainties.},
  archive      = {J_ASOC},
  author       = {Bin Zhang and Yung C. Shin},
  doi          = {10.1016/j.asoc.2022.108995},
  journal      = {Applied Soft Computing},
  pages        = {108995},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A probabilistic neural network for uncertainty prediction with applications to manufacturing process monitoring},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). User dynamic topology-information-based matrix factorization
for e-government recommendation. <em>ASOC</em>, <em>124</em>, 108993.
(<a href="https://doi.org/10.1016/j.asoc.2022.108993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, there is a growing tendency to integrate all public services on e-government websites, a trend that increases the risk of information overload. Matrix factorization (MF)-based recommendation models can effectively predict the user preference for an item, thus demonstrating their superiority in alleviating information overload problems. However, factors such as poor latent representations and the linear interaction function limit the further performance of these models To address these issues, we propose a novel method named user dynamic topology-information-based matrix factorization (User-DTMF). User-DTMF contains two designed modules: the dynamic topology feature learning module and the interactive preference learning module. The former first constructs the user dynamic topology sequence based on user historical behaviors. A convolutional neural network (CNN) is then used to extract features from the sequence. To obtain the final representations of users and items, the latter module uses MF and a fully connected (FC) neural network to model the dynamic topology features and static user-item interactive information. Next, another FC layer, which can be regarded as a nonlinear interaction function, is used to predict the probability of a user clicking on an item. Comprehensive experiments on a real dataset show that User-DTMF outperforms the best benchmark method by a margin of 1.68\% and 3.05\% in terms of Recall@10 and NDCG@10, respectively.},
  archive      = {J_ASOC},
  author       = {Ninghua Sun and Tao Chen and Qiangqiang Luo and Longya Ran},
  doi          = {10.1016/j.asoc.2022.108993},
  journal      = {Applied Soft Computing},
  pages        = {108993},
  shortjournal = {Appl. Soft. Comput.},
  title        = {User dynamic topology-information-based matrix factorization for e-government recommendation},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ensuring expected security cost with flexible resources
using modified DE algorithm based dynamic optimal power flow.
<em>ASOC</em>, <em>124</em>, 108991. (<a
href="https://doi.org/10.1016/j.asoc.2022.108991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new approach to solve the Expected-Security-Cost with Dynamic Optimal Power Flow (ESCDOPF) problem incorporating flexible resources (FRs). The main objective of this approach is to minimize the expected total operation cost, which includes the overall system cost in both pre-and post-contingency states, by satisfying all the constraints of the model. The proposed model incorporates FRs such as game-theory based demand-response-management, battery-energy-storage-systems, and HVDC systems to reduce overall operating costs by ensuring adequate power balance and also maintaining the voltage and line loading limits. To solve the proposed model on an IEEE-30 bus system, a “Modified Differential Evolution” (MDE) algorithm is developed based on a combination of new crossover and new local adaptation approaches. This combination guarantees a good balance between exploration as well as extraction power with less computational costs and population size. The effectiveness of the proposed algorithm is tested for OPF, DOPF and ESCDOPF problems. From the results, it is observed that the proposed algorithm for the ESCDOPF problem helps to minimize the total system operation cost up to 3.04\% in all scenarios when tested with/without FRs during pre-and post-contingency states.},
  archive      = {J_ASOC},
  author       = {B. Aruna Kumari and K. Vaisakh},
  doi          = {10.1016/j.asoc.2022.108991},
  journal      = {Applied Soft Computing},
  pages        = {108991},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Ensuring expected security cost with flexible resources using modified DE algorithm based dynamic optimal power flow},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Work alone then meet: Cognitive attributes and team
interaction in engineering design using evolutionary algorithms.
<em>ASOC</em>, <em>124</em>, 108989. (<a
href="https://doi.org/10.1016/j.asoc.2022.108989">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Engineering products are becoming increasingly more complex and require skills from multiple disciplines to design, something hardly realizable by a single individual. As a result, most organizations form design teams, assembling which, is a challenging task. This work presents an agent-based model along with a framework for investigating team dynamics as the designers work on a representative engineering design problem . The model simulates evolutionary systems wherein, designs are generated, selected, and improved upon, as in biological evolution. A binary-coded genetic algorithm evolves the designs under the influence of the designers’ cognitive attributes, both individually and in a team setting. The results show that product complexity generally decreases the quality of designs, while increasing the number of team members initially increases team performance. However, as the number of team members increases further, their performance levels out and finally declines. An interesting find is that the longer the designers work individually on a design before a team meeting, the better the overall performance. Furthermore, increasing the number of candidate solutions brought to the team meeting initially increases team performance followed by a decrease, indicating that there is an optimal number. The paper concludes with proposed directions that future work can take.},
  archive      = {J_ASOC},
  author       = {Vijitashwa Pandey and Shruthi Venkatesha Murthy and Sara Naranjo Corona},
  doi          = {10.1016/j.asoc.2022.108989},
  journal      = {Applied Soft Computing},
  pages        = {108989},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Work alone then meet: Cognitive attributes and team interaction in engineering design using evolutionary algorithms},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Weighting construction by bag-of-words with
similarity-learning and supervised training for classification models in
court text documents. <em>ASOC</em>, <em>124</em>, 108987. (<a
href="https://doi.org/10.1016/j.asoc.2022.108987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional models of bag-of-words for text classification are unable to identify weights for the co-occurrence of terms, and, mainly, for this reason, they are being replaced by models of word embedding . This article proposes a method to enhance traditional bag-of-words models in two aspects: (a) build features on the co-occurrence of terms and (b) smooth the non-linearity or make the terms linear for different corpus categories. The datasets used are characterized by the non-linearity of the terms, having four different categories of documents. Two computational representations of the datasets are generated: binary and frequency, being used for supervised training of nine classification technologies: random forest , multilayer perceptron neural networks, adaptive boosting , gradient boosting, Gaussian process , support vector machine , Naive Bayes, k -nn and decision trees , its results are compared with nine other algorithms used in other research work. The combinations of each obtained result are compared and assessed using the accuracy, f-measure, precision, and recall metrics. The research and studies generated resulted in the construction of an API that will integrate the Department of Justice software that controls the judicial proceedings. The results of the evaluation metrics and the comparisons with other studies demonstrate that the proposed methodology is feasible to be applied in meeting the needs of the court, allowing to speed up the judgment of lawsuits.},
  archive      = {J_ASOC},
  author       = {Antonio P. Castro Junior and Gabriel A. Wainer and Wesley P. Calixto},
  doi          = {10.1016/j.asoc.2022.108987},
  journal      = {Applied Soft Computing},
  pages        = {108987},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Weighting construction by bag-of-words with similarity-learning and supervised training for classification models in court text documents},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The OWA operator in multiple linear regression.
<em>ASOC</em>, <em>124</em>, 108985. (<a
href="https://doi.org/10.1016/j.asoc.2022.108985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple linear regression (MLR) is one of the most widely used statistical procedures for scholarly and research. The main limitation of MLR is that when being estimated with linear methodologies as ordinary least squares (OLS) becomes not functional with complex data. The ordered weighted average (OWA) is an aggregation operator that provides means that collect complex information. This work presents a new application that uses MLR and OWA operators in the same formulation. We developed two applications called MLR-OWA operator and MLR-GOWA operator. The main advantage of the MLR with OWA operators is that we can consider the degree of optimism and pessimism of the environment. We study some of its main properties and particular cases. Finally, an application is tested for a volatility exchange rate estimation problem.},
  archive      = {J_ASOC},
  author       = {Martha Flores-Sosa and Ezequiel Avilés-Ochoa and José M. Merigó and Janusz Kacprzyk},
  doi          = {10.1016/j.asoc.2022.108985},
  journal      = {Applied Soft Computing},
  pages        = {108985},
  shortjournal = {Appl. Soft. Comput.},
  title        = {The OWA operator in multiple linear regression},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Promoting the physician–patient consensus with a hesitant
fuzzy linguistic consensus method based on betweenness relation.
<em>ASOC</em>, <em>124</em>, 108979. (<a
href="https://doi.org/10.1016/j.asoc.2022.108979">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the relationship between physicians and patients faces increasing challenges, physician–patient relation has gradually become the common concern of the whole society. To relieve this kind of pressure, the mechanism that reaches a consensus between physicians and patients on treatment choices needs to be discussed. Considering that there always exist uncertainties during the medical treatment process, this paper aims to develop a decision-making method to address the consensus issues under a hesitant fuzzy linguistic environment. Since patients and physicians possess different backgrounds and multiple specialties, they are allowed to evaluate alternatives under the individual set of criteria. Then, a Simos–Roy–Figueira method is proposed to derive the weights of criteria with hesitant fuzzy linguistic information. The ELECTRE III method is introduced to obtain the ranking of alternatives from each decision maker’s opinions. Further, a novel consensus method based on betweenness relation is developed to address the obtained rankings. Finally, the process to determine the treatment plan for a hepatocellular carcinoma patient is solved by the proposed method. The obtained result is considered reasonable by experts involved in the consultation, which illustrates the effectiveness of the method. Then, some simulation experiments are designed to show the features of the method. The short running time of the proposed method shows its high efficiency.},
  archive      = {J_ASOC},
  author       = {Hangyao Wu and Peijia Ren and Zeshui Xu},
  doi          = {10.1016/j.asoc.2022.108979},
  journal      = {Applied Soft Computing},
  pages        = {108979},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Promoting the physician–patient consensus with a hesitant fuzzy linguistic consensus method based on betweenness relation},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-fold correlation attention network for predicting
traffic speeds with heterogeneous frequency. <em>ASOC</em>,
<em>124</em>, 108977. (<a
href="https://doi.org/10.1016/j.asoc.2022.108977">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-term traffic prediction (e.g., less than 15 min) is challenging due to severe fluctuations of traffic data caused by dynamic traffic conditions and uncertainties (e.g., in data acquisition, driver behaviors , etc.). Substantial efforts have been undertaken to incorporate spatiotemporal correlations for improving traffic prediction accuracy. In this paper, we demonstrate that closely located road segments exhibit diverse spatial correlations when characterized using different measurements, and considering these multi-fold correlations can improve prediction performance. We propose new measurements to model multiple spatial correlations among traffic data. We develop a Multi-fold Correlation Attention Network (MCAN) that achieves accurate prediction by capturing multi-fold spatial correlation and multi-fold temporal correlations, and incorporating traffic data of heterogeneous sampling frequencies. The effectiveness of MCAN has been extensively evaluated on two real-world datasets in terms of overall performance, ablation study, sensitivity analysis, and case study, by comparing with several state-of-the-art methods. The results show that MCAN outperforms the best baseline with a reduction in mean absolute error (MAE) by 13\% on Singapore dataset and 11\% on Beijing dataset.},
  archive      = {J_ASOC},
  author       = {Yidan Sun and Guiyuan Jiang and Siew-Kei Lam and Peilan He and Fangxin Ning},
  doi          = {10.1016/j.asoc.2022.108977},
  journal      = {Applied Soft Computing},
  pages        = {108977},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-fold correlation attention network for predicting traffic speeds with heterogeneous frequency},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An optimal relevance vector machine with a modified
degradation model for remaining useful lifetime prediction of
lithium-ion batteries. <em>ASOC</em>, <em>124</em>, 108967. (<a
href="https://doi.org/10.1016/j.asoc.2022.108967">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the remaining useful life (RUL) of lithium-ion batteries (LIBs) is vital to ensure the safety and reliability of battery-powered systems. Owing to its ability to represent uncertainties in predictions, relevance vector machine (RVM) regression is effective for short-term predictions, but it has low accuracy for long-term predictions. To improve its performance, an integrated RUL prediction method is proposed based on optimal relevance vectors (RVs) and a modified degradation model (MDM) with the Hausdorff distance (HD), i.e., ORV-MDMHD. First, phase space reconstruction is introduced to produce the inputs to the RVM, which can enhance the long-range dependence of the capacity data for prediction. Then, for RVM regression, its critical parameter, the kernel width, is set to a numerical range rather than a single value. As a result, a series of RVM models is trained, and different sets of RVs are then obtained to represent the original large-scale training data. Moreover, an MDM is designed to fit each set of RVs, which generates one of degradation curves to simulate the possible battery aging process. Then, a curve similarity measure, the HD, is used to select the optimal fitted curve that is most similar to the actual degradation curve. Finally, the predicted RUL of the battery can be calculated by extrapolating the optimal curve to the failure threshold. The experimental results for two cases of batteries indicate that the proposed prediction method can provide more stable prediction with higher accuracy, especially for long-term prediction of the LIB RUL.},
  archive      = {J_ASOC},
  author       = {Wei Guo and Mao He},
  doi          = {10.1016/j.asoc.2022.108967},
  journal      = {Applied Soft Computing},
  pages        = {108967},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An optimal relevance vector machine with a modified degradation model for remaining useful lifetime prediction of lithium-ion batteries},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An RNN-MCDA method to support efficient and stable matching
under uncertain preferences in large-scale sharing platforms.
<em>ASOC</em>, <em>124</em>, 108927. (<a
href="https://doi.org/10.1016/j.asoc.2022.108927">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sharing economy has promoted the rapid development of the global economy, the stable matching plays a vital role in resource sharing. However, the large-scale platform increases the difficulties of stable matching, like low efficiency and weak matching. To realize stable and efficient matching in a large-scale platform, our study designs a recurrent neural network-multiple criteria decision aiding (RNN–MCDA) method. Firstly, to avoid time-consuming mutual assessment in large-scale matching, the RNN–MCDA method is proposed to learn and predict the demanders’ and suppliers’ (DAS) uncertain preferences, like linguistic preferences, which are frequently used in sharing platforms. Considering the disadvantages of low accuracy and interpretability in predicting linguistic preferences in previous studies, we combine the RNN and MCDA to learn and predict the linguistic preferences of DAS. Then, for the matching mechanism, to realize the stable matching, we design a two-stage matching mechanism based on RNN–MCDA. At the first stage, we aim at maximizing total satisfaction based on RNN–MCDA instead of inefficient mutual assessment. For the second stage, we focus on the individuals who do not meet the stable constraint in the first stage and use the platforms’ strategies to adjust the satisfaction of DAS and realize stable matching. Finally, an improved cuckoo algorithm is designed to solve the bi-level programming. An example in the manufacturing capacity sharing platform is used to verify our study.},
  archive      = {J_ASOC},
  author       = {Huagang Tong and Jianjun Zhu},
  doi          = {10.1016/j.asoc.2022.108927},
  journal      = {Applied Soft Computing},
  pages        = {108927},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An RNN-MCDA method to support efficient and stable matching under uncertain preferences in large-scale sharing platforms},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Decomposed neural architecture search for image denoising.
<em>ASOC</em>, <em>124</em>, 108914. (<a
href="https://doi.org/10.1016/j.asoc.2022.108914">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical applications of deep learning , as the demand for the modeling capability increases, the network size may need to be massively enlarged in response. This may form a significant challenge in practice, especially when facing the dilemma of limited computational resources, making model compression indispensable. It can be time-consuming and interminable to obtain an appropriate network architecture through manual compression. In this paper, we propose an automated method for searching decomposed network architectures, named DNAS (standing for Decomposed Neural Architecture Search). It integrates both tasks of neural architecture search and tensor decomposition based model compression within a unified framework. The method is able to efficiently find a compact network with high performance for image denoising , with respect to memory and runtime. Particularly, using one single V100 GPU , it only takes about 1.5 h to obtain a denoising network on the BSD500 dataset. Experimental results demonstrate that compared with models developed using existing methods, DNAS consumes significantly less inference time and employs much fewer trainable parameters, outperforming existing approaches on both synthetic and real-world denoising datasets.},
  archive      = {J_ASOC},
  author       = {Di Li and Yunpeng Bai and Zongwen Bai and Ying Li and Changjing Shang and Qiang Shen},
  doi          = {10.1016/j.asoc.2022.108914},
  journal      = {Applied Soft Computing},
  pages        = {108914},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Decomposed neural architecture search for image denoising},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimized neuro observer-based sliding mode control for a
nonlinear system using fuzzy static sliding surface. <em>ASOC</em>,
<em>124</em>, 108904. (<a
href="https://doi.org/10.1016/j.asoc.2022.108904">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a robust controller for the complete model of the ball and beam system (BBS) is proposed. The aim is to control the position of the ball and also to balance the beam’s angle. Sliding Mode Control (SMC), Fuzzy Logic (FL) and Multi-Layer Perceptron Neural Network (MLPNN) are the techniques utilized in this work. In the presented controller, a fuzzy sliding surface is used to reduce the states’ tracking errors, along with a boundary layer in the control law to decrease the chattering phenomenon of SMC. Also, a neuro observer-based (NOB) controller is designed to estimate the system’s states with assumption of lack of a sensor for reporting the position of the ball. The controller stabilizes the system very well and its stability is proved in detail considering uncertainties. To improve the performance and speed up the system, the controller is optimized using ten single-objective and two multi-objective optimization algorithms. The proposed controller avoids high computational costs and provides less control effort, also reduces the errors and the effects of chattering and all system’s states converge to their desired values in a suitable time domain. The performance of the controller is compared to PID, PD, and fuzzy controllers . To show the effectiveness of the designed controller, a parametric uncertainty and an external disturbance are added. The results indicate an efficient performance and robustness of the designed controllers.},
  archive      = {J_ASOC},
  author       = {Sanam Hajipour and Hamed Pourhashem and Saeed Nezamivand Chegini and Ahmad Bagheri},
  doi          = {10.1016/j.asoc.2022.108904},
  journal      = {Applied Soft Computing},
  pages        = {108904},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Optimized neuro observer-based sliding mode control for a nonlinear system using fuzzy static sliding surface},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pest incidence forecasting based on internet of things and
long short-term memory network. <em>ASOC</em>, <em>124</em>, 108895. (<a
href="https://doi.org/10.1016/j.asoc.2022.108895">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The infestation of litchi stink bugs ( Tessaratoma papillosa ) has always had a significant impact on the yield of longan plantations. Pest control is critical for farmers to detect and timely suppress the occurrence of pests while effectively reducing damages. Environmental factors, climate change in particular, have contributed to the growing population of pests whereas weather can vary in different terrains, locations, and time. Due to the geographical and topographical conditions of Taiwan, this study focuses on investigating fruit plantations on sloping land in subtropics with distinct seasonal changes. The article aims at forecasting meteorological data based on Long short-term memory network (LSTM) and identifying the correlation between pest infestation and environmental factors through Machine Learning (ML). In this section, the structure and experimental process of the research will be outlined. At the first stage, meteorological information of the experimented site is obtained through the self-designed IoT (Internet of Things) system and wireless long-distance transmission technology. Since meteorological information forecasted is displayed in time series, multi-layer LSTM and bidirectional LSTM are used to solve the problem. Finally, environmental data and field surveys conducted for pest surveillance will be employed to forecast the severity of pest infestation through KNN, SVM , and random forest models. The result of the experiment shows that LSTM performs well in weather forecasting with 96\% R-Squared values whereas the accuracy rate of pest prediction conducted by Machine Learning (ML) is 85\%. The study verifies that meteorological factors do affect pest incidence. For example, the population of litchi stink bugs increase easily under suitable temperature, humidity, and sunlight. LSTM is superior in providing solutions for long-range dependence in statistics. This article shall present regions with shifting weather patterns, meteorological conditions and time length forecasted corresponding to the oceanic climate, as well as the correlation between pest population and environmental factors.},
  archive      = {J_ASOC},
  author       = {Ching-Ju Chen and Yuan-Shuo Li and Chen-Yu Tai and Ying-Cheng Chen and Yueh-Min Huang},
  doi          = {10.1016/j.asoc.2022.108895},
  journal      = {Applied Soft Computing},
  pages        = {108895},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Pest incidence forecasting based on internet of things and long short-term memory network},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interval-valued fuzzy sets aggregation and evaluation
approaches. <em>ASOC</em>, <em>124</em>, 108887. (<a
href="https://doi.org/10.1016/j.asoc.2022.108887">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We review interval-valued fuzzy sets (IVFS) and develop their application for several areas. We show how to aggregate IVFSs and provide information measures to guide the aggregation. An example of the use of IVFS to represent the uncertainties in Covid-19 contact tracing is illustrated. Then we consider the application of IVFS in spatial data. By determining distance and area of IVFS data we can use aggregation to apply this to minimum bounding rectangles for GIS. Finally, IVFS can be applied in computing diversity in the process of selection of groups exhibiting diversity.},
  archive      = {J_ASOC},
  author       = {Frederick E. Petry and Ronald R. Yager},
  doi          = {10.1016/j.asoc.2022.108887},
  journal      = {Applied Soft Computing},
  pages        = {108887},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Interval-valued fuzzy sets aggregation and evaluation approaches},
  volume       = {124},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Special issue on soft computing based intelligent decision
making systems for dynamic frameworks with real-world application.
<em>ASOC</em>, <em>123</em>, 109059. (<a
href="https://doi.org/10.1016/j.asoc.2022.109059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ASOC},
  author       = {Enrique Herrera-Viedma and Francisco Chiclana and Yucheng Dong and Yi Peng and Yejun Xu and Francisco Javier Cabrerizo},
  doi          = {10.1016/j.asoc.2022.109059},
  journal      = {Applied Soft Computing},
  pages        = {109059},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Special issue on soft computing based intelligent decision making systems for dynamic frameworks with real-world application},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dealing with distribution mismatch in semi-supervised deep
learning for COVID-19 detection using chest x-ray images: A novel
approach using feature densities. <em>ASOC</em>, <em>123</em>, 108983.
(<a href="https://doi.org/10.1016/j.asoc.2022.108983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of the global coronavirus pandemic, different deep learning solutions for infected subject detection using chest X-ray images have been proposed. However, deep learning models usually need large labelled datasets to be effective. Semi-supervised deep learning is an attractive alternative, where unlabelled data is leveraged to improve the overall model’s accuracy. However, in real-world usage settings, an unlabelled dataset might present a different distribution than the labelled dataset (i.e. the labelled dataset was sampled from a target clinic and the unlabelled dataset from a source clinic). This results in a distribution mismatch between the unlabelled and labelled datasets. In this work, we assess the impact of the distribution mismatch between the labelled and the unlabelled datasets, for a semi-supervised model trained with chest X-ray images, for COVID-19 detection. Under strong distribution mismatch conditions, we found an accuracy hit of almost 30\%, suggesting that the unlabelled dataset distribution has a strong influence in the behaviour of the model. Therefore, we propose a straightforward approach to diminish the impact of such distribution mismatch. Our proposed method uses a density approximation of the feature space. It is built upon the target dataset to filter out the observations in the source unlabelled dataset that might harm the accuracy of the semi-supervised model. It assumes that a small labelled source dataset is available together with a larger source unlabelled dataset. Our proposed method does not require any model training, it is simple and computationally cheap. We compare our proposed method against two popular state of the art out-of-distribution data detectors, which are also cheap and simple to implement. In our tests, our method yielded accuracy gains of up to 32\%, when compared to the previous state of the art methods . The good results yielded by our method leads us to argue in favour for a more data-centric approach to improve model’s accuracy. Furthermore, the developed method can be used to measure data effectiveness for semi-supervised deep learning model training.},
  archive      = {J_ASOC},
  author       = {Saul Calderon-Ramirez and Shengxiang Yang and David Elizondo and Armaghan Moemeni},
  doi          = {10.1016/j.asoc.2022.108983},
  journal      = {Applied Soft Computing},
  pages        = {108983},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dealing with distribution mismatch in semi-supervised deep learning for COVID-19 detection using chest X-ray images: A novel approach using feature densities},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Driver vigilance detection for high-speed rail using fusion
of multiple physiological signals and deep learning. <em>ASOC</em>,
<em>123</em>, 108982. (<a
href="https://doi.org/10.1016/j.asoc.2022.108982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the popularity of high-speed rail in China and with faster operation speeds, the safety of railways has also received more attention. This paper proposes a vigilance detection method for high-speed rail drivers based on wireless wearable multi-physiological signals fusion and deep learning . The intended method consists of three components: wireless wearable signal acquisition equipment, physiological signal preprocessing and driver vigilance detection. In the initial stage, a wireless wearable device based on open source brain–computer interfaces was used to collect electroencephalogram, electrocardiogram and electromyogram signals in the high-speed rail simulation environment. Secondly, linear filtering, fast independent component analysis and wavelet filtering are performed on the three kinds of signals, and reasonable slicing is performed to make a dataset. Finally, a convolutional recurrent neural network with channel attention mechanism and memory ability is proposed. Multiple physiological signals from wireless wearable devices are used to train the network. This network improves the ability to recognize the vigilance of drivers and verifies the effectiveness of the combination of squeeze-and-excitation block and long short-term memory with convolutional neural network . Furthermore, the vigilance detection effectiveness was evaluated under different signal combinations; the testing set verified the accuracy of the network as 98.11\%. Results prove the feasibility of the high-speed rail driver vigilance detection method based on multiple physiological signals and deep learning , which can help to avoid high-speed rail accidents.},
  archive      = {J_ASOC},
  author       = {Jiangfan Chen and Haobo Li and Lei Han and Jiaoyi Wu and Ali Azam and Zutao Zhang},
  doi          = {10.1016/j.asoc.2022.108982},
  journal      = {Applied Soft Computing},
  pages        = {108982},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Driver vigilance detection for high-speed rail using fusion of multiple physiological signals and deep learning},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A three-way multi-attribute decision making method based on
regret theory and its application to medical data in fuzzy environments.
<em>ASOC</em>, <em>123</em>, 108975. (<a
href="https://doi.org/10.1016/j.asoc.2022.108975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiovascular disease is a global leading cause of death, and timely monitoring can determine its extent. Clinicians use these diagnostic indicators to make scientific and reasonable decisions. However, when decision-makers (DMs) encounter risks in complex environments, their limited rationality may affect decision behaviors. Therefore, the paper explores a new three-way multi-attribute decision making method based on regret theory (3W-MADM-R), which uses heart disease data to make decisions in fuzzy environments. There are three main steps in developing 3W-MADM-R, i.e., (i) we propose the notion of relative outcome functions and corresponding aggregated regret-based utility functions of each object; (ii) we estimate the conditional probability via an outranked set defined by an outranking relation based on the Preference Ranking Organization Method for Enrichment Evaluation (PROMETHEE II); (iii) we construct three-way decision rules to solve the problems of clustering and ranking of objects in data analysis. In order to demonstrate the usefulness of 3W-MADM-R, we apply it to analyze heart disease data. By comparing with results of other methods, we show the feasibility, stability and superiority of the presented 3W-MADM-R method.},
  archive      = {J_ASOC},
  author       = {Jinxing Zhu and Xueling Ma and Jianming Zhan and Yiyu Yao},
  doi          = {10.1016/j.asoc.2022.108975},
  journal      = {Applied Soft Computing},
  pages        = {108975},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A three-way multi-attribute decision making method based on regret theory and its application to medical data in fuzzy environments},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generalized susceptible–exposed–infectious–recovered model
and its contributing factors for analysing the death and recovery rates
of the COVID-19 pandemic. <em>ASOC</em>, <em>123</em>, 108973. (<a
href="https://doi.org/10.1016/j.asoc.2022.108973">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 is a highly contagious disease that has infected over 136 million people worldwide with over 2.9 million deaths as of 11 April 2021. In March 2020, the WHO declared COVID-19 as a pandemic and countries began to implement measures to control the spread of the virus. The spread and the death rates of the virus displayed dramatic differences among countries globally, showing that there are several factors affecting its spread and mortality. By utilizing the cumulative number of cases from John Hopkins University, the recovery rate, death rate, and the number of active, recovered, and death cases were simulated to analyse the trends and patterns within the chosen countries. 10 countries from 3 different case severity categories (high cases, medium cases, and low cases) and 5 continents (Asia, North America, South America, Europe, and Oceania) were studied. A generalized SEIR model which considers control measures such as isolation, and preventive measures such as vaccination is applied in this study. This model is able to capture not only the dynamics between the states, but also the time evolution of the states by using the fourth-order-Runge–Kutta process. This study found no significant patterns in the countries under the same case severity category, suggesting that there are other factors contributing to the pattern in these countries. One of the factors influencing the pattern in each country is the population’s age. COVID-19 related deaths were found to be notably higher among older people, indicating that countries comprising of a larger proportion of older age groups have an increased risk of experiencing higher death rates. Tighter governmental control measures led to fewer infections and eventually reduced the number of death cases, while increasing the recovery rate, and early implementations were found to be far more effective in controlling the spread of the virus and produced better outcomes.},
  archive      = {J_ASOC},
  author       = {Felin Wilta and Allyson Li Chen Chong and Ganeshsree Selvachandran and Ketan Kotecha and Weiping Ding},
  doi          = {10.1016/j.asoc.2022.108973},
  journal      = {Applied Soft Computing},
  pages        = {108973},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Generalized Susceptible–Exposed–Infectious–Recovered model and its contributing factors for analysing the death and recovery rates of the COVID-19 pandemic},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Research on product recommendation based on matrix
factorization models fusing user reviews. <em>ASOC</em>, <em>123</em>,
108971. (<a href="https://doi.org/10.1016/j.asoc.2022.108971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, recommendation models based on matrix factorization (MF) suffer from the problem of rating sparsity because user-product rating matrix is usually sparse. To address the problem, it is significant to fuse some contextual data or side information on basic MF models. According to this core idea, this paper proposes a modified recommendation model, MFFR (matrix factorization fusing reviews) which recommend products by considering the fusing information on user reviews and user ratings. First, MFFR constructs user-product preference matrix from user reviews by using Latent Dirichlet Allocation (LDA) topic model. Then MFFR predicts ratings and generates personalized top-n recommendation products by using MF model to learn comprehensive latent factors of user-product rating matrix and user-product preference matrix simultaneously. The experimental results of three published datasets demonstrate that our model MFFR can achieve more accurate predicted ratings and hits more correct products of top-n recommendation than the comparative traditional models. MFFR can effectively raise the quality of recommendation, especially in the high level of rating sparsity .},
  archive      = {J_ASOC},
  author       = {Heyong Wang and Zhenqin Hong and Ming Hong},
  doi          = {10.1016/j.asoc.2022.108971},
  journal      = {Applied Soft Computing},
  pages        = {108971},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Research on product recommendation based on matrix factorization models fusing user reviews},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MMDGAN: A fusion data augmentation method for tomato-leaf
disease identification. <em>ASOC</em>, <em>123</em>, 108969. (<a
href="https://doi.org/10.1016/j.asoc.2022.108969">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tomato disease control is of great significance to ensure crop production and tomato disease classification study is an essential tool for doing so. In this paper, we propose a new data augmentation method based on deep threshold multi-feature extraction convolution GAN with Mixed Attention and Markovian Discriminator (MMDGAN) for tomato disease leaf classification. Firstly, in the generator of MMDGAN, a deep threshold multi-feature extraction module was proposed to improve the feature extraction of tomato disease leaves. Then, a mixed attention mechanism combined cross attention module with fused features-highlighting module was proposed to coordinate the overall generation of images. Finally, for the discriminator, Markov discriminator was used to strengthen the similarity judgment of local texture of images. Based on the open datasets PlantVillage, the Frechet Inception Distance (FID) score of healthy tomato leaf image, Leaf Mold, Leaf Curl and Spider Mite generated by MMDGAN were 159.3010, 164.4744, 230.3825 and 254.9866 respectively. Thereafter, a B-ARNet model is trained on synthetic and real images using transfer learning to classify the four categories of tomato diseases. The proposed method achieved an accuracy of 97.12\%, with and F1 value of 97.78\%. The proposed approach shows its superiority over the existing methodologies.},
  archive      = {J_ASOC},
  author       = {Liangji Zhang and Guoxiong Zhou and Chao Lu and Aibin Chen and Yanfeng Wang and Liujun Li and Weiwei Cai},
  doi          = {10.1016/j.asoc.2022.108969},
  journal      = {Applied Soft Computing},
  pages        = {108969},
  shortjournal = {Appl. Soft. Comput.},
  title        = {MMDGAN: A fusion data augmentation method for tomato-leaf disease identification},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Explainable artificial intelligence-based edge fuzzy images
for COVID-19 detection and identification. <em>ASOC</em>, <em>123</em>,
108966. (<a href="https://doi.org/10.1016/j.asoc.2022.108966">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic continues to wreak havoc on the world’s population’s health and well-being. Successful screening of infected patients is a critical step in the fight against it, with radiology examination using chest radiography being one of the most important screening methods. For the definitive diagnosis of COVID-19 disease, reverse-transcriptase polymerase chain reaction remains the gold standard. Currently available lab tests may not be able to detect all infected individuals; new screening methods are required. We propose a Multi-Input Transfer Learning COVID-Net fuzzy convolutional neural network to detect COVID-19 instances from torso X-ray, motivated by the latter and the open-source efforts in this research area. Furthermore, we use an explainability method to investigate several Convolutional Networks COVID-Net forecasts in an effort to not only gain deeper insights into critical factors associated with COVID-19 instances, but also to aid clinicians in improving screening. We show that using transfer learning and pre-trained models, we can detect it with a high degree of accuracy. Using X-ray images, we chose four neural networks to predict its probability. Finally, in order to achieve better results, we considered various methods to verify the techniques proposed here. As a result, we were able to create a model with an AUC of 1.0 and accuracy, precision, and recall of 0.97. The model was quantized for use in Internet of Things devices and maintained a 0.95 percent accuracy.},
  archive      = {J_ASOC},
  author       = {Qinhua Hu and Francisco Nauber B. Gois and Rafael Costa and Lijuan Zhang and Ling Yin and Naercio Magaia and Victor Hugo C. de Albuquerque},
  doi          = {10.1016/j.asoc.2022.108966},
  journal      = {Applied Soft Computing},
  pages        = {108966},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Explainable artificial intelligence-based edge fuzzy images for COVID-19 detection and identification},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A correlation guided genetic algorithm and its application
to feature selection. <em>ASOC</em>, <em>123</em>, 108964. (<a
href="https://doi.org/10.1016/j.asoc.2022.108964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional feature selection methods based on genetic algorithms randomly evolve using unguided crossover operators and mutation operators . This leads to many inferior solutions being generated and verified using costly fitness functions. In this paper, we propose a new feature selection method based on a correlation-guided genetic algorithm. It first roughly checks the quality of the potential solutions to reduce the possibility of producing inferior solutions. Then more potentially superior solutions can be verified by the classifier to improve the efficiency of the evolutionary process. It is theoretically proven that the proposed method converges to the optimal solution with a very weak precondition . Numerical results on 4 artificial datasets and 6 real datasets show that compared with other existing methods, the proposed method is a competitive feature selection method with higher classification accuracy and a more efficient evolutionary process.},
  archive      = {J_ASOC},
  author       = {Jian Zhou and Zhongsheng Hua},
  doi          = {10.1016/j.asoc.2022.108964},
  journal      = {Applied Soft Computing},
  pages        = {108964},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A correlation guided genetic algorithm and its application to feature selection},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GENEmops: Supervised feature selection from high dimensional
biomedical dataset. <em>ASOC</em>, <em>123</em>, 108963. (<a
href="https://doi.org/10.1016/j.asoc.2022.108963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identification of differentially expressed genes, lying beneath the carcinogenic expression, is still very crucial for accurate detection and treatment of the disease. The challenge of a large number of attributes compared to a small number of instances and the prediction of highly discriminative genes requires an effective method. It can be regarded as a multi-objective problem that involves minimization of the number of selected genes and maximization of the classification performance. It is expected to find the optimal count of the most significant genes which are strongly associated with the classification of cancer. In this paper, we have proposed a framework entitled as GENEmops for gene selection and subsequent classification of the disease. The core of the GENEmops is inspired by multi-objective player selection strategy based hybrid population search (MOPS-HPS). The proposed system uses a multi-filtering and adaptive parameter tuning approach for gene selection. A new graded rotational blending operator is introduced to enhance the exploitation capability of the hybrid wrapper based scheme. Unlike the most current existing methods which employ some strategy to transmute the continuous search space to binary search space, it uses an adaptive way for binary conversion which is stochastically updated during the search phase. GENEmops also improves the performance of the classifier by tuning its parameters. The efficiency of the proposed GENEmops is tested on sixteen biological datasets (eight binary class and eight multi-class) and compared with state-of-the-art computationally intelligent multi-objective approaches. Experimental results demonstrate the efficiency of the proposed work.},
  archive      = {J_ASOC},
  author       = {Prativa Agarwalla and Sumitra Mukhopadhyay},
  doi          = {10.1016/j.asoc.2022.108963},
  journal      = {Applied Soft Computing},
  pages        = {108963},
  shortjournal = {Appl. Soft. Comput.},
  title        = {GENEmops: Supervised feature selection from high dimensional biomedical dataset},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhanced COVID-19 x-ray image preprocessing schema using
type-2 neutrosophic set. <em>ASOC</em>, <em>123</em>, 108948. (<a
href="https://doi.org/10.1016/j.asoc.2022.108948">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we introduce a new medical image enhancement approach depending on a type-2 neutrosophic set (T2NS) and α α -mean and β β - enhancement operations. This new approach obtains a good enhancement result by defining the uncertainties within the image in a six-degree membership. To show the real case study of this proposed technique, a novel enhancement approach for COVID-19 in X-ray is introduced. The X-ray image suffers from poor contrast and inconsistencies in its gray levels. The proposed method tackles this issue by obtaining a neutrosophic domain for gray level images depending on six membership functions. Through enhancement operations, T2NS entropy is obtained to evaluate the change in the gray level of X-ray images. The proposed approach can improve chest X-ray images by reducing the entropy values to minimize the uncertainty within the image. An image de-neutrosophication operation is obtained on the enhanced images to convert them from the neutrosophic set (NS) domain to the grayscale image . Finally, output images are compared with the enhanced images achieved under a single-valued neutrosophic set (SVNS) domain.},
  archive      = {J_ASOC},
  author       = {Mohamed Abdel-Basset and Nihal N. Mostafa and Karam M. Sallam and Ibrahim Elgendi and Kumudu Munasinghe},
  doi          = {10.1016/j.asoc.2022.108948},
  journal      = {Applied Soft Computing},
  pages        = {108948},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Enhanced COVID-19 X-ray image preprocessing schema using type-2 neutrosophic set},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimization of an auto drum fashioned brake using the elite
opposition-based learning and chaotic k-best gravitational search
strategy based grey wolf optimizer algorithm. <em>ASOC</em>,
<em>123</em>, 108947. (<a
href="https://doi.org/10.1016/j.asoc.2022.108947">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Highly non-linear optimization problems are widely found in many real-world engineering applications . To tackle these problems, a novel assisted optimization strategy , named elite opposition-based learning and chaotic k -best gravitational search strategy (EOCS), is proposed for the grey wolf optimizer (GWO) algorithm. In the EOCS based grey wolf optimizer (EOCSGWO) algorithm, the elite opposition-based learning strategy (EOBLS) is proposed to take full advantage of better-performing particles for optimization in the next generations. A chaotic k -best gravitational search strategy (CKGSS) is proposed to obtain the adaptive step to improve the global exploratory ability. The performance of the EOCSGWO is verified and compared with those of other seven meta-heuristic optimization algorithms using ten popular benchmark functions . Results show that the EOCSGWO is more competitive in accuracy and robustness, and obtains the first in ranking among the six optimization algorithms . Further, the EOCSGWO is employed to optimize the design of an auto drum fashioned brake. The results show that the braking efficiency factor can be improved by 28.412\% compared with the initial design.},
  archive      = {J_ASOC},
  author       = {Yongliang Yuan and Xiaokai Mu and Xiangyu Shao and Jianji Ren and Yong Zhao and Zhenxi Wang},
  doi          = {10.1016/j.asoc.2022.108947},
  journal      = {Applied Soft Computing},
  pages        = {108947},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Optimization of an auto drum fashioned brake using the elite opposition-based learning and chaotic k-best gravitational search strategy based grey wolf optimizer algorithm},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data-based variable universe adaptive fuzzy controller with
self-tuning parameters. <em>ASOC</em>, <em>123</em>, 108944. (<a
href="https://doi.org/10.1016/j.asoc.2022.108944">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-based variable universe adaptive fuzzy controllers (VUAFCs) with self-tuning parameters are developed for complex systems with unknown universes in this paper. The main feature of the proposed VUAFC is the new defined contraction–expansion (C-E) factor on an infinite universe, which is more flexible and practical in real applications. Moreover, the data-based methods to tune the parameters including the peak points of output fuzzy subsets and the C-E factor parameters are proposed. The peak points of the output fuzzy subsets are mined by an improved Wang–Mendel method based on conflicting rules. The parameters of the VUAFC are optimized by solving an offline optimization problem using the chaotic particle swarm optimization (CPSO) algorithm. The simulation results on the strip temperature control of the radiant-tube indirect-fired furnace of annealing furnace show that our proposed method has strong practicability and good control performance.},
  archive      = {J_ASOC},
  author       = {Yali Jin and Weihua Cao and Min Wu and Yan Yuan},
  doi          = {10.1016/j.asoc.2022.108944},
  journal      = {Applied Soft Computing},
  pages        = {108944},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Data-based variable universe adaptive fuzzy controller with self-tuning parameters},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). End-to-end table structure recognition and extraction in
heterogeneous documents. <em>ASOC</em>, <em>123</em>, 108942. (<a
href="https://doi.org/10.1016/j.asoc.2022.108942">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatically detecting and parsing tables into an indexable and searchable format is an important problem in document digitization. It relates to computer vision , machine learning , and optical character recognition . This paper presents a simple model based on a deep neural network architecture that combines recent advances in computer vision and machine learning , which can be used to detect and convert a table into a format that can be edited or searched. The motivation for this work is to develop a sound method to extract the vast data set of knowledge available in physical documents such that it can be used to develop data-driven tools that can be used to support decisions in fields such as healthcare and finance. The model uses a Yolo-based object detector trained to maximize the Intersection over Union of the detected table regions within the document image and a novel OCR-based algorithm to parse the table from each table detected in the document.Past works have all focused on documents and images containing a level and even tables. This paper aims to present our findings after the model is run on a set of skewed image datasets. Experiments on the Marmot and Publaynet datasets show that the proposed method is entirely accurate and can generalize different tables formats . At an Intersection over the Union threshold of 50\%, we achieve a mean Average Precision (mAP) of 98\% and an average IoU of 88.81\% on the PubLayNet dataset. With the same IoU threshold, we achieve an mAP of 95.07\% and an average IoU of 75.57\% on the Marmot dataset.},
  archive      = {J_ASOC},
  author       = {Tejas Kashinath and Twisha Jain and Yash Agrawal and Tanvi Anand and Sanjay Singh},
  doi          = {10.1016/j.asoc.2022.108942},
  journal      = {Applied Soft Computing},
  pages        = {108942},
  shortjournal = {Appl. Soft. Comput.},
  title        = {End-to-end table structure recognition and extraction in heterogeneous documents},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multivariate EMD-LSTM model aided with time dependent
intrinsic cross-correlation for monthly rainfall prediction.
<em>ASOC</em>, <em>123</em>, 108941. (<a
href="https://doi.org/10.1016/j.asoc.2022.108941">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of rainfall is a complex problem because of the large number of controlling factors, complex interrelationships between them and the multiscaling behaviour of the process. Because of the multiscaling behaviour of the problem, the use of hybrid modelling involving decomposition techniques is preferable over strenuous physical models and standalone driven techniques for accurate rainfall predictions. This study proposes a novel hybrid modelling framework integrating Long Short Term Memory (LSTM) and Multivariate Empirical Mode Decomposition (MEMD) aided with Time Dependent Intrinsic Cross-Correlation (TDICC) analysis algorithm for monthly rainfall predictions. The application of the proposed model is demonstrated for monthly rainfall prediction of 2005–2015 period at All India spatial domain considering El-Niño Southern Oscillation(ENSO), Indian Ocean Dipole(IOD) and five antecedent values of rainfall are the input variables. The proposed framework first uses MEMD to obtain a set of orthogonal components namely Intrinsic Mode Functions (IMFs) identifying and aligning the common scales embedded in the multiple input variables considered. Subsequently, scale specific rainfall information are predicted by incorporating them on relevant IMFs and their significant lags identified through TDIC and TDICC analyses. Final aggregation of predicted rainfall components from different scales gives the monthly rainfall of a generic time step ahead. The efficacy of the proposed MEMD-TDICC-LSTM framework is compared with five other hybrid models such as MEMD-TDIC-ANN, MEMD-TDICC-ANN, MEMD-ACO-ANN, MEMD-ACO-LSTM and MEMD-TDIC-LSTM, which used Time Dependent Intrinsic Correlation (TDIC) and Ant Colony Optimization (ACO) for predictor selection and Artificial Neural Network (ANN) as modelling tool. The study has used different graphical representations and ten different statistical performance evaluation measures for the prediction of validation period, it is observed that the proposed model could achieve a predictive skill of 0.98, Nash-SutcliffeEfficiency (NSE) of 0.95 and Index of Agreement (IA) of 0.91 which is better than all the five remaining models. The capability of MEMD-TDICC-LSTM model to predict the extremes is also confirmed by using the bar graph for the drought year rainfall of 2009 and is observed that the model is successful in capturing the extremes with an annual rainfall 975.16 mm closer to observed value 927.3 mm. MEMD algorithm facilitates the inclusion of multiple large scale climatic oscillations as inputs and their multi time scale decomposition, TDICC helps to fix the relevant inputs at different time scales and the LSTM functions as the robust modelling tool. Further, the framework using this specific combination resulted in substantial reduction in modelling complexity and faster execution, as the approach considers only the most relevant and significant inputs in the process.},
  archive      = {J_ASOC},
  author       = {Kavya Johny and Maya L. Pai and Adarsh S.},
  doi          = {10.1016/j.asoc.2022.108941},
  journal      = {Applied Soft Computing},
  pages        = {108941},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multivariate EMD-LSTM model aided with time dependent intrinsic cross-correlation for monthly rainfall prediction},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-strategy ensemble firefly algorithm with equilibrium
of convergence and diversity. <em>ASOC</em>, <em>123</em>, 108938. (<a
href="https://doi.org/10.1016/j.asoc.2022.108938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Balancing the convergence and diversity in the multi-objective firefly algorithm is essential for obtaining high precision and well distributed Pareto front . However, most existing algorithms cannot​ guarantee such balance, leading to a poor comprehensive performance. To address this limitation, this paper proposes a multi-strategy ensemble firefly algorithm with equilibrium of convergence and diversity (MEFA-CD). Firstly, an improved linear congruence method is used to generate the initial population with uniform distribution, to provide a good start for the subsequent population evolution and ensure the global search ability; Secondly, a hybrid learning strategy is utilized to identify the best elite solution according to the maximum fitness value. Combined with the current best solution, the firefly is guided to learn under the effect of compensation factor . On the one hand, it breaks through the population constraints, which yields a faster convergence to the Pareto optimal solution set. On the other hand, it expands the search range of the population, which improves the diversity and the accuracy of the Pareto optimal set ; Finally, the crowding distance mechanism is used to delete the aggregation solution, which maintains the diversity of external files and ensures the local development ability of the population, and further improves the convergence of the algorithm. Experimental results show that, compared with other multi-objective optimization algorithms, the proposed algorithm has better performance in convergence and diversity, among which the optimization performance is improved by 61\% compared with the standard MOFA.},
  archive      = {J_ASOC},
  author       = {Jia Zhao and Dandan Chen and Renbin Xiao and Zhihua Cui and Hui Wang and Ivan Lee},
  doi          = {10.1016/j.asoc.2022.108938},
  journal      = {Applied Soft Computing},
  pages        = {108938},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-strategy ensemble firefly algorithm with equilibrium of convergence and diversity},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bandwidth estimation in high mobility scenarios of MANET
using NSGA-II optimized fuzzy inference system. <em>ASOC</em>,
<em>123</em>, 108936. (<a
href="https://doi.org/10.1016/j.asoc.2022.108936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integration of mobility to sensor node enhanced the scalability of Ad-hoc networks. Bandwidth estimation in scenarios where nodes move randomly and frequently changes its link may depend on factors other than congestion in network traffic. The event of link failure due to the high mobility behavior of nodes in the path from source to destination is one of the dominating cause. However, in both cases, TCP’s new-Reno and its variants reduce the congestion-window size to half or 1-MSS, which can cause bandwidth underutilization in the event of a packet drop due to link failure. The proposed approach distinguishes the link failure from network congestion and estimates bandwidth based on link and path stability matrix. The contribution includes the identification of node mobility fuzziness in unicast and broadcast scenarios of IEEE 802.15.4 based MANET . The mobility-fuzziness formulation by the proposed NSGA-II optimized fuzzy-inference-system imitates the node’s mobility behavior and, in the event of packet loss , is employed to realize the path-stability metric to estimate the congestion window size. The thorough evaluation with current state-of-the-art techniques shows that the proposed path stability metric allows the estimation of congestion window size to the current congestion window in the event of a packet loss due to link failure. Improving the bandwidth utilization metric in high mobility scenarios from 53–61\% for existing approaches to above 83\% in proposed approach.},
  archive      = {J_ASOC},
  author       = {Pankaj Pal and Sachin Tripathi and Chiranjeev Kumar},
  doi          = {10.1016/j.asoc.2022.108936},
  journal      = {Applied Soft Computing},
  pages        = {108936},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Bandwidth estimation in high mobility scenarios of MANET using NSGA-II optimized fuzzy inference system},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Instance-based transfer learning method via modified
domain-adversarial neural network with influence function: Applications
to design metamodeling and fault diagnosis. <em>ASOC</em>, <em>123</em>,
108934. (<a href="https://doi.org/10.1016/j.asoc.2022.108934">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The availability of a large amount of high-quality data is critical to the performance of machine-learning models. It is challenging to obtain a training dataset because data collection is costly and time-consuming. However, data scarcity can be overcome and an accurate model can be obtained if data from similar models are reused. In this paper, we propose an instance-based transfer learning method to obtain a more accurate model for situations with data scarcity. The proposed method uses a modified domain-adaptation technique to generate auxiliary target-domain data from source-domain data. Subsequently, useful data are selected from the auxiliary target-domain data to preclude the negative transfer that may leverage source-domain data to reduce the learning performance in the target domain. A modified domain-adversarial neural network was used to generate auxiliary target-domain data in the context of instance-based transfer learning . Particularly, the feature extractor and domain discriminator were trained to extract the domain-invariant features from the source and target domains, whereas the target generator was trained to generate auxiliary target-domain data using the domain-invariant features. Additionally, an influence function that can measure the influence of individual training samples on the learning performance was applied to identify useful data. Three case studies were conducted to validate the proposed method: a mathematical function example, drone blade metamodeling, and bearing fault diagnosis. The results of these case studies indicate a significant improvement in neural network prediction despite data scarcity.},
  archive      = {J_ASOC},
  author       = {Jinhyeok Kim and Jongsoo Lee},
  doi          = {10.1016/j.asoc.2022.108934},
  journal      = {Applied Soft Computing},
  pages        = {108934},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Instance-based transfer learning method via modified domain-adversarial neural network with influence function: Applications to design metamodeling and fault diagnosis},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interval prediction approach to crude oil price based on
three-way clustering and decomposition ensemble learning. <em>ASOC</em>,
<em>123</em>, 108933. (<a
href="https://doi.org/10.1016/j.asoc.2022.108933">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prediction methods have become a hot topic in intelligent decision making . Most of the existing prediction methods focus on the prediction accuracy and stability. As a second choice, accurate interval prediction can provide a relatively reliable reference in the sense of probability and provide help for assisting decision management. Therefore, we propose a novel interval prediction approach. Firstly, the decomposition method based on ensemble empirical mode decomposition (EEMD) is utilized to alleviate the complexity of the original time series, thereby generating a series of relatively smooth subseries. Secondly, a three-way clustering (TWC) algorithm is established by integrating sample entropy into probabilistic rough set, enriching the three-way clustering theory from the perspective of entropy. Thirdly, aiming at determining the optimal input dimensions of different neural networks , the feature selection technique based on phase space reconstruction (PSR) is constructed. Furthermore, an interval prediction system based on TWC is proposed to provide a new data-driven prediction method. Finally, the proposed approach is applied to predict the interval price of crude oil. On the one hand, the practicability of the constructed prediction approach is verified; on the other hand, it provides a new theoretical method for interval prediction of crude oil price. The experiment results show the proposed prediction approach can assist the decision-makers to make scientific and reasonable decisions.},
  archive      = {J_ASOC},
  author       = {Bingzhen Sun and Juncheng Bai and Xiaoli Chu and Shaolong Sun and Yongwu Li and Hongtao Li},
  doi          = {10.1016/j.asoc.2022.108933},
  journal      = {Applied Soft Computing},
  pages        = {108933},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Interval prediction approach to crude oil price based on three-way clustering and decomposition ensemble learning},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LC-net: Localized counting network for extremely dense
crowds. <em>ASOC</em>, <em>123</em>, 108930. (<a
href="https://doi.org/10.1016/j.asoc.2022.108930">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large mass gatherings such as pilgrimages, protests, etc., often pose serious challenges for the crowd management personnel to maintain public safety and security especially in dense crowds. These challenges can be mitigated through estimating the number of attendees as well as localizing them in a particular crowded event, where existing research studies are yet to provide accurate information in an efficient manner. Therefore, in this paper, we propose a novel deep learning architecture namely LC-Net to precisely and efficiently locate as well as count the attendees in dense crowds using a crowd localization map. Here, we exploit the notions of residual layers and dilated convolution to improve both the accuracy and efficiency of our architecture. Besides, we propose a new data augmentation technique to resize the high-resolution training images based on crowd density that substantially boosts our localization accuracy . Rigorous experimental evaluation of our proposed LC-Net over four different public crowd datasets such as NWPU-Crowd, UCF-QNRF, ShanghaiTech-A, and ShanghaiTech-B shows a substantial performance improvement while using LC-Net in terms of precision and recall in most of the cases. The improvement eventually results in an improved F1 score in all cases compared to the state-of-the-art approaches. Further, we present a real implementation of our proposed approach using a client–server application. In the server, we execute the LC-Net model over the images captured in real-time using an IP Camera and then visualize the results in a graphical manner. This implementation demonstrates the applicability of our proposed approach in real cases.},
  archive      = {J_ASOC},
  author       = {Tarik Reza Toha and Najla Abdulrahman Al-Nabhan and Saiful Islam Salim and Masfiqur Rahaman and Uday Kamal and A.B.M. Alim Al Islam},
  doi          = {10.1016/j.asoc.2022.108930},
  journal      = {Applied Soft Computing},
  pages        = {108930},
  shortjournal = {Appl. Soft. Comput.},
  title        = {LC-net: Localized counting network for extremely dense crowds},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Marker planning problem in the apparel industry: Hybrid
PSO-based heuristics. <em>ASOC</em>, <em>123</em>, 108928. (<a
href="https://doi.org/10.1016/j.asoc.2022.108928">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the apparel industry, fabric contributes to the high cost of raw materials, and thus an improvement in terms of a shorter used marker layout would improve the cost efficiency of this industry. The marker planning problem, also known as a 2D irregular cutting and packing problem in the apparel industry, focuses on optimizing the fabric resource by arranging a set of irregularly shaped clothing patterns on a sheet of fabric while preventing any overlap between the patterns, with the aim of finding the shortest length arrangement. Due to the irregular shapes of clothes, the solution time increases exponentially when more pieces are involved, making this problem become NP-hard or NP-complete. In this study, particle swarm optimization (PSO)-based heuristics were evaluated to address the above problem. The moving heuristic proposed by Tsao et al. (2020) acts as a placement strategy considering the order of the pattern and the degree of rotation. A pixel-based representation was used to handle the geometry of the pattern. PSO-based heuristics were developed by enhancing PSO performance with a local search, a genetic algorithm , and simulated annealing. Mixed-size order and a special case of the separated-size arrangement were also considered. The proposed algorithms were tested in an apparel company and compared with the well-known bottom-left fill heuristic approach to obtain competitive results with shorter fabric length and CPU time.},
  archive      = {J_ASOC},
  author       = {Yu-Chung Tsao and Magda Delicia and Thuy-Linh Vu},
  doi          = {10.1016/j.asoc.2022.108928},
  journal      = {Applied Soft Computing},
  pages        = {108928},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Marker planning problem in the apparel industry: Hybrid PSO-based heuristics},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Handling imbalanced data for aircraft predictive maintenance
using the BACHE algorithm. <em>ASOC</em>, <em>123</em>, 108924. (<a
href="https://doi.org/10.1016/j.asoc.2022.108924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing a prognostic model to predict an asset’s health condition is a maintenance strategy that increases asset availability and reliability through better maintenance scheduling. Therefore, developing reliable vehicle health predictive models is vital in the aerospace industry, especially considering a safety–critical system such as aircraft. However, one of the significant challenges faced in building reliable data-driven prognostic models is the imbalance dataset. Training machine-learning models using an imbalanced dataset causes classifiers to be biased towards the class with majority samples, resulting in poor predictive accuracy in data-driven models. This problem can become more challenging if the imbalance ratio is extreme and classes overlap. In this paper, a novel approach called Balanced Calibrated Hybrid Ensemble Technique (BACHE) is developed to tackle the severe imbalanced classification problem. The proposed method involves the combination of hybrid data sampling and ensemble-based learning. It uses a cascading balanced approach to transfer a class imbalance problem into a sub-problem by decomposing the original problem into a set of subproblems, each characterized by a reduced imbalance ratio . Then uses a calibrated boosting with a cost-sensitive decision tree to enhance recognition of hard-to-learn patterns, which improves the prediction of the extreme minority class. BACHE is evaluated using a real-world aircraft dataset with rare component replacement instances. Also, a comparative experiment of the proposed approach with other similar existing methods is conducted. The performance metrics used are precision, recall, G-mean, and an area under the curve. The final results show that the proposed model outperforms other similar methods. Also, it can attain an excellent performance on large, extremely imbalanced datasets.},
  archive      = {J_ASOC},
  author       = {Maren David Dangut and Zakwan Skaf and Ian K. Jennions},
  doi          = {10.1016/j.asoc.2022.108924},
  journal      = {Applied Soft Computing},
  pages        = {108924},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Handling imbalanced data for aircraft predictive maintenance using the BACHE algorithm},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spatial feature-based convolutional neural network for
PolSAR image classification. <em>ASOC</em>, <em>123</em>, 108922. (<a
href="https://doi.org/10.1016/j.asoc.2022.108922">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The deep learning algorithm has made great breakthroughs in optical image processing. Some deep learning algorithms require a large number of labeled samples for training. For PolSAR data sets, due to the influence of speckle noise and other factors, high-quality labeled data are limited. Therefore, it is meaningful to use deep learning algorithm to solve PolSAR classification problem in limited labeled dataset. This paper proposes a spatial feature-based convolutional neural network (SF-CNN). The network adopts a dual-branch CNN structure. Both of the two branches have the same structure and share parameters. SF-CNN can receive more than one sample as input. SF-CNN’s special structure can expand the original training set by combining different samples, and alleviate the problem of insufficient labeled training data in PolSAR image classification tasks. When training, SF-CNN maps high-dimensional PolSAR image to low-dimensional feature space. In low-dimensional feature space, SF-CNN enhances the ability of network to extract discriminative features by maximizing or minimizing the distance between feature centers of different classes. In order to dig up the relationship between the samples, the test sample features are compared with every training sample feature when testing. Finally, labels of test samples are determined by the comparison result. The result of SF-CNN in PolSAR image classification task is better than that of standard CNN.},
  archive      = {J_ASOC},
  author       = {Ronghua Shang and Jiaming Wang and Licheng Jiao and Xiaohui Yang and Yangyang Li},
  doi          = {10.1016/j.asoc.2022.108922},
  journal      = {Applied Soft Computing},
  pages        = {108922},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Spatial feature-based convolutional neural network for PolSAR image classification},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards a parameterless out-of-the-box population size
control for evolutionary and swarm-based algorithms for single objective
bound constrained real-parameter numerical optimization. <em>ASOC</em>,
<em>123</em>, 108920. (<a
href="https://doi.org/10.1016/j.asoc.2022.108920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an innovative step towards a parameterless out-of-the-box population size control for evolutionary and swarm-based algorithms for single objective bound constrained real-parameter numerical optimization . To the best of our knowledge, our approach is the first parameterless out-of-the-box parameter control for such a kind of technique. It is easy to implement and to use, since it does not require the adjustment of any parameter. The general idea is to increment the velocity of the population change if the best fitness stagnates, and decrement it otherwise. Then, in order to effectively change the population size, a mechanism of removal/addition of individuals inspired by the selection methods of evolutionary algorithms is executed. Our experimental results provide evidence that our controller is not only compatible with any evolutionary or swarm-based algorithm for single objective bound constrained real-parameter numerical optimization , but that it also performs well in many scenarios.},
  archive      = {J_ASOC},
  author       = {Marcelo Gomes Pereira de Lacerda and Hugo de Andrade Amorim Neto and Teresa Bernarda Ludermir and Herbert Kuchen and Fernando Buarque de Lima Neto},
  doi          = {10.1016/j.asoc.2022.108920},
  journal      = {Applied Soft Computing},
  pages        = {108920},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Towards a parameterless out-of-the-box population size control for evolutionary and swarm-based algorithms for single objective bound constrained real-parameter numerical optimization},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The combined social engineering particle swarm optimization
for real-world engineering problems: A case study of model-based
structural health monitoring. <em>ASOC</em>, <em>123</em>, 108919. (<a
href="https://doi.org/10.1016/j.asoc.2022.108919">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural health monitoring (SHM) is a substantial research direction in structural engineering being scrutinized in recent years due to its significance in ensuring structural safety and reliability. The SHM using evolutionary computation has gained wide significance thanks to its computational capability and robust performance. By bearing in mind the necessity of efficient search mechanisms, a new algorithm merging the recent social engineering optimizer (SEO) and the particle swarm algorithm (PSO) is proposed in this work. The new algorithm, called the social engineering particle swarm optimization algorithm (SEPSO), combines the PSO population-based elitist-solution mechanism and the SEO two-solution attacker–defender paradigm to establish an effective global–local algorithm for solving complex engineering optimization problems . The SEPSO is developed, benchmarked, and compared with some state-of-the art algorithms using available test functions in the literature. Furthermore, the SEPSO is applied on selected mechanical design problems from the CEC2020 real-world constraint optimization competition in addition to comparison with the best-performed algorithms for benchmarking purpose. The SEPSO algorithm exhibits outstanding results when solving the benchmark functions and the real-world constraint optimization problems . Moreover, aiming to solve the complex problem of the SHM inverse problem , the SEPSO is employed. The SHM framework is presented and applied on the American Society of Civil Engineering (ASCE) frame structure based on an efficient fusion of objective function formulation. Several damage cases are tested using partial and noise-contaminated data. The proposed approach shows notable detectability and severity evaluation regardless the modal data malfunctions. Meanwhile, the proposed SEPSO can serve as an effective global–local search algorithm for solving real-world engineering problems.},
  archive      = {J_ASOC},
  author       = {Nizar Faisal Alkayem and Maosen Cao and Lei Shen and Ronghua Fu and Dragoslav Šumarac},
  doi          = {10.1016/j.asoc.2022.108919},
  journal      = {Applied Soft Computing},
  pages        = {108919},
  shortjournal = {Appl. Soft. Comput.},
  title        = {The combined social engineering particle swarm optimization for real-world engineering problems: A case study of model-based structural health monitoring},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A cost-sensitive imprecise credal decision tree based on
nonparametric predictive inference. <em>ASOC</em>, <em>123</em>, 108916.
(<a href="https://doi.org/10.1016/j.asoc.2022.108916">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classifiers sometimes return a set of values of the class variable since there is not enough information to point to a single class value. These classifiers are known as imprecise classifiers. Decision Trees for Imprecise Classification were proposed and adapted to consider the error costs when classifying new instances. In this work, we present a new cost-sensitive Decision Tree for Imprecise Classification that considers the error costs by weighting instances, also considering such costs in the tree building process. Our proposed method uses the Nonparametric Predictive Inference Model, a nonparametric model that does not assume previous knowledge about the data, unlike previous imprecise probabilities models. We show that our proposal might give more informative predictions than the existing cost-sensitive Decision Tree for Imprecise Classification. Experimental results reveal that, in Imprecise Classification, our proposed cost-sensitive Decision Tree significantly outperforms the one proposed so far; even though the cost of erroneous classifications is higher with our proposal, it tends to provide more informative predictions.},
  archive      = {J_ASOC},
  author       = {Serafín Moral-García and Joaquín Abellán and Tahani Coolen-Maturi and Frank P.A. Coolen},
  doi          = {10.1016/j.asoc.2022.108916},
  journal      = {Applied Soft Computing},
  pages        = {108916},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A cost-sensitive imprecise credal decision tree based on nonparametric predictive inference},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Coalitional bayesian autoencoders: Towards explainable
unsupervised deep learning with applications to condition monitoring
under covariate shift. <em>ASOC</em>, <em>123</em>, 108912. (<a
href="https://doi.org/10.1016/j.asoc.2022.108912">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to improve the explainability of autoencoder (AE) predictions by proposing two novel explanation methods based on the mean and epistemic uncertainty of log-likelihood estimates, which naturally arise from the probabilistic formulation of the AE, the Bayesian autoencoder (BAE). These formulations contrast the conventional post-hoc explanation methods for AEs, which incur additional modelling effort and implementations. We further extend the methods for sensor-based explanations, aggregating the explanations at the sensor level instead of the lower feature level. To evaluate the performance of explanation methods quantitatively, we test them on condition monitoring applications. Due to the lack of a common assessment of explanation methods, especially under covariate shift , we propose three evaluation metrics : (1) the G-mean of Spearman drift coefficients, (2) the G-mean of sensitivity-specificity of explanation ranking and (3) a sensor explanation quality index ( S E Q I SEQI ) which combines the first two metrics, capturing the explanations’ abilities to measure the degree of monotonicity and to rank the sensors. Surprisingly, we observe that the explanations of BAE’s predictions suffer from high correlation resulting in misleading explanations. This new observation cautions against trusting these explanations without further understanding of when they may fail. To alleviate this, a “Coalitional BAE” is proposed, inspired by agent-based system theory. The Coalitional BAE models each sensor independently and eliminates the correlation in explanations. Our comprehensive experiments on publicly available condition monitoring datasets demonstrate significant improvements of the Coalitional BAEs over the baseline Centralised AEs on the proposed metrics, visualised through critical difference diagrams.},
  archive      = {J_ASOC},
  author       = {Bang Xiang Yong and Alexandra Brintrup},
  doi          = {10.1016/j.asoc.2022.108912},
  journal      = {Applied Soft Computing},
  pages        = {108912},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Coalitional bayesian autoencoders: Towards explainable unsupervised deep learning with applications to condition monitoring under covariate shift},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FL-sleep: Temperature adaptive multi-attribute
sleep-scheduling algorithm using hesitant fuzzy logic for wireless
sensor networks. <em>ASOC</em>, <em>123</em>, 108910. (<a
href="https://doi.org/10.1016/j.asoc.2022.108910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sustainable operation of sensor nodes in Wireless Sensor Network depends on the nodes’ adaptability with the environment. A sensor node strives to live longer using periodic sleep/awake activity. But it fails to achieve considerable success due to the node’s inability to make the sleep/awake strategy adaptive to the environment. To this end, we propose an algorithm, ‘ FL-Sleep’ which makes every node in the network to observe the ambient temperature and status of their parameters after every round of operation. Depending on their perception of the parameters, the nodes execute a sleep-scheduling strategy in the subsequent round. It makes the node evaluate its current state and decide the required action ( ’Active’, ‘Listen’ or ‘Sleep’ ) to perform. A node working in a favorable condition would decide the action with an optimistic attitude towards the parameters. In contrast, a critical condition of a node compels it to decide pessimistically. This qualitative measurement provides a precise understanding of the environment. ‘ FL-Sleep ’ works on hesitant fuzzy logic-based Multi-Criteria Decision Making method and is found to improve the network’s lifetime by 247.11\% compared to BMAC, by 68.56\% compared to SOPC, and by 77.2\% compared to RL-Sleep. The best lifetime of nodes is obtained when the network is organized in spiral topology. ‘ FL-Sleep ’ shows better performance in terms of packet-delivery-ratio , energy efficiency , and the number of active nodes in the network compared to BMAC, SOPC, and RL-Sleep.},
  archive      = {J_ASOC},
  author       = {Partha Sarathi Banerjee and SatyendraNath Mandal and Debashis De and Biswajit Maiti},
  doi          = {10.1016/j.asoc.2022.108910},
  journal      = {Applied Soft Computing},
  pages        = {108910},
  shortjournal = {Appl. Soft. Comput.},
  title        = {FL-sleep: Temperature adaptive multi-attribute sleep-scheduling algorithm using hesitant fuzzy logic for wireless sensor networks},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Chaining zscore and feature scaling methods to improve
neural networks for classification. <em>ASOC</em>, <em>123</em>, 108908.
(<a href="https://doi.org/10.1016/j.asoc.2022.108908">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks for classification aim at identifying the class label of new observation based training data containing instances whose category memberships are known. Therefore the data fed into neural networks has to be preprocessed to enhance its quality resulting in promoting the extraction of meaningful insights of data. However, the fact of processing data until you have the required high quality is challenging and time-consuming to manually search for the best method in a sequence of preprocessing independent methods. For feature scaling methods, they consist of scaling the dataset into the same range of data without monitoring data outliers that should eventually occur in the data source. Zscore for outlier’s detection suffers from the issue of predefining the parameters. This paper discussed various approaches that are applied to scale features and detect outliers during data pre-processing. Thereafter, the paper proposed the algorithm that combines Zscore as an outlier’s detection method with every classical feature scaling method in high-dimensional data. The proposed algorithm has benefits in selecting the optimal subset of methods from a sequence of chained methods, detecting outliers , and removing zero variance predictors. The study findings from five sample sizes revealed that the proposed method significantly excels the classical method in terms of accuracy. The outstanding from them was performed at the rate of 99.67\% and had a significant difference of 0.20\% over classical feature scaling.},
  archive      = {J_ASOC},
  author       = {Calpephore Nkikabahizi and Wilson Cheruiyot and Ann Kibe},
  doi          = {10.1016/j.asoc.2022.108908},
  journal      = {Applied Soft Computing},
  pages        = {108908},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Chaining zscore and feature scaling methods to improve neural networks for classification},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Safe intuitionistic fuzzy twin support vector machine for
semi-supervised learning. <em>ASOC</em>, <em>123</em>, 108906. (<a
href="https://doi.org/10.1016/j.asoc.2022.108906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning unlabeled samples without deteriorating performance is a challenge in semi-supervised learning. In this paper, we propose a safe intuitionistic fuzzy twin support vector machine (SIFTSVM) for semi-supervised learning. In our SIFTSVM, whether an unlabeled sample should be learned by a twin support vector machine is determined by its plane intuitionistic fuzzy number. The unlabeled samples are learned gradually according to the current decision environment, which is safer and more precise than learning all of the unlabeled samples simultaneously. Interestingly, the iterative algorithm of our SIFTSVM obtains a solution to a mixed integer programming problem whose global solution corresponds to a classifier by learning the unlabeled samples with implicit labels. Experimental results on several synthetic datasets confirm the safety of our SIFTSVM for learning unlabeled samples, and the results on 56 groups of benchmark datasets demonstrate that our SIFTSVM outperforms the state-of-the-art semi-supervised classifiers on most groups.},
  archive      = {J_ASOC},
  author       = {Lan Bai and Xu Chen and Zhen Wang and Yuan-Hai Shao},
  doi          = {10.1016/j.asoc.2022.108906},
  journal      = {Applied Soft Computing},
  pages        = {108906},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Safe intuitionistic fuzzy twin support vector machine for semi-supervised learning},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A variable-length encoding genetic algorithm for incremental
service composition in uncertain environments for cloud manufacturing.
<em>ASOC</em>, <em>123</em>, 108902. (<a
href="https://doi.org/10.1016/j.asoc.2022.108902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Service composition and optimal selection (SCOS) plays a crucial role in cloud manufacturing (CMfg). While the existing service composition methods are hard to address the changes and uncertainties of CMfg dynamic environment. Therefore, a variable-length encoding genetic algorithm for structure-varying incremental service composition (ISC-GA) is proposed in this paper. Specifically, a novel variable-length encoding scheme containing structural information is proposed to describe the uncertain and changing process model. And the improved crossover and mutation algorithm suitable for individuals with nonlinear varying structure and incremental service composition is designed. It is realized by optimizing both the process structure and service instance combinations, and overcomes the drawbacks resulted from single preset process structure. Due to the difficulty of fitness computation caused by uncertain process structures, novelty is introduced as a new evolutionary pressure, and a novel framework for ISC-GA is presented, which helps to find both novel and high-performance solutions. Experimental results indicate the effectiveness of the proposed approach.},
  archive      = {J_ASOC},
  author       = {Yanrong Jiang and Long Tang and Hailin Liu and An Zeng},
  doi          = {10.1016/j.asoc.2022.108902},
  journal      = {Applied Soft Computing},
  pages        = {108902},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A variable-length encoding genetic algorithm for incremental service composition in uncertain environments for cloud manufacturing},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Output-related fault detection in non-stationary processes
using constructive correlative-SAE and demoting correlative-DNN.
<em>ASOC</em>, <em>123</em>, 108898. (<a
href="https://doi.org/10.1016/j.asoc.2022.108898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault detection in non-stationary processes is a timely research topic in industrial systems. The conventional approaches based on principal component regression (PCR) and partial least-squares (PLS) cannot be loosely used for non-stationary and non-linear processes when the statistical behaviour of the measurements does not follow a Gaussian distribution with constant mean and standard deviation values. This paper introduces a new application of deep learning (DL), specifically a combination of proposed correlative stacked auto-encoder (C-SAE) and correlative deep neural networks (C-DNN) for output-related anomaly detection without complete decomposition of process variables with respect to quality output(s). With this aim, two new constructive and demoting loss functions are proposed to relatively decompose the process measurements with respect to their relevance to quality output variable(s). The loss functions are modified with the incorporation of non-linear correlation analysis and hence integrated into SAE and DNN structures to suggest a correlative SAE and DNN. The proposed C-SAE and C-DNN are integrated into a scheme with an inverted pyramid structure that enables output-related fault detection without limiting stationarity assumptions. Moreover, the proposed framework can be freely applied to both linear and non-linear processes. The performance of the proposed DL strategy is tested and validated on a non-stationary numerical example and Tennessee Eastman Process. The comparison results with recent approaches indicate the outperformance of the proposed approach for process output-related fault detection purposes.},
  archive      = {J_ASOC},
  author       = {Bahador Rashidi and Qing Zhao},
  doi          = {10.1016/j.asoc.2022.108898},
  journal      = {Applied Soft Computing},
  pages        = {108898},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Output-related fault detection in non-stationary processes using constructive correlative-SAE and demoting correlative-DNN},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiagent-based deep reinforcement learning for
risk-shifting portfolio management. <em>ASOC</em>, <em>123</em>, 108894.
(<a href="https://doi.org/10.1016/j.asoc.2022.108894">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing popularity of quantitative trading in pursuit of a systematic and algorithmic approach to investment has drawn considerable attention among traders and investment firms. Consequently, an effective computational method for evaluating potential risk factors and returns is crucial for the development of algorithmic trading strategies. In traditional finance and financial engineering research, statistical approaches have been widely applied to quantitative analysis . Meanwhile, investor demand for quantitative hedge funds has surged worldwide. In the current study, the multiperiod portfolio selection problem was considered in terms of the realistic transaction cost model, which is a major concern for quantitative hedge fund managers. We developed a dedicated multiagent-based deep reinforcement learning framework with a two-level nested agent structure to determine effective portfolio management methods with different objectives. In addition, we proposed a specially-designed reward function for investment performance evaluation and a novel policy network structure for trading decision-making. To efficiently identify specific asset attributes in a portfolio, each agent is equipped with a refined deep policy network and a special training method that enables the proposed reinforcement learning agent to learn risk transfer behaviors. The results revealed the effectiveness of our proposed framework, which outperformed several established or representative portfolio selection strategies.},
  archive      = {J_ASOC},
  author       = {Yu-Cen Lin and Chiao-Ting Chen and Chuan-Yun Sang and Szu-Hao Huang},
  doi          = {10.1016/j.asoc.2022.108894},
  journal      = {Applied Soft Computing},
  pages        = {108894},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multiagent-based deep reinforcement learning for risk-shifting portfolio management},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Attitude control for hypersonic reentry vehicles: An
efficient deep reinforcement learning method. <em>ASOC</em>,
<em>123</em>, 108865. (<a
href="https://doi.org/10.1016/j.asoc.2022.108865">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the attitude control problem of hypersonic reentry vehicles (HRVs), a deep reinforcement learning (DRL) based anti-disturbance control method is proposed. First, a compound control framework consisting of a DRL-based auxiliary controller and a fixed-time anti-disturbance controller is proposed to improve the control performance under the premise of ensuring stability. Then, a novel value function approximation mechanism, named experience-based value expansion (EVE), is proposed to modify the value function update equation based on a two-dimensional replay buffer, which solves the DRL convergence problem brought by the HRV’s strong nonlinearities , tight coupling, and big flight envelope. Furthermore, a result-oriented encoder (ROE) is proposed to solve the DRL generalization problem brought by the HRV’s high uncertainties and unavailable real training environment. A bottleneck shape neural network structure is used for the DRL’s network structure to extract high-dimensional features and prevent overfitting to the training environment. Finally, abundant numerical comparative simulations demonstrate the effectiveness of the proposed efficient DRL algorithms and the DRL-based attitude controller.},
  archive      = {J_ASOC},
  author       = {Yiheng Liu and Honglun Wang and Tiancai Wu and Yuebin Lun and Jiaxuan Fan and Jianfa Wu},
  doi          = {10.1016/j.asoc.2022.108865},
  journal      = {Applied Soft Computing},
  pages        = {108865},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Attitude control for hypersonic reentry vehicles: An efficient deep reinforcement learning method},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interval type-2 generalized fuzzy hyperbolic modelling and
control of nonlinear systems. <em>ASOC</em>, <em>123</em>, 108859. (<a
href="https://doi.org/10.1016/j.asoc.2022.108859">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalized Fuzzy Hyperbolic Models (GFHMs) offer a simpler structure and less computational complexity than the typical fuzzy systems. Type-2 fuzzy systems, in contrast, have better handling of uncertainty but at the cost of higher computational complexity. Here, we propose a synergistic hybrid framework of interval type-2 fuzzy systems and GFHMs for a better uncertainty handling and simpler computational structure in the modelling and control of nonlinear systems . For this purpose, we first extend the GFHM to a computational model with various width and subsequently propose interval type-2 generalized fuzzy hyperbolic systems (IT2-GFHS) as a computational framework for nonlinear systems modelling. We then employ this IT2-GFHS in a general sliding-based robust nonlinear controller. Theoretical Lyapunov analysis reveals the overall asymptotic stability of the resulting closed-loop system. The numerical simulations for system modelling and identification on two nonlinear benchmark problems also reveal higher accuracy, lower computation time, and fewer adjustable parameters for the proposed IT2-GFHS models. Furthermore, applications to two nonlinear benchmark control problems show similar performance in terms of robustness to noise and disturbances compared with type-2 fuzzy systems, with the IT2-GFHS-based nonlinear controller having considerably fewer computations and floating-point operations. Finally, the proposed approach is experimentally implemented to control a 3-Prismatic-Series-Prismatic (3-PSP) parallel robot . Experimental results also confirm the improved tracking performance of the proposed method compared with interval type-2 and type-1 fuzzy systems, while also requiring fewer adjustable parameters.},
  archive      = {J_ASOC},
  author       = {S. Mohammad Tahamipour-Z. and Mohammad-R. Akbarzadeh-T. and Fahimeh Baghbani},
  doi          = {10.1016/j.asoc.2022.108859},
  journal      = {Applied Soft Computing},
  pages        = {108859},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Interval type-2 generalized fuzzy hyperbolic modelling and control of nonlinear systems},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep instance envelope network-based imbalance learning
algorithm with multilayer fuzzy c-means clustering and minimum
interlayer discrepancy. <em>ASOC</em>, <em>123</em>, 108846. (<a
href="https://doi.org/10.1016/j.asoc.2022.108846">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced learning is important and challenging since the problem of the classification of imbalanced datasets is prevalent in machine learning and data mining fields. Sampling approaches are proposed to address this issue, and cluster-based oversampling methods have shown great potential as they aim to simultaneously tackle between-class and within-class imbalance issues. However, all existing clustering methods are based on a one-time approach. Due to the lack of a priori knowledge , improper setting of the number of clusters often exists, which leads to poor clustering performance. Besides, the existing methods are likely to generate noisy instances. To solve these problems, this paper proposes a deep instance envelope network-based imbalanced learning algorithm with the multilayer fuzzy c-means (MlFCM) and a minimum interlayer discrepancy mechanism based on the maximum mean discrepancy (MIDMD). This algorithm can guarantee high quality balanced instances using a deep instance envelope network in the absence of prior knowledge. First, the MlFCM is designed for the original minority class instances to obtain deep instances and increase the diversity of instances. Then, the MIDMD is proposed to avoid the generation of noisy instances and maintain the consistency of the interlayers of instances. Next, the multilayer FCM and minimum interlayer discrepancy mechanism are combined to construct a deep instance envelope network – the MlFC&amp;IDMD. Finally, an imbalance learning algorithm is proposed based on the MlFC&amp;IDMD. In the experimental section, thirty-three popular public datasets are used for verification, and over ten representative algorithms are used for comparison. The experimental results show that the proposed approach significantly outperforms other popular methods.},
  archive      = {J_ASOC},
  author       = {Fan Li and Xiaoheng Zhang and Pin Wang and Yongming Li},
  doi          = {10.1016/j.asoc.2022.108846},
  journal      = {Applied Soft Computing},
  pages        = {108846},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Deep instance envelope network-based imbalance learning algorithm with multilayer fuzzy C-means clustering and minimum interlayer discrepancy},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intelligent monitoring for infectious diseases with fuzzy
systems and edge computing: A survey. <em>ASOC</em>, <em>123</em>,
108835. (<a href="https://doi.org/10.1016/j.asoc.2022.108835">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infectious diseases usually have the characteristics of rapid spread with a large impact range. Once they break out, they will cause a large area of infection, which creates tremendous health and security risks. Thus, early infectious disease monitoring and prevention are critical. Current surveillance systems can predict the incidence of infectious diseases to a certain extent. However, the diversity, inaccuracy and incompleteness of the data collected by sensors make it difficult to obtain accurate monitoring results. Moreover, the limited local resources of a monitoring system cannot process the increasing volume of data in a timely manner. To address these challenges, fuzzy logic and edge computing have been applied to infectious disease monitoring in recent years. This paper presents a comprehensive review of infectious disease monitoring technologies based on fuzzy logic and edge computing . Fuzzy neural networks in infectious disease surveillance are introduced in detail, followed by a brief study of applications of fuzzy systems in infectious disease surveillance. Finally, improvements in existing disease detection systems based on the combination of edge computing and fuzzy logic are described. The review shows that edge computing and fuzzy logic are complementary and that their combination greatly improves the processing efficiency and the storage space of the data. At the same time, with edge computing as the carrier, the combination of fuzzy logic, neural networks , expert systems and other technologies can effectively carry out disease prediction and diagnosis.},
  archive      = {J_ASOC},
  author       = {Qinting Jiang and Xuanhong Zhou and Ruili Wang and Weiping Ding and Yi Chu and Sizhe Tang and Xiaoyun Jia and Xiaolong Xu},
  doi          = {10.1016/j.asoc.2022.108835},
  journal      = {Applied Soft Computing},
  pages        = {108835},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Intelligent monitoring for infectious diseases with fuzzy systems and edge computing: A survey},
  volume       = {123},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). 3D human pose estimation with cross-modality training and
multi-scale local refinement. <em>ASOC</em>, <em>122</em>, 108950. (<a
href="https://doi.org/10.1016/j.asoc.2022.108950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to study two major research problems for 3D human pose estimation using depth data. First we seek an effective way for applying the RGB pre-trained 2D CNN model to 3D pose field, so as to transfer large-scale RGB annotation information to depth domain. In particular, we proposed a cross-modality CNN training strategy, where the key idea is to set a partial Batch Normalization (BN) layer within the RGB pre-trained 2D CNN model to weaken the distribution divergence between the RGB and depth data during training. To involve richer 3D descriptive cues, the raw depth data is appended with the normal vector map. Albeit coarse-to-fine human pose estimation with local refinement is helpful to enhance performance. While the way for setting the optimal local observation scale is not well addressed. Towards this crucial problem, we propose to fuse the multi-scale local information jointly. A multi-scale local refinement network is proposed accordingly, where the small local region focuses on capturing the fine information. On the other hand, the large local region contains richer semantic contextual information. The experiments on two 3D human pose estimation datasets with depth data verify the effectiveness and real-time running capacity of our proposition.},
  archive      = {J_ASOC},
  author       = {Boshen Zhang and Yang Xiao and Fu Xiong and Cunlin Wu and Zhiguo Cao and Ping Liu and Joey Tianyi Zhou},
  doi          = {10.1016/j.asoc.2022.108950},
  journal      = {Applied Soft Computing},
  pages        = {108950},
  shortjournal = {Appl. Soft. Comput.},
  title        = {3D human pose estimation with cross-modality training and multi-scale local refinement},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-level features fusion network-based feature learning
for machinery fault diagnosis. <em>ASOC</em>, <em>122</em>, 108900. (<a
href="https://doi.org/10.1016/j.asoc.2022.108900">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bearings are one of the most critical components in rotating machinery . Since the failures of bearings will cause unexpected machine damages, it is significant to timely and accurately recognize the defects in bearings. However, due to the nonlinear and nonstationary property of vibration signals , it is still a challenging problem to implement feature extraction and fault diagnosis based on vibration signals As a representative deep neural network (DNN), convolutional neural network (CNN) has been widely used for feature learning of vibration signals for machinery fault diagnosis. Due to the hierarchical structure of CNN, multi-level features will be generated by the layer-by-layer convolutional calculation in the deep network. Thus, it is interesting to select the layer-by-layer features in a concatenation layer for multi-level features fusion . In this paper, a novel CNN, multi-level features fusion network (MLFNet) is proposed for feature learning of vibration signals. Firstly, a multi-scale convolution is developed in MLFNet, where multi-branches with different kernel sizes are utilized to extract fault-related features. Secondly, the features at different layers are coupled by a concatenation layer to preserve discriminate information. Thirdly, an adaptive weighted selection based on dynamic feature selection is proposed for multi-level feature fusion. The effectiveness of MLFNet for machinery fault diagnosis is verified on two bearing test-beds. The experimental results demonstrate that MLFNet has good performance of feature extraction on vibration signals. MLFNet obtained the recognition accuracy of 99.75\% for case 1 (single condition) and case 2 (varying condition). It has a better performance on bearing fault diagnosis in comparison with these typical DNNs and the state-of-art methods.},
  archive      = {J_ASOC},
  author       = {Zhuang Ye and Jianbo Yu},
  doi          = {10.1016/j.asoc.2022.108900},
  journal      = {Applied Soft Computing},
  pages        = {108900},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-level features fusion network-based feature learning for machinery fault diagnosis},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interval type-2 outlier-robust picture fuzzy clustering and
its application in medical image segmentation. <em>ASOC</em>,
<em>122</em>, 108891. (<a
href="https://doi.org/10.1016/j.asoc.2022.108891">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on picture fuzzy set theory , picture fuzzy clustering has achieved good results on some data as more information is involved in the clustering process . However, current picture fuzzy clustering methods still suffer from two common weaknesses, i.e., the sensitivity to outliers and the neglect of the uncertainty caused by different fuzzy degrees, which influence their performance in practical applications like medical image segmentation . To solve these issues, we present two new picture fuzzy clustering methods in this paper. First, to improve immunity to outliers, we propose an outlier-robust picture fuzzy clustering method named ORPFC by using a robust distance measurement, which treats the data objects far away from cluster prototypes as outliers and limits their effects on the prototype update. Second, to handle the uncertainty caused by fuzzy degrees, we further present an interval type-2 enhanced method called IT2ORPFC by incorporating the interval type-2 fuzzy set theory into ORPFC. In each iteration, IT2ORPFC estimates positive memberships, neutral memberships, and refusal memberships according to different fuzzification coefficients and then conducts type reduction for reliable type-1 clustering results . In the experiments, the proposed methods obtain robust and reliable results on eleven datasets. Specifically, ORPFC and IT2ORPFC achieve rewarding performance on segmenting medical images with noise.},
  archive      = {J_ASOC},
  author       = {Yingxu Wang and Long Chen and Jin Zhou and Tianjun Li and C.L. Philip Chen},
  doi          = {10.1016/j.asoc.2022.108891},
  journal      = {Applied Soft Computing},
  pages        = {108891},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Interval type-2 outlier-robust picture fuzzy clustering and its application in medical image segmentation},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Objectivity meets subjectivity: A subjective and objective
feature fused neural network for emotion recognition. <em>ASOC</em>,
<em>122</em>, 108889. (<a
href="https://doi.org/10.1016/j.asoc.2022.108889">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using multimodal fusion method to deal with emotion recognition task has become a trend. The fusion vector can more comprehensively reflect the subject’s emotional change state, so as to obtain a more accurate emotion recognition effect. However, different fusion input or feature fusion methods have different effects on the final fusion results. In this paper, we propose a subjective and objective feature fused neural network model (SOFNN) for emotion recognition, which can effectively learn spatial–temporal information from EEG signals and dynamically integrate EEG signals with eye movement signals. Specifically, we extract more abundant spatial and temporal information from the original EEG signal through a series of 1-D convolution kernels of different sizes and we verify the effectiveness of the extracted features through experiments. The size of the 1-D convolution kernels is determined by the characteristics (such as sampling rate and number of channels) of the original EEG signal. Then, we design a subjective and objective feature fusion framework to adjust the proportion of the two features through the dynamic learning of the weight vector , so as to fully exploit their respective advantages. We evaluate the performance of our model on the SEED-IV dataset, which is a common dataset. For the recognition task of four emotions (happy, sad, fear and neutral), our model achieves 86.27\% accuracy and 10.16\% standard deviation, which are better than the existing methods. In addition, we design a variety of ablation experiments to verify the effectiveness of each module in our model. The experiment results show that our model can make better use of the complementary relationship between subjective and objective features, which can achieve better emotion recognition effect.},
  archive      = {J_ASOC},
  author       = {Sijin Zhou and Dongmin Huang and Cheng Liu and Dazhi Jiang},
  doi          = {10.1016/j.asoc.2022.108889},
  journal      = {Applied Soft Computing},
  pages        = {108889},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Objectivity meets subjectivity: A subjective and objective feature fused neural network for emotion recognition},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automated diatom detection in forensic drowning diagnosis
using a single shot multibox detector with plump receptive field.
<em>ASOC</em>, <em>122</em>, 108885. (<a
href="https://doi.org/10.1016/j.asoc.2022.108885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detected result of diatoms is an important indicator in forensic drowning examination, and most of the current deep learning methods have achieved greater success in detecting diatoms with simple or no backgrounds. However, diatom images captured by the high-definition electron scanning microscopy in modern forensic science contain complex backgrounds and hamper the accurate diatom detection, resulting in the omission detection of the small and marginal diatoms in multi-diatom scenario. In this paper, we proposed a Hybrid-Dilated-Convolution-incorporated Single Shot Multibox Detector (HDC-SSD) to address this problem. By adopting the merit of the plump receptive field of HDC, the proposed algorithm not only improves the detection rate but also enhances the detection ability of the small objects and the marginal objects. The proposed method was validated by using our self-established dataset. Compared with SSD, the HDC-SSD reduces the undetected rate by approximately 48.6\% and almost keeps as fast as the SSD. More importantly, compared with some current state-of-the-art methods, the HDC-SSD obtains the highest Recall value at 0.9302.},
  archive      = {J_ASOC},
  author       = {Guosheng Gu and Shaowei Gan and Jiehang Deng and Yukun Du and Zhaowen Qiu and Jingjian Liu and Chao Liu and Jian Zhao},
  doi          = {10.1016/j.asoc.2022.108885},
  journal      = {Applied Soft Computing},
  pages        = {108885},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Automated diatom detection in forensic drowning diagnosis using a single shot multibox detector with plump receptive field},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A deep fuzzy model for diagnosis of COVID-19 from CT images.
<em>ASOC</em>, <em>122</em>, 108883. (<a
href="https://doi.org/10.1016/j.asoc.2022.108883">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From early 2020, a novel coronavirus disease pneumonia has shown a global “pandemic” trend at an extremely fast speed. Due to the magnitude of its harm, it has become a major global public health event. In the face of dramatic increase in the number of patients with COVID-19, the need for quick diagnosis of suspected cases has become particularly critical. Therefore, this paper constructs a fuzzy classifier, which aims to detect infected subjects by observing and analyzing the CT images of suspected patients. Firstly, a deep learning algorithm is used to extract the low-level features of CT images in the COVID-CT dataset. Subsequently, we analyze the extracted feature information with attribute reduction algorithm to obtain features with high recognition. Then, some key features are selected as the input for the fuzzy diagnosis model to the training model. Finally, several images in the dataset are used as the test set to test the trained fuzzy classifier. The obtained accuracy rate is 94.2\%, and the F1-score is 93.8\%. Experimental results show that, compared with the deep learning diagnosis methods widely used in medical image analysis, the proposed fuzzy model improves the accuracy and efficiency of diagnosis, which consequently helps to curb the spread of COVID-19.},
  archive      = {J_ASOC},
  author       = {Liping Song and Xinyu Liu and Shuqi Chen and Shuai Liu and Xiangbin Liu and Khan Muhammad and Siddhartha Bhattacharyya},
  doi          = {10.1016/j.asoc.2022.108883},
  journal      = {Applied Soft Computing},
  pages        = {108883},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A deep fuzzy model for diagnosis of COVID-19 from CT images},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Integrated framework for estimating remaining useful
lifetime through a deep neural network. <em>ASOC</em>, <em>122</em>,
108879. (<a href="https://doi.org/10.1016/j.asoc.2022.108879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an integrated framework for a deep neural network to estimate the remaining useful life (RUL) to ensure the reliability and safety of complex mechanical systems and enable proactive maintenance for intelligent operation. This data-driven method can predict complex and highly nonlinear degradation characteristics that are difficult to predict using physics-based prognostics and health management. In particular, this study focused on feature preprocessing and hyperparameter optimization, whereas previous studies had focused on the neural network architecture to improve prediction accuracy and robustness. The proposed integrated framework comprises four phases: feature preprocessing, feature reasoning using a deep neural network , hyperparameter optimization using a genetic algorithm , and RUL estimation. In the first phase, sensor measurements sensitive to degradation are selected and separated into primary and dynamic degradation trends. In addition, step differential values are extracted to account for multiple operational modes using an unsupervised clustering method . In the second phase, feature reasoning is performed using a deep neural network to characterize hidden complex and highly nonlinear degradation features. The health indicators manipulated in the first phase are trained using the proposed deep neural network. In the third phase, a genetic algorithm is introduced to optimize the hyperparameters used in feature preprocessing and reasoning. The final phase estimates the RUL using the proposed deep neural network with optimized hyperparameters. The proposed method was validated on the C-MAPSS dataset. The results show that the proposed integrated framework outperformed other state-of-the-art machine learning and deep learning methods under different operational conditions, suggesting that efficient feature preprocessing and hyperparameter optimization significantly improve the prediction accuracy and robustness of RUL for data-driven prognostics and health management.},
  archive      = {J_ASOC},
  author       = {Seho Son and Ki-Yong Oh},
  doi          = {10.1016/j.asoc.2022.108879},
  journal      = {Applied Soft Computing},
  pages        = {108879},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Integrated framework for estimating remaining useful lifetime through a deep neural network},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Short-term electrical load forecasting through heuristic
configuration of regularized deep neural network. <em>ASOC</em>,
<em>122</em>, 108877. (<a
href="https://doi.org/10.1016/j.asoc.2022.108877">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An accurate electrical load forecasting is essential for optimal grid operation. The paper presents a methodology for the short-term commercial building electrical load forecasting through a regularized deep neural network : Long Short-Term Memory Recurrent Neural Network (LSTM-RNN). Detailed heuristic analysis regarding relevant input feature selection, the volume of training data, hyperparameter tuning and regularizer selection of an optimal LSTM-RNN network configuration is presented. The regularized LSTM-RNN is used to forecast 30-min and 24-h ahead electrical loads of two commercial buildings in Virginia, USA. The forecast is performed for one week each over four different months in 2019: January, April, July and October to represent four different seasons in North America. The performance of electrical load forecasts has been compared against actual smart meter data from the electric utility of these buildings. For the case study presented, Mean Absolute Percentage Error (MAPE\%) with the regularized LSTM-RNN is 4.9\%, compared to 6.4\%, 9.2\% and 13.3\% with Shallow-ANN (Artificial Neural Network), Support Vector Regression (SVR) and Linear Regression (LR) respectively for 30-min ahead electrical load forecast. For 24-h ahead electrical load forecast, MAPE (\%) is 11.6\%, compared to 12.7\%, 13.4\% and 14.3\% with shallow-ANN, SVR and LR respectively. The methodology to configure a deep neural network (LSTM-RNN) for electrical load forecasting presented in this paper can be utilized for optimal forecasting performance.},
  archive      = {J_ASOC},
  author       = {Ashraful Haque and Saifur Rahman},
  doi          = {10.1016/j.asoc.2022.108877},
  journal      = {Applied Soft Computing},
  pages        = {108877},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Short-term electrical load forecasting through heuristic configuration of regularized deep neural network},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interval forecasting for urban water demand using PSO
optimized KDE distribution and LSTM neural networks. <em>ASOC</em>,
<em>122</em>, 108875. (<a
href="https://doi.org/10.1016/j.asoc.2022.108875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current literature on water demand forecasting mostly focuses on giving accurate point predictions of water demand. However, the water demand point forecasting will encounter uninformative and unreliable problems when the uncertainty level of data increases. To solve the above problem, a hybrid model (KDE-PSO-LSTM), which combines long short-term memory networks (LSTM) to kernel density estimation (KDE) optimized by using the particle swarm optimization (PSO) algorithm, is proposed to acquire the water demand prediction interval (PI) to quantify the likely uncertainties in the predictions. At first, the prediction errors are obtained by the difference between the real values of water demand and the predictive values based on the LSTM model. Then, a novel splitting strategy is proposed to divided point predictions into different levels to deal with the problem that it is difficult to fit the prediction errors of the whole water demand using a single probability density function (PDF). Next, the PSO is used to optimize the hyper-parameter of the KDE method for fitting the PDF curves of different levels prediction errors. Moreover, due to the irregular distribution of prediction errors, a search method called confidence-window shifting is presented to determine the optimal prediction error interval from the fitted PDF curves. After that, the upper bounds and the lower bounds of the best intervals of prediction errors are added to the point predictions to attain the final PI of urban water demand. Finally, to demonstrate the superiorities of the proposed model, the proposed KDE-PSO distribution is compared to other well-known distributions, i.e , the KDE distribution, the Beta-PSO distribution and the normal distribution. The experimental results show that the comprehensive performances of the PIs generated from the proposed KDE-PSO-LSTM model are better than that of KDE-PSO-BP, KDE-PSO-RNN, ND-LSTM, KDE-LSTM, Beta-PSO-LSTM and KDE-GA-LSTM. Therefore, it can be demonstrated that the KDE-PSO-LSTM model can provide reliable decision support to policy-makers for making the optimal water supplying management.},
  archive      = {J_ASOC},
  author       = {Baigang Du and Shuo Huang and Jun Guo and Hongtao Tang and Lei Wang and Shengwen Zhou},
  doi          = {10.1016/j.asoc.2022.108875},
  journal      = {Applied Soft Computing},
  pages        = {108875},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Interval forecasting for urban water demand using PSO optimized KDE distribution and LSTM neural networks},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A swarm intelligence-based robotic search algorithm
integrated with game theory. <em>ASOC</em>, <em>122</em>, 108873. (<a
href="https://doi.org/10.1016/j.asoc.2022.108873">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel decentralize and asynchronous swarm robotic search algorithm integrated with game theory to better disperse robots in the environment while crossing obstacles and solving mazes. This prevents early convergence and improves the efficiency of the searches. In the proposed algorithm, individual robots, while searching, play a sequential game at each iteration, and based on that, choose their velocity update rule. The effectiveness of the proposed strategic game is tested in a specially designed framework. As a validation, the introduced algorithm is compared with the state-of-the-art in simple and complex search environments. The results showed that the suggested algorithm outperforms other methods both in search duration and attained path length to the target, and its success rate is equal to the one of state-of-the-art (i.e., 100\% in the conducted experiments). Also, it is shown that the proposed strategic game works well in search environments with different levels of complexity and especially improves search efficiency further in complex environments.},
  archive      = {J_ASOC},
  author       = {Khalil Al-Rahman Youssefi and Modjtaba Rouhani and Habib Rajabi Mashhadi and Wilfried Elmenreich},
  doi          = {10.1016/j.asoc.2022.108873},
  journal      = {Applied Soft Computing},
  pages        = {108873},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A swarm intelligence-based robotic search algorithm integrated with game theory},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Electric demand forecasting with neural networks and
symbolic time series representations. <em>ASOC</em>, <em>122</em>,
108871. (<a href="https://doi.org/10.1016/j.asoc.2022.108871">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the electric demand prediction problem using neural networks and symbolization techniques. Symbolization techniques provide a time series symbolic representation of a lower length than the original time series. In our methodology, we incorporate the use of encoding from ordinal regression, preserving the notation of order between the symbols and make extensive experimentation with different neural network architectures and symbolization techniques. In our experimentation, we used the total electric demand data in the Spanish peninsula electric network, taken from 2009 to 2019 with a granularity of 10 min. The best model found making use of the symbolization methodology offered us slightly worse quality metrics (1.3655 RMSE and 0.0390 MAPE instead of the 1.2889 RMSE and 0.0363 MAPE from the best numerical model) but it was trained 6826 times faster.},
  archive      = {J_ASOC},
  author       = {D. Criado-Ramón and L.G.B. Ruiz and M.C. Pegalajar},
  doi          = {10.1016/j.asoc.2022.108871},
  journal      = {Applied Soft Computing},
  pages        = {108871},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Electric demand forecasting with neural networks and symbolic time series representations},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A fuzzy-based medical system for pattern mining in a
distributed environment: Application to diagnostic and co-morbidity.
<em>ASOC</em>, <em>122</em>, 108870. (<a
href="https://doi.org/10.1016/j.asoc.2022.108870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we have addressed the extraction of hidden knowledge from medical records using data mining techniques such as association rules in conjunction with fuzzy logic in a distributed environment. A significant challenge in this domain is that although there are a lot of studies devoted to analysing health data, very few focus on the understanding and interpretability of the data and the hidden patterns present within the data. A major challenge in this area is that many health data analysis studies have focussed on classification, prediction or knowledge extraction and end users find little interpretability or understanding of the results. This is due to the use of black-box algorithms or because the nature of the data is not represented correctly. This is why it is necessary to focus the analysis not only on knowledge extraction but also on the transformation and processing of the data to improve the modelling of the nature of the data. Techniques such as association rule mining and fuzzy logic help to improve the interpretability of the data and treat it with the inherent uncertainty of real-world data. To this end, we propose a system that automatically: a) pre-processes the database by transforming and adapting the data for the data mining process and enriching the data to generate more interesting patterns, b) performs the fuzzification of the medical database to represent and analyse real-world medical data with its inherent uncertainty, c) discovers interrelations and patterns amongst different features (diagnostic, hospital discharge, etc.), and d) visualizes the obtained results efficiently to facilitate the analysis and improve the interpretability of the information extracted. Our proposed system yields a significant increase in the compression and interpretability of medical data for end-users, allowing them to analyse the data correctly and make the right decisions. We present one practical case using two health-related datasets to demonstrate the feasibility of our proposal for real data.},
  archive      = {J_ASOC},
  author       = {Carlos Fernandez-Basso and Karel Gutiérrez-Batista and Roberto Morcillo-Jiménez and Maria-Amparo Vila and Maria J. Martin-Bautista},
  doi          = {10.1016/j.asoc.2022.108870},
  journal      = {Applied Soft Computing},
  pages        = {108870},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A fuzzy-based medical system for pattern mining in a distributed environment: Application to diagnostic and co-morbidity},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). COVID-19 prognosis using limited chest x-ray images.
<em>ASOC</em>, <em>122</em>, 108867. (<a
href="https://doi.org/10.1016/j.asoc.2022.108867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COrona VIrus Disease 2019 (COVID-19) pandemic is an ongoing global pandemic that has claimed millions of lives till date. Detecting COVID-19 and isolating affected patients at an early stage is crucial to contain its rapid spread. Although accurate, the primary viral test ‘Reverse Transcription Polymerase Chain Reaction’ (RT-PCR) for COVID-19 diagnosis has an elaborate test kit, and the turnaround time is high. This has motivated the research community to develop CXR based automated COVID-19 diagnostic methodologies. However, COVID-19 being a novel disease, there is no annotated large-scale CXR dataset for this particular disease. To address the issue of limited data, we propose to exploit a large-scale CXR dataset collected in the pre-COVID era and train a deep neural network in a self-supervised fashion to extract CXR specific features. Further, we compute attention maps between the global and the local features of the backbone convolutional network while finetuning using a limited COVID-19 CXR dataset. We empirically demonstrate the effectiveness of the proposed method. We provide a thorough ablation study to understand the effect of each proposed component. Finally, we provide visualizations highlighting the critical patches instrumental to the predictive decision made by our model. These saliency maps are not only a stepping stone towards explainable AI but also aids radiologists in localizing the infected area.},
  archive      = {J_ASOC},
  author       = {Arnab Kumar Mondal},
  doi          = {10.1016/j.asoc.2022.108867},
  journal      = {Applied Soft Computing},
  pages        = {108867},
  shortjournal = {Appl. Soft. Comput.},
  title        = {COVID-19 prognosis using limited chest X-ray images},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Depress-DCNF: A deep convolutional neuro-fuzzy model for
detection of depression episodes using IoMT. <em>ASOC</em>,
<em>122</em>, 108863. (<a
href="https://doi.org/10.1016/j.asoc.2022.108863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discernible patterns of a person’s daily activities can be utilized to detect behavioral symptomatology of mental illness at early stages. Wearable Internet of Medical Things (IoMT) devices with sensors that collect motion data and provide objective measures of physical activity can help to better monitor and detect potential episodes related to the mental health conditions at earlier, more treatable stages. This research puts forward a neuro-symbolic model which uses learnable parameters with integrated knowledge for detection of depression episodes using IoMT based actigraphic input. A novel deep fuzzy model, Depress-DCNF is a hybrid of convolutional neural network (CNN) and an adaptive neuro fuzzy inference system (ANFIS) where CNN is used to extract high-level features from the motor activity recordings which are eventually combined with the discriminative statistical features to produce an optimized feature map. This optimized feature map is finally used to train the ANFIS model which accurately performs the depression classification task . The model is validated on the Depresjon benchmark dataset and compares favorably to state-of-the-art approach giving a superior performance accuracy of 85.10\%.},
  archive      = {J_ASOC},
  author       = {Akshi Kumar and Saurabh Raj Sangwan and Anshika Arora and Varun G. Menon},
  doi          = {10.1016/j.asoc.2022.108863},
  journal      = {Applied Soft Computing},
  pages        = {108863},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Depress-DCNF: A deep convolutional neuro-fuzzy model for detection of depression episodes using IoMT},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multilayer extreme learning machines and their modeling
performance on dynamical systems. <em>ASOC</em>, <em>122</em>, 108861.
(<a href="https://doi.org/10.1016/j.asoc.2022.108861">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, two novel Multilayer Extreme Learning Machine (ML-ELM) networks are presented. We call them Improved Multilayer Extreme Learning Machines (IML-ELM). The proposed network architectures use neuron activations both during and after the training. In the first IML-ELM (IML-ELM1) network, each layer has connection weights assigned randomly as orthonormal. On the other hand, the second IML-ELM (IML-ELM2) has connection weights assigned randomly as orthonormal only in the first layer. Its following layers’ connection weights are taken from the previous layer’s output weight matrix. This assignment strategy made in the IML-ELM2 decreases the computation time even more. The networks’ modeling performances on seven benchmark dynamic systems are investigated and it is shown that the proposed IML-ELM1 and IML-ELM2 perform better modeling than the ML-ELM. They have better modeling performance of more than 70\% for both training and test data sets compared to ML-ELM for some systems studied. For instance, using 100 nodes, ML-ELM, IML-ELM1 and IML-ELM2 gave average testing root mean square error results of 0.627977, 0.104272 (83\%) and 0.092683 (85\%) respectively for BDS 7. In addition, it has been experimentally determined that the developed networks provide improvements in terms of average training time, and this improvement exceeds 60\% in some cases. These achievements clearly prove that the proposed improved multilayer extreme learning machines are efficient tools for system modeling applications.},
  archive      = {J_ASOC},
  author       = {Gizem Atac Kale and Cihan Karakuzu},
  doi          = {10.1016/j.asoc.2022.108861},
  journal      = {Applied Soft Computing},
  pages        = {108861},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multilayer extreme learning machines and their modeling performance on dynamical systems},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evolving interpretable strategies for zero-sum games.
<em>ASOC</em>, <em>122</em>, 108860. (<a
href="https://doi.org/10.1016/j.asoc.2022.108860">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present paper introduces Gesy, a genetic programming approach to script synthesis for zero-sum games. We will explore the sum-zero game context in Real-Time Strategy (RTS) games, where players must look for strategies (planning of actions) to maximize their gains or minimize their losses. The goal is to solve the script synthesis problem , which demands the synthesis of a computer program from a space of programs defined by a Domain-Specific Language (DSL). The synthesized program must encode a practical strategy for zero-sum games. Empirical results validate Gesy using the μ μ RTS platform, an academic test bed game that presents the main features found in RTS commercial games. The results show that our method provides interpretable strategies that are competitive with state-of-the-art search-based approaches in terms of play strength. Moreover, once synthesized, scripts require only a tiny fraction of the time needed by search-based methods to decide on the agent’s next action.},
  archive      = {J_ASOC},
  author       = {Julian R.H. Mariño and Claudio F.M. Toledo},
  doi          = {10.1016/j.asoc.2022.108860},
  journal      = {Applied Soft Computing},
  pages        = {108860},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Evolving interpretable strategies for zero-sum games},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deterministic sampling classifier with weighted bagging for
drifted imbalanced data stream classification. <em>ASOC</em>,
<em>122</em>, 108855. (<a
href="https://doi.org/10.1016/j.asoc.2022.108855">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most critical data analysis tasks is the streaming data classification , where we may also observe the concept drift phenomenon, i.e., changing the decision model’s probabilistic characteristics. From a practical point of view, we may face this type of banking, medicine, or cybersecurity task to enumerate only a few. A vital characteristic of these problems is that the classes we are interested in (e.g., fraudulent transactions , treats, or serious diseases) are usually infrequent, which hinders the classification system design. The paper presents a novel algorithm DSCB ( Deterministic Sampling Classifier with weighted Bagging ) employs data preprocessing methods and weighted bagging technique to classify non-stationary imbalanced data stream. It builds models based on an incoming data chunk, but it also takes previously arrived instances into account. The proposed approach has been evaluated based on a wide range of computer experiments carried out on real and artificially generated data streams with various imbalance ratios , label noise levels, and concept drift types. The results confirmed that the weighted bagging ensemble coupled with data preprocessing could outperform state-of-the-art methods.},
  archive      = {J_ASOC},
  author       = {Jakub Klikowski and Michał Woźniak},
  doi          = {10.1016/j.asoc.2022.108855},
  journal      = {Applied Soft Computing},
  pages        = {108855},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Deterministic sampling classifier with weighted bagging for drifted imbalanced data stream classification},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Graph search and variable neighborhood search for finding
constrained longest common subsequences in artificial and real gene
sequences. <em>ASOC</em>, <em>122</em>, 108844. (<a
href="https://doi.org/10.1016/j.asoc.2022.108844">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the constrained longest common subsequence problem with an arbitrary set of input strings as well as an arbitrary set of pattern strings. This problem has applications, for example, in computational biology where it serves as a measure of similarity for sets of molecules with putative structures in common. We contribute in several ways. First, it is formally proven that finding a feasible solution of arbitrary length is, in general, NP NP -complete. Second, we propose several heuristic approaches: a greedy algorithm , a beam search aiming for feasibility, a variable neighborhood search , and a hybrid of the latter two approaches. An exhaustive experimental study shows the effectivity and differences of the proposed approaches in respect to finding a feasible solution, finding high-quality solutions, and runtime for both, artificial and real-world instance sets. The latter ones are generated from a set of 12681 bacteria 16S rRNA gene sequences and consider 15 primer contigs as pattern strings.},
  archive      = {J_ASOC},
  author       = {Marko Djukanović and Aleksandar Kartelj and Dragan Matić and Milana Grbić and Christian Blum and Günther R. Raidl},
  doi          = {10.1016/j.asoc.2022.108844},
  journal      = {Applied Soft Computing},
  pages        = {108844},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Graph search and variable neighborhood search for finding constrained longest common subsequences in artificial and real gene sequences},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pre-trained ensemble model for identification of emotion
during COVID-19 based on emergency response support system dataset.
<em>ASOC</em>, <em>122</em>, 108842. (<a
href="https://doi.org/10.1016/j.asoc.2022.108842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 precautions, lockdown, and quarantine implemented throughout the epidemic resulted in a worldwide economic disaster. People are facing unprecedented levels of intense threat, necessitating professional, systematic psychiatric intervention and assistance. New psychological services must be established as quickly as possible to support the mental healthcare needs of people in this pandemic condition. This study examines the contents of calls landed in the emergency response support system (ERSS) during the pandemic. Furthermore, a combined analysis of Twitter patterns connected to emergency services could be valuable in assisting people in this pandemic crisis and understanding and supporting people’s emotions. The proposed Average Voting Ensemble Deep Learning model (AVEDL Model) is based on the Average Voting technique. The AVEDL Model is utilized to classify emotion based on COVID-19 associated emergency response support system calls (transcribed) along with tweets. Pre-trained transformer-based models BERT , DistilBERT, and RoBERTa are combined to build the AVEDL Model, which achieves the best results. The AVEDL Model is trained and tested for emotion detection using the COVID-19 labeled tweets and call content of the emergency response support system. This is the first deep learning ensemble model using COVID-19 emotion analysis to the best of our knowledge. The AVEDL Model outperforms standard deep learning and machine learning models by attaining an accuracy of 86.46 percent and Macro-average F1-score of 85.20 percent.},
  archive      = {J_ASOC},
  author       = {K. Nimmi and B. Janet and A. Kalai Selvan and N. Sivakumaran},
  doi          = {10.1016/j.asoc.2022.108842},
  journal      = {Applied Soft Computing},
  pages        = {108842},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Pre-trained ensemble model for identification of emotion during COVID-19 based on emergency response support system dataset},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Identification of DNA n4-methylcytosine sites via fuzzy
model on self representation. <em>ASOC</em>, <em>122</em>, 108840. (<a
href="https://doi.org/10.1016/j.asoc.2022.108840">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {N4-methylcytosine (4mC) has a significant effect on altering protein interactions, DNA conformation, gene expression and genomic imprinting. Accurate recognition of the 4mC sites is helpful for in-depth study of biomedical research. Although there are experimental methods for detecting 4mC sites, these techniques are time-consuming and laborious, and cannot be applied to large-scale genome scanning. Therefore, supplementation with an efficient computational method is absolutely necessary. In this study, we propose a prediction tool, 4mCPred-FSVM, to solve the above problems. We use position-specific trinucleotide propensity (PSTNP) to construct feature vectors. Subsequently, the feature vector was used as the input of the fuzzy support vector machine (FSVM) and the final predictor was developed. We measure the performance of the model on six datasets. In comparison to the state-of-the-art predictor, our predictor has achieved much higher accuracies in predicting 4mC sites.},
  archive      = {J_ASOC},
  author       = {Leyao Wang and Yijie Ding and Junhai Xu and Wenhuan Lu and Jijun Tang and Fei Guo},
  doi          = {10.1016/j.asoc.2022.108840},
  journal      = {Applied Soft Computing},
  pages        = {108840},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Identification of DNA n4-methylcytosine sites via fuzzy model on self representation},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-label rhinitis prediction using ensemble neural
network chain with pre-training. <em>ASOC</em>, <em>122</em>, 108839.
(<a href="https://doi.org/10.1016/j.asoc.2022.108839">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rhinitis is a kind of respiratory disease that is difficult to cure. Timely and accurate prediction in its early stage is an effective method for diagnosis of rhinitis. Machine learning is often applied in predicting clinical rhinitis. However, those problems like multi-label features, class imbalance, and poor generalization performance usually occur on rhinitis prediction. This paper introduces an ensemble neural network chain model with pre-training on rhinitis multi-label classification. We apply stacked autoencoders for denoising and feature dimensionality reduction, add pre-training networks to extract global correlations, and build neural network chain to extract local relevant information for single-label classification. This proposed model can use both global and local label correlations to reduce the influence of unreasonable label sequences on classification. A total of 2231 clinical rhinitis cases from Shanghai Tongji Hospital affiliated to Tongji University is conducted for training and test. The cross-validation results show that the average Hamming Loss, accuracy, recall and F1-score is 0.0195, 87.88\%, 92.32\% and 92.88\%, respectively. Compared to various typical multi-label classifiers, the proposed model achieves better generalization performance in evaluation measures. In addition, we calculate the feature importance of rhinitis based on the purity of splitting nodes in Random Forest and study the correlations between rhinitis features and classification, which have a good reference value for diagnosis and treatment of clinical rhinitis.},
  archive      = {J_ASOC},
  author       = {Jingdong Yang and Meng Zhang and Peng Liu and Shaoqing Yu},
  doi          = {10.1016/j.asoc.2022.108839},
  journal      = {Applied Soft Computing},
  pages        = {108839},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-label rhinitis prediction using ensemble neural network chain with pre-training},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiclass anomaly detection for unsupervised and
semi-supervised data based on a combination of negative selection and
clonal selection algorithms. <em>ASOC</em>, <em>122</em>, 108838. (<a
href="https://doi.org/10.1016/j.asoc.2022.108838">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A key challenge in anomaly detection is the imbalance between the amounts of normal and abnormal signal data. Specifically, the amount of abnormal signal data is considerably less than that of normal signal data. To solve this problem, techniques for detecting abnormalities using only normal signal data derived from artificial immune systems (AISs) have been investigated. A representative example is the negative selection algorithm (NSA), which classifies data and detects anomalies using only normal signals through a process that mimics the underlying principle of vertebrate immunity. However, the NSA is optimized to detect only two classes of anomalies. Therefore, in this study, we developed a multiclass anomaly detection algorithm that hybridizes the principles of NSA and the clonal selection algorithm (CSA). We improved this algorithm using unsupervised and semi-supervised learning algorithms to conveniently detect anomalies at actual industrial sites. This paper presents a process for applying an AIS algorithm to anomaly detection using the evolution of data-based anomaly-detection algorithms. In particular, we leveraged the NSA principle of classification through semi-supervised learning to enable multiple classifications of unlabeled data . The obtained detector data formed clones optimized by the CSA and had constant memory, thus improving the classification accuracy and reducing run time. The proposed algorithm was validated using an intelligent maintenance system bearing dataset and a vacuum deposition equipment dataset.},
  archive      = {J_ASOC},
  author       = {Yun Ji Kim and Weonwoo Nam and Jongsoo Lee},
  doi          = {10.1016/j.asoc.2022.108838},
  journal      = {Applied Soft Computing},
  pages        = {108838},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multiclass anomaly detection for unsupervised and semi-supervised data based on a combination of negative selection and clonal selection algorithms},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Brain fMRI segmentation under emotion stimuli incorporating
attention-based deep convolutional neural networks. <em>ASOC</em>,
<em>122</em>, 108837. (<a
href="https://doi.org/10.1016/j.asoc.2022.108837">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Functional magnetic resonance imaging (fMRI) is widely used for clinical examinations, diagnosis, and treatment. By segmenting fMRI images, large-scale medical image data can be processed more efficiently. Most deep learning (DL)-based segmentation typically uses some type of encoding–decoding model. In this study, affective computing (AC) was developed using the brain fMRI dataset generated from an emotion simulation experiment. The brain fMRI dataset was segmented using an attention model, a deep convolutional neural network-32 (DCNN-32) based on Laplacian of Gaussian (LoG) filter, called ADCNN-32-G. For the evaluation of image segmentation , several indices are presented. By comparing the proposed ADCNN-32s-G model to distance regularized level set evolution (DRLSE), single-seeded region growing, and the single segNet full convolutional network model (FCN), the proposed model performs well in segmenting mass fMRI datasets. The proposed method can be applied to the real-time monitoring of patients with depression, and it can effectively advise human mental health.},
  archive      = {J_ASOC},
  author       = {Jie Liu and Nilanjan Dey and Nabanita Das and Rubén González Crespo and Fuqian Shi and Chanjuan Liu},
  doi          = {10.1016/j.asoc.2022.108837},
  journal      = {Applied Soft Computing},
  pages        = {108837},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Brain fMRI segmentation under emotion stimuli incorporating attention-based deep convolutional neural networks},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A lyapunov-stability-based context-layered recurrent
pi-sigma neural network for the identification of nonlinear systems.
<em>ASOC</em>, <em>122</em>, 108836. (<a
href="https://doi.org/10.1016/j.asoc.2022.108836">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel higher-order context-layered recurrent pi-sigma neural network (CLRPSNN) is presented for the identification of nonlinear dynamical systems . The proposed model is the modified form of the classical pi-sigma neural network (PSNN) and contains an additional layer (known as the context layer) of the context nodes. Pi-sigma networks involve a product operator/unit in their output layer which indirectly incorporates in them the capability of higher-order networks and also reduces their network complexity. For tuning the weights of the proposed CLRPSNN model , a learning procedure is developed by combining the Back-Propagation (BP) and Lyapunov-stability method. The performance of the proposed model is compared with other models such as PSNN, Feed-forward neural network (FFNN) (containing single hidden layer), and various popular recurrent neural network (RNN) like Elman recurrent neural network (ERNN), Jordan recurrent neural network (JRNN), Diagonal recurrent neural network (DRNN), and a deep neural network (DNN). The simulation study showed that the proposed model has given better results as compared to the other models.},
  archive      = {J_ASOC},
  author       = {Rajesh Kumar},
  doi          = {10.1016/j.asoc.2022.108836},
  journal      = {Applied Soft Computing},
  pages        = {108836},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A lyapunov-stability-based context-layered recurrent pi-sigma neural network for the identification of nonlinear systems},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An incentive mechanism in expert-decision-based crowdsensing
networks. <em>ASOC</em>, <em>122</em>, 108834. (<a
href="https://doi.org/10.1016/j.asoc.2022.108834">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of wireless communication and smart devices, crowdsensing applications became popular due to their flexibility to deploy and low cost use. Incentive mechanism is one of the most important research contents in crowdsensing, about crowdsensing incentive mechanism, most existing data quality evaluation methods measure the contributions of users only in terms of data quality, and ignore to measure the sensing cost of users. This leads to the problems of different quality evaluation standards, difficult to measure the data quality and difficult to give a reasonable and effective evaluation to complex problems. However, expert-decision can effectively solve these problems and give high-quality evaluation decision for complex and numerous data results. In this paper, aiming at the shortcomings of existing research, we propose an expert-decision-based crowdsensing framework and gives the multidimensional rating for incentive mechanism based on user cost and data quality (MRAI-UCDQ), which consists of user cost evaluation model, data quality evaluation model, contribution quantification and reward distribution by analysing user sensing cost data and collected sensing data (comprehensive evaluation with quantitative and qualitative analysis). Finally, through nearly 30 days of real experiments, 159 volunteers were recruited and 7000 pieces of sensory data were collected. The result shows the MRAI-UCDQ improves the evaluation performance of data quality and stimulates the user’s perceived participation.},
  archive      = {J_ASOC},
  author       = {Bing Jia and Hao Gong and Zhaopeng Zong and Tao Zhou and Thar Baker and Ahmed Al-Shamma’a and Yan Jia},
  doi          = {10.1016/j.asoc.2022.108834},
  journal      = {Applied Soft Computing},
  pages        = {108834},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An incentive mechanism in expert-decision-based crowdsensing networks},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Threat intelligence ATT&amp;CK extraction based on the
attention transformer hierarchical recurrent neural network.
<em>ASOC</em>, <em>122</em>, 108826. (<a
href="https://doi.org/10.1016/j.asoc.2022.108826">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of cyberattacks in the world wide, Tactics, Techniques &amp; Procedures (TTPs) has become the most prevalent advanced indicator for a particular attack in cybersecurity community. However, extracting TTPs from unstructured cyber threat intelligence (CTI) can be arduous due to the large volume of the intelligence database. Although recent efforts on automatically extracting the structured TTPs from the unstructured intelligence have achieved promising results, they only employ simple statistical methods for TTP extraction and neglect the dependences among the hierarchical structure of TTPs. To solve those limitations, we proposed a novel attention-based method called Attention-based Transformer Hierarchical Recurrent Neural Network (ATHRNN) to extract the TTPs from the unstructured CTI. First of all, a Transformer Embedding Architecture (TEA) is designed to obtain high-level semantic representations of CTI and that of taxonomy of ATT&amp;CK. Subsequently, an Attention Recurrent Structure (ARS) is developed to model the dependences between the tactical and technical labels in ATT&amp;CK. Finally, a joint Hierarchical Classification (HC) module is developed to predict the final TTPs. Experiments of our approach on the collected dataset prove to be encouraging. The accuracies of TTPs extraction achieve 6.5\% and 8.2\% improvement in terms of Macro-F score and Micro-F score respectively.},
  archive      = {J_ASOC},
  author       = {Chenjing Liu and Junfeng Wang and Xiangru Chen},
  doi          = {10.1016/j.asoc.2022.108826},
  journal      = {Applied Soft Computing},
  pages        = {108826},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Threat intelligence ATT&amp;CK extraction based on the attention transformer hierarchical recurrent neural network},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semantic schema based genetic programming for symbolic
regression. <em>ASOC</em>, <em>122</em>, 108825. (<a
href="https://doi.org/10.1016/j.asoc.2022.108825">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the empirical success of Genetic programming (GP) in various symbolic regression applications, GP is not still known as a reliable problem-solving technique in this domain. Non-locality of GP representation and operators causes ineffectiveness of its search procedure. This study employs semantic schema theory to control and guide the GP search and proposes a local GP called semantic schema-based genetic programming (SBGP). SBGP partitions the semantic search space into semantic schemas and biases the search to the significant schema of the population, which is gradually progressing towards the optimal solution. Several semantic local operators are proposed for performing a local search around the significant schema. In combination with schema evolution as a global search, the local in-schema search provides an efficient exploration–exploitation control mechanism in SBGP. For evaluating the proposed method, we use six benchmarks, including synthesized and real-world problems. The obtained errors are compared to the best semantic genetic programming algorithms, on the one hand, and data-driven layered learning approaches, on the other hand. Results demonstrate that SBGP outperforms all mentioned methods in four out of six benchmarks up to 87\% in the first set and up to 76\% in the second set of experiments in terms of generalization measured by root mean squared error .},
  archive      = {J_ASOC},
  author       = {Zahra Zojaji and Mohammad Mehdi Ebadzadeh and Hamid Nasiri},
  doi          = {10.1016/j.asoc.2022.108825},
  journal      = {Applied Soft Computing},
  pages        = {108825},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Semantic schema based genetic programming for symbolic regression},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Introducing macrophages to artificial immune systems for
earthquake prediction. <em>ASOC</em>, <em>122</em>, 108822. (<a
href="https://doi.org/10.1016/j.asoc.2022.108822">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Earthquake prediction (EQP) is crucial for taking preemptive measures and accurately predicting damage. Several historical seismic-event-based EQP approaches have been proposed; however, these approaches only identify anomalies without distinguishing noise, reducing the prediction accuracy. Macrophages play an important role in the immune system by recognizing viruses, apoptotic cells, and normal cells, as well as performing immune responses and suppression to ensure homeostasis; that is, macrophages exhibit strong classification capabilities and self-adaptability. Therefore, in this study, a novel artificial macrophage algorithm (AMA) for EQP is proposed. More specifically, we first introduce the biological mechanism of macrophages to establish recognition and learning mechanisms to identify noise and anomalies. Second, we adopt a distance metric to denote the weights of the AMA, instead of using experience-based parameters. Finally, a stochastic gradient descent is introduced to ensure the adaptability of the AMA. The performance of the AMA was assessed through an analysis of historical seismic events in Sichuan and its surroundings. Our experimental results demonstrate that AMA outperforms state-of-the-art EQP algorithms. The parameters and statistical tests of AMA were further analyzed in this study.},
  archive      = {J_ASOC},
  author       = {Wen Zhou and Yiwen Liang and Xinan Wang and Zhe Ming and Zhenhua Xiao and Xiying Fan},
  doi          = {10.1016/j.asoc.2022.108822},
  journal      = {Applied Soft Computing},
  pages        = {108822},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Introducing macrophages to artificial immune systems for earthquake prediction},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Lung cancer disease detection using service-oriented
architectures and multivariate boosting classifier. <em>ASOC</em>,
<em>122</em>, 108820. (<a
href="https://doi.org/10.1016/j.asoc.2022.108820">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big data analytics in healthcare is emerging as a promising field to extract valuable information from large databases and enhance results with fewer costs. Although numerous methods have been proposed for big data analytics in the medical field, an authorized entity is required to access data, inhibiting diagnosis accuracy and efficiency. Particularly, the detection of lung cancer is critical as it is the third most common type of cancer occurring in both males and females in the US and a leading cause of cancer-related deaths worldwide, the detection of lung cancer. Therefore, this study introduces the Multivariate Ruzicka Regressed eXtreme Gradient Boosting Data Classification (MRRXGBDC) technique and service-oriented architecture (SOA) to improve the prediction accuracy and reduce the prediction time of lung cancer in big data analytics. Service-oriented architectures (SOAs) provide a set of healthcare services , where patient data are stored in the database of a physician or other certified entity. After receiving the patient data as input, several multivariate Ruzicka logistic regression trees are constructed by the physician to calculate the relationship between the dependent and independent variables. With this regression analysis, the presence or absence of disease is discovered. The experimental results reveal that the MRRXGBDC technique performs better with 10\% improvement in prediction accuracy, 50\% reduction of false positives , and 11\% faster prediction time for lung cancer detection compared to existing works.},
  archive      = {J_ASOC},
  author       = {Thaventhiran Chandrasekar and Sekar Kidambi Raju and Manikandan Ramachandran and Rizwan Patan and Amir H. Gandomi},
  doi          = {10.1016/j.asoc.2022.108820},
  journal      = {Applied Soft Computing},
  pages        = {108820},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Lung cancer disease detection using service-oriented architectures and multivariate boosting classifier},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AGSDE: Archive guided speciation-based differential
evolution for nonlinear equations. <em>ASOC</em>, <em>122</em>, 108818.
(<a href="https://doi.org/10.1016/j.asoc.2022.108818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving nonlinear equations (NEs) has been obtained considerable attentions in recent years. However, it is still a difficult problem to improve the efficiency of the algorithm to find multiple roots of NEs. Aiming to deal with this issue, an archive guided speciation-based differential evolution (AGSDE) is presented in this paper. It contains three main components: (i) an archive construction approach is used to save the historical individual with poor fitness values in the selection phase; (ii) a reusing historical individual mechanism is implemented to guide the evolution; (iii) a local search method for solving NEs is performed on different subpopulations to refine the accuracy of the candidate solutions. The performance of AGSDE is tested on 30 NEs problems with different characteristics. Experimental results of AGSDE are competitive with those of other state-of-the-art methods in terms of root rate and success rate. In addition, AGSDE also shows its superiority for solving the other 10 complex NEs problems.},
  archive      = {J_ASOC},
  author       = {Zuowen Liao and Fangyang Zhu and Wenyin Gong and Shuijia Li and Xianyan Mi},
  doi          = {10.1016/j.asoc.2022.108818},
  journal      = {Applied Soft Computing},
  pages        = {108818},
  shortjournal = {Appl. Soft. Comput.},
  title        = {AGSDE: Archive guided speciation-based differential evolution for nonlinear equations},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A human learning optimization algorithm with reasoning
learning. <em>ASOC</em>, <em>122</em>, 108816. (<a
href="https://doi.org/10.1016/j.asoc.2022.108816">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human Learning Optimization (HLO) is a simple yet powerful meta-heuristic developed based on a simplified human learning model. Many cognitive activities of humans contain an element of reasoning, and with reasoning, humans can gain deeper information on problems to boost learning performance. Inspired by this fact, this paper proposes a novel human learning optimization algorithm with reasoning learning (HLORL), in which a social reasoning learning operator (SRLO) is developed by using multiple social information sources to improve the global search ability of the algorithm. A parameter study is performed to give the recommended values of the control parameters. It also analyzes and discusses the role and function of the social reasoning learning operator. Finally, the proposed HLORL is applied to solve the CEC14 benchmark functions and 0-1 knapsack problems . The performance of HLORL is compared with the previous HLO variants and other state-of-art meta-heuristics. The experimental results demonstrate that the proposed HLORL has significant advantages over the compared algorithms.},
  archive      = {J_ASOC},
  author       = {Pinggai Zhang and Jiaojie Du and Ling Wang and Minrui Fei and Taicheng Yang and Panos M. Pardalos},
  doi          = {10.1016/j.asoc.2022.108816},
  journal      = {Applied Soft Computing},
  pages        = {108816},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A human learning optimization algorithm with reasoning learning},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robustified extreme learning machine regression with
applications in outlier-blended wind-speed forecasting. <em>ASOC</em>,
<em>122</em>, 108814. (<a
href="https://doi.org/10.1016/j.asoc.2022.108814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wind energy is a core sustainable source of electric power, and accurate wind-speed forecasting is pivotal to enhancing the power stability, efficiency, and utilization. The existing forecasting methods are still limited by the influence of outliers and the modelling difficulties caused by complex features in wind speed series. This paper proposes a new wind speed forecasting system based on a designed adaptive robust extreme learning machine (ARELM) model and signal decomposition algorithms. Firstly, the ARELM is designed to sufficiently lessen the violation of normality assumptions and contamination by outliers. ARELM takes an adaptive scaled Huber’s loss as its objective function, which can limit the influence of outliers and adaptively determine an appropriate mixture distribution of normal distribution and Laplace distribution at the same time. Secondly, the empirical mode decomposition (EMD) method and its improved methods (EEMD, CEEMD and CEEMDAN) are introduced to our wind-speed forecasting system, where the low-frequent sub-series are modelled by basic ELM and the high-frequent ones are modelled by ARELM. This can decompose the modelling complex wind speed series into modelling several simple sub-series and reduce the difficulty of modelling. Experimental results show that our combined forecasting system, ELM-ARELM, obtains up to 78\% improvement in forecasting performance comparing with the methods using general Huber’s loss and other comparison methods, which show the superiority of the adaptive scaled Huber’s loss. The error indexes (MAE and RMSE) by the proposed system, which are (0.25, 0.34), (0.32, 0.45) and (0.38, 0.53) for 5 min head, 15 min ahead and 25 min ahead experiments respectively, demonstrate the effectiveness of decomposition methods on improving accuracy of wind speed prediction.},
  archive      = {J_ASOC},
  author       = {Yang Yang and Hu Zhou and Jinran Wu and Zhe Ding and You-Gan Wang},
  doi          = {10.1016/j.asoc.2022.108814},
  journal      = {Applied Soft Computing},
  pages        = {108814},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Robustified extreme learning machine regression with applications in outlier-blended wind-speed forecasting},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An IT2FS-PT3 based emergency response plan evaluation with
MULTIMOORA method in group decision making. <em>ASOC</em>, <em>122</em>,
108812. (<a href="https://doi.org/10.1016/j.asoc.2022.108812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The eruption of COVID-19 at the beginning of 2020 has sounded the alarm, making experts pay more attention to public health emergency events. A suitable emergency response plan plays a vital role in handling emergency events. Therefore, this paper focuses on the evaluation of emergency response plans among a set of group in the comprehensive prospect, and an emergency decision making method integrated with the interval type-2 fuzzy information based on the third generation prospect theory ( PT 3 PT3 ) and the extended MULTIMOORA method is proposed. Individuals express their preferences using some given linguistic terms set. Furthermore, considering the conflicts may occur in the group, a convergent iterative algorithm is designed for group consensus reaching. Then, the stochastic multi-criteria acceptability analysis (SMAA) method and the Borda Count (BC) method are generated to combine the results instead of the dominance theory in MULTIMOORA system. Finally, based on the background of the COVID-19 pandemic from Wuhan, a case study about the selection of emergency response plan and the corresponding sensitivity and comparative analysis are exhibited to explain the effectiveness of the proposed method.},
  archive      = {J_ASOC},
  author       = {Jindong Qin and Xiaoyu Ma},
  doi          = {10.1016/j.asoc.2022.108812},
  journal      = {Applied Soft Computing},
  pages        = {108812},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An IT2FS-PT3 based emergency response plan evaluation with MULTIMOORA method in group decision making},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data augmentation for convolutional LSTM based brain
computer interface system. <em>ASOC</em>, <em>122</em>, 108811. (<a
href="https://doi.org/10.1016/j.asoc.2022.108811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalogram (EEG) is a noninvasive method to detect spatio-temporal electric signals in human brain, actively used in the recent development of Brain Computer Interfaces (BCI). EEG’s patterns are affected by the task, but also other variable factors influence the subject focus on the task and result in noisy EEG signals difficult to decipher. To surpass these limitations methods based on artificial neural networks (ANNs) are used, they are inherently robust to noise and do not require models. However, they learn from examples and require lots of training data-sets. This will increase costs, need research time and subjects effort. To reduce the number of experiments necessary for network training, we devised a methodology to provide artificial data from a limited number of training data-sets. This was done by applying Empirical Mode Decomposition (EMD) on the EEG frames and intermixing their Intrinsic Mode Function (IMFs). We experimented on motor imagery (MI) tests where participants were asked to imagine movement of the left (or right) arm while under EEG recording. The EEG data were firstly transformed using the Morlet wavelet and then fed to an originally designed Convolutional Neural Network (CNN) with long short term memory blocks (LSTM-RNN). The introduction of artificial frames improved performances when compared with standard algorithms. The artificial frames become advantageous even when the number of available real frames was only of 7 or 8. In a test with two subjects (200 recordings for each subject), we reached an accuracy better than 88\% for both subjects. Improvements due to the artificial data were especially noticeable for the under-performing subject, whose EEG had lower accuracy. Imagination recognition accuracy was about 89\% with 360 training frames, in which 300 were artificially created starting from 60 real ones. We believe this methodology of synthesizing artificial data may contribute to the development of novel and more efficient ways to train neural networks for brain computer interfaces.},
  archive      = {J_ASOC},
  author       = {Kahoko Takahashi and Zhe Sun and Jordi Solé-Casals and Andrzej Cichocki and Anh Huy Phan and Qibin Zhao and Hui-Hai Zhao and Shangkun Deng and Ruggero Micheletto},
  doi          = {10.1016/j.asoc.2022.108811},
  journal      = {Applied Soft Computing},
  pages        = {108811},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Data augmentation for convolutional LSTM based brain computer interface system},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-face detection and alignment using multiple kernels.
<em>ASOC</em>, <em>122</em>, 108808. (<a
href="https://doi.org/10.1016/j.asoc.2022.108808">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-face detection and alignment techniques under unlimited environment are challenging issues. In recent years, the demand for face detection and alignment techniques has increased in many areas, including automatic drive and security. However, some mainstream algorithms, such as the Multi-task Cascaded Convolutional Networks (MTCNN) algorithm cannot transfer to multi-face detection and alignment, which introduces new multi-size, multi-resolution, and multi-angle challenges. This paper proposes an improved algorithm—Multi-face-MTCNN for precise original face detection and alignment algorithm when there is an overlapping face scenario. We design two new network structures: Pixelfusion-MTCNN and Twoconv-MTCNN. Moreover, we propose new data augmentation method and optimized detection process which are applied in the Multi-face-MTCNN algorithm. The limitations associated with single-scale kernel size in MTCNN are solved to obtain a satisfactory performance. Compared to the MTCNN algorithm, experimental analysis of the FDDB dataset show that 1.766\% improves Multi-face-MTCNN. Meanwhile, on the WIDER FACE verification benchmark, respectively, with regards to the three sub-datasets, the proposed algorithm’s performance is improved by 3.426\%, 2.776\%, and 21.576\%. Besides, average alignment error of the left eye, right eye, nose, left mouth, and right mouth is performed on the proposed algorithm.},
  archive      = {J_ASOC},
  author       = {Qi Guo and Zhihui Wang and Daoerji Fan and Huijuan Wu},
  doi          = {10.1016/j.asoc.2022.108808},
  journal      = {Applied Soft Computing},
  pages        = {108808},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-face detection and alignment using multiple kernels},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comparative study for predictive monitoring of COVID-19
pandemic. <em>ASOC</em>, <em>122</em>, 108806. (<a
href="https://doi.org/10.1016/j.asoc.2022.108806">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 pandemic caused by novel coronavirus (SARS-CoV-2) crippled the world economy and engendered irreparable damages to the lives and health of millions. To control the spread of the disease, it is important to make appropriate policy decisions at the right time. This can be facilitated by a robust mathematical model that can forecast the prevalence and incidence of COVID-19 with greater accuracy. This study presents an optimized ARIMA model to forecast COVID-19 cases. The proposed method first obtains a trend of the COVID-19 data using a low-pass Gaussian filter and then predicts/forecasts data using the ARIMA model. We benchmarked the optimized ARIMA model for 7-days and 14-days forecasting against five forecasting strategies used recently on the COVID-19 data. These include the auto-regressive integrated moving average (ARIMA) model, susceptible–infected–removed (SIR) model, composite Gaussian growth model, composite Logistic growth model, and dictionary learning-based model. We have considered the daily infected cases, cumulative death cases, and cumulative recovered cases of the COVID-19 data of the ten most affected countries in the world, including India, USA, UK, Russia, Brazil, Germany, France, Italy, Turkey, and Colombia. The proposed algorithm outperforms the existing models on the data of most of the countries considered in this study.},
  archive      = {J_ASOC},
  author       = {Binish Fatimah and Priya Aggarwal and Pushpendra Singh and Anubha Gupta},
  doi          = {10.1016/j.asoc.2022.108806},
  journal      = {Applied Soft Computing},
  pages        = {108806},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A comparative study for predictive monitoring of COVID-19 pandemic},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A typhoon trajectory prediction model based on multimodal
and multitask learning. <em>ASOC</em>, <em>122</em>, 108804. (<a
href="https://doi.org/10.1016/j.asoc.2022.108804">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence technology has been widely used in various fields in recent years. In the case of typhoons, trajectory prediction technology can reduce the loss of human life and property caused by typhoon movements. From the perspective of deep learning , multimodal learning and multitask learning are applied to trajectory prediction. And a trajectory prediction model based on deep multimodal fusion and multitask generation (Trj-DMFMG) is proposed. The model mainly includes two modules: a deep multimodal fusion module and a multitask generation module. The deep multimodal fusion module is composed of several multimodal fusion modules. First, the multimodal trajectory sequence is divided into multiple multimodal subtrajectories by using a sliding window. Then, the multimodal fusion module trains different modal data to perform feature fusion through a long short-term memory network (LSTM) and a 3D convolution neural network (3D CNN). Finally, the features generated by multiple multimode fusion modules are deeply fused. The multitask generation module first trains the deep fusion features generated by the deep multimodal fusion module through the LSTM, then it realizes longitude and latitude prediction at the same time. In this paper, real typhoon data in the Northwest Pacific Ocean are used for simulation experiments. Through a comprehensive comparison of the prediction results in longitude and latitude, it is found that Trj-DMFMG has the best prediction effect and is more accurate and stable in long-term prediction.},
  archive      = {J_ASOC},
  author       = {Wanting Qin and Jun Tang and Cong Lu and Songyang Lao},
  doi          = {10.1016/j.asoc.2022.108804},
  journal      = {Applied Soft Computing},
  pages        = {108804},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A typhoon trajectory prediction model based on multimodal and multitask learning},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Biogeography based optimization method for robust visual
object tracking. <em>ASOC</em>, <em>122</em>, 108802. (<a
href="https://doi.org/10.1016/j.asoc.2022.108802">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Moving object tracking is one of the applied fields in artificial intelligence and robotic. The main objective of object tracking is to detect and locate targets in video frames of real scenes. Although various methods have been proposed for object tracking so far, tracking in challenging conditions remains an open issue. Recently, different evolutionary and heuristics algorithms like swarm intelligence have been used to address the tracking challenges, which have shown promising performance. In this paper, a new approach based on modified biogeography based optimization (mBBO) method is introduced. The BBO algorithm includes migration and mutation steps. In the migration phase , the search space is properly explored by sharing information between habitats and weaker solutions to improve their position. On the other hand, the mutation phase leads to diversity and change in solutions. In this algorithm, the elitist method has been also used to keep better solutions. The performance of modified BBO tracker has been evaluated on benchmark video datasets and compared with several other tracking methods. Experimental results demonstrate that the proposed method estimates the location of targets with high accuracy and achieves better performance and robustness compared to other trackers.},
  archive      = {J_ASOC},
  author       = {Seyed Abbas Daneshyar and Nasrollah Moghadam Charkari},
  doi          = {10.1016/j.asoc.2022.108802},
  journal      = {Applied Soft Computing},
  pages        = {108802},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Biogeography based optimization method for robust visual object tracking},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Multi/many-objective evolutionary algorithm assisted by
radial basis function models for expensive optimization. <em>ASOC</em>,
<em>122</em>, 108798. (<a
href="https://doi.org/10.1016/j.asoc.2022.108798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a multi/many-objective optimization algorithm assisted by radial basis function is proposed based on reference vectors to solve computationally expensive optimization. According to the iteration, a set of candidates are first determined by the reference vectors guided evolutionary algorithm in a sub-cycle. Based on the candidate pool, a refinement regeneration strategy and a dynamic exploration strategy are required. The refinement regeneration strategy is adopted to update the reference vectors derived from three types of reference vectors (i.e., the coarse reference vectors, the random reference vectors, and the refined reference vectors). The dynamic exploration strategy aims to determine the infilling samples from the candidate pool, considering space-infilling characteristics in the design space and convergence in the objective space. By repeatedly selecting candidates, the refinement regeneration strategy, as well as the dynamic exploration strategy, the final Pareto-optimal solutions can be yielded when the termination condition is satisfied. To verify the effectiveness of the proposed algorithm in addressing low/high-dimensional multi/many-objective optimization, the algorithm is compared with three state-of-the-art surrogate-assisted evolutionary algorithms in terms of numerous benchmark problems and an engineering problem. According to the corresponding results, the competitiveness of the proposed algorithm is verified.},
  archive      = {J_ASOC},
  author       = {Jinglu Li and Peng Wang and Huachao Dong and Jiangtao Shen},
  doi          = {10.1016/j.asoc.2022.108798},
  journal      = {Applied Soft Computing},
  pages        = {108798},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi/many-objective evolutionary algorithm assisted by radial basis function models for expensive optimization},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An echo state network based adaptive dynamic programming
approach for time-varying parameters optimization with application in
algal bloom prediction. <em>ASOC</em>, <em>122</em>, 108796. (<a
href="https://doi.org/10.1016/j.asoc.2022.108796">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction of algal bloom is one of the important links in eutrophication prevention. Chlorophyll a concentration is the indicating variable of algal bloom, and its time series is non-stationary and non-linear, which brings challenges to its effective prediction. Although the current algae growth model (AGM) can directly describe the algal bloom dynamics, the fixed parameters limit the adaptability of the model. If the fixed parameters are dynamically adjusted, the trend of chlorophyll a concentration can be better captured. Therefore, the adaptive dynamic programming (ADP) approach is used to optimize the parameters of the AGM. The ADP contains an action network and a critic network by echo state network , where the action network is used to output the increment value of the fixed parameters, and the critic network is used to approximate the performance index function. In this paper, the input of the action network uses the time series features extracted by the relevant variables, so that the time-varying parameters of the AGM have better dynamic characteristics. We verify the effectiveness of the proposed model through the dataset of the North Canal and Taihu Lake, and the convergence analysis proves the theoretical reliability. In this way, the improved mechanism model with time-varying parameters not only maintains the better interpretability of the original AGM, but also further enhances the prediction accuracy and adaptability by extracting inherent interactive features from the relevant variables.},
  archive      = {J_ASOC},
  author       = {Huiyan Zhang and Bo Hu and Xiaoyi Wang and Li Wang and Jiping Xu and Qian Sun and Zhiyao Zhao},
  doi          = {10.1016/j.asoc.2022.108796},
  journal      = {Applied Soft Computing},
  pages        = {108796},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An echo state network based adaptive dynamic programming approach for time-varying parameters optimization with application in algal bloom prediction},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Genetically-modified multi-objective particle swarm
optimization approach for high-performance computing workflow
scheduling. <em>ASOC</em>, <em>122</em>, 108791. (<a
href="https://doi.org/10.1016/j.asoc.2022.108791">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, scientific research, industry, and many other fields are greedy regarding computing resources. Therefore, Cloud Computing infrastructures are now attracting pervasive interest thanks to their excellent hallmarks such as scalability, high performance, reliability, and the pay-per-use strategy. The execution of these high-performant applications on such kind of computing environments in respect of optimizing many conflicting objectives brings us to a challenging issue commonly known as the multi-objective workflows scheduling on large scale distributed systems . Having this in mind, we outline in the present paper our proposed approach called Genetically-modified Multi-objective Particle Swarm Optimization (GMPSO) for scheduling application workflows on hybrid Clouds in the context of high-performance computing in an attempt to optimize Makespan and Cost. The GMPSO consists of incorporating genetic operations into the Multi-objective Particle Swarm Optimization to enhance the resulting solutions. To achieve this, we have designed a novel solution encoding that represents the task ordering, the task mapping and the resource provisioning processes of the workflow scheduling problem in hybrid Clouds . In addition, a set of particular adaptive evolutionary operators have been designed. Conducted simulations lead to significant results compared with a set of well-performed algorithms such NSGA-II, OMOPSO and SMPSO, especially, for the most-demanding workload of workflows.},
  archive      = {J_ASOC},
  author       = {Haithem Hafsi and Hamza Gharsellaoui and Sadok Bouamama},
  doi          = {10.1016/j.asoc.2022.108791},
  journal      = {Applied Soft Computing},
  pages        = {108791},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Genetically-modified multi-objective particle swarm optimization approach for high-performance computing workflow scheduling},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ISecureHome: A deep fusion framework for surveillance of
smart homes using real-time emotion recognition. <em>ASOC</em>,
<em>122</em>, 108788. (<a
href="https://doi.org/10.1016/j.asoc.2022.108788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of AI , the internet of things (IoT) and human-centric computing (HCC), the world has witnessed a rapid proliferation of smart homes (SH). However, implementing a robust security system for residents of SH remains a daunting task. The existing smart homes incorporate security provisions such as biometric verification, activity tracking, and facial recognition. Integrating multi-sensor devices, networking systems and data storage facilities escalate the lifecycle costs of these systems. Facial emotions convey important cues on behaviour and intent that can be used as non-invasive feedback for contextual threat analysis. The early mitigation of a hostile situation, such as a fight or an attempted intrusion, is vital for the SH residents’ safety. This research proposes a real-time facial emotion-based security framework called iSecureHome for smart homes using a CMOS camera, which is triggered by a passive infrared (PIR) motion sensor. The impact of chromatic and achromatic features on facial Emotion Recognition (ER), as well as skin colour-based biases in current ER algorithms , are also investigated. A time-bound facial emotion decoding strategy is presented in iSecureHome that is based on EmoFusioNet—a deep fusion-based model—to predict the security concerns in the vicinity of a given residence. EmoFusioNet utilises stacked and late fusion methodologies to ensure a colour-neutral and equitable ER system. Initially, the stacked model synchronously extracts the chromatic and achromatic facial features using deep CNNs, and their predictions are then fed into the late fusion component. After that, a regularised multi-layer perceptron (R-MLP) is trained to fuse the results of stacked CNNs and generate final predictions. Experimental results suggest that the proposed fusion methodology augments the ER model and achieves the final train and test accuracy of 98.48\% and 98.43\%, respectively. iSecureHome also comprises a multi-threaded decision-making framework for threat analysis with efficient performance and minimal latency.},
  archive      = {J_ASOC},
  author       = {Harshit Kaushik and Tarun Kumar and Kriti Bhalla},
  doi          = {10.1016/j.asoc.2022.108788},
  journal      = {Applied Soft Computing},
  pages        = {108788},
  shortjournal = {Appl. Soft. Comput.},
  title        = {ISecureHome: A deep fusion framework for surveillance of smart homes using real-time emotion recognition},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-objective optimization scheduling for manufacturing
process based on virtual workflow models. <em>ASOC</em>, <em>122</em>,
108786. (<a href="https://doi.org/10.1016/j.asoc.2022.108786">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, processing time, energy consumption and processing quality are three significant optimization objectives for manufacturing process . The variety of optimization objectives and the constraints of processes make the production scheduling an NP-hard problem. To improve processing quality, feedback processing is requisite in productive process, but the nonlinearity of feedback process causes further scheduling complexity. The purpose of this research is to realize the multi-objective optimization scheduling of manufacturing process with feedback process. To solve these problems, a virtual workflow modeling method for parallel manufacturing process of manifold varieties of jobs is proposed in this study, and based on the models, a Multi-Objective Virtual Workflow Scheduling Algorithm (MOVWSA) is contributed. In MOVWSA, the genetic evolution based on two-dimensional chromosome coding and weighted elite retention metrics is employed to select processing equipment for processes, and a sequence-selective strategy is proposed to specify processing order and starting time of each process. It is shown from the comparative test results on flexible job shop scheduling benchmark instances (MK01–MK10) that the proposed MOVWSA can provide more dominant static solutions for multi-objective optimization scheduling. The simulation test illustrates that MOVWSA with virtual workflow modeling is capable of dynamically adjusting the processing plans when reprocessing events occur to ensure the stability of processing with makespan and energy consumption. Consequently, the method contributed in this paper achieves the static and dynamic multi-objective optimization scheduling for manufacturing process with nonlinear feedback process by the two mechanisms of virtual modeling and evolutionary optimization .},
  archive      = {J_ASOC},
  author       = {Zhen Quan and Yan Wang and Zhicheng Ji},
  doi          = {10.1016/j.asoc.2022.108786},
  journal      = {Applied Soft Computing},
  pages        = {108786},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-objective optimization scheduling for manufacturing process based on virtual workflow models},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bioinspired approach-sensitive neural network for collision
detection in cluttered and dynamic backgrounds. <em>ASOC</em>,
<em>122</em>, 108782. (<a
href="https://doi.org/10.1016/j.asoc.2022.108782">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid, accurate and robust detection of looming objects in cluttered moving backgrounds is a significant and challenging problem encountered when designing robotic visual systems to perform collision detection and avoidance tasks. Inspired by the neural circuit involved in the elementary motion vision of the mammalian retina, this study proposes a bioinspired approach-sensitive neural network (ASNN). The three main contributions of this work are as follows. First, a direction-selective visual processing module is built based on the spatiotemporal energy framework, which can estimate motion direction accurately via only two mutually perpendicular spatiotemporal filtering channels. Second, a novel approach-sensitive neural network is modeled as a push–pull structure formed by ON and OFF pathways, which responds strongly to approaching motion, but is insensitive to lateral motion. Finally, a method of direction-selective inhibition is introduced, which is able to effectively suppress translational backgrounds. Extensive synthetic and real robotic experiments indicate that the proposed model is able to not only detect collisions accurately and robustly in cluttered and dynamic backgrounds but also extract additional information on the approaching object, such as position and direction, which is critical for guiding rapid decision making.},
  archive      = {J_ASOC},
  author       = {Xiao Huang and Hong Qiao and Hui Li and Zhihong Jiang},
  doi          = {10.1016/j.asoc.2022.108782},
  journal      = {Applied Soft Computing},
  pages        = {108782},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Bioinspired approach-sensitive neural network for collision detection in cluttered and dynamic backgrounds},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). COVID-WideNet—a capsule network for COVID-19 detection.
<em>ASOC</em>, <em>122</em>, 108780. (<a
href="https://doi.org/10.1016/j.asoc.2022.108780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ever since the outbreak of COVID-19, the entire world is grappling with panic over its rapid spread. Consequently, it is of utmost importance to detect its presence. Timely diagnostic testing leads to the quick identification, treatment and isolation of infected people. A number of deep learning classifiers have been proved to provide encouraging results with higher accuracy as compared to the conventional method of RT-PCR testing. Chest radiography, particularly for using X-ray images, is a prime imaging modality for detecting the suspected COVID-19 patients. However, the performance of these approaches still needs to be improved. In this paper, we propose a capsule network called COVID-WideNet for diagnosing COVID-19 cases using Chest X-ray (CXR) images. Experimental results have demonstrated that a discriminative trained, multi-layer capsule network achieves state-of-the-art performance on the COVIDx dataset. In particular, COVID-WideNet performs better than any other CNN based approaches for the diagnosis of COVID-19 infected patients. Further, the proposed COVID-WideNet has the number of trainable parameters that is 20 times less than that of other CNN based models. This results in a fast and efficient diagnosing COVID-19 symptoms, and with achieving the 0.95 of Area Under Curve (AUC), 91\% of accuracy, sensitivity and specificity, respectively. This may also assist radiologists to detect COVID and its variant like delta.},
  archive      = {J_ASOC},
  author       = {P.K. Gupta and Mohammad Khubeb Siddiqui and Xiaodi Huang and Ruben Morales-Menendez and Harsh Panwar and Hugo Terashima-Marin and Mohammad Saif Wajid},
  doi          = {10.1016/j.asoc.2022.108780},
  journal      = {Applied Soft Computing},
  pages        = {108780},
  shortjournal = {Appl. Soft. Comput.},
  title        = {COVID-WideNet—A capsule network for COVID-19 detection},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A self-adaptive and gradient-based cuckoo search algorithm
for global optimization. <em>ASOC</em>, <em>122</em>, 108774. (<a
href="https://doi.org/10.1016/j.asoc.2022.108774">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stochastic global optimization (SGO) methods like particle swarm optimization (PSO), genetic algorithm (GA), and cuckoo search (CS) have been widely used in a variety of optimization problems partly because of the ability to find the global optimum. Most existing SGO algorithms are designed for gradient-free problems and ignore the gradient information even if the gradient is readily available, resulting in low efficiency and high computational cost. In this paper, we introduce a hybrid self-adaptive gradient-based cuckoo search (HAGCS) to tackle this limitation. HAGCS first takes a gradient-based local random walk to explore the search space, and then uses gradient-based local optimization (GBLO) to find a local minimum near to the current best solution, which is more efficient and precise than standard CS. Additionally, in order to avoid premature convergence potentially being caused by the use of the gradient, we introduce two novel self-adaptation and diversity promotion strategies onto HAGCS. These help HAGCS find proper control parameters and prevent HAGCS from getting stuck at local minima or stationary points. Lastly, we compare HAGCS with PSO, GA, CS, and 5 refinements of CS on 12 benchmark functions . Compared to the other methods, the experiment results show that the proposed method HAGCS has about 2 times faster convergence speed, higher accuracy, and 27.5\% higher success rate of finding the global minimum in high-dimension problems. Even when the dimension of the problem is 1000, HAGCS still offers a success rate of 64\% to find the global minima accurately.},
  archive      = {J_ASOC},
  author       = {Bin She and Aimé Fournier and Mengjie Yao and Yaojun Wang and Guangmin Hu},
  doi          = {10.1016/j.asoc.2022.108774},
  journal      = {Applied Soft Computing},
  pages        = {108774},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A self-adaptive and gradient-based cuckoo search algorithm for global optimization},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spatial-frequency convolutional self-attention network for
EEG emotion recognition. <em>ASOC</em>, <em>122</em>, 108740. (<a
href="https://doi.org/10.1016/j.asoc.2022.108740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the combination of neural network and attention mechanism is widely employed for electroencephalogram (EEG) emotion recognition (EER) and has achieved remarkable results. Nevertheless, most of them ignored the individual information in and within different frequency bands, so they just applied a single-layer attention mechanism to the entire EEG signals, with relatively single feature expression. To overcome the shortcoming, a spatial-frequency convolutional self-attention network (SFCSAN) is proposed in this paper to integrate the feature learning from both spatial and frequency domain of EEG signals. In this model, the intra-frequency band self-attention is employed to learn frequency information from each frequency band, and inter-frequency band mapping further maps them into final attention representation to learn their complementary frequency information. Additionally, a parallel convolutional neural network (PCNN) layer is used to excavate the spatial information of EEG signals. By incorporating spatial and frequency band information, the SFCSAN can fully utilize the spatial and frequency domain information of EEG signals for emotion recognition. The experiments conducted on two public EEG emotion datasets achieved the average accuracy of 95.15\%/95.76\%/95.64\%/95.86\% on valence/arousal/dominance/liking label for DEAP dataset, and 93.77\%/95.80\%/96.26\% on valence/arousal/dominance label for DREAMER dataset, which all demonstrate that the proposed method is conducive to enhancing the importing of emotion-salient information and generating better recognition performance. The code of our work is available on “ https://github.com/qeebeast7/SFCSAN ”.},
  archive      = {J_ASOC},
  author       = {Dongdong Li and Li Xie and Bing Chai and Zhe Wang and Hai Yang},
  doi          = {10.1016/j.asoc.2022.108740},
  journal      = {Applied Soft Computing},
  pages        = {108740},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Spatial-frequency convolutional self-attention network for EEG emotion recognition},
  volume       = {122},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Incremental feature selection by sample selection and
feature-based accelerator. <em>ASOC</em>, <em>121</em>, 108800. (<a
href="https://doi.org/10.1016/j.asoc.2022.108800">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incremental feature selection is an efficient paradigm that updates an optimal feature subset from added-in data without forgetting the previously learned knowledge. Most existing studies of rough set-based incremental feature selection require scanning all added-in samples and all possible candidate features when determining a best feature. However, such a classical search strategy has to perform some redundant calculations, which increase the computing and memory space resources. To avoid the redundant calculations, we propose a novel incremental feature selection method using sample selection and feature-based accelerator. First, a feature selection framework based on discernibility score is proposed as basis for our incremental method. Second, sample selection scheme is proposed to eliminate useless samples from added-in data. This scheme ensures that only useful samples are considered in the incremental process. Third, feature-based accelerator is designed to incrementally select a best feature and simultaneously remove redundant candidate features. It is theoretically guaranteed redundant features removed earlier remain redundant and will not be reexamined during the rest of the process. Finally, our incremental feature selection algorithm is designed by a two-stage procedure including sample selection scheme and feature-based accelerator. The results of experiments validate the time efficiency of the proposed incremental algorithm , especially on datasets with numerous instances or high dimensions.},
  archive      = {J_ASOC},
  author       = {Yanyan Yang and Degang Chen and Xiao Zhang and Zhenyan Ji and Yingjun Zhang},
  doi          = {10.1016/j.asoc.2022.108800},
  journal      = {Applied Soft Computing},
  pages        = {108800},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Incremental feature selection by sample selection and feature-based accelerator},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Swarm intelligent based metaheuristics for a bi-objective
flexible job shop integrated supply chain scheduling problems.
<em>ASOC</em>, <em>121</em>, 108794. (<a
href="https://doi.org/10.1016/j.asoc.2022.108794">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a bi-objective integrated supply chain (SC) scheduling (SCS) model to deal with the challenges of providing highly customized and on-time delivery requirements at the least cost. To address these real-life challenges, the model integrates the supply portfolio into production scheduling with a customer-imposed delivery time window. A set of conflicting factors is considered for the SC in which the manufacturer is modeled using the flexible job shop (FJS) problem to include greater flexibility in process routing. Since the proposed SCS model extends the strongly NP-hard FJS problem, two new meta-heuristic algorithms are developed, enhancing the performance of the multi-objective particle swarm optimization (MOPSO). A Tabu search inspired search mechanism and a problem-specific mutation operator are designed in both algorithms. As inadequate archive diversity leads to premature convergence and unsatisfactory Pareto solutions in many cases, this work employs two practical approaches separately (i.e., crowding distance (CD) and niche count preservation of reference point (RP)) in the proposed MOPSOs, called CD-MOPSO and RP-MOPSO, respectively. For leader selection, CD-MOPSO uses the swarm distance-based Roulette wheel, whereas the concept of RP is proposed in RP-MOPSO to expedite convergence. The performances of the proposed algorithms are validated against four existing algorithms and assessed by utilizing several criteria after solving 45 artificial instances. The simulation results and statistical analysis demonstrate the supremacy of the RP-MOPSO which increases the flexibility for a decision-maker in providing a higher number of Pareto solutions and more diverse and regular frontiers within reasonable computational time. Finally, a sensitivity analysis of the model is conducted, and managerial insights are provided.},
  archive      = {J_ASOC},
  author       = {Shahed Mahmud and Ripon K. Chakrabortty and Alireza Abbasi and Michael J. Ryan},
  doi          = {10.1016/j.asoc.2022.108794},
  journal      = {Applied Soft Computing},
  pages        = {108794},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Swarm intelligent based metaheuristics for a bi-objective flexible job shop integrated supply chain scheduling problems},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploring thermal images for object detection in
underexposure regions for autonomous driving. <em>ASOC</em>,
<em>121</em>, 108793. (<a
href="https://doi.org/10.1016/j.asoc.2022.108793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underexposure regions are vital in constructing a complete perception of the surrounding environment for safe autonomous driving . The availability of thermal cameras has provided an essential alternative to explore regions where other optical sensors lack in capturing interpretable signals. A thermal camera captures an image using the heat difference emitted by objects in the infrared spectrum, and object detection in thermal images becomes effective for autonomous driving in challenging conditions . Although object detection in the visible spectrum domain has matured, thermal object detection lacks effectiveness. A significant challenge is the scarcity of labeled data for the thermal domain, which is essential for SOTA artificial intelligence techniques. This work proposes a domain adaptation framework that employs a style transfer technique for transfer learning from visible spectrum images to thermal images . The framework uses a generative adversarial network (GAN) to transfer the low-level features from the visible spectrum domain to the thermal domain through style consistency. The efficacy of the proposed object detection method in thermal images is evident from the improved results when using styled images from publicly available thermal image datasets (FLIR ADAS and KAIST Multi-Spectral).},
  archive      = {J_ASOC},
  author       = {Farzeen Munir and Shoaib Azam and Muhammd Aasim Rafique and Ahmad Muqeem Sheri and Moongu Jeon and Witold Pedrycz},
  doi          = {10.1016/j.asoc.2022.108793},
  journal      = {Applied Soft Computing},
  pages        = {108793},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Exploring thermal images for object detection in underexposure regions for autonomous driving},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A genetic algorithm based on dual hesitant fuzzy preference
relations for consensus group decision making. <em>ASOC</em>,
<em>121</em>, 108778. (<a
href="https://doi.org/10.1016/j.asoc.2022.108778">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consensus is an important issue in group decision making as it aims to avoid future contestation by the decision makers . The elicitation of criteria and decision makers’ weights is an essential part of decision-making problems. This study proposes a new consensus model for group decision making based on dual hesitant fuzzy and evolutionary algorithm for the definition of unknown criteria and decision makers’ weights. The Dual Hesitant Fuzzy Preference Relations combines the advantages of intuitionistic and hesitant fuzzy representations, and it is used to deal with the imprecision in decision makers’ judgments. In order to find decision makers weights to reach a better level of consensus without the need to modify initial assessments, the proposed Genetic Algorithm (GA) is applied. An illustrative application case is presented in a large steel company considering sustainable criteria. An instance generator was proposed to create different scenarios of decision making varying the number of criteria, decision makers, and level of hesitation. Several instances were used in the computational tests for the evaluation of the GA performance. The effectiveness of the proposed GA was verified by comparing its results with the results of the implemented Particle Swarm Optimization (PSO) algorithm. The GA yielded solutions with improved consensus levels in a reasonable runtime, especially for a small or medium number of decision makers.},
  archive      = {J_ASOC},
  author       = {Lucas Daniel Del Rosso Calache and Victor Claudio Bento Camargo and Lauro Osiro and Luiz Cesar Ribeiro Carpinetti},
  doi          = {10.1016/j.asoc.2022.108778},
  journal      = {Applied Soft Computing},
  pages        = {108778},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A genetic algorithm based on dual hesitant fuzzy preference relations for consensus group decision making},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An evolutionary block based network for medical image
denoising using differential evolution. <em>ASOC</em>, <em>121</em>,
108776. (<a href="https://doi.org/10.1016/j.asoc.2022.108776">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image denoising is the key component in several computer vision and image processing operations due to unavoidable noise in the image generation process. For medical image processing , deep convolutional neural networks (CNN) gives a state-of-the-art performance. However, network structures are manually constructed for specific tasks and require several trials to tune a large number of hyperparameters, which can take a long time to construct a network. Additionally, the fittest hyperparameters which may be suitable for source data properties like noisy features cannot be easily found to target data. The realistic noise is generally mixed, complex, and unpredictable in medical images, which makes it difficult to design an efficient denoising network. We developed a Differential Evolution (DE) based automatic network evolution model in this paper to optimize the network architectures and hyperparameters by exploring the fittest parameters. Furthermore, we adopted a transfer learning technique to accelerate the training process. The proposed evolutionary algorithm is flexible and finds optimistic network architectures using well-known methods including residual and dense blocks. Finally, the proposed model was evaluated on four different medical image datasets. The obtained results at different noise levels show the potentiality of the proposed model named DEvoNet for identifying the optimal parameters to develop a high-performance denoising network structure.},
  archive      = {J_ASOC},
  author       = {Chilukamari Rajesh and Sushil Kumar},
  doi          = {10.1016/j.asoc.2022.108776},
  journal      = {Applied Soft Computing},
  pages        = {108776},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An evolutionary block based network for medical image denoising using differential evolution},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Biogeography-based optimization with adaptive migration and
adaptive mutation with its application in sidelobe reduction of antenna
arrays. <em>ASOC</em>, <em>121</em>, 108772. (<a
href="https://doi.org/10.1016/j.asoc.2022.108772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biogeography-based optimization (BBO) is a swarm intelligence optimization algorithm based on migration and mutation operations, which is usually used to solve the complex optimization problems . However, it is also a challenging task for conventional BBO to solve some complex and diversified optimization problems with a perfect balance between the performance of exploration and exploitation. In this paper, we propose a variant of BBO approach called BBO with improved migration and adaptive mutation (BBOIMAM) to improve the performance of conventional BBO for dealing with different optimization problems. First, BBOIMAM introduces an improved migration strategy which includes the generalized sinusoidal migration model and immigration strategy based on elite-learning mechanism for the improvement of the local search ability. Second, we propose an adaptive mutation strategy based on the spring vibration to further enhance the population diversity, so that improving the global search ability of the algorithm. By the combination of the proposed improved migration and adaptive mutation strategies, the exploration and exploitation performance of the algorithm can be balanced. We make a large number of experiments on a set of various kinds of benchmark functions , and the experimental results demonstrate that the proposed BBOIMAM approach achieves better performance than several state-of-the-art peer algorithms on CEC 2017 and CEC 2020 test function sets and three cases of the antenna array beam pattern optimization problems.},
  archive      = {J_ASOC},
  author       = {Shuang Liang and Zhiyi Fang and Geng Sun and Guannan Qu},
  doi          = {10.1016/j.asoc.2022.108772},
  journal      = {Applied Soft Computing},
  pages        = {108772},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Biogeography-based optimization with adaptive migration and adaptive mutation with its application in sidelobe reduction of antenna arrays},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A bi-level memetic algorithm for the integrated order and
vehicle scheduling in a RMFS. <em>ASOC</em>, <em>121</em>, 108770. (<a
href="https://doi.org/10.1016/j.asoc.2022.108770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Robotic Mobile Fulfillment System (RMFS) is a parts-to-picker system designed for e-commerce warehousing where robots are used to fetch inventory pods from the storage area and transport them to the appropriate workstation. At these stations human workers pick the required amount of goods from the pods to fulfill the active orders. The RMFS is composed of several hard sub-problems which are typically solved sequentially. To the best of the authors’ knowledge, there exists no algorithm that integrates multiple of these problems and consider the interdependencies between them. This paper focuses on solving the integrated order to workstation and robot scheduling problem and proposes a bi-level memetic algorithm . Computational experiments on a wide range of problem instances show the importance of considering an integrated solution approach over a sequential approach for this complex problem. The experiment clearly show the impact of the existing interdependencies . Moreover, the study shows that the pod selection problem for the order fulfillment has a significant impact on the overall system performance. The inventory pod’s consolidation opportunity and distance from the picking station has to be taken into account.},
  archive      = {J_ASOC},
  author       = {Sander Teck and Reginald Dewil},
  doi          = {10.1016/j.asoc.2022.108770},
  journal      = {Applied Soft Computing},
  pages        = {108770},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A bi-level memetic algorithm for the integrated order and vehicle scheduling in a RMFS},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A two-stage intrusion detection system with auto-encoder and
LSTMs. <em>ASOC</em>, <em>121</em>, 108768. (<a
href="https://doi.org/10.1016/j.asoc.2022.108768">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {‘Curse of dimensionality’ and the trade-off between low false alarm rate and high detection rate are the major concerns while designing an efficient intrusion detection system . In this study, we propose a hybrid framework comprising deep auto-encoder (AE) with the long short term memory (LSTM) and the bidirectional long short term memory (Bi-LSTM) for intrusion detection system by obtaining optimal features using AE and then LSTMs for classification into normal and anomaly samples. The performance of the proposed models is evaluated on the well-known dataset NSL-KDD in terms of error indices including precision, recall, F-score, accuracy, detection rate (DR), and false alarm rate (FAR). Experimental results indicate that the proposed AE-LSTM performance is significantly better with less prediction error as compared to other deep and shallow machine learning techniques including other recently reported methods. On the NSL-KDD dataset, AE-LSTM shows classification accuracy of 89\% with DR of 89.84\% and FAR of 11\% which demonstrates the enhanced performance of the proposed model over recent state-of-the-art techniques.},
  archive      = {J_ASOC},
  author       = {Earum Mushtaq and Aneela Zameer and Muhammad Umer and Asima Akber Abbasi},
  doi          = {10.1016/j.asoc.2022.108768},
  journal      = {Applied Soft Computing},
  pages        = {108768},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A two-stage intrusion detection system with auto-encoder and LSTMs},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-layer perceptron classification method of medical data
based on biogeography-based optimization algorithm with probability
distributions. <em>ASOC</em>, <em>121</em>, 108766. (<a
href="https://doi.org/10.1016/j.asoc.2022.108766">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of medical informatics, the accuracy of medical data classification plays a vital role. Multi-layer Perceptron (MLP), as one of the most widely used neural networks , has been widely used in the medical fields. In recent years, the Biogeography-based Optimization (BBO) algorithm has been proposed to train MLP, but the original algorithm often encounters local minimums, slow convergence, and sensitivity to initialized values during the optimization process. To this end, this paper adopted the different probability distributions to improve the BBO (PD-BBO) algorithm to train MLP so as to improve medical data classification accuracy . These distributions include Gamma distribution , Beta distribution , Gaussian distribution, Exponential distribution , Poisson distribution, Geometric distribution , Rayleigh distribution and Weber distribution Then these different probability distributions were embed into the migration process of the BBO algorithm to replace the random distribution and the migration probability was defined. Finally, simulation experiments were carried out, and the benchmark function was used to prove the effectiveness of the proposed algorithms. And then it was used to train a multi-layer perceptron, and five medical data sets were selected for classification. After that, the performance of the standard BBO algorithm and five typical meta-heuristic algorithms were compared. The results showed that the PD-BBO algorithms to train MLP was better than the BBO algorithm and the selected meta-heuristic algorithms, and the classification accuracy has been improved to a certain extent.},
  archive      = {J_ASOC},
  author       = {Xu-Dong Li and Jie-Sheng Wang and Wen-Kuo Hao and Min Wang and Min Zhang},
  doi          = {10.1016/j.asoc.2022.108766},
  journal      = {Applied Soft Computing},
  pages        = {108766},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-layer perceptron classification method of medical data based on biogeography-based optimization algorithm with probability distributions},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CT-based severity assessment for COVID-19 using weakly
supervised non-local CNN. <em>ASOC</em>, <em>121</em>, 108765. (<a
href="https://doi.org/10.1016/j.asoc.2022.108765">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluating patient criticality is the foremost step in administering appropriate COVID-19 treatment protocols. Learning an Artificial Intelligence (AI) model from clinical data for automatic risk-stratification enables accelerated response to patients displaying critical indicators. Chest CT manifestations including ground-glass opacities and consolidations are a reliable indicator for prognostic studies and show variability with patient condition. To this end, we propose a novel attention framework to estimate COVID-19 severity as a regression score from a weakly annotated CT scan dataset. It takes a non-locality approach that correlates features across different parts and spatial scales of the 3D scan. An explicit guidance mechanism from limited infection labeling drives attention refinement and feature modulation. The resulting encoded representation is further enriched through cross-channel attention. The attention model also infuses global contextual awareness into the deep voxel features by querying the base CT scan to mine relevant features. Consequently, it learns to effectively localize its focus region and chisel out the infection precisely. Experimental validation on the MosMed dataset shows that the proposed architecture has significant potential in augmenting existing methods as it achieved a 0.84 R-squared score and 0.133 mean absolute difference.},
  archive      = {J_ASOC},
  author       = {R. Karthik and R. Menaka and M. Hariharan and Daehan Won},
  doi          = {10.1016/j.asoc.2022.108765},
  journal      = {Applied Soft Computing},
  pages        = {108765},
  shortjournal = {Appl. Soft. Comput.},
  title        = {CT-based severity assessment for COVID-19 using weakly supervised non-local CNN},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Industrial power quality enhancement using fuzzy logic based
photovoltaic integrated with three phase shunt hybrid active filter and
adaptive controller. <em>ASOC</em>, <em>121</em>, 108762. (<a
href="https://doi.org/10.1016/j.asoc.2022.108762">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Across the globe, solar photovoltaic (PV) sources are treated as the most favorable renewable sources which can fulfill a larger percentage of the total electricity demand with its clean form of energy. But due to its intermittent characteristics, the PV injects lots of uncertainty into the power system . Because of variation in input solar intensity due to climatic conditions , it will impact on the power quality (PQ) issues in power industries. Therefore, in this proposal, a solar PV integrated with shunt hybrid active filter (SHAF) is taken to fulfill the objective of (a) reducing the current harmonics and (b) supplying the active power generated from the PV system . The challenging task in the proposal is to control the PV variables and current control in voltage source inverter (VSI) of the SHAF. Therefore, three-key contributions are made as follows: (a) a control strategy designed which is based on adaptive notch filters (ANF) for reducing the harmonics by generating accurate reference currents; (b) a hysteresis controller is implemented for gating signal pulses; and (c) for maximum power tracking, a fuzzy based maximum power point tracking (MPPT) is developed for the solar tracker. We showed embedded applications of a SHAF for regulating the grid interfaced PV system . Besides a SHAF operated with the ANF and based on the direct current control (DCC) method is used for computing the compensated current. A comparative analysis has been done between ANF (least mean square (LMS) and recursive least square (RLS) method) and the existing non-adaptive notch filters (NNF). Rigorous computer simulations are performed to determine the effectiveness of the proposed system. The real-time digital simulator using OP 5142 designed with low cost and advanced monitoring capability is employed for validating results.},
  archive      = {J_ASOC},
  author       = {Soumya Ranjan Das and Ambika Prasad Hota and Hari Mohan Pandey and Biswa Mohan Sahoo},
  doi          = {10.1016/j.asoc.2022.108762},
  journal      = {Applied Soft Computing},
  pages        = {108762},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Industrial power quality enhancement using fuzzy logic based photovoltaic integrated with three phase shunt hybrid active filter and adaptive controller},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multiplicative maximin-based evaluation approach for
evolutionary many-objective optimization. <em>ASOC</em>, <em>121</em>,
108760. (<a href="https://doi.org/10.1016/j.asoc.2022.108760">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new fitness evaluation approach based on aggregated pairwise comparisons (APC), i.e., a multiplicative maximin fitness ranking indicator with norm- p ( M2F-p ), for solving multi/many-objective problems. The M2F-p uses an adjustable aggregation of pairwise comparisons induced by p to alleviate the incomparability of solutions in terms of Pareto dominance when the number of objectives increases. We analyze the search ability of M2F-p under different p values. It is shown that the p values can control the shape of contour lines (i.e., a set of equal M2F-p values), which can affect the convergence and uniformity of solutions. Then, we illustrate that the M2F-p offers a set of promising properties that can enhance the discriminability of solutions. Further, we develop an efficient algorithm based on M2F-p by using an adaptive p -selection strategy and a diversity-maintenance mechanism. We conduct experiments on a suit of test problems with up to 10 objectives. The experimental results validate the effectiveness of the proposed algorithm on both multi-objective problems and many-objective problems.},
  archive      = {J_ASOC},
  author       = {Jia Ma and Shujun Yang and Gang Shi and Lianbo Ma},
  doi          = {10.1016/j.asoc.2022.108760},
  journal      = {Applied Soft Computing},
  pages        = {108760},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multiplicative maximin-based evaluation approach for evolutionary many-objective optimization},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). An FGM decomposition-based fuzzy MCDM method for selecting
smart technology applications to support mobile health care during and
after the COVID-19 pandemic. <em>ASOC</em>, <em>121</em>, 108758. (<a
href="https://doi.org/10.1016/j.asoc.2022.108758">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a fuzzy multicriteria decision-making (MCDM) problem, a decision maker may have differing viewpoints on the relative priorities of criteria. However, traditional methods merge these viewpoints into a single one, which leads to an unrepresentative decision-making result. Several recent methods identify the multiple viewpoints of a decision maker by decomposing the decision maker’s fuzzy judgment matrix into several symmetric fuzzy subjudgment matrices, which is an inflexible strategy. To enhance flexibility, this study proposed a fuzzy geometric mean (FGM) decomposition-based fuzzy MCDM method in which FGM is applied to decompose a fuzzy judgment matrix into several fuzzy subjudgment matrices that can be asymmetric. These fuzzy subjudgment matrices are diverse and more consistent than the original fuzzy judgment matrix. The proposed methodology was applied to select the best choice from a group of smart technology applications for supporting mobile health care during and after the COVID-19 pandemic. According to the experimental results, the proposed methodology provided a novel approach to decomposing fuzzy judgment matrices and produced more diverse fuzzy subjudgment matrices.},
  archive      = {J_ASOC},
  author       = {Tin-Chih Toly Chen and Chi-Wei Lin},
  doi          = {10.1016/j.asoc.2022.108758},
  journal      = {Applied Soft Computing},
  pages        = {108758},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An FGM decomposition-based fuzzy MCDM method for selecting smart technology applications to support mobile health care during and after the COVID-19 pandemic},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analysis of supply chain resilience drivers in oil and gas
industries during the COVID-19 pandemic using an integrated approach.
<em>ASOC</em>, <em>121</em>, 108756. (<a
href="https://doi.org/10.1016/j.asoc.2022.108756">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic has significantly affected the supply chains (SCs) of many industries, including the oil and gas (O&amp;G) industry. This study aims to identify and analyze the drivers that affect the resilience level of the O&amp;G SC under the COVID-19 pandemic. The analysis helps to understand the driving intensity of one driver over those of others as well as drivers with the highest driving power to achieve resilience. Through an extensive literature review and an overview of experts’ opinions, the study identified fourteen supply chain resilience (SCR) drivers of the O&amp;G industry. These drivers were analyzed using the integrated fuzzy interpretive structural modeling (ISM) and decision-making trial and evaluation laboratory (DEMATEL) approaches. The analysis shows that the major drivers of SCR are government support and security. These two drivers help to achieve other drivers of SCR, such as collaboration and information sharing, which, in turn, influence innovation, trust, and visibility among SC partners. Two more drivers, robustness and agility, are also essential drivers of SCR. However, rather than influencing other drivers for their achievement, robustness and agility are influenced by others. The results show that collaboration has the highest overall driving intensity and agility has the highest intensity of being influenced by other drivers.},
  archive      = {J_ASOC},
  author       = {Sujan Piya and Ahm Shamsuzzoha and Mohammad Khadem},
  doi          = {10.1016/j.asoc.2022.108756},
  journal      = {Applied Soft Computing},
  pages        = {108756},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Analysis of supply chain resilience drivers in oil and gas industries during the COVID-19 pandemic using an integrated approach},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Application of online multitask learning based on least
squares support vector regression in the financial market.
<em>ASOC</em>, <em>121</em>, 108754. (<a
href="https://doi.org/10.1016/j.asoc.2022.108754">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As is known, the financial market prediction and high investing value is receiving more increasing attentions nowadays. But affected by many complex factors, it is difficult to perform the financial market forecast accurately. Among the solving methods, the time-series prediction has caused the focus for its great predictive effect in many fields. However, most of the existing works focus on single-time-series analysis and cannot obtain good learning results because it trains tasks independently and ignores the cross-correlation among multiple time series . Motivated by the multitask learning , a novel online multitask learning based on the least squares support vector regression (OMTL-LS-SVR) algorithm is proposed for multi-step-ahead financial time-series prediction. OMTL-LS-SVR regards multiple related time series as different learning tasks, which are trained in parallel to obtain the prediction model and shorten the training time. Under this scheme, the knowledge from one certain task can benefit others, allowing it to exploit the relatedness among multiple subtasks. The OMTL-LS-SVR is applied to perform the time-series tendency prediction in four branches of China’s financial market, and the experimental results demonstrate the effectiveness of the proposed multitask learning algorithm.},
  archive      = {J_ASOC},
  author       = {Heng-Chang Zhang and Qing Wu and Fei-Yan Li},
  doi          = {10.1016/j.asoc.2022.108754},
  journal      = {Applied Soft Computing},
  pages        = {108754},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Application of online multitask learning based on least squares support vector regression in the financial market},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A discrete squirrel search algorithm for the surgical cases
assignment problem. <em>ASOC</em>, <em>121</em>, 108753. (<a
href="https://doi.org/10.1016/j.asoc.2022.108753">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surgical cases assignment problem (SCAP) is among the most investigated parts in healthcare scheduling and assignment problems, in which a set of surgical cases are assigned to operating rooms within a specified planning horizon. Several methods have been developed to provide approximate solutions for SCAP. Nevertheless, existing methods underperform at the large-scale instances. In this paper, a discrete squirrel search algorithm (DSSA) is proposed for SCAP with the objective of minimizing total operating cost. First, four heuristics are presented to improve quality and diversity of initial population. Second, a surgical case sequence vector is employed to encode individuals, and a corresponding decoding scheme is designed to construct feasible schedules. Third, several efficient heuristics are embedded into DSSA to enhance the search capacity. Moreover, the Taguchi method of design-of-experiment (DOE) is adopted to explore the influence of parameter settings. To the best of our knowledge, it is the first application of the squirrel search algorithm for SCAP. The effectiveness of DSSA is conducted on a typical benchmark dataset. Computational results and comparisons demonstrate the superiority of the proposed scheme over the existing methods in solution accuracy and consuming time for solving SCAP.},
  archive      = {J_ASOC},
  author       = {Lei Zhu and Yusheng Zhou and Shuhui Sun and Qiang Su},
  doi          = {10.1016/j.asoc.2022.108753},
  journal      = {Applied Soft Computing},
  pages        = {108753},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A discrete squirrel search algorithm for the surgical cases assignment problem},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Solving the robust influence maximization problem on
multi-layer networks via a memetic algorithm. <em>ASOC</em>,
<em>121</em>, 108750. (<a
href="https://doi.org/10.1016/j.asoc.2022.108750">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The influence maximization problem is aimed at determining influential nodes as seeds to reach the maximal influential range. Considering the wide application in marketing and social dynamics, increasing attention has been paid to modeling the information diffusion process and efficient seed selection algorithms on both single-layer and multi-layer networks. Interestingly, some recent studies indicate that the robustness of seeds in the diffusion process against potential disturbances like structural failures is significant in applications. But the current study only considers scenarios on single-layer networks. Meanwhile, multi-layer networks have shown non-negligible values in theoretical analyses and practical applications; the study on the robust influence maximization on such networks is urgent but remains to be an open question. Therefore, this paper gives the design of a performance measure to evaluate the influence ability of seeds on multi-layer networks under structural destructions. And a rational configuration of the included changeable parameter is determined based on qualitative analyses. Further, a Memetic algorithm , termed MA-RIM Multi Multi , has been devised with several problem-orientated operators to find influential and robust seeds. This algorithm successfully solves the robust influence maximization problem on multi-layer networks, and shows competitive performance over existing optimization methods on several synthetic and real-world networks. Additionally, the effect of structural changes on the performance of seeds is also studied, and the topological rewiring technique is validated to be effective to improve the influence range of seeds. From the perspective of the influence maximization problem and its robustness, the underlying information behind multi-layer networks has been excavated. Meanwhile, key nodes in such networks can be found via the proposed approach to facilitate possible tasks in social propagation and information diffusion .},
  archive      = {J_ASOC},
  author       = {Shuai Wang and Xiaojun Tan},
  doi          = {10.1016/j.asoc.2022.108750},
  journal      = {Applied Soft Computing},
  pages        = {108750},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Solving the robust influence maximization problem on multi-layer networks via a memetic algorithm},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive search strategy based chemical reaction
optimization scheme for task scheduling in discrete multiphysical
coupling applications. <em>ASOC</em>, <em>121</em>, 108748. (<a
href="https://doi.org/10.1016/j.asoc.2022.108748">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parallel computing problems of multiphysical coupling applications based on discrete grids can be equivalently transformed into parallel computing problems based on a directed acyclic graph (DAG). Due to the problem of the discrete high-dimensional grids of the multiphysical coupling application, the directed data dependencies usually have parallelism . Moreover, this kind of scheduling problem based on DAG is NP-hard problem. Heuristic algorithms are often used to achieve optimal execution order scheduling of tasks and mapping between tasks and processors. In this paper, we propose an improved chemical reaction optimization algorithm based on adaptive search strategy (ASSCRO), which is used to solve the DAG task scheduling problem of discrete multiphysical coupling applications. ASSCRO is divided into two phases. The first phase is used to search the directed execution order of the tasks, and the second phase aims to use the heuristic strategy to map the tasks to the processors efficiently. In the four basic reactions of CRO, the algorithm can cover a larger search solution space by using an adaptive search strategy, it can obtain a better solution, and achieve less overhead and superior performance than the state-of-the-art. We conducted the experiment that applied our ASSCRO to deal with the multiphysical coupling applications. The experimental results showed that the proposed algorithm outperforms other algorithms in multiple metrics when dealing with DAG scheduling problems.},
  archive      = {J_ASOC},
  author       = {Xiong Xiao and Chuanying Li and Bingting Jiang and Qianqian Cai and Kenli Li and Zhuo Tang},
  doi          = {10.1016/j.asoc.2022.108748},
  journal      = {Applied Soft Computing},
  pages        = {108748},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Adaptive search strategy based chemical reaction optimization scheme for task scheduling in discrete multiphysical coupling applications},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A double-adaptive general variable neighborhood search
algorithm for the solution of the traveling salesman problem.
<em>ASOC</em>, <em>121</em>, 108746. (<a
href="https://doi.org/10.1016/j.asoc.2022.108746">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work addresses a novel General Variable Neighborhood Search (GVNS) solution method, which integrates intelligent adaptive mechanisms to re-order the search operators during the intensification and diversification phases, in an effort to enhance its overall efficiency. To evaluate the performance of the new GVNS scheme, asymmetric and symmetric instances of the classic Traveling Salesman Problem (TSP) from the TSPLib were solved. The obtained results of the Double-Adaptive GVNS were compared with those achieved by two single-adaptive GVNS, which use an adaptive mechanism either for the intensification or the diversification phase and with a conventional GVNS. For a fair comparison, all GVNS schemes were structured using the same local search and shaking operators. Moreover, the novel GVNS algorithm was compared with some recent solution methods for the TSP, found in the open literature. The comparative studies revealed the high efficiency of the novel VNS scheme and underlined the significant impact of intelligent mechanisms on the performance of classic metaheuristic frameworks.},
  archive      = {J_ASOC},
  author       = {Panagiotis Karakostas and Angelo Sifaleras},
  doi          = {10.1016/j.asoc.2022.108746},
  journal      = {Applied Soft Computing},
  pages        = {108746},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A double-adaptive general variable neighborhood search algorithm for the solution of the traveling salesman problem},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Behavior-based ransomware classification: A particle swarm
optimization wrapper-based approach for feature selection.
<em>ASOC</em>, <em>121</em>, 108744. (<a
href="https://doi.org/10.1016/j.asoc.2022.108744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ransomware is malware that encrypts the victim’s data and demands a ransom for a decryption key. The increasing number of ransomware families and their variants renders the existing signature-based anti-ransomware techniques useless; thus, behavior-based detection techniques have gained popularity. A difficulty in behavior-based ransomware detection is that hundreds of thousands of system calls are obtained as analysis output, making the manual investigation and selection of ransomware-specific features infeasible. Moreover, manual investigation of the analysis output requires domain experts, who are expensive to hire and unavailable in some cases. Machine learning methods have shown success in a wide range of scientific domains to automate and address the problem of feature selection and extraction from noisy and high-dimensional data. However, automated feature selection is under-explored in malware detection. This study proposes an automated feature selection method that utilizes particle swarm optimization for behavior-based ransomware detection and classification. The proposed method considers the significance of various feature groups of the data in ransomware detection and classification and performs feature selection based on groups’ significance. The experimental results show that, in most cases, the proposed method achieves comparable or significantly better performance than other state-of-the-art methods used in this study for benchmarking. In addition, this article presents an in-depth analysis of the significance of various features groups and the features selected by the proposed method in ransomware detection and classification.},
  archive      = {J_ASOC},
  author       = {Muhammad Shabbir Abbasi and Harith Al-Sahaf and Masood Mansoori and Ian Welch},
  doi          = {10.1016/j.asoc.2022.108744},
  journal      = {Applied Soft Computing},
  pages        = {108744},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Behavior-based ransomware classification: A particle swarm optimization wrapper-based approach for feature selection},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-objective chimp optimization algorithm for
seismicity de-clustering. <em>ASOC</em>, <em>121</em>, 108742. (<a
href="https://doi.org/10.1016/j.asoc.2022.108742">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Earthquakes are random triggering phenomenons that generate clusters in space and time, thus creating a bias in a seismic catalog. Seismic de-clustering separates seismic catalog into mainshocks, aftershocks–foreshocks, and backgrounds, widely used in earthquake prediction models and seismic hazard assessment. The segregation of an optimal number of earthquake clusters and backgrounds is formulated as an unsupervised problem. This manuscript introduces a multi-objective chimp-optimization algorithm (MOCOA) to de-cluster seismicity of earthquake-prone regions. The chimp optimization is inspired by the natural hunting behavior of the chimp to catch the prey. The algorithm effectively balances the exploration of search space (Driving and Chasing) and exploitation around the best solution achieved so far (Attack). In MOCOA, archive controller and archive grid-based approaches are incorporated for selecting non-dominated solutions. The proposed MOCOA is tested on fifteen mathematical test problems and compared with popular algorithms like MOEA/D, MODE, MOPSO , and SPEA2. The binary version of MOCOA is designed for the de-clustering problem. In the time and space domain, respectively, two objective functions, m-Morisita Index (m-MI) and coefficient of variance (COV), are analyzed. The proposed de-clustering algorithm is applied on thirty-two-year historical seismic catalogs of the Himalayas, California, Indonesia, Japan , Iran, and Mexico. Comparative analysis between five existing benchmark de-clustering techniques is performed to check the potential of the proposed MOCOA. The simulation results generated by the proposed algorithm show that obtained de-clustered catalogs COV values lying near unity and m-MI values achieved maximum values. Validation of results using cumulative plots, lambda plots, and inter-event time versus inter-event distance plots signify the accurate discrimination of aftershocks and background events in the catalogs.},
  archive      = {J_ASOC},
  author       = {Ashish Sharma and Satyasai Jagannath Nanda},
  doi          = {10.1016/j.asoc.2022.108742},
  journal      = {Applied Soft Computing},
  pages        = {108742},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-objective chimp optimization algorithm for seismicity de-clustering},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Binary segmentation based on visual attention consistency
under background-change. <em>ASOC</em>, <em>121</em>, 108738. (<a
href="https://doi.org/10.1016/j.asoc.2022.108738">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Good visual perception capability for object plays an important role in binary segmentation task , such as the segmentation for portraits and pulmonary nodules. When facing the same object in different backgrounds, humans always keep consistent visual perception. This has motivated semantic data augmentation strategies widely used in segmentation tasks. For example, ‘Cut-Paste’ strategy creates many images by changing background and assigns them to the same segmentation ground-truths for enhancing training. However, even if using these strategies, there are still differences among the segmentation results of images with the same object and different backgrounds. Hence, this paper proposes to adopt image-level classification and visual attention consistency under background-change to enhance the training of binary segmentation. The combination of image-level classification and class activation mapping can activate and visualize certain regions, which are related to classification label. The visual attention consistency requires the activated object attention to keep consistent when background of the input image changes. Based on this purpose, we augment the dataset by changing backgrounds with ‘Cut-Paste’. Afterwards, we adopt a shared triple-branch network to make original image, background-cut-out image and background image as inputs, and then propose image-level classification and attention consistency to train the binary segmentation network . Experimental results based on two datasets demonstrate that our method achieves new state-of-the-art binary segmentation performance .},
  archive      = {J_ASOC},
  author       = {Xinyu Liu and Donghui Li},
  doi          = {10.1016/j.asoc.2022.108738},
  journal      = {Applied Soft Computing},
  pages        = {108738},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Binary segmentation based on visual attention consistency under background-change},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-surrogate assisted binary particle swarm optimization
algorithm and its application for feature selection. <em>ASOC</em>,
<em>121</em>, 108736. (<a
href="https://doi.org/10.1016/j.asoc.2022.108736">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evolutionary algorithms (EAs) have been shown favorable performance for feature selection. However, a large number of evaluations are required through the EAs. Thus, they will be inappropriate to optimize feature selection when the size of data set is large. In this paper, we propose a multi-surrogate assisted binary particle swarm optimization , denoted as MS-assisted DBPSO. Two surrogate models are trained, which are utilized to approximate the fitness values of the individuals in two sub-populations, respectively. After that, a new population will be generated by the communication between the two sub-populations. Furthermore, dynamic transfer function is proposed in this paper to balance global and local search aiming to find optimal solution with limited computational resource. The experimental results on binary benchmark functions and the feature selection in the UCI data sets demonstrate that our proposed method is efficient on reducing running time and prediction error.},
  archive      = {J_ASOC},
  author       = {Pei Hu and Jeng-Shyang Pan and Shu-Chuan Chu and Chaoli Sun},
  doi          = {10.1016/j.asoc.2022.108736},
  journal      = {Applied Soft Computing},
  pages        = {108736},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-surrogate assisted binary particle swarm optimization algorithm and its application for feature selection},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An adaptive state transition algorithm with local
enhancement for global optimization. <em>ASOC</em>, <em>121</em>,
108733. (<a href="https://doi.org/10.1016/j.asoc.2022.108733">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {State transition algorithm (STA) is an efficient and powerful metaheuristic method for solving global optimization problems , and it has been successfully applied in many engineering fields in the past few years. However, the basic STA has weak local search capability and shows slow convergence rate and low convergence accuracy in the later search stage. In view of the above shortcomings, an adaptive state transition algorithm (ASTA) with local enhancement is proposed in this paper. Firstly, the order of using state transformation operators and the optimal parameters of the operators are considered in each iteration of ASTA, and a statistical method is employed to adaptively select the optimal transformation operator and the parameter values of the optimal operator to speed up the search process. Then, an adaptive call strategy is adopted to determine its convergence to the neighborhood of the optimal solution and to decide whether to perform the quasi-Newton operator for local enhancement. Finally, the degree to which the current solution is close to the optimal solution is judged by the information of historical solutions, and an analytical solution is quickly obtained by calling the quadratic interpolation operator . The effectiveness of the proposed ASTA is checked, through a comparison with other metaheuristic methods, on 15 benchmark functions and several real-world optimization problems . Experimental results show that ASTA has a stronger search capability than the basic STA, STA variants, and some state-of-the-art metaheuristic methods.},
  archive      = {J_ASOC},
  author       = {Yingchao Dong and Hongli Zhang and Cong Wang and Xiaojun Zhou},
  doi          = {10.1016/j.asoc.2022.108733},
  journal      = {Applied Soft Computing},
  pages        = {108733},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An adaptive state transition algorithm with local enhancement for global optimization},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pyramid particle swarm optimization with novel strategies of
competition and cooperation. <em>ASOC</em>, <em>121</em>, 108731. (<a
href="https://doi.org/10.1016/j.asoc.2022.108731">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particle swarm optimization (PSO) has shown its advantages in various optimization problems . Topology and updating strategies are among its key concepts and have significant impacts on optimization ability. This paper proposes a pyramid PSO (PPSO) with novel competitive and cooperative strategies to update particles’ information. PPSO builds a pyramid and assigns each particle to a specific layer according to its fitness. The particles at the same layer will make a pairwise comparison to determine the winners and the losers. The losers will cooperate with their corresponding winners, while the winners will cooperate with the particles at the upper layer and those at the top layer. Each particle in PPSO has its own learning behavior, having more than one exemplar rather than the only global best to learn from. The diversity of the swarm is enhanced and it positively affects the performance of PSO. Extensive experiments demonstrate that the PPSO has superior performance in terms of accuracy, Wilcoxon signed-rank test and convergence speed, yet achieves comparable running time in most cases, when compared with the canonical PSO and eight state-of-the-art PSO variants. Furthermore, we analyze the influence of parameters for the PPSO. All these illustrate that the PPSO is promising for numerical optimization .},
  archive      = {J_ASOC},
  author       = {Taiyong Li and Jiayi Shi and Wu Deng and Zhenda Hu},
  doi          = {10.1016/j.asoc.2022.108731},
  journal      = {Applied Soft Computing},
  pages        = {108731},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Pyramid particle swarm optimization with novel strategies of competition and cooperation},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unsupervised domain adaptation for cross-modality liver
segmentation via joint adversarial learning and self-learning.
<em>ASOC</em>, <em>121</em>, 108729. (<a
href="https://doi.org/10.1016/j.asoc.2022.108729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Liver segmentation on images acquired using computed tomography (CT) and magnetic resonance imaging (MRI) plays an important role in clinical management of liver diseases. Compared to MRI, CT images of liver are more abundant and readily available. However, MRI can provide richer quantitative information of the liver compared to CT. Thus, it is desirable to achieve unsupervised domain adaptation for transferring the learned knowledge from the source domain containing labeled CT images to the target domain containing unlabeled MR images. In this work, we report a novel unsupervised domain adaptation framework for cross-modality liver segmentation via joint adversarial learning and self-learning. We propose joint semantic-aware and shape-entropy-aware adversarial learning with post-situ identification manner to implicitly align the distribution of task-related features extracted from the target domain with those from the source domain. In proposed framework, a network is trained with the above two adversarial losses in an unsupervised manner , and then a mean completer of pseudo-label generation is employed to produce pseudo-labels to train the next network (desired model). Additionally, semantic-aware adversarial learning and two self-learning methods, including pixel-adaptive mask refinement and student-to-partner learning, are proposed to train the desired model. To improve the robustness of the desired model, a low-signal augmentation function is proposed to transform MRI images as the input of the desired model to handle hard samples. Using the public datasets, our experiments demonstrated the proposed unsupervised domain adaptation framework reached four supervised learning methods with a Dice score 0.912 ± 0.037 (mean ± ± standard deviation).},
  archive      = {J_ASOC},
  author       = {Jin Hong and Simon Chun-Ho Yu and Weitian Chen},
  doi          = {10.1016/j.asoc.2022.108729},
  journal      = {Applied Soft Computing},
  pages        = {108729},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Unsupervised domain adaptation for cross-modality liver segmentation via joint adversarial learning and self-learning},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A differential evolution algorithm combined with linear
programming for solving a closed loop facility layout problem.
<em>ASOC</em>, <em>121</em>, 108725. (<a
href="https://doi.org/10.1016/j.asoc.2022.108725">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Closed loop layout problem (CLLP) is an important class of design problems encountered in flexible manufacturing system . It is to determine the locations of manufacturing cells along a closed material handling loop. Existing studies on CLLPs typically ignore clearances between adjacent cells and do not optimize the dimension of the closed loop. However, separating adjacent cells with suitable clearances may achieve a better solution with lower material flow cost, and optimizing cell sequence and the dimension of closed loop simultaneously can also improve the solution quality. In this paper, a mixed integer programming formulation (MIP) is established for the CLLP. Then, based on the formulation, a hybrid approach combining an i mproved d ifferential e volution algorithm and an e xact a pproach (iDE-EA) is proposed to solve the CLLP. The iDE with a hybrid coding is utilized to optimize the dimension of closed loop and the placement sequence of cells simultaneously. The EA is to determine the exact location of each cell (i.e., the clearance between each pair of adjacent cells). iDE-EA is verified on 10 problem instances, and experiments show that iDE-EA improves upon the best-known material handling cost by 0–9.97\% compared against the traditional differential evolution algorithm and three state-of-the-art approaches. In addition, using EA to further optimize clearances among cells in the solution obtained by iDE can achieve a more competitive layout in most cases.},
  archive      = {J_ASOC},
  author       = {Xing Wan and Xingquan Zuo and Xinchao Zhao},
  doi          = {10.1016/j.asoc.2022.108725},
  journal      = {Applied Soft Computing},
  pages        = {108725},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A differential evolution algorithm combined with linear programming for solving a closed loop facility layout problem},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Model selection for RBF-ARX models. <em>ASOC</em>,
<em>121</em>, 108723. (<a
href="https://doi.org/10.1016/j.asoc.2022.108723">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radial basis function network-based autoregressive with exogenous input (RBF-ARX) models are useful in nonlinear system modelling and prediction. The identification of RBF-ARX models includes optimization of the (model lags, number of hidden nodes and state vector) and the parameters of the model. Previous works have usually ignored optimizations of the model’s architecture. In this paper, the RBF-ARX architecture, which includes the selection of lags, number of nodes of the RBF network, lag orders and state vector, is encoded into a chromosome and is evolved simultaneously by a genetic algorithm (GA). This combines the advantages of the GA and the variable projection (VP) method to automatically generate a parsimonious RBF-ARX model with a high generalization performance . The highly efficient VP algorithm is used as a local search strategy to accelerate the convergence of the optimization. The experimental results demonstrate the effectiveness of the proposed method.},
  archive      = {J_ASOC},
  author       = {Qiong-Ying Chen and Long Chen and Jian-Nan Su and Ming-Jian Fu and Guang-Yong Chen},
  doi          = {10.1016/j.asoc.2022.108723},
  journal      = {Applied Soft Computing},
  pages        = {108723},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Model selection for RBF-ARX models},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An application of interval type-2 fuzzy model based control
system for generic aircraft. <em>ASOC</em>, <em>121</em>, 108721. (<a
href="https://doi.org/10.1016/j.asoc.2022.108721">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a design application of Interval Type-2 (IT2) Takagi–Sugeno (T–S)​ Fuzzy Model Based (FMB) control system for generic aircraft. The IT2 T–S FMB flight control system consists of an IT2 T–S fuzzy model and a fuzzy controller connected in a closed-loop. The IT2 T–S​ fuzzy model is obtained by linearizing the nonlinear aircraft dynamics about various representative points (equilibrium points) of the flight envelope with some fuzzy rules. The aircraft flight envelope parameters, i.e., operating altitude and aircraft speed are characterized as premise parameters and elements of stability and control derivative matrix are identified as consequent parameters of fuzzy model. Longitudinal dynamics of X-29A research aircraft is selected for design of IT2 T–S FMB control system. To achieve the optimum design flexibility, an imperfectly matched premise and membership function dependent (MFD) stability analysis is considered. In MFD stability conditions, the information of flight envelope parameters is included to capture the nonlinearity pertaining to variation in flight conditions. The closed-loop response of IT2 T–S FMB controller is presented at trim equilibrium points by taking four initial angle of attack flight conditions. The performance analysis of designed controller is also presented and discussed in comparison with Fuzzy LQR and LQR based optimal controllers . The simulation results reveal that proposed IT2 T–S FMB controller not only stabilizes the aircraft dynamics but also provides improved transient performance as compared with Fuzzy LQR and LQR based optimal controllers . This demonstrates the utility of IT2 T–S FMB control system for aircraft/ UAV’s related application.},
  archive      = {J_ASOC},
  author       = {Dhan Jeet Singh and Nishchal K. Verma and Ajoy Kanti Ghosh and Appasaheb Malagaudanavar},
  doi          = {10.1016/j.asoc.2022.108721},
  journal      = {Applied Soft Computing},
  pages        = {108721},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An application of interval type-2 fuzzy model based control system for generic aircraft},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A constrained cooperative adaptive multi-population
differential evolutionary algorithm for economic load dispatch problems.
<em>ASOC</em>, <em>121</em>, 108719. (<a
href="https://doi.org/10.1016/j.asoc.2022.108719">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many engineering optimization problems are characterized by large scale and complex constraints. High optimization efficiency and reliable constraint handling are two major challenges. The traditional optimization methods hard to obtain practical and feasible solutions in reasonable time. To get better solutions and enhance the global search capability, a constrained cooperative adaptive multi-population differential evolutionary (CCAM-PDE) algorithm is proposed in this paper. The main contributions of this paper are in three aspects. First, a hyperspace dynamic constraint handling region between feasible region and infeasible region is proposed. Second, according to the feasible rate of population, a “one to one” or “one to many” subpopulation generation scheme is adopted for improving the global searching ability. Third, the selection operation of differential evolution algorithm is replaced by the elimination mechanism through the constraint handling technology. Eight economic load dispatch problems and CEC2017 Benchmark test functions are used to testify the performance of the CCAM-PDE algorithm. The experimental results shown that the CCAM-PDE algorithm has a strong constraint-handling efficiency and better global searching ability, its search accuracy and the speed of convergence against the other state-of-the-art algorithms.},
  archive      = {J_ASOC},
  author       = {Liyun Fu and Haibin Ouyang and Chengyun Zhang and Steven Li and Ali Wagdy Mohamed},
  doi          = {10.1016/j.asoc.2022.108719},
  journal      = {Applied Soft Computing},
  pages        = {108719},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A constrained cooperative adaptive multi-population differential evolutionary algorithm for economic load dispatch problems},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ensembles strategies for backtracking search algorithm with
application to engineering design optimization problems. <em>ASOC</em>,
<em>121</em>, 108717. (<a
href="https://doi.org/10.1016/j.asoc.2022.108717">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes two ensemble strategies for the backtracking search algorithm (BSA). The first one is an ensemble of two sets of evolutionary operators that balances exploration and exploitation abilities. The second one is an ensemble of values for each parameter associated with the evolutionary operators. The second strategy provides diverse search moves with various search step lengths that are essential for searching different search landscapes. In addition to the ensemble strategies, another strategy is used to reinitialize specific individuals of the population to escape from local optima. Sixteen variants of the BSA are built based on different combinations of these strategies or their modified versions. The best variant for solving 29 problems of CEC2017 test suite is statistically compared with nineteen state-of-the-art algorithms. The results confirm its superiority to all the considered algorithms. Remarkably, according to the Wilcoxon rank-sum test with a significance level of 0.05, it is better than others for solving at least 20 and 18 functions with 30 and 50 dimensions, respectively. Furthermore, it is applied to five engineering design optimization problems . Its solutions are at least as well as or better than those obtained by the best existing algorithms in the literature for three problems.},
  archive      = {J_ASOC},
  author       = {Amin Rahati and Esmaeil Mirkazehi Rigi and Lhassane Idoumghar and Mathieu Brévilliers},
  doi          = {10.1016/j.asoc.2022.108717},
  journal      = {Applied Soft Computing},
  pages        = {108717},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Ensembles strategies for backtracking search algorithm with application to engineering design optimization problems},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Efficiently tracking multi-strategic opponents: A
context-aware bayesian policy reuse approach. <em>ASOC</em>,
<em>121</em>, 108715. (<a
href="https://doi.org/10.1016/j.asoc.2022.108715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Markov games, accurately detecting opponent policies and reusing optimal response policies is still a challenging problem. Most previous works assume that opponents switch their policies infrequently only at the end of an episode. However, the opponents may change their policies at high-frequency or even within an episode. Besides, the agent may achieve inconsistent optimal returns because of different opponent behaviors, which brings greater challenges to policy detection. This paper studies how to deal with the non-stationary opponent with abrupt policy changes through accurate policy detection and direct policy reuse. Specifically, we propose a context-aware Bayesian policy reuse (CABPR) algorithm to accurately identify and track the multi-strategic opponent. To continuously infer the opponent policy, an intra-episode belief is introduced taking advantage of opponent models. Within an episode, an inter-episode belief using Bayesian inference and the intra-episode belief are jointly used to detect the opponent type based on its behaviors and episodic rewards. Then the agent reuses the best response policies accordingly. We demonstrate the advantages of the proposed algorithm over several state-of-the-art algorithms in terms of episodic rewards, accumulated rewards, and detection accuracy in four competitive scenarios.},
  archive      = {J_ASOC},
  author       = {Hao Chen and Quan Liu and Jian Huang and Ke Fu},
  doi          = {10.1016/j.asoc.2022.108715},
  journal      = {Applied Soft Computing},
  pages        = {108715},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Efficiently tracking multi-strategic opponents: A context-aware bayesian policy reuse approach},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data classification based on attribute vectorization and
evidence fusion. <em>ASOC</em>, <em>121</em>, 108712. (<a
href="https://doi.org/10.1016/j.asoc.2022.108712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classifiers based on evidential reasoning (ER) rule can well handle the uncertainty in the mapping relationship between input attributes and output classes. To avoid the number of model parameters increasing with the growing number of input attributes, this paper proposes a classification model based on attribute vectorization and evidential reasoning (AV-ER). Firstly, different input attributes are combined into attribute vectors by using principal component analysis (PCA). Then, all training samples are casted into reference attribute vectors , and the reference evidence matrix (REM) is generated by likelihood function normalization. After that, all pieces of activated evidence are fused through ER theory to generate the final classification decision. In the fusion process, parameters of the initial classification model are optimized by genetic algorithm (GA), and Akaike information criterion (AIC) is used to evaluate the model performance comprehensively considering the model complexity and classification accuracy . Finally, typical UCI benchmark datasets are applied to verify the proposed AV-ER classification model, and the results indicate that the classification performance of the AV-ER model is satisfying while the number of the model parameters decrease obviously as well.},
  archive      = {J_ASOC},
  author       = {Xiaojian Xu and Xiaobin Xu and Pengfei Shi and Zifa Ye and Yu Bai and Shuo Zhang and Schahram Dustdar and Guodong Wang},
  doi          = {10.1016/j.asoc.2022.108712},
  journal      = {Applied Soft Computing},
  pages        = {108712},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Data classification based on attribute vectorization and evidence fusion},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Forecasting bitcoin returns with long short-term memory
networks and wavelet decomposition: A comparison of several market
determinants. <em>ASOC</em>, <em>121</em>, 108707. (<a
href="https://doi.org/10.1016/j.asoc.2022.108707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Investigating Bitcoin price forecasting has attracted academic attention recently. However, despite some studies on potential economic determinants of Bitcoin price, a consensus on the best predictors is not reached yet. This paper investigates different predictors from various markets including Gold, Oil, S&amp;P500, VIX, USDI, Ether and Ripple as well as Bitcoin historical price in predicting one-step-ahead Bitcoin returns. We propose a two-stage forecasting that comprises discrete wavelet transform as the decomposition method and a deep long short-term memory network as the forecasting algorithm. Beside analyzing forecasting for both univariate and multivariate regression, we design a simulated trading system to put the forecasts into practice and analyze the economic profitability of the predictors. In addition, we shed light on the black box method by implementing sensitivity analysis. To investigate the predictors’ efficacy through time and consider the effects of early 2018 price spike, the dataset is split into two periods: (1) prior to and including the spike and (2) after the spike. According to the experiments, it is hard to choose one predictor over the other in the first period. However, in the second period, Gold and Oil show the highest statistical accuracy, while S&amp;P500 is the most profit-making predictor.},
  archive      = {J_ASOC},
  author       = {Navid Parvini and Mahsa Abdollahi and Sattar Seifollahi and Davood Ahmadian},
  doi          = {10.1016/j.asoc.2022.108707},
  journal      = {Applied Soft Computing},
  pages        = {108707},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Forecasting bitcoin returns with long short-term memory networks and wavelet decomposition: A comparison of several market determinants},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). IPSMT: Multi-objective optimization of multipath
transmission strategy based on improved immune particle swarm algorithm
in wireless sensor networks. <em>ASOC</em>, <em>121</em>, 108705. (<a
href="https://doi.org/10.1016/j.asoc.2022.108705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multipath transmission routing in dynamic wireless sensor network deployed with movable nodes is a multi-objective optimization issue with multi-parameter constraints. Traditional strategies have the deficiencies such as high computational complexity , long solving time, difficulty in obtaining optimal value and easy to fall into local solution especially in the scenario of large quantity of movable sensor nodes being deployed. Therefore, an improved immune particle swarm optimization based multipath transmission strategy (IPSMT) is presented. It contains three parts: improved immune particle swarm algorithm (IIPSO), IPSMT and fault tolerance strategy in multipath transmission routing (FTMT). IIPSO aims to improve the diversity of particle population and accelerate the convergence of multipath establishment respectively through concentration regulation mechanism and immune vaccine operation improvement. IPSMT and MTFT is to establish and optimize multiple transmission paths by considering the movable nodes’ moving distance and energy consumption quality by multi-objective optimization method. Network fault tolerance model has been established to analyze the algorithm’s convergence, energy consumption balance, network fault tolerance and time complexity. Through the multi-objective optimization simulation and analysis of multipath establishment comparing with the related works, IPSMT shows good global searching ability and convergence performance as well as diversity of solution population to realize the optimization of multipath transmission routing. The whole network is proved to have good performance of transmission stability and fault tolerance.},
  archive      = {J_ASOC},
  author       = {Hongbing Li and Shanfeng Wang and Qiang Chen and Maoguo Gong and Liwan Chen},
  doi          = {10.1016/j.asoc.2022.108705},
  journal      = {Applied Soft Computing},
  pages        = {108705},
  shortjournal = {Appl. Soft. Comput.},
  title        = {IPSMT: Multi-objective optimization of multipath transmission strategy based on improved immune particle swarm algorithm in wireless sensor networks},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Applying artificial intelligence and deep belief network to
predict traffic congestion evacuation performance in smart cities.
<em>ASOC</em>, <em>121</em>, 108692. (<a
href="https://doi.org/10.1016/j.asoc.2022.108692">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work is developed to discuss the feasibility and efficiency of adopting Artificial Intelligence (AI) Deep Learning in smart city scenarios. A traffic flow prediction model is constructed based on the Deep Belief Network (DBN) algorithm. The target road section and its historical traffic flow data in Tianjin are collected and pre-processed. Then, several Restricted Boltzmann Machines (RBM) are stacked together to form a DBN, which is trained as a generative model . Finally, its performance is analyzed by the simulation experiment. The algorithm model proposed is compared with Neuro Fuzzy C-Means (FCM) model, Deep Learning Architecture (DLA), and Convolutional Neural Network (CNN) model. The results show that the Root Mean Square Error (RMSE), Mean Absolute Error (MAE), and Mean Absolute Percentage Error (MAPE) of the algorithm model proposed are 4.42\%, 6.21\%, and 8.03\%, respectively. Its prediction accuracy is significantly higher than that of the other three algorithms. In addition, the algorithm can effectively suppress the spread of congestion in the smart city, achieving timely evacuation of traffic congestion. In short, the constructed Deep Learning-based traffic flow prediction model has a high-precision prediction effect and traffic congestion evacuation performance, which can provide experimental references for the later construction of smart cities.},
  archive      = {J_ASOC},
  author       = {Gen Chen and Jiawan Zhang},
  doi          = {10.1016/j.asoc.2022.108692},
  journal      = {Applied Soft Computing},
  pages        = {108692},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Applying artificial intelligence and deep belief network to predict traffic congestion evacuation performance in smart cities},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Type-2 fuzzy ontology-based semantic knowledge for indoor
air quality assessment. <em>ASOC</em>, <em>121</em>, 108658. (<a
href="https://doi.org/10.1016/j.asoc.2022.108658">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic web technology plays an increasing role in performing smart home applied programs and it has led to improve semantic interoperability among different systems. However, classical ontologies fail to illustrate ambiguous, incomplete, and uncertain knowledge often available in the real world. On the other hand, the air quality assessment carried out to determine “the degree of pollution” lacks accurately specified boundaries; therefore, the conventional approach based on classic ontology cannot extract real-valued memberships and consequently fails to support ambiguous, incomplete, and uncertain knowledge. Integrating semantic web of things technology (SWOT) and type-2 fuzzy logic improves the capability of semantic reasoning to retrieve query information. Annotation of sensor-generated data and the ability to infer and represent knowledge based on type-2 fuzzy logic are extremely essential when the available data are ambiguous and uncertain. Hence, in this paper, we have provided a framework to build an IoT-based home air quality assessment system by using type-2 fuzzy ontology so that smart home systems can make a decision and control appropriately based on predefined rules by employing the provided semantic reasoning.},
  archive      = {J_ASOC},
  author       = {Abolfazl Ghorbani and Kamran Zamanifar},
  doi          = {10.1016/j.asoc.2022.108658},
  journal      = {Applied Soft Computing},
  pages        = {108658},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Type-2 fuzzy ontology-based semantic knowledge for indoor air quality assessment},
  volume       = {121},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Choquet capacity identification for multiple criteria
sorting problems: A novel proposal based on stochastic acceptability
multicriteria analysis. <em>ASOC</em>, <em>120</em>, 108727. (<a
href="https://doi.org/10.1016/j.asoc.2022.108727">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Choquet integral is an aggregation operator widely used to deal with interacting criteria in multiple criteria decision analysis (MCDA). A practical problem regarding the use of the Choquet integral is the identification of its parameters, which are known as Choquet capacity. While capacity identification has received considerable attention in the context of ranking problems, it is difficult to find solutions tailored to sorting problems, which is the focus of this paper. We propose a novel method based on the Stochastic Acceptability Multicriteria Analysis (SMAA), by introducing the concept of feasible categorization scenarios . Moreover, two novel SMAA-based descriptive measures are proposed in order to provide valuable information for decision aiding, including the interpretation of the Choquet capacity and the possibility of exploiting the space of capacities by considering the decision makers’ initial preferences. Another feature of our proposal is the ability of dealing with unbalanced three-dimensional decision arrays. Numerical experiments with synthetic data were conducted to assess the proposed method. Furthermore, the applicability of our proposal is also attested to a case study related to the evaluation of research institutions.},
  archive      = {J_ASOC},
  author       = {Renata Pelissari and Alvaro José Abackerli and Leonardo Tomazeli Duarte},
  doi          = {10.1016/j.asoc.2022.108727},
  journal      = {Applied Soft Computing},
  pages        = {108727},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Choquet capacity identification for multiple criteria sorting problems: A novel proposal based on stochastic acceptability multicriteria analysis},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-objective evolutionary optimization of unsupervised
latent variables of turning process. <em>ASOC</em>, <em>120</em>,
108713. (<a href="https://doi.org/10.1016/j.asoc.2022.108713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manufacturing process modeling and optimization is a challenging task due to the numerous objectives to be considered in the optimization. Generally, the optimization of these processes requires many objective optimization methods to deal with four or more objective functions. However, the correlation structure of the outputs cannot be disregarded. In this work, it is proposed the unsupervised learning of the outputs together with multi-objective evolutionary optimization of the turning process of AISI 4340 steel considering three scenarios varying the tool nose radius . A central composite design varying the process parameters is used to conduct the experimental tests. After tests and measurements of quality and productivity outputs the p p correlated observed outputs are firstly transformed in m m unobserved latent variables through factor analysis using principal axis extraction method and varimax rotation, with m m&amp;lt; p . Subsequently, the relation between the process parameters and the scores of latent variables is modeled through response surface methodology . Multi-objective evolutionary optimization methods are applied in the reduced and uncorrelated set of response models of the transformed outputs. The multi-objective algorithms are compared through hypervolume metric and the pseudo-weights approach is used to decision making. The proposed method can also be applied in other multi-response processes with correlated outputs.},
  archive      = {J_ASOC},
  author       = {Simone Aparecida de Melo and Robson Bruno Dutra Pereira and Allexandre Fortes da Silva Reis and Carlos Henrique Lauro and Lincoln Cardoso Brandão},
  doi          = {10.1016/j.asoc.2022.108713},
  journal      = {Applied Soft Computing},
  pages        = {108713},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-objective evolutionary optimization of unsupervised latent variables of turning process},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards delay-optimized and resource-efficient network
function dynamic deployment for VNF service chaining. <em>ASOC</em>,
<em>120</em>, 108711. (<a
href="https://doi.org/10.1016/j.asoc.2022.108711">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By decoupling virtualized network functions from the dedicated network equipment on which they run, Network Function Virtualization (NFV) has brought a flexible and economical way to support the complex communication demands of different applications. Virtualized Network Functions (VNFs) can be dispatched and deployed as instances of plain software on or near the communication paths of applications to establish Service Function Chains (SFCs), so as to provide special packet processing operations beyond simple packet forwarding . However, it is still a great challenge to dynamically place appropriate network functions at suitable locations so as to improve the efficiency of establishing SFCs and optimize network resource utilization. In this paper, the mechanism of dynamically deploying customized network functions via NFV is proposed. By predicting the future popularities of applications to switches, it adaptively places most of the appropriate network functions in corresponding forwarding equipment before they are massively requested. The serious latency and extra resource consumption caused by real-timely dispatching and deploying most of the requested network functions will be avoided. Then, the approach of Ant Colony Optimization (ACO) inspired multi-switch cooperative network function providing is devised. By cooperating multiple forwarding equipment on the packet transmission path, it makes full use of the already placed network functions to support packet processing operations in time with the cost and delay factors jointly considered. Simulation results show that the proposed mechanism has significant improvements in time overhead and resource utilization compared with the current state of the art. Specifically, our mechanism is capable of improving the service delay, the function utilization ratio, and the SFC adjustment efficiency by about 14\%, 10\% and 12\% respectively, compared with corresponding work.},
  archive      = {J_ASOC},
  author       = {Chao Bu and Jinsong Wang and Xingwei Wang},
  doi          = {10.1016/j.asoc.2022.108711},
  journal      = {Applied Soft Computing},
  pages        = {108711},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Towards delay-optimized and resource-efficient network function dynamic deployment for VNF service chaining},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Water–energy–food nexus evaluation using an inverse approach
of the graph model for conflict resolution based on incomplete fuzzy
preferences. <em>ASOC</em>, <em>120</em>, 108703. (<a
href="https://doi.org/10.1016/j.asoc.2022.108703">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous development of economic globalization and the increasing strengthening of human exchanges, the Water–Energy–Food (WEF) nexus evaluation has become a new research area. The purpose of this paper is to develop an inverse approach of graph model for conflict resolution (GMCR) to the conflict problems of WEF nexus evaluation in real life. Specifically, due to lack of information, some decision makers’ (DMs’) preferences over states may be incomplete fuzzy preference relations . Therefore, an algorithm is devised to amend the incomplete fuzzy preference relation to the complete fuzzy preference relation. Subsequently, a complete ordinal score vector is proposed to describe the preference ranking over different states based on the complete fuzzy preference relation. Moreover, in the framework of the inverse approach of GMCR, some mathematical models with the least constraint conditions are proposed to obtain all the required preference relations for opponent DM, which are required to make a given state be stable under four basic stability definitions. Finally, WEF nexus evaluation in Shandong province is illustrated to demonstrate the usefulness of the inverse approach of GMCR with the incomplete fuzzy preference relations .},
  archive      = {J_ASOC},
  author       = {Dayong Wang and Jing Huang and Yejun Xu and Nannan Wu},
  doi          = {10.1016/j.asoc.2022.108703},
  journal      = {Applied Soft Computing},
  pages        = {108703},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Water–Energy–Food nexus evaluation using an inverse approach of the graph model for conflict resolution based on incomplete fuzzy preferences},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid teaching and learning-based optimization algorithm
for distributed sand casting job-shop scheduling problem. <em>ASOC</em>,
<em>120</em>, 108694. (<a
href="https://doi.org/10.1016/j.asoc.2022.108694">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because of global manufacturing, the foundry production workshop has shifted from single-factory production to multi-factory production. The distributed flexible job-shop scheduling problem is studied in this paper, and a distributed sand casting job-shop scheduling problem optimization model is established. To solve this model, this paper proposes a hybrid teaching–learning-based​ optimization (HTLBO) algorithm that involves a three-layer coding solution and a variety of strategies for population initialization. The HTLBO consists of the teacher learning phase, teaching phase, and learning phase. To improve the quality of teachers in the proposed algorithm, this paper sets the dynamic teacher group and adopts the tabu search based on the critical path and key blocks to increase the number of teachers in the dynamic teacher group and conduct the process of the teacher learning phase. In the teaching and learning phase, a variety of crossover operators for teaching and learning operations is designed to realize the process of teaching and learning. Finally, the experimental results of a real sand casting enterprise case indicate that the proposed algorithm performs better than the other six algorithms.},
  archive      = {J_ASOC},
  author       = {Hongtao Tang and Bo Fang and Rong Liu and Yibing Li and Shunsheng Guo},
  doi          = {10.1016/j.asoc.2022.108694},
  journal      = {Applied Soft Computing},
  pages        = {108694},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A hybrid teaching and learning-based optimization algorithm for distributed sand casting job-shop scheduling problem},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interpretable temporal attention network for COVID-19
forecasting. <em>ASOC</em>, <em>120</em>, 108691. (<a
href="https://doi.org/10.1016/j.asoc.2022.108691">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The worldwide outbreak of coronavirus disease 2019 (COVID-19) has triggered an unprecedented global health and economic crisis. Early and accurate forecasts of COVID-19 and evaluation of government interventions are crucial for governments to take appropriate interventions to contain the spread of COVID-19. In this work, we propose the Interpretable Temporal Attention Network (ITANet) for COVID-19 forecasting and inferring the importance of government interventions. The proposed model is with an encoder–decoder architecture and employs long short-term memory (LSTM) for temporal feature extraction and multi-head attention for long-term dependency caption. The model simultaneously takes historical information, a priori known future information, and pseudo future information into consideration, where the pseudo future information is learned with the covariate forecasting network (CFN) and multi-task learning (MTL). In addition, we also propose the degraded teacher forcing (DTF) method to train the model efficiently. Compared with other models, the ITANet is more effective in the forecasting of COVID-19 new confirmed cases. The importance of government interventions against COVID-19 is further inferred by the Temporal Covariate Interpreter (TCI) of the model.},
  archive      = {J_ASOC},
  author       = {Binggui Zhou and Guanghua Yang and Zheng Shi and Shaodan Ma},
  doi          = {10.1016/j.asoc.2022.108691},
  journal      = {Applied Soft Computing},
  pages        = {108691},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Interpretable temporal attention network for COVID-19 forecasting},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An extended interval-valued pythagorean fuzzy WASPAS method
based on new similarity measures to evaluate the renewable energy
sources. <em>ASOC</em>, <em>120</em>, 108689. (<a
href="https://doi.org/10.1016/j.asoc.2022.108689">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent decade has arisen a significant issue in the energy sector, which is how to select proper sources of renewable energy as a sustainable substitution for conventional forms of fossil fuels. The way of solving this problem will meaningfully affect the environmental development and economic growth. To handle the issue, various scholars have concentrated on preferring the desirable energy source by employing the decision-making model based on the different fuzzy sets methods. Therefore, the aim of this paper is two folds. Firstly, various renewable resources potential are reviewed, and secondly, an assessment model is developed for prioritizing renewable options. Five major resources, hydropower, solar, wind, biomass, geothermal are considered. The present paper attempted to propose an integrated method on the basis of the Weighted Aggregated Sum Product Assessment (WASPAS) method in a way to provide an effective solution to decision-making problems on interval-valued Pythagorean fuzzy sets (IVPFSs). For the aim of calculating the criteria weights, the subjective weights offered by decision-makers were combined with objective weights achieved by means of the similarity measure method. This combination helped to attain more realistic weights. In the case of objective and subjective weights, new similarity measures and enhanced score functions were applied to IVPFSs. In addition, a renewable energy source selection problem is addressed in order to demonstrate the developed method is completely applicable to the real-world Multi-Criteria Decision-Making (MCDM) problems. This study also involves a sensitivity analysis using various weights of criteria as well as various values of the method’s parameters in a way to approve the developed method stability. As revealed by the performed analysis, the integration of the subjective and objective weights improved the developed method stability with various weights of criteria. To reliably evaluate the performance of the method developed here, its results were compared with those of different methods formerly proposed in the literature. The evaluation results showed that the wind energy with a maximum assessment score degree (0.6259) using the proposed method was found the best option for selecting renewable energy sources over diverse criteria.},
  archive      = {J_ASOC},
  author       = {Abdullah Al-Barakati and Arunodaya Raj Mishra and Abbas Mardani and Pratibha Rani},
  doi          = {10.1016/j.asoc.2022.108689},
  journal      = {Applied Soft Computing},
  pages        = {108689},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An extended interval-valued pythagorean fuzzy WASPAS method based on new similarity measures to evaluate the renewable energy sources},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data-driven estimation of TBM performance in soft soils
using density-based spatial clustering and random forest. <em>ASOC</em>,
<em>120</em>, 108686. (<a
href="https://doi.org/10.1016/j.asoc.2022.108686">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposed a hybrid approach that integrates supervised and unsupervised learning to estimate the tunnel boring machine (TBM) performance in soft soil under limited geological information. By combining the shared nearest neighbor (SNN) algorithm and the density-based spatial clustering of applications with the noise (DBSCAN) method, an unsupervised learning approach, SNN-DBSCAN method, is performed to extract useful knowledge from the TBM logged data. The supervised random forest (RF) method is further combined with the SNN-DBSCAN method to predict the key TBM performance indicator. A realistic mass rapid transit (MRT) project in Singapore is adopted to examine the efficiency of the proposed methodology. The results from this case study indicate that: (1) The proposed SNN-DBSCAN method is suitable to perform data mining tasks on TBM logged data as the clustering result has an average of 85.03\% similarity with site observation; (2) The knowledge extracted from the proposed approach could assist on soil identification as well as operational parameters determination; (3) Compared to the conventional RF method, the proposed approach achieves a high prediction accuracy with the coefficient of determination ( R 2 R2 ) increasing from 0.78 to 0.92.},
  archive      = {J_ASOC},
  author       = {Xianlei Fu and Liuyang Feng and Limao Zhang},
  doi          = {10.1016/j.asoc.2022.108686},
  journal      = {Applied Soft Computing},
  pages        = {108686},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Data-driven estimation of TBM performance in soft soils using density-based spatial clustering and random forest},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-objective particle swarm optimization with guided
exploration for multimodal problems. <em>ASOC</em>, <em>120</em>,
108684. (<a href="https://doi.org/10.1016/j.asoc.2022.108684">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the multimodal and multi-objective optimization problems, various evolutionary algorithms are developed in the literature. The aim of these algorithms is to find the best feasible solution set for considered objectives. However, approaches developed in literature are unable to determine well distributed Pareto sets and Pareto front in the decision and the objective space respectively. There exists a trade-off in convergence and diversity of Pareto optimal solutions . In this paper, we propose an enhanced multi-objective particle swarm optimization (EMOPSO) method which uses Lévy flight to enhance exploration and expedite the search to obtain multiple global optima. In addition, we introduce parameter gamma that judiciously intertwines exploration and exploitation. Hence, the proposed variant EMOSPO provides diversity in the decision and objective space simultaneously. This method is also successful in maintaining multiple stable niches for multimodal solutions and forms well distributed Pareto set and Pareto front as compared to ten state-of-the-art algorithms. The EMOPSO is evaluated on 24 multimodal multi-objective problems of CEC 2020 based on four performance indicators and is analyzed on the basis of time complexity. Performance of EMOPSO and competitive algorithms is also evaluated on four real world engineering problems. The compared algorithms are ranked on basis of average ranking and Friedman test. Experimental results and analysis show the superior performance of EMOPSO in comparison to the competing state-of-the-art multi-objective algorithms.},
  archive      = {J_ASOC},
  author       = {Parul Agarwal and R.K. Agrawal and Baljeet Kaur},
  doi          = {10.1016/j.asoc.2022.108684},
  journal      = {Applied Soft Computing},
  pages        = {108684},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-objective particle swarm optimization with guided exploration for multimodal problems},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improved MOSADE algorithm incorporating sobol sequences for
multi-objective design of water distribution networks. <em>ASOC</em>,
<em>120</em>, 108682. (<a
href="https://doi.org/10.1016/j.asoc.2022.108682">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Design of Water Distribution Networks (WDNs) is a tremendously hard optimization problem , and consideration of reliability further adds to the complexity, which may involve huge computational effort. As several past studies stressed that Evolutionary Algorithms (EAs) could be efficient tools for WDN design, so this study, presents an effective methodology, Multi-Objective Self Adaptive Differential Evolution (MOSADE) algorithm using Sobol sequences for random number generation , termed as (S-MOSADE) for WDN design. The efficacy of the S-MOSADE framework is evaluated by application on a few benchmark WDNs, by considering cost minimization and mechanical reliability maximization and comparing the results with that of NSGA-II algorithm. The results illustrated that S-MOSADE algorithm leads to a better Pareto-optimal front than NSGA-II with respect to uniformly spaced and wide range of non-dominated solutions, and converges faster as compared to other algorithms. To further reduce the computational burden, minimizing the cost and maximizing the network resilience is carried out to generate the initial population for S-MOSADE algorithm. This has reduced the computational burden by almost three times as compared to random initialization of population, thus saving a lot of computational time. The study concludes that the proposed S-MOSADE algorithm with the strategy of solutions initialized with minimum cost and maximum network resilience could be used effectively for speeding-up the multi-objective design of WDNs.},
  archive      = {J_ASOC},
  author       = {Swati Sirsant and M. Janga Reddy},
  doi          = {10.1016/j.asoc.2022.108682},
  journal      = {Applied Soft Computing},
  pages        = {108682},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Improved MOSADE algorithm incorporating sobol sequences for multi-objective design of water distribution networks},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data analytics and bayesian optimised extreme gradient
boosting approach to estimate cut-offs from wireline logs for net
reservoir and pay classification. <em>ASOC</em>, <em>120</em>, 108680.
(<a href="https://doi.org/10.1016/j.asoc.2022.108680">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate net pay classification is essential in hydrocarbon resource volumetric calculation. However, there is no universal methodology developed for its evaluation hence the existence of many incongruent views on its application since it is data-driven and differs for each reservoir. This research incorporates machine learning and data analytics in predicting net pay, intending to reduce uncertainties associated with the net-pay classification. Log analysis was performed to determine the cut-offs for sonic, neutron, density, and gamma-ray using unsupervised learning and data analytics . The log cut-offs were calculated with petrophysical properties; shale volume, water saturation, permeability, and porosity. A Bayesian Optimised Extreme Gradient Boosting (Bayes Opt-XGBoost) model was applied to predict the petrophysical properties using five wireline logs. The model’s performance and a computational function in classifying net reservoir resulted in an accuracy of 0.93, a combined precision of 0.94, a combined recall of 0.92, and a combined F1-score of 0.93. The model and methodology were deployed on a new well for validation. The classification of net reservoir zones via the proposed data analytics method, Bayes Opt-XGBoost predicted petrophysical properties, and computational function code matched mobility drawdown test data for the well. These results indicate that the developed methodology and machine learning model can work for other reservoirs since the additional computational function code can be manipulated for any data-driven estimated cut-offs. This developed approach can determine net reservoir and net pay zones in any sandstone reservoir.},
  archive      = {J_ASOC},
  author       = {Daniel Asante Otchere and Tarek Omar Arbi Ganat PhD and Vanessa Nta and Eric Thompson Brantson PhD and Tushar Sharma PhD},
  doi          = {10.1016/j.asoc.2022.108680},
  journal      = {Applied Soft Computing},
  pages        = {108680},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Data analytics and bayesian optimised extreme gradient boosting approach to estimate cut-offs from wireline logs for net reservoir and pay classification},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multiagent system based cuckoo search optimization for
parameter identification of photovoltaic cell using lambert w-function.
<em>ASOC</em>, <em>120</em>, 108678. (<a
href="https://doi.org/10.1016/j.asoc.2022.108678">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a multiagent system based cuckoo search optimization (MASCSO) algorithm is developed by combining a multiagent system (MAS) and cuckoo search optimization (CSO) to exploit the complementary nature of the MAS and CSO. The existing behavioral rules in MAS are modified to get improved convergence. The MASCSO algorithm is tested on benchmark single objective bounded constrained functions. Nonparametric statistical analysis is performed to validate the MASCSO algorithm against benchmark algorithms. The proposed MASCSO algorithm is applied to estimate parameters of photovoltaic (PV) cell and module using Lambert W-function (MASCSO(L)) and Direct (MASCSO(D)) current estimation approaches, respectively. The relative power error percentage at the maximum power point (\% Δ P M P P\%ΔPMPP ) is proposed to justify the effectiveness of these parameter estimation techniques. The results indicated that parameters estimated from MASCSO(L) technique have lowered\% Δ P M P P\%ΔPMPP by 54.46\% and 38.88\%, respectively, for PV cell and module.},
  archive      = {J_ASOC},
  author       = {Srihari Gude and Kartick Chandra Jana},
  doi          = {10.1016/j.asoc.2022.108678},
  journal      = {Applied Soft Computing},
  pages        = {108678},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multiagent system based cuckoo search optimization for parameter identification of photovoltaic cell using lambert W-function},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RPI-MDLStack: Predicting RNA–protein interactions through
deep learning with stacking strategy and LASSO. <em>ASOC</em>,
<em>120</em>, 108676. (<a
href="https://doi.org/10.1016/j.asoc.2022.108676">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RNA–protein interactions (RPI) play a crucial role in foundational cellular physiological processes. Traditional methods to predict RPI are implemented through expensive and labor-intensive biological experiments, and existing computational methods are far from being satisfactory. There is a timely need for developing more cost-effective methods to predict RPI. A stacking ensemble deep learning-based framework (named RPI-MDLStack) is constructed for RPI prediction in this study. First, sequential-, physicochemical-, structural- and evolutionary-information from RNA and protein sequences are obtained through eight feature extraction methods. Then, the optimal feature is generated after eliminating the redundancy of the fusion features by the least absolute shrinkage and selection operator (LASSO). Based on the stacking strategy, the optimal feature is first learned by the base-classifier combination composed of multilayer perceptron (MLP), support vector machine (SVM), random forest (RF), gated recurrent unit (GRU), and deep neural networks (DNN). Finally, the prediction scores are fed into a discriminative model for further training. The results of 5-fold cross-validation test prove the superior identification of RPI-MDLStack with accuracy of 96.7\%, 87.3\%, 94.6\%, 97.1\% and 89.5\% on RPI488, RPI369, RPI2241, RPI1807, and RPI1446, respectively. Additionally, RPI-MDLStack obtained the overall prediction accuracy of 97.8\% in the independent tests trained on RPI488. Compared with other state-of-the-art RPI prediction methods using the same datasets, RPI-MDLStack shows more robust and stable for predicting RPI.},
  archive      = {J_ASOC},
  author       = {Bin Yu and Xue Wang and Yaqun Zhang and Hongli Gao and Yifei Wang and Yushuang Liu and Xin Gao},
  doi          = {10.1016/j.asoc.2022.108676},
  journal      = {Applied Soft Computing},
  pages        = {108676},
  shortjournal = {Appl. Soft. Comput.},
  title        = {RPI-MDLStack: Predicting RNA–protein interactions through deep learning with stacking strategy and LASSO},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Quantum-inspired evolutionary algorithm applied to neural
architecture search. <em>ASOC</em>, <em>120</em>, 108674. (<a
href="https://doi.org/10.1016/j.asoc.2022.108674">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The success of machine learning models over the last few years is mostly related to the significant progress of deep neural networks . These powerful and flexible models can even surpass human-level performance in tasks such as image recognition and strategy games. However, experts need to spend considerable time and resources to design the network structure. The demand for new architectures drives interest in automating this design process. Researchers have proposed new algorithms to address the neural architecture search (NAS) problem, including efforts to reduce the high computational cost of such methods. A common approach to improve efficiency is to reduce the search space with the help of expert knowledge, searching for cells rather than entire networks. Motivated by the faster convergence promoted by quantum-inspired evolutionary methods, the Q-NAS algorithm was proposed to address the NAS problem without relying on cell search. In this work, we consolidate Q-NAS, adding a new penalization feature, enhancing its retraining scheme, and also investigating more challenging search spaces than before. In CIFAR-10, we reached 93.85\% of test accuracy in 67 GPU days, considering the addition of an early-stopping mechanism. We also applied Q-NAS to CIFAR-100, without modifying the parameters, and our best accuracy was 74.23\%, which is comparable to ResNet164. The enhancements and results presented in this work show that Q-NAS can automatically generate network architectures that outperform hand-designed models for CIFAR-10 and CIFAR-100. Also, compared to other NAS methods, Q-NAS results are promising regarding the balance between performance, runtime efficiency, and automation. We believe that our results enrich the discussion on this balance, considering alternatives to the cell search approach.},
  archive      = {J_ASOC},
  author       = {Daniela Szwarcman and Daniel Civitarese and Marley Vellasco},
  doi          = {10.1016/j.asoc.2022.108674},
  journal      = {Applied Soft Computing},
  pages        = {108674},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Quantum-inspired evolutionary algorithm applied to neural architecture search},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic synthesizing multi-robot cooperation strategies
based on brain storm robotics. <em>ASOC</em>, <em>120</em>, 108672. (<a
href="https://doi.org/10.1016/j.asoc.2022.108672">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing task complexity and environmental uncertainty, it is hard to achieve adaptability and robustness by manual design methods for multi-robot cooperation tasks. Automatic synthesis approaches with trial and error mechanisms are getting more and more attention. By encoding the strategies to be designed as “ideas”, the newly proposed Brain Storm Robotics (BSR) framework can obtain the sufficiently good solutions for particular tasks after a series of operations on the ideas. However, the original BSR only shows designing the rule base for a fuzzy controller . This paper proposes an automatic design approach for neural network-based strategies for robotic swarms with the BSR framework to realize cooperative behaviors. Two design cases are studied: one is the direct strategy search for a swarm aggregation behavior; the other is synthesizing a backpropagation neural network-based controller for coordinated formation control , which has both evolution and learning characteristics. The results show that the proposed method can automatically find control strategies with scalability for multi-robot cooperation, which has the potential for further development.},
  archive      = {J_ASOC},
  author       = {Jian Yang and Yuhui Shi},
  doi          = {10.1016/j.asoc.2022.108672},
  journal      = {Applied Soft Computing},
  pages        = {108672},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Automatic synthesizing multi-robot cooperation strategies based on brain storm robotics},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An approach for extractive text summarization using fuzzy
evolutionary and clustering algorithms. <em>ASOC</em>, <em>120</em>,
108670. (<a href="https://doi.org/10.1016/j.asoc.2022.108670">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic text summarization schemes are indeed helpful for glancing briefly at the text document. With this motivation, we introduce here a two-stage hybrid model for text summarization task by utilizing the strength of various approaches. In the first step, we cluster the sentences of a document according to their similarity using a partitional clustering algorithm . We then use a linear combination of the normalized Google distance and word mover’s distance to differentiate two sentences. The notion of gap statistics is exploited to approximate the number of partitions for the given document needed in the partitional clustering algorithm . We extract the significant sentences from each cluster (partition), which are recognized by their adjusted text feature scores, in the second step. The teaching–learning based optimization approach is used to find the optimal weights for the text features whereas a fuzzy inference system with a full-fledged knowledge base generated by humans is employed to determine the final score of the sentences. Moreover, we have also proposed an exact method to give a solution for the summarization problem by modeling it as an Integer Linear Programming (ILP) problem. We evaluate the proposed methods on three different datasets: DUC 2001, DUC 2002, and CNN. The observed results on these standard datasets manifest the efficacy of the proposed methods. We further show that partitioning a document in an optimal number of clusters plays a major role in content coverage in summaries. The performance of the proposed hybrid method shows that the combination of fuzzy, evolutionary, and clustering algorithms produces good summaries of the documents.},
  archive      = {J_ASOC},
  author       = {Pradeepika Verma and Anshul Verma and Sukomal Pal},
  doi          = {10.1016/j.asoc.2022.108670},
  journal      = {Applied Soft Computing},
  pages        = {108670},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An approach for extractive text summarization using fuzzy evolutionary and clustering algorithms},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-scale 3D convolution feature-based broad learning
system for alzheimer’s disease diagnosis via MRI images. <em>ASOC</em>,
<em>120</em>, 108660. (<a
href="https://doi.org/10.1016/j.asoc.2022.108660">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease (AD) has become a severe chronic disease that affects the health of the elderly all over the world. And the number of patients currently suffering continues to rise each year. With the rapid development of medical imaging technology, although researchers have done extensive works on the diagnosis of AD through new computer vision technology, it is still a challenge to realize the diagnosis of AD and Mild Cognitive Impairment (MCI) as precise as possible end-to-end by relying on Magnetic Resonance Imaging (MRI) image resources. In this paper, a new variant model of the Broad Learning System (BLS) for accurate diagnosis of AD and MCI is presented for MRI images. The proposed model is composed of two modules named feature mapping module and feature enhancement module . To adapt to the characteristics of medical images, a new feature mapping module that contains multi groups of feature down-sampling is designed to get the multi-scale features of the images without any additional feature selection. As a result, the proposed model can integrate multi-scale convolution features of the feature mapping module and abstract features of the feature enhancement module end-to-end when learning the AD diagnostic task. At the same time, the proposed model is a lightweight model whose complexity has been significantly simplified. To verify the validity of the proposed model, the ANDI-1 dataset was used in the relevant experiments. After 5-fold cross-validation, the proposed model has achieved the accuracy of 91.83\% and 75.52\% for the AD diagnostic task and MCI diagnostic task, respectively. The experimental results demonstrate that the proposed model could achieve better performance compared to other methods under the AD and MCI diagnostic tasks.},
  archive      = {J_ASOC},
  author       = {Ruizhi Han and Zhulin Liu and C.L. Philip Chen},
  doi          = {10.1016/j.asoc.2022.108660},
  journal      = {Applied Soft Computing},
  pages        = {108660},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-scale 3D convolution feature-based broad learning system for alzheimer’s disease diagnosis via MRI images},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LWP-WL: Link weight prediction based on CNNs and the
weisfeiler–lehman algorithm. <em>ASOC</em>, <em>120</em>, 108657. (<a
href="https://doi.org/10.1016/j.asoc.2022.108657">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a new technique for link weight prediction, the Link Weight Prediction Weisfeiler–Lehman (LWP-WL) method that learns from graph structure features and link relationship patterns. Inspired by the Weisfeiler–Lehman Neural Machine, LWP-WL extracts an enclosing subgraph for the target link and applies a graph labelling algorithm for weighted graphs to provide an ordered subgraph adjacency matrix into a neural network. The neural network contains a Convolutional Neural Network in the first layer that applies special filters adapted to the input graph representation. An extensive evaluation is provided that demonstrates an improvement over the state-of-the-art methods in several weighted graphs. Furthermore, we conduct an ablation study to show how adding different features to our approach improves our technique’s performance. Finally, we also perform a study on the complexity and scalability of our algorithm. Unlike other approaches, LWP-WL does not rely on a specific graph heuristic and can perform well in different kinds of graphs.},
  archive      = {J_ASOC},
  author       = {Unai Zulaika and Rubén Sánchez-Corcuera and Aitor Almeida and Diego López-de-Ipiña},
  doi          = {10.1016/j.asoc.2022.108657},
  journal      = {Applied Soft Computing},
  pages        = {108657},
  shortjournal = {Appl. Soft. Comput.},
  title        = {LWP-WL: Link weight prediction based on CNNs and the Weisfeiler–Lehman algorithm},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Urban traffic light scheduling for pedestrian–vehicle
mixed-flow networks using discrete sine–cosine algorithm and its
variants. <em>ASOC</em>, <em>120</em>, 108656. (<a
href="https://doi.org/10.1016/j.asoc.2022.108656">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the traffic light scheduling problem for pedestrian–vehicle mixed-flow networks. A macroscopic model , which strikes an appropriate balance between pedestrians’ needs and vehicle drivers’ needs, is employed to describe the traffic light scheduling problem in a scheduling framework. The objective of this problem is to minimize the total network-wise delay time of vehicles and pedestrians within a given finite-time window, which is crucial to avoid traffic congestion in urban road networks . To achieve this objective, the present study first uses a well-known optimization solver called GUROBI to obtain the optimal solution by converting the problem into mixed-integer linear programming. The obtained results indicate the computational inefficiency of the solver for large network sizes. To overcome this computational inefficiency, three novel metaheuristic methods based on the sine–cosine algorithm are proposed. These methods are denoted by discrete sine–cosine algorithm, discrete sine–cosine algorithm with local search operator, and discrete sine–cosine algorithm with local search operator and memory utilization inspired by harmony search . Each of these methods is developed hierarchically by taking the advantages of previously developed method(s) in terms of a better search process to provide more accurate solutions and a better convergence rate. To validate all these proposed metaheuristics, extensive computational experiments are carried out using the real traffic infrastructure of Singapore. Moreover, various performance measures such as statistical optimization results, relative percentage deviation, computational time, statistical analysis, and convergence behavior analysis have been employed to evaluate the performance of algorithms. The comparison of the proposed SCA variants is done with GUROBI solver and other metaheuristics namely, harmony search , firefly algorithm , bat algorithm , artificial bee colony , genetic algorithm , salp swarm algorithm, and harris hawks optimization. Overall comparison analysis concludes that the proposed methods are very efficient to solve the traffic light scheduling problem for pedestrian–vehicle mixed-flow networks with different network sizes and prediction time horizons.},
  archive      = {J_ASOC},
  author       = {Shubham Gupta and Yi Zhang and Rong Su},
  doi          = {10.1016/j.asoc.2022.108656},
  journal      = {Applied Soft Computing},
  pages        = {108656},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Urban traffic light scheduling for pedestrian–vehicle mixed-flow networks using discrete sine–cosine algorithm and its variants},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fuzziness based semi-supervised multimodal learning for
patient’s activity recognition using RGBDT videos. <em>ASOC</em>,
<em>120</em>, 108655. (<a
href="https://doi.org/10.1016/j.asoc.2022.108655">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic recognition of bedridden patients’ physical activity has important applications in the clinical process. Such recognition tasks are usually accomplished on visual data captured by RGB, depth, and/or thermal cameras by utilizing supervised machine learning . However, supervised machine learning requires a large amount of labeled data and the accuracy depends on extracting appropriate features based on the domain knowledge. A plausible solution to these issues is using semi-supervised learning that focuses less on labeled data and domain knowledge. In this paper, a novel fuzziness-based semi-supervised multimodal learning algorithm, called (FSSL-PAR) is proposed for bedridden patient activity recognition. We use a synergistic interaction on RGB, Depth, and Thermal videos to assess the effect of visual multimodality for the first time in this semi-supervised learning setting. Experiments are conducted on a dataset collected by mimicking the patients with Acute Brain Injury (ABI) from a neurorehabilitation center. The results exhibit the superiority of the proposed algorithm over the existing supervised learning algorithms. We also see a positive correlation between the performance and the size of the labeled data in the proposed FSSL-PAR.},
  archive      = {J_ASOC},
  author       = {Muhammed J.A. Patwary and Weipeng Cao and Xi-Zhao Wang and Mohammad Ahsanul Haque},
  doi          = {10.1016/j.asoc.2022.108655},
  journal      = {Applied Soft Computing},
  pages        = {108655},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fuzziness based semi-supervised multimodal learning for patient’s activity recognition using RGBDT videos},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An optimized kernel extreme learning machine for the
classification of the autism spectrum disorder by using gaze tracking
images. <em>ASOC</em>, <em>120</em>, 108654. (<a
href="https://doi.org/10.1016/j.asoc.2022.108654">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autism spectrum disorder (ASD) is a lifelong neurological condition that affects how a person interacts and learns. The early and accurate diagnosis of ASD is vital to developing a comprehensive rehabilitation plan that improves the quality of life and the integration of the ASD person in the social, family, and work environment. However, the accurate diagnosis of ASD is usually affected since it is linked to the judgment of an expert, which produces biases related to the lack of objectivity. In consequence, several works have been dedicated to developing early detection techniques for ASD based on Machine Learning (ML) technologies and eye-tracking tools. The present work aims to introduce a new methodology for ASD classification, which uses Kernel Extreme Learning Machine (KELM), an objective dataset based on gaze tracking, feature extraction techniques, and data augmentation for training the model. In turn, to enhance the accuracy in ASD classification, the KELM model is optimized through the Giza Pyramids Construction (GPC) algorithm. The proposed approach includes pipeline data augmentation , dimensionality reduction, and a posterior normalization to classify ASD subjects accurately. Statistical tests and analyses were performed to validate the performance of the proposed methodology, resulting in an average accuracy of 98.8\% in ASD classification.},
  archive      = {J_ASOC},
  author       = {Angel Gaspar and Diego Oliva and Salvador Hinojosa and Itzel Aranguren and Daniel Zaldivar},
  doi          = {10.1016/j.asoc.2022.108654},
  journal      = {Applied Soft Computing},
  pages        = {108654},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An optimized kernel extreme learning machine for the classification of the autism spectrum disorder by using gaze tracking images},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving ant colony optimization efficiency for solving
large TSP instances. <em>ASOC</em>, <em>120</em>, 108653. (<a
href="https://doi.org/10.1016/j.asoc.2022.108653">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ant Colony Optimization (ACO) is a family of nature-inspired metaheuristics often applied to finding approximate solutions to difficult optimization problems . Despite being significantly faster than exact methods, the ACOs can still be prohibitively slow, especially if compared to basic problem-specific heuristics. As recent research has shown, it is possible to significantly improve the performance through algorithm refinements and careful parallel implementation benefiting from multi-core CPUs and dedicated accelerators. In this paper, we present a novel ACO variant, namely the Focused ACO (FACO). One of the core elements of the FACO is a mechanism for controlling the number of differences between a newly constructed and a selected previous solution. The mechanism results in a more focused search process, allowing to find improvements while preserving the quality of the existing solution. An additional benefit is a more efficient integration with a problem-specific local search. Computational study based on a range of the Traveling Salesman Problem instances shows that the FACO outperforms the state-of-the-art ACOs when solving large TSP instances. Specifically, the FACO required less than an hour of an 8-core commodity CPU time to find high-quality solutions (within 1\% from the best-known results) for TSP Art Instances ranging from 100 000 to 200 000 nodes.},
  archive      = {J_ASOC},
  author       = {Rafał Skinderowicz},
  doi          = {10.1016/j.asoc.2022.108653},
  journal      = {Applied Soft Computing},
  pages        = {108653},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Improving ant colony optimization efficiency for solving large TSP instances},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Active vehicle suspension control using road preview model
predictive control and radial basis function networks. <em>ASOC</em>,
<em>120</em>, 108646. (<a
href="https://doi.org/10.1016/j.asoc.2022.108646">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active suspension systems in road vehicles are applied in order to mitigate the road-induced chassis vertical accelerations more effectively than standard passive suspensions, thus increasing comfort and handling. Such systems are greatly assisted by road preview schemes, consisting of special sensors usually based on laser scanners (e.g. LiDAR sensors), which detect road irregularities ahead of the vehicle and feed this information to a control system, designed to manipulate the active suspension accordingly. In this paper, a model predictive controller (MPC) with road preview incorporating radial basis function (RBF) models, is presented as a control scheme for a full car active suspension system. The employed RBF models can efficiently approximate the nonlinear behavior of the suspension system, thus improving performance over linear MPC methods. Special care is taken to alleviate the increased computational complexity entailed in the RBF models, in order to ensure that online implementation of the controller is feasible. The proposed scheme is evaluated on a detailed simulated full car model under various road excitation types, while making use of a realistic approach for incorporating LiDAR road scanner noise. Comparisons to a passive suspension system , as well as a standard MPC controller with a fully linear plant model, demonstrate the performance potential of using RBF prediction models in a road preview MPC context.},
  archive      = {J_ASOC},
  author       = {Myron Papadimitrakis and Alex Alexandridis},
  doi          = {10.1016/j.asoc.2022.108646},
  journal      = {Applied Soft Computing},
  pages        = {108646},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Active vehicle suspension control using road preview model predictive control and radial basis function networks},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Metro passenger flow forecasting though multi-source
time-series fusion: An ensemble deep learning approach. <em>ASOC</em>,
<em>120</em>, 108644. (<a
href="https://doi.org/10.1016/j.asoc.2022.108644">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing free access of the Internet provides us with favorable circumstances to investigate search engine index reflecting more and more personal behavior information. Part of valuable travel search information can assist us to achieve more robust and reliable prediction of metro passenger flow. Inspired by this, the paper develops a new multi-source time series fusion and direct interval prediction approach to grasp the dynamic law of metro passenger flow effectively. Multi-source index regarding metro travel from three major search engines (Baidu, Sogou and 360) in China are screened out and fused into the powerful predictors. By integrating an optimized multivariate mode decomposition strategy and long short-term memory model, lower and upper bounds of prediction interval are estimated directly by a multi-objective framework that combines the advantages of both the deep learning models long short-term memory and the ensemble learning approach. Especially, two sets of real experiment data of Beijing and Shanghai metro systems are employed to test our approach. Findings show that fusion of multi-source index information promotes the predictability of metro passenger flow, contributing to improving operation management and service quality.},
  archive      = {J_ASOC},
  author       = {Hongtao Li and Kun Jin and Shaolong Sun and Xiaoyan Jia and Yongwu Li},
  doi          = {10.1016/j.asoc.2022.108644},
  journal      = {Applied Soft Computing},
  pages        = {108644},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Metro passenger flow forecasting though multi-source time-series fusion: An ensemble deep learning approach},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Splitting–merging-based automatic scheduling scheme for
balancing energy consumption and task allocation in WSANs.
<em>ASOC</em>, <em>120</em>, 108642. (<a
href="https://doi.org/10.1016/j.asoc.2022.108642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In wireless sensor and actuator networks (WSANs), sensing region partition, task allocation, and collector schedule greatly affect the performance of WSANs. Specifically, nonuniform data aggregation causes unbalanced energy consumption, thereby reducing the network lifetime. Additionally, unbalanced allocation of data collection tasks of collectors increases the gathering delay. Thus, it is critical to balance the energy consumption of sensor nodes , as well as task allocation and scheduling with the limited number of collectors. This study proposes a novel splitting–merging-based automatic scheduling scheme to balance energy consumption and task allocation for WSANs. First, a sensing region splitting–merging scheme is proposed to make the data load uniform, in which the sensing region is self-organized into many subregions taking into account the maximum number of sensor nodes and the maximum distance between sensor nodes in each subregion. Second, a task allocation strategy based on genetic algorithm is proposed to optimize the number of collectors and uniformly assign tasks to collectors. Finally, the trajectory of each collector is optimized by applying ant colony optimization algorithm. Numerical experiments show that the proposed method outperforms well in terms of prolonging the network lifetime and reducing the gathering delay when compared with several related methods.},
  archive      = {J_ASOC},
  author       = {Yamin Han and Liangliang Zhang and Heejung Byun and Bo Yang},
  doi          = {10.1016/j.asoc.2022.108642},
  journal      = {Applied Soft Computing},
  pages        = {108642},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Splitting–merging-based automatic scheduling scheme for balancing energy consumption and task allocation in WSANs},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Particle swarm-differential evolution algorithm with
multiple random mutation. <em>ASOC</em>, <em>120</em>, 108640. (<a
href="https://doi.org/10.1016/j.asoc.2022.108640">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential evolution (DE) algorithm has attracted considerable attention because of its effectiveness and simplicity. However, previous studies have validated that DE still suffers from some limitations such as premature convergence and slow convergence especially dealing with multimodal optimization problems . To address these concerning issues, we propose an innovative optimization method named particle swarm-differential evolution algorithm with multiple random mutation (MRPSODE) in this paper. The proposed MRPSODE algorithm is based on multiple random mutation framework cooperating with mean particle swarm mutation strategy, DE/current-to-rand/1 mutation strategy and disturbance strategy. Firstly, we incorporate the modified mean particle swarm mutation strategy into DE algorithm to improve the global convergence ability. Secondly, DE/current-to-rand/1 mutation strategy is adopted to increase the population diversity and produce perturbations to avoid the algorithm trapping into a local optimum. Thirdly, we propose a disturbance strategy to help the population escape from local optima, so as to enhance the exploration ability. Finally, to ensure that the proposed algorithm can get satisfactory solutions with a fast convergence speed, we design a multiple random mutation framework, in which these three mutation strategies can effectively play their advantages and make up for the shortcomings of others. To evaluate the performance of the proposed algorithm, three different experiments are constructed on twenty-nine classical benchmark functions . The simulation results demonstrate that, (1) MRPSODE significantly outperforms conventional PSO and DE algorithms, (2) MRPSODE can achieve better performance than nine well-known DE variants in terms of solution quality and robustness, (3) MRPSODE is superior to nine latest heuristic-based algorithms. Furthermore, MRPSODE is successfully applied to seven typical constrained optimization problems and performs better than almost all compared methods.},
  archive      = {J_ASOC},
  author       = {Meijin Lin and Zhenyu Wang and Danfeng Chen and Weijia Zheng},
  doi          = {10.1016/j.asoc.2022.108640},
  journal      = {Applied Soft Computing},
  pages        = {108640},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Particle swarm-differential evolution algorithm with multiple random mutation},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Thresholds learning of three-way decisions in pairwise crime
linkage. <em>ASOC</em>, <em>120</em>, 108638. (<a
href="https://doi.org/10.1016/j.asoc.2022.108638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crime linkage is a difficult task and is of great significance to maintaining social security. It can be treated as a binary classification problem. Some crimes are difficult to determine whether they are serial crimes under the existing evidence, so the two-way decisions are easy to make mistakes for some case pairs. Here, the three-way decisions based on the decision-theoretic rough set are applied and its key issue is to determine thresholds by setting appropriate loss functions. However, sometimes the loss functions are difficult to obtain. In this paper, a method to automatically learn thresholds of the three-way decisions without the need to preset explicit loss functions is proposed. We simplify the loss function matrix according to the characteristic of crime linkage, re-express thresholds by loss functions, and investigate the relationship between overall decision cost and the size of the boundary region. The trade-off between the uncertainty of the boundary region and the decision cost is taken as the optimization objective . We apply multiple traditional classification algorithms as base classifiers , and employ real-world cases and some public datasets to evaluate the effect of our proposed method. The results show that the proposed method can reduce classification errors .},
  archive      = {J_ASOC},
  author       = {Yusheng Li and Xueyan Shao},
  doi          = {10.1016/j.asoc.2022.108638},
  journal      = {Applied Soft Computing},
  pages        = {108638},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Thresholds learning of three-way decisions in pairwise crime linkage},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An autonomous channel deep learning framework for blood
glucose prediction. <em>ASOC</em>, <em>120</em>, 108636. (<a
href="https://doi.org/10.1016/j.asoc.2022.108636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of blood glucose (BG) is conducive to avoiding abnormal blood glucose events and improving blood glucose management for Type 1 diabetes (T1D) patients. Recently, many deep learning-based methods for BG prediction have been proposed with encouraging results. However, most deep prediction methods do not consider the time-dependent scale discrepancy of different variables on BG dynamics and use the same time window for all input variables. This neglect will directly lead to information redundancy on short-term related variables or information incompletion on long-term related variables, which is not conducive to prediction accuracy. In this regard, we proposed an autonomous channel deep learning framework for personalized multivariate BG prediction. The autonomous channel network in the proposed framework learns representation from input variables with reasonable sampling periods and sequence lengths based on the domain knowledge of time-dependent scale between variables, thereby effectively avoiding input information redundancy and incompletion. The framework was evaluated on a clinical dataset, OhioT1DM Dataset, with experimental results in terms of root mean square error (RMSE) (18.930 ± 2.155 mg/dL) with the mean absolute relative difference (MARD) (9.218 ± 1.607\%) for prediction horizons (PH) = 30 min. These are the best-reported results for BG prediction when compared with other methods including the support vector regression (SVR), the long short-term memory network (LSTM), the dilated recurrent neural network (DRNN), the temporal convolutional networks (TCN), and the deep residual time-series forecasting (DRTF).},
  archive      = {J_ASOC},
  author       = {Tao Yang and Xia Yu and Ning Ma and Ruikun Wu and Hongru Li},
  doi          = {10.1016/j.asoc.2022.108636},
  journal      = {Applied Soft Computing},
  pages        = {108636},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An autonomous channel deep learning framework for blood glucose prediction},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-strategy firefly algorithm with selective ensemble for
complex engineering optimization problems. <em>ASOC</em>, <em>120</em>,
108634. (<a href="https://doi.org/10.1016/j.asoc.2022.108634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, more and more optimization techniques are used to deal with complex engineering optimization problems . Firefly algorithm (FA) inspired by the flash communication between fireflies, has been proven to be competitive with other swarm intelligence algorithms and has been widely applied to solve complex engineering optimization problems . However, FA has some defects in dealing with complex engineering optimization problems, such as the exploration and exploitation cannot be well balanced. Therefore, in order to achieve effective performance, the different characteristics of search strategies can be applied at different stages of the search process to achieve a balance between exploration and exploitation. In this paper, a multi-strategy firefly algorithm with selective ensemble (MSEFA) is proposed. In MSEFA, the algorithm has three novel search strategies with different characteristics in the strategy pool. In addition, an idea of selective ensemble is adopted to design a priority roulette selection method. The method can select suitable search strategies in different search stages and coordinate the balance of strategies so that better results can be obtained. Furthermore, a parameter adaptive transformation mechanism is designed to control the decreasing rate of step size α α . To verify the effectiveness of MSEFA, performance tests are conducted on the CEC 2013 and CEC 2019 test suites, after which MSEFA is used to solve four complex engineering optimization problems. Experimental results show that MSEFA has the best performance compared with other FA variants and other improved swarm intelligence algorithms . In addition, MSEFA also achieves the best results in dealing with four complex engineering optimization problems.},
  archive      = {J_ASOC},
  author       = {Hu Peng and Wenhui Xiao and Yupeng Han and Aiwen Jiang and Zhenzhen Xu and Mengmeng Li and Zhijian Wu},
  doi          = {10.1016/j.asoc.2022.108634},
  journal      = {Applied Soft Computing},
  pages        = {108634},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-strategy firefly algorithm with selective ensemble for complex engineering optimization problems},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiframe blind restoration with image quality prior.
<em>ASOC</em>, <em>120</em>, 108632. (<a
href="https://doi.org/10.1016/j.asoc.2022.108632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In dynamic environments, such as ground-based optic observations for space targets, anisotropic turbulence and random noise tend to produce different discriminate image degradations at every moment. These degradations severely reduce the quality of the target images and make restoration of these images very difficult. However, an inconsistent degradation implies that there is complementary information in such images. In this paper, a ranking network (Ranknet) is first proposed to ensure that input sequences have a consistent distribution upon degradation and squeeze the spatial distribution of the sample set. Then, an extraction-refinement neural network (ERnet) is proposed to extract complementary features and blindly reconstruct a clean image of the observation target. In ERnet, an extraction subnetwork (EN) uses 3D convolutions to extract discriminate features from multiframe input sequences, and a refinement subnetwork (RN) based on 2D convolution restores clean images by refining the effective features. In addition, a spatial–temporal attention module (STAM) is devoted to enhancing features through utilization of the high-quality features. Experimental results on the restorations of space target images and motion blur images confirm the superior performance of ERnet as compared with other state-of-the-art methods.},
  archive      = {J_ASOC},
  author       = {Peijian Zhu and Zhisheng Gao and Chunzhi Xie},
  doi          = {10.1016/j.asoc.2022.108632},
  journal      = {Applied Soft Computing},
  pages        = {108632},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multiframe blind restoration with image quality prior},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Binary artificial algae algorithm for feature selection.
<em>ASOC</em>, <em>120</em>, 108630. (<a
href="https://doi.org/10.1016/j.asoc.2022.108630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, binary versions of the Artificial Algae Algorithm (AAA) are presented and employed to determine the ideal attribute subset for classification processes. AAA is a recently proposed algorithm inspired by microalgae’s living behavior, which has not been consistently implemented to determine ideal attribute subset (feature selection) processes yet. AAA can effectively look into the feature space for ideal attributes combination minimizing a designed objective function. The proposed binary versions of AAA are employed to determine the ideal attribute combination that maximizes classification success while minimizing the count of attributes. The original AAA is utilized in these versions while its continuous spaces are restricted in a threshold using an appropriate threshold function after flattening them. In order to demonstrate the performance of the presented binary artificial algae algorithm model, an experimental study was conducted with the latest seven high-performance optimization algorithms . Several evaluation metrics are used to accurately evaluate and analyze the performance of these algorithms over twenty-five datasets with different difficulty levels from the UCI Machine Learning Repository. The experimental results and statistical tests verify the performance of the presented algorithms in increasing the classification accuracy compared to other state-of-the-art binary algorithms, which confirms the capability of the AAA algorithm in exploring the attribute space and deciding the most valuable features for classification problems.},
  archive      = {J_ASOC},
  author       = {Bahaeddin Turkoglu and Sait Ali Uymaz and Ersin Kaya},
  doi          = {10.1016/j.asoc.2022.108630},
  journal      = {Applied Soft Computing},
  pages        = {108630},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Binary artificial algae algorithm for feature selection},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A cluster-based data splitting method for small sample and
class imbalance problems in impact damage classification. <em>ASOC</em>,
<em>120</em>, 108628. (<a
href="https://doi.org/10.1016/j.asoc.2022.108628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From collected experimental data, a rapid and precise classification model for impact damage modes (IMDs) can be developed using machine learning (ML) techniques to evaluate impact resistant capabilities of reinforced concrete (RC) building walls . However, experimental data is often small and imbalanced, resulting in significant degradation and instability in classification performance. In this study, an imbalanced 4-classes dataset consisted of 240 missile impact tests is employed, with the most minor class containing only 10 samples. The paper aims to develop an automated classification model for IDMs, using a clustering-based within-class stratified splitting technique , named WICS, combining with a well-known oversampling technique, namely SMOTE-NC, that considers not only the between-class imbalance but also the within-class distribution to stabilize the classification performance. Four classifiers and five data splitting techniques are developed and implemented to address classification performance. We found that the support vector machine (SVM) classifier using WICS and SMOTE-NC achieves the best micro F1 score (0.821), Cohen’s kappa score (0.700), and AUC value (0.949) with highly stable performance. Friedman and Holm’s post-hoc statistical tests also confirm the outperformance of WICS+SMOTE-NC over other techniques.},
  archive      = {J_ASOC},
  author       = {Quoc Hoan Doan and Sy-Hung Mai and Quang Thang Do and Duc-Kien Thai},
  doi          = {10.1016/j.asoc.2022.108628},
  journal      = {Applied Soft Computing},
  pages        = {108628},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A cluster-based data splitting method for small sample and class imbalance problems in impact damage classification},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Prediction on recommender system based on bi-clustering and
moth flame optimization. <em>ASOC</em>, <em>120</em>, 108626. (<a
href="https://doi.org/10.1016/j.asoc.2022.108626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concerning the problems of weak scalability of traditional collaborative filtering recommender systems , a scalable recommender system based on bi-clustering and moth flame optimization algorithm is proposed. First of all, the users–items scoring matrix is filtered and cleaned in order to reduce the computational overhead, afterwards the bi-clustering data structures are constructed for the processed matrix, and the algorithm searches for bi-cluster containing the target user. Then, the results of bi-clustering are set as the initial population, and the moth flame optimization algorithm is applied to deeply optimize the similar users. Finally, the unrated items are predicted for the target user, and the recommendation list is generated for the target user. Validation experiments are carried on different scales of datasets; the results show that the proposed system achieves a good scalability, and also good recommendation performance.},
  archive      = {J_ASOC},
  author       = {Huan-huan Wu and Gang Ke and Yang Wang and Yu-Teng Chang},
  doi          = {10.1016/j.asoc.2022.108626},
  journal      = {Applied Soft Computing},
  pages        = {108626},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Prediction on recommender system based on bi-clustering and moth flame optimization},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hierarchical auxiliary deep neural network architecture
for large-scale indoor localization based on wi-fi fingerprinting.
<em>ASOC</em>, <em>120</em>, 108624. (<a
href="https://doi.org/10.1016/j.asoc.2022.108624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional application of deep neural networks (DNNs) to multi-building and multi-floor indoor localization is based on pure regression of three-dimensional location coordinates (e.g., longitude, latitude and altitude ( i.e. , floor height)), classification of location labels (e.g., building, floor and room information), or hybrid classification/regression of labels and coordinates (e.g., building and floor information and two-dimensional location coordinates), which, however, does not take into account an innate hierarchical auxiliary information (e.g., building-¿floor-¿location) of indoor localization data. Such conventional application of DNNs faces scalability issues in case of large-scale indoor localization where the numbers of buildings and floors are large. Inserting classification tasks as auxiliary networks into a regression neural network , we propose a new framework called a hierarchical auxiliary deep neural network (HADNN), which not only address the scalability issues with an increasing number of classes but also could further reduce the hierarchical information error. In HADNN, hierarchical auxiliary information of given data are provided and used during the training phase. As there are two possible hierarchical information cases in indoor localization data: (1) given only floors and (2) given both buildings and floors, we propose two architectures: one utilizing only floor information and the other taking both building and floor information. At test phase, HADNN predicts building, floor and location coordinate at the same time. Experimental results show that the architecture of HADNN achieves better performance of a coordinate regression task and require a smaller number of parameters than the pure two-dimensional location coordinates regression model. In addition, HADNN does not require the training data and coarse classes (e.g., building and floor information) at test phase while previous methods still require the training data to obtain location coordinates.},
  archive      = {J_ASOC},
  author       = {Jaehoon Cha and Enggee Lim},
  doi          = {10.1016/j.asoc.2022.108624},
  journal      = {Applied Soft Computing},
  pages        = {108624},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A hierarchical auxiliary deep neural network architecture for large-scale indoor localization based on wi-fi fingerprinting},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Recognition of occluded objects by slope difference
distribution features. <em>ASOC</em>, <em>120</em>, 108622. (<a
href="https://doi.org/10.1016/j.asoc.2022.108622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object recognition under occlusion is a key issue in computer vision . Since one can recognize an occluded object solely based on the shape, one ultimate goal of artificial intelligence is to find an automatic method that could recognize the object solely based on its shape with equal recognition accuracy. In this paper, slope difference distribution (SDD) is used to extract the shape features of the object as its sparse representation . One or several scale-invariant shape models are defined with the general SDD features for each shape class. The object is recognized based on the minimum distances between its detected SDD features and the SDD features of all the shape models. To increase the generality, we propose a two-dimensional SDD feature extraction method that computes the SDD features directly from the two-dimensional contours. Experimental results showed that the proposed object recognition method could recognize the object under significant occlusion robustly. It achieved 100\% recognition and retrieval accuracy on three public datasets, Kimia99, Kimia216 and MPEG-7. For the fine-grained object classification, the proposed method achieved 90.6\% accuracy on CUB-200-2011, which is also better than existing methods.},
  archive      = {J_ASOC},
  author       = {Zhenzhou Wang},
  doi          = {10.1016/j.asoc.2022.108622},
  journal      = {Applied Soft Computing},
  pages        = {108622},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Recognition of occluded objects by slope difference distribution features},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An imbalanced learning method by combining SMOTE with center
offset factor. <em>ASOC</em>, <em>120</em>, 108618. (<a
href="https://doi.org/10.1016/j.asoc.2022.108618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {SMOTE is a well-known oversampling method for learning on imbalanced datasets. However, it has the risk of introducing noisy instances and overfitting problems. In order to improve its performance, this paper proposes an oversampling method called SMOTE-COF, which is an improvement of SMOTE based on center offset factor. The SMOTE-COF method first removes noisy samples, then computes center offset factor to select sparsely distributed minority class samples. Furthermore, these samples are used to generate new minority class samples with other minority class instances distributed in the same sub-cluster by SMOTE. Comparative experiments on one simulated dataset and fourteen UCI datasets provide evidence that the SMOTE-COF can effectively reduce noisy samples, generate better minority classes, and improve classification performance for imbalanced datasets.},
  archive      = {J_ASOC},
  author       = {Dongxia Meng and Yujian Li},
  doi          = {10.1016/j.asoc.2022.108618},
  journal      = {Applied Soft Computing},
  pages        = {108618},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An imbalanced learning method by combining SMOTE with center offset factor},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Effluent ammonia nitrogen prediction using a phase space
reconstruction method combining pipelined recurrent wavelet neural
network. <em>ASOC</em>, <em>120</em>, 108602. (<a
href="https://doi.org/10.1016/j.asoc.2022.108602">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In wastewater treatment processes (WWTPs), the effluent ammonia nitrogen (NH 4 -N) concentration is a significant index to measure effluent quality. Recently, the soft computing methods have been widely used to measure effluent NH 4 -N concentration. However, the performance of soft computing method is closely related with its input variables, which is difficult to choose. As an alternative, the time series prediction method PSR-PRWNN is proposed, which combines phase space reconstruction (PSR) technique and pipelined recurrent wavelet neural network (PRWNN). Different from soft computing methods , the time series prediction method is a method which predicts the effluent NH 4 -N concentration by using its history data rather than other variables data. Firstly, the chaotic characteristics of effluent NH 4 -N time series is proved by using the correlation dimension method. Based on chaotic characteristics, the phase space of effluent NH 4 -N concentration is reconstructed by PSR technique. Then, the relationship model between inputs and output of the reconstructed phase space is established by PRWNN . Thirdly, the parameters of PRWNN are trained by an online gradient algorithm with adaptive learning rates . Finally, the experimental results indicate that the PSR-PRWNN can obtain better training results and prediction accuracy than other algorithms.},
  archive      = {J_ASOC},
  author       = {Yin Su and Cuili Yang and Junfei Qiao},
  doi          = {10.1016/j.asoc.2022.108602},
  journal      = {Applied Soft Computing},
  pages        = {108602},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Effluent ammonia nitrogen prediction using a phase space reconstruction method combining pipelined recurrent wavelet neural network},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PIFHC: The probabilistic intuitionistic fuzzy hierarchical
clustering algorithm. <em>ASOC</em>, <em>120</em>, 108584. (<a
href="https://doi.org/10.1016/j.asoc.2022.108584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical clustering techniques help in building a tree-like structure called dendrogram from the data points which can be used to find the closest related data objects. This paper presents a novel hierarchical clustering technique which considers intuitionistic fuzzy sets to deal with the uncertainty present in the data. Instead of using traditional hamming distance or Euclidean distance measure to find the distance between the data points, it employs the probabilistic Euclidean distance measure to propose a novel clustering approach which we term as ‘Probabilistic Intuitionistic Fuzzy Hierarchical Clustering (PIFHC) Algorithm’. The proposed PIFHC algorithm considers probabilistic weights from the data to measure the distances between the data points. Clustering results over UCI datasets show that our proposed PIFHC algorithm gives better cluster accuracies than its existing counterparts. PIFHC efficiently provides improvements of 1\%–3.5\% in the clustering accuracy compared to other fuzzy hierarchical clustering algorithms for most of the datasets. We further provide experimental results with the real-world car dataset and the Listeria monocytogenes dataset for mouse susceptibility to demonstrate the practical efficacy of the proposed algorithm. For Listeria datasets as well, proposed PIFHC records 1.7\% improvement against the state-of-the-art methods The dendrograms formed by the proposed PIFHC algorithm exhibits high cophenetic correlation coefficient with an improvement of 0.75\% over others. We provide various AGNES methods to update the distance between merged clusters in the proposed PIFHC algorithm.},
  archive      = {J_ASOC},
  author       = {Ayush K. Varshney and Pranab K. Muhuri and Q.M. Danish Lohani},
  doi          = {10.1016/j.asoc.2022.108584},
  journal      = {Applied Soft Computing},
  pages        = {108584},
  shortjournal = {Appl. Soft. Comput.},
  title        = {PIFHC: The probabilistic intuitionistic fuzzy hierarchical clustering algorithm},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adversarial multi-task learning with inverse mapping for
speech enhancement. <em>ASOC</em>, <em>120</em>, 108568. (<a
href="https://doi.org/10.1016/j.asoc.2022.108568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial Multi-Task Learning (AMTL) has demonstrated its promising capability of information capturing and representation learning , however, is hardly explored in speech enhancement. In this paper, we propose a novel adversarial multi-task learning with inverse mapping method for speech enhancement. Our method focuses on enhancing the generator’s capability of speech information capturing and representation learning . To implement this method, two extra networks (namely P and Q) are developed to establish the inverse mapping from the generated distribution to the input data domains. Correspondingly, two new loss functions (i.e., latent loss and equilibrium loss) are proposed for the inverse mapping learning and the enhancement model training with the original adversarial loss. Our method obtains the state-of-the-art performance in terms of speech quality (PESQ=2.93, CVOL=3.55). For speech intelligibility, our method can also obtain competitive performance (STOI=0.947). The experimental results demonstrate that our method can effectively improve speech representation learning and speech enhancement performance.},
  archive      = {J_ASOC},
  author       = {Yuanhang Qiu and Ruili Wang and Feng Hou and Satwinder Singh and Zhizhong Ma and Xiaoyun Jia},
  doi          = {10.1016/j.asoc.2022.108568},
  journal      = {Applied Soft Computing},
  pages        = {108568},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Adversarial multi-task learning with inverse mapping for speech enhancement},
  volume       = {120},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Corrigendum to “adaptive sliding mode control with
hysteresis compensation-based neuroevolution for motion tracking of
piezoelectric actuator” [appl. Soft comput. 115 (2022) 108257].
<em>ASOC</em>, <em>119</em>, 108734. (<a
href="https://doi.org/10.1016/j.asoc.2022.108734">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ASOC},
  author       = {Nguyen Ngoc Son and Cao Van Kien and Ho Pham Huy Anh},
  doi          = {10.1016/j.asoc.2022.108734},
  journal      = {Applied Soft Computing},
  pages        = {108734},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Corrigendum to “Adaptive sliding mode control with hysteresis compensation-based neuroevolution for motion tracking of piezoelectric actuator” [Appl. soft comput. 115 (2022) 108257]},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The evaluation of operational efficiencies of turkish
airports: An integrated spherical fuzzy AHP/DEA approach. <em>ASOC</em>,
<em>119</em>, 108620. (<a
href="https://doi.org/10.1016/j.asoc.2022.108620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The demand for air transport services has significantly increased around the globe, which has brought new investments in airports , which, in turn, requires in-depth efficiency analysis of these capital-intensive endeavors. This study examines the operational efficiencies of 46 Turkish civil airports from 2015 to 2018. We employ a novel hybrid methodology that combines Spherical Fuzzy Sets based Analytic Hierarchy Process (SFS-AHP) and Data Envelopment Analysis (DEA), which provides a solid basis for efficiency analysis. To this end, it can handle the hesitancy and uncertainty that the subjective evaluation process of input and output factors possess. Then, we use Self Organizing Maps (SOM), a machine learning method for clustering, to examine the effect of outlier airports on the efficiency scores. Finally, a posthoc analysis is conducted with Tobit regression model to assess the explanatory power of external factors on the efficiency scores, i.e., tourism potential, number of international flights, distance to the city center, population, public/private ownership, and age of airport. The findings show that 67.2\% of the Turkish airports operate below the optimal efficiency level, and 93.5\% of them should make considerable efforts to refine their operations by implementing managerial and structural changes to reduce input factors. The results also suggest that the airports located in high-density touristic areas achieve higher efficiency levels. Those relatively closer to the city center lead to more airport traffic, generating more revenues. Thus, both factors have a significant impact on efficiency scores. The study provides a novel efficiency analysis framework for airport operators and policy makers that helps them make informed decisions.},
  archive      = {J_ASOC},
  author       = {Mustafa K. Yilmaz and Ali Osman Kusakci and Mine Aksoy and Umit Hacioglu},
  doi          = {10.1016/j.asoc.2022.108620},
  journal      = {Applied Soft Computing},
  pages        = {108620},
  shortjournal = {Appl. Soft. Comput.},
  title        = {The evaluation of operational efficiencies of turkish airports: An integrated spherical fuzzy AHP/DEA approach},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning to optimize timetables for efficient transfers in
public transportation systems. <em>ASOC</em>, <em>119</em>, 108616. (<a
href="https://doi.org/10.1016/j.asoc.2022.108616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents the application of a learning-based optimization method to solve the Bus Synchronization Problem , a relevant problem in public transportation systems. The problem consists in synchronizing the timetable of buses to optimize the transfer of passengers between bus lines. A new problem model is proposed, extending previous formulations in the literature, and solved using Virtual Savant. Virtual Savant is a novel soft computing method inspired by the Savant Syndrome that combines machine learning and optimization to solve complex real-world problems in a massively parallel way. The proposed methodology is validated and evaluated over a set of synthetic and realistic instances based on the public transportation system of Montevideo, Uruguay, and compared against a reference evolutionary algorithm and the current solution defined by the city authorities. The main results indicate that Virtual Savant is able to compute accurate solutions and outperform baseline results in eleven out of fifteen realistic instances. This is the first reported research applying Virtual Savant to a problem with a high synergy between its decision variables. The obtained results suggest that it is a suitable tool for solving this kind of optimization problems .},
  archive      = {J_ASOC},
  author       = {Renzo Massobrio and Sergio Nesmachnow and Jonathan Muraña and Bernabé Dorronsoro},
  doi          = {10.1016/j.asoc.2022.108616},
  journal      = {Applied Soft Computing},
  pages        = {108616},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Learning to optimize timetables for efficient transfers in public transportation systems},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A variable neighborhood search based algorithm and game
theory models for green supply chain design. <em>ASOC</em>,
<em>119</em>, 108615. (<a
href="https://doi.org/10.1016/j.asoc.2022.108615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increase in the volume of greenhouse gases and pollutants, supply chain managers have sought to design and set up networks that pay special attention to environmental factors besides the economic aspects. In this research, a three-level supply chain network is considered including one manufacturer, several retailers and several customers. Greenhouse gas emissions as an environmental issue, the dependence of demand on the selling price of products and cooperative advertising have been examined to design this network. Also, several transportation systems and production methods with different environmental effects and different costs have been considered. The problem has been modeled by both the general and advertising cost classification approaches . Each model has been linearized by McCormick and sequential linear programming methods, and in each approach, Stackelberg, Nash and cooperative games have been used to determine the relationship between members of the supply chain. Finally, an algorithm has been proposed from a combination of variable neighborhood search algorithm and mathematical modeling and after adjusting its parameters by Taguchi statistical method, Stackelberg, Nash and cooperative games have been implemented on it. The results of linearization methods and the meta-heuristic algorithm show that the profit of the manufacturers, retailers and the whole supply chain depends on the type of the game selected. The profit of the whole supply chain is greater in cooperative conditions than in non-cooperative conditions, and in non-cooperative games, the final profit of the manufacturer will be greater in Stackelberg game .},
  archive      = {J_ASOC},
  author       = {Habibeh Amini and Kamran Kianfar},
  doi          = {10.1016/j.asoc.2022.108615},
  journal      = {Applied Soft Computing},
  pages        = {108615},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A variable neighborhood search based algorithm and game theory models for green supply chain design},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic generation of textual descriptions in data-to-text
systems using a fuzzy temporal ontology: Application in air quality
index data series. <em>ASOC</em>, <em>119</em>, 108612. (<a
href="https://doi.org/10.1016/j.asoc.2022.108612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we present a model based on computational intelligence and natural language generation for the automatic generation of textual summaries from numerical data series, aiming to provide insights which help users to understand the relevant information hidden in the data. Our model includes a fuzzy temporal ontology with temporal references which addresses the problem of managing imprecise temporal knowledge, which is relevant in data series. We fully describe a real use case of application in the environmental information systems field, providing linguistic descriptions about the air quality index (AQI), which is a very well-known indicator provided by all meteorological agencies worldwide. We consider two different data sources of real AQI data provided by the official Galician (NW Spain) Meteorology Agency: (i) AQI distribution in the stations of the meteorological observation network and (ii) time series which describe the state and evolution of the AQI in each meteorological station. Both application models were evaluated following the current standards and good practices of manual human expert evaluation of the Natural Language Generation field. Assessment results by two experts meteorologists were very satisfactory, which empirically confirm that the proposed textual descriptions fit this type of data and service both in content and layout.},
  archive      = {J_ASOC},
  author       = {Andrea Cascallar-Fuentes and Javier Gallego-Fernández and Alejandro Ramos-Soto and Anthony Saunders-Estévez and Alberto Bugarín-Diz},
  doi          = {10.1016/j.asoc.2022.108612},
  journal      = {Applied Soft Computing},
  pages        = {108612},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Automatic generation of textual descriptions in data-to-text systems using a fuzzy temporal ontology: Application in air quality index data series},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detection of COVID19 from x-ray images using multiscale deep
convolutional neural network. <em>ASOC</em>, <em>119</em>, 108610. (<a
href="https://doi.org/10.1016/j.asoc.2022.108610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Coronavirus disease 2019 (COVID19) pandemic has led to a dramatic loss of human life worldwide and caused a tremendous challenge to public health. Immediate detection and diagnosis of COVID19 have lifesaving importance for both patients and doctors. The availability of COVID19 tests increased significantly in many countries, thereby provisioning a limited availability of laboratory test kits Additionally, the Reverse Transcription-Polymerase Chain Reaction (RT-PCR) test for the diagnosis of COVID 19 is costly and time-consuming. X-ray imaging is widely used for the diagnosis of COVID19. The detection of COVID19 based on the manual investigation of X-ray images is a tedious process. Therefore, computer-aided diagnosis (CAD) systems are needed for the automated detection of COVID19 disease. This paper proposes a novel approach for the automated detection of COVID19 using chest X-ray images. The Fixed Boundary-based Two-Dimensional Empirical Wavelet Transform (FB2DEWT) is used to extract modes from the X-ray images. In our study, a single X-ray image is decomposed into seven modes. The evaluated modes are used as input to the multiscale deep Convolutional Neural Network (CNN) to classify X-ray images into no-finding, pneumonia , and COVID19 classes. The proposed deep learning model is evaluated using the X-ray images from two different publicly available databases, where database A consists of 1225 images and database B consists of 9000 images. The results show that the proposed approach has obtained a maximum accuracy of 96\% and 100\% for the multiclass and binary classification schemes using X-ray images from dataset A with 5-fold cross-validation (CV) strategy. For dataset B, the accuracy values of 97.17\% and 96.06\% are achieved using multiscale deep CNN for multiclass and binary classification schemes with 5-fold CV. The proposed multiscale deep learning model has demonstrated a higher classification performance than the existing approaches for detecting COVID19 using X-ray images.},
  archive      = {J_ASOC},
  author       = {Neha Muralidharan and Shaurya Gupta and Manas Ranjan Prusty and Rajesh Kumar Tripathy},
  doi          = {10.1016/j.asoc.2022.108610},
  journal      = {Applied Soft Computing},
  pages        = {108610},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Detection of COVID19 from X-ray images using multiscale deep convolutional neural network},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A discrete chaotic jaya algorithm for optimal preventive
maintenance scheduling of power systems generators. <em>ASOC</em>,
<em>119</em>, 108608. (<a
href="https://doi.org/10.1016/j.asoc.2022.108608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main role of the optimal Generator Maintenance Scheduling (GMS) problem in power systems is to develop an optimal preventive maintenance scheduling of the generation part units. An optimal GMS provides power systems with higher operational reliability, extends the generators lifetime and reduces the cost of generators maintenance. The GMS problem is formulated as an optimisation problem . This problem should satisfy both load’s power demand and workforce constraints with ensuring the reliability of power systems at economical operation cost. The GMS problem has been studied for many years when exact mathematical methods have been used in the past to reach exact solutions for small-scale problems. However, these conventional mathematical approaches have many limitations and they suffer from unreasonable computational efforts as system dimension increases. Traditional approximate methods have been adopted to overcome the limitations of exact methods for medium-scale power systems. However, they provide approximate solutions and they require a large computational effort for wide-area systems of big dimensions. Recently, modern methods based on metaheuristics optimisation have taken a long part to solve the GMS problem and to overcome the limitations of approximate methods. In this paper, a proposed Discrete Chaotic Jaya Optimisation (DCJO) algorithm is employed to perform the preventive maintenance scheduling of electric power systems generators. The proposed algorithm is based on a cooperation between the discrete Jaya optimisation algorithm and a proposed move rule based on Chaotic Local Search (CLS) technique to improve both exploration and exploitation phases. The GMS problem is modelled based on the reliability criterion of an objective function of a sum of the squares of the reserves of generation. The optimisation process is performed through minimising an evaluation function of a weighted sum of the objective function and the penalty function for violations of the constraints. The proposed approach has been tested in a 21-unit test system over a planned horizon of 52 weeks in which the peak load is 4739 MW and the maximum generation is 5688 MW and there is a total number of 35 workforce available per week to perform the maintenance tasks. The proposed method has been compared through several statistical tests with recent algorithms of the related works. The obtained results show the effectiveness of the proposed algorithm for solving the GMS problem as compared to other recent algorithms. This approach can be relied at the present upon to solve maintenance scheduling problems of generation units in power systems.},
  archive      = {J_ASOC},
  author       = {Soufiane Belagoune and Noureddine Bali and Karim Atif and Hilal Labdelaoui},
  doi          = {10.1016/j.asoc.2022.108608},
  journal      = {Applied Soft Computing},
  pages        = {108608},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A discrete chaotic jaya algorithm for optimal preventive maintenance scheduling of power systems generators},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A two-archive model based evolutionary algorithm for
multimodal multi-objective optimization problems. <em>ASOC</em>,
<em>119</em>, 108606. (<a
href="https://doi.org/10.1016/j.asoc.2022.108606">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal multi-objective optimization (MMO) can offer more elegant solutions and provide diverse decisions to decision-makers in real world optimization problems . Many multimodal evolutionary mechanisms have been proposed to explore and exploit two solution spaces (i.e. decision space and objective space) in recent years. However, most existing methods only use single evolutionary operator to generate offsprings and ignore the advantage of using hybrid evolutionary algorithm . Moreover, it is still a great challenge to balance the effectiveness and efficiency simultaneously in the evolutionary process of MMO. In view of this, an efficient Two-Archive model based multimodal evolutionary algorithm is proposed in this paper. Two parallel offspring generation mechanisms based on competitive particle swarm optimizer and differential evolution are applied to expand two solution spaces with different evolutionary requirements. Moreover, niching local search scheme and reverse vector mutation strategy play roles in achieving better convergence and diversity. Finally, 22 MMO test problems are used to validate the superiority of the proposed method by comparing it with 5 state-of-the-art MMO algorithms. The proposed method is also expanded to solve 9 feature selection problems for validating the effectiveness of the proposed method on real world applications .},
  archive      = {J_ASOC},
  author       = {Yi Hu and Jie Wang and Jing Liang and Yanli Wang and Usman Ashraf and Caitong Yue and Kunjie Yu},
  doi          = {10.1016/j.asoc.2022.108606},
  journal      = {Applied Soft Computing},
  pages        = {108606},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A two-archive model based evolutionary algorithm for multimodal multi-objective optimization problems},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Joint entity and relation extraction with position-aware
attention and relation embedding. <em>ASOC</em>, <em>119</em>, 108604.
(<a href="https://doi.org/10.1016/j.asoc.2022.108604">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The joint extraction of entities and relations is an important task in natural language processing , which aims to obtain all relational triples in plain text. However, few existing methods excel in solving the overlapping triple problem. Moreover, most methods ignore the position and order of the words in the entity in the entity extraction process, which affects the performance of triples extraction. To solve these problems, a joint extraction model with position-aware attention and relation embedding is proposed, named PARE-Joint. The proposed model first recognizes the subjects, and then uses the subject and relation guided attention network to learn the enhanced sentence representation and determine the corresponding objects. In this way, the interaction between entities and relations is captured, and the overlapping triple problem can be better resolved. In addition, taking into account the important role of word order in the entity for triple extraction, the position-aware attention mechanism is used to extract the subjects and the objects in the sentences, respectively. The experimental results demonstrate that our model can solve the overlapping triple problem more effectively and outperform other baselines on four public datasets.},
  archive      = {J_ASOC},
  author       = {Tiantian Chen and Lianke Zhou and Nianbin Wang and Xirui Chen},
  doi          = {10.1016/j.asoc.2022.108604},
  journal      = {Applied Soft Computing},
  pages        = {108604},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Joint entity and relation extraction with position-aware attention and relation embedding},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-source and multivariate ozone prediction based on
fuzzy cognitive maps and evidential reasoning theory. <em>ASOC</em>,
<em>119</em>, 108600. (<a
href="https://doi.org/10.1016/j.asoc.2022.108600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ozone prediction, a key role for ozone pollution control, is facing the following challenges, i.e., the complex evolution trend of ozone, the cross-interference phenomena between ozone and other pollutants, and the low-quality monitoring data. To overcome the above challenges, we propose a multi-source and multivariate ozone prediction model based on fuzzy cognitive maps (FCMs) and evidential reasoning theory from the perspective of spatio-temporal fusion, termed as ERC-FCM. In this framework, an FCM-based prediction model is introduced to solve the ozone forecasting problem. Inspired by the multivariate time series forecasting, a multivariate ozone prediction problem is modeled as an FCM learned by the real-coded genetic algorithm , in which each node denotes a variable (pollutant). Thus, both the complex evolution trend of ozone and the cross-interference phenomena can be reflected by the FCM. Further, we propose an ensemble theoretical framework based on evidence reasoning theory and the matrix 2 norm. This theoretical framework relieves the negative factors from the low-quality monitoring data and improves the prediction accuracy when facing multi-source and multivariate time series . The performance of ERC-FCM is validated on two real-world datasets. The experimental results demonstrate that our method yields the best prediction performance by comparison with the other classical FCM-based methods on mean absolute error (MAE), mean square error (MSE), and root mean square error (RMSE). In addition, the Friedman test and Nemenyi test show that ERC-FCM gets relatively better prediction accuracy than other models.},
  archive      = {J_ASOC},
  author       = {Xiaoqian Liu and Yingjun Zhang and Jingping Wang and Hua Huang and Hui Yin},
  doi          = {10.1016/j.asoc.2022.108600},
  journal      = {Applied Soft Computing},
  pages        = {108600},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-source and multivariate ozone prediction based on fuzzy cognitive maps and evidential reasoning theory},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Decision-theoretic rough sets based automated scheme for
object and background classification in unevenly illuminated images.
<em>ASOC</em>, <em>119</em>, 108596. (<a
href="https://doi.org/10.1016/j.asoc.2022.108596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of classification of object and background in unevenly illuminated images using Decision-Theoretic Rough Set (DTRS) framework. The proposed scheme employs adaptive windowing technique to partition the image into different windows. Thereafter, the proposed DTRS based method is applied on each window to find out the optimal threshold that is used for classification of the window. Determination of optimal threshold of a given window is dependent on the optimal granule size used for the window. The problem of determination of optimal granule size and optimal threshold is cast in optimization framework. The optimal threshold obtained for each window is used to classify the window and the classification of the entire image is the union of classifications over all the windows. Manual tuning of parameters is not required to determine the optimal threshold. The proposed scheme is tested on different images considered from Berkeley image database. The performance of the proposed scheme is compared with other granular and non-granular computing based schemes. Evaluation of different quantitative measures demonstrates the improved performance of the proposed schemes over others.},
  archive      = {J_ASOC},
  author       = {Mamata Wagh and Pradipta Kumar Nanda},
  doi          = {10.1016/j.asoc.2022.108596},
  journal      = {Applied Soft Computing},
  pages        = {108596},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Decision-theoretic rough sets based automated scheme for object and background classification in unevenly illuminated images},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Micro-expression recognition using 3D DenseNet fused
squeeze-and-excitation networks. <em>ASOC</em>, <em>119</em>, 108594.
(<a href="https://doi.org/10.1016/j.asoc.2022.108594">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Micro-expression is a kind of facial feature that reflects the most real emotional state hidden in the human heart. Most of the existing micro-expression recognition methods are based on manual feature extraction of subtle movements of facial muscles. Due to its short duration and weak intensity, the accurate identification of micro-expression remains a challenging task. This paper investigates micro-expression recognition based on deep learning methods and proposes a three-dimensional SE-DenseNet architecture, which fused Squeeze-and-Excitation Networks with a 3D DenseNet and can automatically integrate the spatiotemporal features extracted from each video to increase the weight of valid feature maps. The proposed architecture first obtains apex frames from each video for the most obvious facial muscle movements and then amplifies facial muscle movements using Euler video magnification to significantly alleviate the issue of small sample size and weak intensity of micro-expression recognition. Finally, the pre-processed videos are fed into the 3D SE-DenseNet for further feature extraction as well as to perform micro-expression classification. Experiments are performed on three public datasets. Our best model obtains an overall accuracy of 95.12\%, 92.96\%, and 82.74\% on SMIC, CAS(ME) 2 and CASME-II dataset, respectively. The experimental results show that the proposed methods can well describe the considerable details of micro-expression and outperform most of the state-of-the-art methods on three public datasets.},
  archive      = {J_ASOC},
  author       = {Linqin Cai and Hao Li and Wei Dong and Haodu Fang},
  doi          = {10.1016/j.asoc.2022.108594},
  journal      = {Applied Soft Computing},
  pages        = {108594},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Micro-expression recognition using 3D DenseNet fused squeeze-and-excitation networks},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Multi-objective cooperative coevolution algorithm with a
master–slave mechanism for seru production. <em>ASOC</em>, <em>119</em>,
108593. (<a href="https://doi.org/10.1016/j.asoc.2022.108593">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Seru Production is usually used as a creative mode of production in electronics. It involves two NP-hard subproblems , namely seru formation and seru scheduling. To obtain the optimal global solution of multi-objective Seru Production, we develop a multi-objective cooperative coevolution algorithm with a Master–Slave mechanism. In the proposed algorithm, a cooperative mechanism is used to simultaneously optimize seru formation and seru scheduling. In addition, three usually non-dominated solutions are defined and used in the cooperative mechanism to improve the quality of non-dominated solutions, which takes more computational time. To reduce the computational time, three seru scheduling/ seru formation populations evolve in parallel with the assistance of the three corresponding non-dominated seru formations/ seru schedulings. To further improve the quality of non-dominated solutions, we propose a Master–Slave​ mechanism. The Master population is designed to store the current non-dominated solutions and communicates with three Slave populations. Extensively tested experiments show that the proposed algorithm outperforms existing algorithms for multi-objective Seru Production.},
  archive      = {J_ASOC},
  author       = {Xiaolong Li and Yang Yu and Min Huang},
  doi          = {10.1016/j.asoc.2022.108593},
  journal      = {Applied Soft Computing},
  pages        = {108593},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-objective cooperative coevolution algorithm with a Master–Slave mechanism for seru production},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimization and assessment of blade tip timing probe layout
with concrete autoencoder and reconstruction error. <em>ASOC</em>,
<em>119</em>, 108590. (<a
href="https://doi.org/10.1016/j.asoc.2022.108590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blade tip timing (BTT) is a promising non-contact measurement method for blade vibration monitoring. The limited number of probes leads to the inherent under-sampled problem of BTT signal. The quality of the analysis result of under-sampled signal depends on the probe layout. However, the application of existing probe layout optimization methods requires domain knowledge about blade vibration . Additionally, the lack of comparisons of probe layouts generated by different probe layout optimization methods makes it difficult to evaluate the performance of different methods. In this paper, we proposed a new probe layout optimization method based on a concrete autoencoder to reduce the reliance on the domain knowledge. The probe layouts were compared using an independently trained reconstructor in the time domain. And the spectral distance was defined to evaluate the performance of different probe layouts in the frequency domain. The validation results showed that the proposed method has superior time domain reconstruction performance and decent frequency domain reconstruction performance compared to other methods. The most informative and representative probe layout can be effectively selected by the proposed method.},
  archive      = {J_ASOC},
  author       = {Zeng-Kun Wang and Zhi-Bo Yang and Shu-Ming Wu and Hao-Qi Li and Shao-Hua Tian and Xue-Feng Chen},
  doi          = {10.1016/j.asoc.2022.108590},
  journal      = {Applied Soft Computing},
  pages        = {108590},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Optimization and assessment of blade tip timing probe layout with concrete autoencoder and reconstruction error},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards motion planning of humanoids using a fuzzy embedded
neural network approach. <em>ASOC</em>, <em>119</em>, 108588. (<a
href="https://doi.org/10.1016/j.asoc.2022.108588">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research work focuses on navigational strategy of humanoid robots in complex environments using a fuzzy embedded neural network based controller. The obstacle distances are measured from robot’s current position and referred as front obstacle distance, right obstacle distance and left obstacle distance. These obstacle distances are served as input variables to the neural network model , and target angle is obtained as output parameter. The target angle obtained from neural network is fed to the Mamdani fuzzy system along with the obstacle distances as input variables to obtain the effective target angle for the humanoid robot. A Petri-net controller is embedded with developed neuro-fuzzy controller to perform dynamic path analysis in complex workspaces Single as well as multiple humanoid robots are used to analyze simulation and experimental navigation in different complex environments using developed neuro-fuzzy-petri-net controller. Various simulations are carried out using V-REP simulation software and similar scenario as per simulation is developed under laboratory conditions for various experimental navigation. The results from both the scenarios are related and are found to be in good covenant with each other having permissible range of errors. Simulation and experimental results in relation to navigational parameters shows the robustness of the developed controller. Surface plots and contour plots developed from the designed controller shows the effectiveness and efficacy in achieving global path during motion planning through optimizing target angle. To validate the results and to find out the effectiveness, the developed controller is compared with existing techniques such as IDQ and substantial progress of 16.66\% in relation to path length is observed.},
  archive      = {J_ASOC},
  author       = {Manoj Kumar Muni and Dayal R. Parhi and Priyadarshi Biplab Kumar and Chinmaya Sahu and Saroj Kumar},
  doi          = {10.1016/j.asoc.2022.108588},
  journal      = {Applied Soft Computing},
  pages        = {108588},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Towards motion planning of humanoids using a fuzzy embedded neural network approach},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feasible–infeasible two-population genetic algorithm to
evolve dungeon levels with dependencies in barrier mechanics.
<em>ASOC</em>, <em>119</em>, 108586. (<a
href="https://doi.org/10.1016/j.asoc.2022.108586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a search-based solution for the generation of dungeon levels with barrier mechanics and the placement of challenges and rewards in the levels’ rooms. The barrier is a feature that temporarily blocks the player’s progression, where one or more keys will unblock the way. The placement of barriers and keys must satisfy some constraints since the player cannot be stuck during the gameplay. Feasible–Infeasible Two-Population Genetic Algorithm (FI2Pop GA) evolves a grid representation that handles the level dependencies of barrier mechanics. We propose the concept of ordered regions to control the availability of keys better in the levels and procedures to create levels with more diversity in their contents. Data to measure the variety of the generated content is collected based on map linearity, mission linearity, leniency, and path redundancy. We analyzed our results through expressive range analysis, and it shows that our approach can generate a wide variety of playable levels.},
  archive      = {J_ASOC},
  author       = {Breno M.F. Viana and Leonardo T. Pereira and Claudio F.M. Toledo and Selan R. dos Santos and Silvia M.D.M. Maia},
  doi          = {10.1016/j.asoc.2022.108586},
  journal      = {Applied Soft Computing},
  pages        = {108586},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Feasible–Infeasible two-population genetic algorithm to evolve dungeon levels with dependencies in barrier mechanics},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feature fusion and kernel selective in inception-v4 network.
<em>ASOC</em>, <em>119</em>, 108582. (<a
href="https://doi.org/10.1016/j.asoc.2022.108582">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep learning has been developed very quickly, and related research has shown a blossoming scene. Inception-v4 is a wide and deep network with good classification performance. The network structure is very complex, with convolution operations of different sizes, but there are two limitations: the inability to adaptively select the convolution kernel according to the characteristics of the image and the feature extraction from the high-level layer is not strong. This paper focuses on the investigation on the Inception-v4 model and has made several improvements. The improved Inception-v4 model is named BeIn-v4, which integrates the ideas of the Selective Kernel Network (SKNet) into the Inception-v4 network, and adjusts the network structure to achieve improvements. A number of comparative experiments have been carried out on the network before and after the improvements. The experimental results show that BeIn-v4 can obtain better classification results on the tested image datasets than Inception-v4.},
  archive      = {J_ASOC},
  author       = {Feng Chen and Jiangshu Wei and Bing Xue and Mengjie Zhang},
  doi          = {10.1016/j.asoc.2022.108582},
  journal      = {Applied Soft Computing},
  pages        = {108582},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Feature fusion and kernel selective in inception-v4 network},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Renewable sources-based automatic load frequency control of
interconnected systems using chaotic atom search optimization.
<em>ASOC</em>, <em>119</em>, 108574. (<a
href="https://doi.org/10.1016/j.asoc.2022.108574">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an improved form of chaotic based atom search optimization (IASO) algorithm by adapting one-dimensional (1D) chaotic map (tent, sine and logistic) to improve the search ability by intensifying the exploration and exploitation phase. The IASO avoids premature convergence and trapping into local optima. Initially, the proposed IASO is validated using a classical benchmark function and its performance is compared with ASO algorithm. Test results indicate that the proposed algorithm outperforms in terms of mean, standard deviation, and best values. Further, the proposed technique is used to design the parameters of fractional-order proportional integral derivative controller for automatic load frequency control (ALFC) of multi-area, multi-source hybrid power system (HPS) by minimizing the integral time absolute error. The results obtained show that the proposed control scheme improves the frequency response of the system by 48\%, 70\%, 15\% and 69\% in terms of settling time, peak undershoot, steady state error value and control effort, respectively compared to ASO. Moreover, the sensitivity analysis is carried out by considering ± ± 25\% variation in HPS parameters and the real-time applicability is tested with Malaysian meteorological data of solar radiation and wind speed variation. These analysis indicates that the transient oscillations are damped out with minimum settling time and the system regains to stable operating conditions. Further, the evaluation of transient and steady-state performance indices shows that the tent map-based IASO is found to be more efficient for obtaining the optimal solution in solving the ALFC problems. In addition, the stability of the system is analysed by approximating the fractional-order transfer function based on the oustaloup filter in frequency domain.},
  archive      = {J_ASOC},
  author       = {Andrew Xavier Raj Irudayaraj and Noor Izzri Abdul Wahab and Manoharan Premkumar and Mohd Amran Mohd Radzi and Nasri Bin Sulaiman and Veerapandiyan Veerasamy and Rizwan A. Farade and Mohammad Zohrul Islam},
  doi          = {10.1016/j.asoc.2022.108574},
  journal      = {Applied Soft Computing},
  pages        = {108574},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Renewable sources-based automatic load frequency control of interconnected systems using chaotic atom search optimization},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AutoIHCNet: CNN architecture and decision fusion for
automated HER2 scoring. <em>ASOC</em>, <em>119</em>, 108572. (<a
href="https://doi.org/10.1016/j.asoc.2022.108572">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, the automated scoring of prognostic marker Human Epidermal Growth Factor Receptor-2 (HER2) stained tissue sample is presented. The HER2 challenge dataset is used for the study to score the sample under observation. Two CNN networks viz. the Xception network in a transfer learning framework and a proposed simpler CNN architecture AutoIHCNet , with three convolution blocks and dense layers, are used in this study considering 228 × 288 × 3 input shape. The training parameters viz. optimizers, learning rate, and the number of epochs are varied to have 48 sets of experiments to choose the best training settings. From the whole slide image, representative region of interest (ROI) images are extracted. One ROI image is divided into eight sub-image patches. 2400 patches from 300 training ROI images were extracted and out of these 2130 patches are used for training based on stained tissue regions available in the patch. Statistical decision fusion using mode is performed for collective voting from eight sub-image patches to label the sample image under observation. 100 test images are used from different cases, to avoid any bias, to assess the models. The proposed deep learning architectures are also compared with the ImmunoMembrane application. Average test accuracy and Pearson’s correlation coefficient are used to assess the performance of automated approaches compared to ground truth. The performance is assessed in terms of improvement in accuracy from the patch-based score to ROI image-based score as well as final comparison for image-based comparison with ImmunoMembrane on 100 separate test images. The architectures, Xception network as transfer learning and AutoIHCNet , with statistical decision fusion, improved the accuracy from 95\% to 97\% and 96\% to 98\% respectively for the patch-based score to ROI image-based score whereas, the state-of-the-art ImmunoMembrane application shows 87\% accuracy for the ROI image-based score.},
  archive      = {J_ASOC},
  author       = {Suman Tewary and Sudipta Mukhopadhyay},
  doi          = {10.1016/j.asoc.2022.108572},
  journal      = {Applied Soft Computing},
  pages        = {108572},
  shortjournal = {Appl. Soft. Comput.},
  title        = {AutoIHCNet: CNN architecture and decision fusion for automated HER2 scoring},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). COPRAS method based on interval-valued hesitant fermatean
fuzzy sets and its application in selecting desalination technology.
<em>ASOC</em>, <em>119</em>, 108570. (<a
href="https://doi.org/10.1016/j.asoc.2022.108570">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper firstly introduces the idea of interval-valued hesitant Fermatean fuzzy set (IVHFFS). It is one of the significant theoretical and practical features, which derive from the integration of hesitant Fermatean fuzzy set (HFFSs) and interval number. In this study, we firstly present the basic concept, various operations and distance measures of IVHFFSs. Then, based on the operations of IVHFFSs, some aggregation operators (AOs) are proposed for aggregating the interval-valued hesitant Fermatean fuzzy information. Furthermore, some elegant properties of these operators are discussed in detail. To show the applicability, we discuss a decision analysis process on IVHFFSs environment with the help of conventional complex proportional assessment (COPRAS) methodology. Finally, the selection process of desalination technology for treating the feed water is also taken to validate the developed decision analysis procedure on IVHFFSs. This paper considers various criteria and sub-criteria in the assessment procedure and determines the most significant criteria influencing the desalination technology selection process are technical, social, environment and economic criteria, with significance weights of 0.3972, 0.289, 0.1653 and 0.1486, respectively. The work concludes that the reverse osmosis (RO) is the suitable desalination technology under the considered criteria followed by electrodialysis (ED), and multiple-effect distillation (MED). Moreover, the sensitivity investigation and comparative study are presented to verify the robustness and stability of the proposed method. The findings of this study show that the proposed model can suggest more feasible performance while facing several input uncertainties and influencing factors.},
  archive      = {J_ASOC},
  author       = {Arunodaya Raj Mishra and Peide Liu and Pratibha Rani},
  doi          = {10.1016/j.asoc.2022.108570},
  journal      = {Applied Soft Computing},
  pages        = {108570},
  shortjournal = {Appl. Soft. Comput.},
  title        = {COPRAS method based on interval-valued hesitant fermatean fuzzy sets and its application in selecting desalination technology},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-neighborhood simulated annealing for personalized user
project planning. <em>ASOC</em>, <em>119</em>, 108566. (<a
href="https://doi.org/10.1016/j.asoc.2022.108566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective decision support systems are very useful management tools in many applied domains. However, such systems are still scarce or even missing in social and medico-social establishments. This study investigates the personalized user project planning problem in French social and medico-social establishments, whose purpose is to optimize the assignment of multi-featured activities and resources to a group of residents or users subject to complex imperative constraints. We focus on the design and implementation of an innovative multi-neighborhood local optimization algorithm that serves as the key component of a decision support system for these establishments. We assess the effectiveness of the proposed approach on realistic data and show comparisons with other approaches including mathematical programming and greedy search.},
  archive      = {J_ASOC},
  author       = {Yinuo Li and Jin-Kao Hao},
  doi          = {10.1016/j.asoc.2022.108566},
  journal      = {Applied Soft Computing},
  pages        = {108566},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-neighborhood simulated annealing for personalized user project planning},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Protein folding in 3D lattice HP model using a combining
cuckoo search with the hill-climbing algorithms. <em>ASOC</em>,
<em>119</em>, 108564. (<a
href="https://doi.org/10.1016/j.asoc.2022.108564">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A protein is a linear chain containing a set of amino acids, which folds on itself to create a specific native structure, called the minimum energy conformation. It is the native structure that determines the functionality of each protein. The Protein Folding Problem (PFP) remains one of the most strenuous computational and chemical biology. The principal challenge of PFP is to predict the optimal conformation of a given protein by considering only its amino acid sequence. Since the conformational space contains a colossal number of possibilities, even when considering short sequences, different simplified models have been developed and applied to make the PFP less complex. Experimental methods can be used to predict the native structure of small and specific proteins. Given the limitations of experimental methods, in the last few years many computational approaches have been proposed to solve the PFP. Based on the folding process , the PFP was formulated as an optimization problem . They are based on simplified lattice models such as the hydrophobic-polar model. In this paper, we present a new Hybrid Cuckoo Search Algorithm (HCSA) to solve the 3D-HP protein folding optimization problem . Our proposed algorithm consists of combining the Cuckoo Search Algorithm (CSA) with the Hill Climbing (HC) algorithm. Simulation results on different benchmark sequences are presented and compared to the state-of-the-art algorithms.},
  archive      = {J_ASOC},
  author       = {Nabil Boumedine and Sadek Bouroubi},
  doi          = {10.1016/j.asoc.2022.108564},
  journal      = {Applied Soft Computing},
  pages        = {108564},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Protein folding in 3D lattice HP model using a combining cuckoo search with the hill-climbing algorithms},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhanced sine cosine algorithm using opposition learning,
adaptive evolution and neighborhood search strategies for multivariable
parameter optimization problems. <em>ASOC</em>, <em>119</em>, 108562.
(<a href="https://doi.org/10.1016/j.asoc.2022.108562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sine cosine algorithm (SCA), an emerging metaheuristic method, is usually limited by the local convergence and search stagnation defects in multivariable optimization problems . To improve the SCA performance, this study proposes an enhanced sine cosine algorithm (ESCA) using several modified strategies, including the opposition learning strategy for enlarging search range, the adaptive evolution strategy for improving global exploration, the neighborhood search strategy for increasing population diversity, and the greedy selection strategy for guaranteeing solution quality. ESCA and several metaheuristics methods are used to solve a group of numerical optimization problems. The experimental results indicate that in terms of solution efficiency and convergence rate, ESCA outperforms several traditional methods for multivariable parameter optimization problems. Then, several engineering optimization problems are employed to further test the feasibility of the ESCA method in practical applications. The simulations show that for various performance evaluation indexes, ESCA can produce high-quality solutions with better objective values compared to the control methods . Thus, a simple but powerful tool is developed to address the complex multivariable parameter optimization problems.},
  archive      = {J_ASOC},
  author       = {Zhong-kai Feng and Jie-feng Duan and Wen-jing Niu and Zhi-qiang Jiang and Yi Liu},
  doi          = {10.1016/j.asoc.2022.108562},
  journal      = {Applied Soft Computing},
  pages        = {108562},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Enhanced sine cosine algorithm using opposition learning, adaptive evolution and neighborhood search strategies for multivariable parameter optimization problems},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hodrick–prescott filter-based hybrid ARIMA–SLFNs model with
residual decomposition scheme for carbon price forecasting.
<em>ASOC</em>, <em>119</em>, 108560. (<a
href="https://doi.org/10.1016/j.asoc.2022.108560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate carbon pricing guidance is of great importance for the inhibition of excessive carbon dioxide emissions. Aiming at improving forecast performance, a number of carbon price forecasting models have been proposed based on the combination or multiscale hybrid frameworks. However, most of these hybrid models cannot easily cast a perfect reflection of erratic fluctuation in carbon trading schemes due to lack of judgment on the trend or inaccurate trend reconstruction. In this study, a novel filter-based modeling with Hodrick–Prescott (HP) filter, that can identify repeated up and down structural features around a certain carbon price, negotiates the obstacle of the parallel–series hybridization concerning the linear and the nonlinear model identification. The residual decomposition scheme with adaptive noise is carried out on the random and nonlinear component for error correction to filter-based models. Moreover, Bayesian optimization adjusts the structure of seven single-hidden layer feedforward neural networks (SLFNs) and the inputs to provide the best generalization performance . The proposed filter-hybrid model using kernel extreme learning machine as the final nonlinear integrator has better stability to the parameters, and has the superiority over the parallel–series and allocation-based models from a statistical perspective. Comparing with existing data-driven models, our proposed model is competitive in view of prediction accuracy and time cost in the majority of carbon futures trading cases.},
  archive      = {J_ASOC},
  author       = {Quande Qin and Zhaorong Huang and Zhihao Zhou and Yu Chen and Weigang Zhao},
  doi          = {10.1016/j.asoc.2022.108560},
  journal      = {Applied Soft Computing},
  pages        = {108560},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Hodrick–Prescott filter-based hybrid ARIMA–SLFNs model with residual decomposition scheme for carbon price forecasting},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An efficient two-factor authentication scheme based on
negative databases: Experiments and extensions. <em>ASOC</em>,
<em>119</em>, 108558. (<a
href="https://doi.org/10.1016/j.asoc.2022.108558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of network communication technology, identity authentication based on smart cards is one of the most common two-factor authentication schemes . In some real-world applications, timeliness is another challenge besides security and privacy because of the frequent logon and logoff or data updating. Presently, two-factor authentication schemes based on elliptic curve cryptography (ECC) are efficient. They are based on asymmetric encryption algorithms. But the time efficiency can be improved by hash-based methods, such as Negative databases ( NDB ) inspired by the artificial immune system . A one-time password authentication scheme based on NDB s is efficient, but it does not achieve the functions of mutual authentication and password changing , nor resists stolen-verifier attacks. In this paper, we propose an efficient two-factor authentication scheme based on NDB s. With this scheme, the password changing function is achieved, and the properties of uncertain form of negative databases can reduce the frequency of data updating. As the proposed scheme is a hash function based one, it has fewer calculation steps and higher time efficiency, compared with the authentication schemes based on asymmetric encryption algorithms such as ECC. This scheme also resists the majority of attacking behaviours, such as password-guessing attacks and man-in-the-middle attacks. Experimental results verify the time efficiency of this proposed scheme, and its security is analysed as well.},
  archive      = {J_ASOC},
  author       = {Ran Liu and Xiang Wang and Can Wang},
  doi          = {10.1016/j.asoc.2022.108558},
  journal      = {Applied Soft Computing},
  pages        = {108558},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An efficient two-factor authentication scheme based on negative databases: Experiments and extensions},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayberry segmentation in a complex environment based on a
multi-module convolutional neural network. <em>ASOC</em>, <em>119</em>,
108556. (<a href="https://doi.org/10.1016/j.asoc.2022.108556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic bayberry picking can substantially reduce labor costs and improve picking efficiency in an orchard management system . Nowadays, an automatic picking system mainly relies on machine vision to segment bayberry fruit from the background. Most existing methods are carried out in an environment where the light intensity is relatively fixed and the bayberries are unobstructed. However, due to the complexity of the growing environment, including variations in lighting and widespread occlusion, segmentation accuracy is quite limited, which affects the large-scale application of automatic picking systems. Aiming at these issues, in this study, a bayberry segmentation method based on a multi-module convolutional neural network is proposed. First, the bayberry images in a real scene were collected and preprocessed to form a dataset. Then, a convolutional neural network was constructed, with an image correction module to improve the network’s robustness to natural ambient lighting. Finally, a shape completion module with a puzzle algorithm was utilized to overcome the occlusion in the natural environment. The experimental results show that the average precision of the proposed method for semantic segmentation and instance segmentation of bayberry fruit can reach 0.913 and 0.755, respectively, which outperforms the existing methods and has important significance for automatic picking in orchards.},
  archive      = {J_ASOC},
  author       = {Huan Lei and Kai Huang and Zeyu Jiao and Yu Tang and Zhenyu Zhong and Yingjie Cai},
  doi          = {10.1016/j.asoc.2022.108556},
  journal      = {Applied Soft Computing},
  pages        = {108556},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Bayberry segmentation in a complex environment based on a multi-module convolutional neural network},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multiobjective state transition algorithm based on
modified decomposition method. <em>ASOC</em>, <em>119</em>, 108553. (<a
href="https://doi.org/10.1016/j.asoc.2022.108553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aggregation functions largely determine the convergence and diversity performance of multi-objective algorithms in decomposition methods . Nevertheless, the traditional Tchebycheff function does not consider the matching relationship between the weight vectors and candidate solutions. To deal with this issue, a new multiobjective state transition algorithm based on modified decomposition method (MOSTA/D) is proposed. According to the analysis of the relationship between the weight vectors and candidate solutions under the Tchebycheff decomposition scheme, the concept of matching degree is introduced which employs vectorial angles between weight vectors and candidate solutions. Based on the matching degree, a new modified Tchebycheff aggregation function is proposed in MOSTA/D. It can adaptively select the candidate solutions which are better matched with the weight vectors. This proposed MOSTA/D decomposes a multiobjective optimization problem into a number of scalar optimization subproblems and optimizes them in a collaborative manner. Each individual solution in the population of MOSTA/D is associated with a subproblem. Four mutation operators in STA are adopted to generating candidate solutions on subproblems and maintaining the population diversity. Relevant experimental results show that the proposed algorithm is highly competitive in comparison with other state-of-the-art evolutionary algorithms on tackling a set of benchmark problems with complicated Pareto fronts and a typical engineering optimization problem .},
  archive      = {J_ASOC},
  author       = {Xiaojun Zhou and Yuan Gao and Shengxiang Yang and Chunhua Yang and Jiajia Zhou},
  doi          = {10.1016/j.asoc.2022.108553},
  journal      = {Applied Soft Computing},
  pages        = {108553},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multiobjective state transition algorithm based on modified decomposition method},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neural collaborative filtering with multicriteria evaluation
data. <em>ASOC</em>, <em>119</em>, 108548. (<a
href="https://doi.org/10.1016/j.asoc.2022.108548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems help consumers find useful items of information given a large amount of information while avoiding information overload. Nowadays, in addition to traditional evaluation information (such as individual reviewer ratings), information such as multicriteria ratings are available on the Web. In the work reported here, we investigated whether collaborative filtering methods using multicriteria evaluation data and deep learning are effective for abundant and sparse multicriteria evaluation data. We also investigated whether adaptability can be achieved by predicting aggregated ratings from the evaluations of a few users. Experimental results show that three proposed methods using deep learning are better than traditional methods for both recommendation and rating aggregation.},
  archive      = {J_ASOC},
  author       = {Hiroki Morise and Kyohei Atarashi and Satoshi Oyama and Masahito Kurihara},
  doi          = {10.1016/j.asoc.2022.108548},
  journal      = {Applied Soft Computing},
  pages        = {108548},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Neural collaborative filtering with multicriteria evaluation data},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive non-linear soft sensor for quality monitoring in
refineries using just-in-time learning—generalized regression neural
network approach. <em>ASOC</em>, <em>119</em>, 108546. (<a
href="https://doi.org/10.1016/j.asoc.2022.108546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real time estimation of target quality variables using soft sensor relevant to time varying process conditions will be a significant step forward in effective implementation of Industry 4.0 . Generalized Regression neural network (GRNN) has been used as a steady state quality monitoring soft sensor with reasonable estimation accuracy. However, the accurate prediction capability of GRNN has rarely been explored in a time varying environment. This article reports design of adaptive soft sensor using GRNN as a local model in Just-in-Time learning (JITL-GRNN) framework. The JITL-GRNN adaptive soft sensing technique is further investigated in various dimensions such as, the effect of different similarity index criteria and relevant dataset size on model prediction accuracy and model computation time. Performance of the proposed JITL-GRNN soft sensor is investigated by assessing its prediction accuracy on two benchmark industrial datasets. In addition, dynamic Non-linear autoregressive with exogenous inputs (NARX) neural network model is also developed and the performance of NARX model was compared with the proposed JITL-GRNN model. Results show that the JITL-GRNN adaptive soft sensor has at par or better prediction capability than the NARX model and many other models reported in literature.},
  archive      = {J_ASOC},
  author       = {Venkata Vijayan S. and Hare K. Mohanta and Ajaya Kumar Pani},
  doi          = {10.1016/j.asoc.2022.108546},
  journal      = {Applied Soft Computing},
  pages        = {108546},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Adaptive non-linear soft sensor for quality monitoring in refineries using just-in-time Learning—Generalized regression neural network approach},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A fresh approach to evaluate performance in distributed
parallel genetic algorithms. <em>ASOC</em>, <em>119</em>, 108540. (<a
href="https://doi.org/10.1016/j.asoc.2022.108540">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes a novel approach to evaluate and analyze the behavior of multi-population parallel genetic algorithms (PGAs) when running on a cluster of multi-core processors. In particular, we deeply study their numerical and computational behavior by proposing a mathematical model representing the observed performance curves. In them, we discuss the emerging mathematical descriptions of PGA performance instead of, e.g., individual isolated results subject to visual inspection, for a better understanding of the effects of the number of cores used (scalability), their migration policy (the migration gap, in this paper), and the features of the solved problem (type of encoding and problem size). The conclusions based on the real figures and the numerical models fitting them represent a fresh way of understanding their speed-up, running time, and numerical effort, allowing a comparison based on a few meaningful numeric parameters. This represents a set of conclusions beyond the usual textual lessons found in past works on PGAs. It can be used as an estimation tool for the future performance of the algorithms and a way of finding out the upper limit of the performance if the number of used cores increases.},
  archive      = {J_ASOC},
  author       = {Tomohiro Harada and Enrique Alba and Gabriel Luque},
  doi          = {10.1016/j.asoc.2022.108540},
  journal      = {Applied Soft Computing},
  pages        = {108540},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A fresh approach to evaluate performance in distributed parallel genetic algorithms},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A covariance-based moth–flame optimization algorithm with
cauchy mutation for solving numerical optimization problems.
<em>ASOC</em>, <em>119</em>, 108538. (<a
href="https://doi.org/10.1016/j.asoc.2022.108538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Moth–Flame Optimization (MFO) algorithm, which is inspired by the navigation method of moths, is a nature-inspired optimization algorithm. The MFO is easy to implement and has been used to solve many real-world optimization problems . However, the MFO cannot balance exploration and exploitation well, and the information exchange between individuals is limited, especially in solving some complex numerical problems. To overcome these disadvantages of the MFO in solving the numerical optimization problems, a covariance-based Moth–Flame Optimization algorithm with Cauchy mutation (CCMFO) is proposed in this paper. In the CCMFO, the concept of covariance is used to transform the individuals of the moths and flames from the original space to the eigenspace and update the positions of moths, which can better improve the information exchange ability of the flames and moths in the eigenspace. In addition, Cauchy mutation is utilized to improve the exploration. And the CCMFO is compared with the other 22 algorithms on CEC 2020 test suite. The test results show that the CCMFO is better than other population-based optimization algorithms and MFO variants in search performance, while its performance is statistically similar to CEC competition algorithms. Furthermore, the CCMFO is compared with the other 12 algorithms on CEC 2020 real-world constrained optimization problems, and the results show that the CCMFO can effectively solve real-world constrained optimization problems. Finally, the CCMFO is used to optimize the tracking controller parameters of continuous casting mold vibration displacement. The experimental results based on the experimental platform show that the CCMFO can effectively reduce the difficulty of parameter selection and improve the tracking accuracy.},
  archive      = {J_ASOC},
  author       = {Xiaodong Zhao and Yiming Fang and Le Liu and Miao Xu and Qiang Li},
  doi          = {10.1016/j.asoc.2022.108538},
  journal      = {Applied Soft Computing},
  pages        = {108538},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A covariance-based moth–flame optimization algorithm with cauchy mutation for solving numerical optimization problems},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). OccupancySense: Context-based indoor occupancy detection
&amp; prediction using CatBoost model. <em>ASOC</em>, <em>119</em>,
108536. (<a href="https://doi.org/10.1016/j.asoc.2022.108536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Occupancy detection and prediction are two well-established problems which can be improved further to achieve higher accuracy in both cases than the existing solutions. To achieve the desired higher accuracy, proposed OccupancySense model detects human presence and predicts indoor occupancy count by the fusion of Internet of Things (IoT) based indoor air quality ( I A Q IAQ ) data along with static and dynamic context data which is a unique approach in this domain. This data fusion helps us to achieve higher forecasting accuracy along with the integration of state of the art gradient boosting based categorical features supported CatBoost algorithm. For comparison, other commonly used machine learning classification and regression algorithms, e.g., Multiple Linear Regression (MLR), Decision Tree (DT), Random Forests (RF) and Support Vector Machine (SVM) for regression and Logistic Regression (LR), Naïve Bayes (NB), Decision Tree (DT) and Random Forest (RF), Support Vector Machine (SVM) for classification, were also assessed during this experiment. Out of these, CatBoost outperformed other models when considered in terms of accuracy. Hence, CatBoost is used as the core of the OccupancySense design and we have validated the proposed model by a real-world case study with continuous 91 days of indoor data, having 33 unique external features. These features are collected directly as well as derived from the collected data. To handle these features, feature engineering plays a key role in the OccupancySense model. The speciality of this model is, it is non-intrusive one but have high predictive power . It can detect occupancy and predicts headcount along with occupancy density of the room pretty accurately with 99.85\%, 93.2\% and 95.6\% respectively (with 10 fold cross-validation) which outperforms other state of the art models.},
  archive      = {J_ASOC},
  author       = {Joy Dutta and Sarbani Roy},
  doi          = {10.1016/j.asoc.2022.108536},
  journal      = {Applied Soft Computing},
  pages        = {108536},
  shortjournal = {Appl. Soft. Comput.},
  title        = {OccupancySense: Context-based indoor occupancy detection &amp; prediction using CatBoost model},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-objective particle swarm optimization algorithm
based on two-archive mechanism. <em>ASOC</em>, <em>119</em>, 108532. (<a
href="https://doi.org/10.1016/j.asoc.2022.108532">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a powerful optimization technique, multi-objective particle swarm optimization algorithms have been widely used in various fields. However, performing well in terms of convergence and diversity simultaneously is still a challenging task for most existing algorithms. In this paper, a multi-objective particle swarm optimization algorithm based on two-archive mechanism (MOPSO_TA) is proposed for the above challenge. First, two archives, including convergence archive (CA) and diversity archive (DA) are designed to emphasize convergence and diversity separately. On one hand, particles are updated by indicator-based scheme to provide selection pressure toward the optimal direction in CA. On the other hand, shift-based density estimation and similarity measure are adopted to preserve diverse candidate solutions in DA. Second, the genetic operators are conducted on particles from CA and DA to further enhance the quality of solutions as global leaders. Then the search ability of MOPSO_TA can be improved by performing hybrid operators. Furthermore, to balance global exploration and local exploitation of MOPSO_TA, a flight parameters adjustment mechanism is developed based on the evolutionary information. Finally, the proposed algorithm is compared experimentally with several representative multi-objective optimization algorithms on 21 benchmark functions . The experimental results demonstrate the competitiveness and effectiveness of the proposed method.},
  archive      = {J_ASOC},
  author       = {Yingying Cui and Xi Meng and Junfei Qiao},
  doi          = {10.1016/j.asoc.2022.108532},
  journal      = {Applied Soft Computing},
  pages        = {108532},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-objective particle swarm optimization algorithm based on two-archive mechanism},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). A radiological image analysis framework for early screening
of the COVID-19 infection: A computer vision-based approach.
<em>ASOC</em>, <em>119</em>, 108528. (<a
href="https://doi.org/10.1016/j.asoc.2022.108528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the absence of any specialized drugs, the novel coronavirus disease 2019 or COVID-19 is one of the biggest threats to mankind Although the RT-PCR test is the gold standard to confirm the presence of this virus, some radiological investigations find some important features from the CT scans of the chest region, which are helpful to identify the suspected COVID-19 patients. This article proposes a novel fuzzy superpixel-based unsupervised clustering approach that can be useful to automatically process the CT scan images without any manual annotation and helpful in the easy interpretation. The proposed approach is based on artificial cell swarm optimization and will be known as the SUFACSO (SUperpixel based Fuzzy Artificial Cell Swarm Optimization) and implemented in the Matlab environment . The proposed approach uses a novel superpixel computation method which is helpful to effectively represent the pixel intensity information which is beneficial for the optimization process. Superpixels are further clustered using the proposed fuzzy artificial cell swarm optimization approach. So, a twofold contribution can be observed in this work which is helpful to quickly diagnose the patients in an unsupervised manner so that, the suspected persons can be isolated at an early phase to combat the spread of the COVID-19 virus and it is the major clinical impact of this work. Both qualitative and quantitative experimental results show the effectiveness of the proposed approach and also establish it as an effective computer-aided tool to fight against the COVID-19 virus. Four well-known cluster validity measures Davies–Bouldin, Dunn, Xie–Beni, and β β index are used to quantify the segmented results and it is observed that the proposed approach not only performs well but also outperforms some of the standard approaches. On average, the proposed approach achieves 1.709792, 1.473037, 1.752433, 1.709912 values of the Xie–Beni index for 3, 5, 7, and 9 clusters respectively and these values are significantly lesser compared to the other state-of-the-art approaches. The general direction of this research is worthwhile pursuing leading, eventually, to a contribution to the community.},
  archive      = {J_ASOC},
  author       = {Shouvik Chakraborty and Kalyani Mali},
  doi          = {10.1016/j.asoc.2022.108528},
  journal      = {Applied Soft Computing},
  pages        = {108528},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A radiological image analysis framework for early screening of the COVID-19 infection: A computer vision-based approach},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Horizontal progressive and longitudinal leapfrogging fuzzy
classification with feature activity adjustment. <em>ASOC</em>,
<em>119</em>, 108511. (<a
href="https://doi.org/10.1016/j.asoc.2022.108511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification accuracy and interpretability are crucial importance for recognizing seizures based on electroencephalogram (EEG) signals. This study presents a novel deep ladder-type Takagi–Sugeno–Kang (TSK) fuzzy classifier (D-LT-TSK) that alternately utilizes horizontal progressive learning and longitudinal leapfrogging learning styles. Based on the nonuniform probability distribution co-generated by the distance correlation (DC) coefficient and random bias matrix, a feature activity adjustment mechanism (DC-FAM) is adopted to adjust the activity of each feature to realize the evolution from full connection to partial connection between the input layer and rule layers of the TSK classifier. Feedforward and feedback neural networks are combined to learn consequent parameters in the Then-part of fuzzy rules, for the sake of strengthening the approximation performance and achieving fast converge capability. To take full advantage of valuable decision-making information, D-LT-TSK is learned in the horizontal progressive and longitudinal leapfrogging learning style by mapping the decision-making information of learning modules into the original input space. Experimental results demonstrated that (1) the highly interpretable D-LT-TSK be capable of yielding satisfactory classification performance by utilizing short fuzzy rules, and (2) the optimization algorithm in the Then-part enhanced the approximation performance and accelerate the convergence speed.},
  archive      = {J_ASOC},
  author       = {Wei Xue and Ta Zhou and Jing Cai},
  doi          = {10.1016/j.asoc.2022.108511},
  journal      = {Applied Soft Computing},
  pages        = {108511},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Horizontal progressive and longitudinal leapfrogging fuzzy classification with feature activity adjustment},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards identification of solutions of interest for
multi-objective problems considering both objective and variable space
information. <em>ASOC</em>, <em>119</em>, 108505. (<a
href="https://doi.org/10.1016/j.asoc.2022.108505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi/many-objective optimization, a decision maker (DM) may often be interested in examining only a small set of solutions instead of the entire Pareto optimal front (PF). Such solutions are referred to as solutions of interest (SOI) in some recent studies. A number of methods have been proposed to identify SOIs in an offline or online setting using measures based on reflex angle, bend angle, expected marginal utility, etc. However, these measures only account for the desirable trade-offs in the objective space. On the other hand, the variable space information is often critical in practical scenarios as it relates directly to the implemented design. For example, a DM may additionally require that the obtained solutions are robust, i.e., insensitive to variable perturbations , or look significantly different in the variable space, thereby offering multiple equivalent designs to achieve similar performance. These require formulation of new measures and search strategies that simultaneously consider both objective and variable spaces while identifying SOIs. In this paper, we develop an approach that can identify a given number of SOIs for DM’s consideration for three different scenarios: (a) purely based on objective space, (b) simultaneous consideration of objectives and robustness, and (c) simultaneous considerations of objectives and equivalent designs. Towards this end, we first define the relevant quantitative measures and illustrate their use for offline selection for a few 2–3 objective test problems. Thereafter, we design an online algorithm that can identify the SOIs and bias the search towards the SOIs based on the scenarios listed above. Lastly, we also present results on two practical examples: a 2-objective welded beam and a 5-objective wind-turbine design problem.},
  archive      = {J_ASOC},
  author       = {Tapabrata Ray and Hemant Kumar Singh and Kamrul Hasan Rahi and Tobias Rodemann and Markus Olhofer},
  doi          = {10.1016/j.asoc.2022.108505},
  journal      = {Applied Soft Computing},
  pages        = {108505},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Towards identification of solutions of interest for multi-objective problems considering both objective and variable space information},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GPU-based acceleration of evolutionary induction of model
trees. <em>ASOC</em>, <em>119</em>, 108503. (<a
href="https://doi.org/10.1016/j.asoc.2022.108503">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary algorithms (EAs) are naturally prone to parallel processing . However, when they are applied to data mining, the fitness calculations start to dominate and the typical population-based decomposition limits the parallel efficiency. When dealing with large-scale data, the scalable solution may become a real challenge. In this article, we propose a GPU-based parallelization of evolutionary induction of model trees. Such trees are a special case of decision tree (DT) that is designed to solve regression problems . The evolutionary approach allows not only a robust prediction but also to preserve the simplicity of DTs. However, the global approach is much more computationally demanding than state-of-the-art greedy inducers, and thus hard to apply to large-scale data mining directly. A parallelized induction of model trees (with univariate tests in the internal nodes and multiple linear regression models in the leaves) requires a carefully designed decomposition strategy. Six GPU-supported procedures are designed to successively: redistribute, sort and rearrange dataset samples , next, calculate models and fitness, and finally gather the results. Experimental validation is performed on real-life and artificial datasets, using various (low- and high-end) GPU accelerators. Results show that the GPU-supported solution enables time-efficient global induction of model trees on large-scale data, which until now was reserved for greedy methods. The obtained speedup is very satisfactory (even up to hundreds of times). The solution is scalable for datasets of different sizes and dimensions.},
  archive      = {J_ASOC},
  author       = {Krzysztof Jurczuk and Marcin Czajkowski and Marek Kretowski},
  doi          = {10.1016/j.asoc.2022.108503},
  journal      = {Applied Soft Computing},
  pages        = {108503},
  shortjournal = {Appl. Soft. Comput.},
  title        = {GPU-based acceleration of evolutionary induction of model trees},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Area-wide traffic signal control based on a deep graph
q-network (DGQN) trained in an asynchronous manner. <em>ASOC</em>,
<em>119</em>, 108497. (<a
href="https://doi.org/10.1016/j.asoc.2022.108497">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Value-based reinforcement learning (RL) algorithms have been widely applied in traffic signal studies. There are, however, several problems in jointly controlling traffic lights for a large transportation network. First, the discrete action space exponentially explodes as the number of intersections to be jointly controlled increases. With its model structure, the original deep Q-network (DQN) could not accommodate a large action space. The problem was resolved by revising the output structure of a DQN holding the framework of a single-agent RL algorithm Second, when mapping traffic states into an action value, it is difficult to consider spatio-temporal correlations over a large transportation network. A deep graph Q-network (DGQN) was devised to efficiently accommodate spatio-temporal dependencies on a large scale. Finally, training the proposed DGQN with a large number of joint actions requires much time to converge. An asynchronous update methodology with multiple actor learners was devised for a DGQN to quickly reach an optimal policy . By combining these three remedies, a DGQN succeeded in jointly controlling the traffic lights in a large transportation network in Seoul. This approach outperformed other “state-of-the-art” RL algorithms as well as an actual fixed-signal operation. The proposed DGQN decreased the average delay of the current fixed operation to 55.7\%, whereas those of reference models DQN-OGCN and DQN-FC were 72.5 and 92.0\%, respectively.},
  archive      = {J_ASOC},
  author       = {Gyeongjun Kim and Keemin Sohn},
  doi          = {10.1016/j.asoc.2022.108497},
  journal      = {Applied Soft Computing},
  pages        = {108497},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Area-wide traffic signal control based on a deep graph Q-network (DGQN) trained in an asynchronous manner},
  volume       = {119},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Applying the quantum approximate optimization algorithm to
the minimum vertex cover problem. <em>ASOC</em>, <em>118</em>, 108554.
(<a href="https://doi.org/10.1016/j.asoc.2022.108554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The minimum vertex cover problem belongs to a NP- complete problem, which is difficult to obtain the near-optimal solution in the polynomial time range using classical algorithms. In this paper, a quantum circuit solution scheme based on the quantum approximate optimization algorithm is presented for the minimum vertex cover problem. Firstly, the quantum Ising model and Hamiltonian of the problem are obtained based on the Ising model corresponding to the problem, which is quantized by the rotation operator and Pauli operator . Secondly, the parametric unitary transformation with the initial Hamiltonian and the problem Hamiltonian as the generator is obtained respectively. Through the alternating evolution of two parametric unitary transformations, the final quantum state and the problem Hamiltonian expectation are derived. In the process of evolution, the parameters in the parametric unitary transformations which are optimized by the classical processor can adjust the problem Hamiltonian expectation, so as to improve the probability of the problem solution. Then, the initial state of the algorithm and the quantum logic gate corresponding to the parametric unitary transformation are derived to generate the quantum circuit which can be implemented on the quantum computer . Simulation results show that the scheme can obtain the problem solution with high probability in polynomial time , realizes exponential acceleration, and has certain feasibility, effectiveness and innovation.},
  archive      = {J_ASOC},
  author       = {Y.J. Zhang and X.D. Mu and X.W. Liu and X.Y. Wang and X. Zhang and K. Li and T.Y. Wu and D. Zhao and C. Dong},
  doi          = {10.1016/j.asoc.2022.108554},
  journal      = {Applied Soft Computing},
  pages        = {108554},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Applying the quantum approximate optimization algorithm to the minimum vertex cover problem},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A statistical feature data mining framework for constructing
scholars’ career trajectories in academic data. <em>ASOC</em>,
<em>118</em>, 108550. (<a
href="https://doi.org/10.1016/j.asoc.2022.108550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal and spatial information about scholars can be found in their academic papers. Examining the footprints of scholars’ careers can help us understand the course of their growth, potential collaborations for future research, and trends in the flow of talent. Although a great deal of research has been conducted in related fields, the challenge of accurately constructing scholars’ career trajectories from redundant and noisy academic data is far from resolved. To address this problem, a unified framework called ATrajRN that employs AMiner academic data is proposed for the first time. To accurately obtain scholars’ geographic location information from their research achievements, this study introduces an algorithm called Positioning based on Academic Achievements of Scholars (PAAS), which aims to make the most of academic data and the characteristics of different maps. To avoid the interference of data redundancy , this paper proposes a statistical feature-based method to find the most reliable career trajectories by some state-of-the-art approaches. To restore the continuously scholars’ career trajectories, this paper offers the trajectory generation algorithm based on the output from the previous step. Experiments and systematic analysis shows that the proposed novel method could achieve approximately 80\% accuracy – an increase of approximately 10\% – manifestly outperform the baseline method . Lastly, based on this work, we develop a system for understanding scholars’ trajectories through analysis and visualization, and we investigate the migration characteristics of typical scholar groups.},
  archive      = {J_ASOC},
  author       = {Zhou Shao and Sha Yuan and Jing Xu and Yongli Wang},
  doi          = {10.1016/j.asoc.2022.108550},
  journal      = {Applied Soft Computing},
  pages        = {108550},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A statistical feature data mining framework for constructing scholars’ career trajectories in academic data},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Advanced traffic congestion early warning system based on
traffic flow forecasting and extenics evaluation. <em>ASOC</em>,
<em>118</em>, 108544. (<a
href="https://doi.org/10.1016/j.asoc.2022.108544">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic congestion is a vital factor hindering travel. As such, developing a reliable traffic congestion early warning system is essential for providing traffic condition supervision and programming. However, previous research has rarely focused on traffic flow characteristics or on providing comprehensive assessments, resulting in poor warning performances. In this study, an innovative traffic congestion early warning system is proposed, comprising point forecasting, characteristic estimate, interval prediction, and comprehensive assessment. In the characteristic assessment phase, eight common statistical distributions are used to fit the characteristics of an original traffic flow parameter series in a training set, and the best fitting results are considered as the basis for building a prediction interval. An extreme learning machine combined with a modified multi-objective dragonfly optimization algorithm and variational mode decomposition is constructed in the point forecasting phase to provide accurate and stable traffic flow parameter forecasting results; two different strategies are used to establish the prediction interval, so as to conduct interval forecasting based on different types of uncertainty information (probability distribution information or known interval information). Extenics evaluation theory is then used in the comprehensive assessment phase to evaluate the traffic congestion level . Simulations of traffic flow parameter series, including simulations of the road density, road occupancy, and average velocity , reveal that the proposed early warning system demonstrates powerful abilities based on its precision and stability. The mean absolute percentage error (MAPE) values of the traffic flow parameters for the three datasets are 3.6265\%, 3.7203\%, and 4.5100\%, respectively. The forecasting accuracy for the traffic congestion level is more than 97\% for both point and interval prediction. Thus, this approach can be widely used for personal traffic route planning and the unified management of governmental traffic conditions.},
  archive      = {J_ASOC},
  author       = {Ping Jiang and Zhenkun Liu and Lifang Zhang and Jianzhou Wang},
  doi          = {10.1016/j.asoc.2022.108544},
  journal      = {Applied Soft Computing},
  pages        = {108544},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Advanced traffic congestion early warning system based on traffic flow forecasting and extenics evaluation},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Medical image fusion via discrete stationary wavelet
transform and an enhanced radial basis function neural network.
<em>ASOC</em>, <em>118</em>, 108542. (<a
href="https://doi.org/10.1016/j.asoc.2022.108542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image fusion of images obtained via different modes can expand the inherent information of original images, whereby the fused image has a superior ability to display details than the original sub-images, to facilitate diagnosis and treatment selection. In medical image fusion, an inherent challenge is to effectively combine the most useful information and image details without information loss. Despite the many methods that have been proposed, the effective retention and presentation of information proves challenging. Therefore, we proposed and evaluated a novel image fusion method based on the discrete stationary wavelet transform (DSWT) and radial basis function neural network (RBFNN). First, we analyze the details or feature information of two images to be processed by DSWT by using two-level decomposition to separate each image into seven parts, comprising both high-frequency and low-frequency sub-bands. Considering the gradient and energy attributes of the target, we substituted the pending parts in the same position in the two images by using the proposed enhanced RBFNN. The input, hidden, and output layers of the neural network comprised 8, 40, and 1 neuron(s), respectively. From the seven neural networks, we obtained seven fused parts. Finally, through inverse wavelet transform , we obtained the final fused image. For the neural network training method, the hybrid adaptive gradient descent algorithm (AGDA) and gravitational search algorithm (GSA) were implemented. The final experimental results revealed that the novel method has significantly better performance than the current state-of-the-art methods.},
  archive      = {J_ASOC},
  author       = {Zhen Chao and Xingguang Duan and Shuangfu Jia and Xuejun Guo and Hao Liu and Fucang Jia},
  doi          = {10.1016/j.asoc.2022.108542},
  journal      = {Applied Soft Computing},
  pages        = {108542},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Medical image fusion via discrete stationary wavelet transform and an enhanced radial basis function neural network},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A stacking neuro-fuzzy framework to forecast runoff from
distributed meteorological stations. <em>ASOC</em>, <em>118</em>,
108535. (<a href="https://doi.org/10.1016/j.asoc.2022.108535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neuro-fuzzy models have been used to predict runoff from rainfall, a hydrological phenomenon associated with a degree of uncertainty. However, rainfall can be measured from different meteorological stations, and runoff forecasting can be biased. Thus, the aim of this work is to propose a new stacking neuro-fuzzy framework for predicting runoff from physically distributed meteorological stations. As a method to estimate single one-day-ahead runoff and as a stacking approach , the Self-Identification Neuro-fuzzy Inference model (SINFIM) and Self-Organizing Neuro-fuzzy Inference System (SONFIS) were developed, respectively. As a case study, data from two Chilean watersheds (the Diguillín River (Ñuble region) and Colorado River (Maule region)) and average daily runoff and average daily rainfall recorded over eighteen years were collected from the Chilean Directorate of Water Resources (DGA). The experimental results show good adjustment in the single forecasting of runoff with meteorological stations showing adjustment and efficiency indexes of greater than 80\% in the validation set and being able to efficiently predict both high and low runoff values. However, better results were obtained with the stacking model with values being higher than single runoff predictions and those of state-of-art approaches. Therefore, the general framework proposed represents a good approach for forecasting runoff since it can improve predictions and generate more accurate runoff values than single models.},
  archive      = {J_ASOC},
  author       = {Marvin Querales and Rodrigo Salas and Yerel Morales and Héctor Allende-Cid and Harvey Rosas},
  doi          = {10.1016/j.asoc.2022.108535},
  journal      = {Applied Soft Computing},
  pages        = {108535},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A stacking neuro-fuzzy framework to forecast runoff from distributed meteorological stations},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Scene recognition using multiple representation network.
<em>ASOC</em>, <em>118</em>, 108530. (<a
href="https://doi.org/10.1016/j.asoc.2022.108530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, with the rapid development of convolutional neural networks (CNNs), a series of computer vision tasks have been solved. However, scene recognition is still a difficult and challenging problem due to the complexity of scene images. With the emergence of large-scale scene datasets, a single representation generated by a plain CNN is no longer discriminative enough to describe massive scene images. Therefore, in this paper, we propose a comprehensive representation for scene recognition, including enhanced global scene representation, local salient scene representation, and local contextual object representation. We use two pretrained CNNs to extract original feature maps to construct the multiple representations. Specifically, we adopt class activation mapping (CAM) to find salient regions and extract local scene features and employ a bidirectional long short-term module (LSTM) to encode contextual information of objects existing in a scene. In addition, the multiple representations are generated by an end-to-end trainable model, which we call MRNet (multiple representation network). Experimental results on three publicly available scene recognition datasets demonstrate that our proposed model is superior to state-of-the-art models.},
  archive      = {J_ASOC},
  author       = {Chaowei Lin and Feifei Lee and Lin Xie and Jiawei Cai and Hanqing Chen and Li Liu and Qiu Chen},
  doi          = {10.1016/j.asoc.2022.108530},
  journal      = {Applied Soft Computing},
  pages        = {108530},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Scene recognition using multiple representation network},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Randomization-based machine learning in renewable energy
prediction problems: Critical literature review, new results and
perspectives. <em>ASOC</em>, <em>118</em>, 108526. (<a
href="https://doi.org/10.1016/j.asoc.2022.108526">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last few years, methods falling within the family of randomization-based machine learning models have grasped a great interest in the Artificial Intelligence community, mainly due to their excellent balance between performance in prediction problems and their computational efficiency. The use of these models for prediction problems related to renewable energy sources has been particularly notable in recent times, including different ways in which randomization is considered, their hybridization with other modeling techniques and/or their multi-layered (deep) and ensemble arrangement. This manuscript comprehensively reviews the most important features of randomization-based machine learning methods, and critically examines recent evidences of their application to renewable energy prediction problems, focusing on those related to solar, wind, marine/ocean and hydro-power renewable sources. Our study of the literature is complemented by an extensive experimental setup encompassing three real-world problems dealing with solar radiation prediction, wind speed prediction in wind farms and hydro-power energy. In all these problems randomization-based methods are reported to achieve a better predictive performance than their corresponding state-of-the-art solutions, while demanding a dramatically lower computational effort for its learning phases. Finally, we pause and reflect on important challenges faced by these methods when applied to renewable energy prediction problems, such as their intrinsic epistemic uncertainty , or the need for explainability. We also point out several research opportunities that arise from this vibrant research area.},
  archive      = {J_ASOC},
  author       = {J. Del Ser and D. Casillas-Perez and L. Cornejo-Bueno and L. Prieto-Godino and J. Sanz-Justo and C. Casanova-Mateo and S. Salcedo-Sanz},
  doi          = {10.1016/j.asoc.2022.108526},
  journal      = {Applied Soft Computing},
  pages        = {108526},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Randomization-based machine learning in renewable energy prediction problems: Critical literature review, new results and perspectives},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Extended rule-based opinion target extraction with a novel
text pre-processing method and ensemble learning. <em>ASOC</em>,
<em>118</em>, 108524. (<a
href="https://doi.org/10.1016/j.asoc.2022.108524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Opinion target extraction (OTE) is the extraction of explicit expressions related to entity aspects interpreted with subjective attributive words in the review sentences using supervised or rule-based approaches. Despite the constraints of syntactic-based relation rules, rule-based approaches can be domain-independently implemented. Although supervised approaches yield better results, more costly due to requiring a large number of labeled samples. This study proposes an unsupervised (rule-based) OTE approach with novel methods and extended rule-based techniques to overcome the aforementioned issues. In this study, first, a novel pattern-based text pre-processing method is proposed to eliminate punctuations that are incompatible with determinative group rules patterns. Then, implemented syntactic-based relation rules on the dependency relation graph are extended with new auxiliary features to extract multi-word expressions which modify each other. The majority voting method is used for optimizing the performance of outputs. Finally, the effectiveness of the proposed approach was tested on a restaurant review dataset. The experimental results show that the proposed approach outperforms all unsupervised approaches. Additionally, it gives comparable results with the supervised approaches, revealing the effectiveness of the proposed approach.},
  archive      = {J_ASOC},
  author       = {Kürşat Mustafa Karaoğlan and Oğuz Fındık},
  doi          = {10.1016/j.asoc.2022.108524},
  journal      = {Applied Soft Computing},
  pages        = {108524},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Extended rule-based opinion target extraction with a novel text pre-processing method and ensemble learning},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A fast parameter optimization approach based on the
inter-cluster induced distance in the feature space for support vector
machines. <em>ASOC</em>, <em>118</em>, 108519. (<a
href="https://doi.org/10.1016/j.asoc.2022.108519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the problem of optimizing the kernel and penalty parameters for SVM classifiers with Gaussian kernel . To reduce the computational overhead of inter-cluster distance in the feature space (ICDF) with a large number of candidate discretized values in a large interval in previous researches, in this paper, the new inter-cluster induced distance in the feature space (ICIDF) is proposed to guide the kernel parameter selection of SVMs, and the theorem that the ICIDF is a positive strictly unimodal function about Gaussian kernel parameter is firstly presented. Then, a fast parameter optimization approach including two stages is presented for SVMs according to this theorem. In the first stage, a modified golden section algorithm (MGSA) is proposed to obtain a shrunk value interval for kernel parameter in small amount of ICIDF calculations. In the second stage, a differential evolutionary algorithm (BBDE or SADE) is applied to select the best parameter combination for SVM in the shrunk interval of kernel parameter obtained by MGSA and a given interval of penalty parameter. Experiments for benchmark datasets illustrate that the training time of SVM models can significantly shortened by our approach, while the testing accuracy of the trained SVMs is competitive.},
  archive      = {J_ASOC},
  author       = {Jiapeng Wang and Jiaxiang Luo},
  doi          = {10.1016/j.asoc.2022.108519},
  journal      = {Applied Soft Computing},
  pages        = {108519},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A fast parameter optimization approach based on the inter-cluster induced distance in the feature space for support vector machines},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Genetic programming for feature extraction and construction
in image classification. <em>ASOC</em>, <em>118</em>, 108509. (<a
href="https://doi.org/10.1016/j.asoc.2022.108509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Genetic Programming (GP) has been successfully applied to image classification and achieved promising results. However, most existing methods either address binary image classification tasks only or need a predefined classifier to perform multi-class image classification while using GP for feature extraction. This limits their flexibility since it is unknown which combinations of classifiers and features are the most effective for an image classification task. Furthermore, high image variations increase the difficulty of feature extraction and image classification. This paper proposes a GP approach with a new program representation, new functions, and new terminals. The new approach can conduct feature extraction, feature construction, and classification, automatically and simultaneously. It can extract and construct informative image features , select a suitable classification algorithm instead of relying on a predefined classifier, and perform classification for binary and multi-class image classification tasks. In addition, this paper develops a new mutation operator based on fitness of population for dynamically adjusting the size of the evolved GP programs. The experimental results on eight datasets with different variations and difficulties show that the proposed approach achieves higher classification accuracy than most of the benchmark methods. Further analysis shows that the GP evolved programs have appropriate tree sizes and potentially high interpretability .},
  archive      = {J_ASOC},
  author       = {Qinglan Fan and Ying Bi and Bing Xue and Mengjie Zhang},
  doi          = {10.1016/j.asoc.2022.108509},
  journal      = {Applied Soft Computing},
  pages        = {108509},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Genetic programming for feature extraction and construction in image classification},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-dimensional recurrent neural network for remaining
useful life prediction under variable operating conditions and multiple
fault modes. <em>ASOC</em>, <em>118</em>, 108507. (<a
href="https://doi.org/10.1016/j.asoc.2022.108507">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven remaining useful life (RUL) prediction approaches, especially those based on deep learning (DL), have been increasingly applied to mechanical equipment. However, two reasons limit their prognostic performance under variable operating conditions. The first one is that the existing DL-based prognostic models usually ignore the utilization of operating condition data. And, the other is that most DL-based prognostic models focus on enhancing the nonlinear representation learning ability by stacking network layers, and lack exploration in extracting diverse features. To break through the limitation of prediction accuracy under variable operating conditions, this paper presents a novel multi-dimensional recurrent neural network (MDRNN) for RUL prediction under variable operating conditions and multiple fault modes (VOCMFM). Different from existing DL prognostic models, MDRNN can simultaneously model and mine multisensory monitoring data and operating condition data to achieve RUL prediction under VOCMFM. In MDRNN, parallel bidirectional long short-term memory and bidirectional gated recurrent unit pathways are constructed to automatically capture degradation features from different dimensions. Two prognostic benchmarking datasets of aircraft turbofan are adopted to validate MDRNN. Experimental results demonstrate that MDRNN can perform the prediction tasks under VOCMFM well and surpass many state-of-the-arts.},
  archive      = {J_ASOC},
  author       = {Yiwei Cheng and Chao Wang and Jun Wu and Haiping Zhu and C.K.M. Lee},
  doi          = {10.1016/j.asoc.2022.108507},
  journal      = {Applied Soft Computing},
  pages        = {108507},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-dimensional recurrent neural network for remaining useful life prediction under variable operating conditions and multiple fault modes},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A study of multi-objective restricted multi-item fixed
charge transportation problem considering different types of demands.
<em>ASOC</em>, <em>118</em>, 108501. (<a
href="https://doi.org/10.1016/j.asoc.2022.108501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we formulate a multi-objective fixed charge transportation problem (FCTP) for multiple items, considering availability of multiple modes of transport along each pair of origin and destination. The variable cost of each item, the fixed cost and the transport time are considered to be different for each mode of transport. It is also considered that some items are mutually incompatible and cannot be transported in the same mode of transport. Two models of the multi-item FCTP are presented, considering the demands of items as crisp and interval numbers, respectively. The transportation problem is then posed as a multi-objective optimization problem (MOOP), in which the objectives are to minimize the total cost and total transport time. For the model with interval demands , the instances are only solved, in which, for each item, the sum total of demands of an item at different destinations is at least the sum total of availabilities of the item at different origins. For each model, a set of four numerical examples are solved using two multi-objective evolutionary algorithms (MOEAs), namely, Non-dominated Soring Genetic Algorithm-II (NSGA-II) and Strength Pareto Evolutionary Algorithm 2 (SPEA2). A comparative study of the computational results are made in terms of four performance index, namely, RNI value, Hyper-volume (HV), Inverted Generational Distance (IGD) and Spread. The computational results clearly indicates that NSGA-II outperforms SPEA2 for all the numerical examples, in terms of generating better approximate Pareto front with respect to dominance, diversity and spread.},
  archive      = {J_ASOC},
  author       = {Amiya Biswas and Leopoldo Eduardo Cárdenas-Barrón and Ali Akbar Shaikh and Avijit Duary and Armando Céspedes-Mota},
  doi          = {10.1016/j.asoc.2022.108501},
  journal      = {Applied Soft Computing},
  pages        = {108501},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A study of multi-objective restricted multi-item fixed charge transportation problem considering different types of demands},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Human-like motion planning of autonomous vehicle based on
probabilistic trajectory prediction. <em>ASOC</em>, <em>118</em>,
108499. (<a href="https://doi.org/10.1016/j.asoc.2022.108499">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motion planning for autonomous vehicles becomes more challenging when both driver comfort and collision risk are considered. To overcome this challenge, a human-like motion planning strategy based on the probabilistic prediction in a dynamic environment is proposed. In this study, it is mainly concerned with the following three aspects: the probabilistic prediction of states of the surrounding vehicles, decision making of the optimal path with a cost function and speed planning based on the driver’s target speed. Firstly, the path generation is realized based on a fifth-degree polynomial and the desired path is optimized by a cost function with four performance indices, i.e., safety, consistency, smoothness, and distance from local path to global path. Secondly, collision detection is analyzed regarding the host vehicle and surrounding vehicles aspects. For the host vehicle, a path-tracking error relating to vehicle speed and road curvature is taken into account. For the surrounding vehicles, the probabilistic trajectory prediction is made by using the structural Long-Short Term Memory (LSTM) network. Next, the collision probability is assessed using the Monte Carlo method and the optimal path is selected through the probability threshold depending on driver styles such as a conservative or aggressive driver. Moreover, the human-like speed planning for longitudinal motion is implemented considering driver target speed in vehicle following and vehicle cut-in situations. Finally, the proposed human-like motion planning algorithm has been validated via Hardware-in-the-loop (HIL) tests. The simulation results have shown the effectiveness of dynamic obstacle avoidance with global path-tracking and speed-tracking with driver comfort. Parameter sensitivity analysis for cost function and speed planner is then performed. The sensitivity analysis and the results also illustrate the influence degree of various parameters on the planned trajectory, which would be conducive to further improving the algorithm performance in the future. With an appropriate selection of the weight ratio between safety and comfort proposed in this work, it is found that the driver’s comfort acceptance will be improved compared with the traditional deterministic motion planning algorithm .},
  archive      = {J_ASOC},
  author       = {Peng Li and Xiaofei Pei and Zhenfu Chen and Xingzhen Zhou and Jie Xu},
  doi          = {10.1016/j.asoc.2022.108499},
  journal      = {Applied Soft Computing},
  pages        = {108499},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Human-like motion planning of autonomous vehicle based on probabilistic trajectory prediction},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A decomposition-based constrained multi-objective
evolutionary algorithm with a local infeasibility utilization mechanism
for UAV path planning. <em>ASOC</em>, <em>118</em>, 108495. (<a
href="https://doi.org/10.1016/j.asoc.2022.108495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicle (UAV) path planning problems can be treated as constrained multi-objective optimization problems , which often have complicated constraints in real-world scenarios. Algorithms for solving them require a powerful constraint-handling technique to utilize infeasible information. However, this has seldom been explored in this field. To remedy this issue, this paper proposes a decomposition-based constrained multi-objective evolutionary algorithm (M2M-DW) with a local infeasibility utilization mechanism for UAV path planning . Therein, M2M-DW is adopted as a solution optimizer since it can utilize infeasible individuals. However, this may result in poor performance due to the arbitrary use of infeasible individuals. To solve this issue, a local infeasibility utilization mechanism is proposed to effectively utilize the infeasible information. Besides, an improved mutation scheme is designed to further explore the promising regions. Experimental studies are conducted on three sets of UAV path planning problems with different difficulties, and the results highlight the effectiveness of the proposed algorithm in terms of reliability and stability in finding a set of feasible optimal solutions.},
  archive      = {J_ASOC},
  author       = {Chaoda Peng and Shaojian Qiu},
  doi          = {10.1016/j.asoc.2022.108495},
  journal      = {Applied Soft Computing},
  pages        = {108495},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A decomposition-based constrained multi-objective evolutionary algorithm with a local infeasibility utilization mechanism for UAV path planning},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Solving time varying many-objective TSP with dynamic
θ-NSGA-III algorithm. <em>ASOC</em>, <em>118</em>, 108493. (<a
href="https://doi.org/10.1016/j.asoc.2022.108493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic many-objective traveling salesman problem (DMaTSP) has a lot of applications in routing challenges. The problem environment describe how the layout and number of cities involve in TSP varies over time. In this manuscript a sixteen cities DMaTSP problem is addressed with four fitness objectives : successive minimum distance between the cities, diametric minimum distance between cities and maximizing associated letters and gifts, which varies over six time periods. The paper introduce a prediction-based dynamic many-objective optimization technique termed as Dynamic θ θ -non-dominated Sorting Genetic Algorithm III (D θ θ -NSGA-III). The algorithm θ θ -NSGA-III, is based on the fundamentals of popular NSGA-III combined with vector angle-based evolutionary algorithm (VaEA). When a change occurs in the problem environment, the prediction set is used to generate the new population, to achieve faster convergence to the new global optimum. Four prediction strategies based on support vector regression (SVR) with linear kernel and radial basis function (RBF) kernel, polynomial interpolation, and cubic spline-based prediction are used for analysis. The validation of the D θ θ -NSGA-III algorithm has been carried out on sixteen benchmark functions taken from DIMP, G, JY and DF Test suites. Comparative analysis have been carried out with dynamic algorithms of NSGA-III, MOEA/D, MRP-MOEA and DNSGA-II algorithms. The simulation analysis reveals superior performance of D θ θ -NSGA-III with RBF kernel over the benchmark test suites as well as DMaTSP problem in the form of Mean of IGD, Shott’s Spacing, Max. Spread metrics. The proposed D θ θ -NSGA-III with prediction approaches solve dynamic many-objective optimization problems with effective run time bit higher than DNSGA-III but lower than DMOEA/D and MRP-MOEA based approach.},
  archive      = {J_ASOC},
  author       = {Rashi Gupta and Satyasai Jagannath Nanda},
  doi          = {10.1016/j.asoc.2022.108493},
  journal      = {Applied Soft Computing},
  pages        = {108493},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Solving time varying many-objective TSP with dynamic θ-NSGA-III algorithm},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Churn prediction in digital game-based learning using data
mining techniques: Logistic regression, decision tree, and random
forest. <em>ASOC</em>, <em>118</em>, 108491. (<a
href="https://doi.org/10.1016/j.asoc.2022.108491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Educational Technology (EdTech) is an industry that integrates education and technology advances. Digital game-based learning (DGBL) is one of the narrowed-down categories of EdTech. One of the common issues in the EdTech market is the higher churn rate. However, because the DGBL market is still in the early stage, few studies related to marketing perspectives exist. Besides, the approach in education or online gaming industries can be only partially applicable to DGBL. A popular approach for addressing a higher churn rate is churn prediction. By using a dataset from a Japanese company providing DGBL services, this work proposes an approach for the combination of defining churn and churn prediction for DGBL. This work has three objectives. First, determining churn in DGBL by comparing the recency and the addition of average and two standard deviations of user inactive time. Second, clarifying the churn rate of the Japanese service, which became evident as 56.77\% by using the newly created churn definition. Third, developing a churn prediction model by comparing logistic regression (LR), decision tree , and random forest models. Feature selection, dataset split ratio comparison, and hyperparameter tuning were conducted to achieve better predictions. Based on the results, LR scored the highest AUC of 0.9225 and an F1-score of 0.9194. These results are on the higher side comparing with the past churn prediction studies in online gaming and education industries. As a consequence, the results indicate the effectiveness of the proposed approach for churn determination and prediction in DGBL.},
  archive      = {J_ASOC},
  author       = {Mai Kiguchi and Waddah Saeed and Imran Medi},
  doi          = {10.1016/j.asoc.2022.108491},
  journal      = {Applied Soft Computing},
  pages        = {108491},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Churn prediction in digital game-based learning using data mining techniques: Logistic regression, decision tree, and random forest},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Community-based anomaly detection using spectral graph
filtering. <em>ASOC</em>, <em>118</em>, 108489. (<a
href="https://doi.org/10.1016/j.asoc.2022.108489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several applications have a community structure where the nodes of the same community share similar attributes. Anomaly or outlier detection in networks is a relevant and widely studied research topic with applications in various domains. Despite a significant amount of anomaly detection frameworks, there is a dearth on the literature of methods that consider both attributed graphs and the community structure of the networks. This paper proposes a community-based anomaly detection algorithm using a spectral graph-based filter that includes the network community structure into the Laplacian matrix adopted as the basis for the Fourier transform . In addition, the choice of the cutoff frequency of the filter considers the number of communities found. In computational experiments, the proposed strategy, called SpecF , showed an outstanding performance in successfully identifying even discrete anomalies. SpecF is better than a baseline disregarding the community structure, especially for networks with a higher community overlapping. Additionally, we present a case study to validate the proposed method to study the dissemination of COVID-19 in the different districts of São José dos Campos, Brazil .},
  archive      = {J_ASOC},
  author       = {Rodrigo Francisquini and Ana Carolina Lorena and Mariá C.V. Nascimento},
  doi          = {10.1016/j.asoc.2022.108489},
  journal      = {Applied Soft Computing},
  pages        = {108489},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Community-based anomaly detection using spectral graph filtering},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multimodal approach to chaotic renewable energy prediction
using meteorological and historical information. <em>ASOC</em>,
<em>118</em>, 108487. (<a
href="https://doi.org/10.1016/j.asoc.2022.108487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wind energy, which exhibits non-stationarity, randomness, and intermittency, is inextricably linked to meteorological data . The wind power series can be broken down into several subsequences using data decomposition techniques to make forecasting simpler and more accurate. Because of this, a single prediction model does not perform well in extracting hidden information from each subsequence. To predict different frequency series, this paper employed shallow and deep learning models and proposed an improved hybrid wind power prediction model based on secondary decomposition, extreme learning machines (ELM), convolutional neural networks (CNN), and bidirectional long short-term memory (BiLSTM). To begin, secondary decomposition was employed to break down the wind power series into several components. The ELM was used to forecast the low-frequency components. Following that, CNN was utilized to reintegrate the input characteristics of the high-frequency components, followed by BiLSTM prediction. Finally, the forecasting values for each component were added to generate the final prediction results. For one-, two-, and three-step predictions, the model was applied to the La Haute Borne wind farm . Additionally, four comparative experiments were conducted to validate the model’s usefulness. The suggested model’s mean absolute error (MAE), mean absolute percentage error (MAPE), and R-squared ( R 2 R2 ) values for one-step prediction of the March data were 14.87 kW, 22.24 kW, and 0.984, respectively, which indicate the proposed model’s superiority to other prediction models.},
  archive      = {J_ASOC},
  author       = {Hui Hwang Goh and Ronghui He and Dongdong Zhang and Hui Liu and Wei Dai and Chee Shen Lim and Tonni Agustiono Kurniawan and Kenneth Tze Kin Teo and Kai Chen Goh},
  doi          = {10.1016/j.asoc.2022.108487},
  journal      = {Applied Soft Computing},
  pages        = {108487},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multimodal approach to chaotic renewable energy prediction using meteorological and historical information},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SCSTCF: Spatial-channel selection and temporal regularized
correlation filters for visual tracking. <em>ASOC</em>, <em>118</em>,
108485. (<a href="https://doi.org/10.1016/j.asoc.2022.108485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, combining multiple features into discriminative correlation filters to improve tracking representation has shown great potential in object tracking. Existing trackers apply fixed weights to fuse features or fuse response maps, which cannot adapt to the object drift well. Moreover, in the tracking algorithm, using cyclic shift to obtain training samples always cause boundary effect, resulting in dissatisfied tracking effect. Therefore, we first design a multiple features fusion method. Various handcrafted features are fused with the same weight, then the fused handcrafted features and deep features are fused by adaptive weights, which considerably improves the representation ability of the tracking object. Second, we propose a correlation filter object function model called Spatial-Channel Selection and Temporal Regularized Correlation Filters. We perform the grouping features selection from the dimensions of channel, spatial and temporal, so as to establish the relevance between the multi-channel features and the correlation filter. Finally, we transform the objective function of the model with equality constraint to augmented Lagrangian multiplier formula without constraint, which is divided into three subproblems with closed-form solutions. The optimal solution is obtained by iteratively solving three subproblems using Alternating Direction Multiplier Method (ADMM). We conduct extensive experiments in four public datasets, OTB-2013, OTB-2015, TC128, UAV123, and VOT2016. The experimental results represent our proposed tracker performs favorably against other prevailing trackers in success rate and precision.},
  archive      = {J_ASOC},
  author       = {Jianming Zhang and Wenjun Feng and Tingyu Yuan and Jin Wang and Arun Kumar Sangaiah},
  doi          = {10.1016/j.asoc.2022.108485},
  journal      = {Applied Soft Computing},
  pages        = {108485},
  shortjournal = {Appl. Soft. Comput.},
  title        = {SCSTCF: Spatial-channel selection and temporal regularized correlation filters for visual tracking},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel improved SMA with quasi reflection operator:
Performance analysis, application to the image segmentation problem of
covid-19 chest x-ray images. <em>ASOC</em>, <em>118</em>, 108483. (<a
href="https://doi.org/10.1016/j.asoc.2022.108483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Slime mold algorithm (SMA) is a meta-heuristic optimization technique based on nature’s slime module oscillation modes. Like other meta-heuristic algorithms, SMA is prone to poor diversity, local optima, and imbalanced exploitation abilities. A new, quasi-reflected slime mold (QRSMA) method, which combines the SMA algorithm with a quasi-reflection-based learning mechanism (QRBL), is presented to increase SMA’s performance. The enhancement contains two parts: firstly, the QRBL mechanism was established to boost population variety early. Then, quasi-reflection-based jumping (QRBJ) was added to enhance convergence and avoid local optimum in each population update and to maintain the balance between exploitation and exploration. On the CEC20 benchmark functions of various kinds and dimensions, the performance of QRSMA was evaluated and checked that the proposed QRSMA’s more robust search capabilities compared to the classic SMA and different search methodologies in terms of statistical, convergence, and diversity measurement. The findings reveal that QRSMA can significantly increase the convergence speed and solution precision of the basic SMA and others by comparing it with basic SMA and other algorithms. Two further tests have also been conducted to assess QRSMA performance. The first is the division of 10 natural gray pictures. Next, the QRSMA was evaluated for a real-world application, such as COVID-19 X-ray images. The region of interest inside the picture containing the characteristics of COVID-19 must be extracted to increase the precision of the classification. Four X-ray images have thus been utilized to assess QRSMA’s performance. To evaluate the quality and performance of the QRSMA, comprehensive comparisons have also been carried out using different approaches. Overall test findings show that the QRSMA is an effective Multi-Level Thresholding (MLT) strategy superior to other current methods.},
  archive      = {J_ASOC},
  author       = {Sukanta Nama},
  doi          = {10.1016/j.asoc.2022.108483},
  journal      = {Applied Soft Computing},
  pages        = {108483},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A novel improved SMA with quasi reflection operator: Performance analysis, application to the image segmentation problem of covid-19 chest X-ray images},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-objective optimization of hexahedral pyramid crash box
using MOEA/d-DAE algorithm. <em>ASOC</em>, <em>118</em>, 108481. (<a
href="https://doi.org/10.1016/j.asoc.2022.108481">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crash box is an important energy-absorbing part of the automobile body, so this paper aims to explore a novel hexahedral pyramid (H-P) crash box with excellent overall performance, which is composed of H-P negative Poisson’s ratio (auxetic) inner core structure and outer shell layer. On this basis, a many-objective optimization design for the novel crash box is conducted to enhance its performance by integrating the response surface model (RSM) method and the multi-objective evolutionary algorithm based on decomposition with detecting and escaping strategy (MOEA/D-DAE). The results demonstrate that, compared with the hollow crash box, the hexagonal honeycomb crash box and the re-entrant hexagon crash box, the initial H-P crash box has better energy absorption characteristics and comprehensive crashworthiness. Moreover, the optimized novel H-P crash box with the MOEA/D-DAE can improve its crashworthiness, energy absorption capability and lightweight more effectively, and make the collision process more controllable and stable.},
  archive      = {J_ASOC},
  author       = {Weiwei Wang and Shijuan Dai and Wanzhong Zhao and Chunyan Wang},
  doi          = {10.1016/j.asoc.2022.108481},
  journal      = {Applied Soft Computing},
  pages        = {108481},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-objective optimization of hexahedral pyramid crash box using MOEA/D-DAE algorithm},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A biased genetic algorithm hybridized with VNS for the
two-dimensional knapsack packing problem with defects. <em>ASOC</em>,
<em>118</em>, 108479. (<a
href="https://doi.org/10.1016/j.asoc.2022.108479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a two-dimensional knapsack packing problem which packing a set of rectangles into a rectangular board to maximize the total value of the rectangles packed. The rectangle has finite types while its quantity is unlimited, and the board has unusable defects. A biased genetic algorithm hybridized with variable neighborhood search (VNS) is proposed to solve the problem as genetic algorithm can effectively solve the combinational optimization problem , has good searching performance, and is easy to implement. We adopt the replacing strategy for increasing the diversity of the population and avoiding converging too early. An improved placement procedure in charge of producing the layout is presented and four neighborhood structures are constructed. We conduct lots of numerical experiments using 5414 benchmark instances taken from the literature for evaluating our approach and comparing it to other excellent approaches. The experimental results show that the proposed algorithm gets many new best solutions in these benchmark instances and is very competitive.},
  archive      = {J_ASOC},
  author       = {Qiang Luo and Yunqing Rao and Xiaoqiang Guo and Bing Du},
  doi          = {10.1016/j.asoc.2022.108479},
  journal      = {Applied Soft Computing},
  pages        = {108479},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A biased genetic algorithm hybridized with VNS for the two-dimensional knapsack packing problem with defects},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CMML: Combined metaheuristic-machine learning for adaptable
routing in clustered wireless sensor networks. <em>ASOC</em>,
<em>118</em>, 108477. (<a
href="https://doi.org/10.1016/j.asoc.2022.108477">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cluster-based routing is the most common routing approach to achieve energy efficiency in wireless sensor networks . However, optimal determination of cluster heads is NP-hard, which calls for heuristics or metaheuristics for obtaining a near-optimal solution. Although metaheuristics achieve better performance, they suffer from high computational time, and thus, cannot rapidly respond to routing requests. Also, a large majority of the existing routing protocols cannot easily adapt to changing network or application configurations. In this paper, a Combined model based on Metaheuristics and Machine Learning , named CMML, is proposed to support efficient and adaptable routing in clustered wireless sensor networks . In our CMML model, a multi-criteria heuristic clustering algorithm is used for clustering in which a metaheuristic (e.g., genetic algorithm) is utilized for the automatic tuning of the heuristic algorithm for each configuration separately. We repeat this process for several configurations (i.e., for different network sizes, numbers of nodes, aggregation factors, lifetime definitions, etc.). The tuned heuristic algorithm in each configuration is subsequently used for network simulation to obtain the corresponding solution. As a result, a comprehensive dataset for different configurations is derived, which is used to train a machine learning model (e.g., support vector machine). The input feature vector of a sample comprises local features (current state of a node at a round), global features (current state of the network), and application-specific features, while the output is the priority factor of each node to be selected as a cluster head. After training the CMML model, it can be applied as a quickly adaptable clustering protocol . In fact, our motivation is to utilize the generalizability of machine learning to learn the behavioral pattern of the metaheuristic algorithm in finding best routes for previous configurations. Simulation results demonstrate that the CMML model can effectively adapt with different applications, while prolonging the network lifetime based on the application requirements.},
  archive      = {J_ASOC},
  author       = {Hojjatollah Esmaeili and Behrouz Minaei Bidgoli and Vesal Hakami},
  doi          = {10.1016/j.asoc.2022.108477},
  journal      = {Applied Soft Computing},
  pages        = {108477},
  shortjournal = {Appl. Soft. Comput.},
  title        = {CMML: Combined metaheuristic-machine learning for adaptable routing in clustered wireless sensor networks},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An automata algorithm for generating trusted graphs in
online social networks. <em>ASOC</em>, <em>118</em>, 108475. (<a
href="https://doi.org/10.1016/j.asoc.2022.108475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online social networks (OSNs) are becoming a popular tool for people to socialize and keep in touch with their friends. OSNs need trust evaluation models and algorithms to improve users’ quality of service and quality of experience . Graph-based approaches make up a major portion of existing methods, in which the trust value can be calculated through a trusted graph. However, this approach usually lacks the ability to find all trusted paths, and needs to put some restrictions to admit the process of finding trusted paths, causing trusted relations to be unreachable and leading to reduced coverage and accuracy. In this paper, graph-based and artificial intelligence approaches are combined to formulate a hybrid model for improving the coverage and accuracy of OSNs. In this approach, a distributed learning automata , which can be used to find all trusted relations without limitation, is employed instead of well-known graphic-based searching algorithms such as breadth-first search. Simulation results, conducted on real dataset of Epinions.com, illustrate an improvement of accuracy and coverage in comparison with state-of-the-art algorithms. The accuracy of the proposed algorithm is 0.9398, a 6\% increase in accuracy over existing comparable algorithms. Furthermore, by the successful removal of imposed restrictions in the existing searching process for finding trusted paths, this algorithm also leads to a 10\% improvement in coverage, reaching approximately 95\% of all existing trusted paths.},
  archive      = {J_ASOC},
  author       = {Nina Fatehi and Hadi Shahriar Shahhoseini and Jesse Wei and Ching-Ter Chang},
  doi          = {10.1016/j.asoc.2022.108475},
  journal      = {Applied Soft Computing},
  pages        = {108475},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An automata algorithm for generating trusted graphs in online social networks},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tree trunk texture classification using multi-scale
statistical macro binary patterns and CNN. <em>ASOC</em>, <em>118</em>,
108473. (<a href="https://doi.org/10.1016/j.asoc.2022.108473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated plant classification using tree trunk has attracted increasing interest in the computer vision community as a contributed solution for the management of biodiversity. It is based on the description of the texture information of the bark surface. The multi-scale variants of the local binary patterns have achieved prominent performance in bark texture description. However, these approaches encode the scale levels of the macrostructure separately from each other. In this paper, a novel handcrafted texture descriptor termed multi-scale Statistical Macro Binary Patterns (ms-SMBP) is proposed to encode the characterizing macro pattern of different bark species. The proposed approach consists of defining a sampling scheme at high scale levels and summarizing the intensity distribution using statistical measures. The characterizing macro pattern is encoded by an in-depth gradient that describes the relationship between the scale levels and their adaptive statistical prototype. Besides this handcrafted feature descriptor , a learning-based description is performed with the ResNet34 model for bark classification. Extensive and comprehensive experiments on challenging and large-scale bark datasets demonstrate the effectiveness of ms-SMBP to identify bark species and outperforming different multi-scale LBP approaches. The tree trunk classification with ResNet34 shows interesting results on a very large-scale dataset.},
  archive      = {J_ASOC},
  author       = {Safia Boudra and Itheri Yahiaoui and Ali Behloul},
  doi          = {10.1016/j.asoc.2022.108473},
  journal      = {Applied Soft Computing},
  pages        = {108473},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Tree trunk texture classification using multi-scale statistical macro binary patterns and CNN},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A triangular hashing learning approach for olfactory EEG
signal recognition. <em>ASOC</em>, <em>118</em>, 108471. (<a
href="https://doi.org/10.1016/j.asoc.2022.108471">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognition of olfactory-induced electroencephalogram (EEG) signals can provide an effective means for the research on disorder diagnostics and human–machine interaction. A novel triangular hashing (TH) approach is proposed for EEG signal recognition. The TH approach consists of a triangular feature construction and a hash inspired coding idea, which makes effective use of the feature differences between EEG electrodes. Firstly, a triangular feature set with N layers is constructed based on power-spectral density (PSD) features extracted from N electrodes for each frequency band of each olfactory EEG sample. Subsequently, the electrode orders, i.e. the TH codes for each layer of the constructed feature set are obtained by arranging the feature values in ascending order. Finally, the prediction type of the testing sample is determined by finding the most similar TH codes between EEG types and the testing sample. Experimental results reveal that for the recognition of olfactory EEG signals acquired from eleven subjects, the proposed TH recognition approach yields the considerably high accuracy of 93.0\%, significantly superior to the other eight traditional methods. Besides, the EEG dataset with 5005 samples used in this study is made public through the website presented in this paper. In this way, the proposed TH method combined with the published EEG dataset may provide new perspectives for further study in olfactory EEG research.},
  archive      = {J_ASOC},
  author       = {Hui-Rang Hou and Qing-Hao Meng and Biao Sun},
  doi          = {10.1016/j.asoc.2022.108471},
  journal      = {Applied Soft Computing},
  pages        = {108471},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A triangular hashing learning approach for olfactory EEG signal recognition},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Discrete sparrow search algorithm for symmetric traveling
salesman problem. <em>ASOC</em>, <em>118</em>, 108469. (<a
href="https://doi.org/10.1016/j.asoc.2022.108469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traveling salesman problem (TSP) is one of the most intensively studied problems in computational mathematics . This paper proposes a swarm intelligence approach using a discrete sparrow search algorithm (DSSA) with a global perturbation strategy to solve the problem. Firstly, the initial solution in the population is generated by the roulette-wheel selection. Secondly, the order-based decoding method is introduced to complete the update of the sparrow position. Then, the global perturbation mechanism combined with Gaussian mutation and swap operator is adopted to balance exploration and exploitation capability. Finally, the 2-opt local search is integrated to further improve the quality of the solution. Those strategies enhance the solution’s quality and accelerate the convergence. Experiments on 34 TSP benchmark datasets are conducted to investigate the performance of the proposed DSSA. And statistical tests are used to verify the significant differences between the proposed DSSA and other state-of-the-art methods. Results show that the proposed method is more competitive and robust in solving the TSP.},
  archive      = {J_ASOC},
  author       = {Zhen Zhang and Yang Han},
  doi          = {10.1016/j.asoc.2022.108469},
  journal      = {Applied Soft Computing},
  pages        = {108469},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Discrete sparrow search algorithm for symmetric traveling salesman problem},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A fuzzy mathematical model for tumor growth pattern using
generalized hukuhara derivative and its numerical analysis.
<em>ASOC</em>, <em>118</em>, 108467. (<a
href="https://doi.org/10.1016/j.asoc.2022.108467">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy mathematical modeling has been extensively used in recent years as a helpful tool to achieve a stronger and broader understanding of a specific biological topic such as cancer. The Fuzzy mathematical model allows one to analyze the structure both qualitatively and quantitatively using mathematical methods and clarifies a tool for observing the results of different components and making behavioral projection. To reduce the ambiguity of model parameters, a fuzzy environment has been designed to address a more accurate mathematical tumor growth model. The complete pattern of tumor growth mechanism is captured with the fuzzy mathematical model using fuzzy differential equation. The concept of Generalized Hukuhara derivative is used to transform the differential equation into a system of two ordinary differential equations. The numerical simulation has also been given to support the mathematical tumor growth model in a fuzzy environment.},
  archive      = {J_ASOC},
  author       = {Rubeena Khaliq and Pervaiz Iqbal and Shahid Ahmad Bhat and Aadil Rashid Sheergojri},
  doi          = {10.1016/j.asoc.2022.108467},
  journal      = {Applied Soft Computing},
  pages        = {108467},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A fuzzy mathematical model for tumor growth pattern using generalized hukuhara derivative and its numerical analysis},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An interval type-2 fuzzy sets based delphi approach to
evaluate site selection indicators of sustainable vehicle shredding
facilities. <em>ASOC</em>, <em>118</em>, 108465. (<a
href="https://doi.org/10.1016/j.asoc.2022.108465">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to rank indicators affecting site selection of vehicle shredding facilities using an interval type-2 fuzzy sets based Delphi approach. The introduced methodology consists of four consecutive stages as follows: indicator identification, questionnaire (survey), decision-making analysis, and statistical analysis and indicator classification. In the first stage, the literature searches are performed on vehicle shredding facility location and forty-eight relevant indicators are determined. In the second stage, a questionnaire has been conducted to collect the preferences of relevant international experts from different countries regarding the indicators. Then, the importance of site selection indicators is obtained to define critical, medium, and uncritical indicators. In the last stage, the analysis are carried out to make a distinction between groups of participants who respond similarly and discover viewpoints from the industry and academia. The research findings show that the most important indicator for locating vehicle shredding facilities is a financial benefit. Critical indicators, which should be taken into account when locating vehicle shredding facilities, are acquisition cost, affected population, demand fluctuations, end-of-life vehicle policy, financial benefit, land availability, operational costs, recycling system, resource accessibility, and safety management.},
  archive      = {J_ASOC},
  author       = {Muhammet Deveci and Vladimir Simic and Selman Karagoz and Jurgita Antucheviciene},
  doi          = {10.1016/j.asoc.2022.108465},
  journal      = {Applied Soft Computing},
  pages        = {108465},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An interval type-2 fuzzy sets based delphi approach to evaluate site selection indicators of sustainable vehicle shredding facilities},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Session-based social and dependency-aware software
recommendation. <em>ASOC</em>, <em>118</em>, 108463. (<a
href="https://doi.org/10.1016/j.asoc.2022.108463">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increase of complexity of modern software, social collaborative coding and reuse of open source software packages become more and more popular, which thus greatly enhances the development efficiency and software quality. However, the explosive growth of open source software packages exposes developers to the challenge of information overload. While this can be addressed by conventional recommender systems , they usually do not consider particular constraints of social coding such as social influence among developers and dependency relations among software packages. In this paper, we aim to model the dynamic interests of developers with both social influence and dependency constraints, and propose the Session-based Social and Dependency-aware software Recommendation (SSDRec) model. This model integrates recurrent neural network (RNN) and graph attention network (GAT) into a unified framework. An RNN is employed to model the short-term dynamic interests of developers in each session and two GATs are utilized to capture social influence from friends and dependency constraints from dependent software packages, respectively. Extensive experiments are conducted on real-world datasets and the results demonstrate that our model significantly outperforms the competitive baselines.},
  archive      = {J_ASOC},
  author       = {Dengcheng Yan and Tianyi Tang and Wenxin Xie and Yiwen Zhang and Qiang He},
  doi          = {10.1016/j.asoc.2022.108463},
  journal      = {Applied Soft Computing},
  pages        = {108463},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Session-based social and dependency-aware software recommendation},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cross-network representation learning for anchor users on
multiplex heterogeneous social network. <em>ASOC</em>, <em>118</em>,
108461. (<a href="https://doi.org/10.1016/j.asoc.2022.108461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online users are typically involved in multiple online social networks simultaneously to enjoy a variety of social network services , thus bringing about the interconnection of online social networks via bridge users called anchor users . Anchor users can be beneficial to a wide range of social network analysis applications such as cross-domain system recommendation, cross-network information diffusion , and link prediction, taking anchor user’s intra-network structural information along with its cross-network structural properties into consideration. Several studies have so far tried to learn low-dimensional representations of social users by capturing their network structures inside one social network but they have not fully leveraged their intra-network structures with their cross-network structures to boost the performance of the aforementioned analysis tasks. In this paper, we present a novel deep learning model to learn O verall low-dimensional V ector R epresentations for A nchor U sers (OVRAU), from a multiplex heterogeneous social network by investigating the intra-network as well as the cross-network structural information. Unlike previous works, our proposed model considers the multi-network scenario to encode diverse network structures of anchor users. We propose two types of embeddings to capture the different structural information of an anchor user from multiple social networks: a high-dimensional base embedding and a low-dimensional social edge embedding for each social network. In particular, we learn a function that generates social edge embeddings by sampling and aggregating structural features from an anchor user’s neighborhood inside different social networks through one of three candidate aggregator functions namely mean, max-pooling and LSTM , with a self-attention mechanism. Link prediction is used as a downstream task to evaluate the effectiveness of the learned embeddings. Experiments were conducted on real-world social networks dataset, and the results demonstrate that our proposed model involving all the three variants can significantly outperform the existing network representation learning approaches when applied on the link prediction task and also achieve better performance over all compared baselines.},
  archive      = {J_ASOC},
  author       = {Amina Amara and Mohamed Ali Hadj Taieb and Mohamed Ben Aouicha},
  doi          = {10.1016/j.asoc.2022.108461},
  journal      = {Applied Soft Computing},
  pages        = {108461},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Cross-network representation learning for anchor users on multiplex heterogeneous social network},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimization of energy-efficient open shop scheduling with
an adaptive multi-objective differential evolution algorithm.
<em>ASOC</em>, <em>118</em>, 108459. (<a
href="https://doi.org/10.1016/j.asoc.2022.108459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There have been growing interests in the energy-efficient production scheduling recently because of the growing shortage of energy. Open shop scheduling problem (OSSP) is a kind of common but seldom concerned production scheduling problem. This paper focuses on energy-efficient OSSP (EOSSP), where the effect of setup operation on production efficiency and energy consumption is considered. A multi-objective energy-efficient model based on machine speed scaling mechanism is proposed. To handle this multi-objective problem, we propose an effective adaptive multi-objective differential evolution (AMODE) algorithm. The AMODE uses a new fitness evaluation mechanism (FEM) based on dynamic reference point and fuzzy correlation entropy analysis to assess the solutions in evolution population. It also uses an adaptive opposition-based learning (AOBL) to improve its local search ability. Taguchi method is utilized to obtain the best combination of critical parameters of the AMODE. The proposed mathematical model is validated with CPLEX, and a lexicographic method is used to determine the preferable solution. Experimental results show that both our proposed FEM and AOBL can improve the performance of AMODE. Extensive experiments reveal that the performance of AMODE is superior to the other three well-known algorithms in addressing the EOSSP.},
  archive      = {J_ASOC},
  author       = {Lijun He and Yulian Cao and Wenfeng Li and Jingjing Cao and Lingchong Zhong},
  doi          = {10.1016/j.asoc.2022.108459},
  journal      = {Applied Soft Computing},
  pages        = {108459},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Optimization of energy-efficient open shop scheduling with an adaptive multi-objective differential evolution algorithm},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Entropy measure for a fuzzy relation and its application in
attribute reduction for heterogeneous data. <em>ASOC</em>, <em>118</em>,
108455. (<a href="https://doi.org/10.1016/j.asoc.2022.108455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A fuzzy binary relation (for short, fuzzy relation) is a fundamental notion in fuzzy set theory . This paper proposes novel entropy measure for a fuzzy relation and considers its application to attribute reduction for heterogeneous data . We first define a new fuzzy entropy to compute the uncertainty of a fuzzy relation and then put forward the notions of joint information entropy, conditional information entropy and mutual information entropy in an information system with heterogeneous data . The proposed measure can overcome the weakness of the existing measure. Next, we apply the proposed measure to perform attribute reduction in this kind of information systems. Finally, we make experimental analysis to check the feasibility and efficiency of the proposed attribute reduction algorithms.},
  archive      = {J_ASOC},
  author       = {Liangdong Qu and Jiali He and Gangqiang Zhang and Ningxin Xie},
  doi          = {10.1016/j.asoc.2022.108455},
  journal      = {Applied Soft Computing},
  pages        = {108455},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Entropy measure for a fuzzy relation and its application in attribute reduction for heterogeneous data},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Customer-oriented product design using an integrated
neutrosophic AHP &amp; DEMATEL &amp; QFD methodology. <em>ASOC</em>,
<em>118</em>, 108445. (<a
href="https://doi.org/10.1016/j.asoc.2022.108445">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing product variety, companies aim to become better than their competitors by providing a superior product developed with a customer-oriented product design approach and a quality strategy. In order to achieve this, companies should well understand customer expectations and quickly be able to convert these expectations to technical characteristics. Since the expectations consist of mostly subjective judgments, this evaluation process contains vagueness and impreciseness. A triplet represents the uncertainty in subjective judgments: the degrees of belongingness or Truthiness (T), non-belongingness or Falsity (F), and indeterminacy (I). For this reason, in this paper, a neutrosophic Quality Function Deployment (QFD) methodology based on neutrosophic AHP and neutrosophic DEMATEL is developed and applied to the design of a car seat. In this methodology, the weighting of customer requirements is performed by neutrosophic AHP. The relationships among the technical characteristics are determined by neutrosophic DEMATEL for the customer-oriented product design, considering both impreciseness in the data and indeterminacy of the decision-makers. In other words, the contribution of this paper is that the proposed methodology provides better integration of the voice of customers into technical characteristics through a practical fuzzy multi-criteria decision analysis. Based on the results, it is revealed that seat height is the most important technical characteristic, followed by vertical travel range and horizontal travel range. Moreover, validity and verification of the proposed methodology have been tested with other methods presented in the literature. Sensitivity analyses have been carried out to show the flexibility of the given decisions under different cases. Lastly, possible implications on theoretical and managerial aspects have been discussed.},
  archive      = {J_ASOC},
  author       = {Ali Karasan and Esra Ilbahar and Selcuk Cebi and Cengiz Kahraman},
  doi          = {10.1016/j.asoc.2022.108445},
  journal      = {Applied Soft Computing},
  pages        = {108445},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Customer-oriented product design using an integrated neutrosophic AHP &amp; DEMATEL &amp; QFD methodology},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A simulated annealing based heuristic for a location-routing
problem with two-dimensional loading constraints. <em>ASOC</em>,
<em>118</em>, 108443. (<a
href="https://doi.org/10.1016/j.asoc.2022.108443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A hybrid heuristic is proposed to solve a location-routing problem with two-dimensional loading constraints. This problem appears in military situations and natural disasters in such a way that decisions are taken in a short time horizon. The proposed heuristic combines the simulated annealing method and the artificial algae algorithm. Simulated annealing is used to handle the location-routing problem, while the artificial algae algorithm is used to determine the sequence in which the items will be packed. Therefore, we apply the Skyline technique to find a feasible packing of such items onto the vehicle’s rectangular surface. As there is no other work in the literature handling the location-routing problem with two-dimensional loading constraints that we can compare the results, we evaluate the heuristic performance on its subproblems : the location-routing problem and the vehicle routing problem with two-dimensional loading constraints. Although the heuristic is not designed for these subproblems , it still obtains competitive results, with an average relative difference of 1.26\% and equal or better solutions for more than 90 instances. Regarding the problem under study, the heuristic obtains solutions close to an estimated lower bound for instances having more items per customer.},
  archive      = {J_ASOC},
  author       = {Kamyla Maria Ferreira and Thiago Alves de Queiroz},
  doi          = {10.1016/j.asoc.2022.108443},
  journal      = {Applied Soft Computing},
  pages        = {108443},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A simulated annealing based heuristic for a location-routing problem with two-dimensional loading constraints},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cybersecurity of multi-cloud healthcare systems: A
hierarchical deep learning approach. <em>ASOC</em>, <em>118</em>,
108439. (<a href="https://doi.org/10.1016/j.asoc.2022.108439">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increase in sophistication and connectedness of the healthcare networks, their attack surfaces and vulnerabilities increase significantly. Malicious agents threaten patients’ health and life by stealing or altering data as it flows among the multiple domains of healthcare networks. The problem is likely to exacerbate with the increasing use of IoT devices, edge, and core clouds in the next generation healthcare networks. Presented in this paper is MUSE, a system of deep hierarchical stacked neural networks for timely and accurate detection of malicious activity that leads to alteration of meta-information or payload of the dataflow between the IoT gateway, edge and core clouds. Smaller models at the edge clouds take substantially less time to train as compared to the large models in the core cloud. To improve the speed of training and accuracy of detection of large core cloud models, the MUSE system uses a novel method of merging and aggregating layers of trained edge cloud models to construct a partly pre-trained core cloud model. As a result, the model in the core cloud takes substantially smaller number of epochs (6 to 8) and, consequently, less time, compared to those in the edge clouds, training of which take 35 to 40 epochs to converge. With the help of extensive evaluations, it is shown that with the MUSE system, large, merged models can be trained in significantly less time than the unmerged models that are created independently in the core cloud. Through several runs it is seen that the merged models give on an average 26.2\% reduction in training times. From the experimental evaluation we demonstrate that along with fast training speeds the merged MUSE model gives high training and test accuracies, ranging from 95\% to 100\%, in detection of unknown attacks on dataflows. The merged model thus generalizes very well on the test data. This is a marked improvement when compared with the accuracy given by un-merged model as well as accuracy reported by other researchers with newer datasets.},
  archive      = {J_ASOC},
  author       = {Lav Gupta and Tara Salman and Ali Ghubaish and Devrim Unal and Abdulla Khalid Al-Ali and Raj Jain},
  doi          = {10.1016/j.asoc.2022.108439},
  journal      = {Applied Soft Computing},
  pages        = {108439},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Cybersecurity of multi-cloud healthcare systems: A hierarchical deep learning approach},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Impersonation fraud detection on building access control
systems: An approach based on anomalous social and spatio-temporal
behaviors. <em>ASOC</em>, <em>118</em>, 108310. (<a
href="https://doi.org/10.1016/j.asoc.2021.108310">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly-based impersonation detection consists in constructing typical profiles based on users’ frequent behaviors and comparing them with new data. The underlying idea is that a very different behavior may indicate possible fraud, i.e., someone trying to impersonate the user. Most research in the area aims to use spatiotemporal data broadly available from ubiquitous location sensors, e.g., GPS, mobile telephony, beacons, and Physical Access Control Systems. Many studies achieved good performance in finding social bonds among users. Our previous work Silva and Sichman (2019) combined concepts from previous research and proposed using social groups to construct mobility profiles to enhance anomaly-detection. This paper extends our previous work and explores the feasibility of using spatiotemporal mobility profiles enriched with group patterns for fraud detection in Physical Access Control Systems. An empirical analysis is conducted using data from two real-world datasets, and results show that it is feasible to add companions activities information to mobility profiles to enhance anomaly-based impersonation attack detection.},
  archive      = {J_ASOC},
  author       = {Gabriel Mariano de Castro Silva and Jaime Simão Sichman},
  doi          = {10.1016/j.asoc.2021.108310},
  journal      = {Applied Soft Computing},
  pages        = {108310},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Impersonation fraud detection on building access control systems: An approach based on anomalous social and spatio-temporal behaviors},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Corrigendum to “an advanced YOLOv3 method for small-scale
road object detection” [appl. Soft comput. 112 (2021) 107846].
<em>ASOC</em>, <em>118</em>, 108289. (<a
href="https://doi.org/10.1016/j.asoc.2021.108289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ASOC},
  author       = {Kun Wang and Maozhen Liu and Zhaojun Ye},
  doi          = {10.1016/j.asoc.2021.108289},
  journal      = {Applied Soft Computing},
  pages        = {108289},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Corrigendum to “An advanced YOLOv3 method for small-scale road object detection” [Appl. soft comput. 112 (2021) 107846]},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Soft computing for recommender systems and sentiment
analysis. <em>ASOC</em>, <em>118</em>, 108246. (<a
href="https://doi.org/10.1016/j.asoc.2021.108246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ASOC},
  author       = {Lorenzo Malandri and Carlos Porcel and Frank Xing and Jesus Serrano-Guerrero and Erik Cambria},
  doi          = {10.1016/j.asoc.2021.108246},
  journal      = {Applied Soft Computing},
  pages        = {108246},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Soft computing for recommender systems and sentiment analysis},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Carbon price forecasting system based on error correction
and divide-conquer strategies. <em>ASOC</em>, <em>118</em>, 107935. (<a
href="https://doi.org/10.1016/j.asoc.2021.107935">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Carbon price forecasting is an important component of a sound carbon price market mechanism. The accurate prediction of carbon prices is an active topic of research. However, many previous studies have focused on the application of a single model, ignoring the application of combination strategies. In this study, a hybrid forecasting system that includes error correction strategy and divide-conquer strategy is designed to predict the carbon price series accurately. Specifically, the main framework of this article comprises four modules. Data preprocessing module of the divide and conquer strategy is proposed. Next, the optimization module uses a multi-objective grasshopper optimization algorithm to enhance the performance of the prediction module. Then, the error correction module predicts the error sequence and corrects the model results. To verify the performance of the established hybrid forecasting system, experiments were performed using two real carbon price series from China and European Union emissions trading schemes , and the results showed that the mean absolute percentage errors of the system were 2.7793\% and 0.6720\%, respectively, which are better than the other benchmark methods considered. Moreover, it was proved that the designed forecasting system provides a new, effective, and feasible solution for carbon price forecasting.},
  archive      = {J_ASOC},
  author       = {Xinsong Niu and Jianzhou Wang and Lifang Zhang},
  doi          = {10.1016/j.asoc.2021.107935},
  journal      = {Applied Soft Computing},
  pages        = {107935},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Carbon price forecasting system based on error correction and divide-conquer strategies},
  volume       = {118},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-scale attention recalibration network for crowd
counting. <em>ASOC</em>, <em>117</em>, 108457. (<a
href="https://doi.org/10.1016/j.asoc.2022.108457">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowd counting using deep convolutional neural networks (CNN) has achieved encouraging progress in recent years. Nevertheless, how to efficiently address the problems of scale variation and complex backgrounds remain a major challenge. For this, we present an innovative Multi-scale Attention Recalibration Network termed MARNet for obtaining more accurate crowd counting. This is achieved mainly by introducing and integrating two significant modules into the proposed model. More concretely, a Feature Pyramid Module (FPM) is first designed to achieve multi-scale feature enhancement by utilizing multiple dilated convolutions with different rates, thus providing rich contextual information for subsequent operations. Besides, to adequately take advantage of these contextual information, a Feature Recalibration Module (FRM) is devised by integrating a Dimension Attention (DA) block with a Region Recalibration (RR) block. The DA block is mainly used for modeling the semantic dependencies between different dimensions of contextual information, while the RR block is responsible for reassigning attention weights for different regions based on the semantic dependencies. By the integration of the above two blocks, the proposed method can be targeted to capture the crowd features for accurately estimating crowd density. Extensive experiments on multiple publicly crowd counting datasets well demonstrate that our method significantly outperforms most existing methods in terms of the counting accuracy and the quality of the generated density map.},
  archive      = {J_ASOC},
  author       = {Jinyang Xie and Chen Pang and Yanjun Zheng and Liang Li and Chen Lyu and Lei Lyu and Hong Liu},
  doi          = {10.1016/j.asoc.2022.108457},
  journal      = {Applied Soft Computing},
  pages        = {108457},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-scale attention recalibration network for crowd counting},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Performance-based emergency landing trajectory planning
applying meta-heuristic and dubins paths. <em>ASOC</em>, <em>117</em>,
108453. (<a href="https://doi.org/10.1016/j.asoc.2022.108453">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emergency Landing is a complex problem of optimal path planning of an impaired airplane in presence of obstacles, while the airplane performance characteristics have degraded. Some in-flight failures can affect the airplane dynamics and therefore the new dynamic constraints must be considered in flight planning to the desired landing site. This paper introduces a novel hybrid form of Dubins-simulated annealing (HDSA) optimization framework for emergency landing. The proposed architecture applies Dubins paths and Apollonius’ tangent line to generate candidate pieces of trajectories respecting the post-failure performance characteristics of the distressed airplane. The optimization pattern is used to select the optimal combination of the candidate trajectories based on the cost functions and the environmental constraints to lead the airplane to the desired landing site. Analytical performance-based equations are developed to achieve an admissible solution in emergency trajectory planning . The goal is to provide a general optimal framework, which can enhance the flight management system by assisting the pilot to plan the most suitable and admissible trajectory to the landing site in emergency flight conditions. The effectiveness of the proposed approach is demonstrated through simulations.},
  archive      = {J_ASOC},
  author       = {Hassan Haghighi and Daniel Delahaye and Davood Asadi},
  doi          = {10.1016/j.asoc.2022.108453},
  journal      = {Applied Soft Computing},
  pages        = {108453},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Performance-based emergency landing trajectory planning applying meta-heuristic and dubins paths},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). A generative adversarial network with joint multistream
architecture and spectral compensation for pansharpening. <em>ASOC</em>,
<em>117</em>, 108451. (<a
href="https://doi.org/10.1016/j.asoc.2022.108451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) and variational models for pansharpening have obtained a compelling performance gain over the state of the art. Inspired by these models, we propose MSCGAN, a generative adversarial network (GAN) with joint multistream architecture and spectral compensation for pansharpening that uses a variational model to incorporate domain-specific knowledge and in particular, introduces a spectral compensation block. First, we extract the structural information of the panchromatic (PAN) image and input it into the generator together with the upsampled multispectral (MS) image. Then, we design a multistream pansharpening CNN architecture suite for domain-specific knowledge. Second, to boost the quality of the pansharpened images, we put the MS image in the generator and design a spectral compensation block. Then, we introduce the concept of the energy function of the variational model and add corresponding spectral constraints and spatial structure constraints to the objective function to achieve a compromise between spectral information fidelity and spatial information fidelity . Finally, the discriminator also introduces spatial structure information to help the generator generate the desired high-resolution multispectral image . Experiments on the images captured by the Quickbird and WorldView-2 satellites show that the our proposed MSCGAN can make use of PAN and LRMS images adequately to attain very encouraging results, obtaining large gains over the state of the art both visually and as measured by quality metrics.},
  archive      = {J_ASOC},
  author       = {Liping Zhang and Weisheng Li and Jiahao Du and Dajiang Lei},
  doi          = {10.1016/j.asoc.2022.108451},
  journal      = {Applied Soft Computing},
  pages        = {108451},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A generative adversarial network with joint multistream architecture and spectral compensation for pansharpening},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The fuzzy filter based on the method of areas’ ratio.
<em>ASOC</em>, <em>117</em>, 108449. (<a
href="https://doi.org/10.1016/j.asoc.2022.108449">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper describes a new fuzzy filter based on the method of areas’ ratio which allows to reduce noise during filtering signals. To expand the functionality of the method of areas’ ratio two computational procedures were developed to eliminate errors inherent in classical defuzzification models, namely a narrow range of defuzzification and insensitivity of a defuzzification model. Presented various computational procedures for the fuzzy filter can change the properties of the output variable resulting. As an example, the proposed mathematical model of the Fuzzy Filter based on the Method of Areas’ Ratio illustrated its distinctive characteristics are shown. Firstly, the Fuzzy Filter based on the Method of Areas’ Ratio model has the property of continuity. Secondly, computational procedures provide an increase in the performance of the fuzzy filter. Using detailed numerically calculated Root Mean Square Error and Mean Absolute Percentage Error evaluated the proposed model of the fuzzy filter with other filters such as Kalman Filter , Fuzzy Kalman Filter , Ensemble Kalman Filter and Fuzzy Extended Kalman Filter , Basic defuzzification distributions, Fuzzy mean, Quality method, Root mean square and New weighted trapezoid median average. One of the main goals of the article was to confirm the hypothesis about the possibility of using a fuzzy filter based on the method of area’s ratio for filtering signals. As well as studies of the sensitivity of the proposed fuzzy filter is based on the Root Mean Square Error and Mean Absolute Percentage Error coefficients . These coefficients were established during the experimental studies and showed that the sensitivity of the fuzzy filter based on the method of area’s ratio is better than other filters.},
  archive      = {J_ASOC},
  author       = {Maxim V. Bobyr and Natalia A. Milostnaya and Valentin A. Bulatnikov},
  doi          = {10.1016/j.asoc.2022.108449},
  journal      = {Applied Soft Computing},
  pages        = {108449},
  shortjournal = {Appl. Soft. Comput.},
  title        = {The fuzzy filter based on the method of areas’ ratio},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interpretable cognitive learning with spatial attention for
high-volatility time series prediction. <em>ASOC</em>, <em>117</em>,
108447. (<a href="https://doi.org/10.1016/j.asoc.2022.108447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In reality, some kinds of time series have the characteristics of high volatility, where fluctuation patterns of sequential data contain rich semantic knowledge and represent the spatial features from two-dimensional perspective. Especially, some non-trivial fluctuations may provide key information for the forecasting of time series. However, how to appropriately represent the fluctuation patterns and achieve the causal reasoning among them remains open. In this work, by learning the causal knowledge of fluctuation patterns, a novel spatial attention fuzzy cognitive map with high-order structure is proposed for the interpretable prediction of time series with high volatility. Firstly, a kind of extended polar fuzzy information granules is utilized to convert time series into granule sequences with interpretable fluctuation features, based on which fuzzy cognitive maps can be constructed by using full data-driven way. Secondly, in order to capture the key fluctuation patterns, the attention mechanism is first introduced into fuzzy cognitive map , where the spatial features of the focused patterns can be taken fully utilized. Thirdly, the high-order structure is involved into the proposed model for the learning of the temporal knowledge existing in the pattern sequences. Finally, real-world financial time series with strong noises and high volatility are empirically utilized to verify the promising performance of the proposed method.},
  archive      = {J_ASOC},
  author       = {Fengqian Ding and Chao Luo},
  doi          = {10.1016/j.asoc.2022.108447},
  journal      = {Applied Soft Computing},
  pages        = {108447},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Interpretable cognitive learning with spatial attention for high-volatility time series prediction},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploiting variability in the design of genetic algorithms
to generate telerehabilitation activities. <em>ASOC</em>, <em>117</em>,
108441. (<a href="https://doi.org/10.1016/j.asoc.2022.108441">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing number of people with impairments and the lack of specialists has led to a loss of efficiency to deliver proper treatments from National healthcare systems. In this light, telerehabilitation can play an important role as patients can perform certain therapies at home. Consequently, telerehabilitation systems must support delivering bespoke therapies to patients tailored to their deficits and preferences. However, creating bespoke telerehabilitation activities is a complex and time-consuming task because of the great assortment of deficits. To address this problem, we propose in this research work an automatic generation of such telerehabilitation activities aiming to both assist the specialist in designing and creating telerehabilitation activities that best fit each patient’s needs. Therefore, the main contributions of this paper are: (1) the exploitation of Feature Models (FM) to describe the variability in the telerehabilitation domain and to facilitate the communication among the stakeholders to accurately specify the patients’ deficits and the features of an association telerehabilitation activity. (2) The design and development of a genetic algorithm (GA) relying on the specified FM able to generate customized association telerehabilitation activities. The FM specified describes precisely the search problem so that the GA chromosomes can be easily identified. It also facilitates the discussion with the stakeholders during the design of the algorithm since its specification can be understood by non-experts in Computer Science. (3) The evaluation of the effectiveness and efficiency of the GA developed by using two sets of experiments: one for tuning the parameters of the GA and another to assess the effectiveness and efficiency of the algorithm while stressed under constraining conditions. (4) The integration of the proposal with a tool for telerehabilitation of people with Acquired Brain Injury (ABI). The proposal targets people with ABI because of the wide assortment of deficits they present, as well as the high impact ABI is having on society, being currently more common than breast cancer, spinal cord injury, HIV/AIDS and multiple sclerosis (MS) combined.},
  archive      = {J_ASOC},
  author       = {Alejandro Moya and Elena Navarro and Javier Jaén and Víctor López-Jaquero and Rafael Capilla},
  doi          = {10.1016/j.asoc.2022.108441},
  journal      = {Applied Soft Computing},
  pages        = {108441},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Exploiting variability in the design of genetic algorithms to generate telerehabilitation activities},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A reinforcement learning guided adaptive cost-sensitive
feature acquisition method. <em>ASOC</em>, <em>117</em>, 108437. (<a
href="https://doi.org/10.1016/j.asoc.2022.108437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the existing feature selection methods tend to pursue the learning performance of the selected feature subset while ignoring the costs of acquiring each feature. However, in real-world problems, we often face the tradeoff between model performance and feature costs because of limited resources. Moreover, in some applications (e.g. medical tests), features are acquired sequentially in the learning process instead of having known the information of the whole feature set in advance. To solve these problems we design a reinforcement learning agent to guide the cost-sensitive feature acquisition process and propose a deep learning-based model to select the informative and lower-cost features for each instance adaptively. The whole process of feature acquisition will be determined by an agent according to what it has observed from inputs. In particular, a Recurrent Neural Network (RNN) model will learn the knowledge from the current sample and the agent will give the instructions on whether the RNN model will continue to select the next feature or stop the sequential feature acquisition process. Moreover, the proposed method can also select the features per block thus it can deal with high dimensional data . We evaluate the effectiveness of the proposed method on a variety of datasets including benchmark datasets, gene datasets, and medical datasets. Compared with the state-of-the-art feature selection methods, the proposed method can achieve comparable learning accuracy while maintaining lower feature costs.},
  archive      = {J_ASOC},
  author       = {Chaojie An and Qifeng Zhou and Shen Yang},
  doi          = {10.1016/j.asoc.2022.108437},
  journal      = {Applied Soft Computing},
  pages        = {108437},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A reinforcement learning guided adaptive cost-sensitive feature acquisition method},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An integrated qualitative group decision-making method for
assessing health-care waste treatment technologies based on linguistic
terms with weakened hedges. <em>ASOC</em>, <em>117</em>, 108435. (<a
href="https://doi.org/10.1016/j.asoc.2022.108435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The assessment of the treatment technologies is a vital point for health care waste (HCW) management. The assessment process is regarded as a multi-attribute group decision-making problem. Considering individual knowledge backgrounds and psychological preferences, and various uncertainty factors which are difficult to describe numerical and precisely, experts often portray their individual assessments by employing qualitative expressions. Linguistic term with weakened hedge (LTWH) is an effective tool to quantify the qualitative information. Additionally, the Bonferroni mean (BM) can capture the interrelationship between input data and the combined compromise solution (CoCoSo) method could produce reliable outcomes. In this paper, we extend the BM operator into the LTWH environment and propose the linguistic term with weakened hedge BM (LTWHBM) operator and the weighted version, i.e., LTWHWBM, to depict the indeterminacy in the HCW management and cope with assessment of the treatment technology problems based on the developed novel operational rules of LTWHs. Various properties and special cases of these operators are investigated in detail. Furthermore, we design a LTWHWBM based CoCoSo group decision-making model, herein the LTWHWBM operator is employed to integrate individual experts’ preferences and the extend CoCoSo method is utilized to yield the ranking of alternatives. Ultimately, a case study concerning the assessment of the HCW treatment technologies is performed. The feasibility and favorable characteristics of the established model are justified by the comparisons with several prevailing methodologies and sensitivity analyses.},
  archive      = {J_ASOC},
  author       = {Lei Wang and Hai Wang},
  doi          = {10.1016/j.asoc.2022.108435},
  journal      = {Applied Soft Computing},
  pages        = {108435},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An integrated qualitative group decision-making method for assessing health-care waste treatment technologies based on linguistic terms with weakened hedges},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An evolutionary algorithm for solving capacitated vehicle
routing problems by using local information. <em>ASOC</em>,
<em>117</em>, 108431. (<a
href="https://doi.org/10.1016/j.asoc.2022.108431">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Capacitated Vehicle Routing Problem (CVRP) is a widely investigated NP-hard problem, which aims to determine the routes for a fleet of vehicles to serve a group of customers with minimum travel cost. In this paper, a fast evolutionary algorithm is proposed to solve CVRPs. To this end, a relevance matrix storing the probability that two customers are served successively by the same vehicle is calculated according to the local information of customer location and elite individuals in population. Based on the relevance matrix, an evolutionary algorithm called RMEA is proposed, where the relevance matrix is used to guide the crossover operation and accelerate the convergence of algorithm. Moreover, a relevance matrix based diversity preservation strategy is designed to increase the population diversity and solution quality. In the experiments, the proposed RMEA is compared to eight state-of-the-art heuristic methods tailored for CVRPs. Experimental results on three CVRP benchmarks demonstrate that the proposed RMEA is superior over eight compared algorithms and shows fast convergence speed.},
  archive      = {J_ASOC},
  author       = {Hao Jiang and Mengxin Lu and Ye Tian and Jianfeng Qiu and Xingyi Zhang},
  doi          = {10.1016/j.asoc.2022.108431},
  journal      = {Applied Soft Computing},
  pages        = {108431},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An evolutionary algorithm for solving capacitated vehicle routing problems by using local information},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Randomized balanced grey wolf optimizer (RBGWO) for solving
real life optimization problems. <em>ASOC</em>, <em>117</em>, 108429.
(<a href="https://doi.org/10.1016/j.asoc.2022.108429">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grey Wolf Optimizer (GWO) is one of the most important Swarm Intelligence based meta-heuristic algorithm which follows leadership mechanism and well planned hunting strategies among wolves’ hierarchy. This paper has introduced a new variant of GWO termed as Randomized Balanced Grey Wolf Optimizer (RBGWO), which assists wolves to explore the search space in an efficient manner. The proposed algorithm improves the overall efficiency of the search process by establishing a balance between its exploitation and exploration capability incorporating three successive enhancement strategies equipped with social hierarchy mechanism and random walk with student’s t-distributed random numbers. This newly proposed variant RBGWO has outperformed GWO and its other variants (RW-GWO, EGWO + EGWO+ and EGWO ∗ EGWO∗ ) in most of the cases on CEC 2014 benchmark functions with different scales. Results of the proposed variant have also been verified with the other meta-heuristic algorithms like GSA , CS , TPHS , CL-PSO, LX-BBO, B-BBO, SOS, DERand1Bin, Firefly, GWO, RW-GWO, EGWO + EGWO+ and EGWO ∗ EGWO∗ on CEC 2014 benchmark functions . The statistical analysis of the results presents the efficiency of RBGWO (the proposed version) in overall performance. The state-of-the-art methods and the proposed algorithm have also been applied together to constrained and unconstrained real life problems. The results produced by the proposed variant are of better quality compared to that of others in these real-life problems also.},
  archive      = {J_ASOC},
  author       = {Joy Adhikary and Sriyankar Acharyya},
  doi          = {10.1016/j.asoc.2022.108429},
  journal      = {Applied Soft Computing},
  pages        = {108429},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Randomized balanced grey wolf optimizer (RBGWO) for solving real life optimization problems},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). EmcFIS: Evolutionary multi-criteria fuzzy inference system
for virtual network function placement and routing. <em>ASOC</em>,
<em>117</em>, 108427. (<a
href="https://doi.org/10.1016/j.asoc.2022.108427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing demands for low-delay network services , mobile edge computing (MEC) has emerged as an appealing solution to provide computing resources in close to the end users. Network function virtualization (NFV) is a new network architecture which replaces dedicated hardware middleboxes with software instances to run network functions via software virtualization on general-purpose servers deployed at edge clouds. Because of the resource limitation at network edges, efficient placement and routing for online virtual network function requests (VNF-PRO) is a challenging task. The VNF-PRO has proven to be NP-hard, and thus, metaheuristic algorithms are the best choice in term of the solution quality. However, metaheuristics suffer from high computational complexity , and cannot be performed for online requests in the VNF-PRO. In this paper, a combined model based on fuzzy logic and genetic algorithm is proposed to achieve proper solution quality-speed trade-off in the VNF-PRO. In this method, a multi-criteria fuzzy inference system (named mcFIS) is used for the online VNF placement and routing. To achieve the best performance, a multi-objective evolutionary algorithm based on genetic algorithm (GA) is utilized in an offline procedure for automatic rule tuning of the mcFIS, once before applying it for online applications. Simulation results on two NFV benchmark instances demonstrate the efficiency of the proposed model against the existing techniques.},
  archive      = {J_ASOC},
  author       = {Seyed Reza Zahedi and Shahram Jamali and Peyman Bayat},
  doi          = {10.1016/j.asoc.2022.108427},
  journal      = {Applied Soft Computing},
  pages        = {108427},
  shortjournal = {Appl. Soft. Comput.},
  title        = {EmcFIS: Evolutionary multi-criteria fuzzy inference system for virtual network function placement and routing},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Transcendental equation solver: A novel neural network for
solving transcendental equation. <em>ASOC</em>, <em>117</em>, 108425.
(<a href="https://doi.org/10.1016/j.asoc.2022.108425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel method called transcendental equation solver (TES) for solving transcendental equations. The TES comprises a generator defined by a neural network and a discriminator defined by the mathematical expression of the transcendental equation. First, a large amount of random noise is input into the TES generator to generate the solutions of the equation; subsequently, the solution is input into the discriminator and the discriminator calculates the error between the discriminator output and the true value. Moreover, this error can update the parameters in the generator with the backpropagation algorithm . The experimental results proved that the TES exhibits an improvement in accuracy, convergence speed, and stability compared to the other methods for solving transcendental equations.},
  archive      = {J_ASOC},
  author       = {Jingyi Liu and Guojun Wang and Weijun Li and Linjun Sun and Liping Zhang and Lina Yu},
  doi          = {10.1016/j.asoc.2022.108425},
  journal      = {Applied Soft Computing},
  pages        = {108425},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Transcendental equation solver: A novel neural network for solving transcendental equation},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A medical big data access control model based on fuzzy trust
prediction and regression analysis. <em>ASOC</em>, <em>117</em>, 108423.
(<a href="https://doi.org/10.1016/j.asoc.2022.108423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the important issues facing HIS (Hospital Information System) in the context of big data is how to ensure that massive data and resources are protected from internal attacks and reduce the abuse of medical information. However, the existing single-value quantitative access control model based on trust or risk may not well reflect the true trust or risk situation because it cannot describe the timeliness and trend of the quantitative value. In response to this problem, we propose an access control model based on the credibility of the requesting user. Quantify the trust based on the user’s historical visit records on the HIS, and introduce the user’s historical behavior trend into the trust evaluation model through the corresponding regression analysis model. Comparative experiments show that in predicting linear, geometric, exponential, and mixed trends, the regression model in this paper is better than existing methods in predicting trust accuracy and predicting trust trends. Different from the working system of trusted access control model proposed in the existing literature, the model in this paper adds “Behavior warning module (BWM)”. The working mode that “User-visit, Early-warning, Trust-evaluation, Access-control” is very effective in reducing information leakage caused by visitors with non-profit purposes (such as curiosity) and purposeless (such as habitual browsing). And this also has a positive effect on improving the overall behavior level of users in the system.},
  archive      = {J_ASOC},
  author       = {Rong Jiang and Yang Xin and Zhenxing Chen and Ying Zhang},
  doi          = {10.1016/j.asoc.2022.108423},
  journal      = {Applied Soft Computing},
  pages        = {108423},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A medical big data access control model based on fuzzy trust prediction and regression analysis},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning vector quantization based predictor model selection
for hourly load demand forecasting. <em>ASOC</em>, <em>117</em>, 108421.
(<a href="https://doi.org/10.1016/j.asoc.2022.108421">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of smart grids has enabled a wide variety of generation units to be included in the grid, which has made it necessary to predict the load demand to manage the grid accurately. In this study, a novel hybridization approach is proposed based on selecting the most appropriate method to be used in each prediction step. In this scope, Learning Vector Quantization (LVQ) is employed as a classifier while Elman Neural Networks (ENN), and Ridge Regression are selected as predictors. In the first stage, a forecasting model is built and trained with ENN and Ridge Regression models on training data using 1-h before, 2-h before, and the first-order derivative of electricity consumption data. In the second stage, the method by which the most successful results are obtained for each forecast is determined and labeled. Then the LVQ model is built and trained to determine the most accurate forecast by using the same input employed in modeling. Finally, forecasts are performed by deciding which model to be used with LVQ. Experimental results show that more accurate forecasting performance is obtained with the proposed approach than the other two individual models. The different combinations of conventional models are used to illustrate the effectiveness of the proposed selection strategy, and experimental results show that better forecasting performance is obtained with the proposed approach than the individual ones at each combination.},
  archive      = {J_ASOC},
  author       = {Emre Akarslan},
  doi          = {10.1016/j.asoc.2022.108421},
  journal      = {Applied Soft Computing},
  pages        = {108421},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Learning vector quantization based predictor model selection for hourly load demand forecasting},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-scale sparse network with cross-attention mechanism
for image-based butterflies fine-grained classification. <em>ASOC</em>,
<em>117</em>, 108419. (<a
href="https://doi.org/10.1016/j.asoc.2022.108419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Butterfly protection is critical for environmental protection, and butterfly classification study is an essential tool for doing so. We proposed a new fine-grained butterfly classification architecture to address the issues of duplicate information in some butterfly images and trouble identifying them due to their tiny inter-class variance. To begin, a Non-Local Mean Filtering and Multi-Scale Retinex-based method (NL-MSR) is employed to enhance the butterfly images in order to efficiently retain more detail information. Then, to accomplish fine-grained categorization of butterfly images, a Multi-scale Sparse Network with Cross-Attention Mechanism (CA-MSNet) is designed. In CA-MSNet, a Cross-Attention Mechanism module (CAM) that offers distinct weights in the horizontal and vertical directions based on two strategies is devised to successfully identify the spatial distribution of butterfly stripes and spots and suppress incorrect information. Then, to overcome the recognition problem of butterfly spots with small inter-class variance, a Multi-scale sparse module (MSS) with multi-scale receptive fields is constructed. Finally, a Depthwise Separable Convolution module is employed to mitigate the parameter rise induced by the MSS network. In order to validate the model’s feasibility and effectiveness in a complex environment, we compared it to existing methods, and our proposed method achieved an average recognition accuracy of 91.88\%, with an F1 value of 92.15\%, indicating that it has a good effect on the fine-grained classification of butterflies and can be applied to their recognition to realize their protection.},
  archive      = {J_ASOC},
  author       = {Maopeng Li and Guoxiong Zhou and Weiwei Cai and Jiayong Li and Mingxuan Li and Mingfang He and Yahui Hu and Liujun Li},
  doi          = {10.1016/j.asoc.2022.108419},
  journal      = {Applied Soft Computing},
  pages        = {108419},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-scale sparse network with cross-attention mechanism for image-based butterflies fine-grained classification},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parallel “same” and “valid” convolutional block and
input-collaboration strategy for histopathological image classification.
<em>ASOC</em>, <em>117</em>, 108417. (<a
href="https://doi.org/10.1016/j.asoc.2022.108417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Histopathological image classification is of great importance in pathological diagnosis, such as tumor grading and cancer type identification. However, the traditional pathological examination is time-consuming and requires the subjective judgments and rich experience of pathologists. In order to alleviate these problems and provide quantitative analysis results, this paper proposes a parallel ‘same’ and ‘valid’ convolutional block (PSV-CB) and an input-collaboration strategy for performing histopathological image classification. The core of PSV-CB is to employ different convolutional operations for learning hidden representations of each input respectively and then correspondingly integrate them together to highlight interesting contents, where an operational flow is constructed via multiple ‘same’ convolutions and followed by a max-pooling, which can be considered as a ‘hard’ feature coding. Another one is established using step-by-step ‘valid’ convolutions that consider feature extraction and down-sampling simultaneously, which can be regarded as a ‘soft’ feature coding. Therefore, the parallel ‘same’ and ‘valid’ convolutional neural network (PSV-ConvNet) is constructed using stacked PSV-CB according to the specific task. To compensate the loss of spatial information, we introduce an input-collaborative PSV-ConvNet (IC-PSV-ConvNet) that adds grayscale version of original inputs into the outputs of each PSV-CB for better fusing global information and learned features. The proposed IC-PSV-ConvNet is evaluated on three histopathological image datasets (lymphoma, breast cancer, and liver cancer) with satisfactory results. Our comparative experiments demonstrate that the proposed IC-PSV-ConvNet can achieve more accurate classification results compared to other existing ConvNets.},
  archive      = {J_ASOC},
  author       = {Huiyan Jiang and Siqi Li and Haoming Li},
  doi          = {10.1016/j.asoc.2022.108417},
  journal      = {Applied Soft Computing},
  pages        = {108417},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Parallel ‘same’ and ‘valid’ convolutional block and input-collaboration strategy for histopathological image classification},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ENIC: Ensemble and nature inclined classification with
sparse depiction based deep and transfer learning for biosignal
classification. <em>ASOC</em>, <em>117</em>, 108416. (<a
href="https://doi.org/10.1016/j.asoc.2022.108416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The electrical activities of the brain are recorded and measured with Electroencephalography (EEG) by means of placing the electrodes on the scalp of the brain. It is quite a famous and versatile methodology utilized in both clinical and academic research activities. In this work, sparse depiction is initially incorporated to the EEG signals by means of using K-Singular Value Decomposition (K-SVD) algorithm and the features are extracted by means of using Self-Organizing Map (SOM) technique. The extracted features are initially classified with Extreme Learning Machine (ELM) and the proposed classification versions of ELM such as Ensemble ELM model and Nature Inclined ELM Model. The proposed ensemble ELM model makes use of the combination of Modified Adaboost . RT based on wavelet thresholding with ELM. The proposed Nature Inclined ELM makes use of the combination of some famous swarm intelligence algorithms such as Genetic Algorithm based ELM (GA-ELM), Particle Swarm Optimization based ELM (PSO-ELM), Ant Colony Optimization based ELM (ACO-ELM), Artificial Bee Colony based ELM (ABC-ELM) and Glowworm Swarm Optimization based ELM (GSO-ELM). The​ extracted features are also classified with deep learning methodology by means of utilizing an incidental Long Short-Term Memory (LSTM) Recurrent Neural Network (RNN). Another famous methodology using Non-negative Matrix Factorization (NMF) and Affinity Propagation Congregation based Mutual Information (APCMI) with transfer learning techniques is also proposed and implemented once the sparse modelling is done and the results are analysed. The proposed methodology is implemented for two EEG datasets such as epilepsy dataset and schizophrenia dataset and a comprehensive analysis is done with very promising results.},
  archive      = {J_ASOC},
  author       = {Sunil Kumar Prabhakar and Seong-Whan Lee},
  doi          = {10.1016/j.asoc.2022.108416},
  journal      = {Applied Soft Computing},
  pages        = {108416},
  shortjournal = {Appl. Soft. Comput.},
  title        = {ENIC: Ensemble and nature inclined classification with sparse depiction based deep and transfer learning for biosignal classification},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ada: Adversarial learning based data augmentation for
malicious users detection. <em>ASOC</em>, <em>117</em>, 108414. (<a
href="https://doi.org/10.1016/j.asoc.2022.108414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malicious user detection in the recommender systems has attracted much attention in the last two decades because malicious users can seriously affect the recommendation results and user experience . The up-to-date detection models usually concentrate on distinguishing users according to their latent features represented in user embeddings. These models can improve detection performance; however, they are usually not fully up to expectations, especially in the scenarios with unbalanced use samples. From these models that concentrate on user embedding representations, we can summarize the following difficulties: (1) the cost of manual labeling malicious causes the lack of labeled malicious users in training data, which leads to imprecise representations of users; (2) current augmentation methods that aim at mitigating the lack of labeled malicious users are hard to simulate the distribution of malicious users. In this paper, we propose a detection model, using adversarial learning based data augmentation (a.k.a. Ada) to alleviate these problems. Concretely, to get precise representations of users, the model integrates potential user relations and structural similarities into user embeddings. After obtaining precise user representation, it presents a novel data augmentation based on the deep convolutional generative adversarial networks (DCGAN) to simulate the distribution of malicious user embeddings and generate additional fake user embeddings. Experiments on public datasets show our model outperforms state-of-the-art detection models with sparse labeled malicious users, and the ablation study confirms the importance and effectiveness of each component of the model.},
  archive      = {J_ASOC},
  author       = {Jia Wang and Min Gao and Zongwei Wang and Chenghua Lin and Wei Zhou and Junhao Wen},
  doi          = {10.1016/j.asoc.2022.108414},
  journal      = {Applied Soft Computing},
  pages        = {108414},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Ada: Adversarial learning based data augmentation for malicious users detection},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A judgment-based model for usability evaluating of
interactive systems using fuzzy multi factors evaluation (MFE).
<em>ASOC</em>, <em>117</em>, 108411. (<a
href="https://doi.org/10.1016/j.asoc.2022.108411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study aimed to propose a judgment-based evaluation model for usability evaluating of interactive systems. Human judgment is associated with uncertainty and gray information. We used the fuzzy technique for integration, summarization, and distance calculation of quality value judgment. The proposed model is an integrated fuzzy Multi Factors Evaluation (MFE) model based on experts’ judgments in HCI , ISPD, and AMLMs . We provided a Fuzzy Inference System (FIS) for scoring usability evaluation metrics in different interactive systems. A multi-model interactive system is implemented for experimental testing of the model. The achieved results from the proposed model and experimental tests are compared using statistical correlation tests. The results show the ability of the proposed model for usability evaluation of interactive systems without the need for conducting empirical tests. It is concluded that applying a dataset in a neuro-FIS and training system cause to produce more than a hundred effective rules. The findings indicate that the proposed model can be applied for interactive system evaluation, informative evaluation, and complex empirical tests. Future studies may improve the FIS with the integration of artificial neural networks .},
  archive      = {J_ASOC},
  author       = {Adeleh Asemi and Asefeh Asemi},
  doi          = {10.1016/j.asoc.2022.108411},
  journal      = {Applied Soft Computing},
  pages        = {108411},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A judgment-based model for usability evaluating of interactive systems using fuzzy multi factors evaluation (MFE)},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-objective optimization algorithm assisted by
metamodels with applications in aerodynamics problems. <em>ASOC</em>,
<em>117</em>, 108409. (<a
href="https://doi.org/10.1016/j.asoc.2022.108409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimization algorithms when used in real engineering problems involving high fidelity numeric simulations often require a large number of numerical assessments to achieve a good approximation of the optimal solution. The computational time needed to find this solution may be unfeasible in these problems. The metamodel assisted algorithms have been used to accelerate optimization problems using different strategies to find the optimum. For single objective problems, CORS (Constrained Optimization using Response Surfaces) was developed with basis on the iterative generation of distance constraints to explore and exploit the design space, such that convergence to a global optimum is mathematically guaranteed. In this paper, a multi-objective optimization strategy based on metamodel construction using radial basis functions , MO-CORS, is presented. It takes the advantage of the CORS strategy in multi-objective problems to perform the effective detection of the non-dominated set extreme points, for the subsequent filling of empty spaces between these extremes. Metamodels are used strategically in an iterative sampling process to guide the search for better solutions and to determine where in the domain the next objective function evaluations should be performed. The evaluations carried out on the expensive functions also allow improving metamodel construction in the promising regions at each iteration. Results obtained in test problems and in aerodynamic problems applications show that the developed algorithm is an effective tool to accelerate single and multi-objective optimization problems and that the use of the CORS strategy inside MO-CORS was relevant in helping it to attain solutions not found by other optimization algorithms.},
  archive      = {J_ASOC},
  author       = {Nelson José Díaz Gautier and Nelson Manzanares Filho and Edna Raimunda da Silva Ramirez},
  doi          = {10.1016/j.asoc.2022.108409},
  journal      = {Applied Soft Computing},
  pages        = {108409},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-objective optimization algorithm assisted by metamodels with applications in aerodynamics problems},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Reliability analysis and ABC based optimization for
CoMP-enabled systems over nakagami-m fading. <em>ASOC</em>,
<em>117</em>, 108399. (<a
href="https://doi.org/10.1016/j.asoc.2021.108399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Providing reliable communications has become one of the major goals for machine-type-oriented applications. In this article, reliable analysis and joint optimization over Nakagami- m m fading are investigated for coordinated multi-point (CoMP) assisted multi-cell systems. First, the reliability analysis model for user equipment (UE) served by multiple base stations (BSs) via CoMP technique over Nakagami- m m fading is presented. The exact closed-form expression for reliability estimation based on the received signal-to-interference-plus-noise ratio (SINR) value over Nakagami- m m fading is derived and verified. Then, the joint sub-carrier assignment and power allocation problem for reliability optimization is formulated. The formulated problem is proved to be NP-hard. Bio-inspired artificial bee colony algorithm (ABC) is thus invoked to tackle this problem, and three ABC based joint optimization frameworks, namely Two-Step ABC Optimization algorithm (TSABC), ABC Combinatorial Optimization algorithm (ABCCO), and Heuristic Two-Step Optimization algorithm (HTSO), are proposed. Simulation results show that the UE reliability can be significantly enhanced by these proposed frameworks. It is also showcased that the proposed ABCCO obtains optimized reliability of 16 nines within 700 generations for most scenarios, which outperforms TSABC, HTSO, and conventional genetic algorithm (GA).},
  archive      = {J_ASOC},
  author       = {Jian Chen and Tao Wang and Jie Jia and Liang Guo and Xingwei Wang},
  doi          = {10.1016/j.asoc.2021.108399},
  journal      = {Applied Soft Computing},
  pages        = {108399},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Reliability analysis and ABC based optimization for CoMP-enabled systems over nakagami-m fading},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Contrastive learning based self-supervised time-series
analysis. <em>ASOC</em>, <em>117</em>, 108397. (<a
href="https://doi.org/10.1016/j.asoc.2021.108397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning architectures usually require large scale labeled datasets for achieving good performance on general classification tasks including computer vision and natural language processing . Recent techniques of self-supervised learning have opened up new a research frontier where deep learning architectures can learn general features from unlabeled data . The task of self-supervised learning is usually accomplished with some sort of data augmentation through which the deep neural networks can extract relevant information. This paper presents a novel approach for self-supervised learning based time-series analysis based on the SimCLR contrastive learning . We present novel data augmentation techniques, focusing especially on time-series data, and study their effect on the prediction task. We provide comparison with several fault classification approaches on benchmark Tennessee Eastman dataset and report an improvement to 81.43\% in the final accuracy using our contrastive learning approach. Furthermore we report a new benchmark of 80.80\%, 81.05\% and 81.43\% for self-supervised training on Tennesee Eastman where a classifier is only trained with 5\%, 10\% or 50\% percent of the available training data. Hence, we can conclude that the contrastive approach is very successful in time-series problems also, and further suitable for usage with partially labeled time-series datasets.},
  archive      = {J_ASOC},
  author       = {Johannes Pöppelbaum and Gavneet Singh Chadha and Andreas Schwung},
  doi          = {10.1016/j.asoc.2021.108397},
  journal      = {Applied Soft Computing},
  pages        = {108397},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Contrastive learning based self-supervised time-series analysis},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Linear ordering problem based classifier chain using genetic
algorithm for multi-label classification. <em>ASOC</em>, <em>117</em>,
108395. (<a href="https://doi.org/10.1016/j.asoc.2021.108395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most challenging tasks in multi-label classification is to identify label interdependence. Classifier Chain is the most prevalent method that utilizes label interdependence for improving classification accuracy as it requires only the number of classifiers equal to the number of labels. It uses a random sequence of labels. However, the order of labels in these sequences affects the classification performance. Nevertheless, despite many proposals in the literature, deciding the order in which these classifiers provide optimum results is a challenge to date. This paper proposes two methods for the ordering problem of the Classifier chain. The first proposed method termed as Linear Ordering Problem based Classifier Chain (LOP-CC) finds the chain order by considering it as a Linear Ordering Problem (LOP). The LOP utilizes a matrix and finds the optimal permutation of rows and corresponding columns that maximizes the sum of all the elements in the upper triangular matrix . This paper utilizes pairwise conditional entropy for creating the matrix to be used with the LOP and solves it using the Genetic Algorithm . It also proposes an extension to LOP-CC method termed as Linear Ordering Problem based partial Classifier Chain (LOP-pCC). It uses the same order of labels as LOP-CC. However, as opposed to LOP-CC, it utilizes partial sequences in the classifier chain rather than a full sequence. Experimentation performed on ten benchmark datasets consisting of a varying number of labels using different performance metrics demonstrates the proposed methods’ effectiveness compared to the other state-of-the-art classifier chain models.},
  archive      = {J_ASOC},
  author       = {Nitin Kumar Mishra and Pramod Kumar Singh},
  doi          = {10.1016/j.asoc.2021.108395},
  journal      = {Applied Soft Computing},
  pages        = {108395},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Linear ordering problem based classifier chain using genetic algorithm for multi-label classification},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An electrocorticographic decoder for arm movement for
brain–machine interface using an echo state network and gaussian
readout. <em>ASOC</em>, <em>117</em>, 108393. (<a
href="https://doi.org/10.1016/j.asoc.2021.108393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain–machine interface (BMI) studies typically use an electrocorticogram (ECoG) to record neural signals from the surface of the cortex because of the high spatial and temporal resolution and high signal-to-noise levels of the data obtained. However, in certain medical conditions, it may not be possible to place the ECoG electrodes at the target brain regions for BMI. Consequently, developing an ECoG decoder with suitable feature extraction and selection processes is challenging. This study investigated the possibility of a novel ECoG decoder for arm movement BMI. The ECoG signals were recorded from four individuals with intractable epilepsy while imaging and performing a reach-and-grasp movement. We examined the performance of the ECoG decoder using an echo state network and 24 Gaussian readouts within the classification problem paradigm of the arm movement directions. A genetic algorithm was used to optimize the hyperparameters of the ECoG decoder. The ECoG decoder successfully classified 24 arm movement directions in the x–y, x–z , and y–z planes in execution and imagination tasks. The best hit rates were 90.9 ± 5.3\%, 92.6 ± 3.9, and 92.6 ± 4.2 for the x–y, x–z , and y–z planes, respectively. A robot arm control simulation indicated that a real-time movement BMI system could use the novel ECoG decoder. Thus, the echo state network with Gaussian readouts for classification can be a successful ECoG decoder model for motor BMIs.},
  archive      = {J_ASOC},
  author       = {Hoon-Hee Kim and Jaeseung Jeong},
  doi          = {10.1016/j.asoc.2021.108393},
  journal      = {Applied Soft Computing},
  pages        = {108393},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An electrocorticographic decoder for arm movement for brain–machine interface using an echo state network and gaussian readout},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interpretability in the medical field: A systematic mapping
and review study. <em>ASOC</em>, <em>117</em>, 108391. (<a
href="https://doi.org/10.1016/j.asoc.2021.108391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the machine learning (ML) field has been rapidly growing, mainly owing to the availability of historical datasets and advanced computational power. This growth is still facing a set of challenges, such as the interpretability of ML models. In particular, in the medical field, interpretability is a real bottleneck to the use of ML by physicians. Therefore, numerous interpretability techniques have been proposed and evaluated to help ML gain the trust of its users. This review was carried out according to the well-known systematic map and review process to analyze the literature on interpretability techniques when applied in the medical field with regard to different aspects: publication venues and publication year, contribution and empirical types, medical and ML disciplines and objectives, ML black-box techniques interpreted, interpretability techniques investigated, their performance and the best performing techniques, and lastly, the datasets used when evaluating interpretability techniques. A total of 179 articles (1994–2020) were selected from six digital libraries: ScienceDirect, IEEE Xplore, ACM Digital Library, SpringerLink, Wiley, and Google Scholar. The results showed that the number of studies dealing with interpretability increased over the years with a dominance of solution proposals and experiment-based empirical type. Diagnosis, oncology, and classification were the most frequent medical task, discipline, and ML objective studied, respectively. Artificial neural networks were the most widely used ML black-box techniques investigated for interpretability. Additionally, global interpretability techniques focusing on a specific black-box model, such as rules, were the dominant explanation types, and most of the metrics used to evaluate interpretability were accuracy, fidelity, and number of rules. Moreover, the variety of the techniques used by the selected papers did not allow categorization at the technique level , and the high number of the sum of evaluations (671) of the articles raised a suspicion of subjectivity. Datasets that contained numerical and categorical attributes were the most frequently used in the selected studies. Further effort is needed in disciplines other than diagnosis and classification. Global techniques such as rules are the most used because of their comprehensibility to doctors, but new local techniques should be explored more in the medical field to gain more insights into the model’s behavior. More experiments and comparisons against existing techniques are encouraged to determine the best performing techniques. Lastly, quantitative evaluation of interpretability and physicians’ implications in interpretability techniques evaluation is highly recommended to evaluate how the techniques will perform in real-world scenarios. It can ensure the soundness of the techniques and help gain trust in black-box models in medical environments.},
  archive      = {J_ASOC},
  author       = {Hajar Hakkoum and Ibtissam Abnane and Ali Idri},
  doi          = {10.1016/j.asoc.2021.108391},
  journal      = {Applied Soft Computing},
  pages        = {108391},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Interpretability in the medical field: A systematic mapping and review study},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A full-featured cooperative coevolutionary memory-based
artificial immune system for dynamic optimization. <em>ASOC</em>,
<em>117</em>, 108389. (<a
href="https://doi.org/10.1016/j.asoc.2021.108389">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel cooperative coevolutionary memory-based artificial immune system enhanced by a new clonal selection algorithm is proposed for dynamic optimization problems . In the proposed algorithm, the whole n-dimensional population is decomposed into n one-dimensional subpopulations. Then, each subpopulation is evaluated separately using a set of context vectors called short-term memory. Also, inspired by the production of new cells in bone marrow, each subpopulation is divided into multiple regions to track and locate multiple optima cooperatively. This division helps the algorithm exploit search space effectively. Additionally, inspired by the immune memory concept, a memory-based approach called long-term memory is proposed to store and retrieve essential information when a fitness change occurs. Furthermore, a new clonal selection method, a combination of negative selection and clonal selection mechanisms, is proposed. This proposed algorithm is faster than the basic clonal selection algorithm. Finally, compared to other immune-based algorithms, which usually are implemented based on one or two qualities of the biologic immune system, the proposed approach exploit almost all immune qualities. Several experiments are conducted on different configurations of the moving peaks benchmark to examine the efficiency of the proposed method. The experimental results confirm that the proposed method is competitive with other state-of-the-art algorithms to optimize dynamic problems.},
  archive      = {J_ASOC},
  author       = {Bahareh Etaati and Zahra Ghorrati and Mohammad Mehdi Ebadzadeh},
  doi          = {10.1016/j.asoc.2021.108389},
  journal      = {Applied Soft Computing},
  pages        = {108389},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A full-featured cooperative coevolutionary memory-based artificial immune system for dynamic optimization},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-agent based sine–cosine algorithm for optimal
integration of DERs with consideration of existing OLTC in distribution
networks. <em>ASOC</em>, <em>117</em>, 108387. (<a
href="https://doi.org/10.1016/j.asoc.2021.108387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a modified version of the sine–cosine algorithm (SCA) has been developed to solve complex optimization problems . This proposed modified algorithm integrates the multi-agent system and sine–cosine algorithm and is termed as multi-agent sine–cosine algorithm (MA-SCA). This work also proposes a simplified strategy for the self-learning operator and modification in inversion operator. These proposed modifications have been validated by implementing the proposed MA-SCA algorithm on standard functions and comparing results with other reported optimization methods. Furthermore, in this work, MA-SCA algorithm has also been applied to optimally deploy the distributed energy resources (DERs) and shunt capacitors (SCs) in the distribution network with and without consideration of the existing on-load tap changing transformer (OLTC). The considered objectives in this optimization problem are reduction of cost of annual energy loss (CAEL) and minimization of voltage deviation under different loading conditions. To demonstrate the efficacy of the MA-SCA algorithm, it has been implemented on IEEE 33 bus radial distribution network (DN) and real-life Indian 108 bus radial DN. The comparison of obtained results with the results obtained by using other optimization methods has been carried out, and it indicates that MA-SCA algorithm provides the improved solution.},
  archive      = {J_ASOC},
  author       = {C.D. Patel and T.K. Tailor},
  doi          = {10.1016/j.asoc.2021.108387},
  journal      = {Applied Soft Computing},
  pages        = {108387},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-agent based sine–cosine algorithm for optimal integration of DERs with consideration of existing OLTC in distribution networks},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detecting adversarial examples by positive and negative
representations. <em>ASOC</em>, <em>117</em>, 108383. (<a
href="https://doi.org/10.1016/j.asoc.2021.108383">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have been successfully applied in various fields. However, it has been demonstrated that a well-designed and quasi-imperceptible perturbation can confuse the targeted DNNs classifier with high confidence and lead to misclassification . Examples with such perturbations are called adversarial examples , and it is a challenging task to detect them. In this paper, we propose a positive–negative detector (PNDetector) to detect adversarial examples. The PNDetector is based on a positive–negative classifier (PNClassifier), which is trained by both the original examples (called positive representations) and their negative representations with the same structural and semantic features . The principle of the PNDetector is that the feature space of the positive and negative representations of adversarial examples under the PNClassifier has a high probability of belonging to different categories, while its performance on clean examples is not reduced by adding negative example representations into the train set. We test the PNDetector with adversarial examples generated by eight typical attack methods on four typical datasets. The experimental results demonstrate that the proposed detector is efficient in all datasets and under all attack types. Furthermore, its detection performance is comparable to that of state-of-the-art methods.},
  archive      = {J_ASOC},
  author       = {Wenjian Luo and Chenwang Wu and Li Ni and Nan Zhou and Zhenya Zhang},
  doi          = {10.1016/j.asoc.2021.108383},
  journal      = {Applied Soft Computing},
  pages        = {108383},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Detecting adversarial examples by positive and negative representations},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A grid-guided particle swarm optimizer for multimodal
multi-objective problems. <em>ASOC</em>, <em>117</em>, 108381. (<a
href="https://doi.org/10.1016/j.asoc.2021.108381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a grid-guided particle swarm optimizer for solving multimodal multi-objective optimization problems that may have multiple disjoint Pareto sets corresponding to the same Pareto front . The concept of grid in the decision space is adopted to detect the special promising subregions , and accordingly to generate multiple subpopulations. The grid-guided technique can maintain the diversity of the population during the search process and improve the search efficiency. To obtain a well distributed Pareto optimal set , an external archive maintenance strategy is employed to select and store the solutions found in each generation. In addition, nine new multimodal multi-objective benchmark test functions are designed. The proposed algorithm is compared with ten state-of-the-art evolutionary algorithms on thirty-seven test functions. Moreover, the proposed algorithm is applied to solve a real-world problem. The experimental results demonstrate that the proposed algorithm is able to achieve superior performance compared with the alternative evolutionary methods considered.},
  archive      = {J_ASOC},
  author       = {Boyang Qu and Guosen Li and Li Yan and Jing Liang and Caitong Yue and Kunjie Yu and Oscar D. Crisalle},
  doi          = {10.1016/j.asoc.2021.108381},
  journal      = {Applied Soft Computing},
  pages        = {108381},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A grid-guided particle swarm optimizer for multimodal multi-objective problems},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Social network clustering and consensus-based distrust
behaviors management for large-scale group decision-making with
incomplete hesitant fuzzy preference relations. <em>ASOC</em>,
<em>117</em>, 108373. (<a
href="https://doi.org/10.1016/j.asoc.2021.108373">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of social network platforms, large-scale group decision-making in social network (LSGDM-SN) has been formed. As decision makers (DMs) come from different fields and have complex individual backgrounds, which leads to their distrust in the moderator. Moreover, in LSGDM-SN, since DMs can hardly grasp all the information about the decision problem, the hesitant fuzzy preference relations (HFPRs) they have expressed may be incomplete. However, in current LSGDM-SN issues, the distrust behaviors and incomplete HFPRs have never been discussed simultaneously. In this context, this paper aims to propose a method to estimate incomplete values in HFPRs, and develop a consensus management process which considers distrust behaviors. This paper focuses on LSGDM-SN on the basis of social network clustering and consensus-based distrust behaviors management with incomplete HFPRs. In this paper, a social network clustering method based on grey clustering algorithm is proposed to classify the DMs with similar social clustering degree into a subset. Afterwards, a method including two situations is developed to estimate incomplete values in HFPRs. Furthermore, an identification mechanism is presented to detect the DMs’ distrust behaviors, and three modification strategies are provided for managing different types of distrust behaviors. In addition, a case study is given to illustrate the feasibility of the proposed method. Finally, comparative analysis and discussion are explored to verify the advantages of the proposed LSGDM-SN with incomplete HFPRs.},
  archive      = {J_ASOC},
  author       = {Yanling Lu and Yejun Xu and Jing Huang and Ju Wei and Enrique Herrera-Viedma},
  doi          = {10.1016/j.asoc.2021.108373},
  journal      = {Applied Soft Computing},
  pages        = {108373},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Social network clustering and consensus-based distrust behaviors management for large-scale group decision-making with incomplete hesitant fuzzy preference relations},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An adaptive artificial bee colony with reinforcement
learning for distributed three-stage assembly scheduling with
maintenance. <em>ASOC</em>, <em>117</em>, 108371. (<a
href="https://doi.org/10.1016/j.asoc.2021.108371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed three-stage assembly scheduling problem extensively exists in the real-life assembly production process and is seldom considered. The integration of reinforcement learning with meta-heuristic can effectively improve the performance of meta-heuristic and effectively solve the problem; however, the integration is seldom used to cope with the problem. In this study, distributed three-stage assembly scheduling problem with D P m → 1 DPm→1 layout and maintenance at three stages is considered and a mathematical model is provided. A new artificial bee colony with Q-learning (QABC) is proposed to minimize maximum tardiness. An effective Q-learning algorithm is implemented to dynamically select search operator, which consists of 12 states based on population quality evaluation, 8 actions defined by global search and neighborhood search, a new reward and an effective action selection. Two employed bee swarms are formed, an adaptive communication and an adaptive competition process between them are adopted to intensify exploration ability and improve search efficiency. QABC and its four comparative algorithms are tested on 80 instances. The computational results demonstrate that the new strategies of QABC really improve its search performance and QABC is a competitive algorithm for the considered problem.},
  archive      = {J_ASOC},
  author       = {Jing Wang and Deming Lei and Jingcao Cai},
  doi          = {10.1016/j.asoc.2021.108371},
  journal      = {Applied Soft Computing},
  pages        = {108371},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An adaptive artificial bee colony with reinforcement learning for distributed three-stage assembly scheduling with maintenance},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). OPFaceNet: OPtimized face recognition network for noise and
occlusion affected face images using hyperparameters tuned convolutional
neural network. <em>ASOC</em>, <em>117</em>, 108365. (<a
href="https://doi.org/10.1016/j.asoc.2021.108365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face recognition is considered as important research in computer vision applications, and it is regarded as the basic biometric security system. Research related to face recognition has been done in the past several years. Still, many more challenges associated with this field need to be addressed. Some literary works have designed the face recognition model on the relatively controlled environments; yet, their performance in general settings has been substandard This paper develops an Optimal Face Recognition Network (OPFaceNet) to recognize the face images affected by high noise and occlusion. The feature patterns subjected to noise like LBP, FLBP, and NRLBP are extracted. The average of all three patterns is given to the proposed Convolutional Neural Network (CNN) classifier. As the main contribution, the CNN model is enhanced by optimizing the Fitness Sorted Rider Optimization Algorithm (FS-ROA). This algorithm optimizes the hyperparameters of CNN like Convolutional layer , Pooling Layer, Fully connected layer, number of Hidden layers, and Type of Pooling. Finally, the simulation results show that the system achieves a good recognition rate of 97.2\% and is robust against variations in terms of occlusion and noise when benchmarked over diverse datasets.},
  archive      = {J_ASOC},
  author       = {Gurukumar Lokku and G. Harinatha Reddy and M.N. Giri Prasad},
  doi          = {10.1016/j.asoc.2021.108365},
  journal      = {Applied Soft Computing},
  pages        = {108365},
  shortjournal = {Appl. Soft. Comput.},
  title        = {OPFaceNet: OPtimized face recognition network for noise and occlusion affected face images using hyperparameters tuned convolutional neural network},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fuzzy temporal convolutional neural networks in p300-based
brain–computer interface for smart home interaction. <em>ASOC</em>,
<em>117</em>, 108359. (<a
href="https://doi.org/10.1016/j.asoc.2021.108359">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The processing and classification of electroencephalographic signals (EEG) are increasingly performed using deep learning frameworks, such as convolutional neural networks (CNNs), to generate abstract features from brain data, automatically paving the way for remarkable classification prowess. However, EEG patterns exhibit high variability across time and uncertainty due to noise. It is a significant problem to be addressed in P300-based Brain Computer Interface (BCI) for smart home interaction. It operates in a non-optimal natural environment where added noise is often present. In this work, we propose a sequential unification of temporal convolutional networks (TCNs) modified to EEG signals, LSTM cells, with a fuzzy neural block (FNB), we called EEG-TCFNet. Fuzzy components may enable a higher tolerance to noisy conditions. We applied three different architectures comparing the effect of using block FNB to classify a P300 wave to build a BCI for smart home interaction with healthy and post-stroke individuals. Our results reported a maximum classification accuracy of 98.6\% and 74.3\% using the proposed method of EEG-TCFNet in subject-dependent strategy and subject-independent strategy, respectively. Overall, FNB usage in all three CNN topologies outperformed those without FNB. In addition, we compared the addition of FNB to other state-of-the-art methods and obtained higher classification accuracies on account of the integration with FNB. The remarkable performance of the proposed model, EEG-TCFNet, and the general integration of fuzzy units to other classifiers would pave the way for enhanced P300-based BCIs for smart home interaction within natural settings.},
  archive      = {J_ASOC},
  author       = {Christian Flores Vega and Jonathan Quevedo and Elmer Escandón and Mehrin Kiani and Weiping Ding and Javier Andreu-Perez},
  doi          = {10.1016/j.asoc.2021.108359},
  journal      = {Applied Soft Computing},
  pages        = {108359},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fuzzy temporal convolutional neural networks in p300-based brain–computer interface for smart home interaction},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). A least square support vector machine approach based on
bvRNA-GA for modeling photovoltaic systems. <em>ASOC</em>, <em>117</em>,
108357. (<a href="https://doi.org/10.1016/j.asoc.2021.108357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate model plays an important role in designing, assessing, and controlling photovoltaic (PV) systems. In this work, the least-squares support vector machine (LSSVM) is adopted to model the current–voltage (V–I) characteristic curves of different PV systems. A novel RNA genetic algorithm (bvRNA-GA) is proposed to determine the parameters of LSSVM. The bvRNA-GA is featured by designing the bulge loop crossover operator and the virus-induced mutation operator , they are employed to balance the exploration and exploitation capacities. Different experiments with 10 benchmark functions are conducted to show that the search efficiency of bvRNA-GA is better than the other four state-of-art algorithms. The outputs of bvRNA-GA optimized LSSVM models can better agree with the real outputs of different PV systems, the modeling results demonstrate the effectiveness of bvRNA-GA in solving real-world problems.},
  archive      = {J_ASOC},
  author       = {Xiu Liu and Ning Wang and Daniel Molina and Francisco Herrera},
  doi          = {10.1016/j.asoc.2021.108357},
  journal      = {Applied Soft Computing},
  pages        = {108357},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A least square support vector machine approach based on bvRNA-GA for modeling photovoltaic systems},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Society-based grey wolf optimizer for large scale combined
heat and power economic dispatch problem considering power losses.
<em>ASOC</em>, <em>117</em>, 108351. (<a
href="https://doi.org/10.1016/j.asoc.2021.108351">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combined Heat and Power Economic Dispatch (CHPED) reflects a momentous optimization and operation problem in the power systems for optimally allocating the produced heat and power to the committed Power-only (PO), Heat-only (HO), and CHP units. In this work, a new society-based optimization algorithm using social hierarchy of grey wolves, namely Society-based Grey Wolf Optimizer (SGWO) is proposed for the CHPED problem. This scheme divides the group of wolves to some societies so that each society has its own leader. These leaders follow the dominant wolf and also guide their societies in which the classification of wolves is based on the social hierarchy. Moreover a novel attacking and hunting the prey is suggested to change the effects of dominant, ordinate, and subordinate wolves in their new roles in societies. In order to verify the capabilities of the SGWO, simulations are conducted through two large-scale CHPED problems with the related challenges like Valve-Point Loading Effect (VPLE) and Prohibited Zones (PZ) of PO units, mutual dependency of produced heat and power of CHP units, and especially transmission power losses. Moreover, it is evaluated on twenty-three standard functions to verify its stability on different low- and high-dimensional functions. Comparisons based on the obtained solutions by different methods demonstrate the robustness and superior performance of the presented technique to fast provide better optimum point (more economical benefits) and solution quality meeting all equality and inequality constraints . In addition, the results of CHPED indicate that ≈ 0 . 5\% ≈0.5\% reduction in the production cost results in up to $ 2 . 6 − $ 34 × 1 0 6 $2.6−$34×106 increase in Annual Cost Saving (ACS). Also, the transmission losses and PZs of POs can increase the production cost by about 1.4\% which leads to over $ 1 . 3 × 1 0 7 $1.3×107 reduction in ACS in comparison with ignoring them. Moreover, this condition increases the computational time by about 35\% while the proposed method can still be up to 13 − 26 13−26 times faster than the other analysed algorithms.},
  archive      = {J_ASOC},
  author       = {Saman Hosseini-Hemati and Soheil Derafshi Beigvand and Hamdi Abdi and Abdollah Rastgou},
  doi          = {10.1016/j.asoc.2021.108351},
  journal      = {Applied Soft Computing},
  pages        = {108351},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Society-based grey wolf optimizer for large scale combined heat and power economic dispatch problem considering power losses},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distributed multi-objective grey wolf optimizer for
distributed multi-objective economic dispatch of multi-area
interconnected power systems. <em>ASOC</em>, <em>117</em>, 108345. (<a
href="https://doi.org/10.1016/j.asoc.2021.108345">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the gradual opening and rapid development of power markets, large-scale multi-area interconnected power systems (LMIPSs) have become an inevitable pattern. The traditional centralized economic dispatch optimization method has the disadvantages of slow calculation speed, easy exposure of private equipment information, and considers only one cost objective. This paper introduces the distributed concept into the multi-objective grey wolf optimizer (MOGWO) to mitigate these deficiencies; then proposes the distributed MOGWO (DMOGWO). When the DMOGWO solves the LMIPS problems, the sub-problems of each area are optimized independently, and the overall optimization can be realized by sharing only part of the boundary bus information between areas. Case studies are carried out in two cases of the Institute of Electrical and Electronics Engineers (IEEE) 39-bus and 118-bus systems. The results show that when solving the multi-objective economic dispatch in LMIPS, compared with centralized optimization, the proposed DMOGWO can effectively ensure the privacy of information, the obtained objective values are smaller, and the performance test is better.},
  archive      = {J_ASOC},
  author       = {Linfei Yin and Zhixiang Sun},
  doi          = {10.1016/j.asoc.2021.108345},
  journal      = {Applied Soft Computing},
  pages        = {108345},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Distributed multi-objective grey wolf optimizer for distributed multi-objective economic dispatch of multi-area interconnected power systems},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An attention based dual learning approach for video
captioning. <em>ASOC</em>, <em>117</em>, 108332. (<a
href="https://doi.org/10.1016/j.asoc.2021.108332">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video captioning aims to generate sentences/captions to describe video contents. It is one of the key tasks in the field of multimedia processing. However, most of the current video captioning approaches utilize only the visual information of a video to generate captions. Recently, a new encoder–decoder–reconstructorarchitecture was developed for video captioning, which can capture the information in both raw videos and the generated captions through dual learning. Based on this architecture, this paper proposes a novel attention based dual learning approach (ADL) for video captioning. Specifically, ADL is composed of a caption generation module and a video reconstruction module. The caption generation module builds a translatable mapping between raw video frames and the generated video captions, i.e., using the visual features extracted from videos by an Inception-V4 network to produce video captions. Then the video reconstruction module reproduces raw video frames using the generated video captions, i.e ., using the hidden states of the decoder in the caption generation module to reproduce/synthesize raw visual features. A multi-head attention mechanism is adopted to help the two modules focus on the most effective information in videos and captions, and a dual learning mechanism is adopted to fine-tune the performance of the two modules to generate final video captions. Therefore, ADL can minimize the semantic gap between raw videos and the generated captions by minimizing the differences between the reproduced and the raw videos, thereby improving the quality of the generated video captions. Experimental results demonstrate that ADL is superior to the state-of-the-art video captioning approaches on benchmark datasets.},
  archive      = {J_ASOC},
  author       = {Wanting Ji and Ruili Wang and Yan Tian and Xun Wang},
  doi          = {10.1016/j.asoc.2021.108332},
  journal      = {Applied Soft Computing},
  pages        = {108332},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An attention based dual learning approach for video captioning},
  volume       = {117},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust state-of-charge estimation of li-ion batteries based
on multichannel convolutional and bidirectional recurrent neural
networks. <em>ASOC</em>, <em>116</em>, 108401. (<a
href="https://doi.org/10.1016/j.asoc.2021.108401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the lack of multiscale feature extraction and bidirectional feature learning abilities, the existing deep state-of-charge (SOC) estimators are difficult to capture: (1) localized invariant characteristics hidden in battery measurement perturbations at multiple scales; and (2) intercorrelations among measurements in both time and reverse-time orders. If these situations are not considered, it will lead to large fluctuations in estimated SOC and accumulation of estimated errors at continuous time steps To solve these problems, an estimator combining multichannel convolutional and bidirectional recurrent neural networks (MCNN-BRNN) is proposed for SOC estimation. Specifically, MCNN can extract multiscale local robust features that are invariant to perturbations from measurements on different input paths reducing the estimation fluctuations and enhancing the robustness of the estimator. Moreover, a global convolutional layer is designed to learn the intercorrelations of multiscale features and preserve their temporal coherence. By this means, BRNN can capture the effective time-varying information of intercorrelated features in the forward and reverse directions to sequentially estimate SOC, thus alleviating the error accumulation and improving the overall estimation accuracy. Experiments results reveal that MCNN-BRNN outperforms the state-of-the-art estimators in terms of robustness and accuracy under the situations where multiscale perturbations and their comovements exist in measurements.},
  archive      = {J_ASOC},
  author       = {Chong Bian and Shunkun Yang and Jie Liu and Enrico Zio},
  doi          = {10.1016/j.asoc.2021.108401},
  journal      = {Applied Soft Computing},
  pages        = {108401},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Robust state-of-charge estimation of li-ion batteries based on multichannel convolutional and bidirectional recurrent neural networks},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Method to enhance deep learning fault diagnosis by
generating adversarial samples. <em>ASOC</em>, <em>116</em>, 108385. (<a
href="https://doi.org/10.1016/j.asoc.2021.108385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern industrial fields utilize complex mechanical equipment and machinery, which are closely linked, and equipment faults are difficult to express. Therefore, fault diagnosis is important to ensure the safety of complex mechanical equipment in modern industries. Deep learning has achieved excellent results with recent fault diagnosis methods . At present, three common deep learning models (MLP, CNN , and RNN models) can achieve diagnosis rates close to 100\% with original fault diagnosis data and a signal-to-noise ratio above 10 dB. However, we found that the diagnostic rate of these three models was completely incorrect when an adversarial sample with a signal-to-noise ratio noise greater than 10 dB was added to the original sample. We propose a GAN-based adversarial signal generative adversarial network (AdvSGAN) in this paper. We conduct experiments on the CWRU dataset and conclude that we can easily obtain adversarial noise and generate training samples through AdvSGAN. With the addition of adversarial data training, the diagnostic rate of the model on these adversarial samples increased from less than 5\% to 98.69\%, 97.38\% and 96.94\%. Hence, this method increases the reliability of our deep learning model.},
  archive      = {J_ASOC},
  author       = {Jie Cao and Jialin Ma and Dailin Huang and Ping Yu and Jinhua Wang and Kangjie Zheng},
  doi          = {10.1016/j.asoc.2021.108385},
  journal      = {Applied Soft Computing},
  pages        = {108385},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Method to enhance deep learning fault diagnosis by generating adversarial samples},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-granular linguistic distribution-based group
decision making method for renewable energy technology selection.
<em>ASOC</em>, <em>116</em>, 108379. (<a
href="https://doi.org/10.1016/j.asoc.2021.108379">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The scarcity of resources requires a decrease in nonrenewable energy consumption, which progressively promotes the development of renewable energy due to its immense potential and environmental friendliness. Hence, the use of renewable energy technology is critical for realizing the economic effect, the environment effect and the social benefit unified. Generally, renewable energy technology selection is treated as a multiple criteria group decision making problem. However, decision makers are not allowed to express multiple preferences via personalized linguistic distribution assessments deliberating on diverse criteria in the existing approaches. This work proposes a multi-granular linguistic distribution-based group decision-making method by linking multi-granular linguistic distribution assessments and LINMAP (Linear Programming Technique for Multidimensional Analysis of Preference) method with a mathematical model that can simultaneously yield the credible weights of the considered criteria and prioritize the sequence of optimal renewable energy technologies. To this end, the linguistic distribution-based Hellinger distance measure and linguistic hierarchy-based multi-granular linguistic distribution transformation method are proposed. The decision framework is applied to a case study of power generation-based technology selection, generating reliable criteria weights and yielding acceptable outcomes based on collected assessments. Eventually, the sensitivity analysis and comparative analysis are conducted to verify the feasibility and practicability of our proposal. This flexible decision support technique is geared towards managers and strives to provide reference and inspiration for renewable energy technology selection.},
  archive      = {J_ASOC},
  author       = {Yingying Liang and Yanbing Ju and Luis Martínez and Peiwu Dong and Aihua Wang},
  doi          = {10.1016/j.asoc.2021.108379},
  journal      = {Applied Soft Computing},
  pages        = {108379},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-granular linguistic distribution-based group decision making method for renewable energy technology selection},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploration of DevOps testing process capabilities: An ISM
and fuzzy TOPSIS analysis. <em>ASOC</em>, <em>116</em>, 108377. (<a
href="https://doi.org/10.1016/j.asoc.2021.108377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {DevOps is an emerging paradigm that refer to a collaborative culture of development and operation teams aiming to develop the high quality software product. Software organizations are adopting DevOps culture for software development and easy maintenance instead of using traditional SDLC mechanism. To enter the production stage, in DevOps process, the software product have to pass through quality gates were the software are tested during development phase to meet the established targeted criteria. This indicates that the mechanism of testing in DevOps process is not straightforward, and to establish strong DevOps testing platform there is a need to explore more automated testing practices. Thus, using multivocal literature review approach, we have selected 39 studies and identify the 20 testing capabilities. Finally, the interpretive structure modeling (ISM) and fuzzy technique for order preference by similarity to ideal solution (fuzzy TOPSIS) were applied. The results shows that (C2, CCi=0.808; C6, CCi=0.720; and C3, CCi=0.705) are top ranked testing capabilities. Using analysis results, we develop a holistic structure of testing capabilities to show their inter-relationship with each other and their priorities to select the best testing capabilities for DevOps process.},
  archive      = {J_ASOC},
  author       = {Saima Rafi and Muhammad Azeem Akbar and Wu Yu and Ahmed Alsanad and Abdu Gumaei and Muhammad Umer Sarwar},
  doi          = {10.1016/j.asoc.2021.108377},
  journal      = {Applied Soft Computing},
  pages        = {108377},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Exploration of DevOps testing process capabilities: An ISM and fuzzy TOPSIS analysis},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An automatic selection of optimal recurrent neural network
architecture for processes dynamics modelling purposes. <em>ASOC</em>,
<em>116</em>, 108375. (<a
href="https://doi.org/10.1016/j.asoc.2021.108375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A problem related to the development of algorithms designed to find the structure of artificial neural network used for behavioural (black-box) modelling of selected dynamic processes has been addressed in this paper. The research has included four original proposals of algorithms dedicated to neural network architecture search. Algorithms have been based on well-known optimisation techniques such as evolutionary algorithms and gradient descent methods . In the presented research an artificial neural network of recurrent type has been used, whose architecture has been selected in an optimised way based on the above-mentioned algorithms. The optimality has been understood as achieving a trade-off between the size of the neural network and its accuracy in capturing the response of the mathematical model under which it has been learnt. During the optimisation, original specialised evolutionary operators have been proposed. The research involved an extended validation study based on data generated from a mathematical model of the fast processes occurring in a pressurised water nuclear reactor .},
  archive      = {J_ASOC},
  author       = {Krzysztof Laddach and Rafał Łangowski and Tomasz A. Rutkowski and Bartosz Puchalski},
  doi          = {10.1016/j.asoc.2021.108375},
  journal      = {Applied Soft Computing},
  pages        = {108375},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An automatic selection of optimal recurrent neural network architecture for processes dynamics modelling purposes},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Aerodynamic data predictions based on multi-task learning.
<em>ASOC</em>, <em>116</em>, 108369. (<a
href="https://doi.org/10.1016/j.asoc.2021.108369">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quality of datasets is one of the key factors that affect the accuracy of aerodynamic data models. For example, in the uniformly sampled Burgers’ dataset, insufficient high-speed data is overwhelmed by massive low-speed data. Predicting high-speed data is more difficult than predicting low-speed data, owing to the fact that the number of high-speed data is limited, i.e. the quality of the Burgers’ dataset is not satisfactory. To improve quality of datasets, traditional methods usually employ data resampling technology to produce enough data for the insufficient parts in the original datasets before modeling, which increases computational costs. Motivated by the mixtures of experts in natural language processing , we propose a multi-task learning (MTL) scheme in the field of aerodynamic data predictions to eliminate the need for data resampling. Our MTL is a datasets quality-adaptive learning scheme, which combines task allocation and aerodynamic characteristic learning together to disperse the pressure of an entire learning task. The task allocation divides a whole learning task into several independent subtasks, while the aerodynamic characteristic learning learns these subtasks simultaneously to achieve better precisions. Two experiments with poor quality datasets are conducted to verify the data quality-adaptivity of the MTL to datasets. The results show that the MTL whose subtasks are divided by the K-means is more accurate than fully connected networks (FCNs), generative adversarial networks (GANs) and radical basis function neural networks (RBFNNs) in poor quality datasets.},
  archive      = {J_ASOC},
  author       = {Liwei Hu and Yu Xiang and Jun Zhang and Zifang Shi and Wenzheng Wang},
  doi          = {10.1016/j.asoc.2021.108369},
  journal      = {Applied Soft Computing},
  pages        = {108369},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Aerodynamic data predictions based on multi-task learning},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tabu search and variable neighborhood search algorithms for
solving interval bus terminal location problem. <em>ASOC</em>,
<em>116</em>, 108367. (<a
href="https://doi.org/10.1016/j.asoc.2021.108367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Ghanbari and Mahdavi-Amiri (2011) have proposed a model for the bus terminal location problem. Here, we want to improve Ghanbari and Mahdavi-Amiri’s model by defining three types of neighborhoods for each terminal. In our model, we consider a neighbor for each terminal, so the cost of service to stations in a neighborhood is individual. The proposed model is an NP-hard problem, so we suggest two algorithms based on the Tabu search and variable neighborhood search for solving it. Due to the Mann–Whitney and Dolan–Moré performance profiles, we use the recently proposed nonparametric statistical test to access the performance of numerical algorithms and demonstrate the efficiency of our proposed approach in comparison with other available methods.},
  archive      = {J_ASOC},
  author       = {Sahar Rahdar and Reza Ghanbari and Khatere Ghorbani-Moghadam},
  doi          = {10.1016/j.asoc.2021.108367},
  journal      = {Applied Soft Computing},
  pages        = {108367},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Tabu search and variable neighborhood search algorithms for solving interval bus terminal location problem},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multivariate intuitionistic fuzzy inference system for stock
market prediction: The cases of istanbul and taiwan. <em>ASOC</em>,
<em>116</em>, 108363. (<a
href="https://doi.org/10.1016/j.asoc.2021.108363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many of decision-making and policy planning processes involve a time-series prediction problem and so this area has extensive literature including a great variety of time-series prediction tools and inferences systems. An important part of these is based on fuzzy sets. However, it is known that fuzzy sets may fail to satisfy or characterize the uncertainty of the data in a comprehensive manner because they cannot depict the neutrality degree of time-series. Another important and decisive deficiency of current inference systems is to based on the univariate structure. However, the time series dealt with in a prediction problem generally interact with other time series. Considering these issues, creating an inference system based on intuitionistic fuzzy sets and multivariate relationships for a time series prediction problem is a requirement even an obligation. With these regards, this study presents a multivariate intuitionistic fuzzy time-series definition and its prediction models and introduces a multivariate intuitionistic fuzzy inference system (M-IFIS). The basic novelty of the article can be expressed as the definition of a multivariate intuitionistic fuzzy time series, as well as the creation of a relevant analysis mechanism, first-time in the literature. Sigma-pi neural network is used as an inference tool in M-IFIS and membership and non-membership values and lagged crisp observations of multivariable time-series are used as inputs of it. In order to reveal the performance of the proposed system, Istanbul Stock Exchange (IEX) and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX) are analysed and the results are evaluated as comprehensive and comparative. All findings reveal the superiority M-IFIS in predictive accuracy .},
  archive      = {J_ASOC},
  author       = {Ozge Cagcag Yolcu and Erol Egrioglu and Eren Bas and Ufuk Yolcu},
  doi          = {10.1016/j.asoc.2021.108363},
  journal      = {Applied Soft Computing},
  pages        = {108363},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multivariate intuitionistic fuzzy inference system for stock market prediction: The cases of istanbul and taiwan},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Inverse order based optimization method for task offloading
and resource allocation in mobile edge computing. <em>ASOC</em>,
<em>116</em>, 108361. (<a
href="https://doi.org/10.1016/j.asoc.2021.108361">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge computing , which provides lightweight cloud computing and storage capabilities at the edge of the network, has become a new computing paradigm . A key research challenge for edge computing is to design an efficient offloading strategy for offloading decision-making and resource allocation. Although many researches attempt to address this challenge, the traditional offloading strategies cannot adapt to complex environments, and the offloading strategies based on reinforcement learning require centralized control or the pursuit of the user’s best interests, which is impractical. Individual users should rationally pursue benefits in order to create a high-quality offloading environment to obtain long-term benefits. In this paper, we first separate the offloading process into a two-step offloading framework, and reverse the order of solving offloading decision and resource allocation problems to reduce the dimensionality of the action and state space. We formulate the resource allocation as a Markov Decision Process (MDP) and use the Deep Deterministic Policy Gradient Algorithm (DDPG) to adjust load balancing of the edge server and reduce the transmission energy and delay, and then use the genetic algorithm (GA) to search for decisions and use Fully-Connected Network (FCN) to fit the decision-making process, thereby avoiding excessive response time caused by iteration. Simulation results show that compared with baseline methods , the proposed algorithm is more stable, flexible, adaptable and suitable for practical applications.},
  archive      = {J_ASOC},
  author       = {Junyao Yang and Yan Wang and Zijian Li},
  doi          = {10.1016/j.asoc.2021.108361},
  journal      = {Applied Soft Computing},
  pages        = {108361},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Inverse order based optimization method for task offloading and resource allocation in mobile edge computing},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Virtual information core optimization for collaborative
filtering recommendation based on clustering and evolutionary
algorithms. <em>ASOC</em>, <em>116</em>, 108355. (<a
href="https://doi.org/10.1016/j.asoc.2021.108355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative filtering (CF), the most widely used recommendation algorithm , has to face the sparsity and scalability problem. Some researchers proposed to select a representative set of real users called information core (IC) from all the real users, which is used as the candidate neighbor set in the CF to alleviate the scalability problem. However, the rating vectors of these real users that compose IC are usually sparse, which will negatively affect the recommendation accuracy. In this paper, a virtual information core (VIC) optimization algorithm is proposed based on clustering and evolutionary algorithms for CF recommendation (VICO-CEA). The problem of searching for VIC is modeled as a combinatorial optimization problem , and is solved offline by the proposed evolutionary algorithm. The VIC is a set of virtual core users, each of which is constructed by averaging out multiple real users. These virtual core users in the VIC are no longer sparse and are found by the evolutionary optimization , which will improve the recommendation accuracy and reduce the online recommendation time as the VIC is used as the candidate neighbor set in the CF. Meanwhile, to make offline optimization more efficient, two strategies are proposed. One is to design a simple similarity measure based on dimensionality reduction and clustering to save time in calculating similarities by reducing the dimensionality of users’ rating vectors. The other is to use dimensionality reduction and clustering to construct a smaller training set and validation set by reducing the dimensionality of items’ rating vectors. The experimental results show that VICO-CEA can not only significantly reduce the online recommendation time further but also improve the recommendation accuracy greatly compared to traditional CF and other information-core-based methods.},
  archive      = {J_ASOC},
  author       = {Caihong Mu and Weizhu Chen and Yi Liu and Dongchang Lei and Ruochen Liu},
  doi          = {10.1016/j.asoc.2021.108355},
  journal      = {Applied Soft Computing},
  pages        = {108355},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Virtual information core optimization for collaborative filtering recommendation based on clustering and evolutionary algorithms},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A radial basis function surrogate model assisted
evolutionary algorithm for high-dimensional expensive optimization
problems. <em>ASOC</em>, <em>116</em>, 108353. (<a
href="https://doi.org/10.1016/j.asoc.2021.108353">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary algorithms require large number of function evaluations to locate the global optimum, making it computationally prohibitive on dealing with expensive problems. Surrogate-based optimization methods have shown promising ability on accelerating the convergence speed. However, it is still a challenging work for surrogate-assisted methods to deal with high-dimensional expensive problems because it is hard to approximate the objective function in high-dimensional space. In this paper, a novel radial basis function surrogate model assisted evolutionary algorithm for high-dimensional expensive optimization problems (RSAEH) is proposed. Specifically, the proposed algorithm consists of local search part and surrogate-guided prescreening part. In the local search part, the local surrogate is built by radial basis function with the most promising training sample points, and the optima (or near-optima) is located by optimizer to conduct exact function evaluation. In the surrogate-guided prescreening part, the current best sample point is refined by using sequential quadratic programming , thus guide the mutation direction by using differential evolution operator, and promising offspring prescreened by surrogate model are evaluated using exact function evaluation. To validate the effectiveness of the proposed algorithm, it is tested on benchmark problems with dimension ranging from 30 to 100, as well as a real-world oil reservoir production optimization problem. The proposed algorithm achieved best optimization results on 16 benchmark functions among 21 benchmark function sets in comparison with other algorithms. The performance of RSAEH is competitive especially on 100-D benchmark functions . In addition, RSAEH also showed promising performance on a real-world oil reservoir production optimization problem with 160 variables, in comparison with several state-of-the-art algorithms.},
  archive      = {J_ASOC},
  author       = {Guodong Chen and Kai Zhang and Xiaoming Xue and Liming Zhang and Chuanjin Yao and Jian Wang and Jun Yao},
  doi          = {10.1016/j.asoc.2021.108353},
  journal      = {Applied Soft Computing},
  pages        = {108353},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A radial basis function surrogate model assisted evolutionary algorithm for high-dimensional expensive optimization problems},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Prediction on blockchain virtual currency transaction under
long short-term memory model and deep belief network. <em>ASOC</em>,
<em>116</em>, 108349. (<a
href="https://doi.org/10.1016/j.asoc.2021.108349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advantages of blockchain virtual currency are convenient circulation, low transaction costs, and decentralized power. At present, more and more investors have focused their investment in the blockchain virtual currency. Transaction data of blockchain virtual currency belongs to the financial time series, which is noisy and random, bringing challenges to the prediction of transaction trends. The improved deep belief network (IDBN) model and Echo state network (ESN) are constructed based on deep belief network (DBN) model to explore the long short-term memory (LSTM) model and the transaction prediction of blockchain virtual currency under the DBN and to improve the transaction prediction accuracy of the blockchain virtual currency. In addition, the parameters of IDBN model were optimized using particle swarm optimization (PSO) algorithm, which are verified with the transaction data of stocks and blockchain virtual currencies (Bitcoin, Bitcoin Cash, and Ethereum), and compared with other cash algorithms for analysis. The results show that the PSO-IDBN-based time series prediction model proposed in this study can be applied to predicting the high-latitude and high-complexity data, showing superior performance compared to the traditional time series prediction and other deep learning prediction methods.},
  archive      = {J_ASOC},
  author       = {Xin Li and Qingquan Liu and Yingli Wu},
  doi          = {10.1016/j.asoc.2021.108349},
  journal      = {Applied Soft Computing},
  pages        = {108349},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Prediction on blockchain virtual currency transaction under long short-term memory model and deep belief network},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). End-to-end multi-task learning for simultaneous optic disc
and cup segmentation and glaucoma classification in eye fundus images.
<em>ASOC</em>, <em>116</em>, 108347. (<a
href="https://doi.org/10.1016/j.asoc.2021.108347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automated analysis of eye fundus images is crucial towards facilitating the screening and early diagnosis of glaucoma. Nowadays, there are two common alternatives for the diagnosis of this disease using deep neural networks . One is the segmentation of the optic disc and cup followed by the morphological analysis of these structures. The other is to directly address the diagnosis as an image classification task . The segmentation approach presents the advantage of using pixel-level labels with precise morphological information for training. However, while this detailed training feedback is not available for the classification approach , in this case the image-level labels may allow the discovery of additional non-morphological cues that are also relevant for the diagnosis. In this work, we propose a novel multi-task approach for the simultaneous classification of glaucoma and segmentation of the optic disc and cup. This approach can improve the overall performance by taking advantage of both pixel-level and image-level labels during the network training. Additionally, the segmentation maps that are predicted together with the diagnosis allow the extraction of relevant biomarkers such as the cup-to-disc ratio. The proposed methodology presents two relevant technical novelties. First, a network architecture for simultaneous segmentation and classification that increases the number of shared parameters between both tasks. Second, a multi-adaptive optimization strategy that ensures that both tasks contribute similarly to the parameter updates during training, avoiding the use of loss weighting hyperparameters. To validate our proposal, an exhaustive experimentation was performed on the public REFUGE and DRISHTI-GS datasets. The results show that our proposal outperforms comparable multi-task baselines and is highly competitive with existing state-of-the-art approaches. Additionally, the provided ablation study shows that both the network architecture and the optimization approach are independently advantageous for multi-task learning.},
  archive      = {J_ASOC},
  author       = {Álvaro S. Hervella and José Rouco and Jorge Novo and Marcos Ortega},
  doi          = {10.1016/j.asoc.2021.108347},
  journal      = {Applied Soft Computing},
  pages        = {108347},
  shortjournal = {Appl. Soft. Comput.},
  title        = {End-to-end multi-task learning for simultaneous optic disc and cup segmentation and glaucoma classification in eye fundus images},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial bee colony algorithm with distant savants for
constrained optimization. <em>ASOC</em>, <em>116</em>, 108343. (<a
href="https://doi.org/10.1016/j.asoc.2021.108343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the scientific and engineering problems are defined as constrained optimization functions. It can be very difficult due to their complex structures. Artificial Bee Colony Algorithm (ABC) is a remarkable metaheuristic developed for global optimization problems . However, due to the inadequacy of ABC’s search capability, it cannot handle constraint optimization problems very well. In this study, an ABC variant adapted for solving constrained optimization problems called Artificial Bee Colony Algorithm with Distant Savants (ABCDS) is proposed to overcome this deficiency. ABCDS is based on a new and adaptable search equation that enables learning with savants that are at a certain distance from each other. Also, the algorithm is hybridized with competitive local search mechanism. To test the performance of ABCDS, benchmark set for Constrained Real-Parameter Optimization defined in CEC 2017 conference (CEC2017COP) and some of the problems in the benchmark set on real-world problems defined in CEC 2020 conference (CEC2020) are used. The results obtained by the algorithm are compared with recent ABC algorithms and some state-of-the-art algorithms. According to the experimental results, ABCDS is better and competitive than the compared algorithms.},
  archive      = {J_ASOC},
  author       = {Gürcan Yavuz and Burhanettin Durmuş and Doğan Aydın},
  doi          = {10.1016/j.asoc.2021.108343},
  journal      = {Applied Soft Computing},
  pages        = {108343},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Artificial bee colony algorithm with distant savants for constrained optimization},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dual-stream spatio-temporal decoupling network for video
deblurring. <em>ASOC</em>, <em>116</em>, 108342. (<a
href="https://doi.org/10.1016/j.asoc.2021.108342">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is very important to obtain spatio-temporal information in video deblurring based on deep learning . The existing methods usually jointly learn the spatio-temporal information of blurred videos through single-stream networks, which inevitably limit spatio-temporal information learning and video deblurring performance of networks. Therefore, we propose a dual-stream spatio-temporal decoupling network (STDN), which can learn the spatio-temporal information of blurred videos more flexibly and efficiently with the decoupled temporal stream and spatial stream , for solving this problem. Firstly, in the temporal stream of STDN, we propose a video deblurring pipeline, that is motion compensation plus 3D CNNs, for solving the drawback of 3D CNNs that its receptive field cannot effectively cover the same but misplaced contents of different frames. Thus, the temporal stream can aggregate temporal information of frame sequences and handle inter-frame misalignments more effectively. Specifically, we design a novel deformable convolution compensation module (DCCM) to achieve motion compensation of this pipeline more accurately. Then, we develop a 3DConv module optimized by the designed temporal, spatial, and channel decoupling attention block, named the CTS, to achieve 3D CNNs of this pipeline. Secondly, we design a spatial stream in which two types of wide-activation residual modules are stacked, for learning more spatial features of the central frame to supplement the temporal stream. Finally, extensive experiments on the baseline datasets demonstrate that the proposed STDN has better performance than the latest methods. Remarkably, using the proposed temporal stream alone already can achieve competitive video deblurring performance than the existing methods.},
  archive      = {J_ASOC},
  author       = {Taigong Ning and Weihong Li and Zhenghao Li and Yanfang Zhang},
  doi          = {10.1016/j.asoc.2021.108342},
  journal      = {Applied Soft Computing},
  pages        = {108342},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dual-stream spatio-temporal decoupling network for video deblurring},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimization of optimal power flow problem using
multi-objective manta ray foraging optimizer. <em>ASOC</em>,
<em>116</em>, 108334. (<a
href="https://doi.org/10.1016/j.asoc.2021.108334">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding a feasible solution set for optimization problems in conflict with objective functions poses significant challenges. Moreover, in such problems, the level of complexity may increase depending on the geometry of the objective and decision spaces. The most effective methods in solving multi-objective problems having high levels of complexity are search algorithms using the Pareto-based archiving approach. Recently, the crowding distance approach has been used to improve the performance of the Pareto-based archiving method. This article presents research conducted on the development of a method that can find the optimum solution set for a multi-objective optimal power flow (MOOPF) problem whose objective functions are in conflict. For this purpose, a powerful and effective method was developed using the Pareto archiving approach based on crowding distance. The performance of the developed method was tested on twenty-four benchmark problems of different types and difficulty levels and compared with competing algorithms. The data obtained from the experimental trials and four different performance metrics were analyzed using statistical test methods. Analysis results showed that the proposed method yielded a competitive performance on different types of multi-objective optimization problems and was able to find the best solutions in the literature for the real-world MOOPF problem.},
  archive      = {J_ASOC},
  author       = {Hamdi Tolga Kahraman and Mustafa Akbel and Serhat Duman},
  doi          = {10.1016/j.asoc.2021.108334},
  journal      = {Applied Soft Computing},
  pages        = {108334},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Optimization of optimal power flow problem using multi-objective manta ray foraging optimizer},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Scrutinizing blockchain applicability in sustainable supply
chains through an integrated fuzzy multi-criteria decision making
framework. <em>ASOC</em>, <em>116</em>, 108331. (<a
href="https://doi.org/10.1016/j.asoc.2021.108331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sustainability has become increasingly important over the last three decades and has proven to be a key enabler for constructing resilient supply chains. Customers who want their products to be authenticated for sustainability put pressure on Original Equipment Manufacturers and suppliers to become more sustainable on a global scale. Moreover, social sustainability issues have become more challenging to address, and a growing number of stakeholders put emphasis on societal concerns . To this end, decision-makers are becoming increasingly interested in applying disruptive technologies to address societal, environmental, and economic concerns and accomplish sustainability goals. Researchers argue that disruptive technologies such as blockchain may be implemented to assist supply chains towards building sustainability. However, our literature analysis concluded that existing research has not quantitatively examined the critical functions of sustainable supply chain (SSC) for blockchain applicability using a decision framework. Therefore, this research, through Fuzzy SWARA-COPRAS-EDAS and COPELAND-based framework, is aimed at investigating the most feasible functions of a SSC for potential blockchain implementations. Using this framework, the critical functions of a SSC were ranked against the benefits of blockchain. The findings of this study implied that while sourcing, delivery, transformation and product recovery proved to be the most appropriate functions of SSCs for blockchain applications, customers and product use was the least feasible one. This study aids decision-makers in gaining a more thorough understanding of where in a SSC blockchain may create additional value.},
  archive      = {J_ASOC},
  author       = {Ismail Erol and Ilker Murat Ar and Iskender Peker},
  doi          = {10.1016/j.asoc.2021.108331},
  journal      = {Applied Soft Computing},
  pages        = {108331},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Scrutinizing blockchain applicability in sustainable supply chains through an integrated fuzzy multi-criteria decision making framework},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predicting the eddy current loss of a large nuclear power
turbo generator using a fuzzy c-means deep gaussian process regression
model. <em>ASOC</em>, <em>116</em>, 108328. (<a
href="https://doi.org/10.1016/j.asoc.2021.108328">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The distribution of the rotor slot wedge eddy current loss in large nuclear power turbo generators is complex and is influenced by many factors. Excessive eddy current loss leads to severe rotor heating, potentially leading to thermal accidents; therefore, the design precision of large generators must be improved. In this paper, a Fuzzy C-Means Deep Gaussian Process Regression (FCM-DGPR) method is proposed to predict the eddy current loss of a large generator in order to solve the problem of the insufficient accuracy of deep Gaussian process regression (DGPR) with increasing number of the data samples. First, the original dataset is obtained by the finite element method (FEM) and then normalized to construct the samples of the eddy current loss of a large nuclear power generator . Second, the training set is automatically clustered into different subsets by the fuzzy c-means algorithm, and each subset is used to train the DGPR model to obtain different sub models. The membership degree of each data point in the test set is calculated and used to evaluate the sub model of the data. Then, the sub model is used to predict the eddy current loss. Finally, the result is obtained by concatenating the results of each sub model. The results show that the goodness of fit ( R 2 R2 ) is 0.9809, the root mean square error (RMSE) is 0.0271, the prediction error is small, and the model exhibits good prediction performance. Further experimental results show that the FCM-DGPR method is superior to the existing DGPR models and other models and is more suitable for predicting the eddy current loss of large generators.},
  archive      = {J_ASOC},
  author       = {Hai Guo and Yifan Song and Likun Wang and Jingying Zhao and Fabrizio Marignetti},
  doi          = {10.1016/j.asoc.2021.108328},
  journal      = {Applied Soft Computing},
  pages        = {108328},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Predicting the eddy current loss of a large nuclear power turbo generator using a fuzzy c-means deep gaussian process regression model},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Multi-scale deep adversarial network for particle detection
in liquid crystal module. <em>ASOC</em>, <em>116</em>, 108326. (<a
href="https://doi.org/10.1016/j.asoc.2021.108326">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conductive particle inspection is the crucial procedure in the circuit detection process of liquid crystal modules since only validly deformed particles have conductive effects in the circuit. The main task of inspection is to accurately locate and count the validly deformed particles. However, due to various difficulties such as the variety of deformed particles, the aggregation between valid and invalid particles, the different sizes to overlap of deformed particles, and uneven illumination, etc., robust real-time detection of valid particles becomes a challenging problem. In this paper, a novel Multi-Scale Deep Adversarial Network (MSDA-Net) composed of Generator and Discriminator is proposed for detecting valid particles in a liquid crystal module. Firstly, a compact Multi-branch network is adopted as Generator for detecting valid particles, which achieves well detection accuracy with less time by utilizing the lightweight structure and the Coarse-to-Fine multi-scale feature extraction form. Secondly, the designed Logical Focusing Attention module (LFA) is applied in Generator to enhance the center location precision of valid particles. Furthermore, the Multi-branch based Deep Adversarial Strategy is proposed to distinguish deeply the similarity of visual characteristics between valid and invalid particles, which achieves higher detection accuracy with fewer fake particles. The experiments on the real datasets demonstrate the effectiveness of the proposed methods for the real-time detection of valid particles compared to the state-of-the-art methods.},
  archive      = {J_ASOC},
  author       = {Yuanyuan Wang and Ling Ma and Lihua Jian and Chengshuai Fan and Zhipeng Zhang and Huiqin Jiang},
  doi          = {10.1016/j.asoc.2021.108326},
  journal      = {Applied Soft Computing},
  pages        = {108326},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-scale deep adversarial network for particle detection in liquid crystal module},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). COVID-19 symptoms app analysis to foresee healthcare
impacts: Evidence from northern ireland. <em>ASOC</em>, <em>116</em>,
108324. (<a href="https://doi.org/10.1016/j.asoc.2021.108324">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile health (mHealth) technologies, such as symptom tracking apps, are crucial for coping with the global pandemic crisis by providing near real-time, in situ information for the medical and governmental response. However, in such a dynamic and diverse environment, methods are still needed to support public health decision-making. This paper uses the lens of strong structuration theory to investigate networks of COVID-19 symptoms in the Belfast metropolitan area. A self-supervised machine learning method measuring information entropy was applied to the Northern Ireland COVIDCare app. The findings reveal: (1) relevant stratifications of disease symptoms, (2) particularities in health-wealth networks, and (3) the predictive potential of artificial intelligence to extract entangled knowledge from data in COVID-related apps. The proposed method proved to be effective for near real-time in-situ analysis of COVID-19 progression and to focus and complement public health decisions. Our contribution is relevant to an understanding of SARS-COV-2 symptom entanglements in localised environments. It can assist decision-makers in designing both reactive and proactive health measures that should be personalised to the heterogeneous needs of different populations. Moreover, near real-time assessment of pandemic symptoms using digital technologies will be critical to create early warning systems of emerging SARS-CoV-2 strains and predict the need for healthcare resources.},
  archive      = {J_ASOC},
  author       = {José Sousa and João Barata and Hugo C van Woerden and Frank Kee},
  doi          = {10.1016/j.asoc.2021.108324},
  journal      = {Applied Soft Computing},
  pages        = {108324},
  shortjournal = {Appl. Soft. Comput.},
  title        = {COVID-19 symptoms app analysis to foresee healthcare impacts: Evidence from northern ireland},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sound classification using evolving ensemble models and
particle swarm optimization. <em>ASOC</em>, <em>116</em>, 108322. (<a
href="https://doi.org/10.1016/j.asoc.2021.108322">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic sound classification attracts increasing research attention owing to its vast applications, such as robot navigation , environmental sensing, musical instrument classification, medical diagnosis, and surveillance. In this research, we propose an ensemble convolutional bidirectional Long Short-Term Memory (CBiLSTM) network with optimal hyper-parameter selection for undertaking sound classification. We first transform each audio signal into a spectrogram representation using the Short-time Fourier transform (STFT). A Particle Swarm Optimization (PSO) variant is subsequently proposed to optimize the learning rate, weight decay, numbers of filters and hidden units in the convolutional and BiLSTM layers, respectively, in order to extract effective spatial–temporal characteristics from the spectrogram inputs. To tackle the issue of stagnation in optimization, the proposed algorithm incorporates local exploitation using secant and Newton–Raphson methods, promising leader generation using regular and irregular super-ellipse formulae, and three-dimensional spherical search coefficients. Moreover, it takes into account multiple fused elite signals in conjunction with numerical analysis based exploitation to balance between diversification and intensification. A variety of CBiLSTM networks with distinctive optimized settings are devised. An ensemble model is then constructed by incorporating a set of three yielded networks based on a majority voting scheme. Evaluated using several audio data sets, our ensemble CBiLSTM networks outperform those with default and optimal settings identified by other search methods, existing deep architectures and state-of-the-art related studies. In addition to sound classification tasks , the proposed PSO algorithm also outperforms a number of classical and advanced search methods for solving diverse unimodal and multimodal benchmark functions with statistical significance.},
  archive      = {J_ASOC},
  author       = {Li Zhang and Chee Peng Lim and Yonghong Yu and Ming Jiang},
  doi          = {10.1016/j.asoc.2021.108322},
  journal      = {Applied Soft Computing},
  pages        = {108322},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Sound classification using evolving ensemble models and particle swarm optimization},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid model of stacked autoencoder and modified particle
swarm optimization for multivariate chaotic time series forecasting.
<em>ASOC</em>, <em>116</em>, 108321. (<a
href="https://doi.org/10.1016/j.asoc.2021.108321">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Phase space reconstruction (PSR) is an effective method for chaotic system modeling, which can reveal the implicit evolution information in a complex system. However, the reconstructed time series tend to have a high dimension and contain some redundant information. It is difficult for a traditional simple model to directly forecast the reconstructed time series. In this paper, we propose a hybrid model of stacked autoencoder (SAE) and modified particle swarm optimization (MPSO) for multivariate chaotic time series forecasting. We utilize SAE to extract the reconstructed time series and adopt feedforward neural network (FNN) to forecast time series. In the proposed hybrid model, the SAE is followed by FNN, and we make the MPSO to train the output weights of the model, which is a large-scale optimization problem. To enhance the generalization ability and prevent over-fitting, we add a regularization item to the objective function when MPSO trains the weights of the model. Experimental results show that MPSO algorithm has advantages in the exploration and exploitation in large-scale optimization problems. Then, experiments on Lorenz time series and two real-world time series datasets verify the effectiveness of the hybrid model in multivariate chaotic time series forecasting.},
  archive      = {J_ASOC},
  author       = {Xinghan Xu and Weijie Ren},
  doi          = {10.1016/j.asoc.2021.108321},
  journal      = {Applied Soft Computing},
  pages        = {108321},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A hybrid model of stacked autoencoder and modified particle swarm optimization for multivariate chaotic time series forecasting},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A long short-term memory based quasi-virtual analyzer for
dynamic real-time soft sensing of a simulated moving bed unit.
<em>ASOC</em>, <em>116</em>, 108318. (<a
href="https://doi.org/10.1016/j.asoc.2021.108318">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evaluation of unmeasurable quantities is an issue faced in several fields. One example is in the production of pharmaceuticals, in which, typically, isomer properties related to different effects are found: one enantiomer may kill while the other may cure. Thus, strict quality control is necessary in this field, which requires accurate, reliable and frequent measurements of the system. However, the measurement of the main quality properties associated with the production of some pharmaceuticals has a low frequency. Consequently, in addition to safety-related issues, financial losses are also related to these low frequency of measurements, as the product can easily run towards an out of spec production. In this scenario, the present work proposes a novel Deep Artificial Intelligence structure, which has an intrinsic (Nonlinear Output Error) NOE structure, associated with a (Nonlinear AutoRegressive with Exogenous input) NARX predictor, to be used as an online soft sensor in order to provide information about the main properties of a Simulated Moving Bed chromatographic unit, commonly used in the production of pharmaceuticals, in order to mitigate the low frequency of measurement associated with this unit. The proposed structure is here called Improved Quasi-Virtual Analyzer. The model can adapt itself as the process evolves, having the possibility of online learning through measurements obtained in the laboratory periodically. The proposed structure was tested in a software-in-the-loop scenario and compared with a more traditional alternative. These tests showed a robust capacity of the Improved Quasi-Virtual Analyzer to provide reliable predictions in real-time, as well as to outperform the traditional artificial network structure.},
  archive      = {J_ASOC},
  author       = {Paulo H. Marrocos and Igor G.I. Iwakiri and Márcio A.F. Martins and Alírio E. Rodrigues and José M. Loureiro and Ana M. Ribeiro and Idelfonso B.R. Nogueira},
  doi          = {10.1016/j.asoc.2021.108318},
  journal      = {Applied Soft Computing},
  pages        = {108318},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A long short-term memory based quasi-virtual analyzer for dynamic real-time soft sensing of a simulated moving bed unit},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A pseudo-inverse decomposition-based self-organizing modular
echo state network for time series prediction. <em>ASOC</em>,
<em>116</em>, 108317. (<a
href="https://doi.org/10.1016/j.asoc.2021.108317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Echo state network (ESN) refers to a popular recurrent neural network with a largely and randomly generated reservoir for its rapid learning ability. However, it is difficult to design a reservoir that matches a specific task. To solve the structure design of the reservoir, a pseudo-inverse decomposition-based self-organizing modular echo state (PDSM-ESN) is proposed. PDSM-ESN is constructed by growing–pruning method, where the error and condition number are used, respectively. Since the self-organizing process may negatively affect the learning speed, the pseudo-inverse decomposition is adopted to improve learning speed, which means the output weights are learned by an iterative incremental method. Meanwhile, to solve the ill-posed problem, the modular sub-reservoirs corresponding to the high condition number are pruned. Simulation results indicate that PDSM-ESN has better prediction performance and run-time complexity compared with the traditional ESN models.},
  archive      = {J_ASOC},
  author       = {Lei Wang and Zhong Su and Junfei Qiao and Feng Deng},
  doi          = {10.1016/j.asoc.2021.108317},
  journal      = {Applied Soft Computing},
  pages        = {108317},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A pseudo-inverse decomposition-based self-organizing modular echo state network for time series prediction},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-component PSO algorithm with leader learning
mechanism for structural damage detection. <em>ASOC</em>, <em>116</em>,
108315. (<a href="https://doi.org/10.1016/j.asoc.2021.108315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The particle swarm optimization (PSO) algorithm has been widely used to solve optimization problems . One of its main drawbacks is a slow and sometimes premature convergence, which traps the swarm in a local minimum. Several PSO variants have been proposed to alleviate this phenomenon. Still, when dealing with structural damage detection (SDD), the performances of these algorithms are not homogeneous and highly depend on the number of defects and their severities, which even lead them to require assistance from other methods. This paper proposes a multi-component PSO with cooperative learning named MuC-PSO. Instead of resorting to other methods, a strategy pool is constructed in the proposed MuC-PSO by combining four PSO variants, which guarantees that the algorithm can execute multiple search strategies collaboratively. Moreover, a leader learning mechanism (LLM) is also implemented to ensure information exchange and lead the global convergence of the method. This strategy allows the PSO variants to benefit from each other and enables the MuC-PSO to solve complex SDD problems. The performances of the MuC-PSO are evaluated in nine damage scenarios of single and multiple damages with severity levels between [ 10\% , 50\% ] [10\%, 50\%] . Our algorithm is compared with different recent optimization algorithms , including the four PSO variants alone and some non-PSO algorithms. The simulation results on three types of damages clearly demonstrate the effectiveness and superiority of the MuC-PSO.},
  archive      = {J_ASOC},
  author       = {Xiao-Lin Li and Roger Serra and Julien Olivier},
  doi          = {10.1016/j.asoc.2021.108315},
  journal      = {Applied Soft Computing},
  pages        = {108315},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-component PSO algorithm with leader learning mechanism for structural damage detection},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning the parameters of an outranking-based sorting model
with characteristic class profiles from large sets of assignment
examples. <em>ASOC</em>, <em>116</em>, 108312. (<a
href="https://doi.org/10.1016/j.asoc.2021.108312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the problem of learning the parameters of the outranking-based multiple criteria sorting model from large sets of assignment examples. We focus on a recently devised method called Electre TRI-rC, incorporating a single characteristic profile to describe each decision class. We introduce four algorithms aimed at the problem. They use different optimization techniques, including an evolutionary algorithm , linear programming combined with a genetic approach, simulated annealing, and a dedicated heuristic. We present the results of the experiments carried out on both artificial and real-world data sets. They reveal an impact of the comparison and veto thresholds, various sorting rules, and ensembles on the classification accuracy of the proposed algorithms. From a broader perspective, we contribute to cross-fertilizing the fields of Multiple Criteria Decision Aiding and Machine Learning for supporting real-world decision-making.},
  archive      = {J_ASOC},
  author       = {Miłosz Kadziński and Adam Szczepański},
  doi          = {10.1016/j.asoc.2021.108312},
  journal      = {Applied Soft Computing},
  pages        = {108312},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Learning the parameters of an outranking-based sorting model with characteristic class profiles from large sets of assignment examples},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). An irrelevant attributes resistant approach to anomaly
detection in high-dimensional space using a deep hypersphere structure.
<em>ASOC</em>, <em>116</em>, 108301. (<a
href="https://doi.org/10.1016/j.asoc.2021.108301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is a grand challenge to detect anomalies existing in subspaces from a high-dimensional space. Most existing state-of-the-art methods implicitly or explicitly rely on distances. Since the contrast, e.g., distances, between data objects in a high-dimensional space becomes more and more similar. Moreover, high-dimensional spaces may include many irrelevant attributes masking anomalies (if the prior probability for a class remains unchanged regardless of the value observed for attribute att , att is said to be irrelevant to a class, i.e., att is an irrelevant attribute). Obviously, anomalies can exist in any of subspaces, so it is difficult to select subspaces that highlight the relevant attributes in an exponential searching space. To address this issue, we proposed a hybrid method consisting of a deep network and a hypersphere to detect anomalies . The deep network in the proposed method is used as a feature extractor to capture the low-dimensional features from the background space. Then, anomalies are separated by using the hypersphere in the feature space reconstructed by probability distribution. To prevent irrelevant attributes from being mistaken for anomalies during mining anomalies, the upper of the number of anomalies is estimated by the Chebyshev theorem . Finally, the proposed method was verified on synthetic datasets and real-world datasets. Experimental results show that the proposed method outperforms the existing state-of-the-art detection methods in regard to the accuracy of mining anomalies and the ability of noise resistance. We find that feature extractors can improve the ability of noise resistance for anomalous detection methods. In the feature space reconstructed by probability distribution, anomalous features are easily identified from irrelevant features and normal features. We also indicate that irrelevant attributes increase the complexity of the feature space, through calculating the probability distribution of data in the background space, the layered features can be extracted to distinguish anomaly classes, normal classes, and irrelevant attribute classes.},
  archive      = {J_ASOC},
  author       = {Jian Zheng and Hongchun Qu and Zhaoni Li and Lin Li and Xiaoming Tang},
  doi          = {10.1016/j.asoc.2021.108301},
  journal      = {Applied Soft Computing},
  pages        = {108301},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An irrelevant attributes resistant approach to anomaly detection in high-dimensional space using a deep hypersphere structure},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-discipline predictive intelligent control method for
maintaining the thermal comfort on indoor environment. <em>ASOC</em>,
<em>116</em>, 108299. (<a
href="https://doi.org/10.1016/j.asoc.2021.108299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence and application of soft computing have significantly changed the methods to solve engineering problems. For the indoor environmental control, various machine learning methods have been used, attempting to replace the traditional engineering methods. However, the recent single data-driven machine learning approach can hardly meet the requirement, since engineering problems still require prior knowledge to extract features and set up restrictions, while this knowledge should be obtained from engineering analysis. In this case, this paper has proposed an integrated multi-discipline method combining machine learning with engineering analysis, to implement predictive intelligent indoor environmental control in terms of thermal comfort and energy consumption. This method includes three parts, i.e., environmental modelling and simulation , producing an environmental prediction model, and creating an intelligent control agent and system. Firstly, a physical model is created to simulate the indoor environment and analysed through computational fluid dynamics , whose results can guide the setup of sensors in the indoor environment for collecting real-time data. Then, a machine learning method support vector regression is used to create an environmental prediction model for key parameters within the indoor environment, based on the collected data. Finally, a reinforcement learning method is used to train an intelligent agent for the intelligent control on the indoor environment, together with a system for implementation. Experiments and evaluations are carried out in a case study within an office, demonstrating the proposed method’s feasibility, which provides a more efficient and effective intelligently predictive control on the indoor environment considering the balance of thermal comfort and energy efficiency.},
  archive      = {J_ASOC},
  author       = {Hao Qin and Xiaoxu Wang},
  doi          = {10.1016/j.asoc.2021.108299},
  journal      = {Applied Soft Computing},
  pages        = {108299},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-discipline predictive intelligent control method for maintaining the thermal comfort on indoor environment},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hypervolume distribution entropy guided computation
resource allocation mechanism for the multiobjective evolutionary
algorithm based on decomposition. <em>ASOC</em>, <em>116</em>, 108297.
(<a href="https://doi.org/10.1016/j.asoc.2021.108297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The computation resource allocation is a key issue to the multiobjective evolutionary algorithms . Present studies still have some difficulties addressing this issue such as low accuracy, indispensable parameter for balancing the convergence and diversity, discontinuous improvement values of different domination relations and poor discernibility. To solve these problems, a hypervolume distribution model regarding two non-adjacent individuals of each subproblem is proposed in this paper. Based on the hypervolume distribution model, a comprehensive hypervolume distribution entropy (HDE) by integrating the entropy and the Kullback–Leibler divergence is proposed to measure the improvement of the subproblems. The proposed measurement is continuous over different domination relations, requires no parameters and has high precision and discernibility. Thereafter, a hypervolume distribution entropy guided multiobjective evolutionary based on decomposition (HDE-MOEA/D) is proposed. The proposed algorithm is more efficient on solving multiobjective optimization problems . The proposed algorithm is tested on some popular test suits against another five typical and popular algorithms. The proposed HDE-MOEA/D achieves the best generational distances and the inverse generational distances in 57.9\% ranking comparisons. The HDE-MOEA/D also outperforms another compared algorithm in 70.2\% one-to-one comparisons. The experiment results prove the superiority of the proposed algorithm and reveal some important discoveries.},
  archive      = {J_ASOC},
  author       = {Zhao Wang and Maoguo Gong and Peng Li and Jie Gu and Weidong Tian},
  doi          = {10.1016/j.asoc.2021.108297},
  journal      = {Applied Soft Computing},
  pages        = {108297},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A hypervolume distribution entropy guided computation resource allocation mechanism for the multiobjective evolutionary algorithm based on decomposition},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An intrusion detection approach using ensemble support
vector machine based chaos game optimization algorithm in big data
platform. <em>ASOC</em>, <em>116</em>, 108295. (<a
href="https://doi.org/10.1016/j.asoc.2021.108295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mainstream computing technology is not efficient in managing massive data and detecting network traffic intrusions, often including big data. The intrusions present in sustained network traffic and the massive host log event data cannot be effectively managed by conventional analytical tools, resulting in a huge number of false positives and a longer training time. This paper presents a novel technique to enhance the intrusion detection process by handling the fundamental big data complexities associated with different forms of heterogeneous security data. To achieve the earlier objective, the ensemble Support Vector Machine (SVM) is integrated with the Chaos Game Optimization (CGO) algorithm. The proposed methodology improves the intrusion classification accuracy and also identifies nine different types of attacks present in the UNSW-NB15 dataset. The efficiency of the proposed methodology is evaluated using statistical analysis and different performance metrics such as precision, recall, F1-score, accuracy, ROC curve, and confusion matrix by comparing it with different baseline models . The proposed methodology obtains an accuracy of 96.29\% when compared to the chi-SVM (89.12\%) and an improvement of 6.47\% is noted in the proposed methodology in terms of accuracy when compared with the chi-SVM. The higher classification accuracy shows that the proposed methodology exhibit a fewer number of false positives when handling the security events in big data platforms.},
  archive      = {J_ASOC},
  author       = {A. Ponmalar and V. Dhanakoti},
  doi          = {10.1016/j.asoc.2021.108295},
  journal      = {Applied Soft Computing},
  pages        = {108295},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An intrusion detection approach using ensemble support vector machine based chaos game optimization algorithm in big data platform},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fault diagnosis method of vehicle engine via HOSVD–HOALS
hybrid algorithm-based multi-dimensional feature extraction.
<em>ASOC</em>, <em>116</em>, 108293. (<a
href="https://doi.org/10.1016/j.asoc.2021.108293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Engine faults, which are difficult to be accurately diagnosed, seriously affect the normal running of vehicles. To solve this problem, a novel fault diagnosis method via HOSVD–HOALS​ hybrid algorithm-based multi-dimensional feature extraction was proposed for a vehicle engine. First, multiple source signals-based engine status samples with the form of third-order tensors were constructed to retain the correlation among sample data. Then, by analyzing the high-dimensional characteristics of the constructed tensor samples, the Tucker decomposition was employed to realize the dimension reduction of the samples. Simultaneously, combining the high order singular value decomposition (HOSVD) and high order alternation least square (HOALS), a hybrid algorithm was proposed to solve the optimal low-dimensional core tensors and features of the constructed tensor samples. Finally, based on the extracted features, the fault pattern of the vehicle engine was recognized by using the derived tensor-based K-nearest neighbor (K-NN) and fuzzy C-mean (FCM) algorithms, respectively. Research results show that the average accuracy of the fault diagnosis via HOSVD–HOALS hybrid algorithm-based multi-dimensional feature extraction can reach 96.25\% which is the highest compared with that via the principal component analysis (PCA), HOSVD , HOALS , and direct tensor sample method, respectively, and the computation time required for the fault diagnosis is greatly shortened, which can provide theoretical and technical support for the fault diagnosis of vehicle engines.},
  archive      = {J_ASOC},
  author       = {Wei Wang and Yan Li and Yuling Song},
  doi          = {10.1016/j.asoc.2021.108293},
  journal      = {Applied Soft Computing},
  pages        = {108293},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fault diagnosis method of vehicle engine via HOSVD–HOALS hybrid algorithm-based multi-dimensional feature extraction},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust weakly supervised learning for COVID-19 recognition
using multi-center CT images. <em>ASOC</em>, <em>116</em>, 108291. (<a
href="https://doi.org/10.1016/j.asoc.2021.108291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The world is currently experiencing an ongoing pandemic of an infectious disease named coronavirus disease 2019 (i.e., COVID-19), which is caused by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). Computed Tomography (CT) plays an important role in assessing the severity of the infection and can also be used to identify those symptomatic and asymptomatic COVID-19 carriers. With a surge of the cumulative number of COVID-19 patients, radiologists are increasingly stressed to examine the CT scans manually. Therefore, an automated 3D CT scan recognition tool is highly in demand since the manual analysis is time-consuming for radiologists and their fatigue can cause possible misjudgment. However, due to various technical specifications of CT scanners located in different hospitals, the appearance of CT images can be significantly different leading to the failure of many automated image recognition approaches. The multi-domain shift problem for the multi-center and multi-scanner studies is therefore nontrivial that is also crucial for a dependable recognition and critical for reproducible and objective diagnosis and prognosis. In this paper, we proposed a COVID-19 CT scan recognition model namely coronavirus information fusion and diagnosis network (CIFD-Net) that can efficiently handle the multi-domain shift problem via a new robust weakly supervised learning paradigm. Our model can resolve the problem of different appearance in CT scan images reliably and efficiently while attaining higher accuracy compared to other state-of-the-art methods.},
  archive      = {J_ASOC},
  author       = {Qinghao Ye and Yuan Gao and Weiping Ding and Zhangming Niu and Chengjia Wang and Yinghui Jiang and Minhao Wang and Evandro Fei Fang and Wade Menpes-Smith and Jun Xia and Guang Yang},
  doi          = {10.1016/j.asoc.2021.108291},
  journal      = {Applied Soft Computing},
  pages        = {108291},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Robust weakly supervised learning for COVID-19 recognition using multi-center CT images},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Regularization and concave loss functions for estimation of
chemical kinetic models. <em>ASOC</em>, <em>116</em>, 108286. (<a
href="https://doi.org/10.1016/j.asoc.2021.108286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-linear regression is the primary tool for estimating kinetic models of chemical reactions. The default approach of minimizing the sum of squared residuals tends to underperform in the presence of systematic errors , non-normal distribution of residuals or identifiability issues such as a high correlation between parameters. Therefore, we argue for a careful choice of the fit criteria and propose new, concave loss functions. Together with regularization , they form a robust objective for the regression procedure. Discussion of the rationale behind the proposed approach and its effects is illustrated by laboratory data on the transesterification of palm oil. A dedicated simulation study complements qualitative examples. All of the top-performing methods use regularization. Concave loss functions were among the best in 6–7 out of 8 test cases, compared to 2–3 for the classical square loss confirming both statistical and practical usefulness of the novel fit criteria. This result holds for a variety of modern optimizers. In 76\% of our simulations, we obtained results not significantly worse than the best, whereas methods currently used in the literature provide 38\% for the relative and 0\% for the square loss.},
  archive      = {J_ASOC},
  author       = {Karol R. Opara and Pin Pin Oh},
  doi          = {10.1016/j.asoc.2021.108286},
  journal      = {Applied Soft Computing},
  pages        = {108286},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Regularization and concave loss functions for estimation of chemical kinetic models},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Extension of interval-valued pythagorean FDOSM for
evaluating and benchmarking real-time SLRSs based on multidimensional
criteria of hand gesture recognition and sensor glove perspectives.
<em>ASOC</em>, <em>116</em>, 108284. (<a
href="https://doi.org/10.1016/j.asoc.2021.108284">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several DataGlove wearable electronic devices based on real-time Sign Language Recognition Systems (SLRSs) have been developed recently to assist the deaf and dumb community in translating hand gestures to their spoken language equivalents. Multidimensional evaluation and benchmarking of these systems are critical for determining the most desirable approach for meeting all essential requirements. However, this process is considered a Multicriteria Decision-Making (MCDM) problem due to the presence of several issues, including multiple evaluation criteria, criteria importance and criteria confliction. Hence, the MCDM approach is required to solve these issues. In this study, a new extension of the Fuzzy Decision by Opinion Score Method (FDOSM) for evaluating and benchmarking SLRSs is developed under an Interval-Valued Pythagorean Fuzzy Set (IVPFS) named IVP-FDOSM. Fundamentally, the methodology includes two phases. In the first phase, a decision matrix is formulated on the basis of identified ‘multidimensional criteria of hand gesture recognition and sensor glove perspectives’ and ‘real-time SLRSs’. The second phase introduces the development of IVP-FDOSM in two stages. The decision matrix is transformed into an opinion matrix in the first stage (data transformation unit). Meanwhile, in the second stage (data-processing unit), the opinion matrix is converted into fuzzy opinion decision matrices with the assistance of three experts by transforming the opinion matrix’s linguistic terms to Interval-Value Pythagorean Fuzzy Numbers (IVPFNs). Results indicate the following: (1) individual benchmarking results of real-time SLRS showed high variation (90\%) based on the preference of each Decision Maker (DM), with only 10\% of preferences being identical. (2) The results of group benchmarking reveal that the 10th real-time SLRS was the optimal one and the 6th was the worst. In addition, the rates of ranking match between the group benchmarking and each DM (first DM, second DM and third DM) were 23\%, 37\% and 43\%, respectively. (3) For the results evaluation, the statistical test-based objective assessment shows that the first group received the lowest mean value (2.80333), while the third group received the highest mean (3.8). These values indicate that the group benchmarked systems resulting from IVP-FDOSM are undergoing a systematic ranking. Furthermore, the comparative analysis reveals that IVP-FDOSM is superior to IVP-TOPSIS and IVP-AHP in terms of ranking and weighting.},
  archive      = {J_ASOC},
  author       = {Mohammed S. Al-Samarraay and A.A. Zaidan and O.S. Albahri and Dragan Pamucar and H.A. AlSattar and A.H. Alamoodi and B.B. Zaidan and A.S. Albahri},
  doi          = {10.1016/j.asoc.2021.108284},
  journal      = {Applied Soft Computing},
  pages        = {108284},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Extension of interval-valued pythagorean FDOSM for evaluating and benchmarking real-time SLRSs based on multidimensional criteria of hand gesture recognition and sensor glove perspectives},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel ensemble fuzzy classification model in SARS-CoV-2
b-cell epitope identification for development of protein-based vaccine.
<em>ASOC</em>, <em>116</em>, 108280. (<a
href="https://doi.org/10.1016/j.asoc.2021.108280">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {B-cell epitope prediction research has received growing interest since the development of the first method. B-cell epitope identification with the aid of an accurate prediction method is one of the most important steps in epitope-based vaccine development, immunodiagnostic testing, antibody production , disease diagnosis, and treatment. Nevertheless, using experimental methods in epitope mapping is very time-consuming, costly, and labor-intensive. Therefore, although successful predictions with in silico methods are very important in epitope prediction, there are limited studies in this area. The aim of this study is to propose a new approach for successfully predicting B-cell epitopes for severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). In this study, the SARS-CoV B-cell epitope prediction performances of different fuzzy learning classification models genetic cooperative competitive learning (GCCL), fuzzy genetics-based machine learning (GBML), Chi’s method (CHI), Ishibuchi’s method with weight factor (W), structural learning algorithm on vague environment (SLAVE) and the state-of-the-art ensemble fuzzy classification model were compared. The obtained results showed that the proposed ensemble approach has the lowest error in SARS-CoV B-cell epitope estimation compared to the base fuzzy learners (average error rates; ensemble fuzzy=8.33, GCCL=30.42, GBML=23.82, CHI=29.17, W=46.25, and SLAVE=20.42). SARS-CoV and SARS-CoV-2 have high genome similarities. Therefore, the most successful method determined for SARS-CoV B-cell epitope prediction was used in SARS-CoV-2 cell epitope prediction. Finally, the eventual B-cell epitope prediction results obtained for SARS-CoV-2 with the ensemble fuzzy classification model were compared with the epitope sequences predicted by the BepiPred server and immunoinformatics studies in the literature for the same protein sequences according to VaxiJen 2.0 scores. We hope that the developed epitope prediction method will help design effective vaccines and drugs against future outbreaks of the coronavirus family, especially SARS-CoV-2 and its possible mutations.},
  archive      = {J_ASOC},
  author       = {Zeynep Banu Ozger and Pınar Cihan},
  doi          = {10.1016/j.asoc.2021.108280},
  journal      = {Applied Soft Computing},
  pages        = {108280},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A novel ensemble fuzzy classification model in SARS-CoV-2 B-cell epitope identification for development of protein-based vaccine},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mitigating bullwhip effect in an agent-based supply chain
through a fuzzy reverse ultimatum game negotiation module.
<em>ASOC</em>, <em>116</em>, 108278. (<a
href="https://doi.org/10.1016/j.asoc.2021.108278">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supply Chain Management is frequently regarded as a distributed system whose productivity is mainly influenced by healthy interaction and cooperation among members. Examples of such inefficiencies can be seen in “Demand amplification” referring to asymmetric increase of demands among supply echelons due to both operational and behavioral causes. This paper addresses defective loops of non-cooperation as well as absence of information to manage the dynamics of demand amplification in a four-echelon supply chain; a new agent-based structure is suggested to facilitate the cooperation and coordination among major components and provide a structured context for interactive information sharing. Adequate motivation to share the required information is derived from an automated negotiation between retailer and manufacturer echelons in a four-echelon serial supply model. In doing so, the retailer agent would be encouraged to share customer demand information using Token-Based ordering policy, through a Reverse Ultimatum Game negotiation module. A novel fuzzy approach is suggested in order to cope with ambiguities involved in this negotiation; Numerical experiments prove that the proposed fuzzy negotiation mechanism can warrant the agreement among negotiating parties in nearly half the number of RUG iterations with 30\% agreement share. This success in bringing the negotiation parties to an agreement results in the bullwhip effect decreasing by 30\% in a four-echelon agent-based supply system. The proposed agent-based supply model which is designed to facilitate this cooperative decision-making process includes some unique innovative features: the knowledge base of the proposed system is able to retrieve and reuse the previous negotiation outcomes, through a gradual learning module. A combination of Case-Based Reasoning and Rule-Based inference mechanisms are applied to facilitate this, so prior cases will be stored in a Frame-Based structure. Eventually, the integrity of the proposed agent-based system is examined through combining Top-Down and Subsets integration approaches and some numerical experiments are provided to confirm the efficiency of the proposed agent-based structure in bullwhip effect management.},
  archive      = {J_ASOC},
  author       = {F. Shabany Moghadam and M.H. Fazel Zarandi},
  doi          = {10.1016/j.asoc.2021.108278},
  journal      = {Applied Soft Computing},
  pages        = {108278},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Mitigating bullwhip effect in an agent-based supply chain through a fuzzy reverse ultimatum game negotiation module},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Order book mid-price movement inference by CatBoost
classifier from convolutional feature maps. <em>ASOC</em>, <em>116</em>,
108274. (<a href="https://doi.org/10.1016/j.asoc.2021.108274">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the application of a hybrid model to predict the mid-price trend of assets in the Brazilian Stock Exchange (B3) from the market by order data. A Convolution Neural Network (CNN) is applied to extract spatial features from an order book aggregated by price and then a decision tree-based algorithm (CatBoost) combines these CNN features with events provided by Times and Trades information (TTinfo) to have the final prediction. Differently from most stock exchanges, TTinfo from B3 includes to which broker an order belongs, and in this work its impact in the final prediction is analysed as well. The proposed solution innovates by joining CNN with CatBoost, improving accuracy by 8\% when compared to a common CNN, where 5\% is only due to the adoption of CatBoost and another 3\% is due to the combination of features from CNN with TTinfo. In addition, for training update, only CatBoost needs to be retrained, allowing learning transfer for the CNN, which reduces the overall updating time in at least one order of magnitude.},
  archive      = {J_ASOC},
  author       = {Guilherme A. Bileki and Flávio Barboza and Luiz Henrique C. Silva and Vanderlei Bonato},
  doi          = {10.1016/j.asoc.2021.108274},
  journal      = {Applied Soft Computing},
  pages        = {108274},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Order book mid-price movement inference by CatBoost classifier from convolutional feature maps},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A population-based game-theoretic optimizer for the minimum
weighted vertex cover. <em>ASOC</em>, <em>116</em>, 108272. (<a
href="https://doi.org/10.1016/j.asoc.2021.108272">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Toward higher solution efficiency and faster computation, this paper addresses the minimum weighted vertex cover (MWVC) problem by introducing game theory into iterated optimization and proposing a population-based game-theoretic optimizer (PGTO). A group of candidate solutions are iterated through the specially designed procedures of swarm evolution (SE), learning in games (LIG), and local search (LS) successively. Within the framework of potential game theory, we prove that LIG computes in finite time Nash equilibria that represent vertex cover solutions where no redundant nodes exist. Moreover, theoretical analysis is presented that by exchanging the actions of certain neighbours, LS is capable of generating better results upon the input Nash equilibrium. Through intensive numerical experiments, we show that while enlarging the population size could boost the global objective, a mutation probability between 0.05 and 0.2 is more likely to provide the best performance. Comparison experiments against the state of the art demonstrate the superiority of the presented methodology, both in terms of solution quality and computation speed.},
  archive      = {J_ASOC},
  author       = {Huaxin Qiu and Changhao Sun and Xiaochu Wang and Wei Sun and Qingrui Zhou},
  doi          = {10.1016/j.asoc.2021.108272},
  journal      = {Applied Soft Computing},
  pages        = {108272},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A population-based game-theoretic optimizer for the minimum weighted vertex cover},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-organizing migrating algorithm with narrowing search
space strategy for robot path planning. <em>ASOC</em>, <em>116</em>,
108270. (<a href="https://doi.org/10.1016/j.asoc.2021.108270">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a version of the Self-Organizing Migrating Algorithm with a narrowing search space strategy named iSOMA. Compared to the previous two versions, SOMA T3A and Pareto that ranked 3 r d 3rd and 5 t h 5th respectively in the IEEE CEC (Congress on Evolutionary Computation) 2019 competition, the iSOMA is equipped with more advanced features with notable improvements including applying jumps in the order, immediate update, narrowing the search space instead of searching on the intersecting edges of hyperplanes , and the partial replacement of individuals in the population when the global best improved no further. Moreover, the proposed algorithm is organized into processes named initialization, self-organizing, migrating, and replacement. We tested the performance of this new version by using three benchmark test suites of IEEE CEC 2013, 2015, and 2017, which, together contain a total of 73 functions. Not only is it superior in performance to other SOMAs, but iSOMA also yields promising results against the representatives of well-known algorithmic families such as Differential Evolution and Particle Swarm Optimization . Moreover, we demonstrate the application of iSOMA for path planning of a drone, while avoiding static obstacles and catching the target.},
  archive      = {J_ASOC},
  author       = {Quoc Bao Diep and Thanh Cong Truong and Swagatam Das and Ivan Zelinka},
  doi          = {10.1016/j.asoc.2021.108270},
  journal      = {Applied Soft Computing},
  pages        = {108270},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Self-organizing migrating algorithm with narrowing search space strategy for robot path planning},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cost-sensitive matrixized classification learning with
information entropy. <em>ASOC</em>, <em>116</em>, 108266. (<a
href="https://doi.org/10.1016/j.asoc.2021.108266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classifier design is one of the most significant fields in pattern recognition. Most classifiers are measured by classification accuracy , which assumes that all the misclassification cost are the same. In the real world, different misclassifications usually bring different losses. Based on this fact, cost-sensitive learning is becoming a hot research area in pattern recognition. However, in cost-sensitive learning, examples costs are often difficult to achieve and usually decided by the authors experience. Hence, combining the cost-sensitive learning and matrixized learning thoughts, we propose a two-class cost-sensitive matrixized classification model based on information entropy called CsMatMHKS in this paper. The proposed CsMatMHKS introduces information entropy which can reveal the uncertainty of one sample into matrixized learning framework to decrease the total misclassification cost. The experimental results on the UCI datasets and image datasets indicate that the CsMatMHKS not only reduces the sum of classification costs but also has comparable classification accuracy.},
  archive      = {J_ASOC},
  author       = {Zhe Wang and Xu Chu and Dongdong Li and Hai Yang and Weichao Qu},
  doi          = {10.1016/j.asoc.2021.108266},
  journal      = {Applied Soft Computing},
  pages        = {108266},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Cost-sensitive matrixized classification learning with information entropy},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards an efficient collection and transport of COVID-19
diagnostic specimens using genetic-based algorithms. <em>ASOC</em>,
<em>116</em>, 108264. (<a
href="https://doi.org/10.1016/j.asoc.2021.108264">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The speed by which the COVID-19 pandemic spread throughout the world makes the emergency services unprepared to answer all the patients’ requests. The Tunisian ministry of health established a protocol planning the sample collection from the patients at their location. A triage score is first assigned to each patient according to the symptoms he is showing, and his health conditions. Then, given the limited number of the available ambulances in each area, the location of the patients and the capacity of the nearby hospitals for receiving the testing samples, an ambulance scheduling and routing plan needs to be established so that specimens can be transferred to hospitals in short time. In this paper, we propose to model this problem as a Multi-Origin–Destination Team Orienteering Problem (MODTOP). The objective is to find the optimal one day tour plan for the available ambulances that maximizes the collected scores of visited patients while respecting duration and capacity constraints. To solve this NP-hard problem, two highly effective approaches are proposed which are Hybrid Genetic Algorithm (HGA) and Memetic Algorithm (MA). The HGA combines (i) a k-means construction method for initial population generation and (ii) a one point crossover operator for solution recombination. The MA is an improvement of HGA that integrates an effective local search based on three different neighborhood structures. Computational experiments, supported by a statistical analysis on benchmark data sets, illustrate the efficiency of the proposed approaches. HGA and MA reached the best known solutions in 54.7\% and 73.5\% of instances, respectively. Likewise, MA reached a relative error of 0.0675\% and performed better than four existing approaches. Real-case instances derived from the city of Tunis were also solved and compared with the results of an exact solver Cplex to validate the effectiveness of our algorithm.},
  archive      = {J_ASOC},
  author       = {Takwa Tlili and Hela Masri and Saoussen Krichen},
  doi          = {10.1016/j.asoc.2021.108264},
  journal      = {Applied Soft Computing},
  pages        = {108264},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Towards an efficient collection and transport of COVID-19 diagnostic specimens using genetic-based algorithms},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). One shot model for the prediction of COVID-19 and lesions
segmentation in chest CT scans through the affinity among lesion mask
features. <em>ASOC</em>, <em>116</em>, 108261. (<a
href="https://doi.org/10.1016/j.asoc.2021.108261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel framework that integrates segmentation of lesion masks and prediction of COVID-19 in chest CT scans in one shot. In order to classify the whole input image, we introduce a type of associations among lesion mask features extracted from the scan slice that we refer to as affinities. First, we map mask features to the affinity space by training an affinity matrix . Next, we map them back into the feature space through a trainable affinity vector. Finally, this feature representation is used for the classification of the whole input scan slice. We achieve a 93.55\% COVID-19 sensitivity, 96.93\% common pneumonia sensitivity, 99.37\% true negative rate and 97.37\% F1-score on the test split of CNCB-NCOV dataset with 21192 chest CT scan slices. We also achieve a 0.4240 mean average precision on the lesion segmentation task. All source code , models and results are publicly available on https://github.com/AlexTS1980/COVID-Affinity-Model .},
  archive      = {J_ASOC},
  author       = {Aram Ter-Sarkisov},
  doi          = {10.1016/j.asoc.2021.108261},
  journal      = {Applied Soft Computing},
  pages        = {108261},
  shortjournal = {Appl. Soft. Comput.},
  title        = {One shot model for the prediction of COVID-19 and lesions segmentation in chest CT scans through the affinity among lesion mask features},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Swarm intelligence optimization of the group method of data
handling using the cuckoo search and whale optimization algorithms to
model and predict landslides. <em>ASOC</em>, <em>116</em>, 108254. (<a
href="https://doi.org/10.1016/j.asoc.2021.108254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The robustness of landslide prediction models has become a major focus of researchers worldwide. We developed two novel hybrid predictive models that combine the self-organizing, deep-learning group method of data handling (GMDH) with two swarm intelligence optimization algorithms , i.e., cuckoo search algorithm (CSA) and whale optimization algorithm (WOA) for spatially explicit prediction of landslide susceptibility. Eleven landslide-causing factors and 334 historic landslides in a 31, 340 km 2 landslide-prone area in Iran were used to produce geospatial training and validation datasets . The GMDH model was employed to develop a basic predictive model that was then restructured and its parameters were optimized using the CSA and WOA algorithms, yielding the novel hybrid GMDH-CSA and GMDH-WOA models. The hybrid models were validated and compared to the standalone GMDH model by calculating the area under the receiver operating characteristic (AUC) curve and root mean square error (RMSE). The results demonstrated that the hybrid models overcame the computational shortcomings of the basic GMDH model and significantly improved landslide susceptibility prediction (GMDH-CSA, AUC = 0.909 and RMSE = 0.089; GMDH-WOA, AUC = 0.902 and RMSE = 0.129; standalone GMDH, AUC = 0.791 and RMSE = 0.226). Further, the hybrid models were more robust than the standalone GMDH model, showing consistently excellent performance when the training and validation datasets were changed. Overall, the swarm intelligence-optimized models, but not the standalone model, identified the best trade-offs among objectives, accuracy, and robustness.},
  archive      = {J_ASOC},
  author       = {Abolfazl Jaafari and Mahdi Panahi and Davood Mafi-Gholami and Omid Rahmati and Himan Shahabi and Ataollah Shirzadi and Saro Lee and Dieu Tien Bui and Biswajeet Pradhan},
  doi          = {10.1016/j.asoc.2021.108254},
  journal      = {Applied Soft Computing},
  pages        = {108254},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Swarm intelligence optimization of the group method of data handling using the cuckoo search and whale optimization algorithms to model and predict landslides},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interval-valued intuitionistic fuzzy two-sided matching
model considering level of automation. <em>ASOC</em>, <em>116</em>,
108252. (<a href="https://doi.org/10.1016/j.asoc.2021.108252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past few decades, personnel–position matching (PPM) has garnered increasing attention from scholars. In recent years, with intelligent robots facilitating intelligent production, a new form of problem—personnel–machine position matching (PMPM)—has been derived from PPM. In this study, an interval-valued intuitionistic fuzzy two-sided matching model considering level of automation (LOA) is proposed to solve the PMPM problem in an intelligent production line from the perspective of position homogeneity. The first issue to be considered in this solution is the uncertainty of preference information resulting from the decision-makers’ cognition bias or limitations. By proposing a novel score function based on the centroid method and technique for order preference by similarity to an ideal solution (TOPSIS), this issue is addressed in the information evaluation phase. Another important issue lies in the LOA, which adjusts the degree of human–machine participation. In this study, the classical two-sided matching model was improved by considering the LOA. Furthermore, to maximise the matching satisfaction of multiple sides (personnel, intelligent robots and positions), a multi-objective decision-making model is established. Afterwards, the model is transformed into a single objective model using the combined satisfaction analysis method, which is introduced to produce the final optimisation results in this modelling process. A case is presented to illustrate the practicality of the interval-valued intuitionistic fuzzy two-sided matching model considering LOA, and the results indicate that this model can solve the PMPM problem in an intelligent production line.},
  archive      = {J_ASOC},
  author       = {Zhi-Chao Liang and Yu Yang and Shi-Gen Liao},
  doi          = {10.1016/j.asoc.2021.108252},
  journal      = {Applied Soft Computing},
  pages        = {108252},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Interval-valued intuitionistic fuzzy two-sided matching model considering level of automation},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Collaborative scheduling of operating room in hospital
network: Multi-objective learning variable neighborhood search.
<em>ASOC</em>, <em>116</em>, 108233. (<a
href="https://doi.org/10.1016/j.asoc.2021.108233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, the operating room scheduling of hospital networks with virtual alliance has been studied, which at the same time, there is a kind of cooperation and competition among the agents. The main feature in networks with the virtual alliance is the possibility of different objective functions among the agents, which has priority for agents compared to the network’s overall objective. Here, by considering the conditions of emergency arrival, the time of inter-hospital transportation, and the elective patients and non-elective patients in the scheduling, an attempt has been made to bring the problem closer to real-world situations. To solve this problem, first, a mixed-integer mathematical programming model is proposed. Because of its NP-hardness, then, a multi-objective learning variable neighborhood search algorithm is designed to minimize total completion of surgeries, the cost of allocating the patient to the hospital and the surgeon, and the cost of overtime operating rooms throughout the network. Finally, the performance of the proposed algorithm is evaluated in comparison with the NSGA-II and memetic-based algorithm, which due to considering the learning mechanism along with the use of various neighborhood structures in the proposed algorithm, its results are promising. It is expected that by using the proposed algorithms in a cooperative structure, the hospitals are able to achieve optimal/near-optimal solutions in a reasonable time, in which, in addition to more economic activity, patients also benefit due to better use of resources.},
  archive      = {J_ASOC},
  author       = {M. Lotfi and J. Behnamian},
  doi          = {10.1016/j.asoc.2021.108233},
  journal      = {Applied Soft Computing},
  pages        = {108233},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Collaborative scheduling of operating room in hospital network: Multi-objective learning variable neighborhood search},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Gabor log-euclidean gaussian and its fusion with deep
network based on self-attention for face recognition. <em>ASOC</em>,
<em>116</em>, 108210. (<a
href="https://doi.org/10.1016/j.asoc.2021.108210">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we proposed a face feature extraction method by Learning Gabor Log-Euclidean Gaussian with Whitening Principal Component Analysis (called LGLG-WPCA). The proposed method extracts raw features from the multivariate Gaussian in the transform domain of Gabor wavelet and uses WPCA to get robust features. Because the space of Gaussian is a Riemannian manifold, it is difficult to incorporate the learning mechanism into the model. To address this issue, Log-Euclidean approach is used to embed the multivariate Gaussian into the linear space, and then use WPCA to learn discriminative face features. LGLG-WPCA is good at extracting the detail features of face image. Furthermore, another outstanding advantage of LGLG is that its features can be effectively integrated with the high-level features of deep learning network for face recognition in more complex environments. We presented the feature fusing approaches for face recognition based on Self-attention Network (SAN) and achieved obvious performance improvement to the-state-of-the-art deep networks including SENet and FaceNet. Experiments show the proposed method is robust under adverse conditions such as varying poses, skin aging and uneven illumination, and it is suitable for face image under small-scale datasets in complex environments, such as network-based or video-based person searching or tracking.},
  archive      = {J_ASOC},
  author       = {Chaorong Li and Wei Huang and Yuanyuan Huang},
  doi          = {10.1016/j.asoc.2021.108210},
  journal      = {Applied Soft Computing},
  pages        = {108210},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Gabor log-euclidean gaussian and its fusion with deep network based on self-attention for face recognition},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A three-stage framework for vertical carbon price interval
forecast based on decomposition–integration method. <em>ASOC</em>,
<em>116</em>, 108204. (<a
href="https://doi.org/10.1016/j.asoc.2021.108204">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current context of pursuing carbon neutrality and carbon peaking, many countries are accelerating the construction of carbon trading markets . Accurate prediction of carbon prices can enable national carbon trading markets to play a role in carbon emission reduction as soon as possible. However, current research is limited mostly to point forecasting of carbon prices, which makes it difficult to guarantee the stability of forecasting results in an increasingly complex market. Therefore, this paper proposes a three-stage vertical carbon price interval prediction framework. The contributions of this paper are as follows: the selection process of the decomposition model is regarded as an important process of prediction; a backpropagation neural network optimized by the sparrow search algorithm (SSA-BPNN) is used for the point prediction of carbon prices as a first attempt; and the kernel density estimation (KDE) model is used for interval estimation based on the point prediction results, which improves the confidence of the prediction. To validate the framework, this paper uses Shenzhen SZA-2014 products as the sample. The results show that the root mean square error of the predicted result with the improved complete ensemble empirical mode decomposition model (ICEEMD) is reduced by 29.7\% and the use of SSA increases the predicted R 2 by 8.5\% compared with other optimization algorithms . In addition, the prediction interval coverage probability of interval prediction reaches 86\% under 70\% confidence. These results show that the proposed framework is not only more effective in point prediction but also performs well in interval prediction.},
  archive      = {J_ASOC},
  author       = {Zhengsen Ji and Dongxiao Niu and Mingyu Li and Wanying Li and Lijie Sun and Yankai Zhu},
  doi          = {10.1016/j.asoc.2021.108204},
  journal      = {Applied Soft Computing},
  pages        = {108204},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A three-stage framework for vertical carbon price interval forecast based on decomposition–integration method},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Patrol robot path planning in nuclear power plant using an
interval multi-objective particle swarm optimization algorithm.
<em>ASOC</em>, <em>116</em>, 108192. (<a
href="https://doi.org/10.1016/j.asoc.2021.108192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an interval multi-objective path planning (PP) scheme for patrol robot in nuclear power plant . The purpose of this PP scheme is to find collision-free paths with the shortest length and smallest risk degree. Firstly, a novel workspace modeling method is proposed to describe the static PP environment of patrol robot in nuclear power plant . Then considering the conflicts of the shortest length and smallest risk degree, an interval multi-objective particle swarm optimization (IMOPSO) method is used. In the IMOPSO, an ingenious interval update law for the particle’s global best position and local best position based on the crowding distance of each risk degree interval is used to increase the diversity of population, and an iterative procedure is adopted to update the particle’s position when the found paths are collided with some existing obstacles. Finally, three representative simulation tests are used to verify the validity of proposed IMOPSO method. Results show that comparing with other three well-known multi-objective evolutionary algorithms, our proposed method has the advantages of finding a better Pareto optimal paths.},
  archive      = {J_ASOC},
  author       = {Zhihuan Chen and Huaiyu Wu and Yang Chen and Lei Cheng and Binqiao Zhang},
  doi          = {10.1016/j.asoc.2021.108192},
  journal      = {Applied Soft Computing},
  pages        = {108192},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Patrol robot path planning in nuclear power plant using an interval multi-objective particle swarm optimization algorithm},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Trajectory planning of autonomous mobile robots applying a
particle swarm optimization algorithm with peaks of diversity.
<em>ASOC</em>, <em>116</em>, 108108. (<a
href="https://doi.org/10.1016/j.asoc.2021.108108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new quantum-behaved particle swarm optimization (QPSO) algorithm for the trajectory planning task of mobile robotic vehicles in static and dynamic environments—it is called enhanced diversity particle swarm optimization (EDPSO). The main characteristic of this algorithm is that it has peaks of diversity in its population, making it possible to escape from local minima effectively, avoiding stagnation. Through the proposed PSO, it is possible to obtain safe and efficient routes, avoiding energy waste and maintaining system integrity in several possible applications. The parameters of the proposed algorithm were tuned using the benchmarking functions. The same functions were used to compare the algorithm with those already established in the literature. Once the proposed algorithm showed promising results, it was simulated in four environments, each with different complexities, presenting dangerous regions and terrains unsuitable for robot navigation , and a large number of obstacles or even moving objects. Further, the algorithms used for comparison were also simulated and the EDPSO presented satisfactory results. Through simulations it was possible to notice that the proposed approach resulted in collision-free and planned routes, and the algorithm presented increased exploration features owing to the diversity peaks that occur during the optimization.},
  archive      = {J_ASOC},
  author       = {P.B. Fernandes and R.C.L. Oliveira and J.V. Fonseca Neto},
  doi          = {10.1016/j.asoc.2021.108108},
  journal      = {Applied Soft Computing},
  pages        = {108108},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Trajectory planning of autonomous mobile robots applying a particle swarm optimization algorithm with peaks of diversity},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine learning for hardware security: Classifier-based
identification of trojans in pipelined microprocessors. <em>ASOC</em>,
<em>116</em>, 108068. (<a
href="https://doi.org/10.1016/j.asoc.2021.108068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the last decade, the Integrated Circuit industry has paid special attention to the security of products. Hardware-based vulnerabilities, in particular Hardware Trojans, are becoming a serious threat, pushing the research community to provide highly sophisticated techniques to detect them. Despite the considerable effort that has been invested in this area, the growing complexity of modern devices always calls for sharper detection methodologies. This paper illustrates a pre-silicon simulation-based technique to detect hardware trojans. The technique exploits well-established machine learning algorithms . The paper introduces all the background concepts and presents the methodology. The validity of the approach has been demonstrated on the AutoSoC CPU , an industrial-grade, safety-oriented, automotive benchmark suite. Experimental results demonstrate the applicability and effectiveness of the approach: the proposed technique is highly accurate in pinpointing suspicious code sections. None of the hardware trojans from the set has been left undetected.},
  archive      = {J_ASOC},
  author       = {Aleksa Damljanovic and Annachiara Ruospo and Ernesto Sanchez and Giovanni Squillero},
  doi          = {10.1016/j.asoc.2021.108068},
  journal      = {Applied Soft Computing},
  pages        = {108068},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Machine learning for hardware security: Classifier-based identification of trojans in pipelined microprocessors},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A takeover time-driven adaptive evolutionary algorithm for
mobile user tracking in pre-5G cellular networks. <em>ASOC</em>,
<em>116</em>, 107992. (<a
href="https://doi.org/10.1016/j.asoc.2021.107992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cellular networks are one of today’s most popular means of communication. This fact has made the mobile phone industry subject to a huge scientific and economic competition, where the quality of service is key. Such a quality is measured on the basis of reliability, speed and accuracy when delivering a service to a user no matter his location or behaviour are. This fact has placed the users’ tracking process among the most difficult and determining issues in cellular network design. In this paper, we present an adaptive bi-phased evolutionary algorithm based on the takeover time to solve this problem. The proposal is thoroughly assessed by tackling twenty-five real-world instances of different sizes. Twenty-eight of the state-of-the-art techniques devised to address the users’ mobility problem have been taken as the comparison basis, and several statistical tests have been also conducted. Experiments have demonstrated that our solver outperforms most of the top-ranked algorithms.},
  archive      = {J_ASOC},
  author       = {Zakaria Abdelmoiz Dahi and Enrique Alba and Gabriel Luque},
  doi          = {10.1016/j.asoc.2021.107992},
  journal      = {Applied Soft Computing},
  pages        = {107992},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A takeover time-driven adaptive evolutionary algorithm for mobile user tracking in pre-5G cellular networks},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). KNNOR: An oversampling technique for imbalanced datasets.
<em>ASOC</em>, <em>115</em>, 108288. (<a
href="https://doi.org/10.1016/j.asoc.2021.108288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predictive performance of Machine Learning (ML) models rely on the quality of data used for training the models. However, if the training data is not balanced among different classes, the performance of ML models deteriorate heavily. Several techniques have been proposed in the literature to add some semblance of balance to the data sets by adding artificial data points. Synthetic Minority Oversampling Technique(SMOTE) and Adaptive Synthetic Sampling(ADASYN) are some of the commonly used techniques to deal with class imbalance. However, these approaches are prone to ‘within class imbalance’ and ‘small disjunct problem’. To overcome these problems, this article proposes an advanced algorithm by studying the compactness and location of the minority class relative to other classes. The proposed technique called K-Nearest Neighbor OveRsampling approach (KNNOR) performs a three step process to identify the critical and safe areas for augmentation and generate synthetic data points of the minority class. The relative density of the entire population is considered while generating artificial points. This enables the proposed KNNOR approach to oversample the minority class more reliably and at the same time stay resilient against noise. The proposed method is compared with the ten top performing contemporary oversamplers by testing the accuracy of classifiers trained on augmented data provided by each oversampler. The experimental results on several common imbalanced datasets show that our method ranks first more consistently than the other state-of-art oversamplers. The proposed method is easy to use and has been made open source as a python library.},
  archive      = {J_ASOC},
  author       = {Ashhadul Islam and Samir Brahim Belhaouari and Atiq Ur Rehman and Halima Bensmail},
  doi          = {10.1016/j.asoc.2021.108288},
  journal      = {Applied Soft Computing},
  pages        = {108288},
  shortjournal = {Appl. Soft. Comput.},
  title        = {KNNOR: An oversampling technique for imbalanced datasets},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). IoT based monitoring of air quality and traffic using
regression analysis. <em>ASOC</em>, <em>115</em>, 108282. (<a
href="https://doi.org/10.1016/j.asoc.2021.108282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic traffic management (DTM) systems are used to reduce the negative externalities of traffic congestion, such as air pollution in urban areas. They require traffic and environmental monitoring infrastructures. In this paper we present a prototype of a low-cost Internet of Things (IoT) system for monitoring traffic flow and the Air Quality Index (AQI). The computation of the traffic flows is based on processing video in the compressed domain. Only using motion vectors as input, traffic flow is computed in real-time over an embedded architecture. An estimation of the AQI is supported by machine learning regression techniques , using different feature data obtained from the IoT device. These automatic learning techniques overcome the need for complex calibration and other limitations of embedded devices in making the needed measurements of the pollutant gases for the computation of the actual AQI. The experimentation with the data obtained from different cities representing different scenarios with a variety of climate and traffic conditions, allows validating the proposed architecture. As regressors , Linear Regression (LR), Gaussian Process Regression (GPR) and Random Forest (RF) are compared using the performance metrics R 2 R2 , M S E MSE , M A E MAE and M R E MRE resulting in a relevant improvement of the AQI estimations of our proposal.},
  archive      = {J_ASOC},
  author       = {José Ángel Martín-Baos and Luis Rodriguez-Benitez and Ricardo García-Ródenas and Jun Liu},
  doi          = {10.1016/j.asoc.2021.108282},
  journal      = {Applied Soft Computing},
  pages        = {108282},
  shortjournal = {Appl. Soft. Comput.},
  title        = {IoT based monitoring of air quality and traffic using regression analysis},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Elevator group control as a constrained multiobjective
optimization problem. <em>ASOC</em>, <em>115</em>, 108277. (<a
href="https://doi.org/10.1016/j.asoc.2021.108277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern elevator systems are controlled by the elevator group controllers that assign moving and stopping policies to the elevator cars. Designing an adequate elevator group control (EGC) policy is challenging for a number of reasons, one of them being conflicting optimization objectives . We address this task by formulating a corresponding constrained multiobjective optimization problem , and, in contrast to most studies in this domain, approach it using true multiobjective optimization methods capable of finding approximations for Pareto-optimal solutions. Specifically, we apply five multiobjective optimization algorithms with default constraint handling techniques and demonstrate their performance in optimizing EGC for nine elevator systems of various complexity. The experimental results confirm the scalability of the proposed methodology and suggest that NSGA-II equipped with the constrained-domination principle is the best performing algorithm on the test EGC systems. The proposed problem formulation and methodology allow for better understanding of the EGC design problem and provide insightful information to the stakeholders involved in deciding on elevator system configurations and control policies.},
  archive      = {J_ASOC},
  author       = {Aljoša Vodopija and Jörg Stork and Thomas Bartz-Beielstein and Bogdan Filipič},
  doi          = {10.1016/j.asoc.2021.108277},
  journal      = {Applied Soft Computing},
  pages        = {108277},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Elevator group control as a constrained multiobjective optimization problem},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast terminal sliding mode control design for position
control of induction motors using adaptive quantum neural networks.
<em>ASOC</em>, <em>115</em>, 108268. (<a
href="https://doi.org/10.1016/j.asoc.2021.108268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, an efficient robust control scheme is proposed for position control of induction motors based on field-oriented control (FOC). The proposed control scheme consists of three interior loops. In the outer loop, the central controller based on the nonsingular fast terminal sliding mode control (NFTSM) is designed. The objective of this loop is to provide the required stator current in the q-axis for regulating the electromagnetic torque. In the inner loops, two fractional-order PI (FOPI) controllers are designed to provide the stator voltages . Besides, since induction motors have a complex mathematical model, time-varying dynamics, and non-linear structure, to deal with these challenges in the controller design , the quantum neural network (QNN) is presented with a novel framework and employed to estimate the lumped uncertainties. This makes the main contribution of the paper. In addition, to further improve system performance, the parameters of the FOPI controllers are tuned by employing the artificial bee colony (ABC) optimization algorithm . The stability of the proposed control approach is proved by Lyapunov’s stability theory. According to the results of the comparative simulation, the superiority of this approach is confirmed.},
  archive      = {J_ASOC},
  author       = {Majid Moradi Zirkohi},
  doi          = {10.1016/j.asoc.2021.108268},
  journal      = {Applied Soft Computing},
  pages        = {108268},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fast terminal sliding mode control design for position control of induction motors using adaptive quantum neural networks},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Novel hybrid discrete differential evolution algorithm for
the multi-stage multi-purpose batch plant scheduling problem.
<em>ASOC</em>, <em>115</em>, 108262. (<a
href="https://doi.org/10.1016/j.asoc.2021.108262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-stage multi-product batch plant scheduling problem is an important part of batch chemical industry scheduling problems. Different from the multi-purpose batch scheduling problem, this problem can be characterized by multiple stages with non-identical parallel units, and multiple batches of customer orders. Numerous methodologies for this problem have been investigated to addressing scheduling cases of different production systems in the past two decades. This paper focus on the large-scale batch plant scheduling problem by minimizing the make-span in the scheduling horizon. And a novel hybrid discrete differential evolutionary algorithm is proposed to handle this problem. First, a novel two-line encoding scheme is constructed based on discrete and continuous variables. The sequence of orders is represented by a time-based representation method. Second, two novel mutation methods are proposed within the framework of encoding method. Two methods provide multiple search directions which helps improve the exploration ability and diversity of the population. At last, two local permutation methods are applied to improve the local optimal for the algorithm. The proposed work is tested through several real industrial instances with different sizes and characteristics by comparing with mixed integer linear programming method and meta-heuristic algorithms. The improvement of proposed work is also analyzed by the instances. The results report the efficiency and effectiveness of the novel proposed evolutionary algorithm in solving large scale multi-stage multi-product batch plant scheduling problem.},
  archive      = {J_ASOC},
  author       = {Yuxin Han and Xueli Yan and Xingsheng Gu},
  doi          = {10.1016/j.asoc.2021.108262},
  journal      = {Applied Soft Computing},
  pages        = {108262},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Novel hybrid discrete differential evolution algorithm for the multi-stage multi-purpose batch plant scheduling problem},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). IT2CFNN: An interval type-2 correlation-aware fuzzy neural
network to construct non-separable fuzzy rules with uncertain and
adaptive shapes for nonlinear function approximation. <em>ASOC</em>,
<em>115</em>, 108258. (<a
href="https://doi.org/10.1016/j.asoc.2021.108258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new interval type-2 fuzzy neural network able to construct non-separable fuzzy rules with various shapes is introduced for function approximation problems. To reflect the uncertainty, the shape of fuzzy sets is considered to be uncertain. Therefore, a new form of shapeable interval type-2 fuzzy sets based on a general Gaussian model able to construct different shapes (including triangular, bell-shaped, trapezoidal) is proposed. To consider the interactions among input variables, input vectors are transformed to new feature spaces with uncorrelated variables proper for defining each fuzzy rule. Next, the new features are fed to a fuzzification layer using proposed interval type-2 fuzzy sets with adaptive shapes. Consequently, interval type-2 non-separable fuzzy rules with proper shapes, considering the local interactions of variables and the uncertainty are formed. For type reduction, the contribution of the upper and lower firing strengths of each fuzzy rule is adaptively selected separately. To train different parameters of the network, the Levenberg–Marquardt optimization method is utilized. The performance of the proposed method is investigated on clean and noisy datasets to show the ability to consider the uncertainty. Moreover, the proposed paradigm is successfully applied to real-world time-series predictions, regression problems , and nonlinear system identification . According to the experimental results, the performance of our proposed model outperforms other methods with a more parsimonious structure. Based on several experiments, the test RMSE of the proposed method is equal to 0.0243 for noisy McGlass time series prediction , 1.92 for Santa-Fe Laser prediction , 0.0301 for Box–Jenkins system identification , 0.0569 for Poland electricity load forecasting , 4.22 for Google stock price tracking , and 13.22 for Sydney stock price tracking .},
  archive      = {J_ASOC},
  author       = {Armin Salimi-Badr},
  doi          = {10.1016/j.asoc.2021.108258},
  journal      = {Applied Soft Computing},
  pages        = {108258},
  shortjournal = {Appl. Soft. Comput.},
  title        = {IT2CFNN: An interval type-2 correlation-aware fuzzy neural network to construct non-separable fuzzy rules with uncertain and adaptive shapes for nonlinear function approximation},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Adaptive sliding mode control with hysteresis
compensation-based neuroevolution for motion tracking of piezoelectric
actuator. <em>ASOC</em>, <em>115</em>, 108257. (<a
href="https://doi.org/10.1016/j.asoc.2021.108257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an adaptive sliding mode control with hysteresis compensation-based neuroevolution (ACNE) is proposed for precise motion tracking of the piezoelectric actuator (PEA) in the presence of uncertainties, disturbances, and nonlinearity hysteresis characteristics. Firstly, a new memetic differential evolution (MeDE) algorithm is proposed to optimize the weights of a 3-layer n eural network (called n euro e volution or NE ). In MeDE, a differential evolution algorithm is used as a global search scheme and the Jaya algorithm is used as local search exploitation. Secondly, an inverse hysteresis model of PEA is identified by the neuroevolution model to provide a feed-forward NE control signal to compensate for the hysteresis behavior of PEA system. Thirdly, an adaptive neural sliding mode control plus feedforward NE (ACNE) control is designed to enhance the quality control and guarantee asymptotical stability for PEA system. Based on the Lyapunov method , the stability of the closed-loop system is analyzed and proved. Finally, the experimental Thorlabs piezoelectric actuator (PEA) is set up to verify the robustness and effectiveness of the proposed approach. Results show that the identified MeDE-Neuroevolution model has successfully applied to model the inverse hysteretic of PEA system and the performance of MeDE has better than Jaya, DE, and PSO in terms of best, worst, average, and standard deviation. Furthermore, in motion tracking control , the performance of proposed ACNE control has more accurate than a classical PID control, a feedforward control , a hybrid feedback–feedforward control, and an adaptive neural sliding mode control without a compensator.},
  archive      = {J_ASOC},
  author       = {Nguyen Ngoc Son and Cao Van Kien and Ho Pham Huy Anh},
  doi          = {10.1016/j.asoc.2021.108257},
  journal      = {Applied Soft Computing},
  pages        = {108257},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Adaptive sliding mode control with hysteresis compensation-based neuroevolution for motion tracking of piezoelectric actuator},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-COVID-net: Multi-objective optimized network for
COVID-19 diagnosis from chest x-ray images. <em>ASOC</em>, <em>115</em>,
108250. (<a href="https://doi.org/10.1016/j.asoc.2021.108250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coronavirus Disease 2019 (COVID-19) had already spread worldwide, and healthcare services have become limited in many countries. Efficient screening of hospitalized individuals is vital in the struggle toward COVID-19 through chest radiography, which is one of the important assessment strategies. This allows researchers to understand medical information in terms of chest X-ray (CXR) images and evaluate relevant irregularities, which may result in a fully automated identification of the disease. Due to the rapid growth of cases every day, a relatively small number of COVID-19 testing kits are readily accessible in health care facilities . Thus it is imperative to define a fully automated detection method as an instant alternate treatment possibility to limit the occurrence of COVID-19 among individuals. In this paper, a two-step Deep learning (DL) architecture has been proposed for COVID-19 diagnosis using CXR. The proposed DL architecture consists of two stages, “feature extraction and classification”. The “Multi-Objective Grasshopper Optimization Algorithm (MOGOA)” is presented to optimize the DL network layers; hence, these networks have named as “Multi-COVID-Net”. This model classifies the Non-COVID-19, COVID-19, and pneumonia patient images automatically. The Multi-COVID-Net has been tested by utilizing the publicly available datasets, and this model provides the best performance results than other state-of-the-art methods.},
  archive      = {J_ASOC},
  author       = {Tripti Goel and R. Murugan and Seyedali Mirjalili and Deba Kumar Chakrabartty},
  doi          = {10.1016/j.asoc.2021.108250},
  journal      = {Applied Soft Computing},
  pages        = {108250},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-COVID-net: Multi-objective optimized network for COVID-19 diagnosis from chest X-ray images},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Application of integrated factor evaluation–analytic
hierarchy process–t-s fuzzy fault tree analysis in reliability
allocation of industrial robot systems. <em>ASOC</em>, <em>115</em>,
108248. (<a href="https://doi.org/10.1016/j.asoc.2021.108248">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the defects (only two kinds of state, i.e., normal or fault) of existed reliability allocation methods without considering the intermediate degradation process , a methodology named integrated factor evaluation–analytic hierarchy process–T-S fuzzy fault tree analysis (IFE-AHP-T-S fuzzy FTA) is proposed to allocate the reliability index of industrial robot systems (IRSs) which have multiple fault states. Firstly, the reliability model of IRSs is established and the allocation principle of reliability index is discussed. Secondly, two-layer IFE model is established considering the degradation of mechanical structure and multi-state fault of IRSs to evaluate the technical merit of different subsystems. The hesitant fuzzy language set is adopted to reduce the subjectivity of expert evaluation process, which have the ability of dealing with uncertain information. Then, the AHP is proposed to allocate different weights for influence factors, and the T-S fuzzy FTA is presented to calculate fault probability and mean time between failures (MTBF) in the process of weight allocation of reliability index for IRSs and six subsystems. Finally, multi-state reliability index allocation of IRSs is completed. This investigation has a significance for reducing the fault probability and unsafe factors, and provides a theoretical basis for the whole life cycle design of IRSs.},
  archive      = {J_ASOC},
  author       = {Bin Bai and Chuxiong Xie and Xiangdong Liu and Wei Li and Weiyu Zhong},
  doi          = {10.1016/j.asoc.2021.108248},
  journal      = {Applied Soft Computing},
  pages        = {108248},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Application of integrated factor evaluation–analytic hierarchy process–T-S fuzzy fault tree analysis in reliability allocation of industrial robot systems},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-modal feature fusion for 3D object detection in the
production workshop. <em>ASOC</em>, <em>115</em>, 108245. (<a
href="https://doi.org/10.1016/j.asoc.2021.108245">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D object detection technology is of great significance to realize intelligent perception and ensure the production safety of a workshop. Existing 3D object detection relies on large-scale, high-quality 3D annotation data and is unsuitable for actual workshop scenes’ perception. This paper proposes a multi-modal feature fusion 3D object detection method (MFF3D) for a production workshop. The design of MFF3D includes the following steps: (1) Improved YOLOv3 attains the 2D prior region of an object, and RGB-D saliency detection obtains the object image pixels in that region. (2) Depth image pixels corresponding to the object are projected to generate the object’s frustum point cloud, and a multi-modal feature fusion strategy simplifies the object’s frustum point cloud, so as to remove outlier points and reduce the number of point clouds. This can replace the 3D object reasoning process based on deep neural networks ; (3) An axis-aligned bounding box algorithm is used to generate the object’s 3D bounding box , and principal component analysis algorithm (PCA) is used to calculate the object’s pose information. MFF3D is applied in the workshop, and experiments verify the feasibility and detection accuracy. We set up a production workshop object dataset (PWOD) for experimental evaluation. In the case of a small amount of 2D annotation data and no 3D annotation data, experimental results show that when the threshold value of intersection over union of 3D object (IoU 3D 3D ) is 0.5, the mean average precision value of 3D object (mAP 3D 3D ) reaches 60.31, and the detection speed reaches 3 FPS. MFF3D does not rely on 3D annotation data and can effectively detect objects of a production workshop.},
  archive      = {J_ASOC},
  author       = {Rui Hou and Guangzhu Chen and Yinhe Han and Zaizuo Tang and Qingjun Ru},
  doi          = {10.1016/j.asoc.2021.108245},
  journal      = {Applied Soft Computing},
  pages        = {108245},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-modal feature fusion for 3D object detection in the production workshop},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An efficiency-based interval type-2 fuzzy multi-criteria
group decision making for makeshift hospital selection. <em>ASOC</em>,
<em>115</em>, 108243. (<a
href="https://doi.org/10.1016/j.asoc.2021.108243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since makeshift hospitals have strong ability in blocking the spread of the virus, how to design some methods to select the reasonable sites of makeshift hospitals is vitally important for containing COVID-19. This paper investigates an efficiency-based multi-criteria group decision making (MCGDM) method by combining the best-worst method (BWM) and data envelopment analysis (DEA) in trapezoidal interval type-2 fuzzy (TrIT2F) environment. This MCGDM method is called TrIT2F-BWM-DEA , where the TrIT2F-BWM is used to determine the weights of criteria and decision-makers, and the TrIT2F-DEA is employed to rank alternatives by measuring their overall efficiencies. Based on cut set theory, the expectation and average expectation (AE) of TrIT2FSs are successively defined. To solve three key issues in the development of the TrIT2F-BWM , this paper proposes a flexible ranking relation of TrIT2FSs to transform the TrIT2F constraints, initiates an efficient theorem to normalize the TrIT2F weights, and designs an input-based consistency ratio to check the reliability of the determined weights. A fully TrIT2F-DEA model is originally built to measure the TrIT2F efficiencies of alternatives. The alternatives are finally ranked according to the AEs of alternatives’ TrIT2F efficiencies. A site selection case of Fangcang hospitals and some comparative analyses are provided to confirm the validity and merits of the proposed TrIT2F-BWM-DEA .},
  archive      = {J_ASOC},
  author       = {Ze-hui Chen and Shu-ping Wan and Jiu-ying Dong},
  doi          = {10.1016/j.asoc.2021.108243},
  journal      = {Applied Soft Computing},
  pages        = {108243},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An efficiency-based interval type-2 fuzzy multi-criteria group decision making for makeshift hospital selection},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimization of flight test tasks allocation and sequencing
using genetic algorithm. <em>ASOC</em>, <em>115</em>, 108241. (<a
href="https://doi.org/10.1016/j.asoc.2021.108241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flight test tasks arrangement is one of the most significant problems in the development of new civil aircraft. Normally, there are many factors restraining flight test tasks arrangement, including characteristics of experimental aircraft, requirements of tasks themselves, and logical relationships among them, leading to increased development period and costs. Hence, flight test tasks arrangement is generally viewed as a multi-constraint nonlinear optimization problem. To improve flight test efficiency, a multi-level optimization model of flight test tasks allocation and sequencing is introduced in this paper, where flight test period is the main optimization objective , and a penalty function evaluating tasks testing dates is the minor optimization objective . A flight test tasks sequence oriented improved genetic algorithm (FTTSOIGA) is proposed to solve the model. Firstly, a tasks allocation algorithm is designed to establish the mapping between tasks sequence and tasks arrangement result, which is independent of feasible sequence. Then, the arrangement result is optimized by optimizing the tasks sequence using the genetic algorithm . Furthermore, a tasks sequence adjustment strategy is applied to accelerate algorithm convergence. Simulation cases of 3 experimental aircraft and 80 flight test tasks demonstrate the efficiency of FTTSOIGA.},
  archive      = {J_ASOC},
  author       = {Shuangfei Xu and Wenhao Bi and An Zhang and Zeming Mao},
  doi          = {10.1016/j.asoc.2021.108241},
  journal      = {Applied Soft Computing},
  pages        = {108241},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Optimization of flight test tasks allocation and sequencing using genetic algorithm},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Soft measurement of effluent index in sewage treatment
process based on overcomplete broad learning system. <em>ASOC</em>,
<em>115</em>, 108235. (<a
href="https://doi.org/10.1016/j.asoc.2021.108235">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To measure whether the sewage treatment meets the standards, biochemical oxygen demand (BOD5) is often used to determine, but the measurement of this indicator often has a long time lag and difficult to observe the real-time changes of BOD5, which brings inconvenience to the industrial process. The soft measurement technology based on neural network can realize BOD5 prediction at every moment by means of auxiliary variables, which has attracted people’s attention. However, there are still two problems with soft measurement technology, neural network-based soft measurement technology has high computational complexity and a certain time delay in measurement; and it cannot handle non-Gaussian data well. To solve them, this paper introduces an over-complete broad learning system (OBLS) based on feature fusion to deal with the problems of real-time measurement of BOD5 in sewage treatment industrial process. In view of the data characteristics, the feature extraction ability of the BLS is improved, the non-Gaussian characteristic of sewage data is captured by the method of Overcomplete Independent Component Analysis (OICA), and the OBLS is used to deal with the real-time soft measurement. Compared with state-of-the-art methods on the sewage standard test platform, the measurement accuracy of the proposed algorithm is found to be higher and the performance is more stable.},
  archive      = {J_ASOC},
  author       = {Peng Chang and LuLu Zhao and FanChao Meng and Ying Xu},
  doi          = {10.1016/j.asoc.2021.108235},
  journal      = {Applied Soft Computing},
  pages        = {108235},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Soft measurement of effluent index in sewage treatment process based on overcomplete broad learning system},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intuitionistic fuzzy twin support vector machines with the
insensitive pinball loss. <em>ASOC</em>, <em>115</em>, 108231. (<a
href="https://doi.org/10.1016/j.asoc.2021.108231">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the use of membership and nonmembership functions of samples from intuitionistic fuzzy sets(IFSs), intuitionistic fuzzy twin support vector machines (IFTSVMs) can effectively suppress noise in the data. However, the objective function of IFTSVMs partially considers score values of samples and employs the hinge loss function which leads to the sensitivity to feature noise and instability to re-sampling. To enhance the performance of IFTSVMs, we propose novel IFTSVMs with the insensitive pinball loss function. In the proposed convex optimization models, a simple strategy is devised to achieve the score value of each training sample and score values of samples in both classes are defined by using IFSs. Unlike previous methods, we introduce two groups of slack variables to derive the dual formulations of convex models which make them have compact representations . Some properties of the proposed models including geometric properties and noise insensitivity are theoretically analyzed. We also explain the proposed models in terms of the idea of the weighted scatter minimization, which provides theoretical foundations for the proposed models. Experiments on a series of data sets are performed and experimental results demonstrate that the proposed convex models are superior to some existing learning models in the presence of feature noise or label noise.},
  archive      = {J_ASOC},
  author       = {Zhizheng Liang and Lei Zhang},
  doi          = {10.1016/j.asoc.2021.108231},
  journal      = {Applied Soft Computing},
  pages        = {108231},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Intuitionistic fuzzy twin support vector machines with the insensitive pinball loss},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Vortex-u-net: An efficient and effective vortex detection
approach based on u-net structure. <em>ASOC</em>, <em>115</em>, 108229.
(<a href="https://doi.org/10.1016/j.asoc.2021.108229">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vortex detection methods help researchers to better understand the potential flow mechanism, and can be divided into three groups. Global methods have higher accuracy at the expense of time performance, while local methods provide results rapidly with poor accuracy. Machine learning-based methods consider both computational speed and accuracy, but their generalization and scalability are poor, which prevents them from being applied to real scenes. To address the above issues, we propose a novel vortex detection method, termed Vortex-U-Net. Our method has three characteristics. Firstly, our approach combines the characteristics of both global and local vortex detection methods. Secondly, it adopts the vorticity field, which integrates the velocity field and coordinates of grid points as the input. In this manner, it can keep more physical grid information of flow fields, which further improves the accuracy and generalization. Thirdly, our method fusions the properties of flow fields into the design of the loss function of the network. The proposed Vortex-U-Net model is subsequently evaluated against several widely used vortex detection methods on both numerically-simulated and analytical flows. Results reveal that our approach can achieve both high accuracy and performance.},
  archive      = {J_ASOC},
  author       = {Liang Deng and Wenchun Bao and Yueqing Wang and Zhigong Yang and Dan Zhao and Fang Wang and Chongke Bi and Yang Guo},
  doi          = {10.1016/j.asoc.2021.108229},
  journal      = {Applied Soft Computing},
  pages        = {108229},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Vortex-U-net: An efficient and effective vortex detection approach based on U-net structure},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unsupervised multi-modal modeling of fashion styles with
visual attributes. <em>ASOC</em>, <em>115</em>, 108214. (<a
href="https://doi.org/10.1016/j.asoc.2021.108214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fashion compatibility learning is of great practical significance to satisfy the needs of consumers and promote the development of the apparel industry. As a core task of it, fashion style modeling has received extensive attention. In this work, we apply a polylingual model, the PolyLDA , to discover the fashion style. To establish visual documents for fashion images, a pre-trained convolutional neural network , ResNet-50, which is trained on ImageNet, is employed in the model. The kernels in different layer of the network can encode different level of visual attributes (such as color, texture, pattern and etc.). Specifically, we can use a visual word (e.g., red, wavy, floral design and etc.) to express a particular kernel in a given layer. Therefore, to construct the visual document for a fashion image, all the kernels are directly treated as visual words and their activation is regarded as the appearance of the corresponding visual attribute. By minimizing the variance of style distribution on the training set given by PolyLDA , we train the weights of the visual attributes of each layer, and assign them to the visual attributes of different layers, so that the model can get better modeling ability than the comparative models. Our proposed method is completely unsupervised and cost saving. The experimental results show that the model can not only produce almost the same result as manual discrimination, but also achieve high satisfaction for similar style retrieval.},
  archive      = {J_ASOC},
  author       = {Dunlu Peng and Rui Liu and Jing Lu and Shuming Zhang},
  doi          = {10.1016/j.asoc.2021.108214},
  journal      = {Applied Soft Computing},
  pages        = {108214},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Unsupervised multi-modal modeling of fashion styles with visual attributes},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Novel leakage detection by ensemble 1DCNN-VAPSO-SVM in oil
and gas pipeline systems. <em>ASOC</em>, <em>115</em>, 108212. (<a
href="https://doi.org/10.1016/j.asoc.2021.108212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel ensemble model of one-dimensional convolution neural network (1DCNN) and support vector machine (SVM) is proposed to improve the detection accuracy in the process of pipeline leakage detection. Firstly, 1DCNN is constructed by experiments on different network structures and parameters, and it is used to extract data features adaptively. Then, an improved particle swarm optimization (PSO) algorithm is put forward, called variable amplitude PSO (VAPSO), with the adjustment strategy of parameter variable amplitude vibration to optimize the parameter combination in SVM and decrease the risk of trapping into local optimum in the training process. Finally, the data features extracted adaptively from the network are input into the improved VAPSO-SVM to classify. It is demonstrated by the experimental results that, compared with the existing models, the developed ensemble model has the capacity to extract the features of pipeline data more quickly and accurately with effective improvement in the classification accuracy , and has better robustness in the process of pipeline leakage detection.},
  archive      = {J_ASOC},
  author       = {Dandi Yang and Nan Hou and Jingyi Lu and Daan Ji},
  doi          = {10.1016/j.asoc.2021.108212},
  journal      = {Applied Soft Computing},
  pages        = {108212},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Novel leakage detection by ensemble 1DCNN-VAPSO-SVM in oil and gas pipeline systems},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Classification of cervical cells leveraging simultaneous
super-resolution and ordinal regression. <em>ASOC</em>, <em>115</em>,
108208. (<a href="https://doi.org/10.1016/j.asoc.2021.108208">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic classification of cervical cells plays a critical role in the Computer-assisted Cytology Test (CCT) system. The efficiency of the CCT system can be promoted by sacrificing the microscopic image resolution to speed up the microscopic image acquisition. In this case, the low resolution of the cell image will severely deteriorate the performance of available Convolutional Neural Networks (CNN) based classification methods. Inspired by the positive effect of super-resolution in addressing classification or recognition tasks, we propose a cervical cell classification algorithm leveraging simultaneous super-resolution, which is achieved using Generative Adversarial Network (GAN) techniques. Our framework is designed in an end-to-end manner wherein the classification loss is back-propagated into the super-resolution network during training. Moreover, we perform ordinal regression with smooth L1 loss to further improve the classification results . Extensive experiments have verified the effectiveness of our method. Our simultaneous super-resolution based method achieves 93.5\% classification accuracy on the 6-class Heer dataset, outperforming the method using only the state-of-the-art classifier by an obvious margin of 3.2\%. Besides, our ordinal regression method significantly improves the MAE (Mean Absolute Error) by 0.0143 and 1-off accuracy by 0.95\% on the 4-class Heer dataset. For the Herlev dataset, our method yields the classification accuracy of 98.1\% and 97.6\% for the 2-class and 7-class problems, which is still competitive even with low-resolution input.},
  archive      = {J_ASOC},
  author       = {Zhipeng Lin and Zhi Gao and Hong Ji and Ruifang Zhai and Xiaoqing Shen and Tiancan Mei},
  doi          = {10.1016/j.asoc.2021.108208},
  journal      = {Applied Soft Computing},
  pages        = {108208},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Classification of cervical cells leveraging simultaneous super-resolution and ordinal regression},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unsupervised feature learning with reconstruction sparse
filtering for intelligent fault diagnosis of rotating machinery.
<em>ASOC</em>, <em>115</em>, 108207. (<a
href="https://doi.org/10.1016/j.asoc.2021.108207">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse filtering (SF), as a recently emerging unsupervised feature learning method, has drawn much attention in intelligent fault diagnosis of rotating machinery . Generally, SF implements feature extraction by the trained basis vectors. However, similar features may be extracted by SF due to the lack of effective restrictions on the basis vectors during training, which leads to an adverse effect on the diagnostic performance. To address this drawback, reconstruction sparse filtering (RSF) is proposed based on SF, which explicitly constrains the basis vectors via a soft-reconstruction penalty (SRP). In particular, SRP enables RSF to learn a group of independent basis vectors so as to extract dissimilar and diverse features. These features contain comprehensive and rich fault information that can precisely describe the rotating machinery health conditions, so RSF can perform significantly better. Based on RSF, an intelligent diagnosis method is developed, and it is evaluated through experiments on a gear and two bearing datasets. The results testify that RSF is able to extract dissimilar features from the vibration signals , and it has better feature learning ability than SF and nine other popular unsupervised feature learning methods. Moreover, the superiority of the developed diagnosis method is verified by comparing with several state-of-the-art intelligent diagnosis methods on two famous bearing datasets.},
  archive      = {J_ASOC},
  author       = {Zhiqiang Zhang and Qingyu Yang},
  doi          = {10.1016/j.asoc.2021.108207},
  journal      = {Applied Soft Computing},
  pages        = {108207},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Unsupervised feature learning with reconstruction sparse filtering for intelligent fault diagnosis of rotating machinery},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A dissimilarity-based approach to automatic classification
of biosignal modalities. <em>ASOC</em>, <em>115</em>, 108203. (<a
href="https://doi.org/10.1016/j.asoc.2021.108203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last years, pervasive wearable technology has spread to people’s daily lives, unobtrusively acquiring large amounts of data. Such devices contain biomedical sensors , prone to contribute for the improvement of the user’s quality of life through artificial intelligence algorithms (e.g. health monitoring and emotion recognition). Physiological signals are the basis of such applications, and critical problems are data (un)labeling and incorrect metadata about the source. We propose a framework for the automatic identification of the type of physiological data source, namely Respiration, Electrocardiography , Electrodermal Activity, and Blood Volume Pulse data through the application of Supervised Learning on different representation spaces (feature-based and dissimilarity-based), in both an Online and Offline setting. We build our model through a comprehensive study of (1) Supervised Learning classifiers; (2) Similarity metrics; (3) Data representation; and lastly, (4) Sample aggregation techniques for the creation of the prototypes that will translate the data into the dissimilarity-based space. We explore the aforementioned techniques on two unexplored databases. The experimental results led to accuracies superior to 92\% for the online setting, and 96\% for the offline setting, attaining competitive results with the current state of the art. Our work paves the way to the development of systems capable of automatically identifying sensor types and subsequently applying the most appropriate data processing, analysis and classification workflows.},
  archive      = {J_ASOC},
  author       = {Patrícia Bota and Ana Fred and João Valente and Chen Wang and Hugo Plácido da Silva},
  doi          = {10.1016/j.asoc.2021.108203},
  journal      = {Applied Soft Computing},
  pages        = {108203},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A dissimilarity-based approach to automatic classification of biosignal modalities},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reconfiguration of distribution networks using rain-fall
optimization with non-dominated sorting. <em>ASOC</em>, <em>115</em>,
108200. (<a href="https://doi.org/10.1016/j.asoc.2021.108200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sharp escalating power demand and configuration changes in distribution networks (DNs) may operate the networks more closely to voltage stability boundaries. Under critical operating conditions, the DN is not able to provide good voltage profile and may experience voltage collapse. The performances of the DN can be improved by optimally reconfiguring the network. This paper models the reconfiguration of DN as an optimization problem with objectives of lowering active power loss, improving the voltage profile and enhancing the voltage stability; and suggests a new reconfiguration method involving rain-fall optimization and non-dominated sorting to obtain the best compromised solution for DNs. It presents simulation results of standard 33-, 69- and 95-node DNs, and exhibits that the method was able to lower the active power loss from 201.97 kW to 139.5525 kW, from 225 kW to 98.6082 kW and from 89.6733 kW to 30.5700 kW for 33, 69 and 95 node DN systems respectively. In a similar way, it portrays that the method was able to produce better results in enhancing the voltage profile and voltage stability.},
  archive      = {J_ASOC},
  author       = {Sakthidasan Arulprakasam and Senthilkumar Muthusamy},
  doi          = {10.1016/j.asoc.2021.108200},
  journal      = {Applied Soft Computing},
  pages        = {108200},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Reconfiguration of distribution networks using rain-fall optimization with non-dominated sorting},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A class-specific metric learning approach for graph
embedding by information granulation. <em>ASOC</em>, <em>115</em>,
108199. (<a href="https://doi.org/10.1016/j.asoc.2021.108199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs have gained a lot of attention in the pattern recognition community thanks to their ability to encode both topological and semantic information . Despite their invaluable descriptive power, their arbitrarily complex structured nature poses serious challenges when they are involved in learning systems. Typical approaches aim at building a vectorial representation of the graph in a suitable embedding space by leveraging on the selection of relevant prototypes that enable the use of common pattern recognition methods. An emerging paradigm able to synthesize prototypes in a data-driven fashion can be found in Granular Computing . Nonetheless, these methods often require a core dissimilarity measure defined directly in the graph domain that usually relies on a set of suitable parameters which are heavily problem-dependent. The automatic selection of these parameters is of utmost importance for building embedding spaces able to preserve the semantic contents between the structured and vector domains. In this paper, we propose an evolutionary-based approach for learning multiple dissimilarity measures tailored on each of the problem-related classes for the classification problem at hand. The learnt class-specific metrics contribute in synthesizing prototypes with high informative content related to each class by means of a Granular Computing approach. Such prototypes induce an embedding space where the graph classification can take place with common pattern recognition techniques for vector data. Tests conducted on publicly available datasets corroborate the effectiveness of the proposed approach both in terms of learning performances and interpretability of the model, as measured by the classification accuracy and number of meaningful prototypes considered in the synthesized model.},
  archive      = {J_ASOC},
  author       = {Luca Baldini and Alessio Martino and Antonello Rizzi},
  doi          = {10.1016/j.asoc.2021.108199},
  journal      = {Applied Soft Computing},
  pages        = {108199},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A class-specific metric learning approach for graph embedding by information granulation},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive neighborhood size and effective geometric features
selection for 3D scattered point cloud classification. <em>ASOC</em>,
<em>115</em>, 108196. (<a
href="https://doi.org/10.1016/j.asoc.2021.108196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification of 3D scatter and unorganized point cloud (PC) is an ongoing hard problem due to high redundancy, unbalanced sampling density, and large data structure of PC. Geometric and spectral features derived from the PC are generally used for classification. In this paper, an Omnivariance based adaptive neighborhood size selection method and a new feature set composed of 14 features are proposed for extraction of geometric features for each individual point within the local neighborhood. Performance of 8 modern classifiers with different strategies (i.e., boosting, ensemble, and deep learning etc.) were evaluated on the Oakland, Vaihingen, and ISPRS datasets. These 3 datasets are identified by 5, 9, and 2 distinct object classes, respectively. The results were compared with different neighborhood size selection methods (i.e., eigenentropy based, fixed number of the k-nearest neighbors) and feature set (i.e., 21 features). Only 3D local features were employed to classify datasets with varying characteristics and properties. The proposed optimum neighbor selection method and feature set provided the best statistical results with Auto-Encoder classifier (the overall accuracies are over 85\%, 60\% and, 90\% the Oakland, Vaihingen, and ISPRS datasets, respectively). Especially for the ISPRS dataset, the Auto-Encoder obtained over 94\%, 90\%, and 93\% precision, recall, and f-score, respectively.},
  archive      = {J_ASOC},
  author       = {Mehmet Akif Günen},
  doi          = {10.1016/j.asoc.2021.108196},
  journal      = {Applied Soft Computing},
  pages        = {108196},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Adaptive neighborhood size and effective geometric features selection for 3D scattered point cloud classification},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Autonomous navigation of UAV in multi-obstacle environments
based on a deep reinforcement learning approach. <em>ASOC</em>,
<em>115</em>, 108194. (<a
href="https://doi.org/10.1016/j.asoc.2021.108194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path planning is one of the most essential part in autonomous navigation . Most existing works suppose that the environment is static and fixed. However, path planning is widely used in random and dynamic environment (such as search and rescue, surveillance and other scenarios). In this paper, we propose a Deep Reinforcement Learning (DRL)-based method that enables unmanned aerial vehicles (UAVs) to execute navigation tasks in multi-obstacle environments with randomness and dynamics. The method is based on the Twin Delayed Deep Deterministic Policy Gradients (TD3) algorithm. In order to predict the impact of the environment on UAV, the change of environment observations is added into the Actor–Critic network input, and the two-stream Actor–Critic network structure is proposed to extract features of environment observations. Simulations are carried out to evaluate the performance of the algorithm and experiment results show that our method can enable the UAV to complete autonomous navigation tasks safely in multi-obstacle environments, which reflects the efficiency of our method. Moreover, compared to DDPG and the conventional TD3, our method has better generalization ability .},
  archive      = {J_ASOC},
  author       = {Sitong Zhang and Yibing Li and Qianhui Dong},
  doi          = {10.1016/j.asoc.2021.108194},
  journal      = {Applied Soft Computing},
  pages        = {108194},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Autonomous navigation of UAV in multi-obstacle environments based on a deep reinforcement learning approach},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fully automatic deep convolutional approaches for the
analysis of COVID-19 using chest x-ray images. <em>ASOC</em>,
<em>115</em>, 108190. (<a
href="https://doi.org/10.1016/j.asoc.2021.108190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Covid-19 is a new infectious disease caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). Given the seriousness of the situation, the World Health Organization declared a global pandemic as the Covid-19 rapidly around the world. Among its applications, chest X-ray images are frequently used for an early diagnostic/screening of Covid-19 disease, given the frequent pulmonary impact in the patients, critical issue to prevent further complications caused by this highly infectious disease. In this work, we propose 4 fully automatic approaches for the classification of chest X-ray images under the analysis of 3 different categories: Covid-19, pneumonia and healthy cases. Given the similarity between the pathological impact in the lungs between Covid-19 and pneumonia, mainly during the initial stages of both lung diseases, we performed an exhaustive study of differentiation considering different pathological scenarios. To address these classification tasks , we evaluated 6 representative state-of-the-art deep network architectures on 3 different public datasets: (I) Chest X-ray dataset of the Radiological Society of North America (RSNA); (II) Covid-19 Image Data Collection; (III) SIRM dataset of the Italian Society of Medical Radiology. To validate the designed approaches, several representative experiments were performed using 6, 070 chest X-ray radiographs. In general, satisfactory results were obtained from the designed approaches, reaching a global accuracy values of 0.9706 ± ± 0.0044, 0.9839 ± ± 0.0102, 0.9744 ± ± 0.0104 and 0.9744 ± ± 0.0104, respectively, thus helping the work of clinicians in the diagnosis and consequently in the early treatment of this relevant pandemic pathology.},
  archive      = {J_ASOC},
  author       = {Joaquim de Moura and Jorge Novo and Marcos Ortega},
  doi          = {10.1016/j.asoc.2021.108190},
  journal      = {Applied Soft Computing},
  pages        = {108190},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fully automatic deep convolutional approaches for the analysis of COVID-19 using chest X-ray images},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DeepPlacer: A custom integrated OpAmp placement tool using
deep models. <em>ASOC</em>, <em>115</em>, 108188. (<a
href="https://doi.org/10.1016/j.asoc.2021.108188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mechanisms towards the automatic analog integrated circuit layout design have been an intensive research topic in the past few decades. Still, the industrial environment has no automatic approach established. The advances of machine learning applications in electronic design automation come with the promise to change this reality. This paper proposes a deep learning generative model for the placement “optimization” of analog integrated circuit basic blocks. The model behaves as an argmin operator for the placement cost function and can provide placement solutions instantly. Moreover, the model can be fed with unlabeled data , greatly facilitating data collection. A generic and innovative circuits’ representation at the network’s input layer is proposed, encoding the devices’ dimensions, connectivity, and topological constraints. Besides, the randomness found in generative models is embedded directly into the feature vector, as the order of the features per device is shuffled in the input vector. Shuffling the order of the devices’ features in the input not only brings multi-modality but also solves a generalization problem, as there is not any natural order defined to place devices in the feature vector. As a proof of concept , a deep artificial neural network capable of proposing different placement solutions, in less than 150 ms each, for six amplifier topologies and, in multiple technology nodes ranging from 350 nm down to 65 nm, is demonstrated. DeepPlacer was capable of producing correct solutions for topologies and technology nodes not present in the training set, showing good generalization while not hindering circuit performance due to the placement.},
  archive      = {J_ASOC},
  author       = {António Gusmão and Ricardo Póvoa and Nuno Horta and Nuno Lourenço and Ricardo Martins},
  doi          = {10.1016/j.asoc.2021.108188},
  journal      = {Applied Soft Computing},
  pages        = {108188},
  shortjournal = {Appl. Soft. Comput.},
  title        = {DeepPlacer: A custom integrated OpAmp placement tool using deep models},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Research on the construction of stock portfolios based on
multiobjective water cycle algorithm and KMV algorithm. <em>ASOC</em>,
<em>115</em>, 108186. (<a
href="https://doi.org/10.1016/j.asoc.2021.108186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The financial situation of listed companies has a great impact on the construction of stock portfolio. However, some traditional portfolio models only consider the fluctuation of stock price and ignore the impact of the financial situation of listed companies on the portfolio, which will affect the effectiveness of the portfolio. To fill the gap, a new portfolio model based on the KMV model and a multiobjective water cycle algorithm is proposed to further improve the framework of portfolio construction. Firstly, the KMV model is used to evaluate the financial situation of listed companies, and then the optimization algorithm directly uses both the results of KMV and the fluctuation of stock price to build a more reasonable portfolio. To evaluate the validity of the model, the data of 100 A-share listed companies collected from China were used in two experiments. The results of the experiments show that the model can determine the stock portfolio according to the internal financial information and stock history information of listed companies, which not only can improve the effect and stability of the investment portfolio, but also can play a guiding role in the performance evaluation of listed companies.},
  archive      = {J_ASOC},
  author       = {Jianzhou Wang and Haipeng Zhang and Hua Luo},
  doi          = {10.1016/j.asoc.2021.108186},
  journal      = {Applied Soft Computing},
  pages        = {108186},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Research on the construction of stock portfolios based on multiobjective water cycle algorithm and KMV algorithm},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Randomized neural networks for multilabel classification.
<em>ASOC</em>, <em>115</em>, 108184. (<a
href="https://doi.org/10.1016/j.asoc.2021.108184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multilabel classification is a supervised learning problem in which input instances belong to multiple output labels. In this paper, we propose noniterative randomization-based neural networks for multilabel classification. These multilabel neural networks are named as Multilabel Random Vector Functional Link Network (ML-RVFL), Multilabel Kernelized Random Vector Functional Link Network (ML-KRVFL), Multilabel Broad Learning System (ML-BLS), and Multilabel Fuzzy Broad Learning System (ML-FBLS). The output weights of these neural networks are computed using pseudoinverse . At the output layer, multilabel classification is performed by using an adaptive threshold function. The computation of output weights using pseudoinverse retains the faster computation power of these algorithms compared to iterative learning algorithms. The adaptive threshold function used in the proposed approach can consider the correlation among the output labels and the whole dataset for threshold computation. Five multilabel evaluation metrics evaluate the proposed multilabel neural networks on 12 benchmark datasets of various domains such as text, image, and genomics. The ML-KRVFL provides the overall best Friedman rankings on five evaluation metrics followed by ML-RVFL, ML-FBLS, and ML-BLS, respectively. Based on the experimentation results, the proposed ML-KRVFL, ML-RVFL, ML-FBLS, and ML-BLS perform better than other relevant multilabel approaches in the mentioned order.The proposed approaches are faster than other state-of-the-art iterative approaches and noniterative approaches in terms of running time.},
  archive      = {J_ASOC},
  author       = {Vikas Chauhan and Aruna Tiwari},
  doi          = {10.1016/j.asoc.2021.108184},
  journal      = {Applied Soft Computing},
  pages        = {108184},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Randomized neural networks for multilabel classification},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Auto-tune learning framework for prediction of flowability,
mechanical properties, and porosity of ultra-high-performance concrete
(UHPC). <em>ASOC</em>, <em>115</em>, 108182. (<a
href="https://doi.org/10.1016/j.asoc.2021.108182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning methods are promising to predict key properties of concrete and expedite design of advanced concrete, but the existing methods have limitations in accuracy and generalization performance , because limited dataset size and anomalous data are used to train predictive models . This study presents an auto-tune learning framework for predicting compressive strength , flexural strength, workability, and porosity of ultra-high-performance concrete (UHPC). The presented framework has three features: (1) Structured and unstructured data are combined. (2) Anomalies and inappropriate variables in the dataset are identified and removed using an unsupervised anomaly detection method based on isolation forest and combined mutual information and univariate linear regression. (3) The hyperparameters of machine learning models are optimized using tree-structured Parzen estimator with k-fold cross-validation. Auto-tune predictive models are developed by integrating the presented learning framework and Light Gradient Boosting Machine (LightGBM). The results showed that the developed method achieved high prediction accuracy. The auto-tune models are used to study the effects of mixture design variables on the properties. This research will greatly promote material development by reducing experiments.},
  archive      = {J_ASOC},
  author       = {Soroush Mahjoubi and Weina Meng and Yi Bao},
  doi          = {10.1016/j.asoc.2021.108182},
  journal      = {Applied Soft Computing},
  pages        = {108182},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Auto-tune learning framework for prediction of flowability, mechanical properties, and porosity of ultra-high-performance concrete (UHPC)},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Developing the structural analysis considering fuzzy
performance levels. <em>ASOC</em>, <em>115</em>, 108180. (<a
href="https://doi.org/10.1016/j.asoc.2021.108180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of performance-based engineering in the seismic design and performance evaluation of structures has gained a significant development over the past few decades. The sample performance levels in current building codes are categorized into two levels that represent incipient damage and incipient collapse. Therefore, the performance limits of buildings involve numerous uncertainties such as the lack of clarity in their definition and ambiguity in the individual judgments. The main objective of this paper is to properly address the uncertainties in the performance levels and loading conditions through the evaluation process. The limit state for each performance level is defined as fuzzy numbers to model the fuzziness inherent in their interpretation. Moreover, the fuzzy set theory is adopted to estimate the desired fuzzy structural responses, considering the uncertainty involved in loading conditions within the analysis process. In addition, a novel fuzzy decision-making approach, which includes a comparison of the developed fuzzy sets (i.e., fuzzy structural response and fuzzy performance levels), is proposed to ensure a comprehensive assessment of the building performance. Numerical examples are also given to establish the application of the proposed method. The results demonstrate that the new comparing approach can make a reliable judgment, particularly in questionable cases of decision-making that are in line with the embedded context.},
  archive      = {J_ASOC},
  author       = {Elaheh Ebrahimi and Gholamreza Abdollahzadeh and Ehsan Jahani},
  doi          = {10.1016/j.asoc.2021.108180},
  journal      = {Applied Soft Computing},
  pages        = {108180},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Developing the structural analysis considering fuzzy performance levels},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design of deep ensemble classifier with fuzzy decision
method for biomedical image classification. <em>ASOC</em>, <em>115</em>,
108178. (<a href="https://doi.org/10.1016/j.asoc.2021.108178">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on biomedical science has many components like biomedical engineering , biomedical signal processing, gene analysis, and biomedical image processing . Classification, detection, and recognition have a great value for disease diagnosis and analysis. In this work, biomedical image classification is discussed. In one part, the brain tumor is considered with brain magnetic resonance images and in the other part, COVID affected chest X-rays have been classified using the ensemble approach. The images have been collected from Kaggle online platform. For this purpose, four heterogeneous base classifiers as Convolutional Neural Network , Recurrent Neural Network , Long Short Term Memory , and Gated Recurrent Unit are considered, and metadata is generated. Further, for the detection purpose, a fuzzy min–max model is utilized to avoid uncertainty. The ensemble output from the base classifiers is fed to the fuzzy model in terms of class probability and labels. The min–max algorithm for correct decisions is used in the fuzzy model. The measuring parameters like precision, recall, accuracy, sensitivity, specificity, and F1-score are evaluated. 100\% training accuracy for both the datasets is obtained whereas 97.62\% and 95.24\% of validation accuracy are found for brain image and chest X-ray image classification respectively as exhibited in the result section.},
  archive      = {J_ASOC},
  author       = {Abhishek Das and Saumendra Kumar Mohapatra and Mihir Narayan Mohanty},
  doi          = {10.1016/j.asoc.2021.108178},
  journal      = {Applied Soft Computing},
  pages        = {108178},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Design of deep ensemble classifier with fuzzy decision method for biomedical image classification},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Brain–computer interface channel selection optimization
using meta-heuristics and evolutionary algorithms. <em>ASOC</em>,
<em>115</em>, 108176. (<a
href="https://doi.org/10.1016/j.asoc.2021.108176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many brain–computer interface (BCI) studies overlook the channel optimization due to its inherent complexity. However, a careful channel selection increases the performance and users’ comfort while reducing the cost of the system. Evolutionary meta-heuristics, which have demonstrated their usefulness in solving complex problems, have not been fully exploited yet in this context. The purpose of the study is two-fold: (1) to propose a novel algorithm to find an optimal channel set for each user and compare it with other existing meta-heuristics; and (2) to establish guidelines for adapting these optimization strategies to this framework. A total of 3 single-objective (GA, BDE, BPSO) and 4 multi-objective (NSGA-II, BMOPSO , SPEA2 , PEAIL) existing algorithms have been adapted and tested with 3 public databases: ‘BCI competition III-dataset II’, ‘Center Speller’ and ‘RSVP Speller’. Dual-Front Sorting Algorithm (DFGA), a novel multi-objective discrete method especially designed to the BCI framework, is proposed as well. Results showed that all meta-heuristics outperformed the full set and the common 8-channel set for P300-based BCIs. DFGA showed a significant improvement of accuracy of 3.9\% over the latter using also 8 channels; and obtained similar accuracies using a mean of 4.66 channels. A topographic analysis also reinforced the need to customize a channel set for each user. Thus, the proposed method computes an optimal set of solutions with different number of channels, allowing the user to select the most appropriate distribution for the next BCI sessions.},
  archive      = {J_ASOC},
  author       = {Víctor Martínez-Cagigal and Eduardo Santamaría-Vázquez and Roberto Hornero},
  doi          = {10.1016/j.asoc.2021.108176},
  journal      = {Applied Soft Computing},
  pages        = {108176},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Brain–computer interface channel selection optimization using meta-heuristics and evolutionary algorithms},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evolved extended kalman filter for first-order dynamical
systems with unknown measurements noise covariance. <em>ASOC</em>,
<em>115</em>, 108174. (<a
href="https://doi.org/10.1016/j.asoc.2021.108174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present work focuses on an open problem in the design of Extended Kalman filters : the lack of knowledge of the measurement noise covariance. A novel extension of the analytic behaviors framework, which integrates a theoretical formulation and evolutionary computing, has been introduced as a design methodology for the construction of this unknown parameter. The proposed methodology is developed and applied for the design of Evolved Extended Kalman Filters for nonlinear first-order dynamical systems . The proposed methodology applies an offline evolutionary synthesis of analytic nonlinear functions , to be used as measurement noise covariance, aiming to minimize the Kalman criterion. The virtues of the methodology are exemplified through a complex, highly nonlinear, first-order dynamical system, for which 2649 optimized replacements of the measurement noise covariance are found. Under different scenarios, the performance of the Evolved Extended Kalman Filter with unknown measurement noise covariance is compared with that of the conventional Extended Kalman Filter where the measurement noise covariance is known. The robustness of the Evolved Extended Kalman Filter is demonstrated through numerical evaluation .},
  archive      = {J_ASOC},
  author       = {Leonardo Herrera and M.C. Rodríguez-Liñán and Eddie Clemente and Marlen Meza-Sánchez and Luis Monay-Arredondo},
  doi          = {10.1016/j.asoc.2021.108174},
  journal      = {Applied Soft Computing},
  pages        = {108174},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Evolved extended kalman filter for first-order dynamical systems with unknown measurements noise covariance},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evolutionary algorithms for modeling non-equilibrium
population. <em>ASOC</em>, <em>115</em>, 108172. (<a
href="https://doi.org/10.1016/j.asoc.2021.108172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During protein synthesis the genetic code links each codon, a triplet of nucleotides, with the corresponding amino acid. Synonymous codons are those that code for the same amino acid. The difference in the frequency of occurrence of certain synonymous codons over other synonymous codons is called the codon usage bias (CUB). The Zeng and Charlesworth model is used to estimate the strength of CUB. In their model the evolutionary process is represented by a Markov model, which allows the population size to vary over time. In this paper we propose a new method that incorporates demographic changes into the model. The method is a hybrid of two optimizers, the first is evolutionary programming and the second is a version of the genetic algorithms that uses chromosomes of variable lengths, which allows for expressing more demographic changes than what the simplified model presented by Zeng and Charlesworth does. We conduct several simulations to show why this hybridization is necessary, and also to show the superior performance of this new hybrid.},
  archive      = {J_ASOC},
  author       = {Muhammad Marwan Muhammad Fuad},
  doi          = {10.1016/j.asoc.2021.108172},
  journal      = {Applied Soft Computing},
  pages        = {108172},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Evolutionary algorithms for modeling non-equilibrium population},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generative high-capacity image hiding based on residual CNN
in wavelet domain. <em>ASOC</em>, <em>115</em>, 108170. (<a
href="https://doi.org/10.1016/j.asoc.2021.108170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image hiding is the process of hiding a secret image in another meaningful image or other carriers so that the secret image remains imperceptible and can be recovered securely at the receiving end. The output image of an image hiding algorithm hides the secret image and visually appears to be the same as the carrier image, thus reducing the possibility of being attacked. The current hiding algorithms have relatively low hiding capacity and weak security. In this paper, we propose a generative image hiding algorithm based on a residual convolutional neural network (ResCNN) in wavelet domain to overcome the above-mentioned shortcomings. First, the secret image was subjected to wavelet transform . The low-frequency band of wavelet coefficients were discarded, and only the high-frequency bands were retained as features. These features were then effectively embedded into the carrier image by a generative ResCNN. The recovery network was trained simultaneously with the hiding network so as to extract the hidden features from the container and reconstruct the secret image. Pixel shuffle was used to recover a high-resolution secret image. The experimental results show that the proposed image hiding algorithm is capable of obtaining state-of-the-art results in terms of high hiding capacity and strong security measures.},
  archive      = {J_ASOC},
  author       = {Xishun Zhu and Zhengliang Lai and Yaru Liang and Jianping Xiong and Jianhua Wu},
  doi          = {10.1016/j.asoc.2021.108170},
  journal      = {Applied Soft Computing},
  pages        = {108170},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Generative high-capacity image hiding based on residual CNN in wavelet domain},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A decomposition approach for large-scale non-separable
optimization problems. <em>ASOC</em>, <em>115</em>, 108168. (<a
href="https://doi.org/10.1016/j.asoc.2021.108168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale optimization is the key to many practical decision processes. To deal with the dimensional issue in such problems, many approaches incorporate a divide-and-conquer strategy. Among them, cooperative coevolution approaches have recently gained popularity. Depending on the problem’s structure, the decomposition of any large problem, into a number of smaller sub-problems, may leave some variables common in more than one sub-problem. Such a decomposition may have a negative effect on the quality of the final solution of an optimization problem . In this paper, we have proposed an algorithm that incorporates a novel decomposition method , where the objective of decomposition is to minimize the number of common variables between sub-problems, achieved by exploiting a variable interaction matrix developed from the problem. So the algorithm works as a two-stage approach, where the first stage is the problem decomposition, and the second stage is to find the solutions of the problem. The performance of our proposed algorithm is assessed by solving different sets of large-scale non-separable benchmark functions with up to 2, 905 variables. The experimental results provide important insights into the efficiency of the proposed decomposition method, which in turn improves the performance of the optimization process.},
  archive      = {J_ASOC},
  author       = {Mohamed Meselhi and Ruhul Sarker and Daryl Essam and Saber Elsayed},
  doi          = {10.1016/j.asoc.2021.108168},
  journal      = {Applied Soft Computing},
  pages        = {108168},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A decomposition approach for large-scale non-separable optimization problems},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Object localization through a single multiple-model
switching CNN and a superpixel training approach. <em>ASOC</em>,
<em>115</em>, 108166. (<a
href="https://doi.org/10.1016/j.asoc.2021.108166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object localization has a vital role in any object detector and tracker, and therefore, has been the focus of attention by many researchers. In this article, a special training approach is proposed for a light convolutional neural network (CNN) to determine the region of interest (RoI) in an image while effectively reducing the number of probable anchor boxes . Almost all CNN based detectors utilize a fixed input size image, which may yield poor performance when dealing with various object sizes. In this paper, a different CNN structure is proposed taking three different input sizes, to enhance the performance. To demonstrate the effectiveness of the proposed method, two common data set are used for training while tracking by localization application is considered to demonstrate its final performance. The promising results indicate the applicability of the presented structure and the training method in practice.},
  archive      = {J_ASOC},
  author       = {Faraz Lotfi and Farnoosh Faraji and Hamid D. Taghirad},
  doi          = {10.1016/j.asoc.2021.108166},
  journal      = {Applied Soft Computing},
  pages        = {108166},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Object localization through a single multiple-model switching CNN and a superpixel training approach},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient inference models for classification problems with
a high number of fuzzy rules. <em>ASOC</em>, <em>115</em>, 108164. (<a
href="https://doi.org/10.1016/j.asoc.2021.108164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In data science there are problems that are not visible until you work with a sufficiently large number of data. This is the case, for example, with the design of the inference engine in fuzzy rule-based classification systems. The most common way to implement the winning rule inference method is to use sequential processing that reviews each of the rules in the rule set, to determine the best one and return the associated class. This implementation produces fast response times when the set of rules is small and is applied to a small set of examples. In this paper we explore new versions to implement this inference method, avoiding analyzing all the rules and focusing the analysis on the neighborhood of rules around the example. We study experimentally the conditions where each of them should be applied. Finally, we propose an implementation that combines all the studied versions offering good accuracy results and a significant reduction in the response time.},
  archive      = {J_ASOC},
  author       = {Leonardo Jara and Rubén Ariza-Valderrama and Juan Fernández-Olivares and Antonio González and Raúl Pérez},
  doi          = {10.1016/j.asoc.2021.108164},
  journal      = {Applied Soft Computing},
  pages        = {108164},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Efficient inference models for classification problems with a high number of fuzzy rules},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Weight-of-evidence through shrinkage and spline binning for
interpretable nonlinear classification. <em>ASOC</em>, <em>115</em>,
108160. (<a href="https://doi.org/10.1016/j.asoc.2021.108160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many practical applications, such as fraud detection, credit risk modeling or medical decision making, classification models for assigning instances to a predefined set of classes are required to be both precise and interpretable. Linear modeling methods such as logistic regression are often adopted since they offer an acceptable balance between precision and interpretability . Linear methods, however, are not well equipped to handle categorical predictors with high cardinality or to exploit nonlinear relations in the data. As a solution, data preprocessing methods such as weight of evidence are typically used for transforming the predictors. The binning procedure that underlies the weight-of-evidence approach, however, has been little researched and typically relies on ad hoc or expert-driven procedures. The objective in this paper, therefore, is to propose a formalized, data-driven and powerful method. To this end, we explore the discretization of continuous variables through the binning of spline functions, which allows for capturing nonlinear effects in predictor variables and yields highly interpretable predictors that take only a small number of discrete values. Moreover, we extend the weight-of-evidence approach and propose to estimate the proportions using shrinkage estimators. Together, this method offers an improved ability to exploit both nonlinear and categorical predictors to achieve increased classification precision while maintaining the interpretability of the resulting model and decreasing the risk of overfitting. We present the results of a series of experiments in fraud detection and credit risk settings, which illustrate the effectiveness of the presented approach.},
  archive      = {J_ASOC},
  author       = {Jakob Raymaekers and Wouter Verbeke and Tim Verdonck},
  doi          = {10.1016/j.asoc.2021.108160},
  journal      = {Applied Soft Computing},
  pages        = {108160},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Weight-of-evidence through shrinkage and spline binning for interpretable nonlinear classification},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A population-based algorithm with the selection of
evaluation precision and size of the population. <em>ASOC</em>,
<em>115</em>, 108154. (<a
href="https://doi.org/10.1016/j.asoc.2021.108154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new nature-inspired hybrid population-based algorithm is proposed. Firstly, during its operation, it changes the size of the population to reduce the number of processed individuals. For this purpose, dedicated functions that determine the size of population for each algorithm step are used. Secondly, for each individual of the population, the algorithm selects and changes an operator for its modification. This provides a balance between searching for new solutions and fine-tuning of those already found. Thirdly, the algorithm can control the sampling period of the optimized (dynamic) systems, reducing the complexity of the fitness function for individuals. This makes it easier to use the algorithm to optimize even complex systems, which is of great practical importance. Finally, the algorithm allows to solve problems consisting in choosing the structure of the solution and the parameters of this structure. The control problems considered in the simulations, where both the parameters and the structure of the PID-based controller have to be selected, are exactly this type of problem. The results obtained for the proposed algorithm are significantly better than the results obtained with the use of other methods.},
  archive      = {J_ASOC},
  author       = {Krzysztof Cpałka and Adam Słowik and Krystian Łapa},
  doi          = {10.1016/j.asoc.2021.108154},
  journal      = {Applied Soft Computing},
  pages        = {108154},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A population-based algorithm with the selection of evaluation precision and size of the population},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-objective cross-entropy optimization algorithm and
its application in high-speed train lateral control. <em>ASOC</em>,
<em>115</em>, 108151. (<a
href="https://doi.org/10.1016/j.asoc.2021.108151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper a novel improved multi-objective cross-entropy optimization (MOCEO + + ) algorithm is proposed. We seek to provide a low-cost, fast and effective solution for complex multi-objective problems. Firstly, a population size segmentation mechanism is adopted to reduce the computational cost. This also helps to increase the exploration ability of the algorithm to the optimal Pareto front and the convergence rate is accelerated as well. Then, an individual selection mechanism based on hyper volume (HV) sorting strategy is proposed to retain the elite individuals in the evolution process. Finally, a recombination mechanism is provided to increase diversity of the population individuals and to avoid local optimum. The test results of 2-, 3-, 5-objective WFG test functions indicate that MOCEO + + offers better performance and faster convergence compared with six optimization algorithms . In order to verify feasibility and effectiveness of the MOCEO + + in engineering practice, it is applied to the parameter optimization of the repetitive learning controller for the high-speed train lateral suspension system. The simulation demonstrates that the suspension system optimized by MOCEO + + has better lateral stability compared with three other algorithms. Particularly, the lateral vibration is significantly decreased in the sensitive frequency range [1, 2] Hz of human body.},
  archive      = {J_ASOC},
  author       = {Qichao Tang and Lei Ma and Duo Zhao and Jieyu Lei and Yuhao Wang},
  doi          = {10.1016/j.asoc.2021.108151},
  journal      = {Applied Soft Computing},
  pages        = {108151},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-objective cross-entropy optimization algorithm and its application in high-speed train lateral control},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reliability assessment based on time waveform
characteristics with small sample: A practice inspired by few-shot
learnings in metric space. <em>ASOC</em>, <em>115</em>, 108148. (<a
href="https://doi.org/10.1016/j.asoc.2021.108148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time waveform characteristics of electromagnetic transients such as rise and fall time, duration or energy integral are vital criteria for reliability analysis, but it often meets the challenge to make an evaluation for the electronics of interest due to the lack of sufficient information from sampling and testing. Benefiting from the recent achievements on deep learning technique, in this paper a reliability assessment method for electronics is proposed based on neural network . The recurrent neural network (RNN) is involved to approximate the time waveform norm, so that the time-related characteristic can be extracted in metric space for comparison and classification. Inspired by the model-based few-shot learning strategy, a Siamese network architecture of two weights-sharing RNN is trained to avoid possible over-fitting. Artificial data representing various pulse waveforms are generated, with the help of which the approximation ability of RNN to two kinds of time waveform p-norms is analyzed and discussed in depth. To demonstrate the applicability of the proposed model, the lifetime stage of gas discharge tube (GDT) after cumulative discharge is experimentally investigated. The results are also compared with several informed evaluation model, and the proposed model is verified to able to yield the interpretable estimation in metric space and free from extra prior information.},
  archive      = {J_ASOC},
  author       = {Kejie Li and Lingyun Cheng and Zengwei Lyu and Nianwen Xiang},
  doi          = {10.1016/j.asoc.2021.108148},
  journal      = {Applied Soft Computing},
  pages        = {108148},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Reliability assessment based on time waveform characteristics with small sample: A practice inspired by few-shot learnings in metric space},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semantics in multi-objective genetic programming.
<em>ASOC</em>, <em>115</em>, 108143. (<a
href="https://doi.org/10.1016/j.asoc.2021.108143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantics has become a key topic of research in Genetic Programming (GP). Semantics refers to the outputs (behaviour) of a GP individual when this is run on a dataset. The majority of works that focus on semantic diversity in single-objective GP indicates that it is highly beneficial in evolutionary search. Surprisingly, there is minuscule research conducted in semantics in Multi-objective GP (MOGP). In this work we make a leap beyond our understanding of semantics in MOGP and propose SDO: Semantic-based Distance as an additional criteriOn. This naturally encourages semantic diversity in MOGP. To do so, we find a pivot in the less dense region of the first Pareto front (most promising front). This is then used to compute a distance between the pivot and every individual in the population. The resulting distance is then used as an additional criterion to be optimised to favour semantic diversity. We also use two other semantic-based methods as baselines, called Semantic Similarity-based Crossover and Semantic-based Crowding Distance. Furthermore, we also use the Non-dominated Sorting Genetic Algorithm II and the Strength Pareto Evolutionary Algorithm 2 for comparison too. We use highly unbalanced binary classification problems and consistently show how our proposed SDO approach produces more non-dominated solutions and better diversity, leading to better statistically significant results, using the hypervolume results as evaluation measure, compared to the rest of the other four methods.},
  archive      = {J_ASOC},
  author       = {Edgar Galván and Leonardo Trujillo and Fergal Stapleton},
  doi          = {10.1016/j.asoc.2021.108143},
  journal      = {Applied Soft Computing},
  pages        = {108143},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Semantics in multi-objective genetic programming},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Planning optimal power dispatch schedule using constrained
ant colony optimization. <em>ASOC</em>, <em>115</em>, 108132. (<a
href="https://doi.org/10.1016/j.asoc.2021.108132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the modern power systems , appropriate power dispatch schedule of the online power generating units is essential for reliable and clean power supply and it is desirable to attain this at the lowest possible operating cost. Mathematical model of such an Economic Load Dispatch (ELD) problem turns out to be a complex non-convex optimization problem with practical constraints involving various factors such as, line loss, valve points effect, prohibited operating zones, ramp rate limits, system spinning reserve, multiple fuel options, etc. Nature inspired algorithms have been extensively used to solve such complex ELD problems. Through this study we propose to contribute to the available pool of efficient methodologies for solving ELD problems. Recently, Kumar et al. (2018) developed an ant colony optimization algorithm, namely ACO-LD which has shown impressive results compared to other efficient algorithms in literature when applied to a set of unconstrained optimization problems. In this study we extend ACO-LD to develop a new Constrained Ant Colony Optimization (ACO) algorithm with Adaptive Penalty (AP) method (Lemonge and Barbosa, 2014), to solve the ELD problem. The proposed algorithm is named CACO-LD-AP and is found to be quite efficient in terms of the quality of the solutions found for ELD problems of varied complexities. In order to validate the efficiency of the proposed algorithm, six power systems have been considered in this study. The performance of CACO-LD-AP is compared with various recently published state of the art algorithms for solving ELD problems. Analysis of the experimental results affirms the robustness and superiority of CACO-LD-AP over other algorithms included in this study.},
  archive      = {J_ASOC},
  author       = {Anand Kumar and Manoj Thakur and Garima Mittal},
  doi          = {10.1016/j.asoc.2021.108132},
  journal      = {Applied Soft Computing},
  pages        = {108132},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Planning optimal power dispatch schedule using constrained ant colony optimization},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data-driven optimization for mitigating tunnel-induced
damages. <em>ASOC</em>, <em>115</em>, 108128. (<a
href="https://doi.org/10.1016/j.asoc.2021.108128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Along with the rapid development of urban metro systems, the tunnel-induced damage becomes one of the most critical problems closely related to the safety of tunneling projects. It is urgent to perform an in-depth analysis, identify the key factors influencing the damage, and look for the strategies that could optimize the tunneling process to realize the tunnel-induced damage mitigation. To achieve this, a hybrid data-driven approach with the integration of random forest and non-dominant sorting genetic algorithm-II (NSGA-II) is proposed to perform the multi-objective optimization for mitigating tunnel-induced damages under uncertainty. The random forest is used to construct the meta-model between identified influential factors and objectives. NSGA-II is used to perform the optimization process based on the proposed optimization principle. A total of 16 input variables are identified, and two key factors (i.e., the accumulative settlement and building tilt rate) are determined as the optimization objectives related to the mitigation of the tunnel-induced damage. A case study is conducted to test the applicability and effectiveness of the proposed approach. Through the case study, it is found that: (1) An average damage mitigation improvement degree of 20.9\% can be achieved through the proposed optimization process; (2) The optimization can gain the highest improvement degree 32.6\% for the tunnel-induced damage mitigation problem when adjusting 3 influential variables; (3) The proposed approach is applicable for the damage mitigation optimization with more objectives, but the consideration of a third objective degrades the optimization improvement for the first two by 2.2\% and 6.5\%, respectively. The novelty lies in that: (1) The random forest algorithm is incorporated into the model to represent the complex relationship between the identified objectives and the influential factors; (2) Multi-objectives are identified for the mitigation of the tunnel-induced damages, and the optimization of the multi-objectives is realized by the integration of NSGA-II. This research enriches the area of the safety management of tunneling projects by the integration of the random forest and NSGA-II algorithms. With the proposed hybrid approach, the complex relationship between desired objectives and the influential factors could be represented, and the damage mitigation and project optimization could be realized, even potential conflict between objectives may exist.},
  archive      = {J_ASOC},
  author       = {Kai Guo and Limao Zhang},
  doi          = {10.1016/j.asoc.2021.108128},
  journal      = {Applied Soft Computing},
  pages        = {108128},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Data-driven optimization for mitigating tunnel-induced damages},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An intelligent chaotic clonal optimizer. <em>ASOC</em>,
<em>115</em>, 108126. (<a
href="https://doi.org/10.1016/j.asoc.2021.108126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increasing complexity of real world problems motivated an area to explore efficient optimization methods to solve such problems. Existing optimization algorithms cannot solve all type of problems efficiently (NFL theorem), so new algorithms are proposed to find the better solutions for such complex optimization problems . However, their efficiency and performance can be still improved. Therefore, to follow this vital purpose, in this paper, a novel metaheuristic algorithm , called intelligent clonal optimizer (ICO), is proposed to solve continuous optimization problems . In the proposed algorithm, the initial population is generated through the chaos theory to enhance its exploration capability. It lacks any crossover operator . Instead, a novel clonal operator copying candidate solutions according to their fitness in a self-adaptive way is proposed. Cloning each parent is carried out by two methods, and according to these methods, each offspring is located near the parent or in direction of temporary target. The offsprings are classified to two classes. In addition, a novel conservative selection operator is proposed. According to this operator, the new population is selected from two classes of offsprings and current population by maintaining population diversity. The performance of the ICO algorithm is assessed on 39 well-known unimodal, multimodal, fixed-dimensional multimodal, composite and CEC2019 benchmark functions as well as three engineering application problems. Results of the proposed ICO are compared to sixteen state-of-art metaheuristic algorithms in three categories including the most well-known and recently developed algorithms and the best performer of IEEE CEC competitions using statistical analysis, scalability analysis, Wilcoxon Signed-Rank Test, Friedman test, computational time analysis and convergence analysis . The obtained results proved that ICO performs better than state-of-art metaheuristics in sense of scalability and accurate convergence. According to average rank of Friedman test, the proposed ICO is firstly ranked among others.},
  archive      = {J_ASOC},
  author       = {Vahideh Sahargahi and Vahid Majidnezhad and Saeid Taghavi Afshord and Yasser Jafari},
  doi          = {10.1016/j.asoc.2021.108126},
  journal      = {Applied Soft Computing},
  pages        = {108126},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An intelligent chaotic clonal optimizer},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FDN-ADNet: Fuzzy LS-TWSVM based deep learning network for
prognosis of the alzheimer’s disease using the sagittal plane of MRI
scans. <em>ASOC</em>, <em>115</em>, 108099. (<a
href="https://doi.org/10.1016/j.asoc.2021.108099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease (AD) is the most pervasive form of dementia, resulting in severe psychosocial effects such as affecting personality, reasoning, emotions, and memory. Several neuroimaging techniques are available to correctly identify the structural changes in the brain, out of which the most popular is structural T-1 weighted Magnetic Resonance Imaging (MRI). From 3D MRI, sagittal plane slices provide more clear information related to the hippocampus, amygdala, corpus callosum , and several vital regions of the brain, which defines the extent of degeneration of the AD. Although diverse analysis of machine learning (ML) and deep learning (DL) based algorithm is already proposed for diagnosis of AD, still there is scope of research for early prediction so that treatment can be started either by medication or by improving the lifestyle. This paper proposed a DL model for all level feature extraction and fuzzy hyperplane based least square twin support vector machine (FLS-TWSVM) for the classification of the extracted features for early diagnosis of AD (FDN-ADNet) using extracted sagittal plane slices from 3D MRI images. Model is trained over the online available ADNI dataset and triangular fuzzy function is applied for the construction of hyperplane for classification. The proposed model attains the highest accuracy of 97.15\%, 97.29\% and 95\% for CN vs AD, CN vs MCI and AD vs MCI classification, respectively when compared with the several state of the art networks.},
  archive      = {J_ASOC},
  author       = {Rahul Sharma and Tripti Goel and M. Tanveer and R. Murugan},
  doi          = {10.1016/j.asoc.2021.108099},
  journal      = {Applied Soft Computing},
  pages        = {108099},
  shortjournal = {Appl. Soft. Comput.},
  title        = {FDN-ADNet: Fuzzy LS-TWSVM based deep learning network for prognosis of the alzheimer’s disease using the sagittal plane of MRI scans},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Numerical algorithm for optimal control of switched systems
and its application in cancer chemotherapy. <em>ASOC</em>, <em>115</em>,
108090. (<a href="https://doi.org/10.1016/j.asoc.2021.108090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers an optimal control problem of switched dynamical systems with control input and system state constraints. Unlike in traditional switched dynamical systems , the switching times cannot be specified directly and they are governed by a state-dependent switching condition. Thus, the existing methods cannot be directly used to solve this problem. To overcome this difficulty, the switching conditions are transformed into a continuous-time inequality constraint by introducing an integer constraint. Further, the original optimal control problem is approximated by using a sequence of constrained non-convex nonlinear parameter optimization problems by using a relaxation method, a control vector parameterization technique, and a time-scaling transformation. Following that, a penalty function-based intelligent optimization algorithm is proposed for obtaining a global optimal solution based on a more effective penalty function method and a more effective intelligent optimization algorithm . The convergence results show that the proposed method is globally convergent. Numerical simulation results show that the proposed method is lower time-consuming, has faster convergence speed, can obtain a better objective function value than the existing typical algorithms, and can achieve a stable and robust performance when considering the small perturbations in constraint conditions or the small perturbations of the model parameters.},
  archive      = {J_ASOC},
  author       = {Xiang Wu and Jinxing Lin and Kanjian Zhang and Ming Cheng},
  doi          = {10.1016/j.asoc.2021.108090},
  journal      = {Applied Soft Computing},
  pages        = {108090},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Numerical algorithm for optimal control of switched systems and its application in cancer chemotherapy},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-center sparse learning and decision fusion for
automatic COVID-19 diagnosis. <em>ASOC</em>, <em>115</em>, 108088. (<a
href="https://doi.org/10.1016/j.asoc.2021.108088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The coronavirus disease 2019 (COVID-19) pandemic caused by the novel severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has led to a sharp increase in hospitalized patients with multi-organ disease pneumonia . Early and automatic diagnosis of COVID-19 is essential to slow down the spread of this epidemic and reduce the mortality of patients infected with SARS-CoV-2. In this paper, we propose a joint multi-center sparse learning (MCSL) and decision fusion scheme exploiting chest CT images for automatic COVID-19 diagnosis. Specifically, considering the inconsistency of data in multiple centers, we first convert CT images into histogram of oriented gradient (HOG) images to reduce the structural differences between multi-center data and enhance the generalization performance . We then exploit a 3-dimensional convolutional neural network (3D-CNN) model to learn the useful information between and within 3D HOG image slices and extract multi-center features. Furthermore, we employ the proposed MCSL method that learns the intrinsic structure between multiple centers and within each center, which selects discriminative features to jointly train multi-center classifiers. Finally, we fuse these decisions made by these classifiers. Extensive experiments are performed on chest CT images from five centers to validate the effectiveness of the proposed method. The results demonstrate that the proposed method can improve COVID-19 diagnosis performance and outperform the state-of-the-art methods.},
  archive      = {J_ASOC},
  author       = {Zhongwei Huang and Haijun Lei and Guoliang Chen and Haimei Li and Chuandong Li and Wenwen Gao and Yue Chen and Yaofa Wang and Haibo Xu and Guolin Ma and Baiying Lei},
  doi          = {10.1016/j.asoc.2021.108088},
  journal      = {Applied Soft Computing},
  pages        = {108088},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-center sparse learning and decision fusion for automatic COVID-19 diagnosis},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An adaptive bi-level task planning strategy for multi-USVs
target visitation. <em>ASOC</em>, <em>115</em>, 108086. (<a
href="https://doi.org/10.1016/j.asoc.2021.108086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a task planning problem, which dispatches multiple unmanned surface vehicles (USVs) to visit a set of targets located in ocean environments. The problem is modeled as a bi-level optimization to reduce the total and the individual navigation costs simultaneously. The upper-level allocates targets and schedules target visitation sequences, while the lower-level plans safe and economical paths between two targets under the current influence. Subsequently, a novel nested strategy is proposed to solve the bi-level problem, which modifies each level initialization process and can adaptively give the lower-level function evaluation number according to the problem complexity. Besides, the proposed strategy can adopt general metaheuristics as optimizers. Thus, two upper-level and five lower-level algorithms are employed in combination, which covers most kinds of metaheuristics. Finally, the ten combinations of algorithms are tested on three large-scale and complex cases, and the results verify the effectiveness of the proposed model and strategy.},
  archive      = {J_ASOC},
  author       = {Siqing Sun and Baowei Song and Peng Wang and Huachao Dong and Xiao Chen},
  doi          = {10.1016/j.asoc.2021.108086},
  journal      = {Applied Soft Computing},
  pages        = {108086},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An adaptive bi-level task planning strategy for multi-USVs target visitation},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Granular models as networks of associations of information
granules: A development scheme via augmented principle of justifiable
granularity. <em>ASOC</em>, <em>115</em>, 108062. (<a
href="https://doi.org/10.1016/j.asoc.2021.108062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes an approach to the construction of granular models directly based on information granules expressed both in input and output spaces. Associating these information granules, the constructed granular models come in the framework of three layers networks: input granules, an inference scheme and output granules. The proposed approach consists of two stages. First, an augmented principle of justifiable granularity is proposed and applied to construct information granules in an input space. This principle constructs information granules not only through establishing a sound balance between two criteria, i.e., coverage and specificity, but also by optimizing those information granules on the basis of their homogeneity assessed with respect to data localized in output space. At the second stage, we propose an inference scheme by analyzing a location of an input datum in relation with the already formed information granules in an input space. The computed relation can be quantified as membership grades , thus yielding aggregation results involving information granules in an output space. The performance of the proposed granular model is supported by the mechanisms of granular computing and the principle of justifiable granularity . Experimental studies concerning synthetic and publicly available data are performed and some comparative analysis involving rule-based models is given.},
  archive      = {J_ASOC},
  author       = {TaiLong Jing and Cong Wang and Witold Pedrycz and ZhiWu Li and Giancarlo Succi and MengChu Zhou},
  doi          = {10.1016/j.asoc.2021.108062},
  journal      = {Applied Soft Computing},
  pages        = {108062},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Granular models as networks of associations of information granules: A development scheme via augmented principle of justifiable granularity},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online interval type-2 fuzzy extreme learning machine
applied to 3D path following for remotely operated underwater vehicles.
<em>ASOC</em>, <em>115</em>, 108054. (<a
href="https://doi.org/10.1016/j.asoc.2021.108054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In marine missions that involve 3D path following tasks, the overall goal of Underwater Vehicles (UVs) is the successful completion of a path previously specified by the operator. This implies that the path must be followed by the UV as closely as possible and arrive at a location for collection by a vessel. In this paper, an Online Interval Type-2 Fuzzy Extreme Learning Machine (OIT2-FELM) is suggested to achieve a robust following behaviour along a predefined 3D path using a Remotely Operated Underwater Vehicle (ROV). The proposed machine is a fast sequential learning scheme to the training of a more generalised model of TSK Interval Type-2 Fuzzy Inference Systems (TSK IT2 FISs) equivalent to Single Layer Feedforward Neural Networks (SLFNs). Learning new input data in the OIT2-FELM can be done one-by-one or chunk-by-chunk with a fixed or varying size. The OIT2-FELM is implemented in a hierarchical navigation strategy (HNS) as the main guidance mechanism to infer local control motions and to provide the ROV with the necessary autonomy to complete a predefined 3D path. For local path-planning, the OIT2-FELM performs signal classification for obstacle avoidance and target detection based on data collected by an on-board scan sonar . To evaluate the performance of the proposed OIT2-FELM, two different experiments are suggested. First, a number of benchmark problems in the field of non-linear system identification, regression and classification problems are used. Secondly, a number of experiments to the completion of a predefined 3D path using an ROV is implemented. Compared to other fuzzy strategies, the OIT2-FELM offered two significant capabilities. On the one hand, the OIT2-FELM provides a better treatment of uncertainty and noisy signals in underwater environments while improving the ROV’s performance. Secondly, online learning in OIT2-FELM allows continuous knowledge discovery from survey data to infer the surroundings of the ROV. Experiment results to the completion of 3D paths show the effectiveness of the proposed approach to handle uncertainty and produce reasonable classification predictions ( ∼ 90 . 5\% ∼90.5\% accuracy in testing data).},
  archive      = {J_ASOC},
  author       = {Adrian Rubio-Solis and Uriel Martinez-Hernandez and Luciano Nava-Balanzar and Luis G. Garcia-Valdovinos and Noe A. Rodriguez-Olivares and Juan P. Orozco-Muñiz and Tomas Salgado-Jimenez},
  doi          = {10.1016/j.asoc.2021.108054},
  journal      = {Applied Soft Computing},
  pages        = {108054},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Online interval type-2 fuzzy extreme learning machine applied to 3D path following for remotely operated underwater vehicles},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Decentralized learning of randomization-based neural
networks with centralized equivalence. <em>ASOC</em>, <em>115</em>,
108030. (<a href="https://doi.org/10.1016/j.asoc.2021.108030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a decentralized learning problem where training data samples are distributed over agents (processing nodes) of an underlying communication network topology without any central (master) node. Due to information privacy and security issues in a decentralized setup, nodes are not allowed to share their training data and only parameters of the neural network are allowed to be shared. This article investigates decentralized learning of randomization-based neural networks that provides centralized equivalent performance as if the full training data are available at a single node. We consider five randomization-based neural networks that use convex optimization for learning. Two of the five neural networks are shallow, and the others are deep. The use of convex optimization is the key to apply alternating-direction-method-of-multipliers with decentralized average consensus . This helps us to establish decentralized learning with centralized equivalence. For the underlying communication network topology, we use a doubly-stochastic network policy matrix and synchronous communications . Experiments with nine benchmark datasets show that the five neural networks provide good performance while requiring low computational and communication complexity for decentralized learning. The performance rankings of five neural networks using Friedman rank are also enclosed in the results, which are ELM &amp;lt; RVFL &amp;lt; dRVFL &amp;lt; edRVFL &amp;lt; SSFN .},
  archive      = {J_ASOC},
  author       = {Xinyue Liang and Alireza M. Javid and Mikael Skoglund and Saikat Chatterjee},
  doi          = {10.1016/j.asoc.2021.108030},
  journal      = {Applied Soft Computing},
  pages        = {108030},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Decentralized learning of randomization-based neural networks with centralized equivalence},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A coral-reef approach to extract information from HTML
tables. <em>ASOC</em>, <em>115</em>, 107980. (<a
href="https://doi.org/10.1016/j.asoc.2021.107980">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents Coraline, which is a new table-understanding proposal. Its novelty lies in a coral-reef optimisation algorithm that addresses the problem of feature selection in synchrony with a clustering technique and some custom heuristics that help extract information in a totally unsupervised manner . Our experimental analysis was performed on a large collection of tables with a variety of layouts, encoding problems, and formatting alternatives. Coraline could achieve an F 1 F1 score as high as 0.90 and took 7.07 CPU seconds per table, which improves on the best supervised proposal by 6.67\% regarding effectiveness and 40.54\% regarding efficiency; it also improves on the best unsupervised proposal by 11.11\% regarding effectiveness while it remains very competitive regarding efficiency.},
  archive      = {J_ASOC},
  author       = {Patricia Jiménez and Juan C. Roldán and Rafael Corchuelo},
  doi          = {10.1016/j.asoc.2021.107980},
  journal      = {Applied Soft Computing},
  pages        = {107980},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A coral-reef approach to extract information from HTML tables},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A mixture-of-gaussians model for estimating the magic
barrier of the recommender system. <em>ASOC</em>, <em>114</em>, 108162.
(<a href="https://doi.org/10.1016/j.asoc.2021.108162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rating data collected by the recommender system usually contains noise due to external factors such as human uncertainty and inconsistency. Such noise, usually modeled by a normal distribution, leads to a magic barrier (MGBR) to the recommender system . However, existing MGBR estimation approaches require a user-specified standard deviation of noise, or make strong assumptions about true ratings, or need additional information from experts or users. In this paper, we propose a Mixture of Gaussians (MoG) model without user intervention to handle this issue. First, the user uncertainties are modeled using MoG, which is a universal approximator for any continuous distribution. Second, we employ the expectation–maximization algorithm to determine the parameters of user uncertainty. Finally, the MGBR is computed by Bayesian formula with the parameters. Experimental results on four well-known datasets show that the MGBRs estimated by the new model are close to the results of the state-of-the-art algorithms.},
  archive      = {J_ASOC},
  author       = {Heng-Ru Zhang and Jie Qian and Hui-Lin Qu and Fan Min},
  doi          = {10.1016/j.asoc.2021.108162},
  journal      = {Applied Soft Computing},
  pages        = {108162},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A mixture-of-gaussians model for estimating the magic barrier of the recommender system},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A memetic evolution system with statistical variable
classification for large-scale many-objective optimization.
<em>ASOC</em>, <em>114</em>, 108158. (<a
href="https://doi.org/10.1016/j.asoc.2021.108158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the optimization algorithms have been widely studied, the large-scale many-objective optimization problems (LSMaOPs) remain challenging. Due to the existence of a large number of decision variables, it is necessary to carry out decision variable analysis. However, it is often difficult to discriminate the diversity-related and convergence-related variables when the problem has complex characteristics. Meanwhile, as the number of decision variables and the number of objectives increase, many algorithms will suffer from the convergence challenge. To overcome these challenges, this paper proposes a Memetic Evolution System with Statistical Variable Classification (MES-SVC). A statistical variable classification method is proposed to discriminate the convergence-related and the diversity-related variables. A memetic evolution system, which includes a memetic exploitation and exploration module, and a memetic elite imitation module, is proposed to make information guidance during the evolution, thereby promote convergence. The performance of MES-SVC is compared with the state-of-the-art algorithms on 50 test instances with 3 to 10 objectives and 300 to 1000 decision variables. Experimental studies demonstrate the promising performance of the proposed MES-SVC in terms of both diversity and convergence of solutions.},
  archive      = {J_ASOC},
  author       = {Hongwei Ge and Naiqiang Zhang and Liang Sun and Xia Wang and Yaqing Hou},
  doi          = {10.1016/j.asoc.2021.108158},
  journal      = {Applied Soft Computing},
  pages        = {108158},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A memetic evolution system with statistical variable classification for large-scale many-objective optimization},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Joint segmentation and classification task via adversarial
network: Application to HEp-2 cell images. <em>ASOC</em>, <em>114</em>,
108156. (<a href="https://doi.org/10.1016/j.asoc.2021.108156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recognition of epithelial type 2 (HEp-2) cells has become an important tool for detecting autoimmune diseases diagnosis by using indirect immunofluorescence (IIF) images. For many medical image tasks, the accurate segmentation is considered as the primary step for the classification task , which inspires researchers to solve problems by jointly implementing multiple tasks. For this reason, we devise a hybrid network architecture , which combines the segmentation and classification networks for the final classification of HEp-2 cells, where a multi-task generative adversarial networks (GANs) is employed to produce accurate segmentation masks for improving the latter classification performance. Specifically, the devised generation and discrimination subnetworks establish the GANs architecture for the accurate segmentation masks of HEp-2 cells. Also, the original images are utilized as the conditional input, which are concatenated by the generated masks and the ground-truth to train the discriminator for two tasks: the first task determines whether the generated mask is a ground-truth or not and the other one distinguishes the category of the processed HEp-2 cell image. Furthermore, the ResNet-34 and MobileNetv3 are used as segmentation and classification base network, respectively. We modify the MobileNetv3 structure by adding the channel of the middle outputs, which is called augmented channel MobileNetv3 (ACM-Net). Both the discriminator and classifier share the weights of ACM-Net. The extensive experiments on the public ICPR 2016 task1 dataset show that the proposed hybrid-task based GANs structure can obtain promising segmentation and classification performance via jointly training mode, which achieves a Dice of 97.04\% and for segmentation and a prediction accuracy of 98.82\% for classification, respectively.},
  archive      = {J_ASOC},
  author       = {Hai Xie and Yejun He and Dong Xu and Jong Yih Kuo and Haijun Lei and Baiying Lei},
  doi          = {10.1016/j.asoc.2021.108156},
  journal      = {Applied Soft Computing},
  pages        = {108156},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Joint segmentation and classification task via adversarial network: Application to HEp-2 cell images},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Internal audit planning using spherical fuzzy ELECTRE.
<em>ASOC</em>, <em>114</em>, 108155. (<a
href="https://doi.org/10.1016/j.asoc.2021.108155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internal audit is an independent and objective assurance and consulting activity that aims to improve the operations of an organization and add value to them. Planning internal audit by prioritizing the units to be audit is critical in terms of effective use of available audit and financial resources. In this paper, a new ELimination and Choice Translating Reality (ELECTRE) based decision support model is developed for addressing an internal audit prioritization problem. Spherical fuzzy sets are used for modeling the uncertainty in the nature of the problem and three different approaches are proposed within the study. The first approach is constructed with gradual concordance and discordance sets by comparing spherical fuzzy membership, non-membership, and hesitancy degrees of alternatives; the second approach is developed based on a single type of outranking relation obtained by utilizing score and accuracy functions of spherical fuzzy sets, and the third approach provides an increased fuzziness modeling capacity by using interval-valued spherical fuzzy sets. In the application part of the study, the units of an organization are prioritized for internal audit activity based on five components of the internationally recognized Committee of Sponsoring Organizations (COSO) framework. Sensitivity analyses for decision-maker and criterion weights and a comparative analysis with six other state-of-the-art multi-criteria decision making (MCDM) models are also presented to analyze the consistency and validity of the proposed spherical fuzzy ELECTRE model.},
  archive      = {J_ASOC},
  author       = {Akin Menekse and Hatice Camgoz-Akdag},
  doi          = {10.1016/j.asoc.2021.108155},
  journal      = {Applied Soft Computing},
  pages        = {108155},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Internal audit planning using spherical fuzzy ELECTRE},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Imbalanced credit risk prediction based on SMOTE and
multi-kernel FCM improved by particle swarm optimization. <em>ASOC</em>,
<em>114</em>, 108153. (<a
href="https://doi.org/10.1016/j.asoc.2021.108153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently ensemble models were adopted to predict the credit risk commonly. Although they have a better performance generally, ensemble models are easy to be badly affected by imbalance classes which are a common issue in credit risk prediction. And the prediction model should be constructed according to the feature of complex distributions of financial data. However, these problems have not attracted enough attention. This paper constructs an ensemble model for imbalanced credit risk prediction and improves algorithms for the feature of financial data. The ensemble model mainly combines Synthetic Minority Over-sampling Technique Evaluation (SMOTE) and Multi-Kernel Fuzzy C-Means (MK-FCM) optimized by Particle Swarm Optimization (PSO). In the preprocessing phase , the multi-method of descending dimension is used to reduce the dimension. The improved SMOTE can make new synthetic samples more decentralized, which can not only balance the number of samples of different classes, but avoid the overfitting to some extent. In the base classifier construction phase, Fuzzy C-Means (FCM) is improved by multi-kernel function to build a new base classifier MK-FCM, which can synthetize the merits of multiple kernel functions to enhance the evaluated performance. The improved PSO, which has dynamically adjustable function, is used to optimize parameters for MK-FCM. In the empirical research, the sample data are from financial indicators of Chinese listed hospitality and tourism corporations, and the proposed model makes the comparative analysis with other relative models. The results from Matlab software show that the presented ensemble model has the best performance on imbalanced credit risk prediction.},
  archive      = {J_ASOC},
  author       = {Lu Wang},
  doi          = {10.1016/j.asoc.2021.108153},
  journal      = {Applied Soft Computing},
  pages        = {108153},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Imbalanced credit risk prediction based on SMOTE and multi-kernel FCM improved by particle swarm optimization},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A levy flight motivated meta-heuristic approach for
enhancing maximum loadability limit in practical power system.
<em>ASOC</em>, <em>114</em>, 108146. (<a
href="https://doi.org/10.1016/j.asoc.2021.108146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the practical engineering optimization problems are highly nonlinear, nonconvex, and sometimes discontinuous. Classical optimization techniques, mostly being differential calculus based, either fail to find the optimal solution for practical problems or provide solution after relaxing the nonlinearities . Over the time, population-based meta-heuristic techniques have gained enough popularity among research fraternity due to their unrestricted performance on the nature of the optimization problems . Despite their better performances, they sometimes suffer from the problem of trapping into local optima. Hence, suitable strategies should be adopted to overcome the above said issues. In view of this, a new Levy Flight (LF) based Adaptive Particle Swarm Optimization (APSOLF) technique is designed and proposed in this work to solve complex, nonlinear optimization problems. The performance of the proposed algorithm is gauged by applying it on various mathematical benchmark functions . The technique is also applied to solve the practical electrical engineering problems where the task of proposed algorithm is to optimize the Static Synchronous Series Compensator (SSSC) parameters to improve the Maximum Loadability Limit (MLL) of some standard test power systems viz. IEEE 14, 30, 57, 118 and a practical Indian southern region 205 buses. The results obtained are compared with other variants of PSO. Furthermore, the robustness of the proposed algorithm is tested by performing the statistical analysis (both parametric and nonparametric tests). The results confirm better efficiency, robustness, and consistency of the proposed algorithm. The simulations are performed on MATLAB environment.},
  archive      = {J_ASOC},
  author       = {Debanjan Mukherjee and Sourav Mallick and Abhishek Rajan},
  doi          = {10.1016/j.asoc.2021.108146},
  journal      = {Applied Soft Computing},
  pages        = {108146},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A levy flight motivated meta-heuristic approach for enhancing maximum loadability limit in practical power system},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Observer-based adaptive neural control of robotic systems
with prescribed performance. <em>ASOC</em>, <em>114</em>, 108142. (<a
href="https://doi.org/10.1016/j.asoc.2021.108142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an adaptive neural output feedback control (ANOFC) scheme is proposed for controlling an electrically driven robotic manipulator (EDRM) system with prescribed errors constraint by using a neural network-based adaptive observer (NNAO) and a backstepping design technique. First, the NNAO is designed to observe the unknown and unmeasured joint velocities of EDRM. Second, the prescribed performance bounds of output tracking are used to achieve the prescribed transient and steady-state performance based on barrier Lyapunov function . Then, the ANOFC scheme is derived by using the backstepping design methodology, where neural networks with adaptive update laws are utilized to approximate the unknown nonlinear functions . By using the Lyapunov stability analysis method, the observer and closed-loop control system can be proven to be stable such that all the uniformly bounded variables in the system are guaranteed and the output tracking errors remain within the specified prescribed bounds. Finally, the simulation results demonstrate that the proposed NNAO and ANOFC schemes can achieve the satisfied estimation capability and tracking effectiveness.},
  archive      = {J_ASOC},
  author       = {Jinzhu Peng and Rickey Dubay and Shuai Ding},
  doi          = {10.1016/j.asoc.2021.108142},
  journal      = {Applied Soft Computing},
  pages        = {108142},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Observer-based adaptive neural control of robotic systems with prescribed performance},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online rescue method based on offline learning of dynamics
knowledge for launch vehicles under thrust-drop fault. <em>ASOC</em>,
<em>114</em>, 108140. (<a
href="https://doi.org/10.1016/j.asoc.2021.108140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an online rescue method based on offline learning of dynamics knowledge to solve the problem of the optimal rescue orbit and flight trajectory optimization (OROTO) of launch vehicles experiencing thrust-drop faults. Due to the unknown of the rescue orbit, solving the OROTO problem by the conventional aerospace orbit and trajectory optimization method is time-consuming. In this paper, benefiting from the decision-making of the optimal rescue orbit by the machine learning technology , the OROTO problem is decoupled into a decision-making of the optimal rescue orbit and a trajectory optimization problem with a known orbit. In the decision-making of the optimal rescue orbit, instead of the conventional iteration optimization process based on dynamics, the optimal rescue orbit is determined by the “fault-rescue” knowledge integration (FRKI) model which consists of probabilistic neural network (PNN) and radial basis function neural network (RBFNN) trained by “fault-rescue” knowledge. In the trajectory optimization part, the output of the FRKI model provides terminal constraints for the trajectory optimization problem to decrease the search scope for the optimal solution. Numerical simulation results show that the proposed method can solve the OROTO problem rapidly and accurately, and can potentially be implemented for online applications.},
  archive      = {J_ASOC},
  author       = {Xiao He and Shujun Tan and Zhigang Wu and Liyong Zhang},
  doi          = {10.1016/j.asoc.2021.108140},
  journal      = {Applied Soft Computing},
  pages        = {108140},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Online rescue method based on offline learning of dynamics knowledge for launch vehicles under thrust-drop fault},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Non-revisiting genetic cost-sensitive sparse autoencoder for
imbalanced fault diagnosis. <em>ASOC</em>, <em>114</em>, 108138. (<a
href="https://doi.org/10.1016/j.asoc.2021.108138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is hard to obtain sufficient fault samples in most real-world industrial scenarios. This has raised the need of addressing the critical issue of imbalanced fault diagnosis that remains a major challenge for popular fault diagnosis methods such as the autoencoder(AE). In this research, we propose a non-revisiting genetic cost-sensitive sparse autoencoder(NrGCS-SAE) solution, which not only incorporates cost-sensitive learning with sparse autoencoder but also solves the problem of class weights assignment . Specifically, sparse autoencoder is adopted as it has better generalization performance than autoencoder, and genetic algorithm(GA) is employed to optimize class weights that are initially unknown. In addition, a non-revisiting strategy is devised to prevent repeated evaluation of the same individual in different generations, which can help increase exploration ability and decrease computing costs. Computational experiments are used to evaluate the proposed NrGCS-SAE solution on the Tennessee Eastman(TE) dataset and the real plasma etching process dataset, which involves both binary imbalanced fault diagnosis and multi-class imbalanced faults diagnosis. As evidenced in the tests, NrGCS-SAE achieves improved performance and more importantly this improvement is consistent in different settings of experiments.},
  archive      = {J_ASOC},
  author       = {Peng Peng and Wenjia Zhang and Yi Zhang and Hongwei Wang and Heming Zhang},
  doi          = {10.1016/j.asoc.2021.108138},
  journal      = {Applied Soft Computing},
  pages        = {108138},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Non-revisiting genetic cost-sensitive sparse autoencoder for imbalanced fault diagnosis},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hierarchical variable fidelity evolutionary optimization
methods and their applications in aerodynamic shape design.
<em>ASOC</em>, <em>114</em>, 108135. (<a
href="https://doi.org/10.1016/j.asoc.2021.108135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes two hierarchical evolutionary optimization methods based on variable fidelity analysis and search space contraction for aerodynamic shape design, i.e. hierarchical evolutionary Pareto and Nash games. One of these techniques is used in the optimization process, namely the advantages of high and low fidelity flow simulation. The high-fidelity model provides solution accuracy while the low-fidelity model reduces the computational cost. Especially, the search space contraction and the population size reduction are introduced in the process of transition from the optimization on low fidelity simulation to the optimization on high fidelity simulation, so that the optimization based on high fidelity simulation can get the high-precision optimal solution with a relatively less Central Processing Unit(CPU) cost. They are applied to the single objective natural laminar wing shape design at transonic flow and the multidisciplinary shape optimization of a hypersonic air-breathing vehicle respectively. The optimization results show that regardless of a single objective or multi-objective/multidisciplinary optimization problem , the new hierarchical optimization methods proposed in this paper can improve the optimization efficiency by 5-10 times.},
  archive      = {J_ASOC},
  author       = {Zhili Tang and Shaojun Luo and Yongbin Chen and Xin Zhao and Peng Wu},
  doi          = {10.1016/j.asoc.2021.108135},
  journal      = {Applied Soft Computing},
  pages        = {108135},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Hierarchical variable fidelity evolutionary optimization methods and their applications in aerodynamic shape design},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tree CycleGAN with maximum diversity loss for image
augmentation and its application into gear pitting detection.
<em>ASOC</em>, <em>114</em>, 108130. (<a
href="https://doi.org/10.1016/j.asoc.2021.108130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual detection is an available approach for measuring gear pitting . Unfortunately, the number of gear pitting images is limited, resulting in that the detection accuracy of gear pitting is unsatisfactory. In order to augment gear pitting samples with different styles, a novel Cycle Generative Adversarial Network based on a symmetric tree structure (Tree-CycleGAN) is proposed. In Tree-CycleGAN, a new type of generator with tree structure named tree generator is designed to produce various types of high quality target samples from the source-domain samples, and a maximum diversity loss is constructed to enlarge the difference between two arbitrary branches; then a similar tree reconstructor is designed for translating target samples into source samples. Two discriminators are designed for making the generated images approximate to the target images in two cyclic processes. Via inception score, structural similarity indexes and peak-signal-to-noise ratio, the quality and diversity of images obtained by Tree-CycleGAN are evaluated. Comparative results show the superiority of Tree-CycleGAN over other domain adaptation GANs. The proposed Tree-CycleGAN combined with U-net has been successfully applied to gear pitting detection. Experimental results prove that the proposed methodology precedes the basic U-net method without sample augmentation and the method based on CycleGAN and U-net.},
  archive      = {J_ASOC},
  author       = {Yi Qin and Zhiwen Wang and Dejun Xi},
  doi          = {10.1016/j.asoc.2021.108130},
  journal      = {Applied Soft Computing},
  pages        = {108130},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Tree CycleGAN with maximum diversity loss for image augmentation and its application into gear pitting detection},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Computational intelligence for preventive maintenance of
power transformers. <em>ASOC</em>, <em>114</em>, 108129. (<a
href="https://doi.org/10.1016/j.asoc.2021.108129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Power transformers are an indispensable equipment in power transmission and distribution systems, and failures or hidden defects in power transformers can cause operational and downtime issues in power supply, resulting in economic and resource losses. Therefore, it is highly desirable to put in place intelligent preventive maintenance measures to diagnose and evaluate the condition of power transformers. Although conventional methods have achieved success in detecting problems associated with power transformers, their adoption rate in practical environments is still far from universal. The advent of Computational Intelligence (CI) models offers useful potential to complement the existing diagnostic practices of power transformers. In this paper, we provide a review on various computational intelligence techniques for fault detection and diagnosis pertaining to preventive maintenance of power transformers. An overview of each representative CI approach is presented to facilitate researchers in selecting an appropriate method for a specific problem at hand. We carry out a broad discussion on numerous concerns and challenges that are missing from the current literature, which, nevertheless, need to be addressed seriously. We identify the research gaps in the literature, and suggest the way forward in research that will in the long run enhance power system reliability by embracing CI approaches into business operations in an effort to realize the Sustainable Development Goal (SDGs) advocated by the United Nation, primarily SDG7: Clean and Affordable Energy and SDG9: Industry, Innovation and Infrastructure.},
  archive      = {J_ASOC},
  author       = {Shen Yuong Wong and Xiaofeng Ye and Fengkai Guo and Hui Hwang Goh},
  doi          = {10.1016/j.asoc.2021.108129},
  journal      = {Applied Soft Computing},
  pages        = {108129},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Computational intelligence for preventive maintenance of power transformers},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neighborhood rough set-based multi-attribute prediction
approach and its application of gout patients. <em>ASOC</em>,
<em>114</em>, 108127. (<a
href="https://doi.org/10.1016/j.asoc.2021.108127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate disease prediction is an effective way to reduce medical costs. Due to the difference of eating habits and physical fitness of patients, the traditional disease prediction methods are facing an enormous challenge. How to find a reliable disease prediction method in the uncertain environment and improve the accuracy of prediction will be a valuable scientific problem. To obtain accurate prediction and help patients reduce medical costs, this paper introduces neighborhood rough set into multivariate variational mode decomposition , and proposes a new multi-attribute prediction approach. Firstly, to avoid the interference of redundant attributes, a multi-attribute reduction method based on neighborhood rough set is established. Then, to reduce the volatility and complexity of multi-attribute data in hybrid information system, a neighborhood rough set-based multivariable variational mode decomposition method is constructed. Subsequently, a predictor of extreme learning machine with kernel function , clearly defining the mapping relationship, is developed. Furthermore, Diebold–Mariano (DM) test and probability density distribution are used to evaluate the prediction results. Finally, 2041 random physical examination samples of potential gout patients are utilized to verify the effectiveness and practicability of the proposed approach. Experimental results show that the neighborhood rough set-based multi-attribute prediction approach has high accuracy and stability. Meanwhile, a new quantitative theory and method for chronic disease management decision-making can be provided in medical decision-making.},
  archive      = {J_ASOC},
  author       = {Juncheng Bai and Bingzhen Sun and Xiaoli Chu and Ting Wang and Hongtao Li and Qingchun Huang},
  doi          = {10.1016/j.asoc.2021.108127},
  journal      = {Applied Soft Computing},
  pages        = {108127},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Neighborhood rough set-based multi-attribute prediction approach and its application of gout patients},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Removal of self co-articulation and recognition of dynamic
hand gestures using deep architectures. <em>ASOC</em>, <em>114</em>,
108122. (<a href="https://doi.org/10.1016/j.asoc.2021.108122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural gesticulation in-air is multifaceted, as defining a gesture’s pattern/size/speed or its stroke information is difficult. The unavailability of vision-based techniques to distinguish the ground truth stroke segments and the intentional movements (self co-articulation) results in capturing everything on the trajectory. But recognizing the gesture patterns (A–Z, a–z, 0–9, 04 operators, and 29 symbols) along with their self co-articulations results in the rise of misclassification . Hence, gestures are separated into 3 sets based on their physical structures using an artificial neural network . Then, set specific pre-processing models are proposed to remove these self co-articulations. As a result, a mean error rate of 0.0112 (ground truth segment removed) and 5.63\% of self co-articulations present in the gesture patterns is obtained. A relative improvement of 22\% (accuracy — 94.17\%) over the existing models is achieved. Then, gestures are clustered into two groups by Mamdani fuzzy interference system using prior stroke information. Using transfer learning , separate pre-trained AlexNet models were utilized to recognize the gesture patterns falling under each group with an average accuracy of 97.05\% (precision — 0.9680, recall — 0.9656; F-score — 0.9668). This is a relative improvement of ∼ ∼ 17\% over the existing state-of-the-art models in gesture recognition .},
  archive      = {J_ASOC},
  author       = {Anish Monsley K. and Kuldeep Singh Yadav and Songhita Misra and Rabul Hussain Laskar and Taimoor Khan and M.K. Bhuyan},
  doi          = {10.1016/j.asoc.2021.108122},
  journal      = {Applied Soft Computing},
  pages        = {108122},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Removal of self co-articulation and recognition of dynamic hand gestures using deep architectures},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modeling the factors affecting unsafe behaviors using the
fuzzy best–worst​ method and fuzzy cognitive map. <em>ASOC</em>,
<em>114</em>, 108119. (<a
href="https://doi.org/10.1016/j.asoc.2021.108119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prevention of Unsafe Behaviors (UBs) requires a deep understanding of their root causes and motivations. Therefore, the present study aimed at modeling the factors affecting UBs using the best–worst (FBWM) and Fuzzy Cognitive Map (FCM) methods. The present study consisted of three parts: identifying the factors affecting UBs using content analysis, weighing the factors using the FBWM , and examining the relationships between the factors using the FCM. The first part of the study included semi-structured interviews with 40 workers and safety and health professionals, and the second and third parts were completed with an expert panel. Based on the results, the factors affecting UBs were classified into three categories, namely organizational, individual, and socio-economic factors. The results of weighing the factors showed that among the organizational factors (with a mean weight of 0.36), organizational safety culture was the most important factor. In addition, community safety culture among the socio-economic factors and personality traits among the individual factors were considered significant by the experts. The results of the FCM also showed that management’s attitude towards safety, internal monitoring, training, and organization’s tendency to UBs were the most centralized factors in the map. Overall, management’s attitude towards safety was one of the important factors affecting UBs. The centrality of this factor was high, as well. Hence, by changing the management’s attitude towards safety, the underlying factors of UBs could be controlled and guided for controlling such behaviors.},
  archive      = {J_ASOC},
  author       = {Mahdi Malakoutikhah and Moslem Alimohammadlou and Mehdi Jahangiri and Hadiseh Rabiei and Seyed Aliakbar Faghihi and Mojtaba Kamalinia},
  doi          = {10.1016/j.asoc.2021.108119},
  journal      = {Applied Soft Computing},
  pages        = {108119},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Modeling the factors affecting unsafe behaviors using the fuzzy best–worst​ method and fuzzy cognitive map},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TCRAN: Multivariate time series classification using
residual channel attention networks with time correction. <em>ASOC</em>,
<em>114</em>, 108117. (<a
href="https://doi.org/10.1016/j.asoc.2021.108117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, the most popular and effective approach to solve multivariate time series classification(MTSC) tasks is based on deep learning technology. However, the existing deep learning-based algorithms ignore the unique time characteristics of time series in the process of network training, and do not consider the features correlation in different convolutional layers . So they cannot obtain the convincing feature representation ability and result in unsatisfactory classification accuracy . To solve this problem, we propose a new time corrected residual attention network(TCRAN) which can fully extract the long-term time-dependence information to enhance the discriminative power of the network. The hallmark of TCRAN is that we employ the time residual channel attention block(TRCAB) as the basic structure, which incorporates the adaptive channel feature adjustment mechanism(AFM) and the bi-directional gated recurrent unit(Bi-GRU) into the deep residual structure to adaptively extract time-dependent features. Meanwhile, to integrate the overall dependency information between different layers, we also employ an inter-module adaptive feature adjustment mechanism(IAM) in the TCRAN. The experiments results with 15 multivariate time series datasets illustrate that the proposed TCRAN can achieve the highest average classification accuracy of 0.7276 and improve accuracy by 1.64\% compared to the state-of-the-art method. All these verify the effectiveness of TCRAN.},
  archive      = {J_ASOC},
  author       = {Hegui Zhu and Jiapeng Zhang and Hao Cui and Kai Wang and Qingsong Tang},
  doi          = {10.1016/j.asoc.2021.108117},
  journal      = {Applied Soft Computing},
  pages        = {108117},
  shortjournal = {Appl. Soft. Comput.},
  title        = {TCRAN: Multivariate time series classification using residual channel attention networks with time correction},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PSO-based power-driven x-routing algorithm in semiconductor
design for predictive intelligence of IoT applications. <em>ASOC</em>,
<em>114</em>, 108114. (<a
href="https://doi.org/10.1016/j.asoc.2021.108114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the Internet of Things (IoT) becomes more and more intelligent, a new computing paradigm , predictive intelligence is incorporated into many IoT applications. The devices of predictive intelligence in IoT applications must consider the power and delay consumption. As the Power-Driven X-Routing (PDXR) problem model under the advanced semiconductor design, the length-restricted condition in the multi-dynamic voltage model is introduced to save power consumption and the X-architecture is introduced to better reduce the wirelength to optimize the chip delay. To this end, an effective particle swarm optimization-based power-driven length-restricted X-routing algorithm is proposed for predictive intelligence in IoT applications. Firstly, a pre-calculated lookup table is designed to provide fast information query for the subsequent algorithm flow. Secondly, an improved particle swarm optimization algorithm is presented for the discrete PDXR problem. Thirdly, in the adjustment phase, the choice of intermediate nodes is expanded, and is no longer limited to the corner points of obstacles. Fourthly, a removal strategy of redundant points is proposed to optimize the routing path . Finally, the wirelength is further reduced by a local topology optimization strategy. The experimental results show that the proposed algorithm can achieve the best wirelength cost at a very fast speed under the constraint of restricted wirelength, so as to better satisfy the demand of the power and delay performance of semiconductor design for predictive intelligence in IoT applications.},
  archive      = {J_ASOC},
  author       = {Genggeng Liu and Yuhan Zhu and Saijuan Xu and Yeh-Cheng Chen and Hao Tang},
  doi          = {10.1016/j.asoc.2021.108114},
  journal      = {Applied Soft Computing},
  pages        = {108114},
  shortjournal = {Appl. Soft. Comput.},
  title        = {PSO-based power-driven X-routing algorithm in semiconductor design for predictive intelligence of IoT applications},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-adaptive multi-objective differential evolution
algorithm with first front elitism for optimizing network usage in
networked control systems. <em>ASOC</em>, <em>114</em>, 108112. (<a
href="https://doi.org/10.1016/j.asoc.2021.108112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In networked control systems , by means of event-triggered transmission, it is possible to reduce the network usage, keeping the control system performance at satisfactory levels. There are several schemes for event-triggered transmission. In this study, we propose a multi-objective optimization problem to tune the event-triggered mechanisms. On solving the proposed problem by means of multi-objective evolutionary optimization, a set of efficient solutions is generated with different tradeoffs between control system performance and the number of transmissions. To solve the proposed problem, we also developed an improved multi-objective differential evolution algorithm that includes a self-adaptive mechanism, dynamic crowding distance operator, and novel elitism of the first front. The proposed method is applied to tune decentralized event-triggered mechanisms for a controller given a priori , considering random network-induced delays and packet loss . Two case studies are present ed, comparing the performance of eight different decentralized event-triggered schemes, analyzing the selection of the sampling period, and demonstrating the efficacy of the proposed tuning method.},
  archive      = {J_ASOC},
  author       = {Eduardo Nunes Gonçalves and Mateus Alves Ribeiro Belo and Ana Paula Batista},
  doi          = {10.1016/j.asoc.2021.108112},
  journal      = {Applied Soft Computing},
  pages        = {108112},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Self-adaptive multi-objective differential evolution algorithm with first front elitism for optimizing network usage in networked control systems},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Daily PM2.5 and PM10 forecasting using linear and nonlinear
modeling framework based on robust local mean decomposition and moving
window ensemble strategy. <em>ASOC</em>, <em>114</em>, 108110. (<a
href="https://doi.org/10.1016/j.asoc.2021.108110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Highly accurate forecasting of particulate matter concentration (PMC) is essential and effective for establishing a reliable air pollution early warning system and has both theoretical and practical significance. To meet this demand, a novel multi-scale hybrid learning framework based on robust local mean decomposition (RLMD) and moving window (MW) ensemble strategy is developed for PM 2.5 2.5 and PM 10 forecasting. In this architecture, the RLMD is adopted to adaptively decompose the PMC time series (PMCTS) into several production functions and one residue with different frequencies. These subseries are simpler than the original PMCTS, but they still work alongside mode aliasing . Thus, following the well-established “linear and nonlinear” modeling philosophy, a novel hybrid learning framework, composed of the autoregressive integrated moving average (ARIMA) and combined kernel function relevance vector machine (RVM c o m com ), is proposed to capture both the linear and nonlinear patterns in the subseries. To obtain better final outputs, based on the definition of the ensemble improvement degree, the MW ensemble method is used to merge the forecasting results of all subseries. A comprehensive experiment is conducted using PM 2.5 2.5 and PM 10 datasets from four municipalities in China to investigate the forecasting performance of our proposed framework, and the results demonstrate that our proposed RLMD-ARIMA–RVM c o m com -MW (R-A&amp;R c o m com -M) model is superior to other considered methods in terms of forecasting accuracy and generalization ability . This means that the developed forecasting architecture has a great application value in the field of PMCTS prediction.},
  archive      = {J_ASOC},
  author       = {Zicheng Wang and Huayou Chen and Jiaming Zhu and Zhenni Ding},
  doi          = {10.1016/j.asoc.2021.108110},
  journal      = {Applied Soft Computing},
  pages        = {108110},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Daily PM2.5 and PM10 forecasting using linear and nonlinear modeling framework based on robust local mean decomposition and moving window ensemble strategy},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stock market forecasting using a multi-task approach
integrating long short-term memory and the random forest framework.
<em>ASOC</em>, <em>114</em>, 108106. (<a
href="https://doi.org/10.1016/j.asoc.2021.108106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous studies have adopted deep learning (DL) in financial market forecasting models owing to its superior performance. The DL models require as many relevant input variables as possible to improve performance because they learn high-level features from these inputs. However, as the number of input variables increases, the number of parameters also increases, leaving the model prone to overfitting. We propose a novel stock-market prediction framework (LSTM–Forest) integrating long short-term memory and random forest (RF) to address this issue. We also develop a multi-task model that predicts stock market returns and classifies return directions to improve predictability and profitability. Our model is interpretable because it can identify key variables using the variable importance analysis from RF. We used three global stock indices and 43 financial technical indicators to verify the proposed methods experimentally. The root mean squared errors of LSTM–Forest with multi-task (LFM) in predicting returns from S&amp;P500, SSE, and KOSPI200 were 25.53\%, 22.75\%, and 16.29\% lower, respectively, than those of the baseline RF model. The model’s balanced accuracy in forecasting the daily return direction increased by 7.37, 1.68, and 3.79 points, respectively. Furthermore, our multi-task model outperforms our single-task model and previous DL approaches. In the trading test, LFM produced the highest profits—even compared with the long-only strategy when transaction costs were considered. The proposed framework is readily extensible to other tasks and fields that contend with high-dimensionality problems.},
  archive      = {J_ASOC},
  author       = {Hyun Jun Park and Youngjun Kim and Ha Young Kim},
  doi          = {10.1016/j.asoc.2021.108106},
  journal      = {Applied Soft Computing},
  pages        = {108106},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Stock market forecasting using a multi-task approach integrating long short-term memory and the random forest framework},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-period portfolio selection under the coherent fuzzy
environment with dynamic risk-tolerance and expected-return levels.
<em>ASOC</em>, <em>114</em>, 108104. (<a
href="https://doi.org/10.1016/j.asoc.2021.108104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We discuss the portfolio selection problems in which the uncertainty of future returns and the heterogeneity of investor attitudes towards the stock market (optimistic–pessimistic–neutral) are captured by coherent fuzzy numbers. Two coherent fuzzy multi-period portfolio selection models are developed from the perspectives of wealth maximization and risk minimization . Given that the constraint levels regarding risk and return of the current period tend to be influenced by the outcome of the previous period, the dynamic risk-tolerance and expected-return levels are integrated into the portfolio modeling. Practical constraints and transaction costs are also taken into account, which enables the models more effective and lifelike in simulating the real-world trading of the stock market. The empirical studies based on two large data sets are presented to illustrate the applicability of the proposed models. To survey the models’ performance, several portfolio evaluation criteria are used to conduct out-of-sample analysis. The results show outstanding performance of the presented models with dynamic strategies over conventional ways (static risk-tolerance and expected-return levels) on most of the indicators. This research offers references for investors with different attitudes to make long-term investment decisions, and is an effective supplement to behavioral portfolio selection research based on bounded rationality under uncertainty.},
  archive      = {J_ASOC},
  author       = {Xiaomin Gong and Liangyu Min and Changrui Yu},
  doi          = {10.1016/j.asoc.2021.108104},
  journal      = {Applied Soft Computing},
  pages        = {108104},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-period portfolio selection under the coherent fuzzy environment with dynamic risk-tolerance and expected-return levels},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Information fusion oriented heterogeneous social network for
friend recommendation via community detection. <em>ASOC</em>,
<em>114</em>, 108103. (<a
href="https://doi.org/10.1016/j.asoc.2021.108103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid advance of online social networks and the tremendous growth in the number of participants and attention have led to information overload and increased the difficulty of making accurate recommendations of new friends. Existing recommendation methods based on semantic similarity , social graphs, or collaborative filtering are unsuitable for very large social networks because of their high computational cost or low effectiveness. We present an approach entitled H ybrid R ecommendation T hrough C ommunity D etection (HRTCD) for friend prediction with linear runtime complexity that makes full use of the characteristics of social media based on hybrid information fusion. It extracts the content topics of microblog for each participant along with the appraisal of domain-dependent user impact, builds a small-size heterogeneous network for each target user by fusing the interest similarity and social interaction between individuals, discovers all of the implicit clusters of target user via a community detection algorithm , and establishes the recommendation set consisting of a fixed number of potential friends. Experimental results on both the synthetic and real-world social networks demonstrate that our scheme provides a higher prediction rating and significantly improves the recommendation accuracy and offers much faster performance.},
  archive      = {J_ASOC},
  author       = {Mingqing Huang and Qingshan Jiang and Qiang Qu and Lifei Chen and Hui Chen},
  doi          = {10.1016/j.asoc.2021.108103},
  journal      = {Applied Soft Computing},
  pages        = {108103},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Information fusion oriented heterogeneous social network for friend recommendation via community detection},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimum aeroelastic control via iterative neural network
training for wind-resistant cyber–physical buildings. <em>ASOC</em>,
<em>114</em>, 108100. (<a
href="https://doi.org/10.1016/j.asoc.2021.108100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research presents iterative optimum training (IOT), which integrates deep neural networks (DNNs) and population-based optimization techniques such as genetic algorithms (GAs). The proposed technique reduces the number of experiments needed for training without adding complexity compared with non-iterative DNN-GA techniques commonly used in the literature. In this work, IOT is used to train an optimal controller for minimizing wind-induced vibration (WIV) using distributed aerodynamic actuators. Wind tunnel experiments of a scaled cyber–physical aeroelastic building model are used to demonstrate a novel application of the technique. IOT trains a DNN to approximate building vibration at different wind conditions and actuator orientations using an initial set of experiments. After this initial training, a GA uses the DNN to predict actuator orientations that minimize WIV for the given wind condition. A group containing best orientations from the GA and uniform random orientations is used to perform additional experiments and training of the DNN to enhance exploitation and exploration. This process is repeated until the stopping criteria is achieved. This paper includes results of a benchmark study comparing IOT to GA and DNN-GA techniques. Experimental results show that IOT-based online control of the aeroelastic model reduces WIV acceleration amplitudes by up to 90\% within 9.8 s upon controller activation.},
  archive      = {J_ASOC},
  author       = {Khalid M. Abdelaziz and Jared D. Hobeck},
  doi          = {10.1016/j.asoc.2021.108100},
  journal      = {Applied Soft Computing},
  pages        = {108100},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Optimum aeroelastic control via iterative neural network training for wind-resistant cyber–physical buildings},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Solving interval many-objective optimization problems by
combination of NSGA-III and a local fruit fly optimization algorithm.
<em>ASOC</em>, <em>114</em>, 108096. (<a
href="https://doi.org/10.1016/j.asoc.2021.108096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval many-objective optimization problems (IMaOPS) are ubiquitous in practical applications. Therefore, it is of great significance to study the solving method for IMaOPS. However, there are fewer solving methods due to the uncertain interval of the objective function. In this paper, an improved NSGA-III algorithm (named LFOA-NSGA-III) is proposed to effectively solve these problems. Due to the uncertain interval in the IMaOPs, the original NSGA-III algorithm can ineffectively evaluate the relationship between the interval solution set and the reference point. So the matter-element extension model is introduced, which can make the optimized solution set close to the Pareto optimal solution . Furthermore, in order to improve the optimization performance and population diversity of the improved algorithm, the K-mean algorithm is used to solve the initial solution set, as well as a local fruit fly optimization algorithm (FOA) is combined with the genetic algorithm (GA). Finally, the LFOA-NSGA-III algorithm is empirically evaluated on eleven interval benchmark test problems and an unmanned aerial vehicles (UAVs) path planning problem . Through simulation comparisons with other different algorithms, it is concluded that the hyper-volume value, the imprecision value and the IGD value indicators are significantly better than other comparison algorithms. In addition, from a simulation experiment in application of the multi-UAVs path planning problem , it can be seen that the LFOA-NSGA-III algorithm is more effective and applicative in the IMaOPs.},
  archive      = {J_ASOC},
  author       = {Fawei Ge and Kun Li and Ying Han},
  doi          = {10.1016/j.asoc.2021.108096},
  journal      = {Applied Soft Computing},
  pages        = {108096},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Solving interval many-objective optimization problems by combination of NSGA-III and a local fruit fly optimization algorithm},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An optimized fuzzy ensemble of convolutional neural networks
for detecting tuberculosis from chest x-ray images. <em>ASOC</em>,
<em>114</em>, 108094. (<a
href="https://doi.org/10.1016/j.asoc.2021.108094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early detection of Tuberculosis or TB can help in mitigating the chances of affecting the other body parts like the kidney, spine and brain, thereby reducing the death rate due to this disease. However, manual diagnosis by radiologists using Chest X-rays may include human error. Therefore, researchers have been trying hard to develop a computerized decision support system for efficient detection of TB from Chest X-ray images. In this work, we have proposed a model for screening TB using Chest X-ray images where the decisions from three base learners are combined using the type-1 Sugeno fuzzy integral based ensemble technique. Fuzzy measures required in this fuzzy integral based ensemble method are set experimentally in many state-of-the-art works. To overcome such manual tuning, we have used meta-heuristic optimization algorithms to set the fuzzy measures optimally during the training process of the model. The performance of the ensemble technique on the validation set is considered as the decider of the optimal fuzzy measures. Before applying the ensemble method we have extracted features from images using three state-of-the-art deep learning models, namely DenseNet121, VGG19 and ResNet50 pre-trained on imageNet dataset. With the above pre-trained models, the base learners are built using additional fully connected and softmax layers. We have evaluated the present work on a new and publicly available TB dataset consisting of Chest X-ray images. The obtained results (irrespective of the optimizer used) confirm that our method has outperformed state-of-the-art methods used for TB classification.},
  archive      = {J_ASOC},
  author       = {Subhrajit Dey and Rajarshi Roychoudhury and Samir Malakar and Ram Sarkar},
  doi          = {10.1016/j.asoc.2021.108094},
  journal      = {Applied Soft Computing},
  pages        = {108094},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An optimized fuzzy ensemble of convolutional neural networks for detecting tuberculosis from chest X-ray images},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Gaussian mixture deep dynamic latent variable model with
application to soft sensing for multimode industrial processes.
<em>ASOC</em>, <em>114</em>, 108092. (<a
href="https://doi.org/10.1016/j.asoc.2021.108092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The data-driven deep probabilistic latent variable model (DPLVM) has attracted much attention for industrial process soft sensing in recent years. The DPLVM has well handled the nonlinear characteristics of the processes with powerful feature extracting capability. However, the multimode process property and the dynamic data features seldom be considered in those applications. To tackle the two issues, the article starts from the basic DPLVM, i.e., the Variational Autoencoder (VAE), to build a deep dynamic latent variable regression model (i.e., the Gated Recurrent Unit-based VAE regression, GVAER), where GRU cells are utilized to capture dynamic features from the process time sequence data. With the GVAER, a Gaussian Mixture GVAER (GM-GVAER) model is proposed. The Gaussian Mixture priors are used in the latent space to characterize the multimode process data features . In particular, a semi-supervised learning scheme is also proposed for the model to deal with the unequal scale of input and output data. A numerical example and a real chemical process case are provided to verify the feasibility and effectiveness of the proposed soft sensor model.},
  archive      = {J_ASOC},
  author       = {Jingyun Xu and Zhiduan Cai},
  doi          = {10.1016/j.asoc.2021.108092},
  journal      = {Applied Soft Computing},
  pages        = {108092},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Gaussian mixture deep dynamic latent variable model with application to soft sensing for multimode industrial processes},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid approach for forecasting ship motion using
CNN–GRU–AM and GCWOA. <em>ASOC</em>, <em>114</em>, 108084. (<a
href="https://doi.org/10.1016/j.asoc.2021.108084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The motion of a ship, which has six degrees of freedom, is a complex nonlinear dynamic process with variable periodicity and chaotic characteristics. With the development of smart ships, modern high-precision equipment needs the help from high accuracy of ship motion (SHM) forecasting. Existing models will not easily be able to satisfy future accuracy requirements. Therefore, to improve the accuracy of SHM forecasts, by firstly determining the sequence features of SHM time series, a convolutional neural network (CNN) was used herein to extract automatically spatial feature vectors. Considering the variable-period characteristics of SHM time series, a gated recurrent unit (GRU) was used to learn the inherent time characteristics and to extract temporal feature vectors. The attention mechanism (AM) was developed to control the effect of feature vectors on the output to solve the problem of the contribution of feature vectors. Integrating the above methods, an SHM hybrid forecasting model, the SHM CNN–GRU–AM (SHM-C&amp;G&amp;A) model, was established. Secondly, in view of the difficulty of selecting the hyperparameters of a hybrid model, on account of the defects of the whale optimization algorithm (WOA), a normal cloud local search (NCLS) algorithm was developed. Exploiting the advantages of the normal cloud search (NCS) and the genetic algorithm (GA), a genetic random global search (GRGS) algorithm was developed. Then, a hybrid genetic cloud whale optimization algorithm (GCWOA) was developed and used to optimize the hyperparameters of the SHM-C&amp;G&amp;A model. Accordingly, a hybrid forecasting approach that integrates SHM-C&amp;G&amp;A and GCWOA was proposed; it is referred to as GCWOA-SHM-C&amp;G&amp;A. Finally, ship heave and pitch time series data are used to analyze an example to test the forecasting effectiveness of SHM-C&amp;G&amp;A and the optimization performance of GCWOA. The experimental results reveal that the proposed SHM-C&amp;G&amp;A model is more robust that the other models that are considered in this paper, and exhibits better nonlinear characteristics. The proposed GCWOA yields a better combination of hyperparameters than contrast algorithms in the forecasting process.},
  archive      = {J_ASOC},
  author       = {Ming-Wei Li and Dong-Yang Xu and Jing Geng and Wei-Chiang Hong},
  doi          = {10.1016/j.asoc.2021.108084},
  journal      = {Applied Soft Computing},
  pages        = {108084},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A hybrid approach for forecasting ship motion using CNN–GRU–AM and GCWOA},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Relations and compositions between interval-valued complex
fuzzy sets and applications for analysis of customers’ online shopping
preferences and behavior. <em>ASOC</em>, <em>114</em>, 108082. (<a
href="https://doi.org/10.1016/j.asoc.2021.108082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analyzing the relations and patterns that exist in complex data sets is an integral part of the research in complex fuzzy set theory . The main object of study in this paper is the interval-valued complex fuzzy set (IV-CFS) model. This adaptation of complex fuzzy sets can handle datasets with a time-periodic feature, and the partial ignorance that exists in the data as well as the process of assigning values for the membership functions, in addition to modeling multi-dimensional data. This paper focuses on finding the patterns and relations between complex data sets using the properties of interval-valued complex fuzzy sets (IV-CFSs). To achieve this objective, this paper establishes the concept of relations and the composition operation for IV-CFSs using the extensive properties of the Cartesian product . Some of the algebraic properties of the relations and compositions are also introduced to define the equivalence relation between IV-CFSs. The proposed method is then applied to an MCDM problem related to customers’ online shopping preferences and behavior. A detailed case study of this MCDM problem is then presented through the interpretation of the results that were obtained. A brief comparison is then presented between our proposed method and other methods in literature used to analyze patterns between complex data sets.},
  archive      = {J_ASOC},
  author       = {Ganeshsree Selvachandran and Shio Gai Quek and Le Hoang Son and Pham Huy Thong and Bay Vo and Tahani A. Abdusalam Hawari and Abdul Razak Salleh},
  doi          = {10.1016/j.asoc.2021.108082},
  journal      = {Applied Soft Computing},
  pages        = {108082},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Relations and compositions between interval-valued complex fuzzy sets and applications for analysis of customers’ online shopping preferences and behavior},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial neural networks in drought prediction in the 21st
century–a scientometric analysis. <em>ASOC</em>, <em>114</em>, 108080.
(<a href="https://doi.org/10.1016/j.asoc.2021.108080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Droughts are the most spatially complex geohazard, which often lasts for years, thereby severely impacting socio-economic sectors. One of the critical aspects of drought studies is developing a reliable and robust forecasting model, which could immensely help drought management planners in adopting adequate measures. Further, the prediction of drought events are extremely challenging due to the involvement of several hydro-meteorological factors, which are further aggravated by the effect of climate change. Among the several techniques such as statistical, physical and data-driven that are used to forecast droughts, artificial neural networks provide one of the most robust approach. As droughts are inherently non-linear and multivariate in nature, the capability of neural networks to capture the dynamic relationship easily and efficiently has seen a rise in its use. Here we evaluate the most used architectures in the last two decades, using scientometric analysis. A general framework used in drought prediction studies is explained and examples from various continents are provided, thus exploring the topic in a global context. The findings show that using sophisticated input representation, the artificial intelligence-based solutions applied to drought prediction of hydro-meteorological variables have promising success, particularly in complex geographical scenarios. The future works need to focus on interpretable models, use of deep learning architectures for long lead time forecasting and use of neural networks to predict different drought characteristics like drought propagation and flash droughts. We also summarize the most widely used neural network approaches in spatial drought prediction, which would serve as a foundation for future research in drought prediction studies.},
  archive      = {J_ASOC},
  author       = {Abhirup Dikshit and Biswajeet Pradhan and M. Santosh},
  doi          = {10.1016/j.asoc.2021.108080},
  journal      = {Applied Soft Computing},
  pages        = {108080},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Artificial neural networks in drought prediction in the 21st century–A scientometric analysis},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-period multi-product green supply network design
problem with price and greenness dependent demands under uncertainty.
<em>ASOC</em>, <em>114</em>, 108078. (<a
href="https://doi.org/10.1016/j.asoc.2021.108078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Governmental limitations and customer expectations have increased the focus on sustainability in supply chain network design (SCND). To address this issue, a bi-objective mixed-integer mathematical model is introduced with the aim of simultaneously maximizing supply chain profit and minimizing overall carbon emissions. Additionally, customer demands are considered price- and greenness-sensitive for multiple products, and uncertainty in the production process is estimated by a finite number of scenarios. The Monte Carlo sampling approach is used to produce the initial scenarios, and a heuristic scenario reduction approach is subsequently utilized. Due to the complexity of the model, we develop a hybrid metaheuristic algorithm that embeds variable neighborhood search (VNS) in two genetic algorithms to accelerate the convergence of the algorithm to high-quality solutions. These algorithms are compared to multi-objective particle swarm optimization (MOPSO) with two leader selection procedures. To improve the performance of these algorithms, the response surface method is applied to modulate the algorithm parameters. Finally, several analyses are performed to investigate the efficiency and effectiveness of the proposed approach.},
  archive      = {J_ASOC},
  author       = {Jian Wang and Qian Wan},
  doi          = {10.1016/j.asoc.2021.108078},
  journal      = {Applied Soft Computing},
  pages        = {108078},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-period multi-product green supply network design problem with price and greenness dependent demands under uncertainty},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interval type-2 hesitant fuzzy entropy-based WASPAS approach
for aircraft type selection. <em>ASOC</em>, <em>114</em>, 108076. (<a
href="https://doi.org/10.1016/j.asoc.2021.108076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Choosing the most appropriate aircraft type for a given route is one of the crucial issues that the decision makers at airline companies have to address under uncertainty based on various commercial, marketing and operational criteria. A novel multi-criteria decision making approach integrating Entropy-based Weighted Aggregated Sum Product Assessment (WASPAS) method and interval type-2 hesitant fuzzy sets (IT2HFS) is introduced for tackling this problem and tested using a particular case study obtained from a full service carrier in Turkey. This study contributes to representing and handling degrees of uncertainty in the decision making process of aircraft type selection based on the IT2HFS. The results showed that Airbus 32C is the suitable alternative for a given route in between Kuwait and Istanbul airports . The experts evaluated the results and confirmed that the proposed approach is the most suitable one when compared to four other IT2HFS based approaches.},
  archive      = {J_ASOC},
  author       = {Muhammet Deveci and Sultan Ceren Öner and Muharrem Enis Ciftci and Ender Özcan and Dragan Pamucar},
  doi          = {10.1016/j.asoc.2021.108076},
  journal      = {Applied Soft Computing},
  pages        = {108076},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Interval type-2 hesitant fuzzy entropy-based WASPAS approach for aircraft type selection},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards robust partially supervised multi-structure medical
image segmentation on small-scale data. <em>ASOC</em>, <em>114</em>,
108074. (<a href="https://doi.org/10.1016/j.asoc.2021.108074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The data-driven nature of deep learning (DL) models for semantic segmentation requires a large number of pixel-level annotations. However, large-scale and fully labeled medical datasets are often unavailable for practical tasks. Recently, partially supervised methods have been proposed to utilize images with incomplete labels in the medical domain. To bridge the methodological gaps in partially supervised learning (PSL) under data scarcity, we propose Vicinal Labels Under Uncertainty (VLUU), a simple yet efficient framework utilizing the human structure similarity for partially supervised medical image segmentation. Motivated by multi-task learning and vicinal risk minimization, VLUU transforms the partially supervised problem into a fully supervised problem by generating vicinal labels. We systematically evaluate VLUU under the challenges of small-scale data, dataset shift, and class imbalance on two commonly used segmentation datasets for the tasks of chest organ segmentation and optic disc-and-cup segmentation. The experimental results show that VLUU can consistently outperform previous partially supervised models in these settings. Our research suggests a new research direction in label-efficient deep learning with partial supervision.},
  archive      = {J_ASOC},
  author       = {Nanqing Dong and Michael Kampffmeyer and Xiaodan Liang and Min Xu and Irina Voiculescu and Eric Xing},
  doi          = {10.1016/j.asoc.2021.108074},
  journal      = {Applied Soft Computing},
  pages        = {108074},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Towards robust partially supervised multi-structure medical image segmentation on small-scale data},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cooperative relay spectrum sensing for cognitive radio
network: Mutated MWOA-SNN approach. <em>ASOC</em>, <em>114</em>, 108072.
(<a href="https://doi.org/10.1016/j.asoc.2021.108072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spectrum overcrowding is one of the prime issues faced by wireless telecommunication based applications. The network blockage causing the disconnection or call drops is another important concern. These problems, are needed to be addressed for implementing the 5G and beyond technologies. Therefore, to tackle the issues of spectrum overcrowding and network blockage simultaneously a Cognitive Radio (CR) technology based relay network is proposed in this work. The accurate detection of the primary user’s signal by the cognitive radio users is the most integral functioning of the cognitive radio networks . The existing spectrum sensing using Deep Neural Network (DNN) and Convolutional Neural Network (CNN) techniques have their limitations concerned with accurate prediction and classification of vacant spectrum due to their tendency of getting jammed to the local optima. In this paper, we firstly propose a novel mutated Modified Whale Optimization Algorithm (MWOA) trained Spiking Neural Network (SNN) based spectrum sensing technique for the efficient detection of spectrum holes. Here, the weights of the SNN are trained by means of MWOA for efficiently predicting the spectrum holes. The proposed scheme exploits underlying structural information of the sensed signals via continuous wavelet transforms . The proposed scheme does not require any priori information about the channel state and is shown to achieve state of the art performance in the detection of spectrum holes. The simulation results have inferred that the proposed CR based relay model with the MWOA trained SNN based spectrum sensing has significantly improved the performance of the User Equipment (UE) in the network blockage area in terms of higher opportunistic throughput and lower BER (Bit Error Rate). The MWOA has proved to be an efficient training algorithm for SNN with the validation accuracy of 98\%.},
  archive      = {J_ASOC},
  author       = {Geoffrey Eappen and Shankar T and Rajagopal Nilavalan},
  doi          = {10.1016/j.asoc.2021.108072},
  journal      = {Applied Soft Computing},
  pages        = {108072},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Cooperative relay spectrum sensing for cognitive radio network: Mutated MWOA-SNN approach},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An information entropy-based evolutionary computation for
multi-factorial optimization. <em>ASOC</em>, <em>114</em>, 108071. (<a
href="https://doi.org/10.1016/j.asoc.2021.108071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, a new category of problems known as multi-factorial optimization (MFO) is gaining momentum in the field of evolutionary computation (EC). This paper aims at improving the aggregate performance of an underlying EC model in a multi-tasking environment by implementing simple strategies with minimal parameter tuning effort. Firstly, an enhanced Simulated Binary Crossover (SBX)-based unary variation operator to improve EC performance is devised. Secondly, to overcome the challenge in parameter tuning and operators selection, an adaptive control strategy underpinned by information entropy is proposed. We study the measure of entropy to quantify the uncertainty of evolutionary search and use the information to adapt the algorithmic parameters. Thirdly, the MFO problems are solved using the proposed methods. Three experiments are carried out to attest the methodology efficacy. The first experiment benchmarks the proposed method against twelve state-of-the-art single objective optimization algorithms in the CEC2014 competition. The second experiment compares the performance of the proposed method using a recent benchmark MFO problem. We further extend the investigation into the analysis of parameter sensitivity and solicit insights pertaining to the algorithm characteristics. Overall, the empirical results on various benchmark problems are promising. The third experiment offers a solution to a multi-mode resource-constrained project scheduling problem in the real-world construction industry. The results indicate improvements of 2.29\% in project quality and 8.23\% in project duration subject to an increase of 4.78\% in project cost, which are well within the acceptance limits of the decision makers .},
  archive      = {J_ASOC},
  author       = {Ting Yee Lim and Choo Jun Tan and Wai Peng Wong and Chee Peng Lim},
  doi          = {10.1016/j.asoc.2021.108071},
  journal      = {Applied Soft Computing},
  pages        = {108071},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An information entropy-based evolutionary computation for multi-factorial optimization},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adopting microservice architecture: A decision support model
based on genetically evolved multi-layer FCM. <em>ASOC</em>,
<em>114</em>, 108066. (<a
href="https://doi.org/10.1016/j.asoc.2021.108066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microservice architectures foster the development of applications as suites of small, autonomous and conversational services, which are then easy to understand, deploy and scale. However, one of the problems nowadays is that microservices introduce new complexities to the system and, despite the hype, many factors should be considered when deciding whether to use them or not. This paper introduces a novel decision and analysis model with enhanced interpretative and explanatory capabilities. The model is conceived by identifying the key concepts and factors in deciding whether to adopt microservice architectures, or not, through literature review and experts’ feedback from the industry and academia. These concepts are organized as a Multi-Layer Fuzzy Cognitive Map (MLFCM), a graph-based computational intelligent model. A new formulation is proposed, along with a novel genetically evolved algorithm, both aiming at improving the model in terms of performance, bias resilience and explainability. The model is evaluated and calibrated through a series of executions over real and synthetic scenarios. The application of static and dynamic analyses, in conjunction with the incorporation of the evolutionary approach, guide the identification of the prevailing factors that regulate the adoption of a microservice architecture and allow the interpretation of the importance of each concept. Finally, an industrial scenario leverages the assessment of the model’s applicability and efficacy, highlighting some interesting results.},
  archive      = {J_ASOC},
  author       = {Andreas Christoforou and Andreas S. Andreou and Martin Garriga and Luciano Baresi},
  doi          = {10.1016/j.asoc.2021.108066},
  journal      = {Applied Soft Computing},
  pages        = {108066},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Adopting microservice architecture: A decision support model based on genetically evolved multi-layer FCM},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive residual CNN-based fault detection and diagnosis
system of small modular reactors. <em>ASOC</em>, <em>114</em>, 108064.
(<a href="https://doi.org/10.1016/j.asoc.2021.108064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of Industry 4.0 technology, it is a popular trend to reduce maintenance costs and ensure the safety of novel nuclear systems combined with deep learning (DL) technology. In this paper, an intelligent fault detection and diagnosis system (IFDDS) based on designed adaptive residual convolutional neural networks (ARCNNs) for small modular reactors (SMRs) is proposed. The features under different noise levels are learned as the residual and passed through the designed networks. Additionally, the learning efficiency is enhanced by the soft threshold (ST) method assembled in the adaptive residual processing (ARP) module. The Bayesian optimization (BO) method is adopted to improve the learning decay rate (LDR) of designed networks for better diagnosis performance. A total of 1, 760 experimental data points under 11 different operation scenarios at three different noise levels are collected from the established Chinese lead-based nuclear reactor (CLEAR) platform to verify the effectiveness of the proposed IFDDS. The comparisons with the traditional RCNNs and CNNs adopted in previous works highlight the proposed diagnosis method’s superiority. The performance of IFDDS is further improved by using the BO method. The proposed method, as a maiden attempt of intelligence research for SMRs, will provide remote decision-making support for nuclear operators in unattended conditions. Moreover, the universal method can also be applied to other diagnosis systems under a noise environment.},
  archive      = {J_ASOC},
  author       = {Yuantao Yao and Jianye Wang and Min Xie},
  doi          = {10.1016/j.asoc.2021.108064},
  journal      = {Applied Soft Computing},
  pages        = {108064},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Adaptive residual CNN-based fault detection and diagnosis system of small modular reactors},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GA and GWO algorithm for the special bin packing problem
encountered in field of aircraft arrangement. <em>ASOC</em>,
<em>114</em>, 108060. (<a
href="https://doi.org/10.1016/j.asoc.2021.108060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a special case of irregular bin packing problem which the irregular pieces with free rotation have to fill a large irregular stock sheet with defective regions while satisfying the special boundary constraint, i.e., the piece can protrude from the sheet so long as the key points in the piece’s interior lie within the container. The objective of this problem is to maximize the number of filled pieces. To our best knowledge, the piece must be placed completely inside the sheet for all packing problem tackled by published literature. Thus, existing approaches are not good solutions to this special packing problem . To achieve the goal of automated arrangement of pieces and maximize the space utilization, the genetic algorithm and grey wolf optimization algorithm are designed to solve it. The genetic algorithm adopts the elitism strategy for maintaining the portion of the best chromosomes. A new method of updating the main controlling parameter is applied for reinforcing the exploration ability of the grey wolf optimization . These two algorithms use a vector of pieces as the solution representation, and a novel heuristic algorithm decodes it to produce a layout. The proposed heuristic algorithm divides the process of packing into two stages with the objective of satisfying constraints and achieving good space utilization of sheet. Computational experiments show that the presented methods can solve this new kind of the packing problem very well.},
  archive      = {J_ASOC},
  author       = {Qiang Luo and Yunqing Rao Ph.D and Deng Peng},
  doi          = {10.1016/j.asoc.2021.108060},
  journal      = {Applied Soft Computing},
  pages        = {108060},
  shortjournal = {Appl. Soft. Comput.},
  title        = {GA and GWO algorithm for the special bin packing problem encountered in field of aircraft arrangement},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An efficient ant colony optimization framework for HPC
environments. <em>ASOC</em>, <em>114</em>, 108058. (<a
href="https://doi.org/10.1016/j.asoc.2021.108058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combinatorial optimization problems arise in many disciplines, both in the basic sciences and in applied fields such as engineering and economics. One of the most popular combinatorial optimization methods is the Ant Colony Optimization (ACO) metaheuristic . Its parallel nature makes it especially attractive for implementation and execution in High Performance Computing (HPC) environments. Here we present a novel parallel ACO strategy making use of efficient asynchronous decentralized cooperative mechanisms. This strategy seeks to fulfill two objectives: (i) acceleration of the computations by performing the ants’ solution construction in parallel; (ii) convergence improvement through the stimulation of the diversification in the search and the cooperation between different colonies. The two main features of the proposal, decentralization and desynchronization, enable a more effective and efficient response in environments where resources are highly coupled. Examples of such infrastructures include both traditional HPC clusters, and also new distributed environments, such as cloud infrastructures, or even local computer networks. The proposal has been evaluated using the popular Traveling Salesman Problem (TSP), as a well-known NP-hard problem widely used in the literature to test combinatorial optimization methods. An exhaustive evaluation has been carried out using three medium and large size instances from the TSPLIB library, and the experiments show encouraging results with superlinear speedups compared to the sequential algorithm (e.g. speedups of 18 with 16 cores), and a very good scalability (experiments were performed with up to 384 cores improving execution time even at that scale).},
  archive      = {J_ASOC},
  author       = {Patricia González and Roberto R. Osorio and Xoan C. Pardo and Julio R. Banga and Ramón Doallo},
  doi          = {10.1016/j.asoc.2021.108058},
  journal      = {Applied Soft Computing},
  pages        = {108058},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An efficient ant colony optimization framework for HPC environments},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tabu search with simulated annealing for solving a
location–protection–disruption in hub network. <em>ASOC</em>,
<em>114</em>, 108056. (<a
href="https://doi.org/10.1016/j.asoc.2021.108056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, designing a reliable hub network has become a critical issue in the process of transporting goods from an origin to a destination. Due to intentional disasters, both location and protection of hub play a key role in satisfying the demands and ensuring network reliability. This study tries to model the impact of the number of hubs opened, allocation of defensive resources, and the risk of disruptions on the configuration of the hub network. This model aims is to minimize the total transportation cost via the primary and backup hubs subject to the installed hubs, allocation of defensive resources, and the risk of disruptions. The formulation with the location of hubs, allocation of protection budget, flow routing between two nodes in origin–destination via the primary and backup hubs, and hub failure probabilities have not been remarked in the literature. As the problem is an NP-hard, the performance of some metaheuristic algorithms called tabu search (TS), simulated annealing (SA), variable neighborhood search (VNS), imperialist competitive algorithm (ICA) and genetic algorithm (GA) is investigated to solve instances of problem with 50 nodes and 5, 10, and 15 hubs. Computational results show that the SA and TS algorithms are superior to existing metaheuristic methods to the novel problem based on solution accuracy and computational time, respectively. Additionally, this study presents a fast and robust hybrid approach that combines the advantages of TS and SA. The proposed algorithm has been successfully used to solve a large number of instances of this problem via sensitivity analysis and instances from the Turkish Postal data set. Several experimental results indicate the applicability of the new model and the advantage of the new hybrid method compared to other metaheuristic algorithms concerning decision and execution time.},
  archive      = {J_ASOC},
  author       = {Arun Kumar Sangaiah and Raheleh Khanduzi},
  doi          = {10.1016/j.asoc.2021.108056},
  journal      = {Applied Soft Computing},
  pages        = {108056},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Tabu search with simulated annealing for solving a location–protection–disruption in hub network},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Eagle strategy using uniform mutation and modified whale
optimization algorithm for QoS-aware cloud service composition.
<em>ASOC</em>, <em>114</em>, 108053. (<a
href="https://doi.org/10.1016/j.asoc.2021.108053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud manufacturing (CMfg) has received increasingly attention from both academia and industry. Cloud service composition is a critical technique in CMfg that connects different available manufacturing cloud services (MCSs) to generate a composite manufacturing cloud service (CMCS) to satisfy users’ requirements. Many available MCSs with the same or similar functionality but different QoS attributes are deployed in the CMfg platform. So it is challenging to obtain an optimal CMCS to satisfy the users’ complex requirements. Considerable numbers of approaches have been proposed to solve this problem. However, most of them often fall in a local optimum instead of the global one. In this paper, a novel eagle strategy using uniform Mutation and modified Whale Optimization Algorithm (MWOA) is proposed to maintain a balance between the global and local search abilities. In this approach, the uniform mutation is applied to perform the global search to preserve the diversification of the population, and a modified whale optimization algorithm is designed to perform the local search. The performance of the new approach is verified on various benchmark functions and different scales of QoS-aware cloud service composition problems . The experimental results demonstrate that the proposed MWOA has superior performance over the other methods.},
  archive      = {J_ASOC},
  author       = {Hong Jin and Shengping Lv and Zhou Yang and Ying Liu},
  doi          = {10.1016/j.asoc.2021.108053},
  journal      = {Applied Soft Computing},
  pages        = {108053},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Eagle strategy using uniform mutation and modified whale optimization algorithm for QoS-aware cloud service composition},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Application of a mixed variable physics-informed neural
network to solve the incompressible steady-state and transient mass,
momentum, and energy conservation equations for flow over in-line heated
tubes. <em>ASOC</em>, <em>114</em>, 108050. (<a
href="https://doi.org/10.1016/j.asoc.2021.108050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prohibitive cost and low fidelity of experimental data in industry-scale thermofluid systems limit the usefulness of pure data-driven machine learning methods. Physics-informed neural networks (PINN) strive to overcome this by embedding the physics equations in the construction of the neural network loss function. In the present paper, the mixed-variable PINN methodology is applied to develop steady-state and transient surrogate models of incompressible laminar flow with heat transfer through a 2D internal domain with obstructions. Automatic spatial and temporal differentiation is applied to the partial differential equations for mass, momentum and energy conservation, and the residuals are included in the loss function, together with the boundary and initial values. Good agreement is obtained between the PINN and CFD results for both the steady-state and transient cases, but normalization of the PDEs proves to be crucial. Although this proves the ability of the PINN approach to solve multiple physics-based PDEs on a single domain, the PINN takes significantly longer to solve than the traditional finite volume numerical methods utilized in commercial CFD software.},
  archive      = {J_ASOC},
  author       = {Ryno Laubscher and Pieter Rousseau},
  doi          = {10.1016/j.asoc.2021.108050},
  journal      = {Applied Soft Computing},
  pages        = {108050},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Application of a mixed variable physics-informed neural network to solve the incompressible steady-state and transient mass, momentum, and energy conservation equations for flow over in-line heated tubes},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A computational proposal for a robust estimation of the
pareto tail index: An application to emerging markets. <em>ASOC</em>,
<em>114</em>, 108048. (<a
href="https://doi.org/10.1016/j.asoc.2021.108048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we backtest and compare, under the VaR risk measure, the fitting performances of three classes of density distributions (Gaussian, Stable and Pareto) with respect to three different types of emerging markets: Egypt, Qatar and Mexico. We also propose a new technique for the estimation of the Pareto tail index by means of the Threshold Accepting (TAVaR) and the Hybrid Particle Swarm Optimization algorithm (H-PSOVaR). Furthermore, we test the accuracy and robustness of our estimates demonstrating the effectiveness of the proposed approach.},
  archive      = {J_ASOC},
  author       = {Joseph Andria},
  doi          = {10.1016/j.asoc.2021.108048},
  journal      = {Applied Soft Computing},
  pages        = {108048},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A computational proposal for a robust estimation of the pareto tail index: An application to emerging markets},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-objective optimal power flow with stochastic wind and
solar power. <em>ASOC</em>, <em>114</em>, 108045. (<a
href="https://doi.org/10.1016/j.asoc.2021.108045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classical optimal power flow problem is usually formulated with only thermal generators, in which the fuel used to generate power is limited and emissions from the network system are often ignored. Due to several promising features like renewability, richness, and cleanness, renewable energy sources have been drew growing attention. As a result, more and more renewable energy sources are penetrated into the electrical grid. In this paper, the standard IEEE-30 bus system is modified by integrating renewable energy sources as the case study, where the traditional thermal generators on buses 5 and 11 are replaced by wind generators, and bus 13 is replaced by solar generators. In addition, to address the intermittence and uncertainty of renewable sources, the Weibull probability density function is used to calculate the available wind power. Meanwhile, the lognormal probability density function is employed to calculate the available solar power. The optimal power flow with stochastic wind and solar energy is formulated as a multi-objective optimization problem. A multi-objective evolutionary algorithm based on non-dominated sorting with constraint handling technique are presented to solve it. In addition, another larger test system i.e., IEEE-57 bus system is selected to further verify the performance of the proposed approach in handling large dimensional problem. Simulation results indicate that proposed approach can obtain competitive compromise solution on different optimization objectives .},
  archive      = {J_ASOC},
  author       = {Shuijia Li and Wenyin Gong and Ling Wang and Qiong Gu},
  doi          = {10.1016/j.asoc.2021.108045},
  journal      = {Applied Soft Computing},
  pages        = {108045},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-objective optimal power flow with stochastic wind and solar power},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Komodo mlipir algorithm. <em>ASOC</em>, <em>114</em>,
108043. (<a href="https://doi.org/10.1016/j.asoc.2021.108043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes Komodo Mlipir Algorithm (KMA) as a new metaheuristic optimizer. It is inspired by two phenomena: the behavior of Komodo dragons living in the East Nusa Tenggara, Indonesia, and the Javanese gait named mlipir . Adopted the foraging and reproduction of Komodo dragons, the population of a few Komodo individuals (candidate solutions) in KMA are split into three groups based on their qualities: big males, female, and small males. First, the high-quality big males do a novel movement called high-exploitation low-exploration to produce better solutions. Next, the middle-quality female generates a better solution by either mating the highest-quality big male (exploitation) or doing parthenogenesis (exploration). Finally, the low-quality small males diversify candidate solutions using a novel movement called mlipir (a Javanese term defined as a walk on the side of the road to reach a particular destination safely), which is implemented by following the big males in a part of their dimensions. A self-adaptation of the population is also proposed to control the exploitation–exploration balance. An examination using the well-documented twenty-three benchmark functions shows that KMA outperforms the recent metaheuristic algorithms . Besides, it provides high scalability to optimize thousand-dimensional functions. The source code of KMA is publicly available at: https://suyanto.staff.telkomuniversity.ac.id/komodo-mlipir-algorithm and https://www.mathworks.com/matlabcentral/fileexchange/102514-komodo-mlipir-algorithm .},
  archive      = {J_ASOC},
  author       = {Suyanto Suyanto and Alifya Aisyah Ariyanto and Alifya Fatimah Ariyanto},
  doi          = {10.1016/j.asoc.2021.108043},
  journal      = {Applied Soft Computing},
  pages        = {108043},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Komodo mlipir algorithm},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Novel multi-site graph convolutional network with
supervision mechanism for COVID-19 diagnosis from x-ray radiographs.
<em>ASOC</em>, <em>114</em>, 108041. (<a
href="https://doi.org/10.1016/j.asoc.2021.108041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The novel Coronavirus disease 2019 (COVID-2019) has become a global pandemic and affected almost all aspects of our daily life. The total number of positive COVID-2019 cases has exponentially increased in the last few months due to the easy transmissibility of the virus. It can be detected using the nucleic acid test or the antibodies blood test which are not always available and take several hours to get the results. Therefore, researchers proposed computer-aided diagnosis systems using the state-of-the-art artificial intelligence techniques to learn imaging biomarkers from chest computed tomography and X-ray radiographs to effectively diagnose COVID-19. However, previous methods either adopted transfer learning from a pre-trained model on natural images or were trained on limited datasets. Either cases may lead to accuracy deficiency or overfitting. In addition, feature space suffers from noise and outliers when collecting X-ray images from multiple datasets. In this paper, we overcome the previous limitations by firstly collecting a large-scale X-ray dataset from multiple resources. Our dataset includes 11, 312 images collected from 10 different data repositories. To alleviate the effect of the noise, we suppress it in the feature space of our new dataset. Secondly, we introduce a supervision mechanism and combine it with the VGG-16 network to consider the differences between the COVID-19 and healthy cases in the feature space. Thirdly, we propose a multi-site (center) COVID-19 graph convolutional network (GCN) that exploits dataset information, the status of training samples, and initial scores to effectively classify the disease status. Extensive experiments using different convolutional neural network-based methods with and without the supervision mechanism and different classifiers are performed. Results demonstrate the effectiveness of the proposed supervision mechanism in all models and superior performance with the proposed GCN.},
  archive      = {J_ASOC},
  author       = {Ahmed Elazab and Mohamed Abd Elfattah and Yuexin Zhang},
  doi          = {10.1016/j.asoc.2021.108041},
  journal      = {Applied Soft Computing},
  pages        = {108041},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Novel multi-site graph convolutional network with supervision mechanism for COVID-19 diagnosis from X-ray radiographs},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bifurcated particle swarm optimizer with topology learning
particles. <em>ASOC</em>, <em>114</em>, 108039. (<a
href="https://doi.org/10.1016/j.asoc.2021.108039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The flying speed and trajectory of particles are subject to several factors, including neighborhood structures, inertia weight, and acceleration coefficients. This paper improves particle swarm optimizer by exploiting these factors. Specifically, it proposes an approach to adjust the neighborhood structures of particles adaptively. The search task is divided between two groups of particles, termed even and uneven, to perform a vigorous in-depth search. Each particle group pursues a different objective and conducts its search in a different manner. Even particles adaptively adjust their number of attractors and neighborhood radiuses to experience various flying trajectories and paces. Each uneven particle follows a single even one for a while until it is assigned to another even particle. Uneven particles are responsible for performing fine-grained searches in the vicinity of their associated even particles as well as their previously experienced locations. A tree structure is utilized to implement the neighborhood structures of the proposed method. In the presented structure, particles can experience large neighborhoods by choosing their attractors from higher levels of the tree. The proposed method is experimentally investigated on the comprehensive CEC2013 benchmark set and two challenging real-world problems: non-uniform circular antenna array synthesis and image segmentation . The comparison results with advanced particle swarm optimization algorithms demonstrate that search bifurcation and topology adjustment can significantly improve particle swarm optimization . Experimental results also indicate that the proposed method can be successfully employed for solving challenging real-world problems with various characteristics.},
  archive      = {J_ASOC},
  author       = {Reza Vafashoar and Hossein Morshedlou and Mohammad Reza Meybodi},
  doi          = {10.1016/j.asoc.2021.108039},
  journal      = {Applied Soft Computing},
  pages        = {108039},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Bifurcated particle swarm optimizer with topology learning particles},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Integrating feature extraction approaches with hybrid
emotional neural networks for water quality index modeling.
<em>ASOC</em>, <em>114</em>, 108036. (<a
href="https://doi.org/10.1016/j.asoc.2021.108036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The establishment of water quality prediction models is vital for aquatic ecosystems analysis. The traditional methods of water quality index (WQI) analysis are time-consuming and associated with a high degree of errors. These days, the application of artificial intelligence (AI) based models are trending for capturing nonlinear and complex processes. Therefore, the present study was conducted to predict the WQI in the Kinta River, Malaysia by employing the hybrid AI model i.e., GA-EANN (genetic algorithm-emotional artificial neural network). The extreme gradient boosting (XGB) and neuro-sensitivity analysis (NSA) approaches were utilized for feature extraction, and six different model combinations were derived to examine the relationship among the WQI with water quality (WQ) variables. The efficacy of the proposed hybrid GA-EANN model was evaluated against the backpropagation neural network (BPNN) and multilinear regression (MLR) models during calibration, and validation periods based on Nash–Sutcliffe efficiency (NSE), mean square error (MSE), root mean square error (RMSE), mean absolute percentage error (MAPE), and correlation coefficient (CC) indicators. According to the results of appraisal the hybrid GA-EANN model produced better outcomes (NSE = 0.9233/ 0.9018, MSE = 10.5195/ 9.7889 mg/L, RMSE = 3.2434/ 3.1287 mg/L, MAPE = 3.8032/ 3.0348 mg/L, and CC = 0.9609/ 0.9496) in calibration/ validation phases than BPNN and MLR models. In addition, the results indicate the better performance and suitability of the hybrid GA-EANN model with five input parameters in predicting the WQI for the study site.},
  archive      = {J_ASOC},
  author       = {S.I. Abba and R.A. Abdulkadir and Saad Sh. Sammen and Quoc Bao Pham and A.A. Lawan and Parvaneh Esmaili and Anurag Malik and Nadhir Al-Ansari},
  doi          = {10.1016/j.asoc.2021.108036},
  journal      = {Applied Soft Computing},
  pages        = {108036},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Integrating feature extraction approaches with hybrid emotional neural networks for water quality index modeling},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning graph representation with randomized neural network
for dynamic texture classification. <em>ASOC</em>, <em>114</em>, 108035.
(<a href="https://doi.org/10.1016/j.asoc.2021.108035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic textures (DTs) are pseudo periodic data on a space × × time support, that can represent many natural phenomena captured from video footages. Their modeling and recognition are useful in many applications of computer vision . This paper presents an approach for DT analysis combining a graph-based description from the Complex Network framework, and a learned representation from the Randomized Neural Network (RNN) model. First, a directed space × × time graph modeling with only one parameter (radius) is used to represent both the motion and the appearance of the DT. Then, instead of using classical graph measures as features, the DT descriptor is learned using a RNN , that is trained to predict the gray level of pixels from local topological measures of the graph. The weight vector of the output layer of the RNN forms the descriptor. Several structures are experimented for the RNNs, resulting in networks with final characteristics of a single hidden layer of 4, 24, or 29 neurons, and input layers of sizes 4 or 10, meaning 6 different RNNs. Experimental results on DT recognition conducted on Dyntex++ and UCLA datasets show a high discriminatory power of our descriptor, providing an accuracy of 99.92\%, 98.19\%, 98.94\% and 95.03\% on the UCLA-50, UCLA-9, UCLA-8 and Dyntex++ databases, respectively. These results outperform various literature approaches, particularly for UCLA-50. More significantly, our method is competitive in terms of computational efficiency and descriptor size. It is therefore a good option for real-time dynamic texture segmentation , as illustrated by experiments conducted on videos acquired from a moving boat.},
  archive      = {J_ASOC},
  author       = {Lucas C. Ribas and Jarbas Joaci de Mesquita Sá Junior and Antoine Manzanera and Odemir M. Bruno},
  doi          = {10.1016/j.asoc.2021.108035},
  journal      = {Applied Soft Computing},
  pages        = {108035},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Learning graph representation with randomized neural network for dynamic texture classification},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A combined forecasting system based on multi-objective
optimization and feature extraction strategy for hourly PM2.5
concentration. <em>ASOC</em>, <em>114</em>, 108034. (<a
href="https://doi.org/10.1016/j.asoc.2021.108034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate hourly PM 2.5 concentration prediction plays a key role in air quality monitoring and controlling system, especially when severe haze occurs frequently. A PM 2.5 hourly prediction system is developed in this paper, based on an advanced data processing strategy, an effective feature selection technology and a novel optimization algorithm . First, the collected original sequence is decomposed into a group of filters with different wave frequencies and each filter is weighted and reconstructed to mitigate the negative impact of noisy fluctuations. Then mRMR is introduced for extracting interaction information between pollutants, further determining the input of artificial intelligence models. Whereafter, a five-component combined system is taken shape, in which BPNN, ELM, GRNN and BiLSTM are employed as foundation models while Multi-objective Water Cycle Algorithm (MOWCA) is the weight optimization model. The results of hourly PM 2.5 concentration prediction simulation experiment in the Bei–Shang–Guang–Shen area make clear that the developed system with minimum forecasting error, excellent generalization capability and robust prediction performance shows a definite latent capacity and future to deal with early warning problems and to design suitable abatement strategies.},
  archive      = {J_ASOC},
  author       = {Jianzhou Wang and Rui Wang and Zhiwu Li},
  doi          = {10.1016/j.asoc.2021.108034},
  journal      = {Applied Soft Computing},
  pages        = {108034},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A combined forecasting system based on multi-objective optimization and feature extraction strategy for hourly PM2.5 concentration},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Benders decomposition-based particle swarm optimization for
competitive supply networks with a sustainable multi-agent platform and
virtual alliances. <em>ASOC</em>, <em>114</em>, 107985. (<a
href="https://doi.org/10.1016/j.asoc.2021.107985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The involvement of competition in supply networks has changed the existing monopoly platform in different fields. This paper examines a multi-level decision-making framework within a triple-stage strategic approach in competitive supply networks. The various levels of these supply networks consist of parent firms (parent brands), manufacturing plants, state-owned logistics company and franchised sales centers. The parent brands, while following the strategies of the state logistics company (as the leader of the game), seek to further expand their market share in the production, supply and sales sectors. The main contributions of the proposed approach are: the existence of partnership and non-partnership synergies in different stages of planning, the emergence and development of supply networks based on downstream alliances, the design of a multi-agent distribution mechanism based on environmental sustainability requirements, and the simultaneous development of cooperation and competition in terms of virtual alliances. Further, given the features of the issue under discussion, a hybrid Benders Decomposition-Particle Swarm Optimization algorithm is utilized. The designed structure of the algorithm helps to facilitate high-dimensional problem-solving while also addressing the interactive requirements of competitive games. The results of comparing the proposed solution approach with a game-theoretical heuristic, pure Benders decomposition and bi-level sub-population genetic algorithm prove its better performance, especially in large-size instances.},
  archive      = {J_ASOC},
  author       = {S. Rezaei and J. Behnamian},
  doi          = {10.1016/j.asoc.2021.107985},
  journal      = {Applied Soft Computing},
  pages        = {107985},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Benders decomposition-based particle swarm optimization for competitive supply networks with a sustainable multi-agent platform and virtual alliances},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Migrating birds optimization with a diversified mechanism
for blocking flow shops to minimize idle and blocking time.
<em>ASOC</em>, <em>114</em>, 107834. (<a
href="https://doi.org/10.1016/j.asoc.2021.107834">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blocking flow shop scheduling problem widely exists in industrial processes, and most attention has focused on minimization of economic indicators, such as makespan, total flow time, and due-date-based functions, rather than energy-efficient indicators. This paper considers idle and blocking time criterion, which is closely related to machine energy consumption in blocking flow shops, and proposes a migrating birds optimization with a diversified mechanism (dMBO) for the problem. On the basis of the profile fitting (PF) heuristic and the characteristics of the idle and blocking time, an improved heuristic, named PFI, is proposed by modifying the PF and performing an insert procedure. A best insert operator and an insert-based local search are hybridized in the proposed migrating birds optimization algorithm to enhance its exploitation capability. In order to maintain the diversity of the flock in the algorithm, a diversified mechanism containing three tabu lists and one candidate pool is designed. Extensive computational results validate the effectiveness of the proposed PFI heuristic, and a statistical analysis of the computational results confirms the superiority of the dMBO over several other high-performing metaheuristics .},
  archive      = {J_ASOC},
  author       = {Guanlong Deng and Mingming Xu and Shuning Zhang and Tianhua Jiang and Qingtang Su},
  doi          = {10.1016/j.asoc.2021.107834},
  journal      = {Applied Soft Computing},
  pages        = {107834},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Migrating birds optimization with a diversified mechanism for blocking flow shops to minimize idle and blocking time},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Virtual special issue on recent advances in discrete swarm
intelligence algorithms for solving engineering problems. <em>ASOC</em>,
<em>114</em>, 107823. (<a
href="https://doi.org/10.1016/j.asoc.2021.107823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ASOC},
  author       = {Mustafa Servet Kiran ( Guest Editors ) and Xiao-Zhi Gao and Muneeswaran Vasudevan and Mesut Gündüz},
  doi          = {10.1016/j.asoc.2021.107823},
  journal      = {Applied Soft Computing},
  pages        = {107823},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Virtual special issue on recent advances in discrete swarm intelligence algorithms for solving engineering problems},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Corrigendum to “a parallel compact cuckoo search algorithm
for three-dimensional path planning” [appl. Soft comput. 94 (2020)
106443]. <em>ASOC</em>, <em>114</em>, 106710. (<a
href="https://doi.org/10.1016/j.asoc.2020.106710">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ASOC},
  author       = {Pei-Cheng Song and Jeng-Shyang Pan and Shu-Chuan Chu},
  doi          = {10.1016/j.asoc.2020.106710},
  journal      = {Applied Soft Computing},
  pages        = {106710},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Corrigendum to “A parallel compact cuckoo search algorithm for three-dimensional path planning” [Appl. soft comput. 94 (2020) 106443]},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Corrigendum to “scheduling software updates for connected
cars with limited availability” [appl. Soft comput. (2019) 105575].
<em>ASOC</em>, <em>114</em>, 106523. (<a
href="https://doi.org/10.1016/j.asoc.2020.106523">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ASOC},
  author       = {Carlos E. Andrade and Simon D. Byers and Vijay Gopalakrishnan and Emir Halepovic and David J. Poole and Lien K. Tran and Christopher T. Volinsky},
  doi          = {10.1016/j.asoc.2020.106523},
  journal      = {Applied Soft Computing},
  pages        = {106523},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Corrigendum to “Scheduling software updates for connected cars with limited availability” [Appl. soft comput. (2019) 105575]},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
