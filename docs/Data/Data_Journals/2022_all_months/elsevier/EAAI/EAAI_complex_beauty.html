<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>EAAI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="eaai---494">EAAI - 494</h2>
<ul>
<li><details>
<summary>
(2022). Multiple hierarchical compression for deep neural network
toward intelligent bearing fault diagnosis. <em>EAAI</em>, <em>116</em>,
105498. (<a
href="https://doi.org/10.1016/j.engappai.2022.105498">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Network (DNN) models have been extensively developed for intelligent bearing fault diagnosis. The superior performance of DNN-based fault diagnosis methods is attributed to the deepening network structure, which increases the complexity of the deep models and causes difficulties to deploy them in industrial environments with constrained resources. To address the problems, this paper proposes a multi-hierarchical compression to compact the deep neural network for intelligent fault diagnosis. It combines network pruning, parameter quantization, and matrix compression to process the deep model from different perspectives, which achieves a considerable reduction of parameter volume and acceleration of training and response. Firstly, structured pruning is employed to prune the inconsequential filters in the convolutional layer, and unstructured pruning is utilized to eliminate the trivial connections in the fully connected layer. Then, parameter quantization is applied to minimize the number of bits that are required for parameter representation. Finally, the matrix compression storage is taken advantage of to reduce the requirements of storage capacity and further alleviate the excessive demands for the monitoring system. Experimental results and comparisons on two bearing datasets validate the effectiveness of the proposed method. The results show that for two CNN networks with different depths, the integrated network compression method can achieve considerable reductions in the number of parameters and the floating-point operations while almost no decrease in recognition accuracy. The proposed method makes an inspiring exploration for the application of intelligent fault diagnosis in the practical industry.},
  archive      = {J_EAAI},
  author       = {Jiedi Sun and Zhao Liu and Jiangtao Wen and Rongrong Fu},
  doi          = {10.1016/j.engappai.2022.105498},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105498},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multiple hierarchical compression for deep neural network toward intelligent bearing fault diagnosis},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automated identification of dominant physical processes.
<em>EAAI</em>, <em>116</em>, 105496. (<a
href="https://doi.org/10.1016/j.engappai.2022.105496">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The identification of processes that locally and approximately dominate dynamical system behavior has enabled significant advances in understanding and modeling nonlinear differential dynamical systems. Conventional methods of dominant process identification involve piecemeal and ad hoc (non-rigorous, informal) scaling analyses to identify dominant balances of governing equation terms and to delineate the spatiotemporal boundaries (boundaries in space and/or time) of each dominant balance. For the first time, we present an objective global measure of the fit of dominant balances to observations, which is desirable for automation, and was previously undefined. Furthermore, we propose a formal definition of the dominant balance identification problem in the form of an optimization problem. We show that the optimization can be performed by various machine learning algorithms, enabling the automatic identification of dominant balances. Our method is algorithm agnostic and it eliminates reliance upon expert knowledge to identify dominant balances which are not known beforehand.},
  archive      = {J_EAAI},
  author       = {Bryan E. Kaiser and Juan A. Saenz and Maike Sonnewald and Daniel Livescu},
  doi          = {10.1016/j.engappai.2022.105496},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105496},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automated identification of dominant physical processes},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Geometrically interpretable variance hyper rectangle
learning for pattern classification. <em>EAAI</em>, <em>116</em>,
105494. (<a
href="https://doi.org/10.1016/j.engappai.2022.105494">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many current intrinsically interpretable machine learning models can only handle the data that are linear, low-dimensional, and relatively independent attributes and often with discrete attribute values, while the models that are capable of handling high-dimensional nonlinear data, like deep learning, have very poor interpretability. Based on the geometric characteristics, a new idea of accurately wrapping the data region with minimum-volume geometry is proposed for pattern classification. The Variance Hyper Rectangle (VHR) model presented in this paper is a realization of the idea. The VHR model uses the minimum-volume hyper rectangles, obtained through projection variance calculation, to wrap the regions occupied by a category of data, hence it has strong and clear geometric interpretability. In addition, the VHR model is well suited for large data volume, as it approaches the linear complexity in both time and space. Extensive qualitative and quantitative experiments are performed on seven real-world data sets, demonstrating that VHR outperforms the state-of-the-art interpretable methods while running quickly.},
  archive      = {J_EAAI},
  author       = {Jie Sun and Huamao Gu and Haoyu Peng and Yili Fang and Xun Wang},
  doi          = {10.1016/j.engappai.2022.105494},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105494},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Geometrically interpretable variance hyper rectangle learning for pattern classification},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Solar radiation forecasting with deep learning techniques
integrating geostationary satellite images. <em>EAAI</em>, <em>116</em>,
105493. (<a
href="https://doi.org/10.1016/j.engappai.2022.105493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction of solar radiation allows estimating photovoltaic systems’ power production in advance, guaranteeing a more reliable and stable energy supply. In this work, we present a novel approach for short-term solar radiation forecasting that leverages multi-channel images from the geostationary satellites of the Meteosat series, coupled with GHI values in clear-sky conditions. We propose two distinct deep learning models, a 3D-CNN and a ConvLSTM, to forecast solar radiation in terms of GHI values, up to 6-h ahead with a temporal granularity of 15 min, over a test study area, the city of Turin, Piedmont, Italy. The models have been validated with ground GHI measurements, and the results show that the ConvLSTM consistently outperforms the 3D-CNN for longer forecasting horizons, achieving a MAD of 27.18% and an nRMSE of 0.57 for 6-h ahead predictions. To motivate the use of satellite images, we compared the performance of our approach with a baseline Smart Persistence model and another benchmark model, which previously achieved state-of-the-art performance on the same data set by exploiting various kinds of meteorological inputs. The proposed models outperform the Smart Persistence for predictions farther than 15-min ahead, achieving a Forecast Skill of 0.56 for predictions 6-h ahead. Furthermore, the comparison shows that using raw satellite images overcomes the performance achievable by solely using meteorological variables, reducing the RMSD by more than 3% and the MAD by 1.37% for prediction horizons greater than 4-h ahead.},
  archive      = {J_EAAI},
  author       = {Raimondo Gallo and Marco Castangia and Alberto Macii and Enrico Macii and Edoardo Patti and Alessandro Aliberti},
  doi          = {10.1016/j.engappai.2022.105493},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105493},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Solar radiation forecasting with deep learning techniques integrating geostationary satellite images},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). An efficient fire and smoke detection algorithm based on an
end-to-end structured network. <em>EAAI</em>, <em>116</em>, 105492. (<a
href="https://doi.org/10.1016/j.engappai.2022.105492">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detection transformer (DETR) combines convolutional neural network (CNN) with transformer, providing a more advanced idea. In this paper, an object detection model based on DETR is proposed for fire and smoke detection. Compared with other methods that based on deep learning, the proposed one simplifies the pipeline of detection and builds an end-to-end detector. At the same time, the original DETR model usually requires long training time and large amount of computation, resulting in relatively poor performance in detection speed and accuracy, and it shows to be not friendly for small or early fire detection. Therefore, when designing the proposed network model, a normalization-based attention module is added in the feature extraction stage to highlight the effective features, being beneficial to the process of encoding. A multiscale deformable attention is also used in the encoder–decoder structure, accelerating therefore, the process of convergence during the training of the model, which includes the enhancement of the detection of small objects. Also, considering the cost of computation, the number of layers in the encoder–decoder structure is redefined to reduce the complexity of the model, and that also reduces the requirements of the application equipment. Detailed experiments are conducted on three self-built datasets and two public video sets. The results show that, the proposed method has an excellent performance on all of the datasets considered here.},
  archive      = {J_EAAI},
  author       = {Yuming Li and Wei Zhang and Yanyan Liu and Rudong Jing and Changsong Liu},
  doi          = {10.1016/j.engappai.2022.105492},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105492},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An efficient fire and smoke detection algorithm based on an end-to-end structured network},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Recent advancements in deep learning based lung cancer
detection: A systematic review. <em>EAAI</em>, <em>116</em>, 105490. (<a
href="https://doi.org/10.1016/j.engappai.2022.105490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cancer is considered to be a key cause of substantial fatality and morbidity in the world. A report from the International Agency for Research on Cancer (IARC) states that 27 million new cases of cancer are expected before 2030. 1 in 18 men and 1 in 46 women are estimated to develop lung cancer over a lifetime. This paper discusses an overview of lung cancer, along with publicly available benchmark data sets for research purposes. Recent research performed in medical image analysis of lung cancer using deep learning algorithms is compared using various technical aspects such as efficiency, advantages, and limitations. These discussed approaches provide insight into techniques that can be used to perform the detection and classification of lung cancer. Numerous techniques adapted in the acquisition of the images, extraction of relevant features, segmentation of region affected, selection of optimal features, and classification are also discussed. The paper is concluded by stating the clinical, technical challenges and prominent future directions.},
  archive      = {J_EAAI},
  author       = {Shubham Dodia and Annappa B. and Padukudru A. Mahesh},
  doi          = {10.1016/j.engappai.2022.105490},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105490},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Recent advancements in deep learning based lung cancer detection: A systematic review},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Underwater image dehazing using global color features.
<em>EAAI</em>, <em>116</em>, 105489. (<a
href="https://doi.org/10.1016/j.engappai.2022.105489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate underwater imaging is a challenging task. Unlike regular photography, visibility underwater is drastically hazed by water molecules and suspended particles distorting light rays and causing differential absorption of different wavelengths of color. Existing research produces well-adjusted but not perfect results. In this work, we present a novel method that dehazed underwater images by estimating global background light based on the optimal eigenvalues of a matrix constructed from three components: (1) gradient of the pairwise wavelength of color channels (blue–red ( b r ), blue–green ( b g ), and green–red ( g r )) (2) gradient of the wavelength of color channels, and (3) the color channels themselves. We estimate transmission maps via scene depth by exploiting the difference in absorption of the different color channel wavelengths. The proposed technique is executed by augmenting UWCNN (Under-Water CNN) with graph-cut theory. The resultant dehazed images successfully show greatly improved color. The proposed results outperform the existing methods in terms of entropy, UIQM n o r m , UICM, UISM, and UCIQE. These improvements will provide stronger imaging tools to domains like submarine search and rescue, navigation, oceanography, and mapping. There is room for future research because our process slightly darkens images which leads to marginally lower UIConM values. Future study can also further evaluate the effect of color channels while assuming pixels with the highest intensity are used as the global ambient light.},
  archive      = {J_EAAI},
  author       = {Fayadh Alenezi and Ammar Armghan and K.C. Santosh},
  doi          = {10.1016/j.engappai.2022.105489},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105489},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Underwater image dehazing using global color features},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Local-based k values for multi-label k-nearest neighbors
rule. <em>EAAI</em>, <em>116</em>, 105487. (<a
href="https://doi.org/10.1016/j.engappai.2022.105487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label learning is a growing field in machine learning research. Many applications address instances that simultaneously belong to many categories, which cannot be disregarded if optimal results are desired. Among the many algorithms developed for multi-label learning, the multi-label k -nearest neighbor method is among the most successful. However, in a difficult classification task, such as multi-label learning, a challenge that arises in the k -nearest neighbor approach is the assignment of the appropriate value of k . Although a suitable value might be obtained using cross-validation, it is unlikely that the same value will be optimal for the whole space spanned by the training set. It is evident that different regions of the feature space would have different distributions of instances and labels that would require different values of k . The very complex boundaries among the many present labels make the necessity of local k values even more important than in the case with a single-label k -nearest neighbor. We present a simple yet powerful approach for setting a local value of k . We associate a potentially different k with every prototype and obtain the best value of that k by optimizing the criterion consisting of the local effect of the different k values in the neighborhood of the prototype. The proposed method has a fast training stage, as it only uses the neighborhood of each training instance to set the local k value. The complexity of the proposed method in terms of the testing time is similar to that of the standard multi-label k -nearest neighbor approach. Experiments performed on a set of 20 problems show that not only does our proposed method significantly outperform the standard multi-label k -nearest neighbor rule but also the locally adaptive multi-label k-nearest neighbor method can benefit from a local k value.},
  archive      = {J_EAAI},
  author       = {J.A. Romero-del-Castillo and Manuel Mendoza-Hurtado and Domingo Ortiz-Boyer and Nicolás García-Pedrajas},
  doi          = {10.1016/j.engappai.2022.105487},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105487},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Local-based k values for multi-label k-nearest neighbors rule},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improved deep CNN-based two stream super resolution and
hybrid deep model-based facial emotion recognition. <em>EAAI</em>,
<em>116</em>, 105486. (<a
href="https://doi.org/10.1016/j.engappai.2022.105486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans have traditionally found it easy to determine emotions from facial expressions, but doing so by utilizing a computer algorithm is far more challenging. It is now feasible to discern emotions from photographs because of recent advances in computer vision as well as artificial intelligence. The following issues afflict existing face expression detection systems throughout the application process: As the extant shallow feature extraction framework has lost a great deal of effective feature data and also has limited detection performance, the paper proposes a novel technique termed “Improved Deep CNN-based Two Stream Super Resolution and Hybrid Deep Model-based Facial Emotion Detection”, which consists of three working phases: super-resolution, facial emotion recognition, as well as classification. Improved Deep CNN has been used in the super-resolution phase for two streams, structure and texture stream super-resolution, that delivers high pixel density to the pictures with minimal cross-entropy loss. The facial emotion identification phase involves face recognition utilizing the Viola–Jones face detection algorithm and feature extraction using three traditional methods: Texton, Bag of Words (BOW), and GLCM, as well as improved LGXP features. In addition, classification was performed in our work utilizing RNN as well as Bi-GRU neural networks. A voting mechanism known as Score level fusion was used to get precise categorization results. Our unique Deep CNN-based facial emotion recognition system provides 95% accuracy, which is superior to other traditional approaches, according to the results. Positive and negative performance metrics for various databases have also been assessed and compared with our proposed methodology, proving that our novel strategy surpasses conventional approaches.},
  archive      = {J_EAAI},
  author       = {Zia Ullah and Lin Qi and Asif Hasan and Muhammad Asim},
  doi          = {10.1016/j.engappai.2022.105486},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105486},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improved deep CNN-based two stream super resolution and hybrid deep model-based facial emotion recognition},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LA-SPA: A new learning automata-based approach for the
parking space selection and reservation. <em>EAAI</em>, <em>116</em>,
105484. (<a
href="https://doi.org/10.1016/j.engappai.2022.105484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, with the increasing number of vehicles in the urban environment, finding a parking space has become an important and challenging issue. Vehicles may have to spend a lot of time looking for a parking space, which can lead to excessive fuel consumption, area traffic congestion, increased air pollution, and even driver impatience and immorality. To solve this problem, this article has used Roadside-to-Vehicle/Vehicle-to-Roadside (R2V/V2R), Roadside-to-Roadside (R2R) and Parking-to-Roadside/Roadside-to-Parking (P2R/R2P) communication in Vehicular Ad-hoc Network (VANET) and learning automata with variable actions to select and reserve the most suitable parking space. The performance of the proposed method was evaluated using computer simulation. The simulation results showed the efficiency of the proposed method in terms of improving service quality, reducing computational overhead, and making optimal use of parking resources in the city compared to existing methods. The proposed algorithm helps reduce air and noise pollution by reducing traffic congestion caused by parking space searches, and also helps increase the use of parking facilities efficiently.},
  archive      = {J_EAAI},
  author       = {Sanaz Afshari and Javad Akbari Torkestani and Mehdi Fartash},
  doi          = {10.1016/j.engappai.2022.105484},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105484},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {LA-SPA: A new learning automata-based approach for the parking space selection and reservation},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Transformer-based moving target tracking method for unmanned
aerial vehicle. <em>EAAI</em>, <em>116</em>, 105483. (<a
href="https://doi.org/10.1016/j.engappai.2022.105483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicle (UAV) moving target tracking is one of the fundamental implementations in remote sensing and has been widely applied in monitoring, search and rescue, pursuit-escapes, and other fields. Currently, most UAV tracking algorithms merely establish the local relationship between the template and search region without fully using the global context information, leading to problems such as target loss and misclassification, and imprecise bounding boxes. This paper innovatively proposes a UAV tracker, TransUAV, overcoming the above challenge by a feature correlation network based on the self-attention mechanism. The method efficiently combines global features between the search region and the template to reduce the influence of external interference, enhancing the precision and robustness of the tracking algorithm. Moreover, the global spatio-temporal features are acquired by learning query embedding and temporal update strategies to make predictions, enhancing the adaptability to rapid changes in the appearance of target object. There is no proposal or predetermined anchor in this method to satisfy the requirements of onboard operational speed, therefore, no post-processing procedure is required, and the entire approach is end-to-end. The superiority of the proposed TransUAV is verified by an exhaustive evaluation of six challenging target tracking video datasets benchmarks, and the accuracy and robustness of the proposed TransUAV are compared with state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Nianyi Sun and Jin Zhao and Guangwei Wang and Chang Liu and Peng Liu and Xiong Tang and Jinbiao Han},
  doi          = {10.1016/j.engappai.2022.105483},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105483},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Transformer-based moving target tracking method for unmanned aerial vehicle},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improvement of performance in freezing of gait detection in
parkinson’s disease using transformer networks and a single waist-worn
triaxial accelerometer. <em>EAAI</em>, <em>116</em>, 105482. (<a
href="https://doi.org/10.1016/j.engappai.2022.105482">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Freezing of gait (FOG) is one of the most incapacitating symptoms in Parkinson’s disease, affecting more than 50% of patients in advanced stages of the disease. The presence of FOG may lead to falls and a loss of independence with a consequent reduction in the quality of life. Wearable technology and artificial intelligence have been used for automatic FOG detection to optimize monitoring. However, differences between laboratory and daily-life conditions present challenges for the implementation of reliable detection systems. Consequently, improvement of FOG detection methods remains important to provide accurate monitoring mechanisms intended for free-living and real-time use. This paper presents advances in automatic FOG detection using a single body-worn triaxial accelerometer and a novel classification algorithm based on Transformers and convolutional networks. This study was performed with data from 21 patients who manifested FOG episodes while performing activities of daily living in a home setting. Results indicate that the proposed FOG-Transformer can bring a significant improvement in FOG detection over the reproduction of related approaches based on machine and deep learning (i.e., from 0.916 to 0.957 in the AUC metric compared with the baseline, with a corresponding sensitivity, specificity, and precision of 0.842, 0.939 and 0.617, respectively) using a leave-one-subject-out cross-validation (LOSO CV). These results present opportunities for the implementation of accurate monitoring systems for use in ambulatory or home settings.},
  archive      = {J_EAAI},
  author       = {Luis Sigcha and Luigi Borzì and Ignacio Pavón and Nélson Costa and Susana Costa and Pedro Arezes and Juan Manuel López and Guillermo De Arcas},
  doi          = {10.1016/j.engappai.2022.105482},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105482},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improvement of performance in freezing of gait detection in parkinson’s disease using transformer networks and a single waist-worn triaxial accelerometer},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust self-supervised monocular visual odometry based on
prediction-update pose estimation network. <em>EAAI</em>, <em>116</em>,
105481. (<a
href="https://doi.org/10.1016/j.engappai.2022.105481">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual odometry aims at estimating the camera pose from video sequence, which is an important part of visual Simultaneous Localization and Mapping (SLAM). In this paper, we propose a novel prediction-update pose estimation network, PU-PoseNet, for self-supervised monocular visual odometry. It allows the network to use the effective information of the previous frame in estimating the current pose. The long-time pose consistency constraint-based motion weighted photometric loss is designed to make the network to pay more attention to the pixels of stationary objects and enhance the time consistency of estimation results. The depth image-based occlusion detection, the depth smoothness loss and auto-Masking are used to construct the depth consistency constraint loss term to reduce the influences of interferences such as occlusion. To further improve the robustness and the accuracy of the proposed method, both the depth consistency constraint and the variational auto-encoder are used for network training. For frame missing cases, a novel frame missing training strategy is used to make our method adapt frame missing cases. Extensive experiments on the KITTI dataset have validated the effectiveness of our proposed method.},
  archive      = {J_EAAI},
  author       = {Haixin Xiu and Yiyou Liang and Hui Zeng and Qing Li and Hongmin Liu and Bin Fan and Chen Li},
  doi          = {10.1016/j.engappai.2022.105481},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105481},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust self-supervised monocular visual odometry based on prediction-update pose estimation network},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Performing in-situ analytics: Mining frequent patterns from
big IoT data at network edge with d-HARPP. <em>EAAI</em>, <em>116</em>,
105480. (<a
href="https://doi.org/10.1016/j.engappai.2022.105480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big IoT data is inherently distributed, high-dimensional, irregular, and sparse in nature. Fog computing model in its original form is by no means the optimal solution for mining big IoT data. However, utilizing the network edge for mining tasks, such as enabling edge and IoT devices to mine locally frequent patterns can significantly improve the mining performance. Additionally, edge devices capable of performing distributed job processing could utilize the model to the fullest. But resource poorness of edge and IoT devices needs lightweight pattern mining algorithms. This paper presents Distributed HARnessing the Power of Powersets for Mining Frequent Itemsets (D-HARPP), a spark-based distributed algorithm to mine frequent co-occurring itemsets in big IoT data. Unlike state-of-the-art distributed algorithms, D-HARPP makes a single pass over the data and does not create candidate itemsets; thus, achieves significantly better runtime and consumes the least memory. Moreover, performance of D-HARPP is not deteriorated at lower minimum support thresholds. These distinguishing characteristics make D-HARPP an optimal choice for Spark-enabled edge and IoT devices. D-HARPP has outperformed Spark-Apriori, another distributed algorithm by significant margins, both in terms of runtime and memory consumption, particularly on sparse datasets.},
  archive      = {J_EAAI},
  author       = {Muhammad Yasir and Ali Haidar and Muhammad Umar Chaudhry and Muhammad Asif Habib and Aamir Hussain and Elżbieta Jasińska and Zbigniew Leonowicz and Michał Jasiński},
  doi          = {10.1016/j.engappai.2022.105480},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105480},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Performing in-situ analytics: Mining frequent patterns from big IoT data at network edge with D-HARPP},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-mechanism-based modified bi-objective harris hawks
optimization for sustainable robotic disassembly line balancing
problems. <em>EAAI</em>, <em>116</em>, 105479. (<a
href="https://doi.org/10.1016/j.engappai.2022.105479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the increasingly severe resource scarcity and environmental pollution, appropriate recovery of end-of-life (EOL) products has gained significant importance in recent years. The disassembly lines are one of the vital steps during the entire recovery process. However, considering the disadvantages of manual disassembly lines such as high labor cost, low efficiency, and harm to workers’ health, the transition to robotic disassembly lines is underway. Therefore, in this paper, a sustainable robotic disassembly line balancing problem (RDLBP) is proposed to improve the disassembly efficiency (cycle time) and environmental friendliness (total energy consumption) simultaneously. To narrow the gap between theory and practice, uncertain processing time, sequence-based tool changeover, and robots with different efficiencies and energy consumption rates are considered, which requires adding the steps of resequencing the tasks and allocating the most suitable robots within each workstation on the basis of assigning the tasks to workstations as evenly as possible. To solve this problem, the epsilon constraint algorithm is used to obtain the exact solutions for small scale cases and verify the validity of the proposed model. Simultaneously, due to the NP-hard nature, a modified bi-objective Harris Hawks optimization (MBOHHO) algorithm is developed to solve the line balancing problem for the first time, which combines opposition-based learning, differential evolution, and Gaussian mutation mechanisms, and modifies the renewal strategy of two vital parameters based on bioenergy consumption pattern, contributing to improve the diversity and help jump out of local optimum. Finally, computational experiments are performed to evaluate the performance of the MBOHHO algorithm by comparing it with four other outstanding optimization algorithms, and the results reveal its effectiveness and superiority in various metrics.},
  archive      = {J_EAAI},
  author       = {Binghai Zhou and Jingrao Bian},
  doi          = {10.1016/j.engappai.2022.105479},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105479},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-mechanism-based modified bi-objective harris hawks optimization for sustainable robotic disassembly line balancing problems},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A privacy preserving diagnostic collaboration framework for
facial paralysis using federated learning. <em>EAAI</em>, <em>116</em>,
105476. (<a
href="https://doi.org/10.1016/j.engappai.2022.105476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the machine learning and artificial intelligence applications are data driven. When it comes to sensitive data, maintaining the data privacy principles is a big challenge. Building a machine learning model for classifying sensitive data is discussed in this paper. Focus is given for medical field where the patient data comes under sensitive or private information category. There are restrictions to share patient data for research purposes or collaboration among doctors in different hospitals due to the privacy concerns. In this work, we take facial paralysis as an example and discuss how to build a model for facial paralysis detection. Here, the data used for training the model is face images which implicitly reveals identity of the patient. We analyse how the facial paralysis images from multiple hospitals can be combined together for building an efficient facial paralysis detection system without compromising privacy of patients. Support Vector Machine based federated learning is applied for the purpose. Hospitals are considered as clients which are the data sources where the local training happens and there is a server performing federated averaging. Unlike in traditional federated learning, soft clustering approach is considered at server side and the update to each client is different. The federated averaging algorithm at server takes care of the distribution of data each client holds and customises the update sent to each client. This approach improves the local test accuracy and the convergence speed. To validate the findings, experiments are conducted with MNIST and covid pneumonia datasets as well.},
  archive      = {J_EAAI},
  author       = {Divya G. Nair and Jyothisha J. Nair and K. Jaideep Reddy and C.V. Aswartha Narayana},
  doi          = {10.1016/j.engappai.2022.105476},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105476},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A privacy preserving diagnostic collaboration framework for facial paralysis using federated learning},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Real-time prediction of the mechanical behavior of suction
caisson during installation process using GA-BP neural network.
<em>EAAI</em>, <em>116</em>, 105475. (<a
href="https://doi.org/10.1016/j.engappai.2022.105475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the short construction period, convenient transportation and strong geological adaptability, the suction caisson has received more and more attention in offshore geotechnical foundation engineering associated with oil and gas production platforms. A good understanding of the mechanical behaviors of soils, such as real-time effective stress and settlement, around the suction caisson during its installation is important for analyzing the stability and loading capacity of the platforms in deep water. The objective of this research is to develop a numerical model for predicting the mechanical behavior of soils around the suction caisson during installation based on the data including real-time settlement and effective stress produced from the centrifuge tests in the literature by using the genetic algorithm-back propagation (GA-BP) neural network method. Furthermore, the nonlinear relationship among the settlement, penetration pressure, effective stress, and suction required during the installation is thoroughly investigated. It is found that, compared with the experimental results, the relative error of the prediction results from the proposed model is −0.3% ∼ 1.4% for settlement, 0.8% ∼ 2.3% for effective lateral stress in a single clay layer, and −2.5% ∼ 4.5% for normalized required suction in multilayered soils at the final stage. It can be concluded that the GA-BP neural network method can be used to predict the real-time hydromechanical behavior of the caisson foundation during the installation process in terms of efficiency and accuracy.},
  archive      = {J_EAAI},
  author       = {Shengshen Wu and Gaofeng Zhao and Bisheng Wu},
  doi          = {10.1016/j.engappai.2022.105475},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105475},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Real-time prediction of the mechanical behavior of suction caisson during installation process using GA-BP neural network},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhancing scene understanding based on deep learning for
end-to-end autonomous driving. <em>EAAI</em>, <em>116</em>, 105474. (<a
href="https://doi.org/10.1016/j.engappai.2022.105474">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient understanding of the environment is a crucial prerequisite for autonomous driving, but explicitly modeling the environment is hard to come true. In contrast, imitation learning, in theory, can arrive at the direct mapping from visual input to driving command, but the inscrutability of scene representation in imitation learning is still a challenging problem. In this paper, we propose to enhance the abstract representation of visual scene from two aspects for better scene understanding, i.e. Visual Guide path and Driving Affordances path. For Visual Guide path, we leverage semantic information as visual priors to learn the intuitive state of the environment, e.g. the spatial semantic occupation of the visual scene. For Driving Affordances path, several driving affordance indicators reflecting the relationship between environment and vehicle behavior are learned as the global guidance to guide the driving system to learn safe and efficient driving policies. With the complementarity of these two paths, a Bilateral Guide Network is designed to realize the complete mapping from visual input to driving command. Our method is evaluated on the CARLA simulator with various scenarios to demonstrate the effectiveness. Besides, comparative analyses are made with some state-of-the-art methods to justify the performance of our method in the aspect of autonomous driving.},
  archive      = {J_EAAI},
  author       = {Jie Hu and Huifang Kong and Qian Zhang and Runwu Liu},
  doi          = {10.1016/j.engappai.2022.105474},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105474},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing scene understanding based on deep learning for end-to-end autonomous driving},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). New adaptive robust h∞ control of smart structures using
synchrosqueezed wavelet transform and recursive least-squares algorithm.
<em>EAAI</em>, <em>116</em>, 105473. (<a
href="https://doi.org/10.1016/j.engappai.2022.105473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two kinds of uncertainties, one due to the dynamic earthquake loads with a wide frequency band and the other due to structural parameters exist in large and complex real-life structures. Most existing control algorithms consider only one of them, resulting in difficulty to guarantee necessary control performance for large complex structures, such as better vibration suppression on structural peak response and robustness performance. Considering the two uncertainties simultaneously, in this paper, a new adaptive robust H ∞ control methodology is presented for vibration control of structures through adroit integration of synchrosqueezed wavelet transform (SWT) and recursive least-squares (RLS) algorithm. The robust H ∞ control is more effective than the traditional LQR/LQG control in terms of the stability and robustness of the control system. The external excitation signal from ground sensors is filtered by a low-pass filter based on SWT and then inputted into the filtered-x RLS adaptive controller. The effectiveness, accuracy, and computational efficiency of the new adaptive control method is demonstrated using a 76-story wind-excited benchmark super high-rise building structure and a 24-story shear-wall building with an active tuned mass damper (ATMD) system on the top floor. Compared with the existing linear quadratic Gaussian control algorithm, the wavelet-hybrid feedback-least mean square algorithm and the robust H ∞ control algorithm, the simulation results show that the control effect and robust performance indexes of the structure are increased by 5%–35% and 5%–25%, respectively, using the new control methodology.},
  archive      = {J_EAAI},
  author       = {Zhijun Li and Hojjat Adeli},
  doi          = {10.1016/j.engappai.2022.105473},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105473},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {New adaptive robust h∞ control of smart structures using synchrosqueezed wavelet transform and recursive least-squares algorithm},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A review of the use of artificial intelligence methods in
infrastructure systems. <em>EAAI</em>, <em>116</em>, 105472. (<a
href="https://doi.org/10.1016/j.engappai.2022.105472">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The artificial intelligence (AI) revolution offers significant opportunities to capitalise on the growth of digitalisation and has the potential to enable the ‘system of systems’ approach required in increasingly complex infrastructure systems. This paper reviews the extent to which research in economic infrastructure sectors has engaged with fields of AI, to investigate the specific AI methods chosen and the purposes to which they have been applied both within and across sectors. Machine learning is found to dominate the research in this field, with methods such as artificial neural networks, support vector machines, and random forests among the most popular. The automated reasoning technique of fuzzy logic has also seen widespread use, due to its ability to incorporate uncertainties in input variables. Across the infrastructure sectors of energy, water and wastewater, transport, and telecommunications, the main purposes to which AI has been applied are network provision, forecasting, routing, maintenance and security, and network quality management. The data-driven nature of AI offers significant flexibility, and work has been conducted across a range of network sizes and at different temporal and geographic scales. However, there remains a lack of integration of planning and policy concerns, such as stakeholder engagement and quantitative feasibility assessment, and the majority of research focuses on a specific type of infrastructure, with an absence of work beyond individual economic sectors. To enable solutions to be implemented into real-world infrastructure systems, research will need to move away from a siloed perspective and adopt a more interdisciplinary perspective that considers the increasing interconnectedness of these systems.},
  archive      = {J_EAAI},
  author       = {Lauren McMillan and Liz Varga},
  doi          = {10.1016/j.engappai.2022.105472},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105472},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A review of the use of artificial intelligence methods in infrastructure systems},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust visual odometry using sparse optical flow network.
<em>EAAI</em>, <em>116</em>, 105471. (<a
href="https://doi.org/10.1016/j.engappai.2022.105471">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based visual odometry (VO) has recently attracted much attention. In performing computer vision tasks, deep models are often more robust than manually extracted features. Deep models, however, have limited reliability and generalization ability which constrain their application in the VO systems. The existing approaches to address these issues are often based on creating more realistic datasets or employing strategies such as unsupervised learning and online fine-tuning. In contrast to the previous research, here we tackle these issues from the model structure standpoint. We present a simple yet robust VO (namely SF-VO) based on an especially designed sparse optical flow network. We then show that this network becomes suitable for VO applications by decomposing the global optimization problem into a single-point optimization. Combining the network with a consistency verification module and a Perspective-n-Point (PnP) solver, we then form a frame-to-frame VO system using the traditional pose estimation pipeline. Extensive experiments show that the proposed VO system effectively generalizes to real scenes while only synthetic datasets are used in the training process. It is also shown that the proposed model also outperforms other deep learning-based methods with a model size of only 1.69 M. Comparisons with the state-of-art optical flow models and performing expansion experiments further confirm that the designed network demonstrates a higher level of generalization ability and is capable of being trained based on limited datasets.},
  archive      = {J_EAAI},
  author       = {Qiang Liu and Baojia Chen},
  doi          = {10.1016/j.engappai.2022.105471},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105471},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust visual odometry using sparse optical flow network},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Failure mode risk assessment methodology for controlling
multi-uncertainties in the evaluation process. <em>EAAI</em>,
<em>116</em>, 105470. (<a
href="https://doi.org/10.1016/j.engappai.2022.105470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The failure mode risk evaluation results of FMEA are affected by multi-uncertainties. This paper proposes a risk evaluation methodology for controlling multi-uncertainties in the assessment process. First, the fuzzy confidence interval number (FCIN) evaluation model is provided to control the uncertainty in assessing the severity ( S ), occurrence ( O ), and detectability ( D ). Then, the FCINs are converted into generalized trapezoidal fuzzy numbers (GTrFNs), and the GTrFNs’ scalar characteristic distances modified by the non-membership are used as the evaluation results of S , O , D and their synthesizer or risk priority number ( RPN ) to control the risk evaluation model uncertainty. Furthermore, the evaluation parameter value criteria of S , O , D are formulated based on the sensitivity analysis results, more precise than the general value guidelines introduced by industrial FMEA standards. The case study results show that the proposed methodology can significantly improve the risk assessment results and the risk discrimination of failure modes.},
  archive      = {J_EAAI},
  author       = {Yan Liu and Bingsong Chen and Qiuxian Dong and Weidong Liu and Wenbin Nie and Chao Yang},
  doi          = {10.1016/j.engappai.2022.105470},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105470},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Failure mode risk assessment methodology for controlling multi-uncertainties in the evaluation process},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Waveform level adversarial example generation for joint
attacks against both automatic speaker verification and spoofing
countermeasures. <em>EAAI</em>, <em>116</em>, 105469. (<a
href="https://doi.org/10.1016/j.engappai.2022.105469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial examples crafted to deceive Automatic Speaker Verification (ASV) systems have attracted a lot of attention when studying the vulnerability of ASV. However, real-world ASV systems usually work together with spoofing countermeasures (CM) to exclude fake voices generated by text-to-speech (TTS) or voice conversion (VC). The deployment of CM would reduce the capability of the adversarial samples on deceiving ASV. Although additional perturbations against CM may be generated and put on the crafted adversarial examples against ASV to yield new adversarial examples against both ASV and CM, those additional perturbations would however hinder the examples’ adversarial effectiveness on ASV. In this paper, a novel joint approach is proposed to generate adversarial examples by considering attacking ASV and CM simultaneously. For any voice from TTS, VC or a real-world speaker, our crafted adversarial perturbations will turn its original labels on CM and speaker ID to bonafide and some target speaker ID, correspondingly. In our approach, a differentiable front-end is introduced to replace the conventional hand-crafted time–frequency feature extractor. Perturbations can thus be estimated by updating the gradients of the joint objective of ASV and CM on the waveform variables. The proposed method has demonstrated a 99.3% success rate on white-box logical access attacks to deceive ASV and CM simultaneously, which outperforms the baselines of 65.3% and 36.7%. Furthermore, transferability on black-box and physical settings has also been validated.},
  archive      = {J_EAAI},
  author       = {Xingyu Zhang and Xiongwei Zhang and Wei Liu and Xia Zou and Meng Sun and Jian Zhao},
  doi          = {10.1016/j.engappai.2022.105469},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105469},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Waveform level adversarial example generation for joint attacks against both automatic speaker verification and spoofing countermeasures},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RPNet: Rotational pooling net for efficient micro aerial
vehicle trail navigation. <em>EAAI</em>, <em>116</em>, 105468. (<a
href="https://doi.org/10.1016/j.engappai.2022.105468">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart agile Micro Aerial Vehicles are becoming ubiquitous in industrial applications; however, their computational efficacy poses a constraint limiting their deployment. The challenge mentioned above is mitigated in the context of a Micro Aerial Vehicle vision-based navigation task. RPNet, a computational-efficient model, is proposed as a Micro Aerial Vehicle navigational controller. RPNet comprises a sequential arrangement of generic imaginary and real Gabor filters for computation reduction. Further, a novel rotational pooling mechanism that induces online feature descriptors augmentation is proposed and plugged after each convolutional block in RPNet for robustness and increase in performance. RPNet is initially trained on synthetic data for domain knowledge and further trained and tested in a real-world setting using a Micro Aerial Vehicle. Extensive experimental verification of RPNet based on four evaluation metrics shows satisfactory performance compared to the reference trajectories. Further, via comparisons, RPNet attains better error distribution of about ± 5 m, and computational conservation of around 9% than the first runner-up comparator among the state-of-the-art models in the vision-based Micro Aerial Vehicle navigation task.},
  archive      = {J_EAAI},
  author       = {Isaac Osei Agyemang and Xiaoling Zhang and Daniel Acheampong and Isaac Adjei-Mensah and Enoch Opanin Gyamfi and Joseph Roger Arhin and Williams Ayivi and Chikwendu Ijeoma Amuche},
  doi          = {10.1016/j.engappai.2022.105468},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105468},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {RPNet: Rotational pooling net for efficient micro aerial vehicle trail navigation},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Physics-informed multi-fidelity learning-driven imaging
method for electrical capacitance tomography. <em>EAAI</em>,
<em>116</em>, 105467. (<a
href="https://doi.org/10.1016/j.engappai.2022.105467">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The electrical capacitance tomography is considered to be a promising non-invasive visualization method for the measurement of multiphase flow parameters, but low-quality tomograms limit the reliability and accuracy of measurements. In order to overcome this limitation and bottleneck, the physics-informed data-dependent prior learned from the given samples is introduced and coupled with the measurement mechanism and the domain knowledge modeled by a new L 1 / L 2 norm-based regularizer into a new optimization imaging model in this study. To improve the convergence and reduce the computational load, the built imaging model is solved by a new numerical scheme driven by the split Bregman method and the forward–backward splitting method. A new physics-informed robust sparse extreme learning machine method that not only obeys the measurement mechanism in training but also promotes the robustness and performance of the model is proposed and used to build a novel multi-fidelity learning method to infer the physics-informed data-dependent prior. The new imaging method achieves multi-source data fusion, leads to new changes in reconstruction algorithms, increases the complementarity and diversity of image priors, unifies the image reconstruction and multi-fidelity learning method, and improves robustness, numerical stability and flexibility of the model. The reconstruction results show that the new imaging method achieves more accurate reconstruction with reduced sensitivity to noise compared to important and popular imaging methods. This study leads to new changes in imaging algorithms and mining and use of image priors, and serves as a catalyst for the paradigm shift in image reconstruction.},
  archive      = {J_EAAI},
  author       = {Jing Lei and Qibin Liu and Xueyao Wang},
  doi          = {10.1016/j.engappai.2022.105467},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105467},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physics-informed multi-fidelity learning-driven imaging method for electrical capacitance tomography},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predicting and interpreting financial distress using a
weighted boosted tree-based tree. <em>EAAI</em>, <em>116</em>, 105466.
(<a href="https://doi.org/10.1016/j.engappai.2022.105466">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Financial distress prediction aims at providing an early warning solution of financial distress to help business participants, investors, and regulators to achieve better profit growth and financial risk management. Extreme gradient boosting (XGBoost), has been recognized as a favorable competitor compared with machine learning-based individual classifiers. However, its commercial value for FDP is hindered by two reasons. First, FDP is a classical imbalance issue, traditional XGBoost is considered a cost-insensitive approach that yields skew-sensitive FDP results. Second, XGBoost is a complex ensemble approach that faces the performance-interpretability dilemma, making the decision logic of XGBoost cannot be easily understood. To solve the above limitations, in this study, we first focus on addressing the imbalance issue in FDP by introducing a weighted cost-sensitive XGBoost, reducing the error of misclassifying financial distress firms. Next, we merge the decision rules extracted from the optimized weighted XGBoost to reconstruct a new tree as the approximation of the cost-sensitive ensemble model, making the proposed weighted XGBoost-based tree (XGBoost-W-BT) an accurate and interpretable solution for imbalanced FDP. Experimental results on a Chinese FDP dataset collected from China Security Market Accounting Research Database (CSMARD) showed that XGBoost-W-BT can be an alternative to weighted XGBoost to predict financial distress at an early stage. Besides, the transparent tree-based structure provides an explicit explanation to help industry participants and regulators make scientific policies, guiding investors to make rational investments.},
  archive      = {J_EAAI},
  author       = {Wanan Liu and Hong Fan and Min Xia and Congyuan Pang},
  doi          = {10.1016/j.engappai.2022.105466},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105466},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Predicting and interpreting financial distress using a weighted boosted tree-based tree},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stimulating trust cooperation in edge services: An
evolutionary tripartite game. <em>EAAI</em>, <em>116</em>, 105465. (<a
href="https://doi.org/10.1016/j.engappai.2022.105465">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network edge services have contributed to ordinary people’s daily lives with numerous conveniences but the accompanying problems, such as counterfeiting, the trust crisis and the service provider’ s lack of standardization, have created some turmoil in the industry. Trust is crucial to network services, and the responsibilities of a platform’s trust supervision can no longer be ignored. To enhance trust and cooperation among service participants, this paper constructs a new tripartite game model of monitors, edge service providers (ESPs) and users. First, this paper discusses the characteristics of the players in the edge service game and establishes a tripartite payment matrix model. Second, this paper outlines the concept of an evolutionary stability strategy, analyzes how to apply the dynamic replication equation to calculate the equilibrium solution and obtains the phase diagrams of the monitor, ESP, and the user. The ideal stable state point {active monitoring, honesty, trust} is obtained by calculating the value of an eigenvalue less than zero in the Jacobian matrix. Finally, this paper designs relevant experimental studies to verify and compare the correctness and effectiveness of several factors that affect the convergence stability of the evolutionary games, compares them with other research models, considers some advantages and discusses future development directions.},
  archive      = {J_EAAI},
  author       = {Panjun Sun and Shigen Shen and Zongda Wu and Haiping Zhou and Xiao-Zhi Gao},
  doi          = {10.1016/j.engappai.2022.105465},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105465},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Stimulating trust cooperation in edge services: An evolutionary tripartite game},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Forecasting turning points in stock price by applying a
novel hybrid CNN-LSTM-ResNet model fed by 2D segmented images.
<em>EAAI</em>, <em>116</em>, 105464. (<a
href="https://doi.org/10.1016/j.engappai.2022.105464">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to forecast stock price Turning Points (TPs) with a developed hybrid Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) model. To this end, at first, each day of the time series is classified into TPs and Ordinary Points (OPs); therefore, the investors demand to know the TPs precisely to make fewer trades and gain more profits. Secondly, a balancing approach is developed to have a balanced number of TPs and OPs. Thirdly, different technical indicators, as inputs, are converted into 2D images to consider the relationship between the indicators. Fourthly, the Fuzzy C-Means segmenting algorithm is applied to reduce the inputs’ complexity by segmenting them and aid the Neural Networks in being trained more efficiently. In the next step, a classification hybrid CNN-LSTM-ResNet model is proposed to precisely forecast TPs and OPs. Moreover, augmentation techniques, including Residual Networks (ResNet), are employed to strengthen the proposed model. Finally, the forecasted TPs and OPs are relabeled with Buying/Selling/Holding by a presented strategy to make trades. For numerical experiments, two markets of Exchange-traded funds (ETFs) and Dow-30 are used to evaluate the models and strategy’s performance. The results reveal that the proposed CNN-LSTM-ResNet model reaches a profit up to three times in the stocks of Dow-30 and profit up to four times more than the Buy and Hold strategy in the ETFs. More importantly, the proposed model outperforms other benchmarks with an average accuracy of 60.19% in Dow-30 and 63.62% in ETFs.},
  archive      = {J_EAAI},
  author       = {Pouya Khodaee and Akbar Esfahanipour and Hassan Mehtari Taheri},
  doi          = {10.1016/j.engappai.2022.105464},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105464},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Forecasting turning points in stock price by applying a novel hybrid CNN-LSTM-ResNet model fed by 2D segmented images},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dealing with multi-criteria decision analysis in
time-evolving approach using a probabilistic prediction method.
<em>EAAI</em>, <em>116</em>, 105462. (<a
href="https://doi.org/10.1016/j.engappai.2022.105462">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-criteria Decision Analysis (MCDA) is a methodology that has been classically used to rank alternatives according to a set of decision criteria. The MCDA techniques have been shown to be an efficient tool in a number of real-life engineering problems. Nevertheless, most of the proposed approaches in the field do not consider the temporal characteristic of the criteria values, which can be an interesting information to be explored in order to predict future rankings. The present work proposes a novel MCDA methodology in which the past data of the criteria are considered to predict their future values. Our approach is based on a tensorial formulation, together with the use of the recursive least mean squares method in the prediction step. In addition, we consider a probabilistic prediction and use the Stochastic Multi-criteria Acceptability Analysis, which allows the decision maker to observe the degree of uncertainty in the ranking. Numerical experiments with synthetic and actual data attest to the proposal’s relevance in scenarios in which the criteria values change over time.},
  archive      = {J_EAAI},
  author       = {Betania Silva Carneiro Campello and Leonardo Tomazeli Duarte and João Marcos Travassos Romano},
  doi          = {10.1016/j.engappai.2022.105462},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105462},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dealing with multi-criteria decision analysis in time-evolving approach using a probabilistic prediction method},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel method for improving the robustness of deep
learning-based malware detectors against adversarial attacks.
<em>EAAI</em>, <em>116</em>, 105461. (<a
href="https://doi.org/10.1016/j.engappai.2022.105461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malware is constantly evolving with rising concern for cyberspace. Deep learning-based malware detectors are being used as a potential solution. However, these detectors are vulnerable to adversarial attacks. The adversarial attacks manipulate files in such a way that the resulting malware files evade being detected. Adversarial training is one of the techniques used to develop malware detectors using saddle-point (min–max) formulation. In adversarial training, malware samples are manipulated using multiple adversarial attacks to generate adversarially poisoned malware samples. These poisoned malware samples are incorporated in the training of models to make them robust against evasion attacks (i.e. attacks at the testing time). In this work, ten neural network-based malware detectors are developed, with nine trained with a particular adversarial attack and one without such training. To consider the characteristics of multiple adversarial attacks and utilise the performance of the ten detectors on various evasion attacks, a novel approach is developed to design a malware detector by training a neural network with a mixture of multiple adversarial attacks. This novel approach achieved the best performance among all the eleven malware detectors. Experimental results demonstrated that the new approach significantly enhanced the robustness of the malware detector and achieved the lowest evasion rates of 12% on average on VirusShare and 18% on average on VXHeaven datasets, respectively, against all possible evasion attacks. The experiments show that the detectors trained with other adversarial attacks such as DeepFool and multi-step bit gradient ascent achieve higher evasion rates of 17% and 36% on VirusShare, and 24% and 45% on VXHeaven datasets, respectively.},
  archive      = {J_EAAI},
  author       = {Kamran Shaukat and Suhuai Luo and Vijay Varadharajan},
  doi          = {10.1016/j.engappai.2022.105461},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105461},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel method for improving the robustness of deep learning-based malware detectors against adversarial attacks},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). UD_BBC: Named entity recognition in social network combined
BERT-BiLSTM-CRF with active learning. <em>EAAI</em>, <em>116</em>,
105460. (<a
href="https://doi.org/10.1016/j.engappai.2022.105460">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of Internet penetration, more and more people choose the Internet to express their views on topics of interest. In recent years, named entity recognition (NER) is becoming a popular task for the public to obtain structured information from public opinion text. At present, NER models with good results, such as deep learning model, need a lot of labeled data for training. However, this will give rise to a problem: labeling a large amount of data requires a lot of human resources, which is thankless in some areas. Therefore, in this paper, we propose a NER model combining active learning and deep learning methods. Firstly, the active learning method can solve the above problem. The strategy combines uncertainty-based sampling and diversity-based sampling to estimate the information of data. We use highly informative data as the initial training dataset. Secondly, this paper uses a deep learning model combining bidirectional encoder representations from Transformers, bidirectional long–short-term memory and conditional random field (BERT-BiLSTM-CRF). BERT extracts the semantic features of data, and BiLSTM predicts the probability distribution of entity labels. We use the CRF for decoding the probability distribution into corresponding entity labels. Finally, we use the initial training dataset for training BERT-BiLSTM-CRF. This model predicts the entity labels of the unlabeled data. Then, we judge if the machine-labeled data is highly reliable and expand the highly reliable data to the initial training dataset. The updated dataset retrains the NER model, so that the trained model has higher precision than the previous model. The results show that our model performs well without a large number of labeled datasets. The model achieves a precision value of 70.31%, recall rate of 74.93% and F1 score of 72.55% in the named entity recognition task, which proves the effectiveness of our model. Besides, the F1 score of BERT-BiLSTM-CRF with uncertainty-based sampling and diversity-based sampling (UD_BBC) is higher than the BiLSTM-CRF based on maximum normalized log-probability (MNLP_BiLSTM-CRF) by 9.00%, when recognizing overall entity categories. It provides a solution to the problem of named entity recognition in educational public opinion.},
  archive      = {J_EAAI},
  author       = {Wei Li and Yajun Du and Xianyong Li and Xiaoliang Chen and Chunzhi Xie and Hui Li and Xiaolei Li},
  doi          = {10.1016/j.engappai.2022.105460},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105460},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {UD_BBC: Named entity recognition in social network combined BERT-BiLSTM-CRF with active learning},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An embedded solution for fault detection and diagnosis of
photovoltaic modules using thermographic images and deep convolutional
neural networks. <em>EAAI</em>, <em>116</em>, 105459. (<a
href="https://doi.org/10.1016/j.engappai.2022.105459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, an embedded system for fault detection and diagnosis of photovoltaic (PV) modules based on infrared thermographic images and deep conventional neural networks (DCNNs) is introduced. First, a binary classifier is developed for PV modules fault detection. Then, a multiclass classifier is developed to diagnose the type of defects occurred on PV modules. In this study, four common defects are examined: partial shading effect, dust deposit on PV modules surface, short-circuited PV module and bypass diode failure. The developed DCNN-based classifiers have been first optimized and then embedded into a low-cost microprocessor (Raspberry Pi 4). The models have also been compared with three main TF-Lite optimization techniques (Simple conversion, Dynamic range quantization and Float 16 quantization). Experimental results demonstrate the feasibility of the developed embedded system to operate in real-time, and can detect and diagnose anomalies with acceptable accuracy. The trade-off between accuracy and models size has been also discussed. Furthermore, the operator could be notified about the state of the PV array through SMS (phone message) using a GSM module (SIM808), as well as by email. This embedded solution can help to make real-time analyses for decision making (i.e. removing fault, cleaning PV modules, changing PV modules, replacing diodes, etc.).},
  archive      = {J_EAAI},
  author       = {Adel Mellit},
  doi          = {10.1016/j.engappai.2022.105459},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105459},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An embedded solution for fault detection and diagnosis of photovoltaic modules using thermographic images and deep convolutional neural networks},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Convolutional-LSTM networks and generalization in
forecasting of household photovoltaic generation. <em>EAAI</em>,
<em>116</em>, 105458. (<a
href="https://doi.org/10.1016/j.engappai.2022.105458">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solar panels can generate energy to meet almost all of the energy needs of a house. Batteries store energy generated during daylight hours for future use. Also, it may be possible to sell extra electricity back to distribution companies. However, the efficiency of photovoltaic systems varies according to several factors, such as the solar exposition at ground levels, atmospheric temperature, and relative humidity, and predicting the energy generated by such a system is not easy. This work is on the use of deep learning to predict the generation of photovoltaic energy by residential systems. We use real-world data to evaluate the performance of LSTM, Convolutional, and hybrid Convolutional-LSTM networks in predicting photovoltaic power generation at different forecasting horizons. We also assess the generalizability of the solutions, evaluating the use of models trained with data aggregated by geographic areas to predict the energy generation by individual systems. We compare the performance of deep networks with Prophet in terms of MAE, RMSE, and NRMSE, and in most cases, Convolutional and Convolutional-LSTM networks achieve the best results. Using models trained with region-based data to predict the power generation of individual systems is confirmed to be a promising approach.},
  archive      = {J_EAAI},
  author       = {Rogério Luís de C. Costa},
  doi          = {10.1016/j.engappai.2022.105458},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105458},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Convolutional-LSTM networks and generalization in forecasting of household photovoltaic generation},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Divergence measures for circular intuitionistic fuzzy sets
and their applications. <em>EAAI</em>, <em>116</em>, 105455. (<a
href="https://doi.org/10.1016/j.engappai.2022.105455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Circular Intuitionistic Fuzzy Set (C-IFS) is the real extension of the standard Intuitionistic Fuzzy Sets (IFS), where each element is represented by a circle instead of a single value. The divergence measures for fuzzy sets are used to find the discrimination between fuzzy sets. In this study, several divergence functions for C-IFSs are defined. The investigations verify that the divergence functions respect axiomatic properties to be divergence measures. Additional qualities of divergence measures are investigated to assure good performance. Also, the C-IF entropy and dissimilarity measures are explored. Divergence-based VIKOR (“VlseKriterijumska Optimizacija I Kompromisno Resenje” and in English “multi-criteria optimization and compromise solution”) method for C-IFSs is extended and applied to the multi-criteria decision-making problems. In the end, pattern recognition and multi-period medical diagnosis problems are focused on. The numerical examples are provided to illustrate the debated methods.},
  archive      = {J_EAAI},
  author       = {Muhammad Jabir Khan and Wiyada Kumam and Nasser Aedh Alreshidi},
  doi          = {10.1016/j.engappai.2022.105455},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105455},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Divergence measures for circular intuitionistic fuzzy sets and their applications},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A reinforcement learning approach to long-horizon
operations, health, and maintenance supervisory control of advanced
energy systems. <em>EAAI</em>, <em>116</em>, 105454. (<a
href="https://doi.org/10.1016/j.engappai.2022.105454">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a Reinforcement Learning (RL) approach to the supervisory control problem for advanced energy systems, such as novel nuclear reactors and other demand-driven, mission-critical, and component-health-sensitive energy plants. The inclusive problem landscape considered captures the stochastic confluence of plant performance, component health evolution, power demand from the grid, diverse maintenance actions, and operator-defined goals and constraints, all considered over meaningfully long-enough reasoning horizons. Key aspects of the proposed approach are a receding horizon control-inspired technique dictating time- or event-triggered supervisory policy (re-)constructions, as well as additional capability-enabling contributions such as timescale compression, to handle long reasoning horizons and uncertainty in parts of the problem, and practical yet demonstrably-effective handling of hybrid action spaces with continuous and discrete decision variables. The resulting algorithm consists of a simulation-based RL agent constructing stochastic supervisory control policies over nontrivial action spaces and for long horizons, applying the learned policy to the system for a much shorter interval, and perpetually repeating, to construct the next long-horizon policy. That next policy will only be applied, again, for a short interval, yet originally far-in-time events move progressively closer, their associated uncertainty decreases, and new events and aspects enter the reasoning horizon. The proposed methodology bridges fundamental receding horizon concepts with the unequivocally stronger and more scalable reasoning of contemporary RL. Numerical examples using Soft Actor–Critic Deep RL illustrate the operation and efficacy of the proposed technique for a power plant tasked with health-aware load following missions in a dynamic electricity market landscape.},
  archive      = {J_EAAI},
  author       = {Dimitrios Pylorof and Humberto E. Garcia},
  doi          = {10.1016/j.engappai.2022.105454},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105454},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A reinforcement learning approach to long-horizon operations, health, and maintenance supervisory control of advanced energy systems},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adioc loss: An auxiliary descent IoC loss function.
<em>EAAI</em>, <em>116</em>, 105453. (<a
href="https://doi.org/10.1016/j.engappai.2022.105453">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection based on deep learning has progressed significantly hitherto. Intersection over Union (IoU) is a wildly adopted evaluation metric in this field, which is also used as a loss function to constrain training. To address the problem of IoU zero gradient under the non-overlap circumstance, most improved loss functions tend to change penalty terms while few loss functions tried to improve IoU itself. In this paper, we proposed an intersection over convex (IoC) algorithm via analysis of IoU series loss functions. IoC can provide a gradient when a bounding box (also called a predicted box) and a ground truth (also called a target box) share no region. This characteristic will accelerate the training phase. In consideration of the comprehensiveness of the loss function, we constructed Auxiliary descent intersection over convex (Adioc) loss. Adioc loss function was tested on a one-stage network named Yolov5 and a two-stage network named Faster-RCNN. For the one-stage network, the results showed that under the same training batch, the accuracy of the Yolov5s network on VOC datasets increased by 0.1% ∼ 0.4%, and the accuracy of the Yolov5s network on COCO datasets increased by 0.1% ∼ 0.4% The relative improvement of Yolov5 m is 0.6% ∼ 0.7% on COCO dataset. For the two-stage network, the improvement of Faster-RCNN on COCO datasets is about 0.3% ∼ 0.5%.},
  archive      = {J_EAAI},
  author       = {Yanyan Zhang and Zhiliang Shi and Yuhao Zhang},
  doi          = {10.1016/j.engappai.2022.105453},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105453},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adioc loss: An auxiliary descent IoC loss function},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GCNET: Graph-based prediction of stock price movement using
graph convolutional network. <em>EAAI</em>, <em>116</em>, 105452. (<a
href="https://doi.org/10.1016/j.engappai.2022.105452">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The importance of considering related stocks data for the prediction of stock price movement has been shown in many studies; however, advanced graphical techniques for modeling, embedding and analyzing the behavior of inter-related stocks have not been widely exploited for the prediction of stocks price movements yet. The main challenges in this domain are to find a way for modeling the existing relations among an arbitrary set of stocks and to exploit such a model for improving the prediction performance for those stocks. The most of existing methods in this domain rely on basic graph-analysis techniques, with limited prediction power, and suffer from a lack of generality and flexibility. In this paper, we introduce a novel framework, called GCNET that models the relations among an arbitrary set of stocks as a graph structure called influence network and uses a set of history-based prediction models to infer plausible initial labels for a subset of the stock nodes in the graph. Finally, GCNET uses the Graph Convolutional Network algorithm to analyze this partially labeled graph and predicts the next price direction of movement for each stock in the graph. GCNET is a general prediction framework that can be applied for the prediction of the price fluctuations of interacting stocks based on their historical data. Our experiments and evaluations on a set of stocks from the NASDAQ index demonstrate that GCNET improves the performance of the state-of-the-art algorithms in terms of Accuracy and Matthew’s Correlation Coefficient by at least 1.5% and 2%, respectively.},
  archive      = {J_EAAI},
  author       = {Alireza Jafari and Saman Haratizadeh},
  doi          = {10.1016/j.engappai.2022.105452},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105452},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {GCNET: Graph-based prediction of stock price movement using graph convolutional network},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Federated learning-based vertebral body segmentation.
<em>EAAI</em>, <em>116</em>, 105451. (<a
href="https://doi.org/10.1016/j.engappai.2022.105451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To ensure the safety of spinal surgery, sufficiently labeled Magnetic Resonance Imaging (MRI) images are essential for training an accurate vertebral segmentation model, but the number of labeled MRI images owned by the independent medical institution such as the hospital is generally limited. Besides, in consideration of patients’ privacy, annotated images are difficult to share directly as the medical data to train vertebral body segment models. To address these challenges, a Federated Learning-based Vertebral Body Segment Framework (FLVBSF) is proposed in this work, which includes a novel local Dual Attention Gates (DAGs)-based attention mechanism and a global federated learning framework. The model sensitivity to vertebral body pixels and segmentation accuracy can be improved by using the DAGs. The performance of vertebral body segmentation models is boosted by the global federated learning framework via collaboratively exploiting the labeled spine image data from different institutions. The centralized training-based experimental results show that 98.29% in pixel-level accuracy is achieved by the U-Net with DAGs, 88.04% in dice similarity coefficient, 88.25% in sensitivity, 99.16% in specificity, and 79.09% in Jaccard similarity coefficient and the mean segmentation time per case is 0.14 s. Meanwhile, the federated learning-based experimental results show that the proposed FLVBSF can enhance the performance of the vertebral segmentation model by a statistically significant margin.},
  archive      = {J_EAAI},
  author       = {Junxiu Liu and Xiuhao Liang and Rixing Yang and Yuling Luo and Hao Lu and Liangjia Li and Shunsheng Zhang and Su Yang},
  doi          = {10.1016/j.engappai.2022.105451},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105451},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Federated learning-based vertebral body segmentation},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Compound short- and long-term memory for memory augmented
neural networks. <em>EAAI</em>, <em>116</em>, 105450. (<a
href="https://doi.org/10.1016/j.engappai.2022.105450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adding memory to artificial intelligence systems in an effective way has been addressed by researchers for many years. Recurrent neural networks and long short-term memories (LSTMs), among other neural network systems, have some inherent memory capabilities. Recently, in memory augmented neural networks, such as neural Turing machine (NTM) and its variants, a separate memory module is implemented, which can be accessed via read and write heads. Despite its capabilities in simple algorithmic tasks, such as copying and repeat copying, neural Turing machines fail when doing complex tasks with long-term dependencies due to their limited memory capacity. In this paper, we propose a new memory module in which data storing and access mechanisms are based on a graph-based neural structure rather than a matrix model. This is inspired by the human memory system, in which memories are stored via synapses (connections between neurons) and are recalled through a path passing from different neuronal networks. Differentiable mechanisms are designed for this graph-based neural memory so that it can be trained via backpropagation. The proposed structure is used to solve tasks with long-time dependencies and operations on the input sequences as well as the bAbI question answering dataset. The analysis shows that the proposed memory system can help solve these tasks better than NTM and LSTM in terms of the convergence speed and the final error},
  archive      = {J_EAAI},
  author       = {Amir Bidokhti and Shahrokh Ghaemmaghami},
  doi          = {10.1016/j.engappai.2022.105450},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105450},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Compound short- and long-term memory for memory augmented neural networks},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A benchmark for multi-class object counting and size
estimation using deep convolutional neural networks. <em>EAAI</em>,
<em>116</em>, 105449. (<a
href="https://doi.org/10.1016/j.engappai.2022.105449">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic object counting and object size estimation in digital images can be very useful in many real-world applications such as surveillance, smart farming, intelligent traffic systems, etc. However, most existing research mainly focus on scenarios where only one type of object is considered due to the lack of proper datasets. Furthermore, they use the traditional detection algorithms for size estimation and can only do segmenting tasks but cannot identify different types of objects and return corresponding individual size information. To fill these gaps, we create a synthetic dataset and propose a benchmark for multi-class object counting and size estimation ( MOCSE ) within a unified framework. We create the dataset MOCSE13 by using Unity to generate synthetic images for 13 different objects (fruits and vegetables). Besides, we propose a deep architecture approach for multi-class object counting and object size estimation. Our proposed models with different backbones are evaluated on the synthetic dataset. The experimental results provide a benchmark for multi-class object counting and size estimation and the synthetic dataset can be served as a proper testbed for future studies.},
  archive      = {J_EAAI},
  author       = {Zixu Liu and Qian Wang and Fanlin Meng},
  doi          = {10.1016/j.engappai.2022.105449},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105449},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A benchmark for multi-class object counting and size estimation using deep convolutional neural networks},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Research on public opinion sentiment classification based on
attention parallel dual-channel deep learning hybrid model.
<em>EAAI</em>, <em>116</em>, 105448. (<a
href="https://doi.org/10.1016/j.engappai.2022.105448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The research on sentiment classification of online public opinion is helpful to the management and control of online public opinions. In the matter of the problems of previous sentiment analysis research that it is difficult to well capture text sentiment features and to identify words ambiguity, an Attention Parallel Dual-channel Deep Learning Hybrid Model (ADDHM) is proposed. Bidirectional Encoder Representations from Transformers (BERT) is applied to extract semantic features and training text vector representation. Convolutional Neural Network (CNN) and Bidirectional Long Short-term Memory (BiLSTM), introducing the attention mechanism, form a dual-channel model to extract text semantic features so as to enrich the words meaning and improve the classification level. Microblog public opinion is taken as an experiment case and hyperparameters are adjusted to find the optimal hyperparameter combination. Six comparison models are selected to verify the validity of ADDHM on four data sets. The classification accuracy of the proposed model on the four experimental data sets are respectively 96.68%, 88.86%, 89.64% and 92.72%, which are superior to the comparison model, and the ROC curve performance of the model is also the best. The performance of ADDHM is significantly different from that of the comparison models. ADDHM can effectively optimize the expression of text features and enhance the capacity of extracting text sentiment feature. It has better classification effect and is more befitting for sentiment classification of online public opinion comments.},
  archive      = {J_EAAI},
  author       = {Chun Yan and Jiahui Liu and Wei Liu and Xinhong Liu},
  doi          = {10.1016/j.engappai.2022.105448},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105448},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Research on public opinion sentiment classification based on attention parallel dual-channel deep learning hybrid model},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-organizing broad network using information evaluation
method. <em>EAAI</em>, <em>116</em>, 105447. (<a
href="https://doi.org/10.1016/j.engappai.2022.105447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Broad network (BN) is commonly used as an efficient and computationally inexpensive machine learning method. The flat structure of BN ensures the efficiency of model learning, but in the mean time the structural characteristics also affect the network performances, such as generalization. However, it is challenging to improve the BN’s generalization performance via adjusting its structure based on certain specific criteria. In this paper, to get the required network structure, a self-organizing BN based on the information evaluation method (IE-SOBN) is designed. First, a capability evaluation metric (CEM) is introduced into BN, which can evaluate the ability of hidden neurons to express and transmit data information. Then, the evaluation metric obtained by CEM is used as the basis for structure adjustment. Second, a structure adjustment mechanism (SAM) based on CEM is proposed to dynamically optimize the BN structure, leading to an improved generalization performance. Third, the convergence of the suggested IE-SOBN is theoretically analyzed to ensure its effectiveness. Finally, the advantages of IE-SOBN are verified by three real applications. The generalization performance and test accuracy of the proposed IE-SOBN are satisfactory in the experiments.},
  archive      = {J_EAAI},
  author       = {Hong-Gui Han and Xiao-Ye Fan and Fang-Yu Li},
  doi          = {10.1016/j.engappai.2022.105447},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105447},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-organizing broad network using information evaluation method},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Service price forecasting of urban charging infrastructure
by using deep stacked CNN-BiGRU network. <em>EAAI</em>, <em>116</em>,
105445. (<a
href="https://doi.org/10.1016/j.engappai.2022.105445">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve the accuracy of short-term time series price forecasting, a hybrid model of convolutional neural network (CNN) coupled with bi-directional gated recurrent unit (Bi-GRU) and attention mechanism is proposed. The architecture first uses CNN to extract valid information from the data to construct feature vectors, then delivers the feature vectors into the Bi-GRU network for training, and finally uses a self-attentive mechanism to fully exploit the input feature information to predict the load values. Relative to the single use of existing datasets, we then deploy a complex urban environment to evaluate the trained model. The conclusions show that the proposed model architecture has outstanding advantages in terms of both predictive metrics and model performance.},
  archive      = {J_EAAI},
  author       = {Tong Wang and Liyue Fu and Yuhu Zhou and Shan Gao},
  doi          = {10.1016/j.engappai.2022.105445},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105445},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Service price forecasting of urban charging infrastructure by using deep stacked CNN-BiGRU network},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Development of improved sparrow search-based PI controller
for power quality enhancement using UPQC integrated with medical
devices. <em>EAAI</em>, <em>116</em>, 105444. (<a
href="https://doi.org/10.1016/j.engappai.2022.105444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photovoltaic (PV) panel interfaces with the grid create the issues regarding power quality such as voltage distortion, voltage harmonics, etc. To mitigate the harmonics in PV systems, Active Power Filters (APF) are taken. Unified Power Quality Conditioner (UPQC) is utilized for alleviating the problems correlated with voltage dip/swell in source voltage that has regulated the load voltage absolutely. On the other hand, the existing researches do not solve the power quality problems such as Voltage Stability Index (VSI), UPQC cost and power loss. Power quality is taken as the main demanding one in the analyzing the smart grid. Thus, APFs are primarily selected for compensating the problems occurring in power quality as they has some active compensation and are competent of filtering fast. Moreover, power quality constraint with load current must be addressed, which considers the factors like reduced power factor, huge Total Harmonic Distortion (THD) level, and unbalanced power. To reach the ideal efficiency on UPQC, the voltage control of the DC link capacitor is important. Thus, a new power quality enhancement model with UPQC especially for medical devices is focused. The UPQC-connected medical devices are suggested with a new Adaptively Updating-Sparrow Search Algorithm (AU-SSA)-based Proportional plus Integral (PI) controller, which is integrated with renewable energy like wind turbine Squirrel Cage Induction Generator (SCIG) to eliminate the current and harmonics imperfection accurately. This model implements a new power quality enhancement model by formulating a newly derived objective function. Finally, the experimental verification of the proposed scheme is done.},
  archive      = {J_EAAI},
  author       = {T. Arulkumar Assistant Professor and N. Chandrasekaran Professor},
  doi          = {10.1016/j.engappai.2022.105444},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105444},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Development of improved sparrow search-based PI controller for power quality enhancement using UPQC integrated with medical devices},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A heuristic and meta-heuristic based on problem-specific
knowledge for distributed blocking flow-shop scheduling problem with
sequence-dependent setup times. <em>EAAI</em>, <em>116</em>, 105443. (<a
href="https://doi.org/10.1016/j.engappai.2022.105443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The distributed production scenario with the sequence-dependent setup times (SDST) widely exists in the modern manufacturing system. This paper investigates the distributed blocking flow-shop scheduling problem with sequence-dependent setup times (SDST/DBFSP). Considering the complexity of the distributed scenario and SDSTs, a discrete heuristic and meta-heuristic is proposed by exploring the problem-specific knowledge. First, a knowledge-incorporated construction heuristic is proposed to reduce the blocking times and idle times generated by SDSTs. In the first stage of the meta-heuristic, an insertion-based neighborhood operator of different factories is developed to explore promising regions in the decision space. In the second stage, a local search operator is embedded to enhance the exploitation ability. Additionally, a simulated annealing-like acceptance criterion of the iterated greedy algorithm is employed to keep the diversity of the population. Finally, an insertion operation for critical factories is introduced to further improve the accuracy of the solutions. Moreover, a speedup method for the insertion neighborhood is expanded to reduce the computational complexity of SDST/DBFSP. In the part of the experiment, a deconstruction process is designed to gain insight into the contribution of each component in the proposed meta-heuristic. The proposed meta-heuristic is assessed through comparing with five state-of-the-art algorithms to demonstrate its effectiveness. The experimental results testified that the proposed meta-heuristic outperforms other algorithms regarding the significance of the SDST/DBFSP.},
  archive      = {J_EAAI},
  author       = {Fuqing Zhao and Haizhu Bao and Ling Wang and Tianpeng Xu and Ningning Zhu and Jonrinaldi},
  doi          = {10.1016/j.engappai.2022.105443},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105443},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A heuristic and meta-heuristic based on problem-specific knowledge for distributed blocking flow-shop scheduling problem with sequence-dependent setup times},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). I-SISSO: Mutual information-based improved sure independent
screening and sparsifying operator algorithm. <em>EAAI</em>,
<em>116</em>, 105442. (<a
href="https://doi.org/10.1016/j.engappai.2022.105442">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Symbolic regression is a method to extract quantitative expressions from dataset and has already been applied in different research fields. The sure independence screening and sparsifying operation ( SISSO ) is a powerful data-driven method widely applied in various fields of material research or other research directions and can handle large candidate descriptor spaces and generate prediction models in the form of equations with high accuracy. However, SISSO is confronted by the combinatorial explosion phenomenon when enumerating each case to decide the sparsing representation with an ensured L0-norm. This study uses the Max-Relevance and Min-Redundancy ( mRMR ) algorithm to solve the problem arising from the combinatorial explosion in SISSO by reducing the candidate descriptor space before the SO phase and shrinking the possible search space without losing excess information. Experimental results on six different public datasets and 12 predictive targets show that, when compared with SISSO, mutual information based SISSO significantly reduced time consumption and maintained the error of the model close to the model generated by SISSO, demonstrating that the optimal strategy works on it. Hence, the time cost decreases to approximately 1 1000 , and the predictive accuracy remains steady.},
  archive      = {J_EAAI},
  author       = {Yuqin Xu and Quan Qian},
  doi          = {10.1016/j.engappai.2022.105442},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105442},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {I-SISSO: Mutual information-based improved sure independent screening and sparsifying operator algorithm},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Constrained multi-agent ergodic area surveying control based
on finite element approximation of the potential field. <em>EAAI</em>,
<em>116</em>, 105441. (<a
href="https://doi.org/10.1016/j.engappai.2022.105441">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heat Equation Driven Area Coverage (HEDAC) is a state-of-the-art multi-agent ergodic motion control guided by a gradient of a potential field. A finite element method is hereby implemented to obtain a solution of the Helmholtz partial differential equation, which models the potential field for surveying motion control. This allows us to survey arbitrarily shaped domains and to include obstacles in an elegant and robust manner intrinsic to HEDAC’s fundamental idea. For a simple kinematic motion, the obstacles and boundary avoidance constraints are successfully handled by directing the agent motion with the gradient of the potential. However, including additional constraints, such as the minimal clearance distance from stationary and moving obstacles and the minimal path curvature radius, requires further alternations of the control algorithm. We introduce a relatively simple yet robust approach for handling these constraints by formulating a straightforward optimization problem based on collision-free escape route maneuvers. This approach provides a guaranteed collision avoidance mechanism while being computationally inexpensive as a result of the optimization problem partitioning. The proposed motion control is evaluated in three realistic surveying scenarios simulations, showing the effectiveness of the surveying and the robustness of the control algorithm. Furthermore, potential maneuvering difficulties due to improperly defined surveying scenarios are highlighted and we provide guidelines on how to overpass them. The results are promising and indicate real-world applicability of the proposed constrained multi-agent motion control for autonomous surveying and potentially other HEDAC utilizations.},
  archive      = {J_EAAI},
  author       = {Stefan Ivić and Ante Sikirica and Bojan Crnković},
  doi          = {10.1016/j.engappai.2022.105441},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105441},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Constrained multi-agent ergodic area surveying control based on finite element approximation of the potential field},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design and evaluation of adaptive deep learning models for
weather forecasting. <em>EAAI</em>, <em>116</em>, 105440. (<a
href="https://doi.org/10.1016/j.engappai.2022.105440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has emerged as a promising tool in time-series prediction tasks such as weather forecasting, and adaptive models can deal with dynamic data more effectively. In this work, we first investigate how successfully meteorological features can be predicted by a deep learning model based on long-short-term memory (LSTM). Then, we endeavor to improve the prediction model’s performance by employing various LSTM types and choosing a model type that provides robust and accurate results. After that, we extend the proposed model to deal with univariate and multivariate problems, and we compare them. Finally, we apply the adaptive learning concept to the selected model by retraining and updating the model periodically to improve its accuracy. The experimental findings demonstrate that applying adaptive learning in the bidirectional LSTM-based model decreases the prediction error by 45% compared to the baseline models. Moreover, the results reveal that exploiting only the univariate model leads to learning from fewer features; and thus, less time and memory consumption for the model construction and usage.},
  archive      = {J_EAAI},
  author       = {Nawaf Abdulla and Mehmet Demirci and Suat Ozdemir},
  doi          = {10.1016/j.engappai.2022.105440},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105440},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Design and evaluation of adaptive deep learning models for weather forecasting},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine learning approach for truck-drones based last-mile
delivery in the era of industry 4.0. <em>EAAI</em>, <em>116</em>,
105439. (<a
href="https://doi.org/10.1016/j.engappai.2022.105439">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under the vision of industry 4.0, the integration of drones in last-mile delivery can transform traditional delivery practices and provide competitive advantages. However, the combinatorial nature of the routing problem and the technical limitations of the drones present a real challenge for adopting a stand-alone drone delivery as an alternative to truck delivery. This study introduces the Parking Location and Traveling Salesman Problem with Homogeneous Drones (PLTSPHD). This problem considers a scenario in which a single truck carries identical drones along with parcels from the depot to preassigned launching/parking sites, from where the drones complete the last-mile deliveries. In contrast to previous studies that tackle truck-drone delivery using conventional optimization approaches, this paper proposes a two-phase machine learning (ML) approach for the PLTSPHD, which minimizes the total operational cost of the last-mile problem. The proposed ML approach for PLTSPHD consists of clustering and routing phases. In the first phase, a constrained k -means clustering algorithm is proposed to cluster delivery locations based on the maximum flight range and number of available drones per truck. A deep reinforcement learning (DRL) model is then developed in the second stage to find an optimal route among all constrained clusters. Experimental results show that solving the presented truck-drone problem using the ML framework can significantly reduce the operational cost compared to standard truck delivery. The constrained clustering reduces the complexity of the routing problem while adhering to the constraints. In addition, the trained DRL model outperforms the state-of-art Google’s OR-tools solver and other types of well-known heuristics in terms of both solution quality and computation time. Moreover, a sensitivity analysis of different key parameters is conducted to highlight some key trade-offs in using multiple drones and their dependence on operating costs and problem sizes.},
  archive      = {J_EAAI},
  author       = {Ali Arishi and Krishna Krishnan and Majed Arishi},
  doi          = {10.1016/j.engappai.2022.105439},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105439},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Machine learning approach for truck-drones based last-mile delivery in the era of industry 4.0},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Computer vision for package tracking on omnidirectional
wheeled conveyor: Case study. <em>EAAI</em>, <em>116</em>, 105438. (<a
href="https://doi.org/10.1016/j.engappai.2022.105438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a real-time camera tracking system for package transportation on omnidirectional wheeled conveyor is presented. The camera tracking system is integrated with a closed-loop controller for packages path planning. No additional sensors are used for the controller implementation, only a 2-D Camera. The package’s position and orientation are detected by the camera tracking system in real-time. Two proposed systems are presented, System I is implemented using the conventional image processing technique threshold method while System II is implemented using computer vision. In System II, three computer vision models were evaluated: Detectron2 , YOLOv5 and Faster R-CNN . Experimental results in real-time show that System I have lower accuracy rate 85.7% compared to System II which reported 98% and 88.1% for YOLOv5 and Detectron2 , respectively. YOLOv5 reported the best results among the computer vision models with 1% missing rate, 45.5 FPS and average precision of 99.8%.},
  archive      = {J_EAAI},
  author       = {Mohamed E. El-sayed and Arsany W. Youssef and Omar M. Shehata and Lamia A. Shihata and Eman Azab},
  doi          = {10.1016/j.engappai.2022.105438},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105438},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Computer vision for package tracking on omnidirectional wheeled conveyor: Case study},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust control of a planar snake robot based on interval
type-2 takagi–sugeno fuzzy control using genetic algorithm.
<em>EAAI</em>, <em>116</em>, 105437. (<a
href="https://doi.org/10.1016/j.engappai.2022.105437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents trajectory tracking control of a snake robot in the presence of system uncertainty such as disturbances and parameter uncertainties. First, we derive a realistic dynamic model of the snake robot in the framework of the bond graph technique. Next, we present an interval type-2 Takagi–Sugeno fuzzy proportional–derivative (IT2FPD) control scheme, whose parameters are tuned using a genetic algorithm (GA) optimization approach. An improved optimization formulation with randomness is employed for robust near-optimal parameters. Under the assumption that forward velocity of the robot is always positive, we apply the proposed IT2FPD controller to the snake robot model so that the robot can have locomotion along the desired trajectory against uncertainties. To validate the performance of the proposed robot model and control scheme, we conduct in-depth numerical experiments using 20-sim software. Experimental results demonstrate that the snake robot embedded with the IT2FPD controller achieves a straight-line locomotion with the serpenoid gait function despite infiltration of external disturbances and parameter changes.},
  archive      = {J_EAAI},
  author       = {Garima Bhandari and Ritu Raj and Pushparaj Mani Pathak and Jung-Min Yang},
  doi          = {10.1016/j.engappai.2022.105437},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105437},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust control of a planar snake robot based on interval type-2 Takagi–Sugeno fuzzy control using genetic algorithm},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A global interactive attention-based lightweight denoising
network for locating internal defects of CFRP laminates. <em>EAAI</em>,
<em>116</em>, 105436. (<a
href="https://doi.org/10.1016/j.engappai.2022.105436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Carbon fiber reinforced plastic (CFRP) has become one of the main structural materials for aerospace vehicles. However, some internal defects are prone to occur and have potential to cause significant losses of life and property. Currently, the detection of internal defects for CFRP mainly relies on ultrasonic, and other technologies, while they have disadvantages of low efficiency, and poor adaptability. Therefore, this paper explores a novel method to locate internal defects of CFRP laminates by analyzing vibration signals. Firstly, a signal acquisition scheme is designed. Then, a global interactive attention-based lightweight denoising network (GIALDN) is designed to analyze vibration signals and locate internal defects of CFRP laminates. In GIALDN, the threshold denoising method is used to eliminate noise-related features and improve feature discrimination; a global interactive attention module is designed, which makes the network pay more attention to the valid features while realizing the global interactive connection and obtains the rich contextual features; combining with the convolution layer of de-pooling strategy and multi-layer convolution using the residual connection, the backbone of the network is formed. Finally, an experimental platform is established to test the performance of GIALDN. Results show that the location accuracy of GIALDN can reach 98.68%, which is more than 15% higher than those of VGGnet11 and FaultNet, and is also superior to those of LSTM, RNN, Rsenet18, SEresnet18 and Densenet121. Lastly, the location accuracies of GIALDN on CFRP laminates with the same thickness and different stacking sequences are investigated and a good model applicability can be observed.},
  archive      = {J_EAAI},
  author       = {Bo Yang and Yang Zhang and Shilong Wang and Weichun Xu and Meng Xiao and Yan He and Fan Mo},
  doi          = {10.1016/j.engappai.2022.105436},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105436},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A global interactive attention-based lightweight denoising network for locating internal defects of CFRP laminates},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Recent text-based research and applications in railways: A
critical review and future trends. <em>EAAI</em>, <em>116</em>, 105435.
(<a href="https://doi.org/10.1016/j.engappai.2022.105435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the railway industry, a significant amount of data is stored in the textual format. The advanced development of natural language processing and text mining techniques enable automatic knowledge extraction and discovery from such documents. This paper presents a systematic review with quantitative and qualitative analyses to understand the current state of text-based research in the context of railway transport. The paper collects 107 relevant publications in the past decade and identifies different channels for researchers to obtain text data in railways and the corresponding text analysis application use-cases. Moreover, a comprehensive analysis is performed on the state-of-the-art machine learning and natural language processing methods. Four key research directions, namely multilingual NLP, digital maintenance, external data integration, and railway-centred solution pipeline, are identified from Siemens Mobility’s perspective to highlight the most prominent challenges faced in the railway industry.},
  archive      = {J_EAAI},
  author       = {Kaitai Dong and Igor Romanov and Colin McLellan and Ahmet F. Esen},
  doi          = {10.1016/j.engappai.2022.105435},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105435},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Recent text-based research and applications in railways: A critical review and future trends},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MGNet: Mutual-guidance network for few-shot semantic
segmentation. <em>EAAI</em>, <em>116</em>, 105431. (<a
href="https://doi.org/10.1016/j.engappai.2022.105431">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot semantic segmentation has recently drawn attention for its remarkable potential to segment the regions of different object classes with only a few labeled samples as guidance. Although recent methods have achieved impressive performance, there exist two critical bottleneck problems to be solved. First, most existing methods typically model a target class only using information from the foreground regions of support images, which actually does not adequately exploit the background region information of support images. Second, segmentation performance will be greatly affected when there is a large intra-class variation between the support and query images of the same class. To address these problems, we propose a mutual-guidance network (MGNet) for few-shot semantic segmentation to enhance the discriminative ability of class-specific prototypes. More specifically, the prototype learning module is first devised to learn the class-specific prototype of the foreground and background regions. Then, with non-parametric metric learning, the deep features of the query image are matched with multiple learned prototypes. Finally, to make good use of the ground truth mask of the support image, a reverse auxiliary learning module is constructed to reinforce the learned prototype. Extensive experiments on two standard benchmarks PASCAL- 5 i and COCO- 2 0 i are shown that the proposed method can yield competitive segmentation results with state-of-the-art methods. Surprisingly, our model achieves state-of-the-art results under both 1-shot and 5-shot tasks on more challenging COCO- 2 0 i when ResNet-101 is used as the backbone network.},
  archive      = {J_EAAI},
  author       = {Zhaobin Chang and Yonggang Lu and Xiangwen Wang and Xingcheng Ran},
  doi          = {10.1016/j.engappai.2022.105431},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105431},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MGNet: Mutual-guidance network for few-shot semantic segmentation},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neuromorphic circuit based on the un-supervised learning of
biologically inspired spiking neural network for pattern recognition.
<em>EAAI</em>, <em>116</em>, 105430. (<a
href="https://doi.org/10.1016/j.engappai.2022.105430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most sophisticated platforms for hosting intelligent systems is bio-inspired. This study proposes pattern recognition hardware using a biologically inspired Spiking Neural Network (SNN) and the new dimensionality reduction approach. The SNN model is based on real neural networks consisting of spiking neurons linked by excitatory and inhibitory synapses activated by excitatory and inhibitory neurotransmitters. Also, a semi-supervised (un-supervised STDP based learning with supervised weight initialization), spike-based learning strategy based on the learning procedure of the nervous system is used to teach the spiking output layer neurons, albeit that the hardware implementation benefits from a semi-supervised approach. The goal of this research is to accurately categorize patterns in the MNIST and CIFAR10 datasets using an SNN-based hardware platform. Due to the limitations of the latter’s resources, a dimensionality reduction based on principal component analysis (PCA) is proposed to speed up the processing procedure and reduce the hardware implementation cost. The presented pattern recognition platform is implemented using the Xilinx® VIVADO high-level synthesis platform (HLS). Finally, optimization approaches are used to improve the used space, reduce hardware implementation delay, and speed up the design process.},
  archive      = {J_EAAI},
  author       = {Soheila Nazari and Alireza Keyanfar and Marc M. Van Hulle},
  doi          = {10.1016/j.engappai.2022.105430},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105430},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Neuromorphic circuit based on the un-supervised learning of biologically inspired spiking neural network for pattern recognition},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Geometric characteristic learning r-CNN for shockproof
hammer defect detection. <em>EAAI</em>, <em>116</em>, 105429. (<a
href="https://doi.org/10.1016/j.engappai.2022.105429">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shockproof hammers are key components of power transmission lines. Aiming at the problems regarding the same kind of defect having various manifestations, different defects having similarities, and defect data being difficult to obtain, a geometric characteristic learning region-based convolutional neural network (GCL R-CNN) is proposed to detect shockproof hammer defects in aerial images of transmission lines. First, a GCL module is proposed for the first time and introduced in the Faster R-CNN, and artificial samples are generated via 3D modeling. Second, to make the model pay more attention to the geometric characteristics of the observed shockproof hammer, artificial samples with monochromatic backgrounds are used to guide the neural network training process. In this way, the model can better learn the salient features of the shockproof hammer defects and the model’s ability to distinguish normal samples from defective samples is enhanced. Finally, in the case of few samples of shockproof hammer defects, artificial samples with real backgrounds are used to expand the training set and improve the accuracy of shockproof hammer defect detection. Experimental results on real aerial images of transmission lines show that the proposed model can accurately detect normal shockproof hammers, missing shockproof hammer heads and tilted shockproof hammers, with detection accuracies of 93.8%, 89.94% and 66.22%, respectively. The above results show that the proposed model can realize the detection of two types of defects in the shockproof hammer, that is, the fault diagnosis of the shockproof hammer.},
  archive      = {J_EAAI},
  author       = {Yongjie Zhai and Ke Yang and Zhenyuan Zhao and Qianming Wang and Kang Bai},
  doi          = {10.1016/j.engappai.2022.105429},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105429},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Geometric characteristic learning R-CNN for shockproof hammer defect detection},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Localization of myocardial infarction using a multi-branch
weight sharing network based on 2-d vectorcardiogram. <em>EAAI</em>,
<em>116</em>, 105428. (<a
href="https://doi.org/10.1016/j.engappai.2022.105428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early diagnosis and localization of myocardial infarction (MI) assist clinicians in saving numerous lives through the timely treatment for patients with MI. Vectorcardiogram (VCG) can reflect the characteristic changes of cardiac electrical activity in MI in detail. In this context, the present study reports a multi-branch weight sharing network model based on 2-D VCG constructed to realize the automatic localization of MI. The three-branch network extracted the spatial morphological features of the three planes of the 2-D VCG, respectively, and the weight-sharing part of the network obtained the spatial correlation information among the three planes. Subsequently, the Softmax classifier was employed to classify normal individuals and MI patients (11 class infarct sites). To evaluate the performance of the proposed method for MI localization, PTB(Physikalisch-Technische Bundesanstalt) diagnostic ECG database was employed. The localization accuracy, sensitivity, and specificity achieved using the proposed method were 99.87%, 99.92%, and 99.99%, respectively. Thus, the proposed scheme is expected to be useful in assisting cardiologists in interpreting VCG for clinical diagnosis.},
  archive      = {J_EAAI},
  author       = {Cong He and Ming Liu and Peng Xiong and Jianli Yang and Haiman Du and Jinpeng Xu and Zengguang Hou and Xiuling Liu},
  doi          = {10.1016/j.engappai.2022.105428},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105428},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Localization of myocardial infarction using a multi-branch weight sharing network based on 2-D vectorcardiogram},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid multi-step sensitivity-driven evolutionary
polynomial regression enables robust model structure selection.
<em>EAAI</em>, <em>116</em>, 105421. (<a
href="https://doi.org/10.1016/j.engappai.2022.105421">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary Polynomial Regression (EPR) has found widespread application and use for model structure development in engineering and science. This hybrid evolutionary approach merges real world data and explanatory variables to generate well-structured models in the form of polynomial equations. The simple and transparent models produced by this technique enable us to explore, via sensitivity analysis, the robustness of the derived models. Yet, existing EPR frameworks do not make explicit use of sensitivity analysis in the selection of robust and high-fidelity model structures. In this paper, we develop a multi-step sensitivity-driven method which combines the strengths of differential evolution and model selection via Monte Carlo simulation to explore the input–output relationships of model structures. In the first step, our hybrid approach automatically determines the optimum number of terms of the polynomial equations. In a subsequent step, our algorithm explores the mean parametric response of each explanatory variable used in the mathematical formulation to select a final model structure. Finally, in our selection of the most robust mathematical structure, we take explicit consideration of the prediction uncertainty of the simulated output. We illustrate and evaluate our EPR method for different engineering problems involving modeling and prediction of the moisture content and creep index of soils. Altogether, our results demonstrate that the use of sensitivity analysis as an integral part of model structure search and selection will lead to robust models with high predictive ability.},
  archive      = {J_EAAI},
  author       = {Ruan G.S. Gomes and Guilherme J.C. Gomes and Jasper A. Vrugt},
  doi          = {10.1016/j.engappai.2022.105421},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105421},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid multi-step sensitivity-driven evolutionary polynomial regression enables robust model structure selection},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DPCFN: Dual path cross fusion network for medical image
segmentation. <em>EAAI</em>, <em>116</em>, 105420. (<a
href="https://doi.org/10.1016/j.engappai.2022.105420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thanks to the better performance of U-Net in medical segmentation, many U-Net variants have emerged one after another, but U-Net has the non-negligible drawback that it cannot accurately segment low-level features such as edge regions of images, and in addition this simple skip connection of U-Net itself is still a challenge for global information modeling. To solve the above problems, Channel-wise Cross Fusion Transformer (CCT) and Channel-wise Cross Attention (CCA) are introduced on the basis of U-Net, where CCT is used for cross fusion of U-Net encoders and Transformer, and CCA interacts the fused features with the decoder features to eliminate semantic gaps, naming the network Trans-Net. Another branch network SeU-Net is built to capture details and edge regions, and SE-Attention is added at the skip joints of the network to reinforce important features. The two branches interact through a Cross Residual Feature Block (CRFB). By testing on five datasets, it was experimentally demonstrated that the method proposed in this paper has more accurate segmentation performance.},
  archive      = {J_EAAI},
  author       = {Shen Jiang and Jinjiang Li and Zhen Hua},
  doi          = {10.1016/j.engappai.2022.105420},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105420},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {DPCFN: Dual path cross fusion network for medical image segmentation},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ASPD-net: Self-aligned part mask for improving text-based
person re-identification with adversarial representation learning.
<em>EAAI</em>, <em>116</em>, 105419. (<a
href="https://doi.org/10.1016/j.engappai.2022.105419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-based person re-identification aims to retrieve images of the corresponding person from a large visual database according to a natural language description. When it comes to visual local information extraction, most of the state-of-the-art methods adopt either a strict uniform strategy which can be too rough to catch local details properly, or pre-processing with external cues which may suffer from the deviations of the pre-trained model and the large computation consumption. In this paper, we proposed an Adversarial Self-aligned Part Detecting Network (ASPD-Net) model which extracts and combines multi-granular visual and textual features. A novel Self-aligned Part Mask Module was presented to autonomously learn the information of human body parts, and obtain visual local features in a soft-attention manner by using K Self-aligned Part Mask Detectors. Regarding the main model branches as a generator, a discriminator is employed to determine whether the representation vector comes from the visual modality or the textual modality. With Adversarial Loss training, ASPD-Net can learn more robust representations, as long as it successfully tricks the discriminator. Experimental results demonstrate that the proposed ASPD-Net outperforms the previous methods and achieves the state-of-the-art performance on the CUHK-PEDES and RSTPReid datasets.},
  archive      = {J_EAAI},
  author       = {Zijie Wang and Jingyi Xue and Xili Wan and Aichun Zhu and Yifeng Li and Xiaomei Zhu and Fangqiang Hu},
  doi          = {10.1016/j.engappai.2022.105419},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105419},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ASPD-net: Self-aligned part mask for improving text-based person re-identification with adversarial representation learning},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A self-learning hyper-heuristic for the distributed assembly
blocking flow shop scheduling problem with total flowtime criterion.
<em>EAAI</em>, <em>116</em>, 105418. (<a
href="https://doi.org/10.1016/j.engappai.2022.105418">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The distributed assembly blocking flow shop scheduling problem, which is a significant scenario in modern supply chains and manufacturing systems, has attracted significant attention from researchers and practitioners. To formulate the problem, a mixed-integer linear programming model is introduced to optimize the total flowtime. A constructive heuristic (HHNRa) and a self-learning hyper-heuristic (SLHH) are proposed to address the scheduling problem. HHNRa is designed based on the problem-specific knowledge to obtain initial solutions with high quality. A self-learning high-level strategy based on the historical success rate of low-level heuristics is presented to manipulate the low-level heuristics to operate in the solution space. In addition, a restart scheme with three distinct constructive heuristics is utilized to maintain the diversity of the solution. Based on 900 small-scale benchmark instances and 810 large-scale benchmark instances, comprehensive numerical experiments are conducted to evaluate the performance of the proposed SLHH algorithm. The results of the statistical analysis indicate that the proposed self-learning hyper-heuristic is superior to the compared state-of-the-art algorithms for the problem under consideration. Consequently, the proposed constructive heuristic and the self-learning hyper-heuristic are effective methods for the distributed assembly blocking flow shop scheduling problem.},
  archive      = {J_EAAI},
  author       = {Fuqing Zhao and Shilu Di and Ling Wang and Tianpeng Xu and Ningning Zhu and Jonrinaldi},
  doi          = {10.1016/j.engappai.2022.105418},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105418},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A self-learning hyper-heuristic for the distributed assembly blocking flow shop scheduling problem with total flowtime criterion},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust assembly line balancing problem considering
preventive maintenance scenarios with interval processing time.
<em>EAAI</em>, <em>116</em>, 105417. (<a
href="https://doi.org/10.1016/j.engappai.2022.105417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering preventive maintenance (PM) scenarios in the assembly line balancing problem (ALBP) have been proved effective and can be used to increase production efficiency. All these studies assumed that the processing time of tasks was fixed. However, many factors can affect the processing time in the actual production process and make the original task allocation plans infeasible. The robust method is introduced to solve the uncertain processing time, and the robust ALBP considering PM scenarios (RALBP_PMs) is studied in this paper. In this problem, three objectives are optimized: the cycle time under the regular scenario, the maximum cycle time, and the maximum task alteration under all PM scenarios. A robust mixed-integer optimization model is proposed to hedge against uncertainty, and then it is linearized by duality to make it solvable. A Q-learning-based variable neighborhood search (QVNS) algorithm with several improvements is designed to solve this problem. Several heuristic rules are designed to improve the performance of the initial population. Roulette wheel selection based on crowding distance is designed to select a solution with more potential. Eleven problem-specific neighborhood structures are designed to improve search efficiency. These structures are sorted by the Q-learning-based sorting method to find a good solution quickly. Experiment results demonstrate that considering PM scenarios in RALBP is necessary. The proposed mathematical model can obtain the Pareto solutions of small-scale instances, and the proposed QVNS algorithm is more suitable for solving large-scale instances.},
  archive      = {J_EAAI},
  author       = {Kai Meng and Qiuhua Tang and Zikai Zhang},
  doi          = {10.1016/j.engappai.2022.105417},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105417},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust assembly line balancing problem considering preventive maintenance scenarios with interval processing time},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Segmentation of medical images using an attention embedded
lightweight network. <em>EAAI</em>, <em>116</em>, 105416. (<a
href="https://doi.org/10.1016/j.engappai.2022.105416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate segmentation of computerized tomography (CT) images is of great significance to clinical diagnosis. However, because of the high similarity of gray values, it is a challenging task for CT image segmentation. The encoder and decoder based CNN architecture has greatly improved the segmentation effect, but it also encounters a bottleneck due to the information loss in the encoding process. In view of this, we proposed an image segmentation model based on a novel network architecture for medical image segmentation. To improve the efficiency and decrease the number of model parameters, we optimized the Inception module by substituting the depth-wise separable convolutions (DWSC) for the standard convolutions. Then, the optimized Inception module paired with the residual network was chosen as the backbone extractor to extract high-quality image features. Further, a hybrid attention mechanism, which consists of channel-wise and spatial attention, was incorporated into the network to realize the maximum reuse of inter-channel relationships and spatial point characteristics. In particular, the attention module was separately embedded into the contracting and expansive paths to enhance the feature extraction capability and detail restoration effects. The experimental indicators were significantly improved on the test dataset, and the intersection over union (IoU) of the proposed method reached no less than 0.9645, 0.6499, and 0.7945 on the Lung, Colon tumor, and DRIVE datasets, respectively, which demonstrated the effectiveness of the proposed method. Our code and data are available at https://github.com/xtu502/medical-image-segmentation/ .},
  archive      = {J_EAAI},
  author       = {Junde Chen and Weirong Chen and Adan Zeb and Defu Zhang},
  doi          = {10.1016/j.engappai.2022.105416},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105416},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Segmentation of medical images using an attention embedded lightweight network},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Topological analysis of intuitionistic fuzzy distance
measures with applications in classification and clustering.
<em>EAAI</em>, <em>116</em>, 105415. (<a
href="https://doi.org/10.1016/j.engappai.2022.105415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The distance measure is a vital classifier used to solve classification and clustering problems in a metric space. In this paper, we discussed the types of distance measures and elaborated that they generate uniquely shaped balls. Due to their balls, they cannot guarantee a satisfactory classification outcome for a given dataset. To address this limitation, researchers used intuitionistic fuzzy sets (IFSs) to lose the boundary of belongingness of data points in a given metric space with respect to the chosen membership and non-membership functions and accomplished some novel intuitionistic fuzzy distance measures (IFDMs). IFDMs are successfully used in various applications; however, they also predict counterintuitive cases. To address this issue, in this paper, we conducted a topological analysis of intuitionistic fuzzy distance measures. To do that, we constructed three categories of distance measures; Type 1 distance measures, Type 2 distance measures, and Intuitionistic fuzzy distance measures (in this paper, we called them Intuitive Distance Measures (IDMs)). We further sub-categorized Intuitive Distance Measures into Type 1 Intuitive Distance Measures (T1IDMs) and Type 2 Intuitive Distance Measures (T2IDMs). We established a homeomorphic relation between the topological spaces generated by the T1IDMs and T2IDMs. Using the proposed homeomorphic relation and proving the necessary lemma and theorems, we presented the type 2 distance measures of well-known normable T1IDMs. We applied the proposed type 2 variants to solve some classification and clustering problems of machine learning. The result analysis shows that the proposed type 2 variants overcome the drawbacks of their type 1 counterparts.},
  archive      = {J_EAAI},
  author       = {Mohd Shoaib Khan and Q.M. Danish Lohani},
  doi          = {10.1016/j.engappai.2022.105415},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105415},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Topological analysis of intuitionistic fuzzy distance measures with applications in classification and clustering},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel two-stage TOPSIS approach based on interval-valued
probabilistic linguistic q-rung orthopair fuzzy sets with its
application to MAGDM problems. <em>EAAI</em>, <em>116</em>, 105413. (<a
href="https://doi.org/10.1016/j.engappai.2022.105413">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy theories are widely used in multi-attribute group decision-making (MAGDM) problems to describe uncertain and hesitant information. The recently proposed probabilistic linguistic q-rung orthopair fuzzy set (PLq-ROFS) is capable in dealing with quantitative and qualitative information simultaneously. However, in many actual situations, decision-makers (DMs) prefer to utilize interval values to express their minds and evaluations, this paper employs interval values to represent the probabilistic distribution of the membership degrees (MDs) and non-membership degrees (NMDs), and proposes the interval-valued PLq-ROFS (IVPLq-ROFS). Based on which, a novel two-stage TOPSIS approach is introduced. The IVPLq-ROFS weighted extended power average (IVPLq-ROFWEPA) operator is proposed to obtain the comprehensive matrix and weights of each attribute, while a further advanced TOPSIS model is constructed to get the final rank of alternatives. An example of a new-type smart city development evaluation problem is given to illustrate the efficacy of the proposed approach. Results show that our approach is more flexible, more adaptable, more accurate, more freedom, and has much lower calculation complexity in the calculation process of the MAGDM problem. The contributions of the proposed method are mainly manifested in giving the concept of IVPLq-ROFSs, and proposing a novel two-stage TOPSIS model for dealing with MAGDM problems under IVPLq-ROFSs.},
  archive      = {J_EAAI},
  author       = {Yuan Xu and Shifeng Liu and Jun Wang and Xiaopu Shang},
  doi          = {10.1016/j.engappai.2022.105413},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105413},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel two-stage TOPSIS approach based on interval-valued probabilistic linguistic q-rung orthopair fuzzy sets with its application to MAGDM problems},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TPET: Two-stage perceptual enhancement transformer network
for low-light image enhancement. <em>EAAI</em>, <em>116</em>, 105411.
(<a href="https://doi.org/10.1016/j.engappai.2022.105411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-light images captured under low light or backlight conditions can suffer from different types of degradation such as low visibility, strong noise and color distortion. In this paper, to solve the degradation problem of low-light images, we propose Two-stage Perceptual Enhancement Transformer Network(TPET) for Low-light Image Enhancement by combining the advantages of local spatial perception of convolutional neural network and global spatial perception of transformer. The method is generally divided into two stages: feature extraction stage and detail fusion stage. First, in the feature extraction stage, the encoder composed of transformers performs global feature extraction and expands the receptive field. Since the transformer lacks the ability to capture local features, we introduce a perceptual enhancement module (PEM) to improve the interaction of local and global feature information. Second, between the corresponding encoding and decoding blocks in each layer, a feature fusion block (FFB) is introduced to compensate the feature information at different scales to improve the reusability of features and enhance the stability of the network. In addition, between the two stages, the local information features are redistributed and the network supervision capability is improved by introducing a self-calibration module (SCM). In the detail fusion stage, in order to further preserve the details of textural features of the image, we designed a detail enhancement unit (DEU) for recovering high-resolution enhanced images. Through qualitative comparison and quantitative analysis, our method outperforms other low-light image enhancement methods in terms of subjective visual effects and objective metrics values.},
  archive      = {J_EAAI},
  author       = {Hengshuai Cui and Jinjiang Li and Zhen Hua and Linwei Fan},
  doi          = {10.1016/j.engappai.2022.105411},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105411},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {TPET: Two-stage perceptual enhancement transformer network for low-light image enhancement},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A double-layer coding model with a rotation-based particle
swarm algorithm for unmanned combat aerial vehicle path planning.
<em>EAAI</em>, <em>116</em>, 105410. (<a
href="https://doi.org/10.1016/j.engappai.2022.105410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned combat aerial vehicle (UCAV) technology has to address many challenges in complex battlefield environments. To produce a safe and low-energy flying path, a UCAV requires many points to build a path that avoids threats, which increases the problem dimension, consumes more computational resources and makes the results unstable. To address this issue, this paper employs a new model known as double-layer coding (DLC) for path planning with unevenly distributed points to decrease the number of superfluous points on the path. Meanwhile, the RPSO algorithm, which introduces a novel strategy of rotating particles in high-dimensional space to search for targets, is proposed as an enhanced particle swarm optimization (PSO) algorithm. The proposed method effectively improves PSO ′ s exploration capacity. Furthermore, RPSO is employed to implement the double-layer coding model for path planning (DLCRPSO). The experimental results show that the proposed DLCRPSO method for path planning always produces feasible flight paths in complex environments.},
  archive      = {J_EAAI},
  author       = {Yingjuan Jia and Liangdong Qu and Xiaoqin Li},
  doi          = {10.1016/j.engappai.2022.105410},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105410},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A double-layer coding model with a rotation-based particle swarm algorithm for unmanned combat aerial vehicle path planning},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A distance of quantum mass function and its application in
multi-source information fusion method based on discount coefficient.
<em>EAAI</em>, <em>116</em>, 105407. (<a
href="https://doi.org/10.1016/j.engappai.2022.105407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distance measures provide a novel perspective for measuring the difference or consistency between bodies of evidence, which have been used in a wide range of fields. However, under the framework of quantum mass function, existing distances cannot measure the difference. Hence, this paper formulates a new distance measure, referred to as the distance of the quantum mass functions. The purpose of this distance measure is to quantify the difference between quantum mass functions. It can be demonstrated mathematically that it is a strict distance measure that satisfies the nonnegativity, symmetry, definiteness, triangle inequality. The proposed distance measure is a generalization of the classical evidence distance, and it introduces the concept of Minkowski distance as well. It is therefore not only able to reflects the difference of discord and non-specificity in the mass functions, but it also has the advantage of Minkowski distance, as well as high compatibility. Moreover, A number of numerical examples are also provided to illustrate its properties and advantages. Using the proposed distance measure, we design a new information fusion method based on the discount coefficient within a complex framework. As a further investigation, the proposed fusion method is applied to several data sets experiments and results indicate that compared to other methods, it has a certain potential in the field of multi-source information fusion under the framework of evidence theory.},
  archive      = {J_EAAI},
  author       = {Lipeng Pan and Xiaozhuan Gao and Yong Deng},
  doi          = {10.1016/j.engappai.2022.105407},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105407},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A distance of quantum mass function and its application in multi-source information fusion method based on discount coefficient},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Measuring technological innovation efficiency using interval
type-2 fuzzy super-efficiency slack-based measure approach.
<em>EAAI</em>, <em>116</em>, 105405. (<a
href="https://doi.org/10.1016/j.engappai.2022.105405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important leading industry in China’s economy, the high-tech industry needs to systematically analyze technological innovation activities, thereby measuring the technological innovation efficiency and further improving sustainable development. The high-tech industry in different provinces benefits from individual policies due to their geographical locations. However, since the intensity of policy implementation in the technological innovation activities of the provincial high-tech industry is qualitative information, which is difficult to be expressed by quantitative data and rarely considered in the efficiency assessment. Therefore, this study adopts interval type-2 fuzzy sets to characterize the uncertain qualitative information and constructs an interval type-2 fuzzy evaluation method to measure the technological innovation efficiency of China’s high-tech industry. More specifically, considering the handling of undesirable outputs and the ranking of multiple efficient decision-making units, the super-efficiency slack-based measure (SBM)-Data envelopment analysis (DEA) method has been selected as the basic evaluation model. Then, the super-efficiency SBM-DEA model has been extended into an interval type-2 evaluation approach by considering the uncertain variables. Moreover, the α -cuts and best-and-worst methods are introduced to conduct the decomposition of the proposed evaluation model and aggregate the ultimate efficiency. Finally, a comparative analysis of technological innovation efficiency in the regional high-tech industry has been performed to validate the applicability of the proposed model.},
  archive      = {J_EAAI},
  author       = {Xiaoqing Chen and Xinwang Liu and Qun Wu and Muhammet Deveci and Luis Martínez},
  doi          = {10.1016/j.engappai.2022.105405},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105405},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Measuring technological innovation efficiency using interval type-2 fuzzy super-efficiency slack-based measure approach},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Randomly initialized CNN with densely connected stacked
autoencoder for efficient fire detection. <em>EAAI</em>, <em>116</em>,
105403. (<a
href="https://doi.org/10.1016/j.engappai.2022.105403">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision sensors-based fire detection is an interesting and useful research domain with significant alleviated attention from computer vision experts. The baseline research is based on low-level color features, lately replaced by the effective representation of deep models, achieving better accuracy, but higher false alarm rates still exist with expensive computations. Furthermore, the current feed-forward neural networks initialize and allocate the weights according to the input shape, posing a vanishing gradient problem with slow convergence speed. The main challenges associated with fire detection are the limited performance of the developed models in terms of accuracy, higher false alarm rates, higher computational complexity, and vanishing gradient problems for very deep network architectures. To tackle these issues, herein, we introduce Stacked Encoded-EfficientNet (SE-EFFNet), a cost-aware deep model with reduced false alarm rates and better fire recognition abilities. SE-EFFNet uses a lightweight EfficientNet as a backbone to extract useful features that are further refined using stacked autoencoders before the final classification decision. The stacked autoencoder in SE-EFFNet is not linearly connected, but we use dense connections to ensure effective fire scene recognition, where the weights are randomly initialized to solve the vanishing gradient problems and provide fast convergence speed. The experimental evaluation using benchmarks against recent state-of-the-art demonstrates better recognition abilities of SE-EFFNet and flexible inferencing potentials toward edge devices. We also offer evaluation using favorable lightweight models before selecting the optimal SE-EFFNet.},
  archive      = {J_EAAI},
  author       = {Zulfiqar Ahmad Khan and Tanveer Hussain and Fath U Min Ullah and Suneet Kumar Gupta and Mi Young Lee and Sung Wook Baik},
  doi          = {10.1016/j.engappai.2022.105403},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105403},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Randomly initialized CNN with densely connected stacked autoencoder for efficient fire detection},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MARCOS approach based upon cubic fermatean fuzzy set and its
application in evaluation and selecting cold chain logistics
distribution center. <em>EAAI</em>, <em>116</em>, 105401. (<a
href="https://doi.org/10.1016/j.engappai.2022.105401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evaluation and selection of cold chain logistics distribution center (CCLDC) possesses important strategic significance for enterprises to optimize logistics network. This paper firstly introduces an innovative uncertain information representation model called cubic Fermatean fuzzy set (CCFS) by integrating the cubic fuzzy set (CFS) and Fermatean fuzzy set (FFS) to portray the complicated indeterminacy and inaccuracy information. To begin with, the definition, score and accuracy functions, comparison laws, and generalized distance measure of CFFS are all defined successively. Then, based upon the defined Aczel-Alsina operations of CFFS, several cubic Fermatean fuzzy Aczel-Alsina aggregation operators are presented to flexibly integrate the cubic Fermatean fuzzy information, as well as some elegant properties of those operators are investigated at length. Again, two weight identification models are introduced based upon the defined score function and distance measure to calculate the weight of experts and criteria. In addition, an extended measurement alternatives and ranking based on the compromise solution (MARCOS) method by means of the presented operators, score function, and distance measure is brought forward within cubic Fermatean fuzzy circumstance. Consequently, an empirical study about the evaluation and selection of CCLDC is applied to demonstrate the efficacy and practicability of the presented method. Moreover, the comparative study and sensibility analysis are implemented to validate the rationality and superiority of the propounded method in addressing the problem of selecting the optimal CCLDC. The outcomes reflect that the developed approach provides a synthetic, robust and operable group decision framework for the evaluation and selection of CCLDC within an uncertain context.},
  archive      = {J_EAAI},
  author       = {Yuan Rong and Liying Yu and Wenyao Niu and Yi Liu and Tapan Senapati and Arunodaya Raj Mishra},
  doi          = {10.1016/j.engappai.2022.105401},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105401},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MARCOS approach based upon cubic fermatean fuzzy set and its application in evaluation and selecting cold chain logistics distribution center},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A review of driver fatigue detection and its advances on the
use of RGB-d camera and deep learning. <em>EAAI</em>, <em>116</em>,
105399. (<a
href="https://doi.org/10.1016/j.engappai.2022.105399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driver fatigue is an essential reason for traffic accidents, which poses a severe threat to people’s lives and property. In this review, we summarize the latest research findings and analyze the developmental trends of driver fatigue detection. Firstly, we analyze and discuss four types of different fatigue detection technologies based on driver physiological signals, behavior features, vehicle running features, and information fusion, respectively. Then, we focus on RGB-D camera and deep learning which are two state-of-the-art solutions in this field. Finally, we present the work on integration of RGB-D camera and deep learning, where Generative Adversarial Networks and multi-channel schemes are utilized to enhance the performance. We conducted experiments to show that the fatigue features extracted by Convolutional Neural Networks are superior to traditional handcrafted ones while single features cannot guarantee robustness. Moreover, the latent fatigue features extracted by deep learning methods have been demonstrated to be effective for fatigue detection.},
  archive      = {J_EAAI},
  author       = {Fan Liu and Delong Chen and Jun Zhou and Feng Xu},
  doi          = {10.1016/j.engappai.2022.105399},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105399},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A review of driver fatigue detection and its advances on the use of RGB-D camera and deep learning},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). E-GCS: Detection of COVID-19 through classification by
attention bottleneck residual network. <em>EAAI</em>, <em>116</em>,
105398. (<a
href="https://doi.org/10.1016/j.engappai.2022.105398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: Recently, the coronavirus disease 2019 (COVID-19) has caused mortality of many people globally. Thus, there existed a need to detect this disease to prevent its further spread. Hence, the study aims to predict COVID-19 infected patients based on deep learning (DL) and image processing. Objectives: The study intends to classify the normal and abnormal cases of COVID-19 by considering three different medical imaging modalities namely ultrasound imaging, X-ray images and CT scan images through introduced attention bottleneck residual network (AB-ResNet). It also aims to segment the abnormal infected area from normal images for localising the disease infected area through the proposed edge based graph cut segmentation (E-GCS). Methodology: AB-ResNet is used for classifying images whereas E-GCS segment the abnormal images. The study possess various advantages as it rely on DL and possess capability for accelerating the training speed of deep networks. It also enhance the network depth leading to minimum parameters, minimising the impact of vanishing gradient issue and attaining effective network performance with respect to better accuracy. Results/Conclusion: Performance and comparative analysis is undertaken to evaluate the efficiency of the introduced system and results explores the efficiency of the proposed system in COVID-19 detection with high accuracy (99%).},
  archive      = {J_EAAI},
  author       = {T. Ahila and A.C. Subhajini},
  doi          = {10.1016/j.engappai.2022.105398},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105398},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {E-GCS: Detection of COVID-19 through classification by attention bottleneck residual network},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial intelligence in single screw polymer extrusion:
Learning from computational data. <em>EAAI</em>, <em>116</em>, 105397.
(<a href="https://doi.org/10.1016/j.engappai.2022.105397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single screw polymer extrusion can be seen as a multi-objective optimization problem where a set of design variables must be defined as a function of objectives and constraints that are to be satisfied simultaneously. The development of powerful modelling routines based on the use of numerical methods allows linking those objectives with the decision variables. In reality, only a single solution can be used in the problem under consideration. However, the computation times become prohibitive when effective optimization algorithms dealing with multi-objectives and decision-making are to be used, such as those based on populations of solutions. It is proposed here the use of Artificial Intelligence techniques to determine the interrelation between the design variables and the objectives. For that, a data analysis technique, named DAMICORE, was used to define these interrelations. Examples, involving the design of a screw extruder, a barrel grooves section, and a rotational barrel segment, were investigated using the proposed AI techniques. The results obtained show a good correspondence with the expected thermomechanical behaviour of the process. This constitutes an initial step in the application of AI techniques in different fields of engineering in the way of accomplishing, in the future, optimization based on the use of available data.},
  archive      = {J_EAAI},
  author       = {António Gaspar-Cunha and Francisco Monaco and Janusz Sikora and Alexandre Delbem},
  doi          = {10.1016/j.engappai.2022.105397},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105397},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Artificial intelligence in single screw polymer extrusion: Learning from computational data},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A bi-level model and hybrid heuristic algorithm for the
optimal location of prefabricated building industrial park.
<em>EAAI</em>, <em>116</em>, 105393. (<a
href="https://doi.org/10.1016/j.engappai.2022.105393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal location for prefabricated building industrial park (PBIP) can significantly reduce the logistic cost, delivery time and environmental pollution of prefabricated and modular construction. PBIP site selection problems can be more complex than other location selection problems when considering the goals of the PBIP at a manager level and a costumer level. There is little to no research that has examined the bi-level model for PBIP site selection. Thus, this paper addresses this issue by constructing a quantitative bi-level programming model which considers the economic, traffic, and environmental constrains. Subsequently, combining the genetic algorithm and Partan Frank–Wolfe​ algorithm, a hybrid heuristic algorithm is constructed to calculate the model. An empirical analysis is then carried out in the case of Chongqing, China. The results clearly demonstrate the applicability of the model. Furthermore, the paper discusses the trade-off between transport costs and environmental benefits, and the impact of transport radius on transport schemes. The proposed model contributes to solving location–allocation problems. It considers road congestion and traffic distribution by combining the location–allocation model with the user equilibrium model. The model can aid planners in making more robust decisions for setting up new PBIPs, thus contributing to the sustainable development of prefabricated and modular construction.},
  archive      = {J_EAAI},
  author       = {Ruopeng Huang and Kaijian Li and Guiwen Liu and Asheem Shrestha and Ruidong Chang and Xiaoya Tang},
  doi          = {10.1016/j.engappai.2022.105393},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105393},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A bi-level model and hybrid heuristic algorithm for the optimal location of prefabricated building industrial park},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reliability assessment and prediction of rolling bearings
based on hybrid noise reduction and BOA-MKRVM. <em>EAAI</em>,
<em>116</em>, 105391. (<a
href="https://doi.org/10.1016/j.engappai.2022.105391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To figure out the problem of reliability assessment and prediction due to the noise in rolling bearing vibration signals, bearing reliability assessment and prediction model was proposed combine intrinsic time-scale decomposition-adaptive maximum correlation kurtosis deconvolution (ITD-AMCKD) and Bayesian optimization algorithm mixed kernel relevance vector machine(BOA-MKRVM). First, the ITD-AMCKD hybrid model is come up with to decrease noise and extract valid information of bearing vibration signal; secondly, set up the reliability assessment model of bearing through logistic regression model; in the end, use BOA-MKRVM model to predict bearing degraded state, then substitute consequence into established reliability assessment model to acquire the prediction consequence of the bearing’s reliability. The test data from Xi’an Jiaotong University demonstrate availability of model in the paper.},
  archive      = {J_EAAI},
  author       = {Shuzhi Gao and Yifan Yu and Yimin Zhang},
  doi          = {10.1016/j.engappai.2022.105391},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105391},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reliability assessment and prediction of rolling bearings based on hybrid noise reduction and BOA-MKRVM},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Investigation of the pharmaceutical warehouse locations
under COVID-19—a case study for duzce, turkey. <em>EAAI</em>,
<em>116</em>, 105389. (<a
href="https://doi.org/10.1016/j.engappai.2022.105389">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pharmaceutical warehouses are among the centers that play a critical role in the delivery of medicines from the producers to the consumers. Especially with the new drugs and vaccines added during the pandemic period to the supply chain, the importance of the regions they are located in has increased critically. Since the selection of pharmaceutical warehouse location is a strategic decision, it should be handled in detail and a comprehensive analysis should be made for the location selection process. Considering all these, in this study, a real-case application by taking the problem of selecting the best location for a pharmaceutical warehouse is carried out for a city that can be seen as critical in drug distribution in Turkey. For this aim, two effective multi-criteria decision-making (MCDM) methodologies, namely Analytic Hierarchy Process (AHP) and Evaluation based on Distance from Average Solution (EDAS), are integrated under spherical fuzzy environment to reflect fuzziness and indeterminacy better in the decision-making process and the pharmaceutical warehouse location selection problem is discussed by the proposed fuzzy integrated methodology for the first time. Finally, the best region is found for the pharmaceutical warehouse and the results are discussed under the determined criteria. A detailed robustness analysis is also conducted to measure the validity, sensibility and effectiveness of the proposed methodology. With this study, it can be claimed that literature has initiated to be revealed for the pharmaceutical warehouse location problem and a guide has been put forward for those who are willing to study this area.},
  archive      = {J_EAAI},
  author       = {Melike Erdogan and Ertugrul Ayyildiz},
  doi          = {10.1016/j.engappai.2022.105389},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105389},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Investigation of the pharmaceutical warehouse locations under COVID-19—A case study for duzce, turkey},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new approach to dominant motion pattern recognition at the
macroscopic crowd level. <em>EAAI</em>, <em>116</em>, 105387. (<a
href="https://doi.org/10.1016/j.engappai.2022.105387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic analysis and the recognition and prediction of the behaviour of large-scale crowds in video-surveillance data is a research field of paramount importance for the security of modern societies. It serves to predict and help prevent disasters in public places where crowds of people gather. The paper proposes a novel method for generating meta-tracklets and recognition of dominant motion patterns as a basis for automatic crowd behaviour analysis at the macroscopic level, where a crowd is treated as an entity. The basic characteristic of macroscopic crowd scenes is that it is impossible to detect and track individuals in the scene. The idea of the method proposed in this paper is to recognize dominant crowd motion patterns, by avoiding time-consuming and error-sensitive crowd segmentation, crowd tracking and detection of regions of interest. Thus, the process of determining dominant motion patterns and recognizing crowd behaviour is accelerated. The method is inspired by a quantum mechanical approach. It combines a set of particles, which are considered as particles in quantum mechanics, tracklets of particles’ advection in a video clip, and the interaction of wave functions spread out from particle positions. A wave function is expressed in the form of an asymmetric potential function. Peaks of the wave field define the most probable particle flow, which defines a meta-tracklet. Dominant motion patterns are recognized by applying the functions of fuzzy predicates, which represent a combination of common-sense and human expert knowledge about crowd motions, to the meta-tracklets. The experimental results of the proposed method are presented for a subset of UCF dataset and AGORASET crowd simulation videos and have shown promising results in dominant motion pattern recognition.},
  archive      = {J_EAAI},
  author       = {Franjo Matkovic and Marina Ivasic-Kos and Slobodan Ribaric},
  doi          = {10.1016/j.engappai.2022.105387},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105387},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new approach to dominant motion pattern recognition at the macroscopic crowd level},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A digital implantation system for z-direction yarn of
three-dimensional preform based on flexible oriented woven process.
<em>EAAI</em>, <em>116</em>, 105385. (<a
href="https://doi.org/10.1016/j.engappai.2022.105385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The implantation of Z-direction yarn is crucial in the process of forming flexible oriented 3D woven preforms, but manual implantation of Z-direction yarn is both time-consuming and inefficient. In this study, the digital Z-direction yarn implantation process and device are developed. Firstly, in view of many targets, small diameter, and serious interference in the identification process of the guide sleeve, a modified YOLOv3 algorithm is proposed to improve the accuracy and speed of detection, completing the coarse identification of guide sleeve. Then, an algorithm with modified Hough transform is proposed to improve the accuracy and speed of circle detection of coarse identification guide sleeve. Finally, based on the 1.2 mm diameter guide sleeve, a digital yarn replacement device was built to precisely replace the guide sleeve with replacement needles and implant the Z-direction yarn into the preform. The identification error of the guide sleeve is within 0.31% and the error between the reconstructed coordinates and the actual coordinates is within 3.08%. This study is crucial to the identification and positioning of small targets under complex working conditions and the development of digital forming of preform.},
  archive      = {J_EAAI},
  author       = {Zitong Guo and Hao Huang and Zhongde Shan and Jihua Huang and Zhuojian Hou and Wenfeng Li},
  doi          = {10.1016/j.engappai.2022.105385},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105385},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A digital implantation system for Z-direction yarn of three-dimensional preform based on flexible oriented woven process},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Secure distributed estimation under byzantine attack and
manipulation attack. <em>EAAI</em>, <em>116</em>, 105384. (<a
href="https://doi.org/10.1016/j.engappai.2022.105384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless sensor networks (WSN) with distributed cooperation has been widely used in various fields due to their strong adaptive learning ability. However, WSN is vulnerable to malicious attacks, and the damaging behaviors of these attacks would make sensor nodes work unsatisfactorily and then contaminate the entire network. Although some security algorithms have been proposed to detect these malicious attacks, such as manipulation attack and Byzantine attack, they are not robust enough. To ameliorate this situation, a secure distributed diffusion least-mean-square (LMS) algorithm is designed, which adopts the dual detection mechanisms over the designed two subsystems. One subsystem is based on the LMS with cooperative strategy (L-CS), which uses an angle detector to filter manipulation attack, while the other subsystem is based on the LMS with non-cooperative strategy (L-NCS), where the sensors utilize non-cooperation to improve the detection effect on Byzantine attack. Moreover, the L-CS subsystem could further provide the secure estimation for the proposed algorithm by isolating malicious nodes. The performances are analyzed from the mean and mean-square convergence. Finally, some simulations are implemented to prove the effectiveness of the proposed algorithm.},
  archive      = {J_EAAI},
  author       = {Fangyi Wan and Ting Ma and Yi Hua and Bin Liao and Xinlin Qing},
  doi          = {10.1016/j.engappai.2022.105384},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105384},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Secure distributed estimation under byzantine attack and manipulation attack},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). NPNT: Non-oscillating process negation transformation of
mass functions and a negation-based discounting method in information
fusion. <em>EAAI</em>, <em>116</em>, 105381. (<a
href="https://doi.org/10.1016/j.engappai.2022.105381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Yager proposes a Probability Negation Transformation (PNT) based on the maximum entropy distribution. After continuous PNTs, the Probability Mass Function (PMF) reaches the maximum entropy distribution, i.e., an uniform distribution. In this paper, we propose a new negation transformation method based on Belief Evolution Network (BEN) and Disjunctive Combination Rule (DCR), called Non-oscillating Process Negation Transformation (NPNT). As a cognitive negation transformation, NPNT expresses the negation from known to unknown. The Full Causality Probability Transformation (FCPT) is used to connect the PMF and Basic Belief Assignment (BBA) under NPNT. Based on the proposed method, we extend the Shafer’s discounting method from the perspective of DCR, which realizes less commitment under a same discount coefficient.},
  archive      = {J_EAAI},
  author       = {Qianli Zhou and Yong Deng},
  doi          = {10.1016/j.engappai.2022.105381},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105381},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {NPNT: Non-oscillating process negation transformation of mass functions and a negation-based discounting method in information fusion},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). A misbehavior detection system to detect novel position
falsification attacks in the internet of vehicles. <em>EAAI</em>,
<em>116</em>, 105380. (<a
href="https://doi.org/10.1016/j.engappai.2022.105380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Internet of Vehicle (IoV) networks, vehicles exchange periodic Basic Safety Messages (BSMs) containing information regarding speed and position. Safety-critical applications like blind-spot warning and lane change warning systems use the BSMs to ensure the safety of road users. To create chaos in the network, an insider attacker may inject false information into the BSM and broadcast it to nearby vehicles. One such attack is the position falsification attack, where the attacker inserts false information regarding the position in the BSMs. The literature has explored the use of Misbehavior Detection Systems (MDSs) to detect such attacks. But the limitaitons of the existing approaches are that they either perform exceptionally well in specific environmental settings or have compromised detection accuracy favoring a generalized model. Moreover, all the current machine learning-based detection models are signature-based, which requires prior knowledge about the attacks for effective detection. Motivated by the research gap, we propose a Novel Position Falsification Attack Detection System for the Internet of Vehicles (NPFADS for the IoV) to learn and detect novel position falsification attacks emerging in IoV networks. The performance of NPFADS is analyzed using the metrics precision, recall, F1 score, ROC, and PR curves. The Vehicular Reference Misbehavior (VeReMi) dataset is used as the benchmark for the study. The system’s performance is compared to existing MDSs in the literature. The analysis shows that our proposed system outperforms the existing supervised learning models even when initialized with zero knowledge about the novel position falsification attacks.},
  archive      = {J_EAAI},
  author       = {Harun Surej Ilango and Maode Ma and Rong Su},
  doi          = {10.1016/j.engappai.2022.105380},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105380},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A misbehavior detection system to detect novel position falsification attacks in the internet of vehicles},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Seam tracking system based on laser vision and CGAN for
robotic multi-layer and multi-pass MAG welding. <em>EAAI</em>,
<em>116</em>, 105377. (<a
href="https://doi.org/10.1016/j.engappai.2022.105377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A robotic seam tracking system based on laser vision and conditional generative adversarial networks (CGAN) was proposed to address the problem of low welding precision for the multi-layer and multi-pass MAG welding process. The seam tracking system consisted of three modules, i.e., laser-vision (LV), server-terminal (ST), and robot-terminal (RT), and the real-time seam tracking for multi-layer and multi-pass welding was realized though the seam feature points extraction, coordinate conversion, deviation calculation and welding torch position correction based on the KUKA robot sensor interface (RSI). Experimental results showed that the proposed restoration and extraction network (REN) based on the CGAN principle could not only restore the seam feature information but also extract the seam feature points accurately. The welding torch could run smoothly in the strong noise environment, and there were no obvious correction marks in the weld appearance. The average correction error was less than 0.6 mm, and the adjustment process of the welding torch position can be completed within 1 s, indicating that the accuracy and speed of the proposed seam tracking system were acceptable.},
  archive      = {J_EAAI},
  author       = {Chenfan Liu and Junqi Shen and Shengsun Hu and Dingyong Wu and Chao Zhang and Hui Yang},
  doi          = {10.1016/j.engappai.2022.105377},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105377},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Seam tracking system based on laser vision and CGAN for robotic multi-layer and multi-pass MAG welding},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning large-scale fuzzy cognitive maps under limited
resources. <em>EAAI</em>, <em>116</em>, 105376. (<a
href="https://doi.org/10.1016/j.engappai.2022.105376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on the problem of learning large-scale fuzzy cognitive maps (FCMs) with a limited computational budget is outstanding. To learn large-scale FCMs from time series, in most work, this problem is decomposed into learning local connections of each concept, respectively, and then one optimizer is employed to optimize each such sub-problem. Each sub-problem may have different requirements for the computational resource, but the existing methods ignore this issue and allocate the same amounts of computational resources for each sub-problem. In this paper, we propose two strategies to address this problem. We first develop a dynamic resource allocation strategy to maximize the performance of the decomposition-based optimizer under a limited computational budget. Second, we propose a half-thresholding memetic algorithm to improve the performance of the traditional evolutionary algorithm. We term our proposal as a half-thresholding memetic algorithm with a dynamic resource allocation strategy (HTMA-DRA). Finally, the experiments on large-scale synthetic data and DREAM datasets compared with the existing state-of-the-art methods demonstrate the effectiveness of the proposed HTMA-DRA.},
  archive      = {J_EAAI},
  author       = {Kai Wu and Jing Liu},
  doi          = {10.1016/j.engappai.2022.105376},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105376},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning large-scale fuzzy cognitive maps under limited resources},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Single nighttime image dehazing based on unified variational
decomposition model and multi-scale contrast enhancement. <em>EAAI</em>,
<em>116</em>, 105373. (<a
href="https://doi.org/10.1016/j.engappai.2022.105373">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of existing dehazing methods are unable to deal with nighttime hazy scenarios well due to complex degraded factors such as non-uniform illumination, low light, glows and hazes. To obtain high-quality image under nighttime haze imaging conditions, we propose a single nighttime image dehazing framework based on a unified variational decomposition model and multi-scale contrast enhancement to simultaneously address these undesirable issues. First, a unified variational decomposition model consisting of three regularization terms is proposed to simultaneously decompose a nighttime hazy image into a structure layer, a detail layer and a noise layer. Concretely, we employ ℓ 1 norm to constrain the structure component, adopt ℓ 0 sparsity term to enforce the piece-wise continuous of the residual of the gradients between the detail layer and the modified glow-free image, and use the Frobenius norm to estimate the noise layer. Next, the hazes in the structure layer are removed by inversing the physical model and the effective details in the texture layers are enhanced while the amplified noises are suppressed in a multi-scale fashion. Finally, the dehazed structure layer and the enhanced detail layers are integrated into a haze-free image. Experiments demonstrate that the proposed framework achieves superior performance on nighttime haze removal and noise suppression compared with state-of-the-art dehazing techniques.},
  archive      = {J_EAAI},
  author       = {Yun Liu and Zhongsheng Yan and Tian Ye and Aimin Wu and Yuche Li},
  doi          = {10.1016/j.engappai.2022.105373},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105373},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Single nighttime image dehazing based on unified variational decomposition model and multi-scale contrast enhancement},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mechanical equipment health management method based on
improved intuitionistic fuzzy entropy and case reasoning technology.
<em>EAAI</em>, <em>116</em>, 105372. (<a
href="https://doi.org/10.1016/j.engappai.2022.105372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Management becomes more challenging as machinery becomes more widely used. From the health management history case records of mechanical devices, we can find that there are many health problems of the same type occurring repeatedly, but when similar problems occur again, solutions are not found in a short period. Case-based reasoning technology aimed at solving the above problems are widely used in equipment health management, but there are problems such as inadequate data utilization and failure to achieve the required accuracy and reliability. To uncover important information from historical failure case data and help reduce equipment downtime due to failure, this paper proposes a machinery equipment health management method based on improved intuitionistic fuzzy entropy and case reasoning technology. Firstly, the axiomatic definition of traditional intuitionistic fuzzy entropy is optimized and a new intuitionistic fuzzy entropy formula in the framework of case-based reasoning decision matrix is proposed. Secondly, the weight value of each attribute is obtained by combining the formula of the entropy weight method. Finally, the feature attribute weight values are fused into the case-based reasoning, and the historical cases that are most similar to the target cases are obtained by combining the existing case base. The effectiveness of the method was verified by comparing and analyzing the example calculation results with the traditional method. The method improves the management of machinery equipment operation and maintenance data. Furthermore, it helps enterprises to carry out the management and analysis of machinery equipment health problems.},
  archive      = {J_EAAI},
  author       = {Yupeng Gao and Ruixin Bao and Zhen Pan and Guiyang Ma and Jia Li and Xiuquan Cai and Qiqiang Peng},
  doi          = {10.1016/j.engappai.2022.105372},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105372},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Mechanical equipment health management method based on improved intuitionistic fuzzy entropy and case reasoning technology},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spatial template-based geometric complexity reduction method
for photo-realistic modeling of large-scale indoor spaces.
<em>EAAI</em>, <em>116</em>, 105369. (<a
href="https://doi.org/10.1016/j.engappai.2022.105369">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent progresses in image-based rendering (IBR) have demonstrated the feasibility of photo-realistic modeling in room-scale indoor spaces. However, it is difficult to extend the method to large-scale indoor spaces, because the computational complexity increases exponentially as the geometric complexity increases. In this study, we propose a framework that automatically generates photo-realistic model of large-scale indoor spaces. We first define primary factors that increase geometrical complexity as geometrically excluded objects (GEOs). The proposed framework removes GEOs in images and point clouds to efficiently represent large-scale indoor spaces. To this end, we introduce a segmentation method to segment GEOs from every image coherently. In addition, we also introduce an image inpainting method to fill in the segmented images for photo-realistic indoor modeling. Experiments are conducted in three small-scale spaces and two large-scale indoor spaces. In the experiments, the proposed modules are validated thoroughly. In addition, the experimental results show that the proposed method enables to generate photo-realistic indoor models automatically and efficiently.},
  archive      = {J_EAAI},
  author       = {Janghun Hyeon and Joohyung Kim and Hyunga Choi and Bumchul Jang and Jaehyeon Kang and Nakju Doh},
  doi          = {10.1016/j.engappai.2022.105369},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105369},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Spatial template-based geometric complexity reduction method for photo-realistic modeling of large-scale indoor spaces},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning unsupervised disentangled skill latents to adapt
unseen task and morphological modifications. <em>EAAI</em>,
<em>116</em>, 105367. (<a
href="https://doi.org/10.1016/j.engappai.2022.105367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning adaptable policies in the absence of explicit reward signals is a challenging problem in reinforcement learning. We propose an algorithm that disentangles the morphology-aware variables from skill latent space for adapting quickly to unseen morphological changes. Through several task learning experiments using MuJoCo Ant environments, we demonstrate that the agent can perform zero-shot inference and adapt to mild modification in morphology within an expected performance range. Furthermore, in the case of severe unseen morphological damage to the agent’s body, with the help of add-on training steps, we can subjoin additional value incorporated into the disentangled latent space without catastrophically destroying the pre-trained network. We observe that the proposed separable-skill based method outperforms prior evolutionary meta-learning-based approaches, and the presented approach opens up research direction toward reinforcement learning for open-world novelty. Our source code is available at: https://github.com/boratw/sd4m .},
  archive      = {J_EAAI},
  author       = {Taewoo Kim and Pamul Yadav and Ho Suk and Shiho Kim},
  doi          = {10.1016/j.engappai.2022.105367},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105367},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning unsupervised disentangled skill latents to adapt unseen task and morphological modifications},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). IoT data analytics in dynamic environments: From an
automated machine learning perspective. <em>EAAI</em>, <em>116</em>,
105366. (<a
href="https://doi.org/10.1016/j.engappai.2022.105366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the wide spread of sensors and smart devices in recent years, the data generation speed of the Internet of Things (IoT) systems has increased dramatically. In IoT systems, massive volumes of data must be processed, transformed, and analyzed on a frequent basis to enable various IoT services and functionalities. Machine Learning (ML) approaches have shown their capacity for IoT data analytics. However, applying ML models to IoT data analytics tasks still faces many difficulties and challenges, specifically, effective model selection, design/tuning, and updating, which have brought massive demand for experienced data scientists. Additionally, the dynamic nature of IoT data may introduce concept drift issues, causing model performance degradation. To reduce human efforts, Automated Machine Learning (AutoML) has become a popular field that aims to automatically select, construct, tune, and update machine learning models to achieve the best performance on specified tasks. In this paper, we conduct a review of existing methods in the model selection, tuning, and updating procedures in the area of AutoML in order to identify and summarize the optimal solutions for every step of applying ML algorithms to IoT data analytics. To justify our findings and help industrial users and researchers better implement AutoML approaches, a case study of applying AutoML to IoT anomaly detection problems is conducted in this work. Lastly, we discuss and classify the challenges and research directions for this domain.},
  archive      = {J_EAAI},
  author       = {Li Yang and Abdallah Shami},
  doi          = {10.1016/j.engappai.2022.105366},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105366},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {IoT data analytics in dynamic environments: From an automated machine learning perspective},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interval type-3 fuzzy fractal approach in sound speaker
quality control evaluation. <em>EAAI</em>, <em>116</em>, 105363. (<a
href="https://doi.org/10.1016/j.engappai.2022.105363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article is presenting a proposal for the mathematical definition of interval type-3 fuzzy sets, as a basis for later constructing all the theory needed for building interval type-3 fuzzy systems for different areas of application. It is well known that the most used form of fuzzy logic is the one called type-1, which later evolved into interval and general type-2. Recently, we have seen that type-2 fuzzy has outperformed type-1 in many real problems when there is high level of uncertainty, dynamic situations or nonlinearity. For these reasons it is worthwhile to explore the new area of type-3 fuzzy logic, and in this paper, we are putting forward some mathematical definitions of type-3 fuzzy sets and systems, as a starting point for later proposing their applications. In addition, we illustrate the potential of interval type-3 in a decision-making application in quality control. The aim of this study is to show the advantages of type-3 in a quality control problem that can be viewed as a decision-making process under uncertainty that estimates product quality Speaker manufacturing requires strict quality control and a combination of type-3 with fractal theory is able to outperform previous works with type-2 and type-1 in quality control. Simulation results of the proposed approach are compared with the results provided by human experts in sound speaker quality control to validate the effectiveness of the type-3 fuzzy fractal method in handling the uncertainty of this problem.},
  archive      = {J_EAAI},
  author       = {Oscar Castillo and Juan R. Castro and Patricia Melin},
  doi          = {10.1016/j.engappai.2022.105363},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105363},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Interval type-3 fuzzy fractal approach in sound speaker quality control evaluation},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A complex jensen–shannon divergence in complex evidence
theory with its application in multi-source information fusion.
<em>EAAI</em>, <em>116</em>, 105362. (<a
href="https://doi.org/10.1016/j.engappai.2022.105362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-source information fusion has attracted considerable attention in the few past years and plays a great role in real applications. However, the uncertainty or conflict will make the fusion results unreasonable. Furthermore, the information may be collected in the form of complex number that cannot be processed by existing methods. In this article, to handle the above issues, the complex evidence theory (CET) is exploited. CET is the generalization of Dempster–Shafer evidence theory, where the mass function is modeled by complex number, called complex mass function (CMF). In order to deal with multi-source information fusion from the perspective of the complex plane, a new Complex Jensen–Shannon divergence (CJS divergence) is presented in this article. The proposed CJS divergence can effectively measure the conflict between two CMFs, and it satisfies the properties of boundedness, symmetry and nondegeneracy. In addition, for a better combination result, we have adjusted the complex Dempster’s rule of combination, which is called the reinforced complex evidence combination rule (RCECR). Then an algorithm for multi-source information fusion is proposed based on the CJS divergence and the RCECR. Some numerical examples and two applications in target identification and medical diagnosis illustrate the effectiveness of the new approach.},
  archive      = {J_EAAI},
  author       = {Wentao Fan and Fuyuan Xiao},
  doi          = {10.1016/j.engappai.2022.105362},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105362},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A complex Jensen–Shannon divergence in complex evidence theory with its application in multi-source information fusion},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Boosting the prediction of molten steel temperature in ladle
furnace with a dynamic outlier ensemble. <em>EAAI</em>, <em>116</em>,
105359. (<a
href="https://doi.org/10.1016/j.engappai.2022.105359">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Molten steel temperature prediction is a critical step in the development of level-two control systems for ladle furnace. Many machine learning algorithms have been employed to complete such a work. Whereas data-driven predictors often deteriorate due to the presence of outliers in practical applications. This paper proposes to boost the predictive performance via outlier detection. Specifically, a dynamic outlier ensemble is developed inspired by the superiority of dynamic classifier selection in classification. Clustering analysis is used to determine the region of competence, on which base detectors are selected with the dedicated measure. The reason for the usage of clustering analysis lies in its efficiency during online detection. One attribute weighting algorithm is used to enhance the capability of clustering in outlier detection. The information behind regression is used to facilitate the measure of competence, results of which can promote the performance of predictors. Such a strategy can achieve double-win from the perspective of regression and outlier detection. Extensive experiments on real-world data sets show that results of all 4 predictive models with respect to accuracy and hit rate can be improved. Moreover, the detection performance in terms of G-mean and F1 score of our detector has also been confirmed via the comparison with 8 competitors.},
  archive      = {J_EAAI},
  author       = {Biao Wang and Wenjing Wang and Guanglei Meng and Zhihua Qiao and Yuming Guo and Na Wang and Wei Wang and Zhizhong Mao},
  doi          = {10.1016/j.engappai.2022.105359},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105359},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Boosting the prediction of molten steel temperature in ladle furnace with a dynamic outlier ensemble},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Short-term residential load forecasting using graph
convolutional recurrent neural networks. <em>EAAI</em>, <em>116</em>,
105358. (<a
href="https://doi.org/10.1016/j.engappai.2022.105358">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The abundance of energy consumption data collected by smart meters has inspired researchers to employ deep neural networks to solve the existing problems in the power industry, such as Short-Term Load Forecasting (STLF). Most studies addressing the STLF problem, focus on historical load data and to achieve higher performance, they supplement costly accessible environmental and calendar variables with data. This approach ignores the existing spatial information among the consumers which subsequently might lead into the emergence of similar consumption patterns. In this paper, we present a Graph Convolutional Recurrent Neural Network, a novel neural architecture, for STLF problem that combines Graph Convolutional Networks and Long Short-Term Memory networks to simultaneously extract spatial and temporal information from users with similar consumption patterns. Our model captures spatial information from users without prior knowledge of their geographic location and does not rely on additional environmental variables. We compared our model to traditional baseline models for STLF using two real-world electricity consumption datasets. The empirical results demonstrate a significant improvement in prediction compared with the baseline models, exhibiting a 9.5% and an 8% improvement in terms of Mean Absolute Percentage Error, in the Customer Behavior Trials and Low Carbon London datasets, respectively.},
  archive      = {J_EAAI},
  author       = {Sana Arastehfar and Mohammadjavad Matinkia and Mohammad Reza Jabbarpour},
  doi          = {10.1016/j.engappai.2022.105358},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105358},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Short-term residential load forecasting using graph convolutional recurrent neural networks},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Effective algorithms to mine skyline frequent-utility
itemsets. <em>EAAI</em>, <em>116</em>, 105355. (<a
href="https://doi.org/10.1016/j.engappai.2022.105355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skyline frequent-utility itemset mining is used to discover itemsets that are non-dominated by considering both support and utility factors. It is an extension of high-utility itemset mining. Most existing algorithms are based on the utility-list structure to mine skyline frequent-utility itemsets. A major limitation of utility-list based algorithms is that numerous join operations consume a huge amount of time and memory. To address this issue, two algorithms named EMSFUI-D and EMSFUI-B are proposed to mine skyline frequent-utility itemsets. EMSFUI-D performs the depth-first search to explore the search space of all itemsets. EMSFUI-B discovers itemsets based on the breadth-first search. Both algorithms utilize two pruning strategies to limit the search space. Moreover, in order to further facilitate the mining performance, the ISU -1 and ISU -2 structures are presented in EMSFUI-D to provide tighter utility upper bounds. These structures maintain the support and utility information of all 1-itemsets and 2-itemsets, respectively. Thus, there is no need to use these structures to prune search space in the breadth-first search algorithm. An extensive experimental study on real and synthetic datasets shows that our proposed algorithms outperform the state-of-the-art SKYFUP-D and SKYFUP-B algorithms in terms of execution time, memory consumption and pruning performance. Moreover, our designed algorithms are scalable for handling a large number of distinct items and transactions.},
  archive      = {J_EAAI},
  author       = {Xuan Liu and Genlang Chen and Wanli Zuo},
  doi          = {10.1016/j.engappai.2022.105355},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105355},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Effective algorithms to mine skyline frequent-utility itemsets},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Broad learning system based on driving amount and
optimization solution. <em>EAAI</em>, <em>116</em>, 105353. (<a
href="https://doi.org/10.1016/j.engappai.2022.105353">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Broad learning system (BLS) was proposed by C. L. Philip Chen to overcome the time-consuming problem of traditional deep learning. However, the prediction precision of BLS is mainly dependent on its regularized parameter λ . Usually, λ is calculated by the trial and error method, which often suffers from the problem of too much calculation. To alleviate this issue, we propose an improved BLS with the driving amount and optimization solution (i.e., DA-BLS) in the study. The contributions of this study include: First, we use the iterative least square method to replace the ridge regression calculation of BLS, which avoids the selection of λ . Second, we provide the formulas of the driving amount and optimization solution under specific conditions. Third, the universal approximation property of DA-BLS is given. Last but not the least, extensive experimental results on the 1-D nonlinear function, UCI data-sets, and fault diagnosis of TEP show that DA-BLS outperforms the relevant methods such as BLS and the stochastic configuration network.},
  archive      = {J_EAAI},
  author       = {Weidong Zou and Yuanqing Xia and Weipeng Cao},
  doi          = {10.1016/j.engappai.2022.105353},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105353},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Broad learning system based on driving amount and optimization solution},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Risk prediction model for food safety based on improved
random forest integrating virtual sample. <em>EAAI</em>, <em>116</em>,
105352. (<a
href="https://doi.org/10.1016/j.engappai.2022.105352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Food safety has a severe impact on the world economy and global health, and improving the prediction accuracy and prevention ability of food safety risks and hazards protection is of great significance to the society sustainable development. However, the sample size of most food data is very small, resulting in insufficient training sample data for data-driven risk prediction models in low prediction accuracy and inability to provide effective prevention and control measures. Therefore, this paper proposes a food safety risk prediction model based on an improved random forest prediction method integrating Monte Carlo algorithm to protect and reduce the food safety risk. The Monte Carlo algorithm can expand the small sample data for obtaining the generated virtual sample. Then the extended input of a random forest method to construct the novel risk prediction model of food safety for predicting food risk levels and ensuring personnel safety. Finally, the accuracy and effectiveness of the proposed method is verified by the sterilized milk data. The experimental results show that the novel risk prediction model out-performs state-of-the art, which has stronger generalization ability and higher prediction accuracy for realizing effective risk early warning. Moreover, the proposed model can provide decision assistance and technical support for relevant departments to prevent and control in advance, and reduce the occurrence of food risk events.},
  archive      = {J_EAAI},
  author       = {Zhiqiang Geng and Xiaoyan Duan and Jiatong Li and Chong Chu and Yongming Han},
  doi          = {10.1016/j.engappai.2022.105352},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105352},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Risk prediction model for food safety based on improved random forest integrating virtual sample},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). EEG-based emotion recognition using random convolutional
neural networks. <em>EAAI</em>, <em>116</em>, 105349. (<a
href="https://doi.org/10.1016/j.engappai.2022.105349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition based on electroencephalogram (EEG) signals is helpful in various fields, including medical healthcare. One possible medical application is to diagnose emotional disorders in patients. Humans tend to work and communicate efficiently when in a good mood. On the other hand, negative emotions can harm physical and mental health. Traditional EEG-based methods usually extract time-domain and frequency-domain features before classifying them. Convolutional Neural Networks (CNN) enables us to extract features and classify them end-to-end. However, most CNN methods use backpropagation to train their models, which can be computationally expensive, primarily when a complex model is used. Inspired by the successes of Random Vector Functional Link and Convolutional Random Vector Functional Link, we propose using a randomized CNN model for emotion recognition that removes the need for a backpropagation method. Also, we expand our randomized CNN method to a deep and ensemble version to improve emotion recognition performance. We do experiments on the commonly used publicly available Database for Emotion Analysis using the Physiological Signals (DEAP) dataset to evaluate our randomized CNN models. Results on the DEAP dataset show our models outperform all other models, with at least 95% accuracy for all subjects. Our ensemble version outperforms our shallow version, winning the shallow version in most subjects.},
  archive      = {J_EAAI},
  author       = {Wen Xin Cheng and Ruobin Gao and P.N. Suganthan and Kum Fai Yuen},
  doi          = {10.1016/j.engappai.2022.105349},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105349},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {EEG-based emotion recognition using random convolutional neural networks},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive transfer learning-based multiscale feature fused
deep convolutional neural network for EEG MI multiclassification in
brain–computer interface. <em>EAAI</em>, <em>116</em>, 105347. (<a
href="https://doi.org/10.1016/j.engappai.2022.105347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objective. Deep learning (DL)-based brain–computer interface (BCI) in motor imagery (MI) has emerged as a powerful method for establishing direct communication between the brain and external electronic devices. However, due to inter-subject variability, inherent complex properties, and low signal-to-noise ratio (SNR) in electroencephalogram (EEG) signals are major challenges that significantly hinder the accuracy of the MI classifier. Approach. To overcome this, the present work proposes an efficient transfer learning (TL)-based multi-scale feature fused CNN (MSFFCNN) which can capture the distinguishable features of various non-overlapping canonical frequency bands of EEG signals from different convolutional scales for multi-class MI classification. Significance. In order to account for inter-subject variability from different subjects, the current work presents 4 different model variants including subject-independent and subject-adaptive classification models considering different adaptation configurations to exploit the full learning capacity of the classifier. Each adaptation configuration has been fine-tuned in an extensively trained pre-trained model and the performance of the classifier has been studied for a vast range of learning rates and degrees of adaptation which illustrates the advantages of using an adaptive transfer learning-based model. Results. The model achieves an average classification accuracy of 94.06% ( ± 0 . 70 % ) and the kappa value of 0.88 outperforming several baseline and current state-of-the-art EEG-based MI classification models with fewer training samples. The present research provides an effective and efficient transfer learning-based end-to-end MI classification framework for designing a high-performance robust MI-BCI system.},
  archive      = {J_EAAI},
  author       = {Arunabha M. Roy},
  doi          = {10.1016/j.engappai.2022.105347},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105347},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive transfer learning-based multiscale feature fused deep convolutional neural network for EEG MI multiclassification in brain–computer interface},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Resource scheduling methods for cloud computing environment:
The role of meta-heuristics and artificial intelligence. <em>EAAI</em>,
<em>116</em>, 105345. (<a
href="https://doi.org/10.1016/j.engappai.2022.105345">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growth and development of scientific applications have demanded the creation of efficient resource management systems. Resource provisioning and scheduling are two core components of cloud resource management systems. Cloud resource scheduling is the most critical problem to solve efficiently due to the heterogeneity of resources, their inter-dependencies, and unpredictability of load in the cloud environment. In this paper, we review the background of scheduling and state-of-the-art scheduling techniques in cloud computing. We first introduce the general background, and phases of scheduling. A comprehensive survey of existing resource scheduling problems proposed so far is presented considering high-level taxonomy. This high-level taxonomy considers Virtual Machine (VM) placement, Quality of Service (QoS) parameters, heuristic methods, and other miscellaneous techniques for resource scheduling. This study also discusses scheduling in Infrastructure as a Service (IaaS) clouds and comparison based on important parameters is also investigated. The importance of meta-heuristic methods and artificial intelligence for resource scheduling methods in cloud computing is discussed thoroughly. The objective of this work is to help the researchers to understand the basic concepts related to scheduling and facilitate the process of designing new scheduling methods by addressing issues raised in the scheduling and studying the existing methodologies.},
  archive      = {J_EAAI},
  author       = {Rajni Aron and Ajith Abraham},
  doi          = {10.1016/j.engappai.2022.105345},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105345},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Resource scheduling methods for cloud computing environment: The role of meta-heuristics and artificial intelligence},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Q-learning of the storage function in economic nonlinear
model predictive control. <em>EAAI</em>, <em>116</em>, 105343. (<a
href="https://doi.org/10.1016/j.engappai.2022.105343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The closed-loop stability of an optimal policy provided by an Economic Nonlinear Model Predictive Control (ENMPC) scheme requires the existence of a storage function satisfying dissipativity conditions. Unfortunately, finding such a storage function is difficult in general. In contrast, tracking NMPC scheme uses a stage cost that is lower-bounded by a class- K ∞ function and the closed-loop stability is fairly straightforward to establish. Under the dissipativity conditions, ENMPC has an equivalent tracking MPC that delivers the same optimal policy. In this paper, we use this idea and parameterize the stage cost and terminal cost of a tracking MPC with an additional parameterized storage function. We show that, if the parameterization of the tracking MPC scheme is rich enough to capture the exact optimal action-value function of the ENMPC scheme, then the parameterized storage function for the optimal parameters satisfies the dissipativity conditions for both discounted and undiscounted ENMPC schemes. In fact, we show that these conditions are met for dissipative problems. We propose to use Q-learning as a practical way of adjusting the parameters of the tracking MPC. Different numerical examples are provided to illustrate the efficiency of the proposed method, including LQR, non-dissipative, non-polynomial and a nonlinear chemical case studies. For instance, in the provided non-polynomial case study, the learning method can improve the storage function estimation by about 60% and 99.5% after 10 and 50 learning steps, respectively, compared with the Sum-of-Square method.},
  archive      = {J_EAAI},
  author       = {Arash Bahari Kordabad and Sebastien Gros},
  doi          = {10.1016/j.engappai.2022.105343},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105343},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Q-learning of the storage function in economic nonlinear model predictive control},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Research on multi-functional logistics intelligent unmanned
aerial vehicle. <em>EAAI</em>, <em>116</em>, 105341. (<a
href="https://doi.org/10.1016/j.engappai.2022.105341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As Unmanned Aerial Vehicle (UAV) is more and more frequently used in farming and logistics, civil and military alike, researches involving UAVs also starts to boom. In the civil field, UAV is generally flown in urban areas, so buildings are the main factors hindering the normal flight of UAV. Therefore, it is necessary to calculate an optimal flight path of UAV under constraints. The intelligent logistics UAV proposed in this paper can be used to replace special couriers to deliver small goods. It is a quadcopter integrated with a webcam, ultrasound Ground Proximity Warning System (GPWS), and is controllable through a mobile APP. Gradient descent algorithm, Linear Quadratic Regulator (LQR) and improved Proportion–Integral– Derivative (PID) controllers are applied in its flight control system, MATLAB and wavelet transform to handle fuzzy image. In addition, ant colony algorithm and adaptive strategies are used in the path planning process. As a result, it can detect surrounding obstacles in-flight, and the ground control station can receive feedback information and prepare for emergency operations.},
  archive      = {J_EAAI},
  author       = {Hai-Wu Lee},
  doi          = {10.1016/j.engappai.2022.105341},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105341},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Research on multi-functional logistics intelligent unmanned aerial vehicle},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Block-based multi-view classification via view-based l2,p
sparse representation and adaptive view fusion. <em>EAAI</em>,
<em>116</em>, 105337. (<a
href="https://doi.org/10.1016/j.engappai.2022.105337">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To date, many efficient classification methods have been presented by utilizing the multi-view data’s rich information. Nevertheless, they commonly construct models by concatenating entire views together into the high-dimensional vectors while ignoring the individuality and relationship of views. Also, they often use fixed labels to perform classification, ignoring the requirement of the large margin between distinct classes. To address the above problems, we propose a new block-based multi-view classification model via view-based L 2 , p sparse representation and adaptive view fusion. Specifically, the model establishes the L 2 , p regularization in each view space to excavate the individuality information of views. Meanwhile, a newly proposed shared loss term across views is combined in the model to learn the complementarity and consistency information of views. The adaptive weighting is introduced to measure the contribution of distinct views while performing adaptive view fusion. The model also adopts slack labels to increase the distance of distinct classes. Furthermore, an Alternating Direction Method of Multipliers (ADMM) based algorithm is designed to solve the model through block calculation rapidly. And a strict theoretical proof of its convergence is provided. Extensive experiments demonstrate that the proposed method achieves superior performance.},
  archive      = {J_EAAI},
  author       = {Zhi Wang and Qiang Lin and Yingyi Chen and Ping Zhong},
  doi          = {10.1016/j.engappai.2022.105337},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105337},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Block-based multi-view classification via view-based l2,p sparse representation and adaptive view fusion},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient kernel fuzzy clustering via random fourier
superpixel and graph prior for color image segmentation. <em>EAAI</em>,
<em>116</em>, 105335. (<a
href="https://doi.org/10.1016/j.engappai.2022.105335">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The kernel fuzzy clustering algorithms can explore the non-linear relations of pixels in an image. However, most of kernel-based methods are computationally expensive for color image segmentation and neglect the inherent locality information in images. To alleviate these limitations, this paper proposes a novel kernel fuzzy clustering framework for fast color image segmentation. More specifically, we first design a new superpixel generation method that uses random Fourier maps to approximate Gaussian kernels and explicitly represent high-dimensional features of pixels. Clustering superpixels instead of large-sized pixels speeds up the segmentation of a color image significantly. More importantly, the features of superpixels used by fuzzy clustering are also calculated in the approximated kernel space and the local relationships between superpixels are depicted as a graph prior and appended into the objective function of fuzzy clustering as a Kullback–Leibler divergence term. This results in a new fuzzy clustering model that can further improve the accuracy of the image segmentation. Experiments on synthetic and real-world color image datasets verify the superiority and high efficiency of the proposed approach.},
  archive      = {J_EAAI},
  author       = {Long Chen and Yin-Ping Zhao and Chuanbin Zhang},
  doi          = {10.1016/j.engappai.2022.105335},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105335},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Efficient kernel fuzzy clustering via random fourier superpixel and graph prior for color image segmentation},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semi-supervised time series classification model with
self-supervised learning. <em>EAAI</em>, <em>116</em>, 105331. (<a
href="https://doi.org/10.1016/j.engappai.2022.105331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning is a powerful machine learning method. It can be used for model training when only part of the data are labeled. Unlike discrete data, time series data generally have some temporal relation, which can be considered as a supervised signal in semi-supervised learning to supervise the learning of unlabeled time series data. However, the currently known semi-supervised time series classification (TSC) methods always ignore or under-explore the temporal relation structure and fail to fully use the unlabeled time series data. Therefore, we propose a Semi-supervised Time Series Classification Model with Self-supervised Learning (SSTSC). It takes self-supervised learning as the auxiliary task and jointly optimizes it with the main TSC task. Specifically, it performs the TSC task on the labeled time series data; For the unlabeled time series data, it splits the “past-anchor-future” segments and constructs the positive/negative temporal relation samples with different combinations to accurately predict the temporal relations and capture the higher-quality semantic context in self-supervised learning as a supervised signal for TSC task. Experimental results demonstrate that SSTSC has better effects than the baselines from different perspectives.},
  archive      = {J_EAAI},
  author       = {Liang Xi and Zichao Yun and Han Liu and Ruidong Wang and Xunhua Huang and Haoyi Fan},
  doi          = {10.1016/j.engappai.2022.105331},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105331},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Semi-supervised time series classification model with self-supervised learning},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Correcting biased value estimation in mixing value-based
multi-agent reinforcement learning by multiple choice learning.
<em>EAAI</em>, <em>116</em>, 105329. (<a
href="https://doi.org/10.1016/j.engappai.2022.105329">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-agent reinforcement learning (MARL) has become more and more popular over the past decades, and many value-based MARL methods are proposed in the past few years. Neural networks play important roles in these methods and are used to predict the value of the state–action pair, i.e. Q-value and actions of agents are chosen based on this. However the inaccurate prediction of the neural network leads to the biased Q-value estimation, which will cause inefficient usage of the experience data and poor performance. Unlike ensemble methods that just reduce the variance of predictions, multiple choice learning (MCL) methods exploit the cooperation among all the candidate models. This paper corrects the biased Q-value by exploiting the collaboration between the ensemble model and MARL to obtain a stabler and preciser Q-value estimator. In this paper, a new MARL method called Multiple Choice QMIX is developed to address the biased Q-value issue, which also extends the application scenarios of MCL methods. Specifically, we propose a voting network to learn the confidence level of each estimator and thus can provide the best prediction by combining their results. And a voting hindsight loss is proposed to encourage the voting network to overcome the overestimation of the Q-value. We also conduct experiments on four challenging tasks of the StarCraft II micromanagement benchmark. Experiment results show that our method obtains a faster convergence rate and stabler performance in multi-agent tasks.},
  archive      = {J_EAAI},
  author       = {Bing Liu and Yuxuan Xie and Lei Feng and Ping Fu},
  doi          = {10.1016/j.engappai.2022.105329},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105329},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Correcting biased value estimation in mixing value-based multi-agent reinforcement learning by multiple choice learning},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neural-network-based model predictive control for consensus
of nonlinear systems. <em>EAAI</em>, <em>116</em>, 105327. (<a
href="https://doi.org/10.1016/j.engappai.2022.105327">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the consensus problem for discrete-time nonlinear multi-agent systems subjected to switching communication topologies with a model predictive control (MPC) approach. For systems following a Markovian switching law, it is difficult for the existing MPC solutions to obtain reliable optimization based on the model predictions. We propose a new neural-network-based algorithm that reduces the effects of communication deficiencies by approximating and minimizing the MPC’s cost function in real-time. The convenience of the proposed method is certified in simulations for different applications and scenarios.},
  archive      = {J_EAAI},
  author       = {Bruno R.O. Floriano and Alessandro N. Vargas and João Y. Ishihara and Henrique C. Ferreira},
  doi          = {10.1016/j.engappai.2022.105327},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105327},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Neural-network-based model predictive control for consensus of nonlinear systems},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Three-dimensional dynamic uncertainty semantic SLAM method
for a production workshop. <em>EAAI</em>, <em>116</em>, 105325. (<a
href="https://doi.org/10.1016/j.engappai.2022.105325">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneous localization and mapping (SLAM) is the basis for intelligent navigation and intelligent security of mobile robots in a workshop. However, there are numerous dynamic objects in a workshop, such as robots and operators, which can decrease the accuracy of robot localization and mapping. To solve this problem, this paper proposes a three-dimensional dynamic semantic system named the PW_SLAM. First, the production workshop-oriented lightweight semantic segmentation network (PWnet) is integrated with the SLAM system by a robot operating system(ROS) to provide semantic information. Next, a dynamic uncertainty keypoint classifier(DUKC) is proposed to filter the dynamic keypoints and improve the localization accuracy. Then, the map is stored in the form of an octree, and a dynamic object map filter are designed to filter the dynamic objects in the octree map. The proposed system is evaluated on the TUM RGB-D public datasets and the results show that the RMSE of absolute trajectory error in PW_SLAM is decreased by 92.80%, 98.85%, 87.21% compared to that of ORB_SLAM3 on the TUM highly dynamic datasets “fr3/walking_xyz”, “fr3/walking_static”, and “fr3/walking_rpy”, respectively. In addition, the PW_SLAM is also applied to the real workshop environment, and the results show that it can effectively eliminate dynamic objects and build a static octree map of a workshop environment effectively.},
  archive      = {J_EAAI},
  author       = {Rongsong Gou and Guangzhu Chen and Chengliang Yan and Xin Pu and Yuanyuan Wu and Yuan Tang},
  doi          = {10.1016/j.engappai.2022.105325},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105325},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Three-dimensional dynamic uncertainty semantic SLAM method for a production workshop},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Visually-guided motion planning for autonomous driving from
interactive demonstrations. <em>EAAI</em>, <em>116</em>, 105277. (<a
href="https://doi.org/10.1016/j.engappai.2022.105277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The successful integration of autonomous robots in real-world environments strongly depends on their ability to reason from context and take socially acceptable actions. Current autonomous navigation systems mainly rely on geometric information and hard-coded rules to induce safe and socially compliant behaviors. Yet, in unstructured urban scenarios these approaches can become costly and suboptimal. In this paper, we introduce a motion planning framework consisting of two components: a data-driven policy that uses visual inputs and human feedback to generate socially compliant driving behaviors (encoded by high-level decision variables), and a local trajectory optimization method that executes these behaviors (ensuring safety). In particular, we employ Interactive Imitation Learning to jointly train the policy with the local planner, a Model Predictive Controller (MPC), which results in safe and human-like driving behaviors. Our approach is validated in realistic simulated urban scenarios. Qualitative results show the similarity of the learned behaviors with human driving. Furthermore, navigation performance is substantially improved in terms of safety, i.e., number of collisions, as compared to prior trajectory optimization frameworks, and in terms of data-efficiency as compared to prior learning-based frameworks, broadening the operational domain of MPC to more realistic autonomous driving scenarios.},
  archive      = {J_EAAI},
  author       = {Rodrigo Pérez-Dattari and Bruno Brito and Oscar de Groot and Jens Kober and Javier Alonso-Mora},
  doi          = {10.1016/j.engappai.2022.105277},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105277},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Visually-guided motion planning for autonomous driving from interactive demonstrations},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Time-staged photoelastic image prediction using multi-stage
convolutional autoencoders. <em>EAAI</em>, <em>116</em>, 105265. (<a
href="https://doi.org/10.1016/j.engappai.2022.105265">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photoelasticity has been widely utilized for the analysis of changes in the properties of micro-sized objects under variational forces. In machine-learning-based predictive maintenance, failure prediction is realized using sensor data and system signals. However, predictive maintenance using photoelasticity and machine learning is yet to be reported because of the difficulty in obtaining time-staged photoelastic images. The prediction of a future photoelastic image using past photoelastic images may facilitate near-future failure identification so that timely preventive measures can be implemented for mechanical or structural components. Such prediction is a spatiotemporal problem, which requires considerable recurrent data for temporal relations and image-based handling of spatial information. In this study, we first generated datasets of synthetic time-staged photoelastic images. Next, several combinations of deep learning models, including an autoencoder, a recurrent neural network, and a convolutional neural network, were examined. Finally, this study proposes a novel multi-stage convolutional autoencoder model for failure prediction. The effectiveness of the proposed model in terms of loss and accuracy was verified through numerical tests. The results revealed that the proposed model is an effective prediction framework for image-based future prediction of micro/nanosized materials. Furthermore, the proposed model can be extended to other applications that require image-based spatiotemporal data.},
  archive      = {J_EAAI},
  author       = {Hyunsoo Lee and Heungjo An and Dong-Wook Lee},
  doi          = {10.1016/j.engappai.2022.105265},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {105265},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Time-staged photoelastic image prediction using multi-stage convolutional autoencoders},
  volume       = {116},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A double fuzzy multi-criteria analysis to evaluate
international high-performance aircrafts for defense purposes.
<em>EAAI</em>, <em>115</em>, 105339. (<a
href="https://doi.org/10.1016/j.engappai.2022.105339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper contributes the first-known study involving international military high-performance aircrafts together with their weaponry systems for defense purposes. This technical study had the invaluable help from an advisory group of instructor pilots whose expertise in combat aircrafts allowed the calculation of the relative importance of qualitative criteria playing a key role in each analysis. The combination of a modified version of Analytic Hierarchy Process (AHP; to determine the weights of the criteria) and Technique for Order of Preference by Similarity to ideal Solution (TOPSIS; to assess each set of alternatives) approaches with fuzzy logic becomes especially appealing for this case of study. The best scores were obtained by the F-16 jet and the SCALP EG missile. First, the F-16 (with a defuzzified TOPSIS coefficient of 0.95) was closely followed by both jets Su-35 (2nd position, with a coefficient equal to 0.93) and Su-30 (third position, 0.89). However, the difference between the SCALP EG (1.02) and its chasing alternative, the Kh-59M (0.65), was significantly greater. Such results were reinforced by sensitivity analyses through a combination of fuzzy AHP-VIKOR.},
  archive      = {J_EAAI},
  author       = {J.M. Sánchez-Lozano and J.C. Correa-Rubio and M. Fernández-Martínez},
  doi          = {10.1016/j.engappai.2022.105339},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105339},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A double fuzzy multi-criteria analysis to evaluate international high-performance aircrafts for defense purposes},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). InterpolationSLAM: An effective visual SLAM system based on
interpolation network. <em>EAAI</em>, <em>115</em>, 105333. (<a
href="https://doi.org/10.1016/j.engappai.2022.105333">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual SLAM can be mainly divided into direct method and feature-based method, and these two methods develop relatively independently. In recent years, feature-based SLAM systems have been significantly improved by introducing more robust features, effective matching and optimization frameworks, or other sensors. The introduction of semantic information also promotes the development of direct methods. However, visual SLAM usually assumes that the system satisfies the constant velocity assumption. This assumption may lead to a poor initial pose so that the subsequent optimization falls into a local minimal. Meanwhile, large field of view changes often lead to an increase in the error of feature matching for feature-based method and large illumination changes often lead to an increase of photometric error for direct method, thus negatively influencing SLAM systems. In this paper, we mainly target at feature-based method. In detail, we focus on the number and quality of feature matches, as well as the accuracy of the initial pose, thus an interpolation mechanism for SLAM is proposed. Specifically, we introduce the interpolation network originally used to increase the number of video frames into visual SLAM. First, we point out that the traditional interpolation network evaluation metrics are not suitable for the SLAM systems, and we provide the corresponding evaluation metric. Secondly, we verify that it works both for hand-crafted and deep learning features. Thirdly, in order to verify the effectiveness and transferability of our method, we also apply our method to SLAM systems based on direct method, which proves that our method is also applicable to the direct method. Fourthly, we point out that the interpolation network effectively slows down the pose transformation of the SLAM system by inserting an intermediate frame between the previous frame and the current frame, so that the system can obtain a better initial pose based on the constant velocity assumption. This can also explain why visual-inertial systems can effectively improve the performance of visual SLAM. Finally, to ensure the efficiency of the SLAM system, we provide a turning detection module and propose a method to interpolate only at turnings. Extensive experiments and analyses verify the effectiveness and transferability of the proposed system.},
  archive      = {J_EAAI},
  author       = {Zhenkun Zhu and Jikai Wang and Meng Xu and Shiqi Lin and Zonghai Chen},
  doi          = {10.1016/j.engappai.2022.105333},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105333},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {InterpolationSLAM: An effective visual SLAM system based on interpolation network},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). BLCov: A novel collaborative–competitive broad learning
system for COVID-19 detection from radiology images. <em>EAAI</em>,
<em>115</em>, 105323. (<a
href="https://doi.org/10.1016/j.engappai.2022.105323">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the global outbreak of COVID-19, there is an urgent need to develop an effective and automated detection approach as a faster diagnostic alternative to avoid the spread of COVID-19. Recently, broad learning system (BLS) has been viewed as an alternative method of deep learning which has been applied to many areas. Nevertheless, the sparse autoencoder in classical BLS just considers the representations to reconstruct the input data but ignores the relationship among the extracted features. In this paper, inspired by the effectiveness of the collaborative–competitive representation (CCR) mechanism, a novel collaborative–competitive representation-based autoencoder (CCRAE) is first proposed, and then collaborative–competitive broad learning system (CCBLS) is proposed based on CCRAE to effectively address the issues mentioned above. Moreover, an automated CCBLS-based approach is proposed for COVID-19 detection from radiology images such as CT scans and chest X-ray images. In the proposed approach, a feature extraction module is utilized to extract features from CT scans or chest X-ray images, then we use these features for COVID-19 detection with CCBLS. The experimental results demonstrated that our proposed approach can achieve superior or comparable performance in comparison with ten other state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Guangheng Wu and Junwei Duan},
  doi          = {10.1016/j.engappai.2022.105323},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105323},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {BLCov: A novel collaborative–competitive broad learning system for COVID-19 detection from radiology images},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Autonomous unmanned aerial vehicle navigation using
reinforcement learning: A systematic review. <em>EAAI</em>,
<em>115</em>, 105321. (<a
href="https://doi.org/10.1016/j.engappai.2022.105321">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is an increasing demand for using Unmanned Aerial Vehicle (UAV), known as drones, in different applications such as packages delivery, traffic monitoring, search and rescue operations, and military combat engagements. In all of these applications, the UAV is used to navigate the environment autonomously — without human interaction, perform specific tasks and avoid obstacles. Autonomous UAV navigation is commonly accomplished using Reinforcement Learning (RL), where agents act as experts in a domain to navigate the environment while avoiding obstacles. Understanding the navigation environment and algorithmic limitations plays an essential role in choosing the appropriate RL algorithm to solve the navigation problem effectively. Consequently, this study first identifies the main UAV navigation tasks and discusses navigation frameworks and simulation software. Next, RL algorithms are classified and discussed based on the environment, algorithm characteristics, abilities, and applications in different UAV navigation problems, which will help the practitioners and researchers select the appropriate RL algorithms for their UAV navigation use cases. Moreover, identified gaps and opportunities will drive UAV navigation research.},
  archive      = {J_EAAI},
  author       = {Fadi AlMahamid and Katarina Grolinger},
  doi          = {10.1016/j.engappai.2022.105321},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105321},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Autonomous unmanned aerial vehicle navigation using reinforcement learning: A systematic review},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). A novel self-adaptive fractional multivariable grey model
and its application in forecasting energy production and conversion of
china. <em>EAAI</em>, <em>115</em>, 105319. (<a
href="https://doi.org/10.1016/j.engappai.2022.105319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy production and conversion have a significant impact on the economic development of all countries in the world. China’s energy production and conversion are large. Therefore, accurate mid-to-long term China’s energy production and conversion forecasting is becoming more and more important for integrating energy systems and energy strategic planning. For this purpose, a novel fractional grey sequence is proposed based on Grunwald–Letnikov fractional calculus. Furthermore, a novel self-adaptive fractional multivariable grey model is proposed based on the novel sequence. In this article, we compare several classical optimization algorithms and finally choose Particle Swarm Optimization (PSO) to compute the parameters. In addition, Monte-Carlo simulation and probability density analysis (PDA) are presented in this article to verify the model’s performance. Monte-Carlo simulation reduces the randomness of the results of the model runs to a certain extent. Probability density analysis visualizes this randomness through kernel density estimation (KDE). This paper compares the new model with the existing seven grey models and predicts the total energy consumption per capita, energy conversion efficiency and total renewable energy in China, respectively. The experimental results show that the new model is superior to the other seven models in terms of stability and prediction accuracy.},
  archive      = {J_EAAI},
  author       = {Yong Wang and Li Wang and Lingling Ye and Xin Ma and Wenqing Wu and Zhongsen Yang and Xinbo He and Lei Zhang and Yuyang Zhang and Ying Zhou and Yongxian Luo},
  doi          = {10.1016/j.engappai.2022.105319},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105319},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel self-adaptive fractional multivariable grey model and its application in forecasting energy production and conversion of china},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A fuzzy logic-based approach for fault diagnosis and
condition monitoring of industry 4.0 manufacturing processes.
<em>EAAI</em>, <em>115</em>, 105317. (<a
href="https://doi.org/10.1016/j.engappai.2022.105317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the introduction of the industry 4.0 paradigm, manufacturing companies are investing in the development of algorithmic diagnostic solutions for their industrial equipment, relying on measured data and process models. However, process and fault models are not usually available for complex productions plants and production data are usually unlabeled. Thus, to classify machine status, unsupervised approaches such as anomaly detection and signal processing strategies have to be employed. Due to the unsupervised nature of the problem, it is meaningful to apply several diagnostic algorithms to cover most of the process anomalous behaviors. Additionally, in some contexts, the experience of process operators in grasping the correct functioning of machines as well as their ability in understanding early signs of deterioration is relevant for the diagnosis of incoming failures. However, seldom these information can be included in failure diagnosis algorithms. In this paper, we propose a diagnostic scheme for condition monitoring of mechanical components. The proposed scheme combines anomaly detection algorithms, envelope analysis of vibration data, and eventually additional qualitative information on machine functioning. The combination of all the fault indicators is obtained leveraging on a fuzzy inference system. The proposed scheme is experimentally validated on a steel making plant with real process data, making use of heuristic information such monitoring reports of machine health status.},
  archive      = {J_EAAI},
  author       = {Mirko Mazzoleni and Kisan Sarda and Antonio Acernese and Luigi Russo and Leonardo Manfredi and Luigi Glielmo and Carmen Del Vecchio},
  doi          = {10.1016/j.engappai.2022.105317},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105317},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A fuzzy logic-based approach for fault diagnosis and condition monitoring of industry 4.0 manufacturing processes},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A soft-sensor for sustainable operation of coagulation and
flocculation units. <em>EAAI</em>, <em>115</em>, 105315. (<a
href="https://doi.org/10.1016/j.engappai.2022.105315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, Machine Learning (ML) techniques have become one of the most widely used engineering tools due to their numerous advantages, including their continuous improvement. This study proposes a smart soft sensor using various ML algorithms to control and predict the Coagulation and Flocculation Process (CFP). Optimizing and predicting the behaviour of a CFP is difficult due to its non-linear and complex behaviour. Therefore, ML computations is a proper method to overcome this challenge. However, one of the challenges of ML studies is the lack of sufficient data which we overcome by using an 8-year database of experiments. For prediction, this study compares different ML methods, including Random Tree, Random Forest (RF), Artificial Neural Networks (ANN), Quinlan’s M5 algorithm with regression function (M5P), Linear Regression (LR), Simple LR, Gaussian method, Decision Stump method, Smola and Scholkopf’s Sequential Minimal Optimization algorithm with LR (SMOreg), and the Adaptive Neuro-Fuzzy Inference System (ANFIS). Also, for optimization of the studied system, Central Composite Design designed the experimental data with the Response Surface Methodology (CCD-RSM). The most significant factors in turbidity removal are related to FeCl3 dosage, and slow mixing speed with &lt; 0.0001 and 0.005 P-values. The present research findings show that the maximum removal efficiency of 92% is predicted using CCD-RSM under the optimal condition. In addition, ANFIS and RF models with R 2 of 0.96 and 0.92, have shown the highest accuracy levels for removing water turbidity. Finally, a Petri-Net model establishes a Conceptual model to intelligently conduct managerial insights for water treatments.},
  archive      = {J_EAAI},
  author       = {Maliheh Arab and Hadi Akbarian and Mohammad Gheibi and Mehran Akrami and Amir M. Fathollahi-Fard and Mostafa Hajiaghaei-Keshteli and Guangdong Tian},
  doi          = {10.1016/j.engappai.2022.105315},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105315},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A soft-sensor for sustainable operation of coagulation and flocculation units},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TSN-based routing and scheduling scheme for industrial
internet of things in underground mining. <em>EAAI</em>, <em>115</em>,
105314. (<a
href="https://doi.org/10.1016/j.engappai.2022.105314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, there has been a growing interest in Time-Sensitive Networking (TSN) research in the Industrial Internet of Things(IIoT). The research on real-time and reliable IIoT transmission technology based on TSN has received extensive attention. Especially in some industrial scenarios, such as the safety monitoring of the underground construction environment, the real-time and reliability of data transmission is very important due to the long tunnel and complex structure in underground mining. It is a huge challenge to ensure that the data collected by the sensor has a slight end-to-end delay to the receiving end. A routing scheduling method is proposed based on TSN for IIoT applications in underground mining. Firstly, according to the characteristics of large-scale and distributed hybrid topology in mines and the delay constraints of TSN, the multi-hop routing cooperative scheduling problem S is defined. It is proved that the problem is NP-Hard. Secondly, two algorithms are proposed for problem S : (1) greedy algorithm based on local shortest delay; (2) heuristic algorithm based on an ant colony. Finally, a comparative experimental analysis of the proposed algorithm is carried out, proving that this paper’s algorithm performs better in terms of delay and jitter.},
  archive      = {J_EAAI},
  author       = {Yinghui Zhang and Jiamin Wu and Mingli Liu and Aiping Tan},
  doi          = {10.1016/j.engappai.2022.105314},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105314},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {TSN-based routing and scheduling scheme for industrial internet of things in underground mining},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A review on the studies employing artificial bee colony
algorithm to solve combinatorial optimization problems. <em>EAAI</em>,
<em>115</em>, 105311. (<a
href="https://doi.org/10.1016/j.engappai.2022.105311">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ABC algorithm is one of the popular optimization algorithms and has been used successfully in solving many real-world problems. Numeric, binary, integer, mixed integer and combinatorial optimization problems are among the areas where ABC algorithm is used. Combinatorial optimization problems appear in many problem groups in real life. Due to the nature of these problems, they are classified as difficult problems. It is seen in the literature that hundreds of studies have been conducted using the ABC algorithm in solving combinatorial optimization problems. In this study, combinatorial optimization approaches based on ABC algorithm are examined in detail, in order to shed light on new studies. Combinatorial optimization problems are analyzed under 12 groups. These are assembly/disassembly, bioinformatic, graph coloring, routing, rule mining, aware web service composition, socially network analysis, team orienteering, timetabling, traveling salesman, vehicle routing and other problems. 251 studies of related problems are examined. Brief summaries of the studies on combinatorial optimization problems are presented and the ABC algorithm-based approaches used are introduced. Tables, images and equations are included for better understanding of the subject. The added mechanisms to improve the local search capability of the ABC algorithm are evaluated. Neighborhood operators used in ABC algorithms are examined. The used selection schemes and initial populations determination approaches are given. It is stated which mechanisms are included in hybrid approaches based on ABC algorithm. The test instances used to evaluate the performances of the ABC algorithms are mentioned.},
  archive      = {J_EAAI},
  author       = {Ebubekir Kaya and Beyza Gorkemli and Bahriye Akay and Dervis Karaboga},
  doi          = {10.1016/j.engappai.2022.105311},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105311},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A review on the studies employing artificial bee colony algorithm to solve combinatorial optimization problems},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detecting and recognizing driver distraction through various
data modality using machine learning: A review, recent advances,
simplified framework and open challenges (2014–2021). <em>EAAI</em>,
<em>115</em>, 105309. (<a
href="https://doi.org/10.1016/j.engappai.2022.105309">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driver distraction is one of the main causes of fatal traffic accidents. Therefore, the ability to detect driver inattention is essential in building a safe yet intelligent transportation system. Currently, the available driver distraction detection systems are not widely available or limited to specific class actions. Various research efforts have approached the problem through different techniques, including the usage of intrusive sensors, which are not feasible for mass production. Most of the work in early 2010s used traditional machine learning approaches to perform the detection task. With the emergence of deep learning algorithms, many research has been conducted to perform distraction detection using neural networks. Furthermore, most of the work in the field is conducted under simulation or lab environment, and did not validate the proposed system under naturalistic scenario. Most importantly, the research efforts in the field could be further subdivided into many subtasks. Thus, this paper aims to provide a comprehensive review of approaches used to detect driving distractions through various methods. We review all recent papers from 2014–2021 and categorized them according to the sensors used. Based on the reviewed articles, a simplified framework to visualize the detection flow, starting from the used sensors, collected data, measured data, computed events, inferred behaviour, and finally its inferred distraction type is proposed. Besides providing an in-depth review and concise summary of various published works, the practicality and relevancy of driver distraction detection towards increasing vehicle automation are discussed. Further, several open research challenges and provide suggestions for future research directions are provided. We believe that this review will remain helpful despite the development towards a higher level of vehicle automation.},
  archive      = {J_EAAI},
  author       = {Hong Vin Koay and Joon Huang Chuah and Chee-Onn Chow and Yang-Lang Chang},
  doi          = {10.1016/j.engappai.2022.105309},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105309},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Detecting and recognizing driver distraction through various data modality using machine learning: A review, recent advances, simplified framework and open challenges (2014–2021)},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generation of synthetic full-scale burst test data for
corroded pipelines using the tabular generative adversarial network.
<em>EAAI</em>, <em>115</em>, 105308. (<a
href="https://doi.org/10.1016/j.engappai.2022.105308">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper employs a deep learning tool, the tabular generative adversarial network (TGAN), to generate synthetic full-scale burst test data for corroded pipe specimens by capturing the joint probability distribution of five dimensionless random variables characterizing a database of 258 real full-scale burst tests collected from the literature. A simple criterion is proposed to identify outliers contained in the synthetic dataset. Two machine learning models, the random forest and extra tree, are trained using the real and synthetic test data to predict the burst capacity of corroded pipelines for the purpose of tuning the hyper-parameters of TGAN and also validating the credibility of the synthetic data. The generated synthetic data are shown to accurately capture the joint probability distribution of the real test data. This study provides a viable option to effectively generate a large number of high-quality synthetic full-scale test data to facilitate the development of engineering critical assessment models employed in the pipeline integrity management practice.},
  archive      = {J_EAAI},
  author       = {Z. He and W. Zhou},
  doi          = {10.1016/j.engappai.2022.105308},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105308},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Generation of synthetic full-scale burst test data for corroded pipelines using the tabular generative adversarial network},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An evolutionary algorithm with indirect representation for
droplet routing in digital microfluidic biochips. <em>EAAI</em>,
<em>115</em>, 105305. (<a
href="https://doi.org/10.1016/j.engappai.2022.105305">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a revolutionary platform for miniaturizing laboratory procedures, the digital microfluidic biochip (DMFB) has the advantages of flexibility and re-configurability over its flow-based counterpart. Droplet routing is one of the most challenging problems in the design automation of DMFBs, which aims to schedule the movements of a set of droplets from their source electrodes to their target electrodes and satisfy both static and dynamic fluidic constraints. In this paper, we propose an evolutionary algorithm (EA) based droplet routing method with an indirect encoding scheme and an improved Dijkstra-based decoding strategy, to minimize the arrival time of the droplets. To be specific, the priority of the movements of the droplets are encoded in the chromosome instead of directly encoding the solution of the problem, i.e., a complete path from the source to the target for each droplet. In the 2D-routing decoding stage, a problem-specific cost function is defined and introduced in the Dijkstra algorithm for obtaining a more time-efficient path for each droplet. Meanwhile, to avoid accidental mixing of the droplets during their movements, several strategies are proposed to modify the paths for satisfying the fluidic constraints in different scenarios of both 2D-routing and 3D-compaction. Compared with the state-of-the-art droplet routing algorithms, the experimental results demonstrate the superiority of the proposed method based on two synthetic benchmark suites and a real-world bioassay benchmark suite.},
  archive      = {J_EAAI},
  author       = {Chen Jiang and Rong-Quan Yang and Bo Yuan},
  doi          = {10.1016/j.engappai.2022.105305},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105305},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An evolutionary algorithm with indirect representation for droplet routing in digital microfluidic biochips},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). STOWP: A light-weight deep residual network integrated
windowing strategy for storage workload prediction in cloud systems.
<em>EAAI</em>, <em>115</em>, 105303. (<a
href="https://doi.org/10.1016/j.engappai.2022.105303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate storage workload forecasting of big data applications is a constructive approach to improve the job scheduling and fine-grained load balancing in real-time cluster systems. However, despite the recent advances of deep learning architectures, demands for more accurate workload time series forecasting algorithm exist. Therefore, we propose a light-weight STO rage W orkload time series P rediction method named as ‘ STOWP ’ integrating Neural Basis Expansion Analysis (N-BEATS) deep model with windowing strategy. The STOWP approach implements a multi-input–multi-output (MIMO) window strategy for capturing the historical storage variation patterns of the workload data. Furthermore, a within window scaling strategy is adopted to effectively estimate the diversity of the workload requests during different time horizons. For experimental evaluation, we used Web-Search dataset containing Search Engine’s I/O real-time workload traces. To improve the performance of STOWP, the hyper-parameters’ sensitivity is well investigated. Through results, we observed that the ’STOWP’ improves the RMSE by 3.33% and MAE by 3.44% atleast in comparison with the existing benchmarks storage workload forecasting techniques.},
  archive      = {J_EAAI},
  author       = {Jatin Bedi and Yashwant Singh Patel},
  doi          = {10.1016/j.engappai.2022.105303},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105303},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {STOWP: A light-weight deep residual network integrated windowing strategy for storage workload prediction in cloud systems},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiple attribute group decision making based on quasirung
orthopair fuzzy sets: Application to electric vehicle charging station
site selection problem. <em>EAAI</em>, <em>115</em>, 105299. (<a
href="https://doi.org/10.1016/j.engappai.2022.105299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to greatly improve decision makers’ capability of capturing their judgment in a broader space. In order to achieve this, we introduce the notion of a p , q -quasirung orthopair fuzzy set ( p , q -QOFS), which is an extension of the q -rung orthopair fuzzy set. In p , q -QOFS, the sum of the p th power of membership degree and q th power of nonmembership degree is less than or equal to 1, where p and q are natural numbers. Thus, due to the additional parameter p , the p , q -QOFS can express incomplete information more flexibly and elaborately. This paper first develops the concept of p , q -QOFS and establishes that it is an extension of several existing fuzzy sets. Then, we introduce the score and accuracy functions of p , q -QOFS and analyze a few mathematical properties. Next, we define the Hamming distance measure between two p , q -QOFSs and some important properties. After that, we investigate the basic operations of p , q -QOFSs and extend these operational laws to aggregation operators. Further, we introduce the weighted averaging and geometric aggregation operators to aggregate p , q -quasirung orthopair fuzzy data. Moreover, we establish a p , q -quasirung orthopair fuzzy Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) method for solving multi-attribute group decision-making problems with unknown attribute weights. The present study also discusses a case study illustrating the applicability of the method through the selection of the most appropriate site for an electric vehicle charging station in an Indian city. In this case study, we consider seven alternative sites, including Raniganj, Jamuria, Kulti, and Burnpur. As a result of this study, Jamuria appears to be the best location to build an electric vehicle charging station. Finally, we illustrate the validity and practicability of our developed method through a comparative analysis with existing methods.},
  archive      = {J_EAAI},
  author       = {Mijanur Rahaman Seikh and Utpal Mandal},
  doi          = {10.1016/j.engappai.2022.105299},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105299},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multiple attribute group decision making based on quasirung orthopair fuzzy sets: Application to electric vehicle charging station site selection problem},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dual-branch framework: AUV-based target recognition method
for marine survey. <em>EAAI</em>, <em>115</em>, 105291. (<a
href="https://doi.org/10.1016/j.engappai.2022.105291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous recognition of marine targets is considered a promising technology for autonomous underwater vehicle (AUV) marine survey, and AUV equipped with side-scan sonar (SSS) for recognition is the key to surveys. As a fundamental function, SSS recognition remains unsolved due to the challenging image conditions of SSS and insufficient algorithm robustness. This paper proposes an accurate and real-time dual-branch recognition framework containing segmentation and refinement branches. Firstly, the segmentation branch uses a lightweight learning network to analyze the data comprehensively. In this branch, we propose a densely connected local attention recurrent residual (LAR2) block as the backbone, and at the same time, an atrous convolution is introduced. This branch can focus on the features of interest in the image, ensuring better feature representation with low-resolution SSS information while guiding the next branch. Secondly, the refinement branch is to adjust the previous branch’s results and combines the low-level and high-level features. We propose holistic attention (HA) block in this branch, which can further improve the target recognition performance. Finally, we adopt the feature fusion method of bilinear pooling to integrate the results of the two branches to output a high-precision recognition image. In offline experiments and sea trials, our proposed method outperforms other competing algorithms in the four indicators of semantic segmentation, and achieves a computation speed of 92.66 ms ( ± 0.86 ms) per image on AUV dedicated hardware. The method has strong robustness, meets real-time performance, and can be widely used in AUV marine survey.},
  archive      = {J_EAAI},
  author       = {Fei Yu and Bo He and Jixin Liu and Qi Wang},
  doi          = {10.1016/j.engappai.2022.105291},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105291},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dual-branch framework: AUV-based target recognition method for marine survey},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Numerical solution of generalized burger–huxley &amp;
huxley’s equation using deep galerkin neural network method.
<em>EAAI</em>, <em>115</em>, 105289. (<a
href="https://doi.org/10.1016/j.engappai.2022.105289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a deep learning algorithm based on Deep Galerkin method (DGM) is presented for the approximate solution of the generalized Burgers–Huxley equation (gBHE), and generalized Huxley’s equation (gHE). In this method, a deep neural network (DNN) is used for approximating the solution without generating mesh grid, which satisfies the differential operator, boundary and initial conditions. DNN is trained on randomly selected batches of time and space points, thus helping to avoid forming a mesh. Adam optimizer is used for optimizing the parameters of the DNN. Further, the convergence of the cost function and convergence of the neural network to the exact solution is demonstrated. This method shows very encouraging results which have been compared with recent methods such as: A fourth order improved numerical scheme (FDS4), Adomain-decomposition method (ADM), Modified cubic B-spline differential quadrature method (MCB-DQM), Variational iteration method (VIM), and others.},
  archive      = {J_EAAI},
  author       = {Harender Kumar and Neha Yadav and Atulya K. Nagar},
  doi          = {10.1016/j.engappai.2022.105289},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105289},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Numerical solution of generalized Burger–Huxley &amp; huxley’s equation using deep galerkin neural network method},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine learning, deep learning and statistical analysis for
forecasting building energy consumption — a systematic review.
<em>EAAI</em>, <em>115</em>, 105287. (<a
href="https://doi.org/10.1016/j.engappai.2022.105287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The building sector accounts for 36 % of the total global energy usage and 40% of associated Carbon Dioxide emissions. Therefore, the forecasting of building energy consumption plays a key role for different building energy management applications (e.g., demand-side management and promoting energy efficiency measures), and implementing intelligent control strategies. Thanks to the advancement of Internet of Things in the last few years, this has led to an increase in the amount of buildings energy related-data. The accessibility of this data has inspired the interest of researchers to utilize different data-driven approaches to forecast building energy consumption. In this study, we first present state of-the-art Machine Learning, Deep Learning and Statistical Analysis models that have been used in the area of forecasting building energy consumption. In addition, we also introduce a comprehensive review of the existing research publications that have been published since 2015. The reviewed literature has been categorized according to the following scopes: (I) building type and location; (II) data components; (III) temporal granularity; (IV) data pre-processing methods; (V) features selection and extraction techniques; (VI) type of approaches; (VII) models used; and (VIII) key performance indicators. Finally, gaps and current challenges with respect to data-driven building energy consumption forecasting have been highlighted, and promising future research directions are also recommended.},
  archive      = {J_EAAI},
  author       = {Mohamad Khalil and A. Stephen McGough and Zoya Pourmirza and Mehdi Pazhoohesh and Sara Walker},
  doi          = {10.1016/j.engappai.2022.105287},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105287},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Machine learning, deep learning and statistical analysis for forecasting building energy consumption — a systematic review},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A parallel rule-based approach to compute rough
approximations of dominance based rough set theory. <em>EAAI</em>,
<em>115</em>, 105285. (<a
href="https://doi.org/10.1016/j.engappai.2022.105285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many datasets, conditional attributes and decision classes are preference-ordered, however, the classical Rough Set Theory (RST) does not consider the preference order between the values of the attributes. An extension of RST known as a Dominance-based Rough Set Approach (DRSA) provides dominance relation in this regard. In DRSA, data analysis mainly depends on the calculations of lower and upper approximations and these two measures are computationally utilizing many resources i.e., time and memory, due to the consideration of preference order. In this paper, we have proposed a parallel technique for calculating DRSA approximation sets. The proposed method directly computes approximations by following heuristic rules without calculating dominance positive or negative relations. The proposed parallel approach is then compared with the conventional method of calculation of DRSA approximations and a recent another technique of parallel processing using ten UCI publicly available datasets. Results validated the efficiency and effectiveness of the proposed model. An average reduction of 83% was observed in execution time and 86% in memory consumption. The structural complexity of the algorithm also considerably reduced.},
  archive      = {J_EAAI},
  author       = {Faryal Nosheen and Usman Qamar and Muhammad Summair Raza},
  doi          = {10.1016/j.engappai.2022.105285},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105285},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A parallel rule-based approach to compute rough approximations of dominance based rough set theory},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Identification of cyber harassment and intention of target
users on social media platforms. <em>EAAI</em>, <em>115</em>, 105283.
(<a href="https://doi.org/10.1016/j.engappai.2022.105283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to Coronavirus diseases in 2020, all the countries departed into lockdown to combat the spread of the pandemic situation. Schools and institutions remain closed and students’ screen time surged. The classes for the students are moved to the digital platform which leads to an increase in social media usage. Many children had become sufferers of cyber harassment which includes threatening comments on young students, sexual torture through a digital platform, people insulting one another, and the use of fake accounts to harass others. The rising effort on automated cyber harassment detection utilizes many AI-related components Natural language processing techniques and machine learning approaches. Though machine learning models using different algorithms fail to converge with higher accuracy, it is much more important to use significant natural language processes and efficient classifiers to detect cyberbullying comments on social media. In this proposed work, the lexical meaning of the text is analysed by the conventional scheme and the word order of the text is performed by the Fast Text model to improve the computational efficacy of the model. The intention of the text is analysed by various feature extraction methods. The score for intention detection is calculated using the frequency of words with a bully-victim participation score. Finally, the proposed model’s performance is measured by different evaluation metrics which illustrate that the accuracy of the model is higher than many other existing classification methods. The error rate is lesser for the detection model.},
  archive      = {J_EAAI},
  author       = {S. Abarna and J.I. Sheeba and S. Jayasrilakshmi and S. Pradeep Devaneyan},
  doi          = {10.1016/j.engappai.2022.105283},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105283},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Identification of cyber harassment and intention of target users on social media platforms},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Application of reliability-based back-propagation
causality-weighted neural networks to estimate air-overpressure due to
mine blasting. <em>EAAI</em>, <em>115</em>, 105281. (<a
href="https://doi.org/10.1016/j.engappai.2022.105281">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present study, the air-overpressure (AOp) due to mine blasting is predicted using an uncertainty intelligence method based on the Z-number reliability and fuzzy cognitive map (FCM). Hence, the cause-and-effect relationship between effective parameters on AOp was first determined by a team of experts. But, expert opinions are accompanied by uncertainty. Therefore, Z-number concept is used to solve the uncertainty of expert opinions and improve views. Notably, the relationships dependent on expert opinions. To overcome this problem, two learning algorithms called nonlinear Hebbian (NLH) and differential evolution (DE) algorithms integrated to decrease the dependence on experts’ views. An FCM based on NLH-DE and reliability information was first designed; then inputs’ weights were extracted during several simulations in training process. The reliability inputs’ weights were imported into back-propagation causality-weighted neural networks (BPCWNNs). The coefficient of determination (R 2 ), root mean square error (RMSE), variance account for (VAF), and accuracy indices were employed as evaluations criteria to select the optimal topology of artificial neural networks (ANNs). Back propagation neural network (BPNN) and generalized feed forward neural network (GFFNN) models were also used to compare and analyze the performance of the developed BPCWNNs model. The results indicated that Z-number considerably improved the accuracy of the ANN model. Notably, the model assessment revealed that the proposed BPCWNNs model was accurate compared to the BPNN and GFFNN and selected as the most superior model. The BPCWNN is the model with high performance which can be used as an artificial intelligence technique for predicting blast-induced AOp.},
  archive      = {J_EAAI},
  author       = {Shahab Hosseini and Rashed Poormirzaee and Mohsen Hajihassani},
  doi          = {10.1016/j.engappai.2022.105281},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105281},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Application of reliability-based back-propagation causality-weighted neural networks to estimate air-overpressure due to mine blasting},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parallel voice conversion with limited training data using
stochastic variational deep kernel learning. <em>EAAI</em>,
<em>115</em>, 105279. (<a
href="https://doi.org/10.1016/j.engappai.2022.105279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are two types of voice conversion methods: statistical and deep learning-based. Although statistical methods can train with limited data, they face challenges, including spectral oversmoothing and time-domain discontinuity. On the other hand, extensively researched deep learning-based methods rely primarily on massive amounts of data, which limits their practical applicability. Given that voice conversion is an engineering problem with limited training data, it is crucial to develop techniques that can produce satisfactory results in terms of quality and similarity in the absence of a large amount of data. This paper proposes a voice conversion model based on stochastic variational deep kernel learning (SVDKL), which works with limited training data. The model allows the use of both the deep neural network’s expressive capability and the high flexibility of the Gaussian process, which is a Bayesian and non-parametric method. The model utilizes a cascade of a deep neural network and a conventional kernel as the covariance function, which enables it to estimate non-smooth and more complex functions. Furthermore, the model’s sparse variational Gaussian process solves the scalability problem of exact inference and enables the learning of a global mapping function for the entire acoustic space. One of the most important aspects of the proposed scheme is that the model parameters are trained using marginal likelihood optimization, which takes into account both data fitting and model complexity. Considering model complexity reduces the training data by increasing the robustness to overfitting. To evaluate the proposed scheme, we examined the model’s performance with as little as approximately 80 s of training data. The results indicated that our method obtains a higher mean opinion score, smaller spectral distortion, and better preference tests than the state-of-the-art limited data methods.},
  archive      = {J_EAAI},
  author       = {Mohamadreza Jafaryani and Hamid Sheikhzadeh and Vahid Pourahmadi},
  doi          = {10.1016/j.engappai.2022.105279},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105279},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Parallel voice conversion with limited training data using stochastic variational deep kernel learning},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Development of scheduling methodology in a multi-machine
flexible manufacturing system without tool delay employing flower
pollination algorithm. <em>EAAI</em>, <em>115</em>, 105275. (<a
href="https://doi.org/10.1016/j.engappai.2022.105275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses machines, automated guided vehicles (AGVs), tool transporter (TT), and tools concurrent scheduling in a multi-machine flexible manufacturing system (FMS) for makespan minimization. The fewest number of copies of each tool type is employed to prevent tool delays, and job and tool shift times between machines are taken into account. The tools are placed in a central tool magazine (CTM), which shares and serves them to many machines to cut down the price of duplicating the tools in each machine. This simultaneous scheduling problem is challenging to solve because it entails determining the fewest tool copies of each tool kind without tool delay, assigning AGVs and tool copies to job-operations (jb-ons), ordering jb-ons on machines, and related trip operations such as deadheading and loaded flight times for both TT and AGVs. This paper uses a mixed-integer nonlinear programming (MINLP) framework to present the problem, and a flower pollination algorithm (FPA) is employed to solve it. For verification, a manufacturing company’s industrial problem is employed. The results show that employing two copies each for two tool types and one copy each for the remaining tool types causes no tool delay, reduction in makespan and cost, and the FPA outperforms the Jaya algorithm.},
  archive      = {J_EAAI},
  author       = {Padma Lalitha Mareddy and Sivarami Reddy Narapureddy and Venkata Ramamurthy Dwivedula and Prahlada Rao Karanam},
  doi          = {10.1016/j.engappai.2022.105275},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105275},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Development of scheduling methodology in a multi-machine flexible manufacturing system without tool delay employing flower pollination algorithm},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Damage localization and characterization using
one-dimensional convolutional neural network and a sparse network of
transducers. <em>EAAI</em>, <em>115</em>, 105273. (<a
href="https://doi.org/10.1016/j.engappai.2022.105273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early damage identification and continuous system monitoring save dramatically maintenance costs and increase the lifespan of priceless structures. Convolutional neural networks (CNNs) have attracted the attention of the structural health monitoring (SHM) community in recent years due to their great potential for identifying underlying data patterns. However, employing two-dimensional convolutional layers in a CNN necessitates the use of strong computing resources. Therefore, based on the present state-of-the-art technical solutions, a two-dimensional CNN is not suitable for real-time SHM applications with stand-alone processing units. One-dimensional convolutional networks (1D-CNN) have recently been employed in Ultrasonic Guided Wave-based (UGW-based) damage detection to address the aforementioned disadvantage. In this paper, a methodology for damage assessment at three levels – detection, localization, and characterization – based on 1D-CNN is put forward. Furthermore, the sequence length of the time-domain signals is significantly shortened by the application of a novel approach for processing them. Additionally, it is shown to what extend this method can improve the distinguishability between datapoints obtained from various damage scenarios. Consequently, by reducing the dimensionality of the problem, the proposed approach significantly reduces the memory usage of the classification algorithm. Experimental measurements as well as Numerical simulations, in which various damage scenarios such as corrosion, circular hole and cracks have been considered, are carried out to evaluate the efficacy of the proposed algorithm. It is shown that the suggested approach has benefits in terms of true classification rate of instances (above 93 percent for detection, localization, and characterization), computing time, in-situ monitoring, and noise resilience.},
  archive      = {J_EAAI},
  author       = {Afshin Sattarifar and Tamara Nestorović},
  doi          = {10.1016/j.engappai.2022.105273},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105273},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Damage localization and characterization using one-dimensional convolutional neural network and a sparse network of transducers},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel framework for semantic classification of cyber
terrorist communities on twitter. <em>EAAI</em>, <em>115</em>, 105271.
(<a href="https://doi.org/10.1016/j.engappai.2022.105271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential growth of Online Social Networks (OSNs) such as Twitter intrigues many terrorist groups to flourish their dark activities, target people to follow and sympathize with their activities, share their ideas, recruit new members, raise funds, and radicalize. In this paper, we focused on identifying terrorist Twitter profiles with high cyber social impact based on semantic tweets analysis and mining techniques. Practically, we proposed a novel framework based on Social Networks Analysis (SNA) and Semi-Supervised Machine Learning (SSML) techniques to classify user accounts and terrorist communities through identifying top influencers by sampling their cyber behaviors. To achieve the targeted goal, we extracted required features using the contemporary topic modeling technique, known as BERTopic. In addition, those features fed into various machine learning classifier models, like SVM, Naïve Bayes, and Logistic Regression classifiers, to find the polarity, which will be used in predicting twitter profiles as extremist or non-extremist accounts. Then, the proposed node classification algorithm uses SNA measures and techniques to identify key players within such extremist communities, and standard classification metrics are used to evaluate the obtained results. Experiments show the efficiency of our framework by outperforming various baseline methods in confronting Twitter extremism.},
  archive      = {J_EAAI},
  author       = {Firas Saidi and Zouheir Trabelsi and Eswari Thangaraj},
  doi          = {10.1016/j.engappai.2022.105271},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105271},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel framework for semantic classification of cyber terrorist communities on twitter},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intelligent fault diagnosis of rolling bearing based on
wavelet transform and improved ResNet under noisy labels and
environment. <em>EAAI</em>, <em>115</em>, 105269. (<a
href="https://doi.org/10.1016/j.engappai.2022.105269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fault diagnosis (FD) of rolling bearing (RB) has a great significance in safe operation of engineering equipment. Many intelligent diagnosis methods have been successfully developed. However, the performances of traditional fault diagnosis methods are affected by noisy labels and environment which widely exist in realistic industrial applications. This article proposed a novel FD method of RB based on wavelet transform (WT) and an improved residual neural network (IResNet), named WT-IResNet. The proposed WT-IResNet approach uses a new pooling layer for dimension reduction and a global singular value decomposition (SVD) adaptive strategy for feature extraction. Furthermore, the original softmax layer and the logistic loss for training are replaced by a new loss function containing two adjustable parameters to address fault diagnosis with label noises. Two typical bearing failure datasets are used to evaluate the feasibility and effectiveness of WT-IResNet under noisy labels and noisy environment respectively. The experimental results indicate that WT-IResNet has better robustness against noise in comparison with other methods. Whatever under noisy labels or noisy environment, the performance of WT-IResNet outperforms other methods.},
  archive      = {J_EAAI},
  author       = {Pengfei Liang and Wenhui Wang and Xiaoming Yuan and Siyuan Liu and Lijie Zhang and Yiwei Cheng},
  doi          = {10.1016/j.engappai.2022.105269},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105269},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent fault diagnosis of rolling bearing based on wavelet transform and improved ResNet under noisy labels and environment},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). High-performance content-based music retrieval via automated
navigation and semantic features. <em>EAAI</em>, <em>115</em>, 105267.
(<a href="https://doi.org/10.1016/j.engappai.2022.105267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Content-based music retrieval has been studied for many years. However, it is not easy to achieve effective and efficient retrieval because two issues such as search strategy and music feature are not considered simultaneously. Therefore, in this paper, we propose an innovative music search method using automated navigations and semantic features to cope with these issues. For automated navigations, it is a novel autonomous-feedback technique that moves the search towards the user interest space effectively and efficiently. For semantic features, the low-level audio features are transformed into high-level semantic features to effectively associate with user concepts. To reveal the performance of the proposed method, we conducted a set of comprehensive evaluations on two real music datasets. In the comparative experiments, semantic features are shown to be more effective than audio features. Additionally, the proposed method is superior to state-of-the-art methods in terms of precision, which indicates the average improvements of 151.67% and 148.02% on two datasets, respectively. Moreover, the subjective evaluation shows that the proposed method can earn the users’ satisfactions in the materialized system. In summary, the proposed automated navigations and semantic features are useful for dealing with issues of search strategy and music feature in content-based music retrieval.},
  archive      = {J_EAAI},
  author       = {Ja-Hwung Su and Tzung-Pei Hong and Yu-Tang Chen and Chu-Yu Chin},
  doi          = {10.1016/j.engappai.2022.105267},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105267},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {High-performance content-based music retrieval via automated navigation and semantic features},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Metaheuristics for multiobjective optimization in
energy-efficient job shops. <em>EAAI</em>, <em>115</em>, 105263. (<a
href="https://doi.org/10.1016/j.engappai.2022.105263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy awareness is one of the most relevant research directions in scheduling problems. In this paper we consider the minimization of both the makespan and the energy consumption in the classical job shop scheduling problem. The energy model considered allows several possible states for the machines: off , stand-by , idle , setup and processing . To solve this multi-objective problem we propose an NSGA-II based evolutionary algorithm combined with local search and a heuristic procedure to improve the energy consumption of a given schedule. We also propose an advanced constraint programming (CP) approach as well as a Mixed-Integer Linear Programming (MILP) model, to the aim of comparing their performances against those obtained with the NSGA-II. The experimental study is performed against a benchmark set that extends by 41 instances of increasing size, the set tackled in the previous literature against the same problem. The experiments demonstrate the superiority of the NSGA-II algorithm over all other methods, despite the utilization of CP and MILP allows to draw interesting conclusions on the overall solution optimality, revealing that there is still room for further optimization.},
  archive      = {J_EAAI},
  author       = {Miguel A. González and Riccardo Rasconi and Angelo Oddi},
  doi          = {10.1016/j.engappai.2022.105263},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105263},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Metaheuristics for multiobjective optimization in energy-efficient job shops},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ecology based network traffic control: A bee colony
optimization approach. <em>EAAI</em>, <em>115</em>, 105262. (<a
href="https://doi.org/10.1016/j.engappai.2022.105262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The majority of fuel consumed in traffic on urban arterials is related to driving in congested traffic, characterized by frequent speed fluctuations and stops at signalized intersections. A range of traffic control strategies was suggested in the past to decrease fuel consumption and emissions in urban networks. The research presented in this study aims to fill the gap in the existing knowledge by proposing a novel combination of an ecology-based performance index and an evolutionary method for optimization of traffic signal settings. An optimization problem is defined to find the best values for traffic light control parameters on the street network. The ecology-based performance index is used as the criteria for optimization. The defined problem is solved by the Bee Colony Optimization (BCO) technique. The geometry of the subject network has been inserted into a Vissim model calibrated by using relevant traffic demand and field-measured travel times. The Vissim has been used as the tool for the evaluation of the proposed BCO, TRANSYT-7F (T7F) and field signal timing plans. The methodology is tested on the field-real-like network of the City of Kragujevac, Serbia. Results show that in the case of the overall network ecology performance index, BCO makes a decrease of 11.95 % and 8.47% compared to the signal timings from field and T7F, respectively.},
  archive      = {J_EAAI},
  author       = {Aleksandar Jovanović and Aleksandar Stevanović and Nemanja Dobrota and Dušan Teodorović},
  doi          = {10.1016/j.engappai.2022.105262},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105262},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Ecology based network traffic control: A bee colony optimization approach},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Inverse design of nanophotonic devices using generative
adversarial networks. <em>EAAI</em>, <em>115</em>, 105259. (<a
href="https://doi.org/10.1016/j.engappai.2022.105259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The efficient design of structures that exhibit desired properties is challenging across various engineering and scientific applications. Traditional methods employ experts in a specific domain to design new structures with desired properties. Then, simulations are performed for the designed structures to evaluate whether they show desired properties, and such a process is with until the structures exhibit desired properties. Advances in computing power and machine learning have made these simulations and optimizations faster, but challenges remain that the researchers must perform optimizations in each iteration, which generally takes time and cost. A new framework called inverse design has been studied to address the limitations. In inverse design, structures with desired properties can directly be constructed. In this work, as an inverse design framework, we introduce a controllable generative adversarial network (ControlGAN) based model to generate nanophotonic devices with user-defined properties. As a result, the proposed model outperforms other GAN-based models when the model is evaluated by producing structures with maximum transmittance at specific wavelengths. Specifically, the proposed model achieves a mean F1-score of 0.357, corresponding to a 260% improvement compared to the second-best model. The proposed model for inverse design can accelerate device designs not only in the field of nanophotonics but also in other nanostructures.},
  archive      = {J_EAAI},
  author       = {Wonsuk Kim and Soojeong Kim and Minhyeok Lee and Junhee Seok},
  doi          = {10.1016/j.engappai.2022.105259},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105259},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Inverse design of nanophotonic devices using generative adversarial networks},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A spatial temporal graph neural network model for predicting
flashover in arbitrary building floorplans. <em>EAAI</em>, <em>115</em>,
105258. (<a
href="https://doi.org/10.1016/j.engappai.2022.105258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid fire progression, such as flashover, has been one of the leading causes for firefighter deaths and injuries in residential building environments. Due to long computational time of and the required prior knowledge about the fire scene, existing models cannot be used to predict the potential occurrence of flashover in practical firefighting applications. In this paper, a scene-agnostic model (FlashNet) is proposed to predict flashover based on limited heat detector temperature information up to 150 °C. FlashNet utilizes spatial temporal graph convolutional neural networks to effectively learn features from the limited temperature information and to tackle building structure variations. The proposed model is benchmarked against five different state-of-the-art flashover prediction models. Results show that FlashNet outperforms the existing flashover prediction models and it can reliably predict flashover 30 s preceding its occurrence with an overall accuracy of about 92.1%. Ablation study is carried out to examine the effectiveness of different key model components and geometric average adjacency matrix. The research outcomes from this study are expected to enhance firefighters’ situational awareness in the fire scene, protecting them from hazardous fire environments and to pave the way for the development of data-driven prediction systems.},
  archive      = {J_EAAI},
  author       = {Wai Cheong Tam and Eugene Yujun Fu and Jiajia Li and Xinyan Huang and Jian Chen and Michael Xuelin Huang},
  doi          = {10.1016/j.engappai.2022.105258},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105258},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A spatial temporal graph neural network model for predicting flashover in arbitrary building floorplans},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Determining ultimate bearing capacity of shallow foundations
by using multi expression programming (MEP). <em>EAAI</em>,
<em>115</em>, 105255. (<a
href="https://doi.org/10.1016/j.engappai.2022.105255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents an artificial intelligence approach, namely multi expression programming (MEP), for determining ultimate bearing capacity of shallow foundations on cohesionless soils. Five governing parameters (i.e., internal friction angle, soil unit weight, the length to width ratio of foundation, foundation depth and foundation width) were used as input variables to develop the MEP model. Through the determination of the optimal parameter setting of MEP, a group of expressions were proposed. Then, the MEP model was compared with linear multiple regression, non-linear multiple regression and several previous models, and three statistical indices (i.e., coefficient of determination ( R 2 ), root mean squared error ( RMSE ) and mean absolute error ( MAE )) were employed to evaluate the prediction accuracy of these models. The results show that the proposed model has higher prediction precision than the other models, with higher R 2 value and lower RMSE and MAE values. Additionally, a monotonicity analysis was performed to verify the correct relationship between ultimate bearing capacity and various factors. From the monotonicity analysis, the ultimate bearing capacity increases with the increase of internal friction angle ( φ ), soil unit weight ( γ ), foundation width ( B ) and foundation depth ( D ), whereas it decreases with the increase of the length to width ratio of foundation ( L/B ). Then, a sensitivity analysis was performed. Through the sensitivity analysis, the effect rank of the five input parameters on ultimate bearing capacity is φ &gt; B &gt; D &gt; γ &gt; L/B . Finally, a graphical user interface (GUI) of the MEP model is developed for practical application.},
  archive      = {J_EAAI},
  author       = {Ruiliang Zhang and Xinhua Xue},
  doi          = {10.1016/j.engappai.2022.105255},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105255},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Determining ultimate bearing capacity of shallow foundations by using multi expression programming (MEP)},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep and transfer learning for building occupancy detection:
A review and comparative analysis. <em>EAAI</em>, <em>115</em>, 105254.
(<a href="https://doi.org/10.1016/j.engappai.2022.105254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The building internet of things (BIoT) is quite a promising concept for curtailing energy consumption, reducing costs, and promoting building transformation. Besides, integrating artificial intelligence (AI) into the BIoT is essential for data analysis and intelligent decision-making. Thus, data-driven approaches to infer occupancy patterns usage are gaining growing interest in BIoT applications. Typically, analyzing big occupancy data gathered by BIoT networks helps significantly identify the causes of wasted energy and recommend corrective actions. Within this context, building occupancy data aids in the improvement of the efficacy of energy management systems, allowing the reduction of energy consumption while maintaining occupant comfort. Occupancy data might be collected using a variety of devices. Among those devices are optical/thermal cameras, smart meters, environmental sensors such as carbon dioxide (CO 2 ), and passive infrared (PIR). Even though the latter methods are less precise, they have generated considerable attention owing to their inexpensive cost and low invasive nature. This article provides an in-depth survey of the strategies used to analyze sensor data and determine occupancy. The article’s primary emphasis is on reviewing deep learning (DL), and transfer learning (TL) approaches for occupancy detection. This work investigates occupancy detection methods to develop an efficient system for processing sensor data while providing accurate occupancy information. Moreover, the paper conducted a comparative study of the readily available algorithms for occupancy detection to determine the optimal method in regards to training time and testing accuracy. The main concerns affecting the current occupancy detection system in terms of privacy and precision were thoroughly discussed. For occupancy detection, several directions were provided to avoid or reduce privacy problems by employing forthcoming technologies such as edge devices, Federated learning, and Blockchain-based IoT.},
  archive      = {J_EAAI},
  author       = {Aya Nabil Sayed and Yassine Himeur and Faycal Bensaali},
  doi          = {10.1016/j.engappai.2022.105254},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105254},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep and transfer learning for building occupancy detection: A review and comparative analysis},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ZigZag+: A global optimization algorithm to solve the view
selection problem for large-scale workload optimization. <em>EAAI</em>,
<em>115</em>, 105251. (<a
href="https://doi.org/10.1016/j.engappai.2022.105251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In advanced database design such as Big Data Warehouses, optimizing large-scale decision support queries passes through the selection of redundant structures such as materialized views and indexes. Materialized View Selection ( M V S ) is one of the most studied problems in the context of the physical design of advanced databases. It is known as an NP-Hard problem. Several algorithms have been proposed to find, within a reasonable computation time, the appropriate materialized views that reduce as much as possible the query processing cost and the view maintenance cost w.r.t. a storage constraint. By analyzing the state-of-art studies, we figure out that almost all are workload-driven approaches. Their efficiency strongly depends on the number of queries of the considered workload. These approaches manage a small set of queries. Having efficient algorithms for selecting materialized views based on a very large set of queries has become a crucial issue for advanced applications. In this paper, we proposed a Z i g Z a g + approach that uses the multiple view processing plan ( M V P P ) as a basic data structure that unifies all query plans. Due to the no-unicity of this M V P P , our approach aims at exploring all possible M V V P s, and for each exploration, it identifies materialized views. After this selection, update operations of the current M V P P are performed. Zigzagging from one M V P P to another is guided by the quality of selected views. Intensive experiments have been conducted to evaluate the effectiveness and efficiency of our proposal by considering large workloads and comparing it with state-of-art approaches.},
  archive      = {J_EAAI},
  author       = {Mohamed Kechar and Ladjel Bellatreche and Safia Nait-Bahloul},
  doi          = {10.1016/j.engappai.2022.105251},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105251},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ZigZag+: A global optimization algorithm to solve the view selection problem for large-scale workload optimization},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A convergence and diversity guided leader selection strategy
for many-objective particle swarm optimization. <em>EAAI</em>,
<em>115</em>, 105249. (<a
href="https://doi.org/10.1016/j.engappai.2022.105249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, particle swarm optimizer (PSO) is extended to solve many-objective optimization problems (MaOPs) and becomes a hot research topic in the field of evolutionary computation. Particularly, the leader particle selection (LPS) and the search direction used in a velocity update strategy are two crucial factors in PSOs. However, the LPS strategies for most existing PSOs are not so efficient in high-dimensional objective space, mainly due to the lack of convergence pressure or loss of diversity. In order to address these two issues and improve the performance of PSO in high-dimensional objective space, this paper proposes a convergence and diversity guided leader selection strategy for PSO, denoted as CDLS, in which different leader particles are adaptively selected for each particle based on its corresponding situation of convergence and diversity. In this way, a good tradeoff between the convergence and diversity can be achieved by CDLS. To verify the effectiveness of CDLS, it is embedded into the PSO search process of three well-known PSOs. Furthermore, a new variant of PSO combining with the CDLS strategy, namely PSO/CDLS, is also presented. The experimental results validate the superiority of our proposed CDLS strategy and the effectiveness of PSO/CDLS, when solving numerous MaOPs with regular and irregular Pareto fronts ( PF s).},
  archive      = {J_EAAI},
  author       = {Lingjie Li and Yongfeng Li and Qiuzhen Lin and Zhong Ming and Carlos A. Coello Coello},
  doi          = {10.1016/j.engappai.2022.105249},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105249},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A convergence and diversity guided leader selection strategy for many-objective particle swarm optimization},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Nonlinear model predictive control algorithm with iterative
nonlinear prediction and linearization for long short-term memory
network models. <em>EAAI</em>, <em>115</em>, 105247. (<a
href="https://doi.org/10.1016/j.engappai.2022.105247">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a practical nonlinear model predictive control with iterative nonlinear prediction and linearization is proposed, considering a long short-term memory (LSTM) artificial neural network (PNMPCi-LSTM) as process model for making the predictions. The prediction model is divided into two portions, the base output prediction, obtained with the LSTM nonlinear model, and the incremental output prediction, obtained using a linearized version of the LSTM model. The base response and the dynamic matrix of the system, which is obtained using the linearized version, are used to find an optimal control effort by solving a quadratic programming problem. This procedure is performed iteratively by updating the base input with the candidate control effort until the incremental response term is small enough compared with the base response term. The advantages of the proposed method in terms of performance and computing times are illustrated using the control of a simulated nonlinear neutralization reactor. For the evaluated case study, the results show that by using the proposed iterative procedure the closed-loop performance measured using the integral absolute error is improved by 8% for a setpoint tracking scenario while keeping the computation times within reasonable levels. In addition, the results support the idea that the proposed PNMPCi-LSTM is an alternative to implement a nonlinear MPC with reasonable computation times.},
  archive      = {J_EAAI},
  author       = {Bernardo B. Schwedersky and Rodolfo C.C. Flesch},
  doi          = {10.1016/j.engappai.2022.105247},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105247},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Nonlinear model predictive control algorithm with iterative nonlinear prediction and linearization for long short-term memory network models},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A learning-based model predictive control scheme and its
application in biped locomotion. <em>EAAI</em>, <em>115</em>, 105246.
(<a href="https://doi.org/10.1016/j.engappai.2022.105246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a learning-based model predictive control scheme. This scheme divides the predictive model into a known nominal model and an unknown model residual. Model residual is learned using Gaussian process regression. The learned stochastic model is solved quickly using differential dynamic programming, taking into account control input constraints. The simulation results show that compared with state of art optimal control methods, this scheme has good robustness to model residual, accelerates the solution of high-dimensional problems, and can strictly constrain the control inputs according to the actual situation. Based on this learning-based model predictive control scheme, this paper also proposes an online learning gait generator for the uncertainty problem in the locomotion control of biped robots. The zero moment point is strictly constrained during training to ensure safety. The simulation results show that the gait generator is robust to unknown load and unknown external force.},
  archive      = {J_EAAI},
  author       = {Jingchao Li and Zhaohui Yuan and Sheng Dong and Xiaoyue Sang and Jian Kang},
  doi          = {10.1016/j.engappai.2022.105246},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105246},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A learning-based model predictive control scheme and its application in biped locomotion},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Corrigendum to “giving commands to a self-driving car: How
to deal with uncertain situations?” [Eng. Appl. Artif. Intell. 103
(2021) 104257]. <em>EAAI</em>, <em>115</em>, 105243. (<a
href="https://doi.org/10.1016/j.engappai.2022.105243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EAAI},
  author       = {Thierry Deruyttere and Victor Milewski and Marie-Francine Moens},
  doi          = {10.1016/j.engappai.2022.105243},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105243},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Corrigendum to “Giving commands to a self-driving car: How to deal with uncertain situations?” [Eng. appl. artif. intell. 103 (2021) 104257]},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Refinement of the feedforward network in multi-class
classification problems using a hybrid approach combining supervised
clustering and a fuzzy classifier. <em>EAAI</em>, <em>115</em>, 105242.
(<a href="https://doi.org/10.1016/j.engappai.2022.105242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A FeedForward Neural Network (FFNN) with a single hidden layer (Single Feedforward Neural Networks, SFNN) represents a classical discriminative model able to estimate conditional probabilities (Bayesian probabilities) and provides an efficient alternative in multi-class classification problems. This paper presents an approach to improve the accuracy of SFNN in recognizing multiple patterns in static data focusing on classification problems which systematically pose difficulties in obtaining high levels of accuracy (low misclassification rates) using different classification methods. In an innovative way, the method comprises the joint application of supervised clustering and fuzzy classifier, starting from the probability distribution predicted by the SFNN. The proposed approach​ (Refinement based on Supervised Clustering and Fuzzy Classifier, RSCFC) is applied in real datasets widely used as a benchmark for multi-class classification. The results were compared with other methods involving different categories of neuro-fuzzy systems (cooperative and hybrid) and other networks with tailored topologies for the classification of static data. The RSCFC method proved to be viable, able to improve the results obtained with the SFNN using classical settings (e.g., softmax function, crossed entropy) and provided correct classification rates higher or similar to those achieved with existing methods. Additionally, the method is flexible as any classifier capable of estimating conditional probabilities for data classification can be adopted as a starting point (primary classifier) for the refinement and achievement of greater accuracy.},
  archive      = {J_EAAI},
  author       = {Cristiano Hora Fontes},
  doi          = {10.1016/j.engappai.2022.105242},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105242},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Refinement of the feedforward network in multi-class classification problems using a hybrid approach combining supervised clustering and a fuzzy classifier},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploring design smells for smell-based defect prediction.
<em>EAAI</em>, <em>115</em>, 105240. (<a
href="https://doi.org/10.1016/j.engappai.2022.105240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Defect prediction is commonly used to reduce the effort from the testing phase of software development. A promising strategy is to use machine learning techniques to predict which software components may be defective. Features are key factors to the prediction’s success, and thus extracting significant features can improve the model’s accuracy. In particular, code smells are a category of those features that have been shown to improve the prediction performance significantly. However, Design code smells, a state-of-the-art collection of code smells based on the violations of the object-oriented programming principles, have not been studied in the context of defect prediction. In this paper, we study the performance of defect prediction models by training multiple classifiers for 97 real projects. We compare using Design code smells as features and using other Traditional smells from the literature and both. Moreover, we cluster and analyze the models’ performance based on the categories of Design code smells. We conclude that the models trained with both the Design code smells and the smells from the literature performed the best, with an improvement of 4.1% for the AUC score, compared to models trained with only Traditional smells. Consequently, Design smells are a good addition to the smells commonly studied in the literature for defect prediction.},
  archive      = {J_EAAI},
  author       = {Bruno Sotto-Mayor and Amir Elmishali and Meir Kalech and Rui Abreu},
  doi          = {10.1016/j.engappai.2022.105240},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105240},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Exploring design smells for smell-based defect prediction},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A deep transfer regression method based on seed replacement
considering balanced domain adaptation. <em>EAAI</em>, <em>115</em>,
105238. (<a
href="https://doi.org/10.1016/j.engappai.2022.105238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of deep transfer learning, the generalization abilities of models in similar scenarios have been significantly improved. However, for regression tasks, either the marginal distribution or the conditional distribution is usually ignored. In addition, initiative regarding the representation and learning of domain knowledge is lacking due to the reliance on the loss function. A deep transfer regression method based on seed replacement considering balanced domain adaptation, called DTRSR, is proposed in this work. DTRSR is composed of four parts: structure freezing and parameter transfer, deep feature extraction, seed replacement and a fusion loss function. First, domain knowledge is captured at the model level through structure freezing and parameter transfer. Second, seed replacement is used for knowledge learning in the source and target domains at the data level. Finally, a fusion loss function considering balanced distribution adaptation is constructed to acquire domain knowledge at the loss level. In summary, domain knowledge is sufficiently learned through DTRSR. In addition, seed replacement improves the initiative of knowledge learning instead of relying only on the loss function to learn automatically. DTRSR is compared on three datasets, namely, Tool Wear, Battery Capacity and Robot Machining Errors, with nine other methods. The proposed method achieves excellent performance on most tasks, which validates its effectiveness and great potential in regression tasks.},
  archive      = {J_EAAI},
  author       = {Teng Zhang and Hao Sun and Fangyu Peng and Shengqiang Zhao and Rong Yan},
  doi          = {10.1016/j.engappai.2022.105238},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105238},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep transfer regression method based on seed replacement considering balanced domain adaptation},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Human trajectory forecasting using a flow-based generative
model. <em>EAAI</em>, <em>115</em>, 105236. (<a
href="https://doi.org/10.1016/j.engappai.2022.105236">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present a flow-based framework for multi-modal trajectory prediction, which is able to provide an accurate and explicit inference of the latent representations on trajectory data. Differently from other typical generative models (such as GAN, VAE, etc.), the flow-based models aim at learning data distribution explicitly through an invertible network, which can convert a complicated distribution into a tractable form via invertible transformations. The whole framework is built upon the standard encoder–decoder architecture, where the LSTM is exploited as the fundamental block to capture the temporal structure of a trajectory. As a core module, we incorporate an invertible network that can learn the multi-modal distributions of trajectory data and further generate plausible future paths by sampling tricks from the standard Gaussian distribution. Extensive experiments carried out on synthetic and realistic datasets demonstrate the effectiveness of the proposed approach, and show the advantages as compared to the GAN-based and the VAE-based prediction frameworks.},
  archive      = {J_EAAI},
  author       = {Bo Zhang and Tao Wang and Changdong Zhou and Nicola Conci and Hongbo Liu},
  doi          = {10.1016/j.engappai.2022.105236},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105236},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Human trajectory forecasting using a flow-based generative model},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new traffic flow prediction model based on cosine
similarity variational mode decomposition, extreme learning machine and
iterative error compensation strategy. <em>EAAI</em>, <em>115</em>,
105234. (<a
href="https://doi.org/10.1016/j.engappai.2022.105234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow data (TFD) prediction is a hot research area in intelligent transportation system. TFD is non-stationary and nonlinear, so it has become a challenge to predict it accurately. In order to improve TFD prediction accuracy, a new TFD prediction model based on cosine similarity variational mode decomposition (CSVMD), extreme learning machine (ELM), and iterative error compensation strategy, named CSVMD-ELM-error, is proposed. To solve mode number K value selection of variational mode decomposition, CSVMD is proposed, which realizes the self-adaptive determination of K value. The idea of CSVMD-ELM-error is roughly as follows. Firstly, CSVMD decomposes TFD into a series of intrinsic mode functions (IMFs), and ELM is established for each IMF component. Then, in order to further improve the prediction accuracy, ELM is used to correct the prediction error of each IMF. Finally, the revised IMF error results and the IMF prediction results are reconstructed to complete the prediction. Four TFDs and nine comparison models are used for simulation experiment, the experimental result shows that CSVMD-ELM-error has the best prediction accuracy and has an effective application in TFD prediction.},
  archive      = {J_EAAI},
  author       = {Hong Yang and Yuanxun Cheng and Guohui Li},
  doi          = {10.1016/j.engappai.2022.105234},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105234},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new traffic flow prediction model based on cosine similarity variational mode decomposition, extreme learning machine and iterative error compensation strategy},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MBGAN: An improved generative adversarial network with
multi-head self-attention and bidirectional RNN for time series
imputation. <em>EAAI</em>, <em>115</em>, 105232. (<a
href="https://doi.org/10.1016/j.engappai.2022.105232">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series data is of great value in data mining and analysis, but it often comes with the problem of data partly missing in many fields. So it is necessary to impute missing values from raw data to improve accuracy in the analysis of time series. Conventional methods based on interpolation ignore the temporal correlation of data. Recurrent Neural Networks (RNN) are good at capturing temporal relationships, while they have a limitation to obtain the potential correlations in multivariate time series. Based on Generative Adversarial Networks, this paper proposes a new model for time series imputation. The key contributions of the paper are: ( i ) A feature extraction module is designed to reduce the influence of irrelevant features in raw data. ( i i ) A bidirectional Gated Recurrent Unit (GRU) module is applied to capture the temporal relationships. A temporal attention mechanism is also designed to help capture important correlations in long sequences which will be neglected by conventional RNN. ( i i i ) A new feature attention based on multi-head self-attention is proposed to extract the potential correlations within multivariate features. ( i v ) A temporal hint mechanism is added so that the discriminator can perform better in identifying fake data and the generator can learn the distribution of raw data better. The proposed model has been tested on 4 real-world datasets. Two metrics are applied to evaluate the results: Root Mean Square Error and Mean Absolute Error. The results illustrate that our model is superior to the other 10 state-of-the-art methods in most cases.},
  archive      = {J_EAAI},
  author       = {Qingjian Ni and Xuehan Cao},
  doi          = {10.1016/j.engappai.2022.105232},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105232},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MBGAN: An improved generative adversarial network with multi-head self-attention and bidirectional RNN for time series imputation},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic speed trajectory generation and tracking control for
autonomous driving of intelligent high-speed trains combining with deep
learning and backstepping control methods. <em>EAAI</em>, <em>115</em>,
105230. (<a
href="https://doi.org/10.1016/j.engappai.2022.105230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of autonomous transportation systems has received increasing attention over the last decades. Different from existing automatic train control systems, the decision-making capability in the autonomous driving system enables a train to adapt to the complicated and dynamic circumstances. This paper in particular focuses on the decision-making problem for the autonomous driving of intelligent high-speed trains, and proposes a novel decision-making framework by combining the deep learning and backstepping control methods. By exploiting the deep learning methods, a speed trajectory generator is trained with the actual driving data, and dynamically calculates the reference speed trajectory according to the real-time driving condition. Then, a backstepping controller is designed to track the reference speed trajectory such that the separation, cohesion and alignment requirements for the autonomous driving of high-speed trains are achieved. Simulation experiments are implemented to illustrate the effectiveness of our methods.},
  archive      = {J_EAAI},
  author       = {Xi Wang and Shukai Li and Yuan Cao and Tianpeng Xin and Lixing Yang},
  doi          = {10.1016/j.engappai.2022.105230},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105230},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic speed trajectory generation and tracking control for autonomous driving of intelligent high-speed trains combining with deep learning and backstepping control methods},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-criteria evaluation of smart product-service design
concept under hesitant fuzzy linguistic environment: A novel cloud
envelopment analysis approach. <em>EAAI</em>, <em>115</em>, 105228. (<a
href="https://doi.org/10.1016/j.engappai.2022.105228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Design concept evaluation is an essential but challenging task in smart product service system (SPSS) design. It is critical to select the design concept with better smart experience to ensure the success of SPSS design. Meanwhile, SPSS design concept evaluation is an expert knowledge-based decision process with scant data and a short time window under a hesitant, ambiguous, and subjective environment, which would lead to low decision-making efficiency and inaccurate evaluation results. Hence, this paper proposes a novel cloud envelopment analysis method to evaluate SPSS design concept with respect to smart experience criteria. The proposed method integrates hesitant fuzzy linguistic terms (HFLTs), cloud model and data envelopment analysis (DEA) method to accurately evaluate SPSS design concepts with handling the hesitancy, fuzziness and randomness in qualitative and subjective information. A hybrid model of normal cloud and trapezium cloud is used to quantify hybrid-length HFLT variables to avoid decision information loss and distortion. A novel cloud non-linear programming model is constructed to extend the classical DEA into cloud environment. Finally, a case study and some comparison analyses illustrate the effectiveness and advantages of proposed method.},
  archive      = {J_EAAI},
  author       = {Tongtong Zhou and Zhihua Chen and Xinguo Ming},
  doi          = {10.1016/j.engappai.2022.105228},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105228},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-criteria evaluation of smart product-service design concept under hesitant fuzzy linguistic environment: A novel cloud envelopment analysis approach},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Double-quantitative feature selection using bidirectional
three-level dependency measurements in divergence-based fuzzy rough
sets. <em>EAAI</em>, <em>115</em>, 105226. (<a
href="https://doi.org/10.1016/j.engappai.2022.105226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection benefits machine learning and knowledge acquisition, and it usually resorts to various intelligent methodologies. Fuzzy rough sets act as a powerful platform of intelligent processing, and they have introduced divergence measures to generate an effective method of feature selection, called FS-DD. However, Algorithm FS-DD still has advancement space, because its underlying dependency degree with absoluteness lacks decision-categorical manifestations and exhibits loose informatization. Within the framework of divergence-based fuzzy rough sets (Div-FRSs), we implement bidirectional three-level dependency measurements to establish double-quantitative feature selection, and two novel approaches of feature selection (i.e., Algorithms FS-AFS and FS-RFS) are designed to reconstruct and improve current Algorithm FS-DD. Based on divergence and lower-approximation matrices, we first make three-level measurements in vertical and horizontal directions, and correspondingly generate absolute and relative dependency degrees. Then, double-quantitative dependency degrees naturally induce double-quantitative feature significances, and the two types of uncertainty measures respectively exhibit granulation monotonicity and non-monotonicity. Furthermore, double-quantitative feature significances are utilized to motivate double-quantitative selection algorithms, i.e., absolute FS-AFS and relative FS-RFS. Finally, measurement properties and selection algorithms are fully validated by table examples and data experiments. This study systematically reveals hierarchical constructions and quantitative characteristics of dependency measurements in Div-FRSs, and the relative measures effectively extract class-specific and condensed information. For related selection algorithms, FS-AFS interprets existing FS-DD, while new FS-RFS outperforms the two to acquire better classification performances, as experimentally verified.},
  archive      = {J_EAAI},
  author       = {Jiefang Jiang and Xianyong Zhang and Jilin Yang},
  doi          = {10.1016/j.engappai.2022.105226},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105226},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Double-quantitative feature selection using bidirectional three-level dependency measurements in divergence-based fuzzy rough sets},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automated bridge surface crack detection and segmentation
using computer vision-based deep learning model. <em>EAAI</em>,
<em>115</em>, 105225. (<a
href="https://doi.org/10.1016/j.engappai.2022.105225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bridge maintenance will become a widespread trend in the engineering industry as the number of bridges grows and time passes. Cracking is a common problem in bridges with concrete structures. Allowing it to expand will result in significant economic losses and accident risks This paper proposed an automatic detection and segmentation method of bridge surface cracks based on computer vision deep learning models. First, a bridge surface crack detection and segmentation dataset was established. Then, according to the characteristics of the bridge, we improved the You Only Look Once (YOLO) algorithm for bridge surface crack detection. The improved algorithm was defined as CR-YOLO, which can identify cracks and their approximate locations from multi-object images. Subsequently, the PSPNet algorithm was improved to segment the bridge cracks from the non-crack regions to avoid the visual interference of the detection algorithm. Finally, we deployed the proposed bridge crack detection and segmentation algorithm in an edge device. The experimental results show that our method outperforms other baseline methods in generic evaluation metrics and has advantages in Model Size(MS) and Frame Per Second (FPS).},
  archive      = {J_EAAI},
  author       = {Jian Zhang and Songrong Qian and Can Tan},
  doi          = {10.1016/j.engappai.2022.105225},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105225},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automated bridge surface crack detection and segmentation using computer vision-based deep learning model},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interpretable machine learning models for predicting and
explaining vehicle fuel consumption anomalies. <em>EAAI</em>,
<em>115</em>, 105222. (<a
href="https://doi.org/10.1016/j.engappai.2022.105222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying anomalies in the fuel consumption of vehicle fleets is crucial for optimizing consumption and reducing costs. However, this information alone is insufficient since fleet operators need to know the causes behind anomalous fuel consumption. Therefore, we combine unsupervised anomaly detection techniques, domain knowledge and interpretable Machine Learning models for explaining potential causes of abnormal fuel consumption in terms of feature relevance. The explanations are used for generating recommendations about fuel optimization that are adjusted according to two different user profiles: fleet managers and fleet operators. Results are evaluated over real-world data from telematics devices connected to diesel and petrol vehicles from different types of industrial vehicle fleets. We carry out an evaluation through model performance and Explainable AI metrics that compare the explanations in terms of representativeness, fidelity, stability, contrastiveness and consistency with prior beliefs.},
  archive      = {J_EAAI},
  author       = {Alberto Barbado and Óscar Corcho},
  doi          = {10.1016/j.engappai.2022.105222},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105222},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Interpretable machine learning models for predicting and explaining vehicle fuel consumption anomalies},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Surgery planning for elective patients: A dedicated
heuristic and an effective ALNS. <em>EAAI</em>, <em>115</em>, 105220.
(<a href="https://doi.org/10.1016/j.engappai.2022.105220">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hospital organization, the medical concerns of the patient, surgery resources and the horizon to be considered are all elements that contribute to the variety of problems encountered in surgery planning. In this paper, we address the admission planning problem for which surgical interventions of hundreds of elective patients need to be scheduled months before the date of surgery. The health care surgery organization we consider here is based on a shared management of operating rooms and surgeons. The main issue for hospital planners is to schedule all the interventions under resource availability constraints while considering the patients’ health priorities. We propose a two-phase 2PSC-EM randomized heuristic that obtains better results on literature benchmark instances. However, for some instances certain interventions are left unscheduled since straightforward heuristic failed to schedule all interventions. We investigated an effective Adaptive Large Neighborhood Search (ALNS) approach. Better results are obtained for each instance, all the patients’ interventions are scheduled which had not been done before. The average improvement is about 11.2% and the processing times are shorter than the timeout fixed in the literature, except for one instance for which we succeeded to schedule all of the patients.},
  archive      = {J_EAAI},
  author       = {Lahcene Mezouari and Jean-Paul Boufflet and Aziz Moukrim},
  doi          = {10.1016/j.engappai.2022.105220},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105220},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Surgery planning for elective patients: A dedicated heuristic and an effective ALNS},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Jointly optimized ensemble deep random vector functional
link network for semi-supervised classification. <em>EAAI</em>,
<em>115</em>, 105214. (<a
href="https://doi.org/10.1016/j.engappai.2022.105214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Randomized neural networks have become more and more attractive recently since they use closed-form solutions for parameter training instead of gradient-based approaches. Among them, the random vector functional link network (RVFL) and its deeper version ensemble deep random vector functional link network (edRVFL) show great performance on both classification and regression tasks. However, the previous research on these two models mainly focuses on the supervised learning area. Although there have been efforts to extend the RVFL network to solve semi-supervised learning problems, the potential of the edRVFL network has not been fully investigated. Therefore, we propose a jointly optimized learning strategy for the edRVFL network (JOSedRVFL) for semi-supervised learning tasks in this paper. The JOSedRVFL network uses an iterative procedure to compute the output weights and consequently predicts the class labels of the unlabeled training data during the training process. In addition, we propose another semi-supervised edRVFL network (SS-edRVFL) using manifold regularization in this work. We then do a brief comparison between these two methods to illustrate their similarities and differences. In the experimental part, we conduct the first set of experiments using the UCI datasets to compare the performance of our proposed semi-supervised algorithms against 11 other classifiers to demonstrate the superior performance of the SS-edRVFL and JOSedRVFL networks. JOSedRVFL achieves the highest accuracy on all 4 datasets while SS-edRVFL takes the second place 3 times which is only worse than JOSedRVFL. Moreover, we apply the proposed methods to real-world applications using the electroencephalography-based emotion recognition dataset to compare the performance of RVFL-based methods (RVFL, SS-RVFL, and JOSRVFL) and their edRVFL counterparts (edRVFL, SS-edRVFL, and JOSedRVFL). Results from this test revealed that the edRVFL-based models (edRVFL, SS-edRVFL, and JOSedRVFL) can obtain higher accuracy than the RVFL-based versions (RVFL, SS-RVFL, and JOSRVFL) with the same learning framework on 45 real-world semi-supervised benchmarks. We then perform the Wilcoxon signed-rank test to show that JOSedRVFL is significantly better than 5 other competitors, which supports our claim that JOSedRVFL can be treated as a superior classifier for semi-supervised classification on both benchmark datasets and real-world applications.},
  archive      = {J_EAAI},
  author       = {Qiushi Shi and Ponnuthurai Nagaratnam Suganthan and Javier Del Ser},
  doi          = {10.1016/j.engappai.2022.105214},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105214},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Jointly optimized ensemble deep random vector functional link network for semi-supervised classification},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multistage retrieval system for health-related
misinformation detection. <em>EAAI</em>, <em>115</em>, 105211. (<a
href="https://doi.org/10.1016/j.engappai.2022.105211">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Web search is widely used to find online medical advice. As such, health-related information access requires retrieval algorithms capable of promoting reliable documents and filtering out unreliable ones. To this end, different types of components, such as query-document matching features, passage relevance estimation and AI-based reliability estimators, need to be combined. In this paper, we propose an entire pipeline for misinformation detection, based on the fusion of multiple content-based features. We present experiments which study the influence of each pipeline stage for the target task. Our technological solution incorporates signals from technologies derived from diverse research fields, including search, deep learning for natural language processing, as well as advanced supervised and unsupervised learning. To combine evidence, different score fusion strategies are compared, including unsupervised rank fusion techniques and learning-to-rank methods. The reference framework for empirically validating our solution is the TREC Health Misinformation Track, which provides several challenging subtasks that foster research on the identification of reliable and correct information for health-related decision making tasks. More specifically, we address a total recall task, the goal of which is to identify all the documents conveying incorrect information for a specific set of topics, and an ad-hoc retrieval task, aiming to rank credible and correct information over incorrect information. All variants are evaluated with an assorted set of effectiveness metrics, which includes standard search measures, such as R-Precision, Average Precision or Normalised Discounted Cumulative Gain, and innovative metrics based on the compatibility between the ranked output and two reference rankings composed of helpful and harmful documents, respectively. Our experiments demonstrate the effectiveness of the proposed pipeline stages and indicate that sophisticated supervised fusion methods do not fare better than simpler fusion alternatives. Additionally, for reliability estimation, unsupervised textual similarity performs better than textual classification based on supervised learning. The results also show that the presented approach is highly competitive when compared with state-of-the-art solutions for the same problem.},
  archive      = {J_EAAI},
  author       = {Marcos Fernández-Pichel and David E. Losada and Juan C. Pichel},
  doi          = {10.1016/j.engappai.2022.105211},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105211},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multistage retrieval system for health-related misinformation detection},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An approach for characterization of infected area in tomato
leaf disease based on deep learning and object detection technique.
<em>EAAI</em>, <em>115</em>, 105210. (<a
href="https://doi.org/10.1016/j.engappai.2022.105210">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tomato leaf infections are a common threat to long-term tomato production that affects many farmers worldwide. Early detection, treatment, and solution of tomato leaf specificity are critical for promoting healthy tomato plant growth and ensuring ample supply and health security for the world’s geometric growth (population). The detection of plant leaf disease using computer-assisted technologies is prevalent these days. In this work, use the 1610 tomato leaf images of different classes from PlantVillage standard repository for the localization of objects. An effective Deep Learning (DL) modified Mask Region Convolutional Neural Network (Mask R-CNN) is proposed for the autonomous segmentation and detection of tomato plant leaf disease in this research. Intending to conserve memory space and computational expense, the suggested model adds a light head “Region Convolutional Neural Network (R-CNN)”. By varying the proportions of anchor in the RPN network and also changing the feature extraction topology, which improves the detection accuracy and computing the metric performance. The proposed technique is compared to existing state-of-the-art models to check if it is viable and robust. The outcomes of the suggested model achieved the results in terms of Mean Average Precision (mAP), F1-score, and accuracy of 0.88, 0.912, and 0.98, respectively. Furthermore, as the model’s ability increases with some parameters, the detection time for lesion detection is reduced by two times than the existing models.},
  archive      = {J_EAAI},
  author       = {Prabhjot Kaur and Shilpi Harnal and Vinay Gautam and Mukund Pratap Singh and Santar Pal Singh},
  doi          = {10.1016/j.engappai.2022.105210},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105210},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An approach for characterization of infected area in tomato leaf disease based on deep learning and object detection technique},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Identifying emerging smells in software designs based on
predicting package dependencies. <em>EAAI</em>, <em>115</em>, 105209.
(<a href="https://doi.org/10.1016/j.engappai.2022.105209">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software systems naturally evolve, and this evolution often brings design problems that contribute to system degradation. Architectural smells are typical symptoms of such problems, and several of these smells are related to undesired dependencies among packages. The early detection of smells is essential for software engineers to plan ahead for maintenance or refactoring efforts. Although tools for identifying smells exist, they detect the smells once they already exist in the source code when their undesired dependencies are already created. In this work, we explore a forward-looking approach for identifying smells that can emerge in the next system version based on inferring package dependencies that are likely to appear in the system. Our approach takes the current design structure of the system as a network, along with information from previous versions, and applies link prediction techniques from the field of social network analysis. In particular, we consider a group of smells known as instability smells (cyclic dependency, hub-like dependency, and unstable dependency), which fit well with the link prediction model. The approach includes a feedback mechanism to progressively reduce false positives in predictions. An evaluation based on six open-source projects showed that, under certain considerations, the proposed approach can satisfactorily predict missing dependencies and smell configurations thereof. The feedback mechanism led to improvements of up to three times the initial precision values. Furthermore, we have developed a tool for practitioners to apply the approach in their projects.},
  archive      = {J_EAAI},
  author       = {Antonela Tommasel and J. Andres Diaz-Pace},
  doi          = {10.1016/j.engappai.2022.105209},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105209},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Identifying emerging smells in software designs based on predicting package dependencies},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Development of a core feature identification application
based on the faster r-CNN algorithm. <em>EAAI</em>, <em>115</em>,
105200. (<a
href="https://doi.org/10.1016/j.engappai.2022.105200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As engineering rock mass quality assessment is an important part of the evaluation of deposit mining technical conditions, the identification and counting of core features are essential but time-consuming, and the complexity of core features leads to the invalidity of traditional image processing programs. In such a case, we developed an efficient automated core feature identification and counting application by adopting the Faster R-CNN algorithm together with a self-designed batch processing and counting program, which allows for the high-speed identification of target features among many pictures and can count and output formatted identification results. The evaluation results show that this application can significantly improve the identification accuracy and speed up the process with the help of a deep learning algorithm and our computer program. In the comparison and selection of the Faster R-CNN and YOLO algorithms, YOLO was eliminated due to poor performance. The main reason is that the multiscale self-similarity of core features has adverse effects on the multiscale segmentation method of the YOLO algorithm, making YOLO identify one feature repeatedly. The overall training evaluation F1-score of the Faster R-CNN-based AI model reaches 0.91, showing an ideal result. In the practical test, the overall AI identification F1-score is 0.93, and the application processing F1-score reaches 0.92. The time complexities of the AI model and application are both acceptable, with T(n) = O(n). In terms of identification speed, the application process is 48 times faster than that of manual identification.},
  archive      = {J_EAAI},
  author       = {Quan Jiang and Mingtao Jia and Lin Bi and Zheng Zhuang and Kaixin Gao},
  doi          = {10.1016/j.engappai.2022.105200},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105200},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Development of a core feature identification application based on the faster R-CNN algorithm},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep architecture for silica forecasting of a real
industrial froth flotation process. <em>EAAI</em>, <em>115</em>, 105196.
(<a href="https://doi.org/10.1016/j.engappai.2022.105196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Froth Flotation is one of the fundamental processes used in iron ore attainment. It involves various physical–chemical reactions, and its multivariate control is not trivial. Traditionally, plant operators get quality measurements from laboratory analysis of sampled material, which can take hours to be published. In this paper, we present alternatives that eliminate both the necessity to periodically sample material as well as the delay associated with laboratory analysis: a predictive machine learning model working as a soft sensor. Two different classes of models were developed, exploring both deep and shallow approaches of machine learning, with a deep neural network architecture constructed for the particular task at hand. All models yielded accurate predictions, with results favoring the deep neural network when a larger volume of data is available.},
  archive      = {J_EAAI},
  author       = {Alexsander C.A.A. Costa and Felipe V. Campos and Lourenço R.G. Araujo and Luiz C.B. Torres and Antonio P. Braga},
  doi          = {10.1016/j.engappai.2022.105196},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105196},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep architecture for silica forecasting of a real industrial froth flotation process},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Life prediction of underground structure by sulfate
corrosion using harris hawks optimizing genetic programming.
<em>EAAI</em>, <em>115</em>, 105190. (<a
href="https://doi.org/10.1016/j.engappai.2022.105190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A corrosive sulfate environment can cause strong deterioration and destruction of reinforced concrete (RC) underground structures and seriously reduce their service life. Thus, it is very important to predict the service life of RC underground structures in corrosive sulfate environments. However, the service life of underground structures is affected by numerous complicated engineering and environmental factors and cannot be determined by traditional theoretical and experimental investigations. Therefore, to solve this problem, a new data-driven method based on Harris hawks optimizing genetic programming (HHO-GP) is proposed. In this new method, to improve the traditional genetic programming (GP), a new global optimization algorithm called Harris hawks optimization (HHO) is adopted to optimize its main controlling parameters. Based on 25 groups of real engineering data, the life prediction model of underground structures in corrosive sulfate environments with 12 main engineering and environmental influence factors is established by the HHO-GP method. The results show that the average relative training error (5.5%) and predicting error (6.3%) of the new prediction model are small. Therefore, the proposed HHO-GP method can construct a suitable life prediction model based on only real engineering data, regardless of how many complicated influencing factors are considered. Moreover, our data-driven life prediction model is described by one explicit polynomial function based on 12 influencing factors. Thus, it can be applied in real engineering simply and easily. Finally, the influence of the main controlling parameters of the HHO-GP on its accuracy and efficiency is analyzed. The results reveal that considering the computing accuracy and efficiency and the model completeness, the small population size and maximum iterations of HHO are suitable, whose recommended values are all 15. The population size and maximum number of iterations of GP have little influence on the prediction accuracy. Their recommended values all can be 50.},
  archive      = {J_EAAI},
  author       = {Yuan Xie and Wei Gao and Yiwei Wang and Xin Chen and Shuangshuang Ge and Sen Wang},
  doi          = {10.1016/j.engappai.2022.105190},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105190},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Life prediction of underground structure by sulfate corrosion using harris hawks optimizing genetic programming},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning-based human body communication baseband
transceiver for WBAN IEEE 802.15.6. <em>EAAI</em>, <em>115</em>, 105169.
(<a href="https://doi.org/10.1016/j.engappai.2022.105169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Wireless Body Area Network (WBAN) has revolutionized e-health-care. WBAN boosts monitoring vital signs utilizing tiny wireless sensors implanted in or around the human body. In February 2012, the IEEE 802.15.6 WBAN standard was released for low-power and short-range communication around the human body. The standard defines one medium access control layer and three different physical layers: narrow band , ultra-wideband, and Human Body Communication (HBC) layers. We are motivated by exploiting the human body as a communication medium. We propose a novel optimized architecture for the HBC baseband transceiver based on deep learning. The receiver utilizes two deep neural networks: one for frame synchronization to recover data and timing precisely and the other for the channel decoder to improve transceiver performance and reduce power consumption. In addition, low-complexity Preamble/SFD generator, Walsh modulation, and FSC spreader modules are proposed to reduce the power consumption while preserving the transceiver performance. Compared with the traditional hard-decision channel decoder, the proposed neural network decoder improves the block error rate by 2 dB. The proposed HBC transceiver supports 1.312 Mbps data rate at 42 MHz clock rate. The transceiver is implemented in RTL and synthesized on 90 nm CMOS technology. It consumes 493 pJ/bit on the receiver side and 105 pJ/bit on the transmitter side.},
  archive      = {J_EAAI},
  author       = {Abdelhay Ali and Sabah M. Ahmed and Mohammed S. Sayed and Ahmed Shalaby},
  doi          = {10.1016/j.engappai.2022.105169},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105169},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep learning-based human body communication baseband transceiver for WBAN IEEE 802.15.6},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ensemble deep learning: A review. <em>EAAI</em>,
<em>115</em>, 105151. (<a
href="https://doi.org/10.1016/j.engappai.2022.105151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble learning combines several individual models to obtain better generalization performance. Currently, deep learning architectures are showing better performance compared to the shallow or traditional models. Deep ensemble learning models combine the advantages of both the deep learning models as well as the ensemble learning such that the final model has better generalization performance. This paper reviews the state-of-art deep ensemble models and hence serves as an extensive summary for the researchers. The ensemble models are broadly categorized into bagging, boosting, stacking, negative correlation based deep ensemble models, explicit/implicit ensembles, homogeneous/heterogeneous ensemble, decision fusion strategies based deep ensemble models. Applications of deep ensemble models in different domains are also briefly discussed. Finally, we conclude this paper with some potential future research directions.},
  archive      = {J_EAAI},
  author       = {M.A. Ganaie and Minghui Hu and A.K. Malik and M. Tanveer and P.N. Suganthan},
  doi          = {10.1016/j.engappai.2022.105151},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {105151},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Ensemble deep learning: A review},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Low-frequency learning quantized control for MEMS gyroscopes
accounting for full-state constraints. <em>EAAI</em>, <em>115</em>,
104724. (<a
href="https://doi.org/10.1016/j.engappai.2022.104724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a low-frequency learning quantized control scheme for micro-electro-mechanical systems (MEMS) gyroscopes subject to full-state constraints is proposed. In order to cope with asymmetric time-varying constraints imposed on MEMS gyroscope states, a nonlinear state-dependent transformation scheme is introduced via converting the constrained system into an equivalent formulation free from constraints, which entirely removes the feasibility condition enforced on the virtual control signal, and avoids the nontrivial optimization of design parameters. A low-frequency learning architecture capable of recovering uncertainties in the transformed system without incurring high-frequency transient chattering is proposed with the aid of a low-pass filter, a state estimator and a minimum-learning-parameter neural network (MLPNN), which has the following striking features: one is that the estimation error rather than tracking error is utilized in the weight update law, allowing for better transient estimation behaviors in the presence of a high adaptive gain. Another is that the high-frequency component of disturbances can be filtered out via inserting a filtering error-based modification term. Then, a logarithm quantizer (LQ) is employed to generate control signal sequences within finite digital sets for MEMS gyroscopes, remarkably saving communication and actuating resources. Eventually, via Lyapunov stability synthesis and substantial simulation results, all closed-loop error signals are proven to be ultimately uniformly bounded, and the effectiveness along with superiority of proposed algorithm are illustrated.},
  archive      = {J_EAAI},
  author       = {Xingling Shao and Haonan Si and Wendong Zhang},
  doi          = {10.1016/j.engappai.2022.104724},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104724},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Low-frequency learning quantized control for MEMS gyroscopes accounting for full-state constraints},
  volume       = {115},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TSadv: Black-box adversarial attack on time series with
local perturbations. <em>EAAI</em>, <em>114</em>, 105218. (<a
href="https://doi.org/10.1016/j.engappai.2022.105218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) for time series classification have potential security concerns due to their vulnerability to adversarial attacks. Previous work that perturbs time series globally requires gradient information to generate adversarial examples, leading to being perceived easily. In this paper, we propose a gradient-free black-box method called TSadv to attack DNNs with local perturbations. First, we formalize the attack as a constrained optimization problem solved by a differential evolution algorithm without any inner information of the target model. Second, with the assumption that time series shapelets provide more discriminative information between different classes, the range of perturbations is designed based on their intervals. Experimental results show that our method can effectively attack DNNs on time series datasets that have potential security concerns and generate imperceptible adversarial samples flexibly. Besides, our approach decreases the mean squared error by approximately two orders of magnitude compared with the state-of-the-art method while retaining competitive attacking success rates.},
  archive      = {J_EAAI},
  author       = {Wenbo Yang and Jidong Yuan and Xiaokang Wang and Peixiang Zhao},
  doi          = {10.1016/j.engappai.2022.105218},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105218},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {TSadv: Black-box adversarial attack on time series with local perturbations},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). BeamsNet: A data-driven approach enhancing doppler velocity
log measurements for autonomous underwater vehicle navigation.
<em>EAAI</em>, <em>114</em>, 105216. (<a
href="https://doi.org/10.1016/j.engappai.2022.105216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous underwater vehicles (AUV) perform various applications such as seafloor mapping and underwater structure health monitoring. Commonly, an inertial navigation system aided by a Doppler velocity log (DVL) is used to provide the vehicle’s navigation solution. In such fusion, the DVL provides the velocity vector of the AUV, which determines the navigation solution’s accuracy and helps estimate the navigation states. This paper proposes BeamsNet, an end-to-end deep learning framework to regress the estimated DVL velocity vector that improves the accuracy of the velocity vector estimate, and could replace the model-based approach. Two versions of BeamsNet, differing in their input to the network, are suggested. The first uses the current DVL beam measurements and inertial sensor data, while the other utilizes only DVL data, taking the current and past DVL measurements for the regression process. Both simulation and sea experiments were made to validate the proposed learning approach relative to the model-based approach. Sea experiments were made with the Snapir AUV in the Mediterranean Sea, collecting approximately four and a half hours of DVL and inertial sensor data. Our results show that the proposed approach achieved an improvement of more than 60% in estimating the DVL velocity vector.},
  archive      = {J_EAAI},
  author       = {Nadav Cohen and Itzik Klein},
  doi          = {10.1016/j.engappai.2022.105216},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105216},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {BeamsNet: A data-driven approach enhancing doppler velocity log measurements for autonomous underwater vehicle navigation},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The interval grey QFD method for new product development:
Integrate with LDA topic model to analyze online reviews. <em>EAAI</em>,
<em>114</em>, 105213. (<a
href="https://doi.org/10.1016/j.engappai.2022.105213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the development of the consuming environment, the way consumers give feedback on product experience changes from passive feedback to active reviews, and the development of artificial intelligence technology brings new possibilities for companies to obtain information on Customer Requirements (CRs) and Market Competition Information (CIs) needed for new product development. In the previous New Product Development (NPD) process, CRs and CIs often need to be corrected through market surveys and questionnaires. To acquire the corrected data from experienced experts without user and designer cognitive bias is very laborious and more subjective. Under the situation of key information shortage for business developers and NPD efficiency &amp; accuracy cannot be guaranteed, online reviews provided a good source for data analysis to enhance the market competition. This study integrates Latent Dirichlet Allocation (LDA), Apriori algorithm, interval grey number, and Quality Function Deployment(QFD) techniques to propose the Latent Dirichlet Allocation-Interval Grey Number Quality Function Deployment (LDA-IGQFD) method, which can use text mining and analysis methods to obtain objective information about CRs and CIs contained in users’ online reviews, transformed them into data and input into Interval Grey Number Quality Function Deployment (IGQFD) to drive product development. LDA-IGQFD can help product developers identify CRs and Engineering Characteristics (ECs) important information and provide suggestions for product development. The aim of the research process under the LDA-IGQFD method is explained with the design of a dishwasher as an example, and the effectiveness and practicality of the proposed method is scientifically verified.},
  archive      = {J_EAAI},
  author       = {Shengqing Huang and Jie Zhang and Chaoxiang Yang and Quan Gu and Ming Li and Wenqiang Wang},
  doi          = {10.1016/j.engappai.2022.105213},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105213},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {The interval grey QFD method for new product development: Integrate with LDA topic model to analyze online reviews},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning causal bayesian networks based on causality
analysis for classification. <em>EAAI</em>, <em>114</em>, 105212. (<a
href="https://doi.org/10.1016/j.engappai.2022.105212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Revealing causal information by analyzing purely observational data, known as causal discovery, has drawn much attention. To prove that the causal knowledge mined from data can be applied to facilitate various machine learning tasks (e.g., classification), we propose to measure, describe and evaluate the causalities in the framework of Bayesian network (BN) learning. In this paper, heuristic search strategy is applied to explore the causal interpretation in the form of directed acyclic graph (DAG) for classification. While adding directed edges to the DAG, we first introduce the log-likelihood equivalence assertion to make the learned joint probability encoded in BN approximates the true one, then introduce the causal dependence assertion to assess the rationality of the learned causal relationship. We perform a range of experiments on 35 datasets and empirically show that this novel algorithm demonstrates competitive classification performance and excellent causal interpretation compared to state-of-the-art Bayesian network classifiers (e.g. SKDB, WATAN, SLB, and TAODE).},
  archive      = {J_EAAI},
  author       = {Limin Wang and Jiaping Zhou and Junyang Wei and Meng Pang and Minghui Sun},
  doi          = {10.1016/j.engappai.2022.105212},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105212},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning causal bayesian networks based on causality analysis for classification},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A fast community detection algorithm based on coot bird
metaheuristic optimizer in social networks. <em>EAAI</em>, <em>114</em>,
105202. (<a
href="https://doi.org/10.1016/j.engappai.2022.105202">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection (CD) is critical to understanding complex networks. Researchers have made serious efforts to develop efficient CD algorithms in this sense. Since community detection is an NP-hard problem, utilizing metaheuristic algorithms is preferred instead of classical approaches in solving the problem. For this reason, in this study, six different metaheuristic algorithms called Archimedes optimization algorithm (AOA), Atom search optimization (ASO), Coot Bird Natural Life Model (COOT), Harris Hawks Optimization (HHO), Slime Mould Algorithm (SMA) and Arithmetic Optimization Algorithm (AROA) are used in the solution of CD problems and all of which have been proposed for solving continuous problems in recent years. Since the CD problem has a discrete structure, discrete versions of all the algorithms are produced, and then the proposed discrete algorithms are adapted to the problem. In addition, in the phase of evaluating the objective function of the problem, a fast approach based on CommunityID is proposed to minimize the time cost when solving the problem, and this approach is utilized in all the algorithms when calculating the fitness value. In the experimental studies, firstly, the novel discrete algorithms are compared with each other in terms of solution quality and time and according to these results, COOT becomes the most effective and very fast algorithm. Then, the results obtained by COOT are compared with those of important studies in the literature. When compared in terms of solution quality, it is seen that the COOT algorithm is more effective than the other algorithms. In addition, it is quite obvious that all of the proposed algorithms using the CommunityID- based approach are faster than the other algorithms in the literature in terms of time. As a result, it can be said that COOT can be an effective alternative method for dealing with CD problems. In addition, the approach based on CommunityID can also be utilized in larger networks to obtain remarkable solutions in a much shorter time.},
  archive      = {J_EAAI},
  author       = {Ismail Koc},
  doi          = {10.1016/j.engappai.2022.105202},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105202},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A fast community detection algorithm based on coot bird metaheuristic optimizer in social networks},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comprehensive survey and taxonomy of sign language
research. <em>EAAI</em>, <em>114</em>, 105198. (<a
href="https://doi.org/10.1016/j.engappai.2022.105198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sign language relies on visual gestures of human body parts to convey meaning and plays a vital role in modern society to communicate and interact with people having hearing difficulty as well as for human–machine interaction applications. This field has attracted a growing attention in recent years and several research outcomes have been witnessed covering various issues including sign acquisition, segmentation, recognition, translation and linguistic structures. In this paper, a comprehensive up-to-date survey of the state-of-the-art literature of automated sign language processing is presented. The survey provides a taxonomy and review of the body of knowledge and research efforts with focus on acquisition devices, available databases, and recognition techniques for fingerspelling signs, isolated sign words, and continuous sentence recognition systems. It covers recent advances including deep machine learning and multimodal approaches and discusses various related challenges. This survey is directed to junior researchers and industry developers working on sign language gesture recognition and related systems to gain insights and identify distinctive aspects and current status of existing landscape as well as future perspectives leading to further advancements.},
  archive      = {J_EAAI},
  author       = {El-Sayed M. El-Alfy and Hamzah Luqman},
  doi          = {10.1016/j.engappai.2022.105198},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105198},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A comprehensive survey and taxonomy of sign language research},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic-balanced double-attention fusion for image
captioning. <em>EAAI</em>, <em>114</em>, 105194. (<a
href="https://doi.org/10.1016/j.engappai.2022.105194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image captioning has received significant attention in the cross-modal field in which spatial and channel attentions play a crucial role. However, such attention-based approaches ignore two issues: (1) errors or noise in the channel feature map amplifies in the spatial feature map, leading to a lower model reliability; (2) image spatial feature and channel feature provide different contributions to the prediction both function words (e.g., “in”, “out” and “on”) and notional words (e.g., “girl”, “teddy” and “bear”). To alleviate the above issues, in this paper we propose the Dynamic-Balanced Double-Attention Fusion (DBDAF) for image captioning task that novelly exploits the attention variation and enhances the overall performance of the model. Technically, DBDAF first integrates a parallel Double Attention Network (DAN) in which channel attention is capitalized on as a supplement to the region attention, enhancing the model reliability. Then, a attention variation based Balancing Attention Fusion Mechanism (BAFM) module is devised. When predicting function words and notional words, BAFM makes a dynamic balance between channel attention and region attention based on attention variation. Moreover, to achieve the richer image description, we further devise a Doubly Stochastic Regularization (DSR) penalty and integrate it into the model loss function. Such DSR makes the model equally focus on every pixel and every channel in generating entire sentence. Extensive experiments on the three typical datasets show our DBDAF outperforms the related end-to-end leading approaches clearly. More remarkably, DBDAF achieves 1.04% and 1.75% improvement in terms of BLEU4 and CIDEr on the MSCOCO datasets.},
  archive      = {J_EAAI},
  author       = {Changzhi Wang and Xiaodong Gu},
  doi          = {10.1016/j.engappai.2022.105194},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105194},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic-balanced double-attention fusion for image captioning},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Toward axial accuracy prediction and optimization of metal
tube bending forming: A novel GRU-integrated pb-NSGA-III optimization
framework. <em>EAAI</em>, <em>114</em>, 105193. (<a
href="https://doi.org/10.1016/j.engappai.2022.105193">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Springback is particularly common in metal tube bending, which extremely affects the metal tube axial accuracy. At present, the springback mechanism still remains unclear due to the complex plastic deformation characteristics of metal materials. It is difficult to obtain the accurate axial springback information before bending forming, not to mention formulating a reasonable processing plan to compensate springback. To alleviate this difficulty, a novel optimization framework is constructed which takes the radius changes series (RCS) as the new axial accuracy evaluation index for the first time. The optimization framework contains a GRU-based deep learning network as the prediction module to predict the springback more reliably. Subsequently, NSGA-III has been improved by the proposed guiding factor (GF) and dynamic reference points (DRF) algorithm, i.e, priority-based NSGA-III (Pb-NSGA-III), which can more efficiently deal with the objectives with different priorities when generating the processing plan. With the help of the finite element (FE) and bending experiment, the springback dataset construction and the accuracy verification can be achieved. The results show that the framework can achieve high-precision and robust prediction of the tube axial accuracy. Compared with the existing commonly used multi-objective algorithms, the proposed Pb-NSGA-III shows its superiority in engineering application.},
  archive      = {J_EAAI},
  author       = {Chang Sun and Zili Wang and Shuyou Zhang and Xiaojian Liu and Le Wang and Jianrong Tan},
  doi          = {10.1016/j.engappai.2022.105193},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105193},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Toward axial accuracy prediction and optimization of metal tube bending forming: A novel GRU-integrated pb-NSGA-III optimization framework},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient gesture recognition for the assistance of visually
impaired people using multi-head neural networks. <em>EAAI</em>,
<em>114</em>, 105188. (<a
href="https://doi.org/10.1016/j.engappai.2022.105188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing research for the assistance of visually impaired people mainly focus on solving a single task (such as reading a text or detecting an obstacle), hence forcing the user to switch applications to perform other actions. This paper proposes an interactive system for mobile devices controlled by hand gestures that allow the user to control the device and use several assistance tools by making simple static and dynamic hand gestures (e.g., pointing a finger at an object will show a description of it). The system is based on a multi-head neural network, which initially detects and classifies the gestures, and subsequently, depending on the gesture detected, performs a second stage that carries out the corresponding action. This architecture optimizes the resources required to perform different tasks, it takes advantage of the information obtained from an initial backbone to perform different processes in a second stage. To train and evaluate the system, a dataset with about 40k images was manually compiled and labeled including different types of hand gestures, backgrounds (indoors and outdoors), lighting conditions, etc. This dataset contains synthetic gestures (whose objective is to pre-train the system to improve the results) and real images captured using different mobile phones. The comparison made with nearly 50 state-of-the-art methods shows competitive results as regards the different actions performed by the system, such as the accuracy of classification and localization of gestures, or the generation of descriptions for objects and scenes.},
  archive      = {J_EAAI},
  author       = {Samer Alashhab and Antonio Javier Gallego and Miguel Ángel Lozano},
  doi          = {10.1016/j.engappai.2022.105188},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105188},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Efficient gesture recognition for the assistance of visually impaired people using multi-head neural networks},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An improvement in data interpretation to estimate residual
stresses and mechanical properties using instrumented indentation: A
comparison between machine learning and kriging model. <em>EAAI</em>,
<em>114</em>, 105186. (<a
href="https://doi.org/10.1016/j.engappai.2022.105186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The instrumented indentation method has been introduced as an effective means of estimating surface residual stresses. This technique has also been widely utilized to measure mechanical properties of the materials. Most studies in recent years have been conducted for the nano and micro-indentation. However, macro-indentation technique can result in interesting results in terms of residual stresses as well as mechanical properties. The instrumented indentation is a rapid and non-destructive method with acceptable precision which is desirable for a variety of different applications. This technique is applicable not only for large samples or those under service but also for small material volumes. In the author’s previous work, a portable indentation apparatus was examined for extracting the p–h curve. The fuzzy neural networks were then employed to determine the residual stresses as well as the plastic mechanical properties of materials. The current research uses different data interpretation methods to extract equi-biaxial residual stresses and mechanical properties. A comparative study between two methods, supervised machine learning and Kriging model, was conducted to estimate the unknown parameters. The performance accuracies of machine learning and Kriging were then compared. The results indicated that supervised machine learning using kNN algorithms can perform slightly better than the universal Kriging model. The findings were later compared with the experimental results for an aluminum plate.},
  archive      = {J_EAAI},
  author       = {S. Salmani Ghanbari and A.H. Mahmoudi},
  doi          = {10.1016/j.engappai.2022.105186},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105186},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An improvement in data interpretation to estimate residual stresses and mechanical properties using instrumented indentation: A comparison between machine learning and kriging model},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Review on the COVID-19 pandemic prevention and control
system based on AI. <em>EAAI</em>, <em>114</em>, 105184. (<a
href="https://doi.org/10.1016/j.engappai.2022.105184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a new technology, artificial intelligence (AI) has recently received increasing attention from researchers and has been successfully applied to many domains. Currently, the outbreak of the COVID-19 pandemic has not only put people’s lives in jeopardy but has also interrupted social activities and stifled economic growth. Artificial intelligence, as the most cutting-edge science field, is critical in the fight against the pandemic. To respond scientifically to major emergencies like COVID-19, this article reviews the use of artificial intelligence in the combat against the pandemic from COVID-19 large data, intelligent devices and systems, and intelligent robots. This article’s primary contributions are in two aspects: (1) we summarized the applications of AI in the pandemic, including virus spreading prediction, patient diagnosis, vaccine development, excluding potential virus carriers, telemedicine service, economic recovery, material distribution, disinfection, and health care. (2) We concluded the faced challenges during the AI-based pandemic prevention process, including multidimensional data, sub-intelligent algorithms, and unsystematic, and discussed corresponding solutions, such as 5G, cloud computing, and unsupervised learning algorithms. This article systematically surveyed the applications and challenges of AI technology during the pandemic, which is of great significance to promote the development of AI technology and can serve as a new reference for future emergencies.},
  archive      = {J_EAAI},
  author       = {Junfei Yi and Hui Zhang and Jianxu Mao and Yurong Chen and Hang Zhong and Yaonan Wang},
  doi          = {10.1016/j.engappai.2022.105184},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105184},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Review on the COVID-19 pandemic prevention and control system based on AI},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). UAV trajectory planning in cluttered environments based on
PF-RRT* algorithm with goal-biased strategy. <em>EAAI</em>,
<em>114</em>, 105182. (<a
href="https://doi.org/10.1016/j.engappai.2022.105182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent decades, Rapidly-exploring Random Tree star(RRT*) with asymptotic optimality has attracted much attention in path planning algorithm, but it suffers from slow convergence. Hence to solve the drawback, this paper proposes a novel Unmanned Aerial Vehicle(UAV) trajectory planning in cluttered environments based on PF-RRT* algorithm with goal-biased strategy. It creates a novel parent node for the new node near the obstacle by dichotomy method, instead of updating the parent node in the existing random tree nodes, which considerably decreases the path cost. The improved artificial potential field(APF) is proposed to guide the growth of the random tree towards the target point by adding random point attraction, target point attraction and obstacle repulsion, which not only addresses the local minimum problem, but also boosts the search rate of the random tree. The algorithm proposed in this paper combines with goal-biased strategy to obtain higher quality sampling points during the sampling process. Finally, the simulation verifies that the proposed algorithm is greatly optimized in terms of the number of iterations, convergence rate and path cost.},
  archive      = {J_EAAI},
  author       = {Jiaming Fan and Xia Chen and Yu Wang and Xiangmin Chen},
  doi          = {10.1016/j.engappai.2022.105182},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105182},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {UAV trajectory planning in cluttered environments based on PF-RRT* algorithm with goal-biased strategy},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). VAE4RSS: A VAE-based neural network approach for robust
soft sensor with application to zinc roasting process. <em>EAAI</em>,
<em>114</em>, 105180. (<a
href="https://doi.org/10.1016/j.engappai.2022.105180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft sensor plays a progressively significant role in modern industrial processes. However, process variables usually have complex distribution characteristics, which can adversely affect the performance of soft sensor. On the other hand, due to the inevitable presence of noise in industrial data, the effect of traditional prediction models based on point estimates are greatly reduced. To address these problems, this article proposes a variation autoencoder (VAE) based neural network for robust soft sensor (VAE4RSS) approach. Specifically, on the basis of reconstructing the process variables by the autoencoder (AE), Gaussian distribution constraints are added to the latent features, and the unfavorable effects of complex distribution characteristics on prediction can be overcome by converting the original data into constrained latent features. Then, in order to reduce the negative effect of outliers, the probability density function (PDF) is introduced to describe the training errors instead of the traditional point estimates, an error PDF optimization based neural network prediction model is established to improve the robustness of soft sensor. Finally, in order to evaluate the efficiency and superiority of the proposed method quantitatively, we conduct extensive experiments on a numerical simulation case and an industrial zinc roasting process case in comparison with several state-of-the-art methods. The experimental results demonstrate that the proposed method exhibits satisfactory prediction results and is robust to outliers.},
  archive      = {J_EAAI},
  author       = {Chengzhu Wang and Yonggang Li and Keke Huang and Chunhua Yang and Weihua Gui},
  doi          = {10.1016/j.engappai.2022.105180},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105180},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {VAE4RSS: A VAE-based neural network approach for robust soft sensor with application to zinc roasting process},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). IGCRRN: Improved graph convolution res-recurrent network for
spatio-temporal dependence capturing and traffic flow prediction.
<em>EAAI</em>, <em>114</em>, 105179. (<a
href="https://doi.org/10.1016/j.engappai.2022.105179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic flow prediction is critical for traffic management and route guidance, enabling urban traffic to be free-flowing conditions and maximizing transport efficiency. In current prediction methods, the simple and fixed spatial graph only uses the prior knowledge of the traffic network, resulting in weak prediction performance. This paper proposes an Improved Graph Convolution Res-Recurrent Network (IGCRRN), which relies on uncertain spatio-temporal information for traffic flow prediction. In particular, a spatial dependence matrix that combines the origin graph matrix and the data-generated embedding node matrix is created. In this way, the spatial connection relationship can be obtained from the static graph information and changing traffic flow series, making the improved graph convolution block infer and quantify the different contributions in both spatial dependence and temporal dependence in a data-driven manner. In addition, the residual structure is employed to model the multi-level spatial dependence, and the IGCRRN-cell units based on the residual connection block and LSTM are designed to make the model automatically capture the spatio-temporal dependence in the traffic flow sequence. Experiments are conducted on two real traffic datasets, and the experiment results show that our proposed spatial dependence matrix can investigate the valuable information and consider the heterogeneity in the traffic flow. The IGCRRN model outperforms the baseline and state-of-the-art methods in prediction performance.},
  archive      = {J_EAAI},
  author       = {Qingyong Zhang and Conghui Yin and Yuepeng Chen and Fuwen Su},
  doi          = {10.1016/j.engappai.2022.105179},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105179},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {IGCRRN: Improved graph convolution res-recurrent network for spatio-temporal dependence capturing and traffic flow prediction},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Physics-informed neural networks for non-newtonian fluid
thermo-mechanical problems: An application to rubber calendering
process. <em>EAAI</em>, <em>114</em>, 105176. (<a
href="https://doi.org/10.1016/j.engappai.2022.105176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-Informed Neural Networks (PINNs) have gained much attention in various fields of engineering thanks to their capability of incorporating physical laws into the models. However, the assessment of PINNs in industrial applications involving coupling between mechanical and thermal fields is still an active research topic. In this work, we present an application of PINNs to a non-Newtonian fluid thermo-mechanical problem which is often considered in the rubber calendering process. We demonstrate the effectiveness of PINNs when dealing with inverse and ill-posed problems, which are impractical to be solved by classical numerical discretization methods. We study the impact of the placement of the sensors and the distribution of unsupervised points on the performance of PINNs in a problem of inferring hidden physical fields from some partial data. We also investigate the capability of PINNs to identify unknown physical parameters from the measurements captured by sensors. The effect of noisy measurements is also considered throughout this work. The results of this paper demonstrate that in the problem of identification, PINNs can successfully estimate the unknown parameters using only the measurements on the sensors. In ill-posed problems where boundary conditions are not completely defined, even though the placement of the sensors and the distribution of unsupervised points have a great impact on PINNs performance, we show that the algorithm is able to infer the hidden physics from local measurements.},
  archive      = {J_EAAI},
  author       = {Thi Nguyen Khoa Nguyen and Thibault Dairay and Raphaël Meunier and Mathilde Mougeot},
  doi          = {10.1016/j.engappai.2022.105176},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105176},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physics-informed neural networks for non-newtonian fluid thermo-mechanical problems: An application to rubber calendering process},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Multi-view hypergraph neural networks for student academic
performance prediction. <em>EAAI</em>, <em>114</em>, 105174. (<a
href="https://doi.org/10.1016/j.engappai.2022.105174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Academic performance prediction is a fundamental and hot issue in educational data mining (EDM). Recently, researchers have proposed a series of effective machine learning (ML) based classification strategies to predict students’ academic performance. However, prior arts are typically concerned about individual models but neglect the association among students, which might considerably have an effect on the integrity of the academic performance-related representations. Meanwhile, students’ multi-viewing behavior contains complex relations among students. Therefore, we propose a Multi-View Hypergraph Neural Network (MVHGNN) for predicting students’ academic performance. MVHGNN uses hypergraphs to construct high-order relations among students. The semantic information implied by multiple behaviors is consolidated through meta-paths. Further, a Cascade Attention Transformer (CAT) module is introduced to mine the weight of different behaviors by the self-attention mechanism. Our method is evaluated on real campus student behavioral datasets. The experimental results demonstrate that our method outperforms the state-of-the-art ones.},
  archive      = {J_EAAI},
  author       = {Mengran Li and Yong Zhang and Xiaoyong Li and Lijia Cai and Baocai Yin},
  doi          = {10.1016/j.engappai.2022.105174},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105174},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-view hypergraph neural networks for student academic performance prediction},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel carbon price combination forecasting approach based
on multi-source information fusion and hybrid multi-scale decomposition.
<em>EAAI</em>, <em>114</em>, 105172. (<a
href="https://doi.org/10.1016/j.engappai.2022.105172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate carbon price forecasting is essential to reduce carbon dioxide emissions and slow down global warming. However, a key issue in the carbon trading market is the diversity and uncertainty of external factors. Some studies began to focus on the impact of a single external factor, but few of them considered the application of multi-source information on carbon prices. In addition, the selection of the decomposition method is still controversial, making carbon price forecasting inefficient and unstable. Therefore, this paper proposes a carbon price forecasting method based on multi-source information fusion (MSIF) and hybrid multi-scale decomposition (HMSD). First, MSIF can provide complete, interactive, and timely information for raw carbon prices, including historical data, influencing factors (coal prices, oil prices), and unstructured data (Baidu index, social media sentiment). Second, HMSD is used to completely extract the internal features of multi-source information and avoid the problem of decomposition method selection. Third, due to the linear and nonlinear characteristics of carbon prices, a combination strategy based on Holt, ARIMA, SVR, BPNN, and LSTM can achieve satisfactory results. Finally, to evaluate the effectiveness of the proposed framework, seven types of comparative experiments (based on historical data, influencing factors, Baidu index, and sentiment analysis) are carried out. The results show that MSIF is superior to single-source information in improving carbon price forecasting performance. Furthermore, the HMSD is stronger than the single multi-scale decomposition method in information extraction. Therefore, the proposed hybrid framework is a state-of-the-art carbon price forecasting approach.},
  archive      = {J_EAAI},
  author       = {Piao Wang and Jinpei Liu and Zhifu Tao and Huayou Chen},
  doi          = {10.1016/j.engappai.2022.105172},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105172},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel carbon price combination forecasting approach based on multi-source information fusion and hybrid multi-scale decomposition},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the feature extraction process in machine learning. An
experimental study about guided versus non-guided process in falling
detection systems. <em>EAAI</em>, <em>114</em>, 105170. (<a
href="https://doi.org/10.1016/j.engappai.2022.105170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Falls are current events that can lead to severe injuries and even accidental deaths among the population, especially the elderly. Since them usually live alone and their contact with other people has decreased since pandemic, recent years studies have focused on automatic fall detection systems with wearable devices using machine learning algorithms. Overall, and according to other works, these systems can be classified as non-guided, if the machine learning model directly uses raw data without feature extraction, or as guided systems, if a previous step of feature extraction is needed to reduce complexity of the algorithm. However, no recommendations are made in the literature on which system could be more advantageous for detecting fall events. Therefore, in this work, a detailed comparison between both types of systems is carried out, using the same process for different machine learning models in order to obtain an accurate classification of activities of daily living, falling risks, and falls. This process includes the optimization of models’ hyperparameters to obtain the best classifiers, followed by an assessment using common evaluation metrics, confusion matrices, ROC curves and execution times. Results show a better classification of models’ three classes for the non-guided models. However, the guided models show more stable metrics and lower computational load.},
  archive      = {J_EAAI},
  author       = {Elena Escobar-Linero and Francisco Luna-Perejón and Luis Muñoz-Saavedra and José Luis Sevillano and Manuel Domínguez-Morales},
  doi          = {10.1016/j.engappai.2022.105170},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105170},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {On the feature extraction process in machine learning. an experimental study about guided versus non-guided process in falling detection systems},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Long range multi-step water quality forecasting using
iterative ensembling. <em>EAAI</em>, <em>114</em>, 105166. (<a
href="https://doi.org/10.1016/j.engappai.2022.105166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-life water quality monitoring applications such as aquaculture domains and water resource management need long range multi-step prediction for disaster control. However, prediction accuracy usually degrades gradually as the prediction target timepoint is further away from the current timepoint. To address this, recent water quality forecasting methods mostly rely on complex deep learning models. In this paper, we propose a simple time-variant iterative ensembling method that strives to significantly improve the performance of a given arbitrary long range multi-step time series predictor for water quality data with minimal increase in computational cost. With the given predictor, our proposed method iteratively uses ensembles of predicted values for preceding steps to improve the prediction accuracy for the succeeding steps. The iterative ensembling operation is performed on the trained model and only at the inference stage, and so does not need any further computing-intensive training for the performance improvement. We experimentally show that the proposed method is effective with 7 predictors and 9 water quality datasets of various types, and it outperforms the state-of-the-art results in those datasets by around 2%–29% in mean absolute error (MAE), root mean squared error (RMSE) and mean absolute percentage error (MAPE) metrics. Similar improvement has also been found in two other metrics such as normalized Nash–Sutcliffe model efficiency coefficient (NNSE) metric and Taylor diagram plot. Overall, the proposed iterative ensembling is a promising approach for multi-step long range water quality prediction for high-frequency water quality monitoring systems.},
  archive      = {J_EAAI},
  author       = {Md Khaled Ben Islam and M.A. Hakim Newton and Julia Rahman and Jarrod Trevathan and Abdul Sattar},
  doi          = {10.1016/j.engappai.2022.105166},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105166},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Long range multi-step water quality forecasting using iterative ensembling},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pose estimation and robotic insertion tasks based on YOLO
and layout features. <em>EAAI</em>, <em>114</em>, 105164. (<a
href="https://doi.org/10.1016/j.engappai.2022.105164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we proposed a practical scheme for the challenging robotic cable insertion task. In general, the applied architecture is based on two YOLOs, vision-based pose estimation and admittance control. A precise and effective method was developed to estimate the pose of a manipulated connector. Our method uses a deep convolutional neural network to detect the relevant regions in the image. The characteristics of these relevant regions along with the pins’ layout manifold are combined to conduct the estimation. Practical problems such as error examination and time efficiency were considered in the proposed method for real applications. An admittance controller is introduced to experimentally validate the performance of pose estimation and provide compliant insertion by the proposed architecture. Our method is only based on less prior layout knowledge and does not require a precise model, which facilitates modeling and deployment. In addition, our method is robust to image quality and has low computational complexity, which makes it highly suitable for online manipulation. Besides, our method can handle multiple connector types which can cover most cases in aeronautical manufacturing and guide the design of connectors in the production process. The advantages of our method were demonstrated by extensive testing using both synthetic data and experiments. We also designed an insertion controller and realized a complete insertion task using a PC with a 12 GB RTX 3060 GPU and 32 GB RAM. These experimental results show that our method can achieve precise and reliable estimation with mean absolute errors less than 0.44 deg and 0.36 mm, an estimation accuracy of over 99%, and a successful manipulation rate of over 94%. This reveals that the proposed method displays potential for the challenging robotic cable insertion task.},
  archive      = {J_EAAI},
  author       = {Fangli Mou and Hao Ren and Bin Wang and Dan Wu},
  doi          = {10.1016/j.engappai.2022.105164},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105164},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Pose estimation and robotic insertion tasks based on YOLO and layout features},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unidirectional RGB-t salient object detection with
intertwined driving of encoding and fusion. <em>EAAI</em>, <em>114</em>,
105162. (<a
href="https://doi.org/10.1016/j.engappai.2022.105162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The U-shaped encoder–decoder architecture based on CNNs has been rooted in salient object detection (SOD) tasks, and it have revealed two drawbacks while driving the rapid development of saliency detection. (1) The inherent characteristics of CNNs dictate that it is difficult to learn long-range dependencies and model global correlations. (2) For the common purpose of improving the performance of saliency detection, the encoder and decoder should complement each other and work together. However, the existing encoder–decoder architecture treats encoder and decoder independently of each other. Specifically, the encoder is responsible for extracting features and the decoder fuses multi-level or multi-modal features to produce prediction maps. That is, the encoder alone needs to be responsible for the decoder, while the valuable information after the decoder fusion will not facilitate feature extraction. Therefore, we propose a unidirectional RGB-T salient object detection network with intertwined driving of encoding and fusion to solve the above problems. Firstly, we introduce transformer (SegFormer) as the backbone of the network to deal with the problem that CNNs are difficult to establish long-range dependence. Secondly, we constructed a unidirectional architecture where encoding and fusion are intertwined and mutually driving, which discards the drawbacks of encoder–decoder architecture to make the network more powerful and concise. Based on the unidirectional architecture, the proposed Local Detail-driven Fusion Module (LDFM) uses the fused features of the previous level to drive the cross-modal fusion at the current level. Meanwhile, the proposed Local Detail-driven Weighting Module (LDWM) uses the fused features to drive the cross-modal weighting. They will drive more effective features to be fed into the next level of the encoding block. Comprehensive experiments have verified the superior performance of our method on the RGB-T saliency detection task.},
  archive      = {J_EAAI},
  author       = {Jie Wang and Kechen Song and Yanqi Bao and Yunhui Yan and Yahong Han},
  doi          = {10.1016/j.engappai.2022.105162},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105162},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unidirectional RGB-T salient object detection with intertwined driving of encoding and fusion},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Quantized-communication-based neural network control for
formation tracking of networked multiple unmanned surface vehicles
without velocity information. <em>EAAI</em>, <em>114</em>, 105160. (<a
href="https://doi.org/10.1016/j.engappai.2022.105160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a quantized communication-based output-feedback control strategy for formation tracking of networked unmanned surface vehicles (USVs) with uncertainty. Under limited network communication, it is assumed that each USV measures only the position and orientation information. In particular, this information is quantized and transmitted to USVs connected to a band-limited directed network. The primary contributions of this study are to derive distributed learning laws for neural networks using discontinuous signals and to analyze the stability of the neural network-based output-feedback control system designed in a quantized communication environment. A neural network-based local observer is developed to estimate the velocity information of each USV with model uncertainty and external disturbance. Then, a neural network-based output-feedback control design strategy using distributed and quantized postures is presented to accomplish the desired formation of networked USVs with uncertainty and underactuation. The distributed learning laws of neural networks are derived using neighbors’ quantized signals. The auxiliary signal and approach angle are employed to solve the underactuation and stability analysis problems. Despite the discontinuity of quantized signals, it is proven that all errors in the closed-loop system are bounded and can be made arbitrarily small. Finally, simulation results are given to verify the theoretical results of the proposed control system.},
  archive      = {J_EAAI},
  author       = {Bong Seok Park and Sung Jin Yoo},
  doi          = {10.1016/j.engappai.2022.105160},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105160},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Quantized-communication-based neural network control for formation tracking of networked multiple unmanned surface vehicles without velocity information},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An interval-valued linguistic markov decision model with
fast convergency. <em>EAAI</em>, <em>114</em>, 105158. (<a
href="https://doi.org/10.1016/j.engappai.2022.105158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To rapidly generate stable solutions to the interval-valued linguistic decision-making problems, this paper proposes a novel interval-valued linguistic Markov decision model with fast convergency. A mapping framework is constructed to associate an interval-valued linguistic decision-making problem with a Markov chain. In consideration of two types of decision parameters including criterion weight and criterion reliability, two pairs of optimization problems are constructed under the framework to determine the optimized criterion weight interval and criterion reliability interval. A similarity measure between two rectangles formed by two pairs of optimized criterion weight and criterion reliability intervals is defined, and its relevant properties are theoretically proven. Based on the similarity measure, the transition probability of an alternative from one interval-valued linguistic term into another is constructed from the abstract combination of the developed similarity measure and an adaption parameter for fast convergency. The second largest eigenvalue modulus is then minimized to accelerate the generation of stable solutions, in which the corresponding adaption parameter is determined. The proposed decision model is used to help select suppliers of enterprise resource planning system for an enterprise that manufactures the key parts of high-speed trains, in which its applicability and validity are demonstrated. The necessity of the proposed decision model is further highlighted by comparative experiments.},
  archive      = {J_EAAI},
  author       = {Chao Fu and Xiaoyi Ding and Wenjun Chang},
  doi          = {10.1016/j.engappai.2022.105158},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105158},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An interval-valued linguistic markov decision model with fast convergency},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Survey on deep learning based computer vision for sonar
imagery. <em>EAAI</em>, <em>114</em>, 105157. (<a
href="https://doi.org/10.1016/j.engappai.2022.105157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on the automatic analysis of sonar images has focused on classical, i.e. non deep learning based, approaches for a long time. Over the past 15 years, however, the application of deep learning in this research field has constantly grown. This paper gives a broad overview of past and current research involving deep learning for feature extraction, classification, detection and segmentation of sidescan and synthetic aperture sonar imagery. Most research in this field has been directed towards the investigation of convolutional neural networks (CNN) for feature extraction and classification tasks, with the result that even small CNNs with up to four layers outperform conventional methods. The purpose of this work is twofold. On one hand, due to the quick development of deep learning it serves as an introduction for researchers, either just starting their work in this specific field or working on classical methods for the past years, and helps them to learn about the recent achievements. On the other hand, our main goal is to guide further research in this field by identifying main research gaps to bridge. We propose to leverage the research in this field by combining available data into an open source dataset as well as carrying out comparative studies on developed deep learning methods.},
  archive      = {J_EAAI},
  author       = {Yannik Steiniger and Dieter Kraus and Tobias Meisen},
  doi          = {10.1016/j.engappai.2022.105157},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105157},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Survey on deep learning based computer vision for sonar imagery},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PITS: An intelligent transportation system in pandemic
times. <em>EAAI</em>, <em>114</em>, 105154. (<a
href="https://doi.org/10.1016/j.engappai.2022.105154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The control of the pandemic caused by SARS-CoV-2 is a challenge for governments all around the globe. To manage this situation, countries have adopted a bundle of measures, including restrictions to population mobility. As a consequence, drivers face with the problem of obtaining fast routes to reach their destinations. In this context, some recent works combine Intelligent Transportation Systems (ITS) with big data processing technologies taking the traffic information into account. However, there are no proposals able to gather the COVID-19 health information, assist in the decision-making process, and compute fast routes in an all-in-one solution. In this paper, we propose a Pandemic Intelligent Transportation System (PITS) based on Complex Event Processing (CEP), Fuzzy Logic (FL) and Colored Petri Nets (CPN). CEP is used to process the COVID-19 health indicators and FL to provide recommendations about city areas that should not be crossed. CPNs are then used to create map models of health areas with the mobility restriction information and obtain fast routes for drivers to reach their destinations. The application of PITS to Madrid region (Spain) demonstrates that this system provides support for authorities in the decision-making process about mobility restrictions and obtain fast routes for drivers. PITS is a versatile proposal which can easily be adapted to other scenarios in order to tackle different emergency situations.},
  archive      = {J_EAAI},
  author       = {Enrique Brazález and Hermenegilda Macià and Gregorio Díaz and Valentín Valero and Juan Boubeta-Puig},
  doi          = {10.1016/j.engappai.2022.105154},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105154},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {PITS: An intelligent transportation system in pandemic times},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online robot guidance and navigation in non-stationary
environment with hybrid hierarchical reinforcement learning.
<em>EAAI</em>, <em>114</em>, 105152. (<a
href="https://doi.org/10.1016/j.engappai.2022.105152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical Reinforcement Learning (HRL) provides an option to solve complex guidance and navigation problems with high-dimensional spaces, multiple objectives, and a large number of states and actions. The current HRL methods often use the same or similar reinforcement learning methods within one application so that multiple objectives can be easily combined. Since there is not a single learning method that can benefit all targets, hybrid Hierarchical Reinforcement Learning (hHRL) was proposed to use various methods to optimize the learning with different types of information and objectives in one application. The previous hHRL method, however, requires manual task-specific designs, which involves engineers’ preferences and may impede its transfer learning ability. This paper, therefore, proposes a systematic online guidance and navigation method under the framework of hHRL, which generalizes training samples with a function approximator, decomposes the state space automatically, and thus does not require task-specific designs. The simulation results indicate that the proposed method is superior to the previous hHRL method, which requires manual decomposition, in terms of the convergence rate and the learnt policy. It is also shown that this method is generally applicable to non-stationary environments changing over episodes and over time without the loss of efficiency even with noisy state information.},
  archive      = {J_EAAI},
  author       = {Ye Zhou and Hann Woei Ho},
  doi          = {10.1016/j.engappai.2022.105152},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105152},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Online robot guidance and navigation in non-stationary environment with hybrid hierarchical reinforcement learning},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comprehensive comparison among metaheuristics (MHs) for
geohazard modeling using machine learning: Insights from a case study of
landslide displacement prediction. <em>EAAI</em>, <em>114</em>, 105150.
(<a href="https://doi.org/10.1016/j.engappai.2022.105150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning (ML) has been extensively applied to model geohazards, yielding tremendous success. However, researchers and practitioners still face challenges in enhancing the reliability of ML models. In the present study, a systematic framework combining k-fold cross-validation (CV), metaheuristics (MHs), support vector regression (SVR), and Friedman and Nemenyi tests was proposed to improve the reliability and performance of geohazard modeling. The average normalized mean square error (NMSE) from k-fold CV sets was adopted as the fitness metric. Twenty of the most well-established MHs and the most recent MHs were adopted to tune the hyperparameters of SVR and were evaluated through nonparametric Friedman and post hoc Nemenyi tests to identify significant differences. Observations from a typical reservoir landslide were selected as a benchmark dataset, and the accuracy, robustness, computational time, and convergence speed of the MHs were compared. Significant performance differences among the twenty MHs were identified by Friedman and post hoc Nemenyi tests of the mean absolute error (MAE), root mean squared error (RMSE), Kling–Gupta efficiency (KGE), and computational time, with p values lower than 0.05. The comparison of results demonstrated that the multiverse optimizer (MVO) is among the highest-performing, most stable, and computationally efficient algorithms, providing superior performance to other methods, with nearly optimum values of the correlation coefficient (R), a low MAE (23.5086 versus 23.9360), a low mean RMSE (48.6946 versus 50.1882), and a high mean KGE (0.9803 versus 0.9893) in predicting the displacement of the Shuping landslide. This paper considerably enriches the literature regarding hyperparameter optimization algorithms and the enhancement of their reliability. In addition, Friedman and post hoc Nemenyi tests have the potential for evaluating and comparing various ML-based geohazard models.},
  archive      = {J_EAAI},
  author       = {Junwei Ma and Ding Xia and Yankun Wang and Xiaoxu Niu and Sheng Jiang and Zhiyang Liu and Haixiang Guo},
  doi          = {10.1016/j.engappai.2022.105150},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105150},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A comprehensive comparison among metaheuristics (MHs) for geohazard modeling using machine learning: Insights from a case study of landslide displacement prediction},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Gas path fault diagnosis of aircraft engine using HELM and
transfer learning. <em>EAAI</em>, <em>114</em>, 105149. (<a
href="https://doi.org/10.1016/j.engappai.2022.105149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gas-path fault diagnosis of an aero-engine is a key challenge for flight safety. However, there are two problems: 1) Large collections of healthy condition samples and few fault samples; 2) The diagnosis accuracy cannot meet the practical demands. Therefore this paper proposes a new integrative diagnostic approach for gas-path fault of an aircraft engine to overcome the limitations. A novel model (HELM-TL) is presented to improve fault diagnosis performance, which ensembles the advantages of HELM and transfer learning by fusing target domain data and source domain data effectively. The attention mechanism is adopted to construct global dependency of gas-path monitoring data. Furthermore, this paper develops a novel algorithm for fault diagnosis which dynamically updates learning rate according to loss function. The proposed approach not only obtains more accurate fault distribution, but also avoids over-fitting problem, which greatly improves diagnosis performance and generalization. Finally, experimental data from China Eastern Airlines is adopted to validate. The experimental results show that proposed method has excellent robust according to sensitivity analysis. Moreover, it achieves a good tradeoff between diagnosis accuracy, transfer performance, and runtime cost. The proposed method also improves training accuracy by 5%–15%, reduces RMSE of fault diagnosis by 11%, and improves prediction accuracy by 12.1% compared with the average value of state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Junqiang Liu},
  doi          = {10.1016/j.engappai.2022.105149},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105149},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Gas path fault diagnosis of aircraft engine using HELM and transfer learning},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Engineering the neural automatic passenger counter.
<em>EAAI</em>, <em>114</em>, 105148. (<a
href="https://doi.org/10.1016/j.engappai.2022.105148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic passenger counting (APC) in public transportation has been approached with various machine learning and artificial intelligence methods since its introduction in the 1970s. It is mainly used for revenue sharing, which (in Germany alone) is in the billions annually and supply planning, which is essential for services of general interest. While equivalence testing is becoming more popular than difference detection (Student’s t-test), the former is much more difficult to pass to ensure low user risk. On the other hand, recent developments in artificial intelligence have led to algorithms that promise much higher counting quality (lower bias). However, gradient-based methods (including Deep Learning) typically run into local optima. In this work, we explore and exploit various aspects of machine learning to increase the reliability, performance, and counting quality of the Neural APC 3D depth video-based LSTM neural network. We perform a grid search with several fundamental parameters: the selection and size of the training set, which is similar to cross-validation, and the initial network weights and randomness during the training process. Using this experiment, we show how aggregation techniques such as ensemble quantiles can reduce bias, and we give an idea of the overall spread of the results. We utilize the test success chance, a simulative metric based on the empirical distribution. We also employ a post-training Monte Carlo quantization approach and introduce cumulative summation to turn counting into a stationary method and allow unbounded counts. All in all, our numerous additions provide a major quality increase to the NAPC.},
  archive      = {J_EAAI},
  author       = {Nico Jahn and Michael Siebert},
  doi          = {10.1016/j.engappai.2022.105148},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105148},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Engineering the neural automatic passenger counter},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Welding sequence optimization to reduce welding distortion
based on coupled artificial neural network and swarm intelligence
algorithm. <em>EAAI</em>, <em>114</em>, 105142. (<a
href="https://doi.org/10.1016/j.engappai.2022.105142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to develop a welding sequence optimization (WSO) framework based on coupled artificial neural network (ANN) and swarm intelligence algorithm for minimizing welding distortion of thin-walled squared Al–Mg–Si alloy tube components. This framework is mainly composed of two critical computer programs. Firstly, a multilayer feedforward backpropagation neural network (BPNN) system was established to rapidly estimate residual distortion for an arbitrary welding sequence so that welding sequence can be optimized for achieving desired welding quality. For this purpose, a series of nonlinear thermo-elastic–plastic finite element (FE) simulations were conducted and verified with experiments to generate the input database of the neural network. Subsequently, a reliable BPNN model was successfully created and trained within an acceptable error. Secondly, a novel swarm intelligence algorithm, namely, bees algorithm (BA) was proposed to solve the complicated WSO problems. In this optimization process, the trained BPNN model was implanted into this proposed BA for computing the fitness value of arbitrary welding sequences. Moreover, welding experiments were also performed to confirm the performance of the proposed optimization method. Comparing the results from experimental measurements, FE simulations, and proposed WSO framework, it is demonstrated that this proposed BPNN-and-BA-based WSO framework can be successfully applied in practical engineering to obtain an optimal welding sequence for minimizing final welding distortion.},
  archive      = {J_EAAI},
  author       = {Chunbiao Wu and Chao Wang and Jae-Woong Kim},
  doi          = {10.1016/j.engappai.2022.105142},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105142},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Welding sequence optimization to reduce welding distortion based on coupled artificial neural network and swarm intelligence algorithm},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A robust model selection framework for fault detection and
system health monitoring with limited failure examples: Heterogeneous
data fusion and formal sensitivity bounds. <em>EAAI</em>, <em>114</em>,
105140. (<a
href="https://doi.org/10.1016/j.engappai.2022.105140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault detection models play a fundamental role in monitoring the health state of engineering systems subject to degradation processes. Data-driven fault detection models, albeit very effective when trained on large databases of failures, fail to perform well under a lack of failure examples. Because reliable engineering systems seldom fail, data shortage is often inevitable. To overcomes failure data scarcity, this work proposes a new model selection framework for the robust selection of fault detection and system health monitoring models. We combine heterogeneous sources of information (time-to-failure and sensors data), a model of the system structure, and mathematical bounds on the sensitivity and specificity of components fault classifiers. We use Support Vector Machines (SVMs) to detect components faults and Scenario theory to derive formal sensitivity and specificity bounds. The component predictions are combined within a system structure-function for system health states estimation. A novel model selection strategy optimizes the hyper-parameters of the SVM ensemble by minimizing system-level prediction errors and generalization error bounds of the individual fault classifiers. One of the main advantages of the proposed framework is a set of formal epistemic bounds on fault detection and false alarm probabilities quantifying the lack of data uncertainty affecting the fault detection rate. We test the method on three representative case studies: (1) On randomized fault detection experiments with synthetic data, (2) on ten SVM models for predictive maintenance of industrial health care imaging systems, and (3) on a real-world PHM challenge problem. The results prove the efficacy of the proposed approach and its usefulness for solving fault detection.},
  archive      = {J_EAAI},
  author       = {Roberto Rocchetta and Qi Gao and Dimitrios Mavroeidis and Milan Petkovic},
  doi          = {10.1016/j.engappai.2022.105140},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105140},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A robust model selection framework for fault detection and system health monitoring with limited failure examples: Heterogeneous data fusion and formal sensitivity bounds},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parameter adaptation-based ant colony optimization with
dynamic hybrid mechanism. <em>EAAI</em>, <em>114</em>, 105139. (<a
href="https://doi.org/10.1016/j.engappai.2022.105139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a parameter adaptation-based ant colony optimization (ACO) algorithm based on particle swarm optimization (PSO) algorithm with the global optimization ability, fuzzy system with the fuzzy reasoning ability and 3-Opt algorithm with local search ability, namely PF3SACO is proposed to improve the optimization ability and convergence, avoid to fall into local optimum. In the PF3SACO, a new dynamic parameter adjustment mechanism by the PSO and the fuzzy system is designed to adaptively adjust the pheromone importance factor α , pheromone volatilization coefficient ρ and the heuristic function importance factor β to accelerate the convergence, improve the search ability, enhance the local search ability and avoid premature. This is achievable by parameter adaptation to reflect the dynamic search characteristic by exploring and exploiting in the search process for the parameter values to be close to the optimal values. In addition, 3-Opt algorithm is applied to optimize the generated path to eliminate the cross path, obtain the optimal path and avoid to fall into local optimum. The optimization performance of the PF3SACO is investigated on fifteen travelling salesman problems (TSPs) with the scales from 42 to 783 cities. The experiment results show that the PF3SACO has better optimization performance by comparing with ABC, NACO, HYBRID, ACO-3Opt, PACO-3Opt, PSO-ACO-3Opt and some other well-known algorithms in most TSP in term of the solution quality, robustness and space distribution. It provides a reference to solve the large-scale TSP for obtaining better path length.},
  archive      = {J_EAAI},
  author       = {Xiangbing Zhou and Hongjiang Ma and Jianggang Gu and Huiling Chen and Wu Deng},
  doi          = {10.1016/j.engappai.2022.105139},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105139},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Parameter adaptation-based ant colony optimization with dynamic hybrid mechanism},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Depth-first random forests with improved grassberger entropy
for small object detection. <em>EAAI</em>, <em>114</em>, 105138. (<a
href="https://doi.org/10.1016/j.engappai.2022.105138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a random forests-based method appropriate for detecting small objects such as Unmanned Aerial Vehicles (UAVs) and aircrafts when these objects occupy a small portion within an image filmed by an autonomously moving camera. Random forests classifiers are machine learning methods that manage an accurate prediction ability and are computationally efficient both during training and testing. In the random forests classifier model, the split node data is divided into left and right child node data based on the optimal split parameter determined by the node having the maximum information gain, which is calculated based on information entropy. It is well known that the information entropy estimation procedure is biased, and therefore we replace it with an improved Grassberger entropy scheme that achieves a better random forests classifier. Grassberger entropy is improved in terms of its representation and digamma function properties, and we adequately justify its validity. Although a breadth-first training scheme is a natural choice, it uses excessive memory when the tree grows to deeper layers. To compensate, a depth-first recursive training random forests classifier is used, where only one node is split in each recursive process. A depth-first recursive training random forests classifier uses a constant amount of memory to deal with underfitting. The performance of the proposed method is evaluated on classification and object detection datasets. The experimental results demonstrate that the improved Grassberger entropy estimation improves predictive performance, and the tree generated by the depth-first method suppresses underfitting. We believe that employing a depth-first random forests classifier with an improved Grassberger entropy is appealing and effective for real-world applications.},
  archive      = {J_EAAI},
  author       = {Juanjuan Ma and Quan Pan and Yaning Guo},
  doi          = {10.1016/j.engappai.2022.105138},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105138},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Depth-first random forests with improved grassberger entropy for small object detection},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Towards fusing fuzzy discriminative projection and
representation learning for image classification. <em>EAAI</em>,
<em>114</em>, 105137. (<a
href="https://doi.org/10.1016/j.engappai.2022.105137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fuzzy and indistinguishable data affected by complex and variable factors lead to the inferior recognition performance, which is hard to avoid in data acquisition. Subspace projection is widely used in extracting low-dimensional important features for image processing task. However, many existing methods rarely explore on the fuzziness and uncertainty of visual data, while lack sufficient mining of prior knowledge. In this work, we propose a novel fuzzy discriminative projection and representation learning (FDPR) method for image classification. Specifically, the fuzzy weight matrix with label information is designed in the data reconstruction to generate more specific sparse constraint on representation coefficients. In addition, low-rank and l 2 , 1 norm constraints are introduced to enhance the robustness of the algorithm. Finally, we combine a classification regression term with the representation coefficients carrying discriminative information for the subspace projection learning, thus fully utilizing data label information and eventually benefiting the subspace to be more distinguishable. The experimental results on several datasets show that our proposed model performs well with effectiveness and robustness surpassing other state-of-the-art approaches.},
  archive      = {J_EAAI},
  author       = {Yun Wang and Zhenbo Li and Fei Li and Pu Yang and Jun Yue},
  doi          = {10.1016/j.engappai.2022.105137},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105137},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Towards fusing fuzzy discriminative projection and representation learning for image classification},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A heterogeneous couplings and persuasive user/item
information model for next basket recommendation. <em>EAAI</em>,
<em>114</em>, 105132. (<a
href="https://doi.org/10.1016/j.engappai.2022.105132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Next Basket Recommender Systems (NBRS) are session-based recommenders that leverage a user’s sequential behaviour and context to predict the next items they could buy during the next shop visit. This field is popular now. Current research works rely primarily on item–user relations, ignoring complicated heterogeneous couplings and persuasive item/user information, causing sparsity and cold-start, stifling NBRS performance. This research implements a Heterogeneous Coupling and Persuasive User/Item Information Model (HCPIM) comprising of heterogeneous couplings and a persuasive embedding layer (HCPEL), the consecutive basket layer, and a basket prediction layer. The HCPEL learns heterogeneous couplings (user–user, user–item, item–item) and persuasive user information for every basket to model the composite intra-basket associations across the items inside a basket given a user’s behaviour sequences. The consecutive basket layer learns inter-basket associations from the HCPEL using a Gated Recurrent Unit network. In the basket prediction layer, an improved Particle Swarm Optimization (PSO) algorithm optimizes the network’s weight and bias to iteratively learn heterogeneous couplings and persuasive information inside and across baskets to recommend the next basket. In PSO, we incorporate the exploratory Gravitation Search Algorithm to balance exploration and exploitation. Our architecture includes an Adaptive Response to Particle Adjustment Strategy to increase exploitation and prevent particles from being trapped. Extensive tests are run to evaluate HCPIM on TaFeng and the IJCAI 2015 dataset. The HCPIM improves performance by 27.87, 29.5, and 27.29 percent when density is 50, 100, and 150 on the IJCAI-15 dataset, and 8.53, 10.57, and 4.85 percent on the TaFeng dataset.},
  archive      = {J_EAAI},
  author       = {John Kingsley Arthur and Conghua Zhou and Jeremiah Osei-Kwakye and Eric Appiah Mantey and Yaru Chen},
  doi          = {10.1016/j.engappai.2022.105132},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105132},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A heterogeneous couplings and persuasive user/item information model for next basket recommendation},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Crack segmentation network using additive attention
gate—CSN-II. <em>EAAI</em>, <em>114</em>, 105130. (<a
href="https://doi.org/10.1016/j.engappai.2022.105130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the emerging and powerful tools of Artificial Intelligence (AI) in computer vision is Convolutional Neural Network (CNN) which can outperform traditional algorithms for crack detection by extracting unique image features. The segmentation of crack images is intensively affected by the imbalanced presence of crack and non-crack elements. Tackling the influence of class imbalanced datasets on the training network, we proposed an additive attention gate-based network architecture called Crack Segmentation Network-II (CSN-II). CSN-II has fewer encoder–decoder blocks with improved accuracy and reduced computational cost as compared to other crack segmentation network architectures. An additive attention gate is used as a connecting block between the encoder–decoder section of CSN-II that focuses on significant crack regions in the image. The network performance is evaluated on two different crack image datasets i.e., MSCI (500 images) and CFD (118 images). The experimental results showed that the CSN-II architecture using a local balanced cross-entropy (LBCE) loss function has achieved 98.48 % and 94.39 % mean accuracy for MSCI and CFD dataset, respectively. Furthermore, extensive research experiments are performed on MSCI and CFD datasets to delineate the best combination of five network architectures (U-Net, SegNet, DeepLabv3＋, CSN, and CSN-II) and twelve loss functions for crack segmentation to observe the efficiency for tackling imbalanced dataset.},
  archive      = {J_EAAI},
  author       = {Raza Ali and Joon Huang Chuah and Mohamad Sofian Abu Talip and Norrima Mokhtar and Muhammad Ali Shoaib},
  doi          = {10.1016/j.engappai.2022.105130},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105130},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Crack segmentation network using additive attention Gate—CSN-II},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Direct estimation of prediction intervals for solar and wind
regional energy forecasting with deep neural networks. <em>EAAI</em>,
<em>114</em>, 105128. (<a
href="https://doi.org/10.1016/j.engappai.2022.105128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNN) are becoming increasingly relevant for probabilistic forecasting because of their ability to estimate prediction intervals (PIs). Two different ways for estimating PIs with neural networks stand out: quantile estimation for posterior PI construction and direct PI estimation. The former first estimates quantiles, which are then used to construct PIs, while the latter directly obtains the lower and upper PI bounds by optimizing some loss functions, with the advantage that PI width is directly considered in the optimization process and thus may result in narrower intervals. In this work, two different DNN-based models are studied for direct PI estimation, and compared with DNN for quantile estimation in the context of solar and wind regional energy forecasting. The first approach is based on the recent quality-driven loss and is formulated to estimate multiple PIs with a single model. The second is a novel approach that employs hypernetworks (HN), where direct PI estimation is formulated as a multi-objective problem, returning a Pareto front of solutions that contains all possible coverage-width optimal trade-offs. This formulation allows HN to obtain optimal PIs for all possible coverages without increasing the number of network outputs or adjusting additional hyperparameters, as opposed to the first direct model. Results show that prediction intervals from direct estimation are narrower (up to 20%) than those of quantile estimation, for target coverages 70%–80% for all regions, and also 85%, 90%, and 95% depending on the region, while HN always achieves the required coverage for the higher target coverages.},
  archive      = {J_EAAI},
  author       = {Antonio Alcántara and Inés M. Galván and Ricardo Aler},
  doi          = {10.1016/j.engappai.2022.105128},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105128},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Direct estimation of prediction intervals for solar and wind regional energy forecasting with deep neural networks},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Zonotopic observer designs for uncertain takagi–sugeno fuzzy
systems. <em>EAAI</em>, <em>114</em>, 105126. (<a
href="https://doi.org/10.1016/j.engappai.2022.105126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the zonotopic observer design for nonlinear systems affected by uncertainties, i.e., state disturbances and measurement noises using Takagi–Sugeno (TS) fuzzy technique. The system uncertainties are considered as unknown but bounded, which are handled via a set-membership framework. For state estimation purposes, we develop an algorithm to recursively compute the zonotope containing the mismatching nonlinear term caused by unmeasured nonlinearities. Then, two methods are proposed to design the zonotopic observer gains. The first method is based on the minimization of the F − radius of zonotopes, for which the membership-function-dependent observer gain must be completely computed online. For the second method, an ℋ ∞ approach is used together with a nonquadratic Lyapunov function to determine the observer gain. Then, the zonotopic observer design is reformulated a convex optimization problem under linear matrix inequalities (LMIs), which can be effectively solved with numerical solvers. An autonomous vehicle application is provided to demonstrate and analyze the effectiveness of both proposed methods.},
  archive      = {J_EAAI},
  author       = {Masoud Pourasghar and Anh-Tu Nguyen and Thierry-Marie Guerra},
  doi          = {10.1016/j.engappai.2022.105126},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105126},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Zonotopic observer designs for uncertain Takagi–Sugeno fuzzy systems},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-model ensemble prediction of pan evaporation based on
the copula bayesian model averaging approach. <em>EAAI</em>,
<em>114</em>, 105124. (<a
href="https://doi.org/10.1016/j.engappai.2022.105124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pan evaporation ( E p ) is an efficient and practical tool for planning and managing water resources, understanding the water balance in hydrological processes, and developing irrigation systems, particularly in regions with limited water resources. Accurate prediction of E p using easy-to-measure meteorological variables is beneficial for any region. The current study aimed to explore the applicability of Copula-based Bayesian Model Averaging (CBMA) for improving probabilistic E p predictions in different climates of Iran. To this end, the parameters of the Adaptive Neuro-Fuzzy Interface System (ANFIS) were optimized using four meta-heuristic algorithms of Seagull Optimization Algorithm (SOA), Crow search Algorithm (CA), Firefly Algorithm (FFA), and Particle Swarm Optimization (PSO) for finding global solutions. The ANFIS-SOA, ANFIS-CA, ANFIS-FFA, ANFIS-PSO, and ANFIS models were implemented as inputs for employing ensemble CBMA and Bayesian Model Averaging (BMA) methods. Daily meteorological variables of average air temperature ( T a ), sunshine hours (SH), relative humidity (RH), wind speed (WS), and E p from six stations from 2000 to 2003 were applied. Evaluation of five Posterior Distribution Functions (PDFs) and three copula functions showed that Gumbel marginal distribution and Gumbel–Hougaard copula function provide the smallest Kolmogorov–Smirnov statistic indicator at the 5% significance level for all predictive models. The results established that the ensemble CBMA approach exhibited the highest prediction accuracy in all climates, followed by the BMA model, superior to the other individual models. The average root mean square error (RMSE) of the ensemble CBMA model was lower than BMA, ANFIS-SOA, ANFIS-CA, ANFIS-PSO, ANFIS-FFA, ANFIS, by 20.35%, 43.19%, 51.28%, 56.74%, 61.15%, and 64.36%, respectively. Furthermore, the uncertainty analysis indicated the E p predictions were more confident after applying CBMA. In conclusion, we highly recommend applying the ensemble CBMA model to improve E p ’s prediction performance by standalone and hybrid machine learning models. The combination of T a -SH was suggested to be used for robust predicting daily E p in the regions of hot desert, cold desert, and cold semi-arid and T a -RH in the humid subtropical area regarding the convenience of data acquisition.},
  archive      = {J_EAAI},
  author       = {Akram Seifi and Mohammad Ehteram and Fatemeh Soroush and Ali Torabi Haghighi},
  doi          = {10.1016/j.engappai.2022.105124},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105124},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-model ensemble prediction of pan evaporation based on the copula bayesian model averaging approach},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ML-based reconfigurable symbol decoder: An alternative for
next-generation communication systems. <em>EAAI</em>, <em>114</em>,
105123. (<a
href="https://doi.org/10.1016/j.engappai.2022.105123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern Machine Learning (ML) techniques offer numerous opportunities to enable intelligent communication designs while addressing a wide range of problems in communication systems. A wide majority of communication systems ubiquitously employ the Maximum Likelihood (MLH) decoder in the symbol decoding process with QPSK modulation, thereby providing a non-reconfigurable solution. This work addresses the application of an ML-based reconfigurable solution for such systems. The proposed decoder can be considered a strong candidate for future communication systems, owing to its upgradable functionality, lower complexity, faster response, and reconfigurability. First, a novel low-complexity dataset for model training/testing is generated, that uses only the received symbols. Subsequently, three predictors are extracted from each of the received noisy symbols for model training/testing. The model is then trained/tested using nineteen standard ML-based classifiers, and the computations of various performance metrics indicate the suitability of Naïve Bayes (NB), and Ensemble Bagged Decision Tree (EBDT) classifiers for the model. The simulation results show that the model respectively delivers significant decoding accuracies and error rates of about 93% and 7% during testing, even for a low SNR of 5 dB. Moreover, the statistical analysis of simulation results shows the marginal superiority of the Gaussian Naïve Bayes (GNB) classifier. Further, the model reconfiguration is validated using a BPSK modulated dataset. Finally, a user-separation scheme that eliminates Successive Interference Cancellation (SIC) in the next-generation Power-Domain (PD) Non-Orthogonal Multiple Access (NOMA) networks is suggested by employing the proposed decoder.},
  archive      = {J_EAAI},
  author       = {Saurabh Srivastava and Prajna Parimita Dash},
  doi          = {10.1016/j.engappai.2022.105123},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105123},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ML-based reconfigurable symbol decoder: An alternative for next-generation communication systems},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Image- and health indicator-based transfer learning
hybridization for battery RUL prediction. <em>EAAI</em>, <em>114</em>,
105120. (<a
href="https://doi.org/10.1016/j.engappai.2022.105120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the recent influx of electric vehicles and other electrical consumer products, the market has created a large demand for lithium-ion batteries, however, the non-linearity of their internal aging mechanisms still makes them difficult to predict. This study proposes a novel hybridized machine learning model that aims to be accessible to all researchers working in the field of battery prognostics prediction. To make it accessible to all, this study prides itself on using pre-trained and publicly available neural networks. To make full use of these available transferable networks, the traditional battery prognostics prediction methodology of using health indicators is hybridized with the use of images of the raw data curves. Also, this study tests the accuracy performance of the models by using images by themselves without the traditional health indicators to provide a proof of concept that these can be used independently as well An improvement of 6.72% in the remaining-useful-life (RUL) prediction accuracy was observed by simply adding image-based inputs, without the need for additional extensive pre-processing to an already existing health indicator-based model for the prediction of batteries’ RUL, highlighting the benefits of image-based inputs for use in regression tasks.},
  archive      = {J_EAAI},
  author       = {Jonathan Couture and Xianke Lin},
  doi          = {10.1016/j.engappai.2022.105120},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105120},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Image- and health indicator-based transfer learning hybridization for battery RUL prediction},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimation of tool–chip contact length using optimized
machine learning in orthogonal cutting. <em>EAAI</em>, <em>114</em>,
105118. (<a
href="https://doi.org/10.1016/j.engappai.2022.105118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tool–chip contact length has a significant effect on the various characteristics of metal cutting, including cutting pressures, chip formation, tool wear, tool life, and cutting temperatures. It should be added that there is a direct relationship between the tool–chip contact length and secondary shear zone thickness in the metal cutting process. The cutting force and shear zone temperature decrease by the reduction of tool–chip contact length. In addition, the tool–chip contact length affects the tool life and workpiece surface roughness. Lots of researchers have conducted extensive research to calculate the tool–chip contact length using mathematical or machine learning methods. The main objective of this study is to calculate the tool–chip contact length using a highly advanced machine learning method without any time-consuming and expensive experiments. However, an adaptive network-based fuzzy inference system (ANFIS) is not used yet in the prediction of the tool–chip contact length. In this study, we proposed the ANFIS to predict the tool–chip contact length for the first time in orthogonal cutting using depth of cut, feed-rate, and cutting speed as inputs of the proposed model. As the second contribution of this study, three evolutionary-based optimization techniques, including genetic algorithm, particle swarm optimization, and grey wolf optimization, as well as global-based Bayesian optimization, are employed to select the optimal hyperparameters of the proposed ANFIS model known as GA-ANFIS, PSO-ANFIS, GWO-ANFIS, and B-ANFIS, respectively. The proposed methods are designed and developed in MATLAB software to be compared with the previous method using genetic programming (GP). The outcomes of this research demonstrate that the GWO-ANFIS can decrease the mean square error between the actual and predicted tool–chip contact length of 15.60%, 3.67%, 89.75%, and 92.17% in comparison with those of GA-ANFIS, PSO-ANFIS, B-ANFIS, and GP, respectively. In addition, the fuzzy logic rule surface of the GWO-ANFIS shows 57.20%, 30.95%, and 11.85% dependency of tool–chip contact length to cutting speed, feed-rate, and depth of cut as the inputs of the orthogonal cutting process, respectively.},
  archive      = {J_EAAI},
  author       = {Mohammad Reza Chalak Qazani and Vahid Pourmostaghimi and Mehdi Moayyedian and Siamak Pedrammehr},
  doi          = {10.1016/j.engappai.2022.105118},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105118},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Estimation of tool–chip contact length using optimized machine learning in orthogonal cutting},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cyber-security and reinforcement learning — a brief survey.
<em>EAAI</em>, <em>114</em>, 105116. (<a
href="https://doi.org/10.1016/j.engappai.2022.105116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a comprehensive literature review on Reinforcement Learning (RL) techniques used in Intrusion Detection Systems (IDS), Intrusion Prevention Systems (IPS), Internet of Things (IoT) and Identity and Access Management (IAM). This study reviews scientific documents such as journals and articles, from 2010 to 2021, extracted from the Science Direct, ACM, IEEEXplore, and Springer database. Most of the research articles published in 2020 and 2021, for cybersecurity and RL are for IDS classifiers and resource optimization in IoTs. Some datasets used for training RL-based IDS algorithms are NSL-KDD, CICIDS, and AWID. There are few datasets and publications for IAM. The few that exist focus on the physical layer authentication. The current state of the art lacks standard evaluation criteria, however, we have identified parameters like detection rate, precision, and accuracy which can be used to compare the algorithms employing RL. This paper is suitable for new researchers, students, and beginners in the field of RL who want to learn about the field and identify problem areas.},
  archive      = {J_EAAI},
  author       = {Amrin Maria Khan Adawadkar and Nilima Kulkarni},
  doi          = {10.1016/j.engappai.2022.105116},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105116},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cyber-security and reinforcement learning — a brief survey},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An integrated decision model for cloud vendor selection
using probabilistic linguistic information and unknown weights.
<em>EAAI</em>, <em>114</em>, 105114. (<a
href="https://doi.org/10.1016/j.engappai.2022.105114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because of the high competition among IT sectors, companies are planning to migrate to the cloud for effective growth and development. Driven by the importance of the cloud, new cloud vendors emerge each day to satisfy the demand of IT sectors. As a result, selection of an apt cloud vendor is critical. To this end, researchers have proposed different decision models, but these models do not effectively capture uncertainty during the decision-making process. To handle this issue, probabilistic linguistic information (PLI) is adopted in this paper, which associates occurrence probability to each term. Furthermore, weights of criteria are systematically determined using a deviation method, and cloud vendors are prioritized using a mathematical model under the PLI context. These methods are integrated to form the decision model, validated for its applicability using real case data from Cloud Armor. Finally, the advantages and weaknesses of the model are analyzed by using sensitivity analysis and comparison with extant models.},
  archive      = {J_EAAI},
  author       = {R. Krishankumar and S. Supraja Nimmagadda and Arunodaya R. Mishra and Dragan Pamucar and K.S. Ravichandran and Amir H. Gandomi},
  doi          = {10.1016/j.engappai.2022.105114},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105114},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An integrated decision model for cloud vendor selection using probabilistic linguistic information and unknown weights},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Solving the energy-efficient robotic mixed-model assembly
line balancing problem using a memory-based cuckoo search algorithm.
<em>EAAI</em>, <em>114</em>, 105112. (<a
href="https://doi.org/10.1016/j.engappai.2022.105112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minimizing energy consumption is an important issue in robotic assembly lines where a set of robots are assigned to a set of workstations to perform different tasks. When it is planned to assemble several models of one product in the same robotic assembly line, the minimization of energy consumption becomes more difficult since the best assignment of tasks and robots to workstations must be found, taking into consideration all models. The authors cannot find in the literature a work that aims to minimize energy consumption in robotic assembly lines that produce several models with one configuration. Furthermore, the introduction of the heterogeneity of models and robots makes the problem more complex and hard, even for small-scale instances, and for this reason, the authors propose in this paper a Memory-Based Cuckoo Search Algorithm (MBCSA) to tackle this problem. The principle of memory is used in this new Cuckoo Search Algorithm in order to escape from the local optima and discover new search zones. Six problems of different sizes are generated and solved by the proposed MBCSA, and to evaluate its performance, two comparisons are made with two meta-heuristics, the genetic algorithm and another version of the cuckoo search algorithm. Obtained results show that this new version of the Cuckoo search algorithm is promising and can obtain good solutions for problems of different sizes.},
  archive      = {J_EAAI},
  author       = {Lakhdar Belkharroubi and Khadidja Yahyaoui},
  doi          = {10.1016/j.engappai.2022.105112},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105112},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Solving the energy-efficient robotic mixed-model assembly line balancing problem using a memory-based cuckoo search algorithm},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interval type-3 fuzzy aggregators for ensembles of neural
networks in COVID-19 time series prediction. <em>EAAI</em>,
<em>114</em>, 105110. (<a
href="https://doi.org/10.1016/j.engappai.2022.105110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we are presenting an approach for fuzzy aggregation in ensembles of neural networks for forecasting. The aggregator is used in an ensemble to combine the outputs of the networks forming the ensemble. This is done in such a way that the total output of the ensemble is better than the outputs of the individual modules. In our approach a fuzzy system is used to estimate the weights that will be assigned to the outputs in the process of combining them in a weighted average calculation. The uncertainty in the process of aggregation is modeled with interval type-3 fuzzy, which in theory can outperform type-2 and type-1. Publicly available data sets of COVID-19 cases for several countries in the world were utilized to test the proposed approach. Simulation results of the COVID-19 data show the potential of the approach to outperform other aggregators in the literature.},
  archive      = {J_EAAI},
  author       = {Oscar Castillo and Juan R. Castro and Martha Pulido and Patricia Melin},
  doi          = {10.1016/j.engappai.2022.105110},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105110},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Interval type-3 fuzzy aggregators for ensembles of neural networks in COVID-19 time series prediction},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MRRNet: Learning multiple region representation for video
person re-identification. <em>EAAI</em>, <em>114</em>, 105108. (<a
href="https://doi.org/10.1016/j.engappai.2022.105108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video person re-identification is a crucial component of a robust surveillance system. Within a video clip, different human regions exhibit unique stability characteristics, which would be harmful to generating a discriminative representation. Unfortunately, prior works cannot effectively deal with the stability characteristics of different regions. To tackle this problem, we propose a Multiple Region Representation Network (MRRNet) that aims to discover the discriminative information from different human regions. Firstly, a Stable Region Representation (SRR) layer is proposed to capture important clues from the stable regions and exchange temporal information by cross-relation aware operation. Secondly, a Multiple Region Representation (MRR) layer is designed to address the unstable regions and preserve the attention on stable regions. Thirdly, SRR and MRR can be conveniently inserted into multiple stages of the deep residual networks and significantly improve the performance of the network. Comprehensive experiments validate the effectiveness of our network. Particularly, MRRNet achieves 86.7% mAP and 91.1% Rank-1 accuracy on the MARS dataset, which outperforms state-of-the-arts.},
  archive      = {J_EAAI},
  author       = {Hui Fu and Ke Zhang and Haoyu Li and Jingyu Wang},
  doi          = {10.1016/j.engappai.2022.105108},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105108},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MRRNet: Learning multiple region representation for video person re-identification},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stochastic optimal well control in subsurface reservoirs
using reinforcement learning. <em>EAAI</em>, <em>114</em>, 105106. (<a
href="https://doi.org/10.1016/j.engappai.2022.105106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a case study of model-free reinforcement learning (RL) framework to solve stochastic optimal control for a predefined parameter uncertainty distribution and partially observable system. We focus on robust optimal well control problem which is a subject of intensive research activities in the field of subsurface reservoir management. For this problem, the system is partially observed since the data is only available at well locations. Furthermore, the model parameters are highly uncertain due to sparsity of available field data. In principle, RL algorithms are capable of learning optimal action policies – a map from states to actions – to maximize a numerical reward signal. In deep RL, this mapping from state to action is parameterized using a deep neural network. In the RL formulation of the robust optimal well control problem, the states are represented by saturation and pressure values at well locations while the actions represent the valve openings controlling the flow through wells. The numerical reward refers to the total sweep efficiency and the uncertain model parameter is the subsurface permeability field. The model parameter uncertainties are handled by introducing a domain randomization scheme that exploits cluster analysis on its uncertainty distribution. We present numerical results using two state-of-the-art RL algorithms, proximal policy optimization (PPO) and advantage actor–critic (A2C), on two subsurface flow test cases representing two distinct uncertainty distributions of permeability field. The results were benchmarked against optimization results obtained using differential evolution algorithm. Furthermore, we demonstrate the robustness of the proposed use of RL by evaluating the learned control policy on unseen samples drawn from the parameter uncertainty distribution that were not used during the training process.},
  archive      = {J_EAAI},
  author       = {Atish Dixit and Ahmed H. ElSheikh},
  doi          = {10.1016/j.engappai.2022.105106},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105106},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Stochastic optimal well control in subsurface reservoirs using reinforcement learning},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimization and implementation of a photovoltaic pumping
system using the sine–cosine​ algorithm. <em>EAAI</em>, <em>114</em>,
105104. (<a
href="https://doi.org/10.1016/j.engappai.2022.105104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, a particular and considerable attention has been paid to photovoltaic pumping systems in reasoning their operation based on renewable and clean energy. In this sense, we suggest an optimum photovoltaic pumping system based on the monitoring of the maximum power point by the sine cosine optimization algorithm in the meteorological conditions of the village of Ain Beda which is located in the region of Fez–Meknes, Morocco. The objective of the proposed system is to ensure operation at maximum power during the pumping process by directly and intelligently controlling the photovoltaic pumping system by the sine–cosine algorithm under various climatic conditions in this region. A comparative study at the statistical and qualitative levels was carried out on the one hand between the proposed method and two other conventional algorithms such as perturb and observe and fuzzy logic control and on the other hand with other metaheuristic algorithms. The simulation results show the efficiency of the proposed photovoltaic pumping system in terms of fast-tracking time, accelerated convergence speed, very low initial oscillation, very low steady-state oscillations around the maximum power point, the dynamic performance of the flow which reaches 31.15 m 3 /h, and efficiency of the photovoltaic pumping system which reaches 84.88% in different weather conditions. Moreover, the suggested system is validated following the V-cycle validation and verification process by integrating the generated embedded software on a “Raspberry Pi 2 Model B” embedded board.},
  archive      = {J_EAAI},
  author       = {Hicham Karmouni and Mohamed Chouiekh and Saad Motahhir and Hassan Qjidaa and Mohamed Ouazzani Jamil and Mhamed Sayyouri},
  doi          = {10.1016/j.engappai.2022.105104},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105104},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimization and implementation of a photovoltaic pumping system using the sine–cosine​ algorithm},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Atrous residual interconnected encoder to attention decoder
framework for vertebrae segmentation via 3D volumetric CT images.
<em>EAAI</em>, <em>114</em>, 105102. (<a
href="https://doi.org/10.1016/j.engappai.2022.105102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic vertebrae segmentation utilizing Computer Tomography (CT) plays a vital role in automated spine analyses, including the detection of vertebral body fractures and spine deformities assessment. A significant advancement in deep learning (DL) has enabled deep convolutional neural networks (DCNNs) to achieve precise performance in automated vertebrae segmentation. Despite the advantages of semantic segmentation algorithms based on DCNNs, they face limitations such as multi-scale objects, feature loss between the encoder and decoder, lack of medical image data, and limited filter field of view. A novel algorithm is presented that enables automated segmentation of vertebral bodies using volumetric CT images of the spine. The proposed model incorporates an encoder and decoder framework, and utilizes Layer Normalization to enhance the mini-batch training performance. The issue of feature loss between encoder and decoder is addressed by developing an Atrous Residual Path that carries more information from the encoder to the decoder instead of using an easy shortcut. As part of the proposed approach, a 3D Attention Module is designed to extract features from various scales in the decoding stage and further enhance the performance of the decoder. Multiple metrics are used to evaluate the proposed model on a public vertebrae dataset. According to the experimental results, our proposed approach provides competitive performance in comparison with state-of-the-art methods for automatic vertebrae semantic segmentation.},
  archive      = {J_EAAI},
  author       = {Wenqiang Li and Yuk Ming Tang and Ziyang Wang and Kai Ming Yu and Suet To},
  doi          = {10.1016/j.engappai.2022.105102},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105102},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Atrous residual interconnected encoder to attention decoder framework for vertebrae segmentation via 3D volumetric CT images},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Coupled extreme learning machine and particle swarm
optimization variant for projectile aerodynamic identification.
<em>EAAI</em>, <em>114</em>, 105100. (<a
href="https://doi.org/10.1016/j.engappai.2022.105100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate aerodynamic parameters are the basis for the research of uncontrolled projectile drop point dispersion and precise strike. The traditional methods for aerodynamic parameters rely strongly on the projectile dynamics system. To weaken the influence of kinetic effects, an extreme learning machine (ELM) optimized by particle swarm optimization (PSO) is applied. However, the iterative optimization process of PSO makes the algorithm more complicated and impairs the real-time performance of ELM. To accelerate the convergence of PSO, a new hybrid optimization strategy is proposed. The hybrid optimization strategy combines the advantages of the chaos optimization strategy, the adaptive update strategy, and the mutation strategy. The chaos optimization strategy optimizes the distribution of the initial swarm to improve the optimization efficiency of PSO. The adaptive update strategy tunes the velocity inertia weight based on the value of the evolutionary factor to match the current searching state of the particles. The mutation strategy mutates the particles to break out of the local convergence. Numerical experiments show that the introduction of the hybrid optimization strategy enables ELM to exhibit excellent robustness, real-time performance, and accuracy in noisy environments. The hybrid algorithm has excellent prospects for application and extension for the parameter identification of dynamic systems in complex environments.},
  archive      = {J_EAAI},
  author       = {Youran Xia and Wenjun Yi and Dingye Zhang},
  doi          = {10.1016/j.engappai.2022.105100},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105100},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Coupled extreme learning machine and particle swarm optimization variant for projectile aerodynamic identification},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parkinson’s disease diagnosis and stage prediction based on
gait signal analysis using EMD and CNN–LSTM network. <em>EAAI</em>,
<em>114</em>, 105099. (<a
href="https://doi.org/10.1016/j.engappai.2022.105099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson’s disease (PD) diagnosis is a complex and challenging task which needs the assessment of various motor and non-motor symptoms. As gait impairment is one of the early and important symptoms of PD, in a clinical setting, physicians generally evaluate the gait abnormality based on visual observations along with other numerous manifestations to assess the severity of PD. As such kind of assessment majorly depends on the experience and expertise of the physicians, there is scope for bias in assessment, leading to misdiagnosis. In this context, to assist the physicians to diagnose PD effectively, this study aims to design and investigate a gait analysis based classifier model using a hybrid convolutional neural network-long short term memory (CNN–LSTM) network to predict the severity rating of PD. For evaluation, we utilize the openly available gait dataset from Physionet that consists of vertical ground reaction force (VGRF) signals from three different walking tests. Firstly, the prominent VGRF signals obtained using the variability analysis are decomposed using the empirical mode decomposition (EMD) technique to extract the significant intrinsic mode functions (IMFs) that contain the vital gait features. Secondly, through the power spectral analysis the dominant IMFs of the selected VGRF signals are extracted to train the CNN–LSTM classifier model. To address the data overfitting problem in the classifier model, the proposed approach employs L2 regularization along with dropout techniques. Moreover, to solve the stochastic cost function, CNN–LSTM network utilizes the Adam optimizer for its minimal memory requirement and tuning. Finally, the experiments conducted using the gait patterns from 93 PD subjects and 73 healthy controls substantiate that the proposed CNN–LSTM​ classifier model can achieve a maximum multi-class classification accuracy of 98.32% and offer superior performance compared to several other similar methods which have used gait pattern to diagnose PD.},
  archive      = {J_EAAI},
  author       = {B. Vidya and Sasikumar P.},
  doi          = {10.1016/j.engappai.2022.105099},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105099},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Parkinson’s disease diagnosis and stage prediction based on gait signal analysis using EMD and CNN–LSTM network},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Visual sensor network stimulation model identification via
gaussian mixture model and deep embedded features. <em>EAAI</em>,
<em>114</em>, 105096. (<a
href="https://doi.org/10.1016/j.engappai.2022.105096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual sensor networks (VSNs) constitute a fundamental class of distributed sensing systems, with unique complexity and appealing performance features, which correspondingly bring in quite active lines of research. An important research direction consists in the identification and estimation of the VSN sensing features: these are practically useful when scaling with the number of cameras or with the observed scene complexity. With this context in mind, this paper introduces for the first time the idea of Stimulation Model (SM), as a mathematical relation between the set of detectable events and the corresponding stimulated cameras observing those events. The formulation of the related SM identification problem is proposed, along with a proper network observations model, and a solution approach based on deep embedded features and soft clustering. In detail: first, the Gaussian Mixture Modeling is employed to provide a suitable description for data distribution, while an autoencoder is used to reduce undesired effects due to the so-called curse of dimensionality emerging in case of large scale networks. Then, it is shown that a SM can be learnt by solving Maximum A-Posteriori estimation on the encoded features belonging to a space with lower dimensionality. Numerical results on synthetic scenarios are reported to validate the devised estimation algorithm.},
  archive      = {J_EAAI},
  author       = {Luca Varotto and Marco Fabris and Giulia Michieletto and Angelo Cenedese},
  doi          = {10.1016/j.engappai.2022.105096},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105096},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Visual sensor network stimulation model identification via gaussian mixture model and deep embedded features},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TAU: A framework for video-based traffic analytics
leveraging artificial intelligence and unmanned aerial systems.
<em>EAAI</em>, <em>114</em>, 105095. (<a
href="https://doi.org/10.1016/j.engappai.2022.105095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart traffic engineering and intelligent transportation services are in increasing demand from governmental authorities to optimize traffic performance and thus reduce energy costs, increase the drivers’ safety and comfort, ensure traffic laws enforcement, and detect traffic violations. In this paper, we address this challenge, and we leverage the use of Artificial Intelligence (AI) and Unmanned Aerial Vehicles (UAVs) to develop an AI-integrated video analytics framework, called TAU (Traffic Analysis from UAVs), for automated traffic analytics and understanding. Unlike previous works on traffic video analytics, we propose an automated object detection and tracking pipeline from video processing to advanced traffic understanding using high-resolution UAV images. TAU combines six main contributions. First, it proposes a pre-processing algorithm to adapt the high-resolution UAV image as input to the object detector without lowering the resolution. This ensures an excellent detection accuracy from high-quality features, particularly the small size of detected objects from UAV images. Second, it introduces an algorithm for recalibrating the vehicle coordinates to ensure that vehicles are uniquely identified and tracked across the multiple crops of the same frame. Third, it presents a speed calculation algorithm based on accumulating information from successive frames. Fourth, TAU counts the number of vehicles per traffic zone based on the Ray Tracing algorithm. Fifth, TAU has a fully independent algorithm for crossroad arbitration based on the data gathered from the different zones surrounding it. Sixth, TAU introduces a set of algorithms for extracting twenty-four types of insights from the raw data collected. These insights facilitate the traffic understanding using curves, histograms, heatmaps, and animations. The present work presents a valuable added value for academic researchers and transportation engineers to automate the traffic video analytics process and extract useful insights to optimize traffic performance. TAU is a ready-to-use framework for any Transportation Engineer to better understand and manage daily road traffic (video demonstrations are provided here: https://youtu.be/wXJV0H7LviU and here: https://youtu.be/kGv0gmtVEbI ). The source code is available at: https://github.com/bilel-bj/TAU .},
  archive      = {J_EAAI},
  author       = {Bilel Benjdira and Anis Koubaa and Ahmad Taher Azar and Zahid Khan and Adel Ammar and Wadii Boulila},
  doi          = {10.1016/j.engappai.2022.105095},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105095},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {TAU: A framework for video-based traffic analytics leveraging artificial intelligence and unmanned aerial systems},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unsupervised simple siamese representation learning for
blind super-resolution. <em>EAAI</em>, <em>114</em>, 105092. (<a
href="https://doi.org/10.1016/j.engappai.2022.105092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep convolutional neural networks have made unprecedented achievements in image super-resolution (SR) and dominated the field due to their remarkable performance. When the degradation pattern of the test images is inconsistent with the training images, it leads to poor model performance. For example, the degradation could happen after a dimensional stretching. In this case, the most common method is to take blurry, noise, and low-resolution (LR) images and reconstructs SR images by degradation estimation. However, the SR results for this method are highly dependent on the estimation accuracy. To overcome the difficulty with the degradation estimation, this paper designs a degradation representation attention network (DRAN) for image SR. In which, we propose the use of a simple Siamese representation learning to extract the degradation information from various LR images. Specifically, DRAN distinguishes degradation information instead of performing degradation estimation, which can greatly reduce the difficulty. In other words, DRAN can avoid pixel-level operations, transform degradation computation problems into degradation classification problems and flexibly process LR images through degradation representation learning. Finally, DRAN also introduces a channel attention mechanism to enhance the performance of SR. Experimental results show that the proposed scheme can distinguish different degradation modes and obtain accurate degradation information. Meanwhile, experiments on synthetic and real images show that the DRAN achieves remarkable performance on blind SR tasks with good visual effects.},
  archive      = {J_EAAI},
  author       = {Pengfeng Yin and Zhonghua Liu and Di Wu and Hua Huo and Haijun Wang and Kaibing Zhang},
  doi          = {10.1016/j.engappai.2022.105092},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105092},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unsupervised simple siamese representation learning for blind super-resolution},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiple deep neural networks with multiple labels for
cross-modal hashing retrieval. <em>EAAI</em>, <em>114</em>, 105090. (<a
href="https://doi.org/10.1016/j.engappai.2022.105090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most deep hashing methods for cross-modal retrieval use semantic labels to judge simply whether a pair of data are similar or dissimilar. However, they do not make full use of the different labels between the two instances. In addition, they do not generate more discriminative hash codes that scatter around the class centre. To this end, we propose multiple deep neural networks with multiple labels for cross-modal hashing retrieval (MDMCH). MDMCH constructs a multiple deep hash learning framework that contains three-stream deep neural networks for images, texts, and labels. In terms of the objective function, the semantic weight and class centre similarity are calculated according to the multi-labels. Then, the semantic weight is embedded into three cross-entropy loss terms for image, text, and label networks to better preserve inter-modal and intra-modal similarities. Meanwhile, MDMCH fuses the deep features of semantic labels and texts to further improve the text-to-image retrieval accuracy. Additionally, the class centre similarity is applied to the image and text networks, which forces the similar instance pairs to scatter around the class centre. Experiments on three popular benchmark datasets demonstrate that the proposed method outperforms the state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Yicai Xie and Xianhua Zeng and Tinghua Wang and Liming Xu and Dingjie Wang},
  doi          = {10.1016/j.engappai.2022.105090},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105090},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multiple deep neural networks with multiple labels for cross-modal hashing retrieval},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). An adaptively balanced grey wolf optimization algorithm for
feature selection on high-dimensional classification. <em>EAAI</em>,
<em>114</em>, 105088. (<a
href="https://doi.org/10.1016/j.engappai.2022.105088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection, which aims to screen out redundant and irrelevant features from datasets, is integral to machine learning and data mining. Grey Wolf Optimization (GWO) is a recent meta-heuristic algorithm based on swarm intelligence and has wide applicability to various optimization problems due to its fast convergence and few parameters. However, since the wolf pack is always dominated by the three leading wolves ( i.e. , α , β and δ ), the GWO algorithm suffers from weak exploration throughout the whole optimization process and easily stagnates into local optima. In this paper, an Adaptively Balanced Grey Wolf Optimization (ABGWO) algorithm is proposed to seek out the optimal feature subset for high-dimensional classification. Specifically, to improve the exploration ability of GWO, a random wolf is introduced to cooperate with α , β and δ . A novel level-based strategy is further adopted to select the random wolf. Besides, to dynamically modulate the exploration and exploitation ability in different optimization stages, an adaptive coefficient is introduced to regulate the leadership of α , β , δ and the randomly-selected wolf. Finally, the improvement of exploration and exploitation is validated on 12 high-dimensional datasets provided by Arizona State University and University of California Irvine, and the superiority of ABGWO is further verified by comparing it with seven state-of-the-art feature selection approaches on the aspect of classification accuracy, size of feature subset and computational time.},
  archive      = {J_EAAI},
  author       = {Jing Wang and Dakun Lin and Yuanzi Zhang and Shiguo Huang},
  doi          = {10.1016/j.engappai.2022.105088},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105088},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An adaptively balanced grey wolf optimization algorithm for feature selection on high-dimensional classification},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A two stage risk assessment model based on interval-valued
fuzzy numbers and risk attitudes. <em>EAAI</em>, <em>114</em>, 105086.
(<a href="https://doi.org/10.1016/j.engappai.2022.105086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the lack of historical data, experts often score risks based on their experience and some linguistic terms in risk assessment, then the risk assessment is essentially a semi-quantitative problem. When experts score risks, the scores are possibly related to experts’ risk attitudes. On the other hand, the linguistic terms used are inevitably ambiguous, and interval-valued fuzzy numbers can deal with linguistic uncertainty better in complex situation. So a risk analysis model based on interval-valued fuzzy numbers and risk attitudes is novelly proposed in this paper. For safety risks in oil industry, the risk consequence often performs in several aspects, some of them are difficult to be measured by money and cannot be aggregated to a comprehensive index directly. A multi-expert and multi-criterion information fusion(MEMC-IF) model is needed. Firstly, linguistic terms and interval-valued fuzzy numbers are determined and a MEMC-IF model is constructed to derive the collective data and the comprehensive risk consequence. Secondly, a defuzzification model is presented to transform interval-valued fuzzy numbers to crisp values with considering risk attitudes novelly. Then, a risk matrix is constructed to assess which risks are serious and which risks can be ignored. In addition, a case study is demonstrated to show the efficiency of the proposed model and a discussion is completed.},
  archive      = {J_EAAI},
  author       = {Donghong Tian and Junhua Chen and Xiaobing Wu},
  doi          = {10.1016/j.engappai.2022.105086},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105086},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A two stage risk assessment model based on interval-valued fuzzy numbers and risk attitudes},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CASR-net: A color-aware super-resolution network for
panchromatic image. <em>EAAI</em>, <em>114</em>, 105084. (<a
href="https://doi.org/10.1016/j.engappai.2022.105084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial resolution is the ability to distinguish the spatial details of remote sensing images, and high spatial resolution images are conducive to object recognition and visual interpretation. Spectral resolution is the ability to distinguish the spectral details of the ground objects in remote sensing images, and high spectral resolution images are of great significance to the classification and recognition of objects in remote sensing images. The image super-resolution model is used to enhance the spatial resolution of remote sensing image, but it cannot enhance the spectral resolution, while the image colorization model can increase the number of channels by predicting chromatic channels for the input image, thereby improving spectral resolution. In this paper, a color-aware super-resolution network that combines image colorization and super-resolution ideas is designed to improve the spectral and spatial resolution of panchromatic images. The color-aware super-resolution network mainly contains color-aware block and spatial-aware block, color-aware block is presented to predict color information for panchromatic images to improve the spectral resolution, meanwhile, spatial-aware block is used to restore the texture details for panchromatic images to improve the spatial resolution. The trained color-aware super-resolution network only needs to input panchromatic images to generate images with more spectral information and higher spatial resolution than input images. Extensive experiments demonstrate that our color-aware super-resolution network has a good performance in image colorization and super-resolution, and experimental results show that compare with some existing excellent image colorization methods and super-resolution methods, our method is excellent in objective indicators and visual effects.},
  archive      = {J_EAAI},
  author       = {Ling Liu and Qian Jiang and Xin Jin and Jianan Feng and Ruxin Wang and Hangying Liao and Shin-Jye Lee and Shaowen Yao},
  doi          = {10.1016/j.engappai.2022.105084},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105084},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {CASR-net: A color-aware super-resolution network for panchromatic image},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial rabbits optimization: A new bio-inspired
meta-heuristic algorithm for solving engineering optimization problems.
<em>EAAI</em>, <em>114</em>, 105082. (<a
href="https://doi.org/10.1016/j.engappai.2022.105082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new bio-inspired meta-heuristic algorithm, named artificial rabbits optimization (ARO), is proposed and tested comprehensively. The inspiration of the ARO algorithm is the survival strategies of rabbits in nature, including detour foraging and random hiding. The detour foraging strategy enforces a rabbit to eat the grass near other rabbits’ nests, which can prevent its nest from being discovered by predators. The random hiding strategy enables a rabbit to randomly choose one burrow from its own burrows for hiding, which can decrease the possibility of being captured by its enemies. Besides, the energy shrink of rabbits will result in the transition from the detour foraging strategy to the random hiding strategy. This study mathematically models such survival strategies to develop a new optimizer. The effectiveness of ARO is tested by comparison with other well-known optimizers by solving a suite of 31 benchmark functions and five engineering problems. The results show that ARO generally outperforms the tested competitors for solving the benchmark functions and engineering problems. ARO is applied to the fault diagnosis of a rolling bearing, in which the back-propagation (BP) network optimized by ARO is developed. The case study results demonstrate the practicability of the ARO optimizer in solving challenging real-world problems. The source code of ARO is publicly available at https://seyedalimirjalili.com/aro and https://ww2.mathworks.cn/matlabcentral/fileexchange/110250-artificial-rabbits-optimization-aro .},
  archive      = {J_EAAI},
  author       = {Liying Wang and Qingjiao Cao and Zhenxing Zhang and Seyedali Mirjalili and Weiguo Zhao},
  doi          = {10.1016/j.engappai.2022.105082},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105082},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Artificial rabbits optimization: A new bio-inspired meta-heuristic algorithm for solving engineering optimization problems},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cumulative dual-branch network framework for long-tailed
multi-class classification. <em>EAAI</em>, <em>114</em>, 105080. (<a
href="https://doi.org/10.1016/j.engappai.2022.105080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The long-tailed data distribution problem (i.e., a few classes account for majority data, while most classes account for minority data) is widespread in large-scale and real-world datasets, and it poses a huge challenge to the computer vision field. Existing methods of long-tailed classification mainly focus on re-sampling, re-weighting, and transfer learning. Although class imbalance learning can yield better long-tailed classification performance, the feature representative ability of the feature extraction network is damaged to a certain extent. To deal with these issues, the present work proposes a novel cumulative dual-branch network framework (CDBNF), which takes into account the class imbalance learning and feature representation learning at the same time by the dual-branch network architecture. In CDBNF, the class imbalance learning branch greatly improves the classification performance of tail classes, while the few-shot learning branch enhances the feature representative ability. Furthermore, a cumulative learning strategy (CLS) is proposed in CDBNF to make it pay more attention to the tail classes gradually in the training process. The effectiveness and practicability of the proposed CDBNF are verified by the four benchmark datasets. Experimental results show that the classification performance of CDBNF is superior to other state-of-the-art methods, while the intra-class feature variance is smaller than other state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Saite Fan and Xinmin Zhang and Zhihuan Song and Weiming Shao},
  doi          = {10.1016/j.engappai.2022.105080},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105080},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cumulative dual-branch network framework for long-tailed multi-class classification},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient large-scale face clustering using an online
mixture of gaussians. <em>EAAI</em>, <em>114</em>, 105079. (<a
href="https://doi.org/10.1016/j.engappai.2022.105079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the number of applications demanding real-time face clustering algorithms has increased, especially for security and surveillance purposes. However, state-of-the-art face clustering methods are offline, they need to repeat the whole clustering process every time new data arrives, and thus, they are not suitable for real-time applications. On the other hand, online clustering methods are highly dependent on the order and the size of the data, and they are less accurate than offline methods. To overcome these limitations, we present an online gaussian mixture-based clustering method (OGMC). The key idea of this method is the proposal that an identity can be represented by more than just one distribution or cluster. Using feature vectors extracted from the incoming faces, OGMC generates clusters that may be connected to others depending on their proximity and their robustness, and updates their connections every time their parameters are updated. With this approach, we reduce the dependency of the clustering process on the order and the size of the data and we are able to deal with complex data distributions. Experimental results show that OGMC outperforms state-of-the-art clustering methods on large-scale face clustering benchmarks not only in accuracy, but also in efficiency and scalability.},
  archive      = {J_EAAI},
  author       = {David Montero and Naiara Aginako and Basilio Sierra and Marcos Nieto},
  doi          = {10.1016/j.engappai.2022.105079},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105079},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Efficient large-scale face clustering using an online mixture of gaussians},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generating the captions for remote sensing images: A
spatial-channel attention based memory-guided transformer approach.
<em>EAAI</em>, <em>114</em>, 105076. (<a
href="https://doi.org/10.1016/j.engappai.2022.105076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote sensing image captioning (RSIC) is cross-modal interaction task in an artificial intelligence that leads to automatic description of Earth’s geological properties captured from an aerial view. It is noted that, convolutional neural network (CNN) and recurrent neural network (RNN) based encoder–decoder methods are widely adopted for RSIC, but has two main constrains: first, insufficient to capture inherent geographical characteristics due to single level static convolutional features; second, difficult to train regressive time-step sequences. To address these challenges, a novel fully-attentive framework entitled Spatial-Channel Attention based MEmory-guided Transformer (SCAMET) is proposed, which calibrates multilevel visual attentive features and aligns with linguistic information through persistent memory. Here, CNN is integrated with Transformer to generate captions for remote sensing image. To comprehend deeper semantic knowledge of multi-scale, multi-shape, multi-object in remote sensing image, multi-attentive visual features are extracted by employing spatial and channel attention separately. To decode multi-attentive feature into caption, this work proposes memory-guided Transformer as linguistic decoder. Specifically, learnable memory elements are incorporated in multi-head attention block, which perceives intrinsic association within visual multi-attentive features and reconciles with linguistic information. The ablation studies are conducted on three public RSIC datasets, Sydney-captions, UCM-captions and RSICD to evaluate performance of proposed method. The quantitative and qualitative analyses reveal that proposed method performs satisfactory compared to state-of-the-art approaches. This work also proposes a “Weighted Mean Score” index to evaluate conclusive performance of model across all datasets by leveraging global contribution of each test set. The implementation of proposed work is available at: https://github.com/GauravGajbhiye/SCAMET_RSIC .},
  archive      = {J_EAAI},
  author       = {Gaurav O. Gajbhiye and Abhijeet V. Nandedkar},
  doi          = {10.1016/j.engappai.2022.105076},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105076},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Generating the captions for remote sensing images: A spatial-channel attention based memory-guided transformer approach},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dandelion optimizer: A nature-inspired metaheuristic
algorithm for engineering applications. <em>EAAI</em>, <em>114</em>,
105075. (<a
href="https://doi.org/10.1016/j.engappai.2022.105075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel swarm intelligence bioinspired optimization algorithm, called the Dandelion Optimizer (DO), for solving continuous optimization problems. DO simulates the process of dandelion seed long-distance flight relying on wind, which is divided into three stages. In the rising stage, seeds raise in a spiral manner due to the eddies from above or drift locally in communities according to different weather conditions. In the descending stage, flying seeds steadily descend by constantly adjusting their direction in global space. In the landing stage, seeds land in randomly selected positions so that they grow. The moving trajectory of a seed in the descending stage and landing stage are described by Brownian motion and a Levy random walk. CEC2017 benchmark functions are utilized to evaluate the performance of DO, including the optimization accuracy, stability, convergence, and scalability, through a comparison with 9 well-known nature-inspired metaheuristic algorithms. Finally, the applicability of DO is verified by solving 4 real-world optimization problems. The experimental results indicate that the proposed DO method is a higher performing optimizer with outstanding iterative optimization and strong robustness compared with well-established algorithms. Source codes of DO are publicly available at https://ww2.mathworks.cn/matlabcentral/fileexchange/114680-dandelion-optimizer .},
  archive      = {J_EAAI},
  author       = {Shijie Zhao and Tianran Zhang and Shilin Ma and Miao Chen},
  doi          = {10.1016/j.engappai.2022.105075},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105075},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dandelion optimizer: A nature-inspired metaheuristic algorithm for engineering applications},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). EcoForecast: An interpretable data-driven approach for
short-term macroeconomic forecasting using n-BEATS neural network.
<em>EAAI</em>, <em>114</em>, 105072. (<a
href="https://doi.org/10.1016/j.engappai.2022.105072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It will be beneficial to devise an effective approach for short-term macroeconomic forecasting. Existing traditional statistics-based macroeconomic forecasting mainly focuses on exploring feasible methods for improving the accuracy of long-term predictions. However, the performance of short-term predictions was far less impressive under the impact of unexpected incidents. Furthermore, some deep learning-based approaches can achieve fine-grained variable frequency forecasting and preliminarily demonstrate effective results, but the interpretability is still controversial. Therefore, how to consider both the performance and the interpretability has already become a universal concern and an urgent unsolved problem. In this paper, we identified the above issue and proposed an interpretable data-driven approach, named EcoForecast 1 , for short-term macroeconomic forecasting based on the N-BEATS (neural basis expansion analysis for interpretable time series forecasting) neural network. To the best of our knowledge, EcoForecast is the first interpretable purely data-driven unified normative scheme for macroeconomic forecasting that achieves variable forecast frequencies and prediction domains, surpassing traditional statistics-based and deep learning-based approaches in performance or interpretability. EcoForecast used a three-level hierarchical signal encoding, including the fully connected neural network (FCNN) level, the block level, and the stack level. The FCNN level implemented both forecast and backcast information extraction for the temporal prediction and parameter learning of context. Block levels were connected by residuals so that the block’s backcast could be sequentially filtered on the input. The stack level was used to form the top-level system of EcoForecast, where each stack was constrained to specialize in different inductive functions. To some extent, EcoForecast can balance effectiveness, efficiency, generalizability and interpretability while conditions such as forecast frequency and time window change, even when unexpected incidents occur. Based on the actual macroeconomic data for China from 1992 to 2022, the data-driven EcoForecast demonstrated high stability in different sequence learning scenarios and the accompanying high-accuracy performance. This stability was reflected in smaller prediction error expectation and variance, tolerance of fewer input samples, and robustness across prediction domains. The experimental results indicated that EcoForecast improved the accuracy up to 3.94 times compared with the traditional BVAR. In the robustness test, EcoForecast required only a quarter of the data to achieve 2.51 times smaller forecast errors than the BVAR while also improving the accuracy of varied macroeconomic indicators such as the Purchasing Managers’ Index (PMI) and national electricity generation (ELEC)forecasting by 2.38 and 1.45 times. EcoForecast had a high sensitivity to the emergence of economic inflection points and adapts quickly when the economic environment changes, thus demonstrating a performance that exceeds traditional solutions in GDP forecasting during epidemics and PMI forecasting during economic turmoil. Interfacing with traditional economics research, the interpretable EcoForecast can uncover the trends and cycles of economic change, from which the conclusions are validated with the actual economics practice in China. Our findings can provide a new possible research direction for short-term macroeconomic forecasting.},
  archive      = {J_EAAI},
  author       = {Xuanzheng Wang and Changwang Li and Chengqi Yi and Xinan Xu and Jiandong Wang and Youhui Zhang},
  doi          = {10.1016/j.engappai.2022.105072},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105072},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {EcoForecast: An interpretable data-driven approach for short-term macroeconomic forecasting using N-BEATS neural network},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Edge-aware and spectral–spatial information aggregation
network for multispectral image semantic segmentation. <em>EAAI</em>,
<em>114</em>, 105070. (<a
href="https://doi.org/10.1016/j.engappai.2022.105070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation is a fundamental task in the field of remote sensing image intelligent interpretation and computer vision. Multispectral remote sensing images have attracted more and more researchers’ attention because they can accurately describe different types of reflection spectra. However, inaccurate multispectral feature description leads to edge semantic ambiguity and misclassification of small objects. In this article, we propose a novel network named edge-aware and spectral–spatial information aggregation net (ESSANet) to capture both high-level semantic features and low-level edge details for semantic segmentation of remote sensing images. Specifically, on the one hand, in order to improve the representation ability of discriminant features, we design a two-stream spectral–spatial feature extraction network via 3D hybrid convolution and multi-level aggregation network. On the other hand, in order to eliminate the effect of edge semantic ambiguity, we develop a siamese edge-aware structure and multi-stage edge loss function. Experimental results show that our method achieved 3.5% and 4.09% mean intersection over union (mIoU) score improvements and 2.59% and 3.32% Kappa score improvements compared with the competitive baseline algorithm on the SEN12MS and US3D datasets, respectively. In addition, the method proposed in this paper also achieves a better trade-off between speed and accuracy.},
  archive      = {J_EAAI},
  author       = {Di Zhang and Jiaqi Zhao and Jingyang Chen and Yong Zhou and Boyu Shi and Rui Yao},
  doi          = {10.1016/j.engappai.2022.105070},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105070},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Edge-aware and spectral–spatial information aggregation network for multispectral image semantic segmentation},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-adaptive classification learning hybrid JAYA and rao-1
algorithm for large-scale numerical and engineering problems.
<em>EAAI</em>, <em>114</em>, 105069. (<a
href="https://doi.org/10.1016/j.engappai.2022.105069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a self-adaptive classification learning hybrid JAYA and Rao-1 algorithm, which is called EHRJAYA, is proposed for solving large-scale numerical problems and real-world complex engineering optimization problems. JAYA algorithm and Rao-1 algorithm are two kinds of algorithms with simple structure and superior performance, which have the characteristics of no particular controlling parameters. In EHRJAYA the evolution strategies of the two algorithms are selected through a random selection mechanism. Then, a novel self-adaptive classification learning strategy is proposed, which fully utilizes information from different individuals. On this basis, two different adaptive coefficients are introduced to guide the population towards the optimal individual and away from the worst individual. Finally, combining the linear population reduction strategy and the dynamic lens opposition-based learning strategy, the convergence speed and ability to jump out of local optimum of the algorithm are greatly improved. To verify the performance of the proposed EHRJAYA, 59 complex functions from the CEC2014 and CEC2017 competitions are solved by EHRJAYA. Then, EHRJAYA and more than 20 algorithms with superior performance jointly solve ten challenging real-world engineering optimization problems. Experimental results show that the proposed EHRJAYA can obtain optimal results with the least computational resources in most cases. Therefore, in the face of these problems, effective solutions can be provided by EHRJAYA.},
  archive      = {J_EAAI},
  author       = {Yu-Jun Zhang and Yu-Fei Wang and Liu-Wei Tao and Yu-Xin Yan and Juan Zhao and Zheng-Ming Gao},
  doi          = {10.1016/j.engappai.2022.105069},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105069},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-adaptive classification learning hybrid JAYA and rao-1 algorithm for large-scale numerical and engineering problems},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A dual attribute weighted decision fusion system for fault
classification based on an extended analytic hierarchy process.
<em>EAAI</em>, <em>114</em>, 105066. (<a
href="https://doi.org/10.1016/j.engappai.2022.105066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As substantial parts of process monitoring, fault classification techniques have been widely utilized in modern industries. However, most methods can only perform well under specific condition, which indicates that it is always difficult to ensure the classification efficiency for complex industrial processes using only one method. In this paper a weighted decision fusion system is proposed where an extended analytic hierarchy process (EAHP) structure is designed to give a comprehensive explanation for the weights assigned to the original fault classification results. Firstly, the fault category information is embedded in the EAHP structure, which makes it possible to consider both fault-wise and classifier-wise information in the fault classification. Secondly, an overall priority (OP) matrix is proposed to provide full prior knowledge for all classifiers. Different from previous researches, traditional OP vectors are replaced by the new-designed OP matrix which can contain more information about fault category. Thirdly, another confidence matrix is carried out to update the classification results. Compared with previous state-of-art, the confidence matrix can be adjusted according to the specific original classification result Finally, the effectiveness of the proposed method is verified by a numerical example and the Tennessee Eastman process (TEP) where the proposed decision fusion system shows superior fault classification results in both experiments.},
  archive      = {J_EAAI},
  author       = {Yuchen He and Ruichong Lou and Yun Wang and Jun Wang and Xinyun Fang},
  doi          = {10.1016/j.engappai.2022.105066},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105066},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A dual attribute weighted decision fusion system for fault classification based on an extended analytic hierarchy process},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evolving fuzzy logic systems for creative personalized
socially assistive robots. <em>EAAI</em>, <em>114</em>, 105064. (<a
href="https://doi.org/10.1016/j.engappai.2022.105064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Socially Assistive Robots (SARs) are increasingly used in dementia and elderly care. In order to provide effective assistance, SARs need to be personalized to individual patients and account for stimulating their divergent thinking in creative ways. Rule-based fuzzy logic systems provide effective methods for automated decision-making of SARs. However, expanding and modifying the rules of fuzzy logic systems to account for the evolving needs, preferences, and medical conditions of patients can be tedious and costly. In this paper, we introduce EFS4SAR, a novel Evolving Fuzzy logic System for Socially Assistive Robots that supports autonomous evolution of the fuzzy rules that steer the behavior of the SAR. EFS4SAR combines traditional rule-based fuzzy logic systems with evolutionary algorithms, which model the process of evolution in nature and have shown to result in creative behaviors. We evaluate EFS4SAR via computer simulations on both synthetic and real-world data. The results show that the fuzzy rules evolved over time are not only personalized with respect to the personal preferences and therapeutic needs of the patients, but they also meet the following criteria for creativity of SARs: originality and effectiveness of the therapeutic tasks proposed to the patients. Compared to existing evolving fuzzy systems, EFS4SAR achieves similar effectiveness with higher degree of originality.},
  archive      = {J_EAAI},
  author       = {Davide Dell’Anna and Anahita Jamshidnejad},
  doi          = {10.1016/j.engappai.2022.105064},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105064},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Evolving fuzzy logic systems for creative personalized socially assistive robots},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimizing an integrated home care problem: A
heuristic-based decision-support system. <em>EAAI</em>, <em>114</em>,
105062. (<a
href="https://doi.org/10.1016/j.engappai.2022.105062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous increase in longevity worldwide, the elderly population requiring home health and social care has been continuously growing over the years. Planning combined home health and social services has been shown to be a very difficult task for current decision-makers, not only due to the high number of working regulations and user-related necessities that need to be considered but also due to the need for synchronizing both types of services. Moreover, it is highly desirable that users are visited by the fewest number of different caregivers in the same kind of appointments (continuity of service). The complex and multi-objective nature of the synchronized home health and social care routing and scheduling problem has called for the development of automated planning systems that are able to obtain efficient solutions in reasonable computational times. In this work, we propose two heuristic methods to optimize routing and scheduling decisions for this problem with an extensive set of constraints and objectives. We use (real) data and information from current care providers in the Barcelona area to build and test our models and provide insights into parameter tuning and the trade-off between the associated operating costs, continuity of service and number of unscheduled services. The proposed tool is made available via a web-based decision support system that allows decision-makers to obtain efficient solutions in an intuitive, complete, and timely manner.},
  archive      = {J_EAAI},
  author       = {Bruno Vieira and Jesica de Armas and Helena Ramalhinho},
  doi          = {10.1016/j.engappai.2022.105062},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105062},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimizing an integrated home care problem: A heuristic-based decision-support system},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Performance-based data-driven optimal tracking control of
shape memory alloy actuated manipulator through reinforcement learning.
<em>EAAI</em>, <em>114</em>, 105060. (<a
href="https://doi.org/10.1016/j.engappai.2022.105060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article focuses on the continuous-time optimal tracking control problem of a shape memory alloy (SMA) actuated manipulator subject to prescribed error constraints and completely unknown nonlinear dynamics. Firstly, prespecified error constraints imposed by the prescribed performance function (PPF) are transformed into an equivalent unconstrained task by adopting a transformation function, where the newly designed PPF is irrelated to the initial condition. An unconstrained augmented system and a long-term discounted performance considering tracking errors and input cost are constructed for the convenience of designing the optimal controller. Then, a model-based optimal control algorithm is derived to solve the Hamilton–Jacobi–Bellman equation (HJBE). Next, data-driven reinforcement learning (RL) is employed to approximate the solution of the HJBE iteratively to obviate requiring an SMA manipulator model. Moreover, critic neural networks (NNs) and actor NNs are introduced to the RL-based optimal controller, and the least-squares method is used to find the parameters for the NNs-based RL algorithm. Rigorous theoretical analyses demonstrate that the proposed controller can stable the SMA manipulator system, and the tracking errors are always constrained within the prescribed region. Finally, experiments are conducted on the established SMA actuated manipulator platform, and the results illustrate that the proposed controller is feasible and effective.},
  archive      = {J_EAAI},
  author       = {Hongshuai Liu and Qiang Cheng and Jichun Xiao and Lina Hao},
  doi          = {10.1016/j.engappai.2022.105060},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105060},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Performance-based data-driven optimal tracking control of shape memory alloy actuated manipulator through reinforcement learning},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). A FeedForward–convolutional neural network to detect
low-rate DoS in IoT. <em>EAAI</em>, <em>114</em>, 105059. (<a
href="https://doi.org/10.1016/j.engappai.2022.105059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The lack of standardization and the heterogeneous nature of the Internet of Things (IoT) has exacerbated the issue of security and privacy. In literature, to improve security at the network layer of the IoT architecture, the possibility of using Software-Defined Networking (SDN) was explored. SDN is also plagued by network threats that affect conventional networks. One such threat to a network is the Low-Rate Denial of Service (LR DoS) attack, where the attacker sends precise traffic bursts that force a TCP flow to enter a retransmission timeout state. LR DoS attacks are difficult to detect as their attack signature is similar to benign network traffic. The existing AI-based detection algorithms in the literature are signature-based, and their efficacy in detecting unknown LR DoS attacks was not explored. In this work, an AI-based anomaly detection scheme called FeedForward–Convolutional Neural Network (FFCNN) is proposed to detect LR DoS attacks in IoT-SDN. The Canadian Institute of Cybersecurity Denial of Service 2017 (CIC DoS 2017) dataset is used for the study. An iterative wrapper-based feature selection using Support Vector Machine (SVM) is used to derive the significant features required for detection. The performance of FFCNN is compared to the machine learning algorithms-J48, Random Forest, Random Tree, REP Tree, SVM, and Multi-Layer Perceptron (MLP). The performance of the models is measured using the metrics accuracy, precision, recall, F1 score, detection time per flow, and ROC curves. The empirical analysis shows that FFCNN outperforms other machine learning algorithms on all metrics.},
  archive      = {J_EAAI},
  author       = {Harun Surej Ilango and Maode Ma and Rong Su},
  doi          = {10.1016/j.engappai.2022.105059},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105059},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A FeedForward–Convolutional neural network to detect low-rate DoS in IoT},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-actor activity detection by modeling object
relationships in extended videos based on deep learning. <em>EAAI</em>,
<em>114</em>, 105055. (<a
href="https://doi.org/10.1016/j.engappai.2022.105055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a Multi-actor Activity Detection Framework (MADF) to model the interactive relationship among multiple actors for activity detection in extended videos. MADF can detect 3 groups of multi-actor activities with different kinds of actors, which involves three stages: detection, classification and post-processing. In the detection stage, both interaction proposals and actor proposals are generated in each video clip, in order to eliminate irrelevant background in the scene. In the classification stage, 3 different classification networks are proposed to classify the 3 groups of activities. And further, for person–object interaction, an attention mechanism is adopted to help the person–object classification network to pay more attention to the small-scale objects; for person–person interaction, a suppression module is used to improve the accuracy of the person–person activity detection; for person–vehicle interaction, a spatial–temporal graph convolution network (GCN) module is embedded to model the fine-grained relationship between the person and vehicle in the person–vehicle classification network, with a proposed Mutually Exclusive Category Loss (MECLoss) helping this network distinguish mutually exclusive activities. At last, we use the off-the-shelf post-processing methods to re-score the proposals for more stable results. The proposed system achieves a great progress on our baseline and achieves the state-of-the-art results in TRECVID 2021 ActEV challenge.},
  archive      = {J_EAAI},
  author       = {Binyu Zhang and Junfeng Wan and Yanyun Zhao and Zhihang Tong and Yunhao Du},
  doi          = {10.1016/j.engappai.2022.105055},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105055},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-actor activity detection by modeling object relationships in extended videos based on deep learning},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid local search algorithm for minimum dominating set
problems. <em>EAAI</em>, <em>114</em>, 105053. (<a
href="https://doi.org/10.1016/j.engappai.2022.105053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minimum dominating set (MDS) is a well-known NP-hard fundamental graph theory problem having many applications such as mining social networks and bioinformatics. MDS seeks for the minimum subset of vertices in which every vertex not in the selected subset is adjacent to at least one vertex of this subset. In this study, we consider MDS and a complex variant of MDS known as the minimum positive influence dominating set (MPIDS). In MPIDS, the aim is to identify a subset of vertices where each vertex of a graph must be dominated by at least half of its neighbors. To solve these problems, we propose a two-stage hybrid local search algorithm. In the first stage, we propose an adaptive information content-based local search algorithm as an exploratory procedure. This algorithm focuses on generating promising solutions in different areas of the solution space using the problem search history. Moreover, we introduce information content strategy-based neighborhood structure and tolerance-based features to evolve high-quality and diverse solutions. For the second stage, we propose a gain-based deterministic local search algorithm as an exploitation procedure. It navigates feasible neighborhood areas to improve the solution quality. We conducted extensive analysis to evaluate the impact of the proposed components. The proposed algorithm produced very good results and generalized well overall instances of both MDS and MPIDS. Compared to the literature, the proposed algorithm outperformed other algorithms in most of the tested instances.},
  archive      = {J_EAAI},
  author       = {Saad Adnan Abed and Helmi Md Rais and Junzo Watada and Nasser R. Sabar},
  doi          = {10.1016/j.engappai.2022.105053},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105053},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid local search algorithm for minimum dominating set problems},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Novel single and multi-layer echo-state recurrent
autoencoders for representation learning. <em>EAAI</em>, <em>114</em>,
105051. (<a
href="https://doi.org/10.1016/j.engappai.2022.105051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representation learning impacts the performance of Machine Learning (ML) models. Feature extraction-based methods such as Auto-Encoders (AEs) are used to find new, more accurate data representations from original ones. They perform efficiently on a specific task, in terms of: (1) high accuracy, (2) large short-term memory and (3) low execution time. The Echo-State Network (ESN) is a recent specific kind of a Recurrent Neural Networks (RNN), that presents very rich dynamics on account of its reservoir-based hidden layer. It is widely used in dealing with complex non-linear problems and has been shown to outperform classical approaches in a number of benchmark tasks. In this paper, the powerful dynamism and large memory provided by the ESN and complementary strengths of AEs in feature extraction are integrated, to develop a novel Echo-State Recurrent Autoencoder (ES-RA). In order to devise more robust alternatives to conventional reservoir-based networks, both single- (SL-ES-RA) and multi-layer (ML-ES-RA) models are formulated. The new features, once extracted from ESN’s hidden layer, are applied to various benchmark ML tasks including classification, time series prediction and regression. A range of evaluation metrics are shown to improve considerably compared to those obtained when applying original data features. An accuracy-based comparison is performed between our proposed recurrent AEs and two variants of ELM feed-forward AEs (Single and ML), for both noise free and noisy data. In summary, a comparative empirical study reveals the key contribution of exploiting recurrent connections in improving benchmark performance results.},
  archive      = {J_EAAI},
  author       = {Naima Chouikhi and Boudour Ammar and Amir Hussain and Adel M. Alimi},
  doi          = {10.1016/j.engappai.2022.105051},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105051},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Novel single and multi-layer echo-state recurrent autoencoders for representation learning},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Decision making framework based fermatean fuzzy integrated
weighted distance and TOPSIS for green low-carbon port evaluation.
<em>EAAI</em>, <em>114</em>, 105048. (<a
href="https://doi.org/10.1016/j.engappai.2022.105048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Green low-carbon port (GLCP) development and evaluation have gained increase attention in recent years. However, the uncertain assessment procedure and complex index in the GLCP assessment has brought great challenges to achieve a consensus for decision. To solve above problems, this study aims to present a novel decision making framework based on Fermatean fuzzy integrated weighted distance measure and Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) approach for the GLCP evaluation. The Fermatean fuzzy integrated weighted average distance (FFIWAD) measure is first proposed, which takes into account the subjective significance of the variables and the attitudinal characteristics of decision makers. A FFIWAD-TOPSIS decision making framework is then developed, wherein the weights of index are determined by entropy method, and the FFIWAD is applied to calculate the distance between each alternative and the positive (or negative) ideal solution. Moreover, on the basis of the constructed index system of GLCP evaluation, the presented FFIWAD-TOPSIS method is applied to assess the development status GLCP of five major ports in China. The case analysis shows that Guangzhou Port behaves the best comprehensive performance among the five cities, while Shenzhen Port is the worst. Finally, the sensitivity analysis, as well as comparative analysis of the presented model are conducted.},
  archive      = {J_EAAI},
  author       = {Sha Yang and Yan Pan and Shouzhen Zeng},
  doi          = {10.1016/j.engappai.2022.105048},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105048},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Decision making framework based fermatean fuzzy integrated weighted distance and TOPSIS for green low-carbon port evaluation},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fully hesitant fuzzy linear programming with hesitant fuzzy
numbers. <em>EAAI</em>, <em>114</em>, 105047. (<a
href="https://doi.org/10.1016/j.engappai.2022.105047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a new approach to solve a fully hesitant fuzzy linear programming (FHFLP) problem with hesitant fuzzy numbers (HFNs) as parameters. Using an ( α , k ) -cut for the HFNs, we convert this problem into some interval linear programming (ILP) problems, and solve these problems through one of the available algorithms to solve the ILP problems. Then through statistical regression analysis, we get k fuzzy numbers as the final approximate solutions, and we have proved that they are well defined. Finally, using the hesitant fuzzy arithmetic, we obtain a hesitant fuzzy value of the objective function. An example is introduced to clarify the solution process of this method, and a comparison between the optimal solutions through the proposed method to an FHFLP problem and its converted form to a fully fuzzy linear programming problem has been done. The outcomes indicate that the obtained solutions for decision variables and objective function are reasonable.},
  archive      = {J_EAAI},
  author       = {M. Ranjbar and S. Effati and S.M. Miri},
  doi          = {10.1016/j.engappai.2022.105047},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105047},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fully hesitant fuzzy linear programming with hesitant fuzzy numbers},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Application of artificial intelligence for university
information system. <em>EAAI</em>, <em>114</em>, 105038. (<a
href="https://doi.org/10.1016/j.engappai.2022.105038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We know that Artificial Intelligence is play a major role in a multiplicity of fields ranging from manufacturing industries to sale industries, to customer care in public relations. Chat bots and online Artificial Intelligence (AI) systems which are already available that help people get answer to their day to day queries. So AI based college information system were invented that can solve any college related query. This will function as a university data Intelligence machine. Exam, fees, placement information related to university courses are answered by AI Bot using algorithm. The university enquiry chat bot will be constructed that examines exact enquiries response by student and answer consequently.},
  archive      = {J_EAAI},
  author       = {Pradeep Udupa},
  doi          = {10.1016/j.engappai.2022.105038},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105038},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Application of artificial intelligence for university information system},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey of visual navigation: From geometry to embodied AI.
<em>EAAI</em>, <em>114</em>, 105036. (<a
href="https://doi.org/10.1016/j.engappai.2022.105036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The capacity to extract information and comprehend an unseen environment is critical for mobile robots to navigate. Few surveys has mentioned the combinatorial-non-optimality problem of the traditional visual navigation methods. As computer vision technology has improved in recent years, visual navigation approaches have escalated drastically, particularly after the appearance of the CVPR Embodied AI workshop. However, few studies take these important changes into account. This survey fills this research gap by collecting, analyzing, and summarizing more than 100 recent papers. The majority of them are published within 5 years and are cited over 80 times, which provide more credible results. Based on our thorough comparison, this survey categorizes all visual navigation methods into two styles: geometry style and embodied AI style. This survey examines these two styles from the perspective of input–output. In addition, this survey attempts to provide mathematical formulations for each style. This paper provides a case study to illustrate the methodological paradigm with greatest potential. This methodological paradigm using photo-realistic simulation in the Embodied AI style, which could solve the combinatorial-non-optimality problem. Thereafter, this survey discusses several issues including pros–cons analysis, problem formulation, common framework, task generalization, dynamic environment consideration, sim-to-real, and inspiring approaches, which are all based on the scholars who have cited the method. In the last part, challenges and future trends are summarized. This survey would assist researchers who work on AI-empowered visual navigation systems.},
  archive      = {J_EAAI},
  author       = {Tianyao Zhang and Xiaoguang Hu and Jin Xiao and Guofeng Zhang},
  doi          = {10.1016/j.engappai.2022.105036},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105036},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A survey of visual navigation: From geometry to embodied AI},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RBM-GP with novel kernels coupled deep learning model for
autism screening. <em>EAAI</em>, <em>114</em>, 105034. (<a
href="https://doi.org/10.1016/j.engappai.2022.105034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autism Spectrum Disorder (ASD) assumes greater significance because of its worldwide prevalence and the need to detect it in its preliminary stage is imperative. No standard medical test exists universally to screen autism. Each and every aspect of our life proves that nature holds the reign. This could be well demonstrated through many prevailing research works which still fails to classify ASD individuals accurately. In the proposed work, a unique framework, RBM-GP (Restricted Boltzmann Machine-Gaussian Process) along with two novel kernels namely RPR and RQ-P are proposed to address the need for automatic classification of ASD individuals and Typical Controls (TC) thereupon with minimum error. Slice Time Correction and Head Motion Correction are carried out as a preparatory step to take care of noisy fMRI (functional Magnetic Resonance Imaging) data. To make the best use of high dimensional fMRI data, the pre-processed fMRI data is normalized for further processing. In the proposed system, deep learning model is executed to extract non-handcrafted features from the pre-processed fMRI data with the notion of attaining less error during classification process. As a result, Bernoulli RBM acts as a feature extractor to derive highly discriminative fMRI features. In order to develop an effective computerized system for the classification of autistic subjects, GP regression, a machine learning classifier is employed in the proposed system to learn deep fMRI features. Kernel plays a vital role in the GP regression. So, RPR and RQ-P kernels are developed and integrated with GP in the proposed work for the accurate classification of autistic subjects. All datasets from the ABIDE I database are utilized for conducting the experiments. The proposed system achieves the minimum Mean Squared Error (MSE) of 20% for USM dataset with RPR kernel and CMU_b dataset with RQ-P kernel. The experimental results and comprehensive result analysis proclaim the superiority of the proposed system than the existing state-of-the-art approaches.},
  archive      = {J_EAAI},
  author       = {Kaviya Elakkiya M. and Dejey},
  doi          = {10.1016/j.engappai.2022.105034},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105034},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {RBM-GP with novel kernels coupled deep learning model for autism screening},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A turnaround control system to automatically detect and
monitor the time stamps of ground service actions in airports: A deep
learning and computer vision based approach. <em>EAAI</em>,
<em>114</em>, 105032. (<a
href="https://doi.org/10.1016/j.engappai.2022.105032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As it is widely known, several ground services are provided by the airports for the domestic and international flights of the commercial passenger aircraft. Some of these services are conducted during the period called as the turnaround which starts with the parking of the aircraft in the aprons before the flight and ends with their leave from the aprons for the flight. Turnaround processes achieved in short time periods allow using the limited airport resources including the service vehicles and staff effectively. In addition, commercial reputation losses and financial losses that may arise from delays can be reduced as well as the delay-associated turnaround penalties. In this article, a deep learning and computer vision based system that detects and allows monitoring the airport service actions is proposed. The proposed system is capable of analyzing all the primary ground services for an aircraft parking on its apron by employing the RGB video frame sequences obtained from a single fixed camera focusing on the apron. In the service detection and analysis modules of the proposed airport ground service analysis system, some deep learning-based subsystems and in-house-developed algorithms were included and utilized. For the training of the machine learning models, a study-specific dataset was used and the constructed learning models were evaluated on real-life cases. Experimental results obtained as a result of the performance evaluations show that the proposed system is quite successful with precision rates over 90% in the detection and analysis of the airport ground services. This study is one of the limited research studies in which deep learning and computer vision techniques have been applied to detect and analyze the ground service actions. The proposed system is also capable of real-time data processing/analysis and concurrent service action monitoring. Furthermore, it allows monitoring when the service is received by stamping the times of service start/end. In a consideration of industrial relevance or operational perspective, such a system may facilitate the airport ground service management noticeably and reduce the delay-associated costs caused by the timing of the ground services.},
  archive      = {J_EAAI},
  author       = {Serdar Yıldız and Onur Aydemir and Abbas Memiş and Songül Varlı},
  doi          = {10.1016/j.engappai.2022.105032},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105032},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A turnaround control system to automatically detect and monitor the time stamps of ground service actions in airports: A deep learning and computer vision based approach},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel intuitionistic fuzzy time series method based on
bootstrapped combined pi-sigma artificial neural network. <em>EAAI</em>,
<em>114</em>, 105030. (<a
href="https://doi.org/10.1016/j.engappai.2022.105030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intuitionistic fuzzy time series forecasting methods have been started to solve the forecasting problems in the literature. Intuitionistic fuzzy time series methods use both membership and non-membership values as auxiliary variables in their models. Because intuitionistic fuzzy sets take into consideration the hesitation margin and so the intuitionistic fuzzy time series models use more information than fuzzy time series models. The background of this study is about intuitionistic fuzzy time series forecasting methods. The study aims to propose a novel intuitionistic fuzzy time series method. It is expected that the proposed method will produce better forecasts than some selected benchmarks. The proposed method uses bootstrapped combined Pi-Sigma artificial neural network and intuitionistic fuzzy c-means. The combined Pi-Sigma artificial neural network is proposed for modelling the intuitionistic fuzzy relations. The proposed method is applied to different sets of SP&amp;500 stock exchange time series. The proposed method can provide more accurate forecasts than established benchmarks for the SP&amp;500 stock exchange time series. The most important contribution of the proposed method is that it creates statistical inference: probabilistic forecasting, confidence intervals and the empirical distribution of the forecasts. Moreover, the proposed method is better than the selected benchmarks for the SP&amp;500 data set.},
  archive      = {J_EAAI},
  author       = {Eren Bas and Erol Egrioglu and Emine Kolemen},
  doi          = {10.1016/j.engappai.2022.105030},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105030},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel intuitionistic fuzzy time series method based on bootstrapped combined pi-sigma artificial neural network},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Error model-oriented vibration suppression control of
free-floating space robot with flexible joints based on adaptive neural
network. <em>EAAI</em>, <em>114</em>, 105028. (<a
href="https://doi.org/10.1016/j.engappai.2022.105028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At the same time, considering the uncertain factors such as load variation, external interference and joint flexibility in engineering practice, a robust control method based on adaptive neural network is proposed. The dynamic model of free-floating space robot is established, and the error model caused by uncertain factors is deduced. Different from the traditional compensation algorithm that ignores the error model, a compensation controller based on Radial basis function neural network (RBFNN) is designed to approximate the error model. The approximation error is eliminated by robust controller to improve the control accuracy. In order to make full use of the nonlinear approximation ability of neural network, the error model is decomposed into four parts according to the input characteristics, and the neural network compensator is designed for separate and overall compensation, which further improves the control accuracy and robustness. The adaptive learning rates of network weights are designed to ensure online real-time adjustment without offline learning stage. A flexible compensator based on torque and a controller based on moment difference feedback controller (MDFC) are designed to suppress elastic vibration. Simulation and experimental studies show that the proposed strategy can have good compensation performance and robustness, and can better suppress elastic vibration, which proves the effectiveness and superiority of the proposed scheme.},
  archive      = {J_EAAI},
  author       = {Wenhui Zhang and Jinmiao Shen and Xiaoping Ye and Shuhua Zhou},
  doi          = {10.1016/j.engappai.2022.105028},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105028},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Error model-oriented vibration suppression control of free-floating space robot with flexible joints based on adaptive neural network},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Observer-based fixed-time adaptive fuzzy control for SbW
systems with prescribed performance. <em>EAAI</em>, <em>114</em>,
105026. (<a
href="https://doi.org/10.1016/j.engappai.2022.105026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a tracking control problem for Steer-by-Wire (SbW) systems with unmeasurable states, model uncertainty, and limited communication resources. An interval type-2 fuzzy logic system (IT2 FLS)-based fixed-time state observer are proposed to estimate the unavailable state. Different from the accurate model-based state observers and the observers with some additional assumptions, under the proposed observer, the extra conditions can be removed and the fixed-time convergence of observation error can be guaranteed. To save communication resources of the controller-to-actuator channels and achieve the prescribed tracking performance, an event-triggered prescribed performance control (PPC) scheme is proposed. Compared with these existing PPC methods, the computational complexity is reduced and a new prescribed performance function with fixed-time convergence is suggested to improve the steady-state and transient performance of the closed-loop system. The Zeno behavior of the event-triggered communication can be avoided. Simulations and experiments are carried out to demonstrate the effectiveness and superiority of the proposed control technique.},
  archive      = {J_EAAI},
  author       = {Yongfu Wang and Gang Luo and Dianhui Wang},
  doi          = {10.1016/j.engappai.2022.105026},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105026},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Observer-based fixed-time adaptive fuzzy control for SbW systems with prescribed performance},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Chance constrained dynamic optimization approach for single
machine scheduling involving flexible maintenance, production, and
uncertainty. <em>EAAI</em>, <em>114</em>, 105024. (<a
href="https://doi.org/10.1016/j.engappai.2022.105024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chance constraints are suitable for industrial process modeling under uncertain conditions, where constraints cannot be strictly satisfied or do not need to be fully satisfied. In this paper, a single machine scheduling problem involving flexible maintenance, production, and uncertainty is modeled as a chance constrained dynamic optimization problem (CCDOP). A novel method is proposed for transforming the CCDOP into an equivalent deterministic dynamic optimization problem (DOP) with fixed state jump times. Furthermore, by using the idea of l 1 penalty function and a smooth approximation technique, the resulting deterministic DOP becomes a smoothing penalty problem, which is a non-convex nonlinear parameter optimization problem (NNPOP) with simple bounds on the variables. To solve the NNPOP, a gradient-based stochastic search algorithm (GSSA) is developed based on a gradient-based adaptive search algorithm (GASA) and a novel stochastic search algorithm (NSSA). The convergence analysis result shows that the GSSA is a globally convergent algorithm. Finally, two numerical examples are used to illustrate the effectiveness of the proposed method. Numerical results show that the GSSA has excellent convergence behavior with robust computation feature, providing better results compared with the other typical methods.},
  archive      = {J_EAAI},
  author       = {Xiang Wu and Kanjian Zhang},
  doi          = {10.1016/j.engappai.2022.105024},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105024},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Chance constrained dynamic optimization approach for single machine scheduling involving flexible maintenance, production, and uncertainty},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pairwise control in swarm flocking with application to UAVs.
<em>EAAI</em>, <em>114</em>, 105023. (<a
href="https://doi.org/10.1016/j.engappai.2022.105023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a pairwise cooperative mode and control method to perform short-range cooperative missions of two specific UAVs in a swarm. The pair of UAVs can converge simultaneously to a specified distance and keep flocking with others. For pairwise control, we propose a new sliding mode control architecture including “Quadratic Error Sliding Surface” and “Sliding Mode Sign Multiplier”, which have the advantages of simple parameter design, high precision, and anti-disturbance ability. The proposed sliding surface is reachable, and the controller is stability which is proved based on the Lyapunov stability theory. Finally, to verify the influence of the pairwise control effect in swarm flight, simulations were carried out with a different number of UAVs based on the quadrotor nonlinear dynamic model. Compared with the classical control method, the simulations demonstrate the superiority in control accuracy.},
  archive      = {J_EAAI},
  author       = {Jintao Liu and Ming He and Peng Xu and Xiangyang Deng},
  doi          = {10.1016/j.engappai.2022.105023},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105023},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Pairwise control in swarm flocking with application to UAVs},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Prediction of ground surface settlement by shield tunneling
using XGBoost and bayesian optimization. <em>EAAI</em>, <em>114</em>,
105020. (<a
href="https://doi.org/10.1016/j.engappai.2022.105020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ground surface settlement caused by shield tunneling is a complex problem caused by multiple factors. Machine learning models can help in the nonlinear intelligent prediction of ground surface settlement caused by shield tunneling. At present, the Artificial Neural Network model and the Support Vector Machine model are the most widely used models for settlement prediction. Due to the black-box characteristics of these two models, they are inherently deficient in interpretability, which means it is difficult to provide guidance for engineering. To solve the problem of poor interpretability in the prediction of ground surface settlement using these two models, an ensemble learning algorithm called the XGBoost model is introduced. In order to select hyperparameters in XGBoost more efficiently, the Bayesian optimization is used for parameter search. In this study, 533 cases of ground surface settlement monitoring data from a shield tunnel construction project in a city were used. Compared with the prediction results of the ANN model and the SVM model, the XGBoost model has the advantages of prediction accuracy and interpretability, especially for the prediction of out-of-limit settlement points.},
  archive      = {J_EAAI},
  author       = {Jie Su and Yuzhe Wang and Xiaokai Niu and Shan Sha and Junyu Yu},
  doi          = {10.1016/j.engappai.2022.105020},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105020},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Prediction of ground surface settlement by shield tunneling using XGBoost and bayesian optimization},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A deep reinforcement learning-based cooperative approach for
multi-intersection traffic signal control. <em>EAAI</em>, <em>114</em>,
105019. (<a
href="https://doi.org/10.1016/j.engappai.2022.105019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Adaptive Traffic Signal Control ( ATSC ) in the multi-intersection system is considered as one of the most critical issues in Intelligent Transportation Systems ( ITS ). Among the proposed AI -based approaches, Deep Reinforcement Learning ( DRL ) has been largely applied while showing better performances. This paper proposes a new DRL -based cooperative approach for controlling multiple intersections. The problem is modelled as a Multi-Agent Reinforcement Learning ( MARL ) system, while each agent is trained to select the best action to control an intersection by obtaining information about its local lanes state. The cooperation aspect is manifested in this approach by considering the effect of the state, action and reward of neighbour agents in the process of policy learning. An intersection controller applies a Deep Q-Network ( DQN ) method, while transferring state, action and reward received from their neighbour agents to its own loss function during the learning process. The experimental results under different scenarios shows that the proposed approach outperforms many state-of-the-art approaches in terms of three metrics: Average Waiting Time ( AWT ), Average Queue Length ( AQL ) and Average Emission CO 2 ( AEC ). In addition, the cooperation between the different trained DRL -based controllers allows the system to continuously learn and improve its performance by interacting with the environment, particularly when the traffic is congested.},
  archive      = {J_EAAI},
  author       = {Tarek Amine Haddad and Djalal Hedjazi and Sofiane Aouag},
  doi          = {10.1016/j.engappai.2022.105019},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105019},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep reinforcement learning-based cooperative approach for multi-intersection traffic signal control},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Flight regimes recognition in actual operating conditions: A
functional data analysis approach. <em>EAAI</em>, <em>114</em>, 105016.
(<a href="https://doi.org/10.1016/j.engappai.2022.105016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Helicopters need adequate monitoring to prevent dynamic failures from excessively affecting components’ health status, increase the level of safety, and reduce operative costs. Health and Usage Monitoring Systems have been developed to monitor helicopters during their lifetime in the last few decades. Recent works demonstrated that despite analyzing physical components’ behavior over time, tracking the regimes performed during each flight contributes to estimating the aircraft’s health and usage status, paving the way for designing accurate prognostics algorithms. However, today, most regime recognition systems rely on data recorded during certification flights. It follows that the training regimes differ from the ones proposed in the prediction phase, which are acquired during helicopter actual operating conditions. This affects these recognition system performances. Aiming at overcoming this limitation, in this work, we proposed an unsupervised regimes recognition system capable of better handling the actual helicopter usage spectrum. In detail, we proposed a system based on an unsupervised learning paradigm, which leverages a soft-membership classification technique to account even for mixed regimes and transitions. In addition, the system represents data according to functional data analysis theory, which allows for considering the temporal relationship between samples in the classification process, often neglected in state-of-the-art approaches. The proposed system was tested on experimental data, collected by Leonardo Helicopter Division, assessing outstanding capabilities in recognizing correctly standard and mixed regimes and transients. Also, the presented results demonstrate the approach capabilities in paving the way for the definition of new regimes, more consistent with the actual helicopter usage spectrum.},
  archive      = {J_EAAI},
  author       = {Jessica Leoni and Francesco Zinnari and Eugenia Villa and Mara Tanelli and Andrea Baldi},
  doi          = {10.1016/j.engappai.2022.105016},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105016},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Flight regimes recognition in actual operating conditions: A functional data analysis approach},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mars-TRP: Classification of mars imagery using dynamic
polling between transferred features. <em>EAAI</em>, <em>114</em>,
105014. (<a
href="https://doi.org/10.1016/j.engappai.2022.105014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Expeditions on Mars and interest in research orienting around these exploration missions have been accelerating more than ever, recently. Due to lack of active human interference in Mars missions, processing and accurate classification of images taken by the rovers is a very essential part of the system. Proper identification of landforms governs the accessibility of the mobile rovers on Mars’ surface. Moreover, NASA has already collected over two million images from the planet, and more volumes are yet to arrive as these photographs serve as major documents for photogrammetry and studies based on remote sensing. Automatic labeling of incoming images and also making searching of the image database easier in the public interest requires highly accurate image classifiers. Deriving motivation from the above causes, this study intends to implement an efficient supervised multi-class image classifier for identifying Mars imagery. However, this objective is confronted by a major bottleneck. Most datasets that are accurately labeled, portray a highly skewed nature and insufficient data to train a deep model from scratch. The MSL surface imagery labeled dataset captured by the Curiosity rover, that has been considered for this study, is one such dataset with only 6691 images distributed unevenly into 25 classes. These obstacles are less signified in the existing literature and hence this paper addresses these challenges, outperforming the state-of-the-art metrics. Due to the absence of large data volume, a transfer learning based methodology was considered, using very deep convolutional networks pre-trained on ImageNet dataset. But images from Mars often involve a difference in hue, contrast and clarity when compared with images taken on Earth. Hence, the deep model was fine-tuned with our dataset and the extracted feature from the tuned neural network was used for the final classification. It was found that the results obtained from a single pre-trained model were not optimum and that ensemble approaches could unify many such results into a better result. Similar feature vectors were extracted from a few other pre-trained models. The whole setup converges into a dynamic routing module, a novel polling algorithm, which for each image, comes to an agreement about the best set of features while generating the output probability vector. The proposed approach is evaluated by several numeric metrics like accuracy, precision and recall, confusion matrices and roc curves, against the chosen individual pre-trained models and most prominent ensemble methods. Mars-TRP produces a test accuracy of around 88% in the standard test set of MSL surface dataset and an accuracy of 96% in the HiRise dataset, outperforming the individual pre-trained models, all the ensemble baselines and other existing approaches.},
  archive      = {J_EAAI},
  author       = {Arpan Nandi and Arjun Mallick and Arkadeep De and Asif Iqbal Middya and Sarbani Roy},
  doi          = {10.1016/j.engappai.2022.105014},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105014},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Mars-TRP: Classification of mars imagery using dynamic polling between transferred features},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pairnorm based graphical convolution network for zero-shot
multi-label classification. <em>EAAI</em>, <em>114</em>, 105012. (<a
href="https://doi.org/10.1016/j.engappai.2022.105012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot learning transfers the knowledge from the seen labels available during training to the unseen labels. In this paper, we propose a Pairnorm based Graphical Convolution Network for zero-shot multi-label classification (ML-ZSLPGCN). The proposed approach uses the label features obtained from the images during training and semantic embedding for the unseen labels. The ML-ZSLPGCN first creates the features corresponding to the images, and the label aware module creates the feature vector of the labels corresponding to the seen labels using the attention region embedding. A graphical convolution network takes the feature vector of seen labels during training and semantic word embedding for the unseen labels as input and learns the classifier. The proposed approach uses a pairnorm-based normalization scheme to tackle the over smoothing problem in the graphical convolution network. The experimental results on the NUSWIDE and MS-COCO datasets show that the proposed approach provides significant performance in terms of precision, recall, and F1 score in comparison to state-of-the-art approaches.},
  archive      = {J_EAAI},
  author       = {Vikas Chauhan and Aruna Tiwari},
  doi          = {10.1016/j.engappai.2022.105012},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105012},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Pairnorm based graphical convolution network for zero-shot multi-label classification},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Complex probabilistic fuzzy set and their aggregation
operators in group decision making extended to TOPSIS. <em>EAAI</em>,
<em>114</em>, 105010. (<a
href="https://doi.org/10.1016/j.engappai.2022.105010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Randomness and fuzziness create uncertainty in the system at the same time. To combine randomness and cognitive uncertainty into a single paradigm and incorporate more data, this article focuses on developing complex probabilistic fuzzy set. The main intention of this article is to develop a method that can solve both statistical and non-statistical uncertainties. Statistical uncertainty depicts the type of uncertainty concerning the possibility of a future event occurring and non-statistical uncertainties denote the concept of partial truth and imprecise reason. Here, statistical uncertainty is given through probability and non-statistical uncertainty is denoted via the complex fuzzy sets and are incorporated together to form the complex probabilistic fuzzy set. This combination summarizes the importance of this article as they could depict the real life situations more precisely. Proposing the complex probabilistic fuzzy set and studying its basic operations are the article’s main contributions. Also, various aggregation operators are developed for the same and their essential properties are duely explained. Further on, these operators are extended to TOPSIS which is utilized for a group decision making problem with data obtained in the form of complex probabilistic fuzzy number to find the best site for construction of ethanol plant to produce biofuel. The main reason for considering TOPSIS here is because it is a concept that formulates a scalar value taking into consideration both the best and worst alternatives, it represents the rationale of human choice in a more simplistic and straightforward logic and also, it takes less computation time.},
  archive      = {J_EAAI},
  author       = {Janani K. and Rakkiyappan R.},
  doi          = {10.1016/j.engappai.2022.105010},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105010},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Complex probabilistic fuzzy set and their aggregation operators in group decision making extended to TOPSIS},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning for image colorization: Current and future
prospects. <em>EAAI</em>, <em>114</em>, 105006. (<a
href="https://doi.org/10.1016/j.engappai.2022.105006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image colorization, as an essential problem in computer vision (CV), has attracted an increasing amount of researchers attention in recent years, especially deep learning-based image colorization techniques(DLIC). Generally, most recent image colorization methods can be regarded as knowledge-based systems because they are usually trained by big datasets. Unlike the existing reviews, this paper adopts a unique deep learning-based perspective to review the latest progress in image colorization techniques systematically and comprehensively. In this paper, a comprehensive review of recent DLIC approaches from algorithm classification to existing challenges is provided to facilitate researchers’ in-depth understanding of DLIC. In particular, we review DLIC algorithms from various perspectives, including color space, network structure, loss function, level of automation, and application fields. Furthermore, other important issues are discussed, such as publicly available benchmark datasets and performance evaluation metrics. Finally, we discuss several open issues of image colorization and outline future research directions. This survey can serve as a reference for researchers in image colorization and related fields.},
  archive      = {J_EAAI},
  author       = {Shanshan Huang and Xin Jin and Qian Jiang and Li Liu},
  doi          = {10.1016/j.engappai.2022.105006},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105006},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep learning for image colorization: Current and future prospects},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MF2-net: A multipath feature fusion network for medical
image segmentation. <em>EAAI</em>, <em>114</em>, 105004. (<a
href="https://doi.org/10.1016/j.engappai.2022.105004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a multipath feature fusion convolutional neural network (MF2-Net) with novel and efficient spatial group convolution (SGC) modules with a multipath feature fusion network for the automated segmentation of medical images. The proposed MF2-Net was designed with multiple encoder paths to extract layer-specific multiscale information. Each encoder path employs SGC modules composed of stacked asymmetric kernels of different sizes ( k × 1 and 1 × k ). In the SGC modules, the context details of high-level features are encoded at varying scales, and neighbor feature information is incorporated with higher precision. In addition, the encoded features fused at the bottleneck layer capture abundant semantic features from input images. Furthermore, the guided block mechanism is used to refine the segmentation boundaries at the decoder stage by integrating the skip connection from the encoder stage. We verified that the SGC modules in a multipath feature fusion network improve the segmentation accuracy with fewer learnable parameters. Experimental results demonstrated that the proposed model outperformed existing medical image segmentation methods by an average score of 0.97 on publicly available datasets.},
  archive      = {J_EAAI},
  author       = {Nagaraj Yamanakkanavar and Bumshik Lee},
  doi          = {10.1016/j.engappai.2022.105004},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105004},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MF2-net: A multipath feature fusion network for medical image segmentation},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-agent cooperative structural vibration control of
three coupled flexible beams based on value decomposition network.
<em>EAAI</em>, <em>114</em>, 105002. (<a
href="https://doi.org/10.1016/j.engappai.2022.105002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-coupled flexible body (MCFB) structure has the characteristics of small damping, close modes and coupled vibration, and the structural vibration is difficult to freely attenuate, which will lead to rapid fatigue failure of the structure. In order to suppress the vibration of the MCFB system quickly, a system identification scheme and a multi-agent reinforcement learning (MARL) scheme are proposed to obtain the cooperative controller. The mathematical model of the three-coupled flexible beam (TCFB) system is identified by wavelet analysis method, particle swarm optimization (PSO) and sinusoidal excitation response method. Based on value decomposition network (VDN) and deterministic policy gradient (DPG), a cooperative MARL framework is constructed to obtain the controller (VDN-DPG controller). The cooperative VDN-DPG controller is applied to the vibration control simulation and experiments of the TCFB system, and compared with proportional–derivative (PD) control without cooperation. The results show that the performance of the VDN-DPG controller is better than that of the PD controller, which verifies the effectiveness of the multi-agent cooperative control scheme based on VDN-DPG.},
  archive      = {J_EAAI},
  author       = {Zhi-cheng Qiu and Cheng-hu He and Xian-min Zhang},
  doi          = {10.1016/j.engappai.2022.105002},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105002},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-agent cooperative structural vibration control of three coupled flexible beams based on value decomposition network},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A siren identification system using deep learning to aid
hearing-impaired people. <em>EAAI</em>, <em>114</em>, 105000. (<a
href="https://doi.org/10.1016/j.engappai.2022.105000">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The research presented in this paper is aiming to address the safety issue that hearing-impaired people are facing when it comes to identifying a siren sound. For that purpose, a siren identification system, using deep learning, was designed, built, and tested. The system consists of a convolutional neural network that used image recognition techniques to identify the presence of a siren by converting the incoming sound into spectrograms. The problem with the lack of datasets for the training of the network was addressed by generating the appropriate data using a variety of siren sounds mixed with relevant environmental noise. A hardware interface was also developed to communicate the detection of a siren with the user, using visual methods. After training the model, the system was extensively tested using realistic scenarios to assess its performance For the siren sounds that were used for training, the system achieved an accuracy of 98 per cent. For real-world siren sounds, recorded in the central streets of London, the system achieved an accuracy of 91 per cent. When it comes to the operation of the system in noisy environments, the tests showed that the system can identify the presence of siren when this is at a sound level of up to -6 db below the background noise. These results prove that the proposed system can be used as a base for the design of a siren-identification application for hearing-impaired people.},
  archive      = {J_EAAI},
  author       = {Arturo Esquivel Ramirez and Eugenio Donati and Christos Chousidis},
  doi          = {10.1016/j.engappai.2022.105000},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {105000},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A siren identification system using deep learning to aid hearing-impaired people},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Novel energy management scheme in IoT enabled smart
irrigation system using optimized intelligence methods. <em>EAAI</em>,
<em>114</em>, 104996. (<a
href="https://doi.org/10.1016/j.engappai.2022.104996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, due to the growing global population and increased food demand, smart agriculture is becoming more vital. In this context, Internet of Things (IoT) technologies have emerged as a significant pathway to innovative agricultural techniques. Due to their low capacity, these IoT nodes have faced energy limits and complicated routing methods. As a result, in the sphere of IoT-based agriculture, transmitting data failure, energy consumption, network lifetime reduction, and delay occur. To overcome this problem, this study proposes a novel combination of optimized intelligent smart irrigation systems to improve the energy management performance of the system. Here, the optimal cluster head formation and selection is performed by Hierarchy Shuffled Shepherd Clustering (HSSC) method. Also, the finest energy regulation and routing path are provided by the proposed Emperor Penguin Jellyfish Optimizer (EPJO) method. The simulation of this work is performed on Network Simulator-2 (NS2) software. The simulation consequences from the proposed method are validated and compared with the conventional methods. Thus, the proposed approach results demonstrate that the developed model has much lesser energy consumption and improved network lifetime as compared to the traditional works.},
  archive      = {J_EAAI},
  author       = {Asif Irshad Khan and Fawaz Alsolami and Fahad Alqurashi and Yoosef B. Abushark and Iqbal H. Sarker},
  doi          = {10.1016/j.engappai.2022.104996},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104996},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Novel energy management scheme in IoT enabled smart irrigation system using optimized intelligence methods},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A review of visual SLAM methods for autonomous driving
vehicles. <em>EAAI</em>, <em>114</em>, 104992. (<a
href="https://doi.org/10.1016/j.engappai.2022.104992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous driving vehicles require both a precise localization and mapping solution in different driving environment. In this context, Simultaneous Localization and Mapping (SLAM) technology is a well-study settlement. Light Detection and Ranging (LIDAR) and camera sensors are commonly used for localization and perception. However, through ten or twenty years of evolution, the LIDAR-SLAM method does not seem to have changed much. Compared with the LIDAR based schemes, the visual SLAM has a strong scene recognition ability with the advantages of low cost and easy installation. Indeed, people are trying to replace LIDAR sensors with camera only, or integrating other sensors on the basis of camera in the field of autonomous driving. Based on the current research situation of visual SLAM, this review covers the visual SLAM technologies. In particular, we firstly illustrated the typical structure of visual SLAM. Secondly, the state-of-the-art studies of visual and visual-based (i.e. visual-inertial, visual-LIDAR, visual-LIDAR-IMU) SLAM are completely reviewed, as well the positioning accuracy of our previous work are compared with the well-known frameworks on the public datasets. Finally, the key issues and the future development trend of visual SLAM technologies for autonomous driving vehicles applications are discussed.},
  archive      = {J_EAAI},
  author       = {Jun Cheng and Liyan Zhang and Qihong Chen and Xinrong Hu and Jingcao Cai},
  doi          = {10.1016/j.engappai.2022.104992},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104992},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A review of visual SLAM methods for autonomous driving vehicles},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine-learning-based hybrid recognition approach for
longitudinal driving behavior in noisy environment. <em>EAAI</em>,
<em>114</em>, 104990. (<a
href="https://doi.org/10.1016/j.engappai.2022.104990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driving behavior recognition has attracted wide attention as it can act as an important reference input of many vehicle intelligent control systems. In this paper, a real-time recognition of driver’s longitudinal driving behavior is investigated by proposing a hybrid adaptive pattern recognition method. Firstly, a framework of integrated behavior recognition model is established consisting of two sub models to cluster and label the sample data, respectively. Secondly, a new fast high-stability clustering method is proposed to solve the problem of clustering samples with non-negligible noise. And the test results show the clustering process can be completed within a short time lower than 0.1 s with different number of cluster centers. Then, support vector machine and artificial neural network are employed and trained to construct a heuristic self-labeling approach to label the clustered sample automatically in real time with high accuracy (92.9%) under an experimental driving cycle generated from our real-vehicle test bench. Subsequently, the two established modules are integrated and offline trained by 96 thousand historical data, and employed to a 400-second-long online application under a smoothly-varying driving condition, and three further applications under extreme driving cycles with about 1000 s, respectively. Simulation results show that the proposed integrated model is capable of eliminating the interference of noise, and has a relatively stable performance of recognition for different driving cycles with different driving behaviors (92.7% of overall performance for commonly cycles, and greater than 91.2% for extreme cycles), enhancing the capacity for online application.},
  archive      = {J_EAAI},
  author       = {Haochen Sun and Zhumu Fu and Fazhan Tao and Yongsheng Dong and Baofeng Ji},
  doi          = {10.1016/j.engappai.2022.104990},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104990},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Machine-learning-based hybrid recognition approach for longitudinal driving behavior in noisy environment},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semi-supervised sparse neighbor constrained co-clustering
with dissimilarity and similarity regularization. <em>EAAI</em>,
<em>114</em>, 104989. (<a
href="https://doi.org/10.1016/j.engappai.2022.104989">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonnegative matrix factorization (NMF) is a very effective method for high dimensional data analysis, which has been widely used in computer vision. However, the conventional NMF is unsupervised, and thus, it cannot utilize the label information. To this end, semi-supervised NMF is proposed, which performs the NMF with the guidance of the supervisory information. However, semi-supervised NMF fails to make full use of label information, which limits the performance of clustering using low dimensional representation, and samples and features cannot be clustered in a mutually reinforcing manner. To solve the above shortcomings, we propose a semi-supervised sparse neighbor constrained co-clustering with dissimilarity and similarity regularization model (SSCCDS). First, co-clustering is introduced to cluster samples and features simultaneously. Secondly, the model imposes similarity and dissimilarity regularization constraints on samples by low-dimensional representations. Specifically, similarity and dissimilar regularization constraints are imposed on labeled samples, and similarity regularization constraints are imposed on unlabeled data. Thirdly, the model proposes sparse neighbor constraints for feature consistent learning. Then, a multiplicative alternating scheme is proposed for objective optimization. A large number of experiments on different data sets show that SSCCDS has good clustering ability.},
  archive      = {J_EAAI},
  author       = {Xiangli Li and Xiyan Lu and Xuezhen Fan},
  doi          = {10.1016/j.engappai.2022.104989},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104989},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Semi-supervised sparse neighbor constrained co-clustering with dissimilarity and similarity regularization},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Adaptive multi-view multiple-means clustering via subspace
reconstruction. <em>EAAI</em>, <em>114</em>, 104986. (<a
href="https://doi.org/10.1016/j.engappai.2022.104986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is a notable research topic, but it is still challenging when facing massive multi-view data from different ways or multiple feature extractors. The crucial problem is how to promote cooperative learning between views via subspace reconstruction while preserving the underlying geometric structure of data. Moreover, most existing methods habitually utilize K-means to achieve the final results, which is not conducive to dealing with intricate non-convex patterns in multi-perspective data. Based on the above consideration, in this paper, we present a fresh multi-view clustering approach called Adaptive Multi-view Multiple-Means Clustering via Subspace Reconstruction(AM 2 CSR). AM 2 CSR aims to simultaneously capture compatible, complementary, geometric, and discrimination information among multiple views. Subsequently, a low-rank restriction is forced on the low-dimensional representation to reduce redundancy, and K-Multiple-Means(KMM) is adopted as the clustering technique to achieve satisfying results. Additionally, an effective iteration updating method with a convergence guarantee is applied to settle the optimization matter of AM 2 CSR. Extensive empirical experiments on eight benchmark datasets exhibit the superiority of AM 2 CSR.},
  archive      = {J_EAAI},
  author       = {Wenzhe Liu and Luyao Liu and Yong Zhang and Huibing Wang and Lin Feng},
  doi          = {10.1016/j.engappai.2022.104986},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104986},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive multi-view multiple-means clustering via subspace reconstruction},
  volume       = {114},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Energy forecasting model based on CNN-LSTM-AE for many time
series with unequal lengths. <em>EAAI</em>, <em>113</em>, 104998. (<a
href="https://doi.org/10.1016/j.engappai.2022.104998">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy is an exceptional commodity, this way, governments and distributors aim to avoid excessive purchase/consumption of electricity through enhanced operational strategy to ensure that energy supply fits the demand at every moment. The consumption prediction is a time series problem where the data may contain uncertainty, missing values, etc. Given the irregular trend and seasonal patterns, accurately predict energy consumption is a difficult problem. Most forecasting methods have been developed to forecasting individual or small groups of time series. In this work, we focus on short-term forecasting in many time series with unequal lengths. Many time series is a challenge since we usually need many dedicated models each forecasting one time series. In this work, we proposed a methodology to process the data and a deep learning approach based on LSTM, CNN, and auto-encoder for training only one model for the many time series. Compared to Temporal Convolutional Network model (TCN) we achieved smaller error measures on the dataset related to energy consumption from a real energy distributor in Brazil. Statistical approaches such as SARIMAX and Prophet achieved small error measures, however, they need to train n models, one for each time series in the dataset, which can be unfeasible in practice.},
  archive      = {J_EAAI},
  author       = {Rodney Rick and Lilian Berton},
  doi          = {10.1016/j.engappai.2022.104998},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104998},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Energy forecasting model based on CNN-LSTM-AE for many time series with unequal lengths},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimal vibration isolation and alignment over non-rigid
bases with the CRO-SL ensemble. <em>EAAI</em>, <em>113</em>, 104984. (<a
href="https://doi.org/10.1016/j.engappai.2022.104984">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes the design of both Single-Input–Single-Output (SISO) and Multiple-Input–Multiple-Output (MIMO) isolation controllers, when the interaction between the isolator system and the base structure is considered. The problem to be addressed is based on the reduction of the vibration of every platform, and also on the alignment between the different isolators. Both techniques, SISO and MIMO, are optimally tuned by the recently-proposed Coral Reefs Optimisation with Substrate Layers (CRO-SL), a multi-method ensemble evolutionary approach. In the proposed design, the stability of both systems (the isolators and the supporting structure) is verified. Also, the importance of considering the supporting structure dynamic is shown, by comparing the results with those obtained when the base structure is assumed to be rigid and infinitely heavy. This work shows considerable and not obvious improvements when the interaction between the isolator system and the base frame is considered. Numerical examples are included to illustrate the significant differences between using SISO and MIMO cases, and to motivate the use of CRO-SL. In addition, a real application example is analysed based on experimental data. Verified practical guidelines to be followed in experimental tests are finally shown.},
  archive      = {J_EAAI},
  author       = {J. Pérez-Aracil and C. Camacho-Gómez and P. Reynolds and E. Pereira and S. Salcedo-Sanz},
  doi          = {10.1016/j.engappai.2022.104984},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104984},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimal vibration isolation and alignment over non-rigid bases with the CRO-SL ensemble},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modeling bidding decisions and bid markup size for
construction projects: A fuzzy approach. <em>EAAI</em>, <em>113</em>,
104982. (<a
href="https://doi.org/10.1016/j.engappai.2022.104982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous studies of construction contract auction bidding have mainly focused on finding factors affecting the markup and decision to bid (d2b), without considering expert weight and critical factors as input variables for estimating the size of markup needed. This study develops a 3-step Mamdani-type of Fuzzy Inference System (FIS) identifying critical factors and predicting markups for construction projects. The first step models the wights of 31 construction experts based on their characteristics (i.e., experience and academic qualifications). The second step models frequency, severity, and importance weights for each factor to find the rank and priority of the factors, revealing the critical factors to be current workload, project (contract) size, need for work, availability of labor and staff required, project owner, and duration. The third step takes the importance weight of each factor from the previous step and the contractor’s evaluation of the frequency of the factors as input variables to predict the bid markup. The model is demonstrated and tested with two actual construction projects having actual markups of 20% and 45%, and the predicted markups are found to be 26.3% and 42% respectively, which ensures reliable outcomes in assessing contractors’ bidding decisions. It is a novel model that can simultaneously identify critical factors and predict an optimal markup in assisting contractors’ d2b for the construction auctions and developing risk management plans. Future research can optimize this model by incorporating competitors’ bids and enhancing prediction accuracy to guarantee the lowest price with a reasonable profit margin.},
  archive      = {J_EAAI},
  author       = {Ibrahim S. Zaqout and Muhammad Saiful Islam and Laith A. Hadidi and Martin Skitmore},
  doi          = {10.1016/j.engappai.2022.104982},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104982},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Modeling bidding decisions and bid markup size for construction projects: A fuzzy approach},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An opposition learning and spiral modelling based arithmetic
optimization algorithm for global continuous optimization problems.
<em>EAAI</em>, <em>113</em>, 104981. (<a
href="https://doi.org/10.1016/j.engappai.2022.104981">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In engineering applications, many real-world optimization problems are nonlinear with multiple local optimums. Traditional algorithms that require gradients are not suitable for these problems. Meta-heuristic algorithms are popularly employed to deal with these problems because they can promisingly jump out of local optima and do not need any gradient information. The arithmetic optimization algorithm (AOA), a recently developed meta-heuristic algorithm, uses arithmetic operators (multiplication, division, subtraction, and addition) to solve optimization problems including nonlinear ones. However, the exploration and exploitation of AOA are not effective to handle some complex optimization problems. In this paper, an opposition learning and spiral modelling based AOA, namely OSAOA, is proposed for enhancing the optimization performance. It improves AOA from two perspectives. In the first perspective, the opposition-based learning (OBL) is committed to taking both candidate solutions and their opposite solutions into consideration for improving the global search with a high probability of jumping out of local minima. Then, the spiral modelling is introduced as the second perspective, which is particularly useful in getting the solutions gathering faster and accelerating the convergence speed in the later stage. In addition, OSAOA is compared with other existing advanced meta-heuristic algorithms based on 23 benchmark functions and four engineering problems: the three-bar truss design, the cantilever beam design, the pressure vessel design, and the tubular column design. From our simulations and engineering applications, the proposed OSAOA can provide better optimization results in dealing with these real-world optimization problems.},
  archive      = {J_EAAI},
  author       = {Yang Yang and Yuchao Gao and Shuang Tan and Shangrui Zhao and Jinran Wu and Shangce Gao and Tengfei Zhang and Yu-Chu Tian and You-Gan Wang},
  doi          = {10.1016/j.engappai.2022.104981},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104981},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An opposition learning and spiral modelling based arithmetic optimization algorithm for global continuous optimization problems},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A 3D-CAE-CNN model for deep representation learning of 3D
images. <em>EAAI</em>, <em>113</em>, 104978. (<a
href="https://doi.org/10.1016/j.engappai.2022.104978">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Representation Learning technologies based on supervised Convolutional Neural Networks (CNNs) have attained significant interest mainly due to their superior performance for learning abstract and robust features used in object detection and image classification tasks. However, to efficiently train such models requires a large number of labeled instances especially when these instances are high dimensional such as for 3-Dimensional (3D) Image inputs. Due to this extra dimension the dimensionality of such instances increases drastically. Therefore, the utilization of Unsupervised CNNs topologies such 3D Convolutional AutoEncoders (3D-CAE) have also been proposed. CAEs can learn features (and later used for classification tasks using common machine learning classifiers), without relying on instance labels and thus they are not prone to label limitation. Nevertheless, it is not clear if the features that CAEs learn, are relevant regarding the classification or object detection task since these features are learned via no target output class. For these reasons, in this work we combine 3D-CAE and 3D-CNN to work synergistically together in order to build a hybrid deep representation learning framework model which exploits the advantages of both unsupervised and supervised representation/feature learning approaches, applied on 3D Image inputs. In order to evaluate our strategy, we performed extensive experimental simulations for the DeepFake and Pneumonia detection problems utilizing Video and 3D Scans datasets respectively. Our proposed framework outperformed all the other utilized frameworks, revealing the efficiency of our applied methodology.},
  archive      = {J_EAAI},
  author       = {Emmanuel Pintelas and Panagiotis Pintelas},
  doi          = {10.1016/j.engappai.2022.104978},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104978},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A 3D-CAE-CNN model for deep representation learning of 3D images},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimal scheduling for palletizing task using robotic arm
and artificial bee colony algorithm. <em>EAAI</em>, <em>113</em>,
104976. (<a
href="https://doi.org/10.1016/j.engappai.2022.104976">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Palletizing using robotic arms is a common aspect of industrial robotization. Due to its efficiency, the robotic arm is often able to handle more then one production line. In such a case, the proper decision of selecting an item from one of several production lines will affect the overall efficiency. In this paper, three production lines handled by a single robotic arm are considered. Cycle time and maximum allowable waiting time of each item is taken into account. The authors proposed four different objective functions related to possible requirements in a factory environment, which led to constrained multi-objective optimization problems. To solve such a problem, the Artificial Bee Colony algorithm supported by Deb’s rules has been applied. The obtained results have been compared with three basic decision mechanisms , and also with the Reinforcement Learning approach. It was shown that the proposed approach significantly increases the production rate and satisfies the particular requirements, i.e., minimum energy per palletized item ratio, equality of containers’ filling.},
  archive      = {J_EAAI},
  author       = {Rafal Szczepanski and Krystian Erwinski and Mateusz Tejer and Artur Bereit and Tomasz Tarczewski},
  doi          = {10.1016/j.engappai.2022.104976},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104976},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimal scheduling for palletizing task using robotic arm and artificial bee colony algorithm},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Regularized nonlinear regression for simultaneously
selecting and estimating key model parameters: Application to head-neck
position tracking. <em>EAAI</em>, <em>113</em>, 104974. (<a
href="https://doi.org/10.1016/j.engappai.2022.104974">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In system identification, estimating parameters of a biomechanical model using limited observations results in poor identifiability. To cope with this issue, we propose a new method to simultaneously select and estimate sensitive parameters as key model parameters while fixing the remaining parameters to a set of typical values. The problem is formulated as a nonlinear least-squares estimator with L 1 -regularization on the deviation of parameters from a set of typical values. In addition, a modified optimization approach is introduced to find the solution to the formulated problem. As a result, we provided consistency and oracle properties of the proposed estimator as a theoretical foundation. To show the effectiveness of the proposed method, we conducted simulation and experimental studies. In the simulation study, the proposed Lasso performed significantly better than the ordinary L 1 -regularization methods in terms of the bias and variance of the parameter estimates. The experimental study presented an application identifying a biomechanical parametric model of a head position tracking task for ten human subjects from limited data. Compared with the variance of the parameter estimates from nonlinear ordinary least-squares regression, that of parameter estimates from the proposed Lasso decreased by 96% using the simulated data. Using the real-world data, the variance of estimated parameters decreased by 71%. In addition, the proposed method kept variance accounted for (VAF) at 83% and was 54 times faster than the ordinary Lasso using a standard simplex-based optimization algorithm.},
  archive      = {J_EAAI},
  author       = {Kyubaek Yoon and Hojun You and Wei-Ying Wu and Chae Young Lim and Jongeun Choi and Connor Boss and Ahmed Ramadan and John M. Popovich Jr. and Jacek Cholewicki and N. Peter Reeves and Clark J. Radcliffe},
  doi          = {10.1016/j.engappai.2022.104974},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104974},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Regularized nonlinear regression for simultaneously selecting and estimating key model parameters: Application to head-neck position tracking},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Active learning of driving scenario trajectories.
<em>EAAI</em>, <em>113</em>, 104972. (<a
href="https://doi.org/10.1016/j.engappai.2022.104972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Annotated driving scenario trajectories are crucial for verification and validation of autonomous vehicles. However, annotation of such trajectories based only on explicit rules (i.e. knowledge-based methods) may be prone to errors, such as false positive/negative classification of scenarios that lie on the border of two scenario classes, missing unknown scenario classes, or even failing to detect anomalies. On the other hand, verification of labels by annotators is not cost-efficient. For this purpose, active learning (AL) could potentially improve the annotation procedure by including an annotator/expert in an efficient way. In this study, we develop a generic active learning framework to annotate driving trajectory time series data. We first compute an embedding of the trajectories into a latent space in order to extract the temporal nature of the data. Given such an embedding, the framework becomes task agnostic since active learning can be performed using any classification method and any query strategy, regardless of the structure of the original time series data. Furthermore, we utilize our active learning framework to discover unknown driving scenario trajectories. This will ensure that previously unknown trajectory types can be effectively detected and included in the labeled dataset. We evaluate our proposed framework in different settings on novel real-world datasets consisting of driving trajectories collected by Volvo Cars Corporation. We observe that active learning constitutes an effective tool for labeling driving trajectories as well as for detecting unknown classes. Expectedly, the quality of the embedding plays an important role in the success of the proposed framework.},
  archive      = {J_EAAI},
  author       = {Sanna Jarl and Linus Aronsson and Sadegh Rahrovani and Morteza Haghir Chehreghani},
  doi          = {10.1016/j.engappai.2022.104972},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104972},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Active learning of driving scenario trajectories},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Light-field image watermarking based on geranion polar
harmonic fourier moments. <em>EAAI</em>, <em>113</em>, 104970. (<a
href="https://doi.org/10.1016/j.engappai.2022.104970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Light-field images provide a spatial and angular description of the light, and they can capture rich visual information in the natural world. In recent years, the research on light-field imaging has achieved many fruitful results. As more and more people are now focusing their attention to light-field imaging, the copyright protection of light-field images has become an urgent problem that needs to be addressed. Digital watermarking can effectively protect the copyright ownership of light-field images. Currently, there exists no light-field image watermarking scheme that can resist various geometric attacks. In this work, relying on geranion theory and polar harmonic Fourier moments (PHFMs), geranion polar harmonic Fourier moments (GPHFMs) are constructed and utilized for light-field image watermarking. The geranion represents a hypercomplex number containing one real part and thirty-one imaginary parts, and the imaginary parts of geranion can be used to encode multiple image color components while maintaining the correlation between each component. GPHFMs are stable image features, with good image reconstruction ability and stability. Essentially, the light-field image watermarking based on GPHFMs offers good imperceptibility and robustness, can resist various attacks, and effectively solves the problem of current watermarking schemes related to their inability of resisting geometric attacks. Furthermore, it is verified through experiments that the proposed scheme is more robust than the previously reported schemes.},
  archive      = {J_EAAI},
  author       = {Chunpeng Wang and Qinghua Zhang and Bin Ma and Zhiqiu Xia and Jian Li and Ting Luo and Qi Li},
  doi          = {10.1016/j.engappai.2022.104970},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104970},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Light-field image watermarking based on geranion polar harmonic fourier moments},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Co-optimizing for task performance and energy efficiency in
evolvable robots. <em>EAAI</em>, <em>113</em>, 104968. (<a
href="https://doi.org/10.1016/j.engappai.2022.104968">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary robotics is concerned with optimizing autonomous robots for one or more specific tasks. Remarkably, the energy needed to operate autonomously is hardly ever considered. This is quite striking because energy consumption is a crucial factor in real-world applications and ignoring this aspect can increase the reality gap. In this paper, we aim to mitigate this problem by extending our robot simulator framework with a model of a battery module and studying its effect on robot evolution. The key idea is to include energy efficiency in the definition of fitness. The robots will need to evolve to achieve high gait speed and low energy consumption. Since our system evolves the robots’ morphologies as well as their controllers, we investigate the effect of the energy extension on the morphologies and on the behavior of the evolved robots. The results show that by including the energy consumption, the evolution is not only able to achieve higher task performance (robot speed), but it reaches good performance faster. Inspecting the evolved robots and their behaviors discloses that these improvements are not only caused by better morphologies, but also by better settings of the robots’ controller parameters.},
  archive      = {J_EAAI},
  author       = {Margarita Rebolledo and Daan Zeeuwe and Thomas Bartz-Beielstein and A.E. Eiben},
  doi          = {10.1016/j.engappai.2022.104968},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104968},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Co-optimizing for task performance and energy efficiency in evolvable robots},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online continual learning via the meta-learning update with
multi-scale knowledge distillation and data augmentation. <em>EAAI</em>,
<em>113</em>, 104966. (<a
href="https://doi.org/10.1016/j.engappai.2022.104966">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual learning aims to rapidly and continually learn the current task from a sequence of tasks, using the knowledge obtained in the past, while performing well on prior tasks. A key challenge in this setting is the stability–plasticity dilemma existing in current and previous tasks, i.e., a high-stability network is weak to learn new knowledge in an effort to maintain previous knowledge. Correspondingly, a high-plasticity network can easily forget old tasks while dealing with well on the new task. Compared to other kinds of methods, the methods based on experience replay have shown great advantages to overcome catastrophic forgetting. One common limitation of this method is the data imbalance between the previous and current tasks, which would further aggravate forgetting. Moreover, how to effectively address the stability–plasticity dilemma in this setting is also an urgent problem to be solved. In this paper, we overcome these challenges by proposing a novel framework called Meta-learning update via Multi-scale Knowledge Distillation and Data Augmentation (MMKDDA). Specifically, we apply multi-scale knowledge distillation to grasp the evolution of long-range and short-range spatial relationships at different feature levels to alleviate the problem of data imbalance. Besides, our method mixes the samples from the episodic memory and current task in the online continual training procedure, thus alleviating the side influence due to the change of probability distribution. Moreover, we optimize our model via the meta-learning update by resorting to the number of tasks seen previously, which is helpful to keep a better balance between stability and plasticity. Finally, our extensive experiments on four benchmark datasets show the effectiveness of the proposed MMKDDA framework against other popular baselines, and ablation studies are also conducted to further analyze the role of each component in our framework.},
  archive      = {J_EAAI},
  author       = {Ya-nan Han and Jian-wei Liu},
  doi          = {10.1016/j.engappai.2022.104966},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104966},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Online continual learning via the meta-learning update with multi-scale knowledge distillation and data augmentation},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PyRCN: A toolbox for exploration and application of
reservoir computing networks. <em>EAAI</em>, <em>113</em>, 104964. (<a
href="https://doi.org/10.1016/j.engappai.2022.104964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reservoir Computing Networks (RCNs) belong to a group of machine learning techniques that project the input space non-linearly into a high-dimensional feature space, where the underlying task can be solved linearly. Popular variants of RCNs are capable of solving complex tasks equivalently to widely used deep neural networks, but with a substantially simpler training paradigm based on linear regression. In this paper, we show how to uniformly describe RCNs with small and clearly defined building blocks, and we introduce the Python toolbox PyRCN (Python Reservoir Computing Networks) for optimizing, training and analyzing RCNs on arbitrarily large datasets. The tool is based on widely-used scientific packages and complies with the scikit-learn interface specification. It provides a platform for educational and exploratory analyses of RCNs, as well as a framework to apply RCNs on complex tasks including sequence processing. With a small number of building blocks, the framework allows the implementation of numerous different RCN architectures. We provide code examples on how to set up RCNs for time series prediction and for sequence classification tasks. PyRCN is around ten times faster than reference toolboxes on a benchmark task while requiring substantially less boilerplate code.},
  archive      = {J_EAAI},
  author       = {Peter Steiner and Azarakhsh Jalalvand and Simon Stone and Peter Birkholz},
  doi          = {10.1016/j.engappai.2022.104964},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104964},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {PyRCN: A toolbox for exploration and application of reservoir computing networks},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). M-FasterSeg: An efficient semantic segmentation network
based on neural architecture search. <em>EAAI</em>, <em>113</em>,
104962. (<a
href="https://doi.org/10.1016/j.engappai.2022.104962">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image semantic segmentation is one of the key technologies for intelligent systems to understand natural scenes. As one of the important research directions in the field of visual intelligence, this technology has a wide range of application scenarios in the fields of mobile robots, drones, and intelligent driving. However, in practical applications, there may be problems such as inaccurate prediction of semantic labels, loss of segmented objects and background edge information. This paper proposes an improved semantic segmentation network that combines self-attention module and neural architecture search (NAS) method. The method first uses the NAS method to find a semantic segmentation network with multiple resolution branches. During the search process, the searched network structure is adjusted by combining the self-attention module, and then combined with the semantic segmentation networks searched by different branches to integrate into two semantic segmentation network models with different complexity, and finally integrate two network models with different complexity according to the current general teacher–student framework. The input image will first pass through the high complexity model to obtain more accurate parameters, which will affect the training weight of the student network, then pass the image into the low-complexity model to get the final predicted result. The experimental results on the Cityscapes dataset show that the accuracy of the algorithm is 69.8 %, the inference speed is 166.4 FPS, and the actual image segmentation speed is 48/s. It can optimize edge segmentation for better performance in complex scenes and achieve a good balance between real-time performance and accuracy in practical applications.},
  archive      = {J_EAAI},
  author       = {Junjun Wu and Huiyu Kuang and Qinghua Lu and Zeqin Lin and Qingwu Shi and Xilin Liu and Xiaoman Zhu},
  doi          = {10.1016/j.engappai.2022.104962},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104962},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {M-FasterSeg: An efficient semantic segmentation network based on neural architecture search},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An improved whale optimization algorithm based on multilevel
threshold image segmentation using the otsu method. <em>EAAI</em>,
<em>113</em>, 104960. (<a
href="https://doi.org/10.1016/j.engappai.2022.104960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an improved multithreshold image segmentation method based on the whale optimization algorithm (RAV-WOA) is proposed, with the between-class variance (Otsu method) as the objective function. The proposed RAV-WOA is able to select satisfactory optimal thresholds while ensuring high efficiency and quality when performing image segmentation on grayscale and color images In the current work, a reverse learning strategy was introduced into the initialization of RAV-WOA populations to improve the quality of the initial population of whales. An adaptive weighting strategy was introduced into the RAV-WOA algorithm, which is influenced by the fitness value and the number of iterations, to balance the global search capability of the algorithm with the local exploitation capability. The proposed RAV-WOA is then applied to the Otsu method to solve the multilevel thresholding image segmentation problem. To better verify the effectiveness of the proposed method, this paper compares the RAV-WOA with some classical heuristic algorithms and performs image segmentation experiments on a set of benchmark images with low and high thresholds. The experimental results show that the convergence speed and convergence accuracy of RAV-WOA are significantly better than other algorithms, and the segmentation results of RAV-WOA in multithreshold image segmentation have better quality and stability than other algorithms.},
  archive      = {J_EAAI},
  author       = {Guoyuan Ma and Xiaofeng Yue},
  doi          = {10.1016/j.engappai.2022.104960},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104960},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An improved whale optimization algorithm based on multilevel threshold image segmentation using the otsu method},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An efficient fault classification method in solar
photovoltaic modules using transfer learning and multi-scale
convolutional neural network. <em>EAAI</em>, <em>113</em>, 104959. (<a
href="https://doi.org/10.1016/j.engappai.2022.104959">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photovoltaic (PV) power generation is one of the remarkable energy types to provide clean and sustainable energy. Therefore, rapid fault detection and classification of PV modules can help to increase the reliability of the PV systems and reduce operating costs. In this study, an efficient PV fault detection method is proposed to classify different types of PV module anomalies using thermographic images. The proposed method is designed as a multi-scale convolutional neural network (CNN) with three branches based on the transfer learning strategy. The convolutional branches include multi-scale kernels with levels of visual perception and utilize pre-trained knowledge of the transferred network to improve the representation capability of the network. To overcome the imbalanced class distribution of the raw dataset, the oversampling technique is performed with the offline augmentation method, and the network performance is increased. In the experiments, 11 types of PV module faults such as cracking, diode, hot spot, offline module, and other classes are utilized. The average accuracy is obtained as 97.32% for fault detection and 93.51% for 11 anomaly types. The experimental results indicate that the proposed method gives higher classification accuracy and robustness in PV panel faults and outperforms the other deep learning methods and existing studies.},
  archive      = {J_EAAI},
  author       = {Deniz Korkmaz and Hakan Acikgoz},
  doi          = {10.1016/j.engappai.2022.104959},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104959},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An efficient fault classification method in solar photovoltaic modules using transfer learning and multi-scale convolutional neural network},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Developing a physics-informed and physics-penalized neural
network model for preliminary design of multi-stage friction pendulum
bearings. <em>EAAI</em>, <em>113</em>, 104953. (<a
href="https://doi.org/10.1016/j.engappai.2022.104953">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last few decades, the field of base isolation systems has made significant strides forward by developing new systems to improve the behavior of isolated structures under moderate and severe seismic excitations. One of the most efficient systems is the multi-stage friction pendulum that can provide a wide range of effective pendula with various regimes to reach high energy dissipation capability. The difficulty in designing such bearing at the preliminary stage comes from the relatively long process of trials to select the parameters of each sliding surface in order to ensure that the required effective period, effective damping, and displacement capacities are met. Thus, the following study proposes a direct design approach relying on a physics-informed and physics-penalized neural network model to overcome this issue. Within the context of the analysis, a large dataset composed of over 35000 isolators that covers a wide range of properties of the recently developed generation of friction pendulum “Quintuple Friction Pendulum” was generated following the mechanics-driven approach and then utilized as the case study to test the reliability of suggested design strategy and capability of the proposed multi-output neural network method. Thereafter, the performance of the physics-informed and physics-penalized model was compared to a purely data-driven approach and a physics-informed one. Generally, the results have shown that the proposed model has considerable accuracy with a maximum MAPE of 4.89% for achieving the required QFP properties. Additionally, they showed that the presented method provides an effective way for rapidly designing a quintuple friction pendulum isolator.},
  archive      = {J_EAAI},
  author       = {Ahed Habib and Umut Yildirim},
  doi          = {10.1016/j.engappai.2022.104953},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104953},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Developing a physics-informed and physics-penalized neural network model for preliminary design of multi-stage friction pendulum bearings},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An improved harris hawks optimization algorithm for
continuous and discrete optimization problems. <em>EAAI</em>,
<em>113</em>, 104952. (<a
href="https://doi.org/10.1016/j.engappai.2022.104952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Harris Hawks Optimization (HHO) is a population-based meta-heuristic optimization algorithm that has been used for the solution of test functions and real-world problems by many researchers. However, HHO has a premature convergence problem. The main motive of the novel approach in this paper is that the performance of an MHA could be improved by simplification and by modifying the way random parameters are determined. The proposed algorithm aims to solve both continuous and discrete optimization problems. HHO is improved in three stages. First, the method to determine the random parameters is modified. Second, the strategy of HHO to produce a new solution is updated. Third, the six-step decision mechanism of HHO is shortened to four. The proposed algorithm is compared to five recently published competitor algorithms by applying to the CEC2019 test functions and a three-dimensional bin packing problem (3D-BPP) dataset with 320 samples. All the algorithms are run on the same computer and the results of 30 independent studies are saved. Minimum, average, and standard deviation values and solution times of CEC2019 functions are used as comparison parameters. For the 3D-BPP, the number of bins and the solution time are used as comparison parameters for in the Wilcoxon test. The proposed algorithm performs better than the selected competitors in terms of its %5 significance level. Moreover, the algorithm proposed in the 3D-BPP data set is the most successful algorithm with its 9745 bins. Besides, the proposed algorithm is also compared to the four most popular algorithms in the literature. The results obtained confirm the validity of the proposed algorithm.},
  archive      = {J_EAAI},
  author       = {Harun Gezici and Haydar Livatyali},
  doi          = {10.1016/j.engappai.2022.104952},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104952},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An improved harris hawks optimization algorithm for continuous and discrete optimization problems},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel picture fuzzy CRITIC &amp; REGIME methodology:
Wearable health technology application. <em>EAAI</em>, <em>113</em>,
104942. (<a
href="https://doi.org/10.1016/j.engappai.2022.104942">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Picture fuzzy sets (PFSs) are one of the most promising extensions of ordinary fuzzy sets with three parameters, namely positive membership, neutral membership, and negative membership, for defining the membership status of an element to a set. CRiteria Importance Through Intercriteria Correlation (CRITIC) &amp; REGIME methods are recently developed multi criteria decision making (MCDM) methods for calculating the criteria weights and ranking alternatives, respectively. CRITIC method determines the criteria weights by using the values in the decision matrix. REGIME method is a compensatory MCDM method employing superiority and guide indices, superiority identifier and impacts, and REGIME matrices. In this paper, an integrated CRITIC &amp; REGIME methodology is developed for the first time by using single-valued PFSs in order to use the advantage of PFSs in handling ambiguity and impreciseness. The main contribution of our study is to demonstrate theoretically and practically how to transform superiority and guide indices, superiority identifier and impacts, and REGIME matrices to the PF environment. A new interval valued Relative Magnitude Index scale and an original Percentile Rank under Vagueness function have been developed. The developed methodology is applied to the selection problem of wearable health technology (WHT). Comparative and sensitivity analyses are presented. These analyses show that CRITIC &amp; REGIME methodology produces very effective and valid results, and unlike the other methods, it shows slight ranking differences due to the statistical-based calculations it contains.},
  archive      = {J_EAAI},
  author       = {Elif Haktanır and Cengiz Kahraman},
  doi          = {10.1016/j.engappai.2022.104942},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104942},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel picture fuzzy CRITIC &amp; REGIME methodology: Wearable health technology application},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An automatic kriging machine learning method to calibrate
meta-heuristic algorithms for solving optimization problems.
<em>EAAI</em>, <em>113</em>, 104940. (<a
href="https://doi.org/10.1016/j.engappai.2022.104940">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For years, meta-heuristic algorithms have been widely studied and many improved versions have been developed: from the evolution of the swarm topologies of the Particle Swarm Optimization algorithm, to the using of machine learning to Differential Evolutionary algorithms. However, the tuning of the fundamental meta-heuristic parameters has been less studied, but may lead to significant improvements on the convergence accuracy of these algorithms. This paper aims at developing an automated methodology to calibrate the parameters of population-based meta-heuristic algorithms for optimization problems. Based on the kriging estimation of the best combination of parameters, the Automated parameter tuning of Meta-heuristics (AptM) methodology gives the optimal algorithm setup for each considered problem in order to lead to a better convergence accuracy. The proposed AptM methodology is used to tune three different meta-heuristic algorithms, each applied to twelve mathematical unimodal or multimodal objective functions. AptM methodology performance is assessed by comparison of classical setups usually used in the literature. The numerical results show that the AptM methodology allows a significant improvement of the convergence accuracy of meta-heuristics with an average improvement of 62.02%, 69.12% and 64.94% on optimization problems defined in dimensions 10, 30 and 50 respectively. An experimental criterion is defined based on the convergence accuracy of the AptM methodology over the classical setups, assessing the AptM performances. The previous experimental criterion allows to compare the AptM methodology over the base-set. The AptM methodology shows a significant improvement of the algorithms performance on 97.2% of the tested problems.},
  archive      = {J_EAAI},
  author       = {J. Tondut and C. Ollier and N. Di Cesare and J.C. Roux and S. Ronel},
  doi          = {10.1016/j.engappai.2022.104940},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104940},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An automatic kriging machine learning method to calibrate meta-heuristic algorithms for solving optimization problems},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Risk evaluation of information technology outsourcing
project: An integrated approach considering risk interactions and
hierarchies. <em>EAAI</em>, <em>113</em>, 104938. (<a
href="https://doi.org/10.1016/j.engappai.2022.104938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective risk evaluation is necessary to guarantee the successful completion of an IT outsourcing (ITO) process. However, previous methods of ITO risk assessment omit the interrelationships between the risk factors and ignore the vagueness of the evaluations. Additionally, most of the approaches fail to show the complex interactions among the risk factors with an intuitive and clear structure diagram. Thus, a new method for ITO risk assessment and visualization is developed in this paper. The proposed method integrates the advantages of improved decision-making and trial evaluation laboratories (DEMATEL) method, to incorporate the vagueness of the evaluations flexibly and evaluate the interactions and internal strengths of risk factors, and the merits of interpretative structural modeling (ISM), to clarify the risk factor structure. To illustrate the practicality and validity of this approach, an ITO case study of a mineral company is used in the implementation section to demonstrate the method.},
  archive      = {J_EAAI},
  author       = {Wenyan Song and Yue Zhu and Shanshan Li and Li Wang and Hui Zhang},
  doi          = {10.1016/j.engappai.2022.104938},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104938},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Risk evaluation of information technology outsourcing project: An integrated approach considering risk interactions and hierarchies},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). M3SPCANet: A simple and effective ConvNets with unsupervised
predefined filters for face recognition. <em>EAAI</em>, <em>113</em>,
104936. (<a
href="https://doi.org/10.1016/j.engappai.2022.104936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The principal component analysis network (PCANet) with predefined filters has recognized as a lightweight convolutional neural networks (CNN) baseline. However, there are three shortages in PCANet: (i) single-scale convolution leads to insufficient feature learning, (ii) the spatial layout information and relationship between channel features are neglected, (iii) lack of nonlinearity because there is no activation function. Therefore, we devise a PCANet alternative dubbed Multi-Scale Spatial pyramid Second-order pooling Principle Component Analysis Network (M3SPCANet) in the paper. First, multi-scale PCA filters are learned and applied to obtain feature maps via convolution. Second, the feature maps are activated via nonlinear function Tanh and stacked together. Third, second-order pooling is exploited to extract correlation information between any two channels of the feature maps, moreover, spatial pyramid strategy is employed to learn local and holistic features simultaneously. Finally, whitening PCA based fully connected layer is constructed to remove redundancy information. We utilize cosine similarity based nearest neighbor classifier for face matching. Extensive experiments on four homogeneous and one heterogeneous face databases indicate that our method can achieve superior identification rates, and yield competitive verification performance. Cross database evaluations demonstrate that the multi-scale filters of our method have strong generalization ability. Our implementation code will be available at https://github.com/dxtyut/facerecognition .},
  archive      = {J_EAAI},
  author       = {Daoxiang Zhou and Shu Feng},
  doi          = {10.1016/j.engappai.2022.104936},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104936},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {M3SPCANet: A simple and effective ConvNets with unsupervised predefined filters for face recognition},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analyzing critical barriers of smart energy city in turkey
based on two-dimensional uncertainty by hesitant z-fuzzy linguistic
terms. <em>EAAI</em>, <em>113</em>, 104935. (<a
href="https://doi.org/10.1016/j.engappai.2022.104935">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Successful implementation of smart energy cities in Turkey is essential to optimize urban energy systems. Turkey faces several barriers on its way to establishing smart energy cities. Since assessment of these barriers must be handled by considering many different perspectives, assessment of the critical barriers for SEC can be considered as a multi-criteria decision-making (MCDM) problem. This study aims to identify possible critical barriers hindering Turkey from becoming an SEC and prioritize these barriers based on an integrated MCDM methodology. This methodology consists of fuzzy Decision Making Trail and Evaluating Laboratory (DEMATEL) and cognitive mapping methods. The integrated methodology has been constructed with hesitant fuzzy Z-numbers, which allows not only to state the impreciseness of the evaluations but also to consider the hesitancy of the decision-makers to evaluate barriers concerning SEC implementation in Turkey. While the relations between the barriers have been determined via the hesitant fuzzy Z-DEMATEL method, their weights have been obtained through the hesitant fuzzy Z-cognitive mapping method. For Turkey, policy, economic, and social barriers are determined as the essential main barriers, respectively. Besides, the following five sub-barriers: the lack of successful past experiences/projects, social/political conflicts, inadequate regulatory framework, lack of regulatory norms, policies/directions, the lack of technical knowledge among planners, and information on new technology are deserved to be more attention since they have high weights. The research should help policymakers and businesses better understand the barriers to smart energy city projects in order to improve effective action and policy interventions that lead to more successful projects.},
  archive      = {J_EAAI},
  author       = {Fatma Kutlu Gündoğdu},
  doi          = {10.1016/j.engappai.2022.104935},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104935},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Analyzing critical barriers of smart energy city in turkey based on two-dimensional uncertainty by hesitant z-fuzzy linguistic terms},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adversarial domain adaptation network with pseudo-siamese
feature extractors for cross-bearing fault transfer diagnosis.
<em>EAAI</em>, <em>113</em>, 104932. (<a
href="https://doi.org/10.1016/j.engappai.2022.104932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional domain adaptation model just uses a single (siamese) feature extractor for mapping the source domain and target domain data to a feature space simultaneously, but it may be not well suitable for the cross-machine feature mapping. To improve the performance of the cross-bearing fault transfer diagnosis, an adversarial domain adaptation network with pseudo-siamese feature extractors (PSFEN) is proposed. The core idea is to construct a pair of feature extractors with the same structure but not sharing parameters, which form a pair of pseudo-siamese feature extractors. When the source domain data differs greatly from the target domain data in the cross-machine transfer diagnosis, a pair of pseudo-siamese feature extractors is used to extract the features of source domain and target domain respectively, thus some exclusive characteristics of two domains can be obtained except for the common characteristics. It is theoretically analyzed that the distribution discrepancy obtained by the pseudo-siamese feature extractors can be closer to its actual upper limit. By reducing the more real supremum, the domain adaptation can be better achieved, thus improving the transfer diagnosis accuracy. Then, a distance metric of maximum mean discrepancy and an unbalanced adversarial training algorithm are integrated to train the pseudo-siamese feature extractors and reduce the discrepancy between the source and target domains. The effectiveness of the proposed method is verified by experiments on six cross-bearing fault transfer diagnosis tasks. The comparative results show that the proposed method have much higher diagnostic accuracy compared to six classical models.},
  archive      = {J_EAAI},
  author       = {Qunwang Yao and Quan Qian and Yi Qin and Liang Guo and Fei Wu},
  doi          = {10.1016/j.engappai.2022.104932},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104932},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adversarial domain adaptation network with pseudo-siamese feature extractors for cross-bearing fault transfer diagnosis},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Commentary on: “STOA: A bio-inspired based optimization
algorithm for industrial engineering problems” [EAAI, 82 (2019),
148–174] and “tunicate swarm algorithm: A new bio-inspired based
metaheuristic paradigm for global optimization” [EAAI, 90 (2020), no.
103541]. <em>EAAI</em>, <em>113</em>, 104930. (<a
href="https://doi.org/10.1016/j.engappai.2022.104930">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This commentary concerns two recently developed metaheuristic algorithms, namely the Sooty Tern Optimization Algorithm, and the Tunicate Swarm Algorithm. Both of these algorithms claim computational superiority over other methods based on experimental results on a certain benchmark set. The aim of this note is to aware researchers that this claim is not valid: the proposed algorithms use a zero-bias operator and many of the studied benchmark functions on which they were found superior have optimal solutions located in the zero vector. Moreover, the codes for the methods provided by the authors are not achieving the results reported in the respective publications.},
  archive      = {J_EAAI},
  author       = {Jakub Kudela},
  doi          = {10.1016/j.engappai.2022.104930},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104930},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Commentary on: “STOA: a bio-inspired based optimization algorithm for industrial engineering problems” [EAAI, 82 (2019), 148–174] and “Tunicate swarm algorithm: a new bio-inspired based metaheuristic paradigm for global optimization” [EAAI, 90 (2020), no. 103541]},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). WCATN: Unsupervised deep learning to classify weather
conditions from outdoor images. <em>EAAI</em>, <em>113</em>, 104928. (<a
href="https://doi.org/10.1016/j.engappai.2022.104928">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weather classification from single images is significant for many outdoor computer vision applications, while it has not been thoroughly studied. Existing methods view it as a supervised task under the guidance of weather labels. Though these methods have made great success, they are not applicable to real-world applications because of their reliance on massive human-annotated weather images. In this paper, we take the initial attempt to treat weather classification as an unsupervised task, i.e. to classify weather conditions from unlabeled outdoor images. Specifically, we propose a three-step unsupervised approach to automatically group images into weather clusters. In the first step, i.e. weather feature learning, semantically meaningful weather features are learned by employing a self-supervised task. Furthermore, we also introduce online triplet mining into the self-supervised task to extract discriminative weather features. In the second step, i.e. weather clustering, we design a learnable clustering method via mining the nearest neighbors and enforcing consistency between each sample and its nearest neighbors. To alleviate the uncertainty of weather clustering due to noisy nearest neighbors, we propose a self-labeling method as the third step to employ the already well-classified samples for fine-tuning. Experimental results on two publicly available weather image datasets demonstrate that the proposed approach achieves promising performance.},
  archive      = {J_EAAI},
  author       = {Kezhen Xie and Lei Huang and Zhiqiang Wei and Wenfeng Zhang and Qibing Qin},
  doi          = {10.1016/j.engappai.2022.104928},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104928},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {WCATN: Unsupervised deep learning to classify weather conditions from outdoor images},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Constructing robust health indicators from complex
engineered systems via anticausal learning. <em>EAAI</em>, <em>113</em>,
104926. (<a
href="https://doi.org/10.1016/j.engappai.2022.104926">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In prognostics and health management (PHM), the task of constructing comprehensive health indicators (HI) from huge amounts of condition monitoring data plays a crucial role. HIs may influence both the accuracy and reliability of remaining useful life (RUL) prediction, and ultimately the assessment of system’s degradation status. Most of the existing methods assume apriori an oversimplified degradation law of the investigated machinery, which in practice may not appropriately reflect the reality. Especially for safety–critical engineered systems with a high level of complexity that operate under time-varying external conditions, degradation labels are not available, and hence, supervised approaches are not applicable. To address the above-mentioned challenges for extrapolating HI values, we propose a novel anticausal-based framework with reduced model complexity, by predicting the cause from the causal models’ effects. Two heuristic methods are presented for inferring the structural causal models. First, the causal driver is identified from complexity estimate of the time series, and second, the set of the effect measuring parameters is inferred via Granger Causality. Once the causal models are known, off-line anticausal learning only with few healthy cycles ensures strong generalization capabilities that helps obtaining robust online predictions of HIs. We validate and compare our framework on the NASA’s N-CMAPSS dataset with real-world operating conditions as recorded on board of a commercial jet, which are utilized to further enhance the CMAPSS simulation model. The proposed framework with anticausal learning outperforms existing deep learning architectures by reducing the average root-mean-square error (RMSE) across all investigated units by nearly 65%.},
  archive      = {J_EAAI},
  author       = {Georgios Koutroulis and Belgin Mutlu and Roman Kern},
  doi          = {10.1016/j.engappai.2022.104926},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104926},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Constructing robust health indicators from complex engineered systems via anticausal learning},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Depth-aware gaze-following via auxiliary networks for
robotics. <em>EAAI</em>, <em>113</em>, 104924. (<a
href="https://doi.org/10.1016/j.engappai.2022.104924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaze-Following aims to predict the gaze target of a subject within an image, and information on orientation and depth greatly improves this task. However, previous methods require additional datasets to obtain depth or orientation information, leading to cumbersome training or inference processes. To this end, we propose an end-to-end depth-aware gaze-following approach that incorporates depth and orientation information without additional datasets. Our approach identifies a primary task, gaze-following, supervised by true labels from the gaze-following dataset and two auxiliary tasks, scene depth estimation and 3D orientation estimation, supervised by generated pseudo labels. Intermediate auxiliary features are integrated into the primary task network as implicit information. We propose a residual filter module for screening useful information that can enhance gaze-following prediction performance. Extensive experiments on GazeFollow and VideoAttentionTarget show that our approach achieves state-of-the-art results (0.120 Ave. Dist. achieved on GazeFollow and 0.104 L2 Dist. achieved on VideoAttentionTarget). Finally, we apply our approach to a real robot for understanding human attention and intention. Compared to the previous depth considered gaze-following method, our method saves half of the computation time.},
  archive      = {J_EAAI},
  author       = {Tianlei Jin and Qizhi Yu and Shiqiang Zhu and Zheyuan Lin and Jie Ren and Yuanhai Zhou and Wei Song},
  doi          = {10.1016/j.engappai.2022.104924},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104924},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Depth-aware gaze-following via auxiliary networks for robotics},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Vector based sentiment and emotion analysis from text: A
survey. <em>EAAI</em>, <em>113</em>, 104922. (<a
href="https://doi.org/10.1016/j.engappai.2022.104922">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a primary means of communication, texts are used to implicitly or explicitly reflect emotions. Emotion or sentiment detection from text has emerged as an important and expanding research area to more clearly understand the actual feelings of humans. Most of the word representation models, such as Word2Vec or GloVe, project the words in vector space such that if words have similar context, then their representations are also very similar. However, according to the recent studies, this approach limits the success of studies in areas such as emotion detection. For instance, love and happy are emotionally similar words, but they may have a lower similarity score than emotionally dissimilar word such as happy and sad which have high co-occurrence frequency, as they are in similar contexts. Recently, researchers propose some methods based on the addition of emotional or sentimental information to the original word vectors. These have improved the vector representation of words and achieved better results in emotion detection or classification tasks. In this survey, we analyze in detail such recent text-based studies in the literature. We summarize their methods used, emotion models, data sources, findings, and performances.},
  archive      = {J_EAAI},
  author       = {Hande Aka Uymaz and Senem Kumova Metin},
  doi          = {10.1016/j.engappai.2022.104922},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104922},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Vector based sentiment and emotion analysis from text: A survey},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A modified adaptive guided differential evolution algorithm
applied to engineering applications. <em>EAAI</em>, <em>113</em>,
104920. (<a
href="https://doi.org/10.1016/j.engappai.2022.104920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a robust strategy based on integrating three mutation phases and adapted control parameters into the Adaptive Guided Differential Evolution algorithm called (mAGDE) to improve diversity and exploration of the original AGDE. The mAGDE performance is evaluated using IEEE CEC’2020 test suite. Furthermore, the mAGDE is employed to identify the solid oxide fuel cell (SOFC) model optimal parameters. Two modes of SOFC operation are investigated, steady and transient states. The results obtained from the proposed mAGDE are compared with a number of recent, well-established and reputed meta-heuristics, including Particle swarm optimization, Teaching learning-based optimization, Whale optimization algorithm, Harris hawks optimization, Marine predators algorithm, Archimedes optimization algorithm, Differential evolution, and the original AGDE. Additionally, the statistical parameters that measure the performance of the proposed optimizer and the other competitors are calculated. The main finding demonstrated the preference and robustness of the suggested mAGDE in constructing the SOFC circuit that closely converges to the actual one. During the steady-state operation, the best fitness value obtained via the suggested mAGDE for operation at 1273 K is 2.2995E−06, while in the transient-state operation, the best SMSE is 1.04. The average cost function is decreased by 43.33% compared to the one obtained by the original AGDE. From the aforementioned assessments, it can be concluded that the proposed mAGDE is outstanding and promising.},
  archive      = {J_EAAI},
  author       = {Essam H. Houssein and Hegazy Rezk and Ahmed Fathy and Mohamed A. Mahdy and Ahmed M. Nassef},
  doi          = {10.1016/j.engappai.2022.104920},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104920},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A modified adaptive guided differential evolution algorithm applied to engineering applications},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A pose-aware dynamic weighting model using feature
integration for driver action recognition. <em>EAAI</em>, <em>113</em>,
104918. (<a
href="https://doi.org/10.1016/j.engappai.2022.104918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic accidents caused by distracted driving are on the rise, posing a serious threat to the safety of people’s lives and property. Recognition and early warning of the driver’s actions is particularly important. Considering the differences in local details of driver actions, we use the keypoint information of drivers that reflects the category differences. Specifically, we explicitly model keypoints features and propose a pose-aware driver action recognition model. We design a pose-based feature fusion module incorporating the attention mechanism, to fuse the global features and keypoint features of different scales in driving images. In addition, we propose an input-dependent weighting module to enhance the discrimination of the fused features. We use dynamic convolution to apply channel attention to convolution weights. According to the input driving image, the corresponding weights are adaptively generated for multiple convolution kernels, and the final weighted summation is carried out. This is a soft gate scheme, which opens a new perspective for driver action recognition. The proposed model achieves 90.7% and 95.3% accuracy on StateFarm dataset and SEU-Driving dataset, which are improved by 1.4% and 3.1% respectively compared to SOTA (MSA-CNN).},
  archive      = {J_EAAI},
  author       = {Mingqi Lu and Yaocong Hu and Xiaobo Lu},
  doi          = {10.1016/j.engappai.2022.104918},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104918},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A pose-aware dynamic weighting model using feature integration for driver action recognition},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ConvPatchTrans: A script identification network with global
and local semantics deeply integrated. <em>EAAI</em>, <em>113</em>,
104916. (<a
href="https://doi.org/10.1016/j.engappai.2022.104916">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical Character Recognition (OCR) system serves the need of reading text from images. Script identification that identifies the language of the text in the image is an important part of OCR technology and an indispensable role in the stability and accuracy of the OCR system. The most challenging for script identification is the interference caused by similarities between texts in different languages. In this paper, a two-branch network named ConvPatchTrans is designed to process global and local semantic features separately, focusing on the text and each word in a picture. The ConvPatchTrans extracts feature from different stages of the Visual Geometry Group network (VGGNet) as global and local semantics. For the global branch, the linear classifier is recommended. For the local branch, text image data is converted to image sequence data. Then, multi-layers convolution-enhanced Transformer (MCET) is proposed to bring about the deep fusion of sequence. Finally, the global and local branches are fused by an adaptive weighted fusion method to get the best result. In order to verify the effectiveness of our proposed method, four public script identification datasets are used for comparative experiments. Our method has obtained the highest values among currently published methods on the CVSI2015 and MLE2E datasets, which are 98.90% and 97.50%, respectively. At the same time, satisfactory results are also obtained on the other two datasets.},
  archive      = {J_EAAI},
  author       = {Ke Yang and Jizheng Yi and Aibin Chen and Jiaqi Liu and Wenjie Chen and Ze Jin},
  doi          = {10.1016/j.engappai.2022.104916},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104916},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ConvPatchTrans: A script identification network with global and local semantics deeply integrated},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A lightweight vehicles detection network model based on
YOLOv5. <em>EAAI</em>, <em>113</em>, 104914. (<a
href="https://doi.org/10.1016/j.engappai.2022.104914">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle detection technology is of great significance for realizing automatic monitoring and AI-assisted driving systems. The state-of-the-art object detection method, namely, a class of YOLOv5, has often been used to detect vehicles. However, it suffers some challenges, such as a high computational load and undesirable detection rate. To address these issues, an improved lightweight YOLOv5 method is proposed for vehicle detection in this paper. In the presented method, C3Ghost and Ghost modules are introduced into the YOLOv5 neck network to reduce the floating-point operations (FLOPs) in the feature channel fusion process and enhance the feature expression performance. A convolutional block attention module (CBAM) is introduced to the YOLOv5 backbone network to select the information critical to the vehicle detection task and suppress uncritical information, thus improving the detection accuracy of the algorithm. Furthermore, CIoU_Loss is considered the bounding box regression loss function to accelerate the bounding box regression rate and improve the localization accuracy of the algorithm. To verify the performance of the proposed approach, we tested our model via two case studies, i.e., the PASCAL VOC dataset and MS COCO dataset. The results show that the detection precision of the proposed model increased 3.2%, the FLOPs decreased 15.24%, and the number of model parameters decreased 19.37% compared with those of the existing YOLOv5. Through case studies and comparisons, the effectiveness and superiority of the presented approach are demonstrated.},
  archive      = {J_EAAI},
  author       = {Xudong Dong and Shuai Yan and Chaoqun Duan},
  doi          = {10.1016/j.engappai.2022.104914},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104914},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight vehicles detection network model based on YOLOv5},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Likelihood-based agreement measurements with pythagorean
fuzzy paired point operators to enrichment evaluations and priority
determination for an uncertain decision-theoretical analysis.
<em>EAAI</em>, <em>113</em>, 104912. (<a
href="https://doi.org/10.1016/j.engappai.2022.104912">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to initiate a useful Pythagorean fuzzy likelihood function on grounds of paired point operators and scalar-valued functions, and to contrive several likelihood-based agreement measurements for enrichment evaluations and priority determination within the framework of uncertain multiple criteria analysis. This paper exploits the characterization parameters of Pythagorean membership grades to expound paired point operators and further reveals relevant theoretical benefits. Supported by scalar-valued functions regarding the admissible lower and upper estimations, an innovative likelihood function is propounded for ascertaining the possibility of Pythagorean fuzzy dominance relations. Based on the advanced superiority and inferiority estimations, a number of valuable likelihood-based agreement measurements are unfolded to enrich the assessments, including (dis)agreement measures via rank-wise fittingness, expected (dis)agreement measures as a proxy for satisfaction and hygiene estimations, and overall (dis)agreement measures. An efficacious linear programming model with a hygiene threshold is constructed for prioritizing competing alternatives. A pragmatic decision-making issue related to hospital-based post-acute care is explored to inquire into application outcomes using the established techniques. Additionally, certain comparative analyses are performed to verify the helpfulness and interesting features possessed by the advanced approach.},
  archive      = {J_EAAI},
  author       = {Ting-Yu Chen},
  doi          = {10.1016/j.engappai.2022.104912},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104912},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Likelihood-based agreement measurements with pythagorean fuzzy paired point operators to enrichment evaluations and priority determination for an uncertain decision-theoretical analysis},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reconstruction and prediction of the layout of indoor
environments from two-dimensional metric maps. <em>EAAI</em>,
<em>113</em>, 104910. (<a
href="https://doi.org/10.1016/j.engappai.2022.104910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metric maps, like occupancy grids, are one of the most common ways to represent indoor environments in autonomous mobile robotics. Although they are effective for navigation and localization, metric maps contain little knowledge about the structure of the buildings they represent. In this paper, we propose a method that identifies the structure of indoor environments from 2D metric maps by retrieving their layout , namely an abstract geometrical representation that models walls as line segments and rooms as polygons. The method works by finding regularities within a building, abstracting from the possibly noisy information of the metric map, and uses such knowledge to reconstruct the layout of the observed part and to predict a possible layout of the partially observed portion of the building. Thus, differently of other methods from the state of the art, our method can be applied both to fully observed environments and, most significantly, to partially observed ones. Experimental results show that our approach performs effectively and robustly on different types of input metric maps and that the predicted layout is increasingly more accurate when the input metric map is increasingly more complete. The layout returned by our method can be exploited in several tasks, such as semantic mapping, place categorization, path planning, human–robot communication, and task allocation.},
  archive      = {J_EAAI},
  author       = {Matteo Luperto and Francesco Amigoni},
  doi          = {10.1016/j.engappai.2022.104910},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104910},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reconstruction and prediction of the layout of indoor environments from two-dimensional metric maps},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Asian stock markets closing index forecast based on
secondary decomposition, multi-factor analysis and attention-based LSTM
model. <em>EAAI</em>, <em>113</em>, 104908. (<a
href="https://doi.org/10.1016/j.engappai.2022.104908">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The analysis and prediction of stock markets in Asian is an important issue which can help to promote the integration and globalization of financial cooperation. However, owning to the non-stationary and complexity of the stock market fluctuation, it is challenging to predict the stock price accurately. Especially after the decomposition of the original series, how to solve the problem of pseudo information and filter the exogenous variables is often certain challenging. This paper presents a hybrid model based on secondary decomposition (SD), multi-factor analysis (MFA) and attention-based long short-term memory (ALSTM) to predict the stock market price trends of four major Asian countries. The original stock price series is preprocessed by two decomposition algorithms so as to capture further non-linear feature and better filter the noise. Multi-factor analysis is introduced as a supplement to the original data information. In the prediction stage, attention layer is added in long short-term memory model to increase the weights of effective information. Finally, four datasets about Asian stock markets and nine compared models were used to verify the performance of the proposed model. The empirical analysis results show that compared to the general long short-term memory, our proposed model can obtain higher 30% accuracy at least. The mean average percentage errors of the system were also the lowest among all models mentioned in this paper (0.612%, 0.903%, 0.606% and 0.402% respectively), which proves the effectiveness of the hybrid model.},
  archive      = {J_EAAI},
  author       = {Jujie Wang and Quan Cui and Xin Sun and Maolin He},
  doi          = {10.1016/j.engappai.2022.104908},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104908},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Asian stock markets closing index forecast based on secondary decomposition, multi-factor analysis and attention-based LSTM model},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). An ensemble and shared selective adversarial network for
partial domain fault diagnosis of machinery. <em>EAAI</em>,
<em>113</em>, 104906. (<a
href="https://doi.org/10.1016/j.engappai.2022.104906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, some adversarial transfer learning (TL) approaches have been developed for addressing the partial domain adaptation (DA) problems in machinery fault diagnosis. However, these existing methods generally follow the partial DA framework of multiple sub-domain discriminators, which causes the overly complex model in dealing with many source classes. Moreover, the classifier mostly based on a single intelligent model with limited generalization, it may predict the wrong class-probability for unlabeled samples, which will cause the negative transfer when used in the model training. In response to the challenges, an ensemble and shared selective adversarial network (ES-SAN) is proposed in this paper. In this network, by introducing a correlation layer to correlate both class and domain informations for each sample, a single-intelligent model based shared module is constructed, which can transform between the classifier and the discriminator capable of multi sub-domain discrimination, so as to form a simplified partial DA framework. Moreover, multiple shared modules based on different intelligent models are integrated into an ensemble module, which can output reliable probability weights to promote positive transfer. Experimental investigations on two diagnosis datasets demonstrate that the proposed ES-SAN outperforms the existing methods in the partial DA diagnosis.},
  archive      = {J_EAAI},
  author       = {Xiaoyang Liu and Shulin Liu and Jiawei Xiang and Ruixue Sun and Yuan Wei},
  doi          = {10.1016/j.engappai.2022.104906},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104906},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An ensemble and shared selective adversarial network for partial domain fault diagnosis of machinery},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-task learning for cavitation detection and
cavitation intensity recognition of valve acoustic signals.
<em>EAAI</em>, <em>113</em>, 104904. (<a
href="https://doi.org/10.1016/j.engappai.2022.104904">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of smart manufacturing, data-driven machinery health management has received a growing attention. As one of the most popular methods in machinery health management, deep learning (DL) has achieved remarkable successes. However, due to the issues of limited samples and poor separability of different cavitation states of acoustic signals, which greatly hinder the eventual performance of DL modes for cavitation intensity recognition and cavitation detection. Also different tasks were performed separately conventionally. In this work, a novel multi-task learning framework for simultaneous cavitation detection and cavitation intensity recognition framework using 1-D double hierarchical residual networks (1-D DHRN) is proposed for analyzing valves acoustic signals. Firstly, a data augmentation method based on sliding window with fast Fourier transform (Swin-FFT) is developed to alleviate the small-sample issue confronted in this study. Secondly, a 1-D double hierarchical residual block (1-D DHRB) is constructed to capture sensitive features from the frequency domain acoustic signals of valve. Then, a new structure of 1-D DHRN is proposed. Finally, the devised 1-D DHRN is evaluated on two datasets of valve acoustic signals without noise ( Dataset 1 and Dataset 2 ) and one dataset of valve acoustic signals with realistic surrounding noise ( Dataset 3 ) provided by SAMSON AG (Frankfurt). Our method has achieved state-of-the-art results. The prediction accuracies of 1-D DHRN for cavitation intensitys recognition are as high as 93.75 %, 94.31 % and 100 %, which indicates that 1-D DHRN outperforms other DL models and conventional methods. At the same time, the testing accuracies of 1-D DHRN for cavitation detection are as high as 97.02 %, 97.64 % and 100 %. In addition, 1-D DHRN has also been tested for different frequencies of samples and shows excellent results for frequency of samples that mobile phones can accommodate.},
  archive      = {J_EAAI},
  author       = {Yu Sha and Johannes Faber and Shuiping Gou and Bo Liu and Wei Li and Stefan Schramm and Horst Stoecker and Thomas Steckenreiter and Domagoj Vnucec and Nadine Wetzstein and Andreas Widl and Kai Zhou},
  doi          = {10.1016/j.engappai.2022.104904},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104904},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-task learning for cavitation detection and cavitation intensity recognition of valve acoustic signals},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Temperature field inversion of heat-source systems via
physics-informed neural networks. <em>EAAI</em>, <em>113</em>, 104902.
(<a href="https://doi.org/10.1016/j.engappai.2022.104902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temperature field inversion of heat-source systems (TFI-HSS) with limited observations is essential to monitor the system health. Although some methods such as interpolation have been proposed to solve TFI-HSS, those existing methods ignore correlations between data constraints and physics constraints, causing the low precision. In this work, we develop a physics-informed neural network-based temperature field inversion (PINN-TFI) method to solve the TFI-HSS task and a coefficient matrix condition number based position selection of observations (CMCN-PSO) method to select optimal positions of noisy observations. For the TFI-HSS task, the PINN-TFI method encodes constrain terms into the loss function and thus the task is transformed into an optimization problem of minimizing the loss function. In addition, we have found that noise significantly affect reconstruction performances of the PINN-TFI method. To alleviate the effect of noises in observations, we propose the CMCN-PSO method to find optimal positions, where the condition number of observations is used to evaluate positions. The results demonstrate that the PINN-TFI method can significantly improve prediction precisions and the CMCN-PSO method can find good positions to improve the robustness of the PINN-TFI method.},
  archive      = {J_EAAI},
  author       = {Xu Liu and Wei Peng and Zhiqiang Gong and Weien Zhou and Wen Yao},
  doi          = {10.1016/j.engappai.2022.104902},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104902},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Temperature field inversion of heat-source systems via physics-informed neural networks},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Micro gas turbine fault detection and isolation with a
combination of artificial neural network and off-design performance
analysis. <em>EAAI</em>, <em>113</em>, 104900. (<a
href="https://doi.org/10.1016/j.engappai.2022.104900">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently Micro Gas Turbines deployment in smart grids is growing, which increases engine load change during its lifecycle; consequently, lifetime reduces faster, and diagnostics is more highlighted. Engine complex dynamic limits studies to only system-level diagnostics at the full-load operation, whereas measurements’ uncertainties and gradual degradation are often neglected. This study proposes a diagnostics scheme to detect and isolate faults in a wide range of part loads and degradation in the presence of uncertainties. An off-design model of Micro Gas Turbine is developed, and uncertainties are considered for preparing a comprehensive training database. An artificial Neural Network is employed to understand the nonlinear correlation between measurements and components’ health state. Different sets of measurements are tested to minimize the number of required measurements. It demonstrates power, and shaft speed measuring is necessary for accurate detection. Moreover, to present appropriate fault isolation using power, shaft speed, exhaust temperature, compressor discharge pressure, and temperature are required. The study indicates diagnostics performance is not sensitive to load variety that exists in the database but shows considerable sensitivity to degradation severities variety. Noise level effects on diagnostics performance are investigated to evaluate the importance of sensors’ uncertainty considerations. It reveals that detection is not so sensitive to the noise level. However, isolation shows more sensitivity. The result demonstrates the high capability of the proposed approach for establishing system level and component level diagnostics in a broad operating range and dealing with measurements’ uncertainties engine high complexity and nonlinearity.},
  archive      = {J_EAAI},
  author       = {S.S. Talebi and A. Madadi and A.M. Tousi and M. Kiaee},
  doi          = {10.1016/j.engappai.2022.104900},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104900},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Micro gas turbine fault detection and isolation with a combination of artificial neural network and off-design performance analysis},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Value-based reinforcement learning approaches for task
offloading in delay constrained vehicular edge computing. <em>EAAI</em>,
<em>113</em>, 104898. (<a
href="https://doi.org/10.1016/j.engappai.2022.104898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the age of booming information technology, human-being has witnessed the need for new paradigms with both high computational capability and low latency. A potential solution is Vehicular Edge Computing (VEC). Previous work proposed a Fuzzy Deep Q-Network in Offloading scheme (FDQO) that combines Fuzzy rules and Deep Q-Network (DQN) to improve DQN’s early performance by using Fuzzy Controller (FC). However, we notice that frequent usage of FC can hinder the future growth performance of model. One way to overcome this issue is to remove Fuzzy Controller entirely. We introduced an algorithm called baseline DQN (b-DQN), represented by its two variants Static baseline DQN (Sb-DQN) and Dynamic baseline DQN (Db-DQN), to modify the exploration rate base on the average rewards of closest observations. Our findings confirm that these baseline DQN algorithms surpass traditional DQN models in terms of average Quality of Experience (QoE) in 100 time slots by about 6%, but still suffer from poor early performance (such as in the first 5 time slots). Here, we introduce baseline FDQO (b-FDQO). This algorithm has a strategy to modify the Fuzzy Logic usage instead of removing it entirely while still observing the rewards to modify the exploration rate. It brings a higher average QoE in the first 5 time slots compared to other non-fuzzy-logic algorithms by at least 55.12%, prevent the model from getting too bad result over all time slots, while having the late performance as good as that of b-DQN.},
  archive      = {J_EAAI},
  author       = {Do Bao Son and Ta Huu Binh and Hiep Khac Vo and Binh Minh Nguyen and Huynh Thi Thanh Binh and Shui Yu},
  doi          = {10.1016/j.engappai.2022.104898},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104898},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Value-based reinforcement learning approaches for task offloading in delay constrained vehicular edge computing},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep subdomain generalisation network for health monitoring
of high-speed train brake pads. <em>EAAI</em>, <em>113</em>, 104896. (<a
href="https://doi.org/10.1016/j.engappai.2022.104896">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uneven wear at different locations in high-speed train brake pads creates inconsistent vibrations, which make the criteria learned by the intelligent model hard to standardise to determine friction block failure. Variable friction-induced vibration makes brake pad health monitoring a cross-domain diagnostic problem. This study proposes a deep subdomain generalisation network for online monitoring of the health status of train brake pads. In contrast to existing transfer learning methods, the proposed approach does not assume the availability of test data during training. The model is generalised using unsupervised learning to new scenarios with unknown specific locations of uneven wear. The network reduces the discrepancy explicitly among the distributions of relevant source subdomains using local maximum mean discrepancy, which helps subdomains with identical labels more accurately find an appropriate common subspace. Furthermore, Bayesian optimisation is used to unify feature extraction, domain generalisation and hyper-parameter optimisation into a framework. The vibration–acceleration signals of different friction blocks are collected, and generalisation experiments are performed on both braking-friction and rotating-machinery datasets. The results indicate that the proposed model outperforms the other domain generalisation approaches and accurately identifies the state of a target friction block.},
  archive      = {J_EAAI},
  author       = {Ruohui Hu and Min Zhang and Xiangyin Meng and Zhuang Kang},
  doi          = {10.1016/j.engappai.2022.104896},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104896},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep subdomain generalisation network for health monitoring of high-speed train brake pads},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid feature selection scheme for high-dimensional data.
<em>EAAI</em>, <em>113</em>, 104894. (<a
href="https://doi.org/10.1016/j.engappai.2022.104894">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a growing interest in developing feature subset selection schemes for high-dimensional datasets by filter, wrapper, embedded, and hybrid manners. In this paper, we propose a new hybrid (filter-wrapper) feature selection approach. At first, in the filter step, we rank input features according to their relevance with the class label. Afterwards, we apply different clustering methods for the classification of the selected features. We perform an inner and outer cluster ranking based on the primary feature ranking in the next step. Then, different search strategies are performed on the best cluster of features in the wrapper phase. Moreover, we add some of them to the feature set based on the classifiers (nearest neighbor, decision tree, support vector machine, and random forests) feedback. Then, the algorithm goes to the next cluster, and this process is continued till all clusters are met. Finally, we compare the results of the proposed method to the state-of-the-art schemes. Comparison results imply the superiority of the proposed method to the counterparts on eight high-dimensional datasets in terms of accuracy and computational complexity.},
  archive      = {J_EAAI},
  author       = {Mohammad Ahmadi Ganjei and Reza Boostani},
  doi          = {10.1016/j.engappai.2022.104894},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104894},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid feature selection scheme for high-dimensional data},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evaluation of deep learning approaches for oil &amp; gas
pipeline leak detection using wireless sensor networks. <em>EAAI</em>,
<em>113</em>, 104890. (<a
href="https://doi.org/10.1016/j.engappai.2022.104890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pipelines are one of the most common systems for storing and transporting petroleum products, both liquid and gaseous. Despite the durable structures, leakages can occur for many reasons, causing environmental disasters, energy waste, and, in some cases, human losses. The object of the ESTHISIS project is the development of a low-cost and low-energy wireless sensor system for the immediate detection of leaks in metallic piping systems for the transport of liquid and gaseous petroleum products in a noisy industrial environment. In this study, two distinct leakage detection methodologies are presented. First, a 2D-Convolutional Neural Network (CNN) model undertakes supervised classification in spectrograms extracted by the signals acquired by the accelerometers mounted on the pipeline wall. This approach allows us to supplant large-signal datasets with a more memory-efficient alternative to storing static images. The second methodology entails a Long Short-Term Memory Autoencoder (LSTM AE), which directly receives the signals from the accelerometers, providing an unsupervised leakage detection solution. Field tests for the validation of our methods were performed using an experimental pipeline network, while evaluation of their efficiency in a real environment was conducted in the premises of an oil refinery in Greece. Results evince the potency of the LSTM AE to recognize in real-time the emergence of deficiencies and the efficacy of the CNN models to classify accurately spectrograms reflecting the operational condition of the monitored pipelines.},
  archive      = {J_EAAI},
  author       = {Christos Spandonidis and Panayiotis Theodoropoulos and Fotis Giannopoulos and Nektarios Galiatsatos and Areti Petsa},
  doi          = {10.1016/j.engappai.2022.104890},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104890},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Evaluation of deep learning approaches for oil &amp; gas pipeline leak detection using wireless sensor networks},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An innovative chain coding mechanism for information
processing and compression using a virtual bat-bug agent-based modeling
simulation. <em>EAAI</em>, <em>113</em>, 104888. (<a
href="https://doi.org/10.1016/j.engappai.2022.104888">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The continuous changes in the size of data create new challenges to design new techniques to reduce its size and encode it in a way that changes its original representation. In this article, we develop a bat-bug agent-based modeling simulation for chain coding and employ it in compressing bi-level image information. The system consists of agents that are classified into static and dynamic depending on their movements. Bugs are considered static agents, and they are distributed over the virtual environment according to the allocation of pixels in the original image. On the other hand, bats are dynamic agent, and their role is to move around to consume bugs while the algorithm tracks their movements. Bats are designed in a way to move within certain boundaries to avoid crashing into each other. Bats employ specific movements that allow them to move in relative directions. Therefore, the frequency of their movements can follow a certain pattern that can help in further size reduction. In other words, the integration of relative movements into our design proved to be advantageous because there is an observable pattern of repeated movements, which allows getting higher compression results. Finally, arithmetic coding is applied to the final strings that represent the movements of bats while searching for bugs to eat. To assess the performance of the algorithm, we compared the findings against standardized benchmarks used in the image processing community: G3, G4, JBIG1, and JBIG2. The outcomes show that we could outperform all these benchmarks using all the images we used for testing. Additionally, we conducted a series of paired samples t-tests, and they revealed that the mean differences between our results and those obtained from other benchmarks are statistically significant.},
  archive      = {J_EAAI},
  author       = {Khaldoon Dhou and Christopher Cruzen},
  doi          = {10.1016/j.engappai.2022.104888},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104888},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An innovative chain coding mechanism for information processing and compression using a virtual bat-bug agent-based modeling simulation},
  volume       = {113},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic selective gaussian process regression for
forecasting temperature of molten steel in ladle furnace. <em>EAAI</em>,
<em>112</em>, 104892. (<a
href="https://doi.org/10.1016/j.engappai.2022.104892">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The requirement for intelligent steelmaking has underlined the significance of data-driven predictions of molten steel temperature in ladle furnace. Recently, predictors based on ensemble learning have shown their superiority over single ones. However, the strong reliability on the ensemble diversity can hardly insure their generalization ability. Moreover, most existing predictors cannot provide statistical meaning to their outputs. This has degraded their engineering value. In this paper, we aim to address these two problems in one scheme, where a dynamic regression ensemble of Gaussian process models is built. Our dynamic ensemble will select the most competent individual for each test pattern according to the competence estimated by informative neighbors. To this end, a distance measure based on RReliefF is constructed to search for these neighbors, rather than traditional K-nearest neighbor. Several evaluation indexes are combined by a meta regressor so that more robust estimation of competence can be achieved. A Bayesian nonparametric model is used for ensemble generation in order to obtain statistical predictions. A data set from real-world ladle furnace is used to verify the effectiveness of the proposed predictor. According to the comparative results, we have found the superiority of our dynamic ensemble over static ensembles and single predictors. Furthermore, the improvement over existing dynamic ensembles has also been confirmed.},
  archive      = {J_EAAI},
  author       = {Biao Wang and Wenjing Wang and Zhihua Qiao and Guanglei Meng and Zhizhong Mao},
  doi          = {10.1016/j.engappai.2022.104892},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104892},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic selective gaussian process regression for forecasting temperature of molten steel in ladle furnace},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new machine learning model based on the broad learning
system and wavelets. <em>EAAI</em>, <em>112</em>, 104886. (<a
href="https://doi.org/10.1016/j.engappai.2022.104886">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we present a new neural network named WAvelet-Based Broad LEarning System ( WABBLES ). WABBLES is based on the flat structure of the broad learning system. Such structure offers an alternative to deep learning models, such as convolutional neural networks. The WABBLES network uses multiresolution analysis to look for subtle, yet important features from the input data for a better classification performance. WABBLES uses wavelets to map the input signal, to obtain more relevant features from it. This is achieved by autonomously learning and adjusting the dilation and translation parameters of a wavelet, which control its shape. In this way, the resulting mapping nodes have a better representation of the most important features for the classification problem. The construction of the model is described here, along with special considerations and algorithms involved. Finally, the proposed model is tested using a database of synthetic astronomical data and a benchmark dataset called the Breast Cancer Wisconsin Dataset (Original). The conducted experiments provide a comparison between the proposed model and several machine learning algorithms with different performance metrics applied to the context of exoplanet identification and breast cancer detection. Our results confirm that the WABBLES model obtains superior accuracy and F-score percentages than the other models.},
  archive      = {J_EAAI},
  author       = {Miguel Jara-Maldonado and Vicente Alarcon-Aquino and Roberto Rosas-Romero},
  doi          = {10.1016/j.engappai.2022.104886},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104886},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new machine learning model based on the broad learning system and wavelets},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial intelligence in industrial design: A
semi-automated literature survey. <em>EAAI</em>, <em>112</em>, 104884.
(<a href="https://doi.org/10.1016/j.engappai.2022.104884">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of industry 4.0, artificial intelligence (AI) may potentially be used to provide reasoning and decision support on engineering and technical challenges. The role of AI in industrial design, which is the practice of improving the function, value and aesthetics of products to optimise customer satisfaction, has not yet been extensively explored. To effectively synthesise the existing literature, an unsupervised learning-enabled review methodology is proposed in this study. Important journals and articles are identified by using k-means clustering, and the relevant articles are analysed by using co-citation, bibliographic coupling, and co-occurrence analyses. Six clusters of the body of knowledge are then extracted, and naming of the clusters is assisted by using document summarisation and evaluation. Consequently, six intellectual cores related to AI in industrial design are formulated: (i) supply chain perspectives on product design and innovation, (ii) manufacturability and performance of new product development, (iii) intelligent tools and systems for industrial design and engineering, (iv) applied intelligence for product and service innovation, (v) industry 4.0 technologies for design and manufacturing, and (vi) blockchain-enabled artificial intelligence in industry 4.0. Future research trends on sustainable design, trust in AI, and emerging technology integration towards the next-generation AI in industrial design are discussed.},
  archive      = {J_EAAI},
  author       = {Y.P. Tsang and C.K.M. Lee},
  doi          = {10.1016/j.engappai.2022.104884},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104884},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Artificial intelligence in industrial design: A semi-automated literature survey},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An adaptive decoding biased random key genetic algorithm for
cloud workflow scheduling. <em>EAAI</em>, <em>112</em>, 104879. (<a
href="https://doi.org/10.1016/j.engappai.2022.104879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the ever-growing data and computing requirements, more and more scientific and business applications represented by workflows have been moved or are in active transition to cloud platforms. Therefore, the cloud workflow scheduling has become a hot topic. As a well-known NP-hard problem, many heuristic or metaheuristic algorithms/methods have been proposed. However, the heuristic method is problem-dependent which fits only a particular of problems, while the metaheuristic method has the problems of incomplete search space or low search efficiency in the complete space. To fill these gaps, a novel adaptive decoding biased random key genetic algorithm for cloud workflow scheduling is proposed. In this algorithm, the improved real number coding based on random key with limited value range is employed, and some novel schemes such as the population initialization based on level and heuristics including dynamic heterogeneous earliest finish time, the dynamic adaptive decoding, the load balance with communication avoidance and iterative forward–backward scheduling are designed for population initialization, chromosome decoding and improvement. To evaluate the performance, extensive experiments have been conducted on various real and random workflow applications, which demonstrates that the proposed algorithm outperforms the conventional approaches.},
  archive      = {J_EAAI},
  author       = {Yi Xie and Yuhan Sheng and Moqi Qiu and Fengxian Gui},
  doi          = {10.1016/j.engappai.2022.104879},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104879},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An adaptive decoding biased random key genetic algorithm for cloud workflow scheduling},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Double information preserving canonical correlation
analysis. <em>EAAI</em>, <em>112</em>, 104870. (<a
href="https://doi.org/10.1016/j.engappai.2022.104870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The methods based on canonical correlation analysis (CCA-based methods) are typical and effective methods for unsupervised dimensionality reduction of multi-view data. However, the traditional CCA-based methods ignore the dissimilarity information while considering the similarity information of samples, which will make the heterogeneous samples in the subspace cannot be well separated. In this paper, we propose a novel unsupervised multi-view dimensionality reduction method: Double Information Preserving Canonical Correlation Analysis (DIPCCA). DIPCCA aims at finding two projection matrices by integrating two cross double weight graphs with CCA to explore the similarity and dissimilarity information of data in cross views. Furthermore, on the basis of consistency and complementarity, DIPCCA uses the similarity information to maintain the local structure, and the dissimilarity information to disperse embedded samples of distinct clusters, so as to extract more discriminative features. Moreover, CCA and a new locality-preserving CCA are two special cases of DIPCCA when parameters take special values. In order to better extract the features of nonlinear data and more than two views, DIPCCA is extended to Double Information Preserving Kernel Canonical Correlation Analysis and Double Information Preserving Multiple Canonical Correlation Analysis, respectively. Experiments on an artificial dataset and three real multi-view datasets show our proposed methods have better performance than the traditional CCA-based methods.},
  archive      = {J_EAAI},
  author       = {Hongjie Zhang and Junyan Tan and Jinxin Zhang and Yingyi Chen and Ling Jing},
  doi          = {10.1016/j.engappai.2022.104870},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104870},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Double information preserving canonical correlation analysis},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reinforcement learning in manufacturing control: Baselines,
challenges and ways forward. <em>EAAI</em>, <em>112</em>, 104868. (<a
href="https://doi.org/10.1016/j.engappai.2022.104868">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of Neural Combinatorial Optimization (NCO) offers multiple learning-based approaches to solve well-known combinatorial optimization tasks such as Traveling Salesman or Knapsack problem capable of competing with classical optimization approaches in terms of both solution quality and speed. This brought the attention of the research community to the tasks of Manufacturing Control (MC) with combinatorial nature. In this paper we outline the main components of MC tasks, select the most promising application fields and analyze dedicated learning-based solutions available in the literature. We draw multiple parallels to the current state of the art in the NCO field and allocate the main research gaps and directions on the perception, cognition and interaction levels. Using a set of practical examples we implement and benchmark common design patterns for single-agent Reinforcement Learning (RL) solutions. Along with testing existing solutions, we build on the ranked reward idea (Laterre et al., 2018) and offer a novel Multi-Instance Ranked Reward (m-R2) approach tailored to MC optimization tasks. It minimizes the reward shaping effort and defines a suitable training curriculum for more stable learning by separately tracking the agent’s performance on every scheduling task and rewarding only policies contributing towards better scheduling solutions. We implement all solution design patterns as a set of interchangeable modules with a shared API, unified in a benchmarking framework with the focus on standardization of training and evaluation processes, reproducibility and simplified experiment lifecycle management. In addition to the framework, we make available our discrete-event simulation of a job shop production.},
  archive      = {J_EAAI},
  author       = {Vladimir Samsonov and Karim Ben Hicham and Tobias Meisen},
  doi          = {10.1016/j.engappai.2022.104868},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104868},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reinforcement learning in manufacturing control: Baselines, challenges and ways forward},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Application of multi-objective particle swarm optimization
based on short-term memory and k-means clustering in multi-modal
multi-objective optimization. <em>EAAI</em>, <em>112</em>, 104866. (<a
href="https://doi.org/10.1016/j.engappai.2022.104866">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve the multi-modal multi-objective optimization problems in which the same Pareto Front (PF) may correspond to multiple different Pareto Optimal Sets (PSs), an improved multi-objective particle swarm optimizer with short-term memory and K-means clustering (MOPSO-SMK) is proposed in this paper. According to the framework of multi-objective particle swarm optimization (MOPSO) algorithm, the designs of updating mechanism and population maintenance mechanism are the keys to obtain the optimal solutions. As a significant influence factor of the updating mechanism, the inertia weight has been discussed in this paper. In the improved algorithm, a new update model for the value of pbest based on short-term memory is proposed. The update strategies based on K-means clustering are adopted to obtain the better gbest and elite archive. 16 multi-modal multi-objective optimization functions are used to verify the feasibility and effectiveness of the proposed MOPSO-SMK. As the results show, MOPSO-SMK has more advantages in four indexes (1/PSP, 1/HV, IGDX, and IGDF) compared with other three multi-objective optimization algorithms.},
  archive      = {J_EAAI},
  author       = {Yang Yang and Qianfeng Liao and Jiang Wang and Yuan Wang},
  doi          = {10.1016/j.engappai.2022.104866},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104866},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Application of multi-objective particle swarm optimization based on short-term memory and K-means clustering in multi-modal multi-objective optimization},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Combining feature importance and neighbor node interactions
for cold start recommendation. <em>EAAI</em>, <em>112</em>, 104864. (<a
href="https://doi.org/10.1016/j.engappai.2022.104864">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cold start recommendation usually views preference embedding as a missing problem because there is not any historical interaction. Existing approaches on graph neural networks for cold start users/items build the attribute embedding of each node through simply concatenating multiple features equally, and then reconstruct node preference embedding from its attribute embedding through a mapping function which is learned from warm users/items. However, these approaches do not consider the different contributions of features for building the attribute embedding. In addition, they assume the neighbors of a target node are independent and ignore interactions between the neighbor nodes when building the mapping function between the attribute embedding and the preference embedding. These two limitations reduce the effectiveness of their performance. To overcome these limitations, we propose a novel framework called Feature Importance and Neighbor node Interactions graph neural network (FINI) that exploits feature weights and interactions between neighbor nodes. The core ideas of the proposed method are as follows. First, it designs a global–local contexts attention mechanism in the attribute encoding layer, which can dynamically learn the importance of the attributes of each node and improve the expression of the feature embeddings. Second, it proposes a mixed interaction mechanism to augment the weighted information of neighbor node interactions in the neighbor interaction layer, which can strengthen the expressive capability of the user/item embeddings and further improve the quality of the mapping function for cold start users/items. Additionally, we also combine the rating prediction loss and mimic loss as the total loss to train the network in the prediction layer for model training. To assess the performance of the FINI, both cold start users and cold start items recommendation are considered. The results demonstrate FINI outperforms the state-of-the-art approaches for cold start recommendation and gains significant improvements in terms of metric evaluations.},
  archive      = {J_EAAI},
  author       = {Jinjin Zhang and Chenhui Ma and Chengliang Zhong and Peng Zhao and Xiaodong Mu},
  doi          = {10.1016/j.engappai.2022.104864},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104864},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Combining feature importance and neighbor node interactions for cold start recommendation},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-supervised monocular depth estimation in dynamic scenes
with moving instance loss. <em>EAAI</em>, <em>112</em>, 104862. (<a
href="https://doi.org/10.1016/j.engappai.2022.104862">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating depth from monocular images is a powerful method to perceive valuable environmental information, which is essential for applications that require three-dimensional (3D) environmental models such as autonomous driving and virtual reality. The monocular self-supervised depth estimation method based on deep learning has made rapid progress without depth ground truth information. However, the existing methods are based on the assumption of a static world during training, and depth estimation in a dynamic environment needs further development. To solve this problem, we propose a new monocular self-supervised depth estimation method in dynamic scenes to eliminate the negative impact of moving objects in the image sequence when calculating the self-supervised loss. Specifically, for the self-supervised depth estimation framework, we propose a moving object mask based on the minimum instance photometric residual and then combine it with the mask based on instance re-projection residual in the existing instance-level moving object segmentation methods. In addition, we design a moving instance loss function to process the moving object, so that the training of the model can achieve better performance. Experiments are conducted on public datasets to verify the effectiveness of the proposed method and each of its components, and the results show that our method achieves better performance for depth estimation in dynamic scenes compared to state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Min Yue and Guangyuan Fu and Ming Wu and Xin Zhang and Hongyang Gu},
  doi          = {10.1016/j.engappai.2022.104862},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104862},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-supervised monocular depth estimation in dynamic scenes with moving instance loss},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybrid deep CNN-SVR algorithm for solar radiation prediction
problems in queensland, australia. <em>EAAI</em>, <em>112</em>, 104860.
(<a href="https://doi.org/10.1016/j.engappai.2022.104860">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a new hybrid deep learning (DL) model, the called CSVR, for Global Solar Radiation ( GSR ) predictions by integrating Convolutional Neural Network (CNN) with Support Vector Regression (SVR) approach. First, the CNN algorithm is used to extract local patterns as well as common features that occur recurrently in time series data at different intervals. Then, the SVR is subsequently adopted to replace the fully connected CNN layers to predict the daily GSR time series data at six solar farms in Queensland, Australia. To develop the hybrid CSVR model, we adopt the most pertinent meteorological variables from Global Climate Model and Scientific Information for Landowners database. From a pool of Global Climate Models variables and ground-based observations, the optimal features are selected through a metaheuristic Feature Selection algorithm, an Atom Search Optimization method. The hyperparameters of the proposed CSVR are optimized by mean of the HyperOpt method, and the overall performance of the objective algorithm is benchmarked against eight alternative DL methods, and some of the other Machine Learning approaches (LSTM, DBN, RBF, BRF, MARS, WKNNR, GPML and M5TREE) methods. The results obtained shows that the proposed CSVR model can offer several predictive advantages over the alternative DL models, as well as the conventional ML models. Specifically, we note that the CSVR model recorded a root mean square error/mean absolute error ranging between ≈ 2.172–3.305 MJ m 2 /1.624–2.370 MJ m 2 over the six tested solar farms compared to ≈ 2.514–3.879 MJ m 2 /1.939–2.866 MJ m 2 from alternative ML and DL algorithms. Consistent with this predicted error, the correlation between the measured and the predicted GSR , including the Willmott’s, Nash-Sutcliffe’s coefficient and Legates &amp; McCabe’s Index was relatively higher for the proposed CSVR model compared to other DL and Machine Learning methods for all of the study sites. Accordingly, this study advocates the merits of CSVR model to provide a viable alternative to accurately predict GSR for renewable energy exploitation, energy demand or other forecasting-based applications.},
  archive      = {J_EAAI},
  author       = {Sujan Ghimire and Binayak Bhandari and David Casillas-Pérez and Ravinesh C. Deo and Sancho Salcedo-Sanz},
  doi          = {10.1016/j.engappai.2022.104860},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104860},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybrid deep CNN-SVR algorithm for solar radiation prediction problems in queensland, australia},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bi-stage multi-modal 3D instance segmentation method for
production workshop scene. <em>EAAI</em>, <em>112</em>, 104858. (<a
href="https://doi.org/10.1016/j.engappai.2022.104858">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The scene perception of a production workshop is the key to realizing its intelligence. Three-dimensional (3D) instance segmentation based on pure deep learning is an effective method for scene perception, but it is difficult to apply in a production workshop owing to the large number of 3D instance segmentation labels required, which are difficult to collect. This paper proposes a bi-stage multi-modal 3D instance segmentation method that realizes high-precision 3D instance segmentation in the absence of 3D instance segmentation labels. The method has two stages: acquisition of two-dimensional (2D) prior information and instance segmentation of the 3D point cloud. In the first stage, an RGB-D multi-modal fusion instance segmentation network is proposed to solve the problem that similar objects are difficult to distinguish in workshop scenes. In the second stage, accurate 3D instance segmentation is achieved by combining the acquired 2D prior information with correlation filtering algorithms. The performance of the proposed 2D and 3D instance segmentation methods is verified based on a self-built dataset: Scene Objects for Production workshop dataset (SOP). In 2D instance segmentation, compared to the sole reliance on RGB features, the mean average precision (mAP) of the instance segmentation network that incorporates depth features is improved by 3.1, to 72.1; in 3D instance segmentation, when the intersection over union (IoU) threshold is 0.35 and the mAP reaches 80.97. The results indicate that the proposed method realizes accurate perception of workshop objects.},
  archive      = {J_EAAI},
  author       = {Zaizuo Tang and Guangzhu Chen and Yinhe Han and Xiaojuan Liao and Qingjun Ru and Yuanyuan Wu},
  doi          = {10.1016/j.engappai.2022.104858},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104858},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Bi-stage multi-modal 3D instance segmentation method for production workshop scene},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-node load forecasting based on multi-task learning
with modal feature extraction. <em>EAAI</em>, <em>112</em>, 104856. (<a
href="https://doi.org/10.1016/j.engappai.2022.104856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate multi-node load forecasting is the key to the safe, reliable, and economical operation of the power system. However, the dynamic nature of load and the coupling nature of networks are difficult to extract, making consistent and accurate forecasting of node load rather difficult. In this regard, this paper proposes a soft sharing multi-task deep learning method for multi-node load forecasting in the power system. It has the following aspects: (1) Considering the coupling characteristics of the node network, a multi-modal feature module, based on the inception strategy and gated temporal convolutional network (GTCN), is firstly designed to explore the coupling features implied in the node load data. (2) A novel multi-objective neural network model is proposed to achieve simultaneous prediction of multi-node load by integrating the multi-modal feature module and gated recurrent unit (GRU). For sharing the learning information of sub-networks, this paper uses the soft sharing mechanism to capture load features, which can better optimize the prediction task for each node load simultaneously. Load data from the New Zealand distribution network and AEMO are used to compare the proposed model’s performance in various scenarios using regression metrics such as mean absolute percentage error (MAPE), Weighted Mean Accuracy (WMA), root mean squared logarithmic error (RMSLE), and Diebold–Mariano (DM). The simulation results show that the proposed method can explore the spatial–temporal coupling characteristics in multi-node load data. Compared with existing state-of-the-art multi-node load prediction methods, our proposed method’s MAPE decrease 17.04% and 3.92% in Non-aggregation and Aggregation situations.},
  archive      = {J_EAAI},
  author       = {Mao Tan and Chenglin Hu and Jie Chen and Ling Wang and Zhengmao Li},
  doi          = {10.1016/j.engappai.2022.104856},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104856},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-node load forecasting based on multi-task learning with modal feature extraction},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Heuristic-driven strategy for boosting aerial photography
with multi-UAV-aided internet-of-things platforms. <em>EAAI</em>,
<em>112</em>, 104854. (<a
href="https://doi.org/10.1016/j.engappai.2022.104854">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicles (UAVs) are gaining much attractiveness due to the emerging 5G, Internet of things applications and the advances in artificial intelligence. Their application fields encompass both civil and military domains. UAVs can ubiquitously supply many Internet-of-things-driven services; as such, they can be configured into airborne networks to provide flexible aerial views, which is essential for photography and videography-based applications like 3D mapping and real-time monitoring. However, many research challenges need to be tackled to facilitate the deployment of such promising applications. This paper addresses a non-convex NP-hard problem of deploying a fleet of UAVs equipped with rotating gimbal-mounted cameras over large-scaled terrains. The problem is heuristically solved in two phases. Firstly, we introduce a fast parallel multi-verse swarm optimization algorithm. A hybrid multi-objective heuristic coalescing two relevant concepts of stochastic optimization: (1) Improved Multi-Objective Particle Swarm Optimization; (2) Improved Multi-Objective Multi-verse Optimization. This heuristic holds several algorithmic tweaks, such as Pareto-based population splitting, Taguchi-based parameters tuning, adaptive mutation, and is used to derive the most near-optimal hovering coordinates of UAVs under two customized objective functions. Secondly, we adopt an efficient gimbal-based rotation and synchronization strategy allowing the UAVs to rotate their cameras resourcefully in four cardinal directions to boost the aerial photographing coverage with few maneuvers. The claimed performance is rigorously endorsed with intensive simulations and comparative analyses (e.g., analysis of variances, Wilcoxon test, performance index) against twenty multi-objective bio-inspired heuristics. The results show that our approach has the upper hand in terms of efficiency and accuracy.},
  archive      = {J_EAAI},
  author       = {Houssem Eddine Mohamadi and Nadjia Kara and Mohand Lagha},
  doi          = {10.1016/j.engappai.2022.104854},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104854},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Heuristic-driven strategy for boosting aerial photography with multi-UAV-aided internet-of-things platforms},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An evolutionary multi-objective path planning of a fleet of
ASVs for patrolling water resources. <em>EAAI</em>, <em>112</em>,
104852. (<a
href="https://doi.org/10.1016/j.engappai.2022.104852">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid increase of human activities with direct influence on the environment has motivated the global awareness of the need to efficiently monitor the natural resources. Among the wide range of problems addressed, such as overuse of agrochemicals, uncontrolled waste, etc., the contamination of water resources plays a protagonist role, given its close links with biodiversity and the food chain. Water monitoring is considered one of the most efficient ways to deal with these problems, especially through the use of autonomous vehicles, which can boost the capabilities and efficiency of the monitoring routines with appropriate strategies. In this work, the monitoring problem is addressed by means of the Non-Homogeneous Patrolling Problem with closed circuits. This problem has a great computational complexity, especially when multiple targets are included in a monitoring mission. A formulation based on closed metric graphs and the application of a multi-objective genetic algorithm is proposed to provide Pareto-efficient monitoring solutions for a variable number of Autonomous Surface Vehicles. To address the multi-agent, multi-objective and constrained paradigm, efficient genetic operators have been designed for the generation of valid solutions in an affordable time. The method results in Pareto-efficient solutions for scenarios with disjoint and uncorrelated objectives, which outperform the fitness of other solutions by a factor of 2, on average. The results provide decision makers a method to find different non-dominated strategies depending on the monitoring needs, depending on fleet and vehicle size.},
  archive      = {J_EAAI},
  author       = {Samuel Yanes Luis and Federico Peralta and Alejandro Tapia Córdoba and Álvaro Rodríguez del Nozal and Sergio Toral Marín and Daniel Gutiérrez Reina},
  doi          = {10.1016/j.engappai.2022.104852},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104852},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An evolutionary multi-objective path planning of a fleet of ASVs for patrolling water resources},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Impact of deep reinforcement learning on variable speed
limit strategies in connected vehicles environments. <em>EAAI</em>,
<em>112</em>, 104850. (<a
href="https://doi.org/10.1016/j.engappai.2022.104850">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Variable Speed Limit (VSL) control is considered in the context of connected vehicles acting as moving sensors, while their obedience to speed limit is enforced by a mandatory Intelligent Speed Adaptation (ISA) system. The objective of this study is to extend spatially static differential VSL control by introducing novel VSL strategies that are based on spatially dynamic speed limit zones. The spatial configuration of speed limit zones requires a novel traffic state representation based on the set of consecutive matrices which encode each vehicle position and speed within the controlled motorway during the control time step. The actions for all proposed VSL strategies are computed by the same Deep Reinforcement Learning (DRL) approach based on the Deep Deterministic Policy Gradient (DDPG) architecture. The DDPG learning models contain integration of Convolution and Long Short-Term Memory (LSTM) known as ConvLSTM layers, along with the Convolution and Fully Connected layers. Thus, those models can learn complex spatio-temporal traffic dynamics based on proposed traffic state representation. The results show that proposed VSL strategies have achieved higher overall motorway throughput compared to one which is based on the static speed limit zones and baseline cases (no-control and Simple Proportional Speed Controller algorithm). Simultaneously, they achieved a minimal increase in the number of aggressive braking, while the average headway is increased. All proposed VSL control approaches are simulated and analyzed by using a synthetic microscopic motorway model and characteristic traffic scenario for urban motorways.},
  archive      = {J_EAAI},
  author       = {Martin Gregurić and Krešimir Kušić and Edouard Ivanjko},
  doi          = {10.1016/j.engappai.2022.104850},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104850},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Impact of deep reinforcement learning on variable speed limit strategies in connected vehicles environments},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A graph convolutional encoder and multi-head attention
decoder network for TSP via reinforcement learning. <em>EAAI</em>,
<em>112</em>, 104848. (<a
href="https://doi.org/10.1016/j.engappai.2022.104848">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the traveling salesman problem (TSP), it is usually hard to find a high-quality solution in polynomial time. In the last two years, graph neural networks emerge as a promising technique for TSP. However, most related learning-based methods do not make full use of the hierarchical features; thereby, resulting in relatively-low performance. Furthermore, the decoder in those methods only generates single permutation and needs additional search strategies to improve the permutation, which leads to more computing time. In this work, we propose a novel graph convolutional encoder and multi-head attention decoder network (GCE-MAD Net) to fix the two drawbacks. The graph convolutional encoder realizes to aggregate neighborhood information through updated edge features and extract hierarchical graph features from all graph convolutional layers. The multi-head attention decoder takes the first and last selected node embeddings and fused graph embeddings as input to generate probability distributions of selecting next unvisited node in order to consider global features. The GCE-MAD Net further allows to choose several nodes at each time step and generate a permutations pool after decoding to increase diversity of solution space. To assess the performance of GCE-MAD Net, we conduct experiments with randomly generated instances. The simulation results show the proposed GCE-MAD Net outperforms the traditional heuristics methods and existing learning-based algorithms on all evaluation metrics. Especially, when encountering large scale problem instances, the small scale pretrained GCE-MAD Net can get much better solutions than CPLEX solver with less time.},
  archive      = {J_EAAI},
  author       = {Jia Luo and Chaofeng Li and Qinqin Fan and Yuxin Liu},
  doi          = {10.1016/j.engappai.2022.104848},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104848},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A graph convolutional encoder and multi-head attention decoder network for TSP via reinforcement learning},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Relational dynamic bayesian network modeling for uncertainty
quantification and propagation in airline disruption management.
<em>EAAI</em>, <em>112</em>, 104846. (<a
href="https://doi.org/10.1016/j.engappai.2022.104846">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Disruption management during the airline scheduling process can be compartmentalized into proactive and reactive processes depending upon the time of schedule execution. The state of the art for decision-making in airline disruption management involves a heuristic human-centric approach that does not categorically study uncertainty in proactive and reactive processes for managing airline schedule disruptions. Hence, this paper introduces an uncertainty transfer function model (UTFM) framework that characterizes uncertainty for proactive airline disruption management before schedule execution, reactive airline disruption management during schedule execution, and proactive airline disruption management after schedule execution to enable the construction of quantitative tools that can allow an intelligent agent to rationalize complex interactions and procedures for robust airline disruption management. Specifically, we use historical scheduling and operations data from a major U.S. airline to facilitate the development and assessment of the UTFM, defined by hidden Markov models (a special class of probabilistic graphical models) that can efficiently perform pattern learning and inference on portions of large data sets. We employ the UTFM to assess two independent and separately disrupted flight legs from the airline route network. Assessment of a flight leg from Dallas to Houston, disrupted by air traffic control hold for bad weather at Dallas, revealed that proactive disruption management for turnaround in Dallas before schedule execution is impractical because of zero transition probability between turnaround and taxi-out. Assessment of another flight leg from Chicago to Boston, disrupted by air traffic control hold for bad weather at Boston, showed that proactive disruption management before schedule execution is possible because of non-zero state transition probabilities at all phases of flight operation.},
  archive      = {J_EAAI},
  author       = {Kolawole Ogunsina and Marios Papamichalis and Daniel DeLaurentis},
  doi          = {10.1016/j.engappai.2022.104846},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104846},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Relational dynamic bayesian network modeling for uncertainty quantification and propagation in airline disruption management},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Incorporate long association into high-order fuzzy logical
relationship based time series forecasting. <em>EAAI</em>, <em>112</em>,
104844. (<a
href="https://doi.org/10.1016/j.engappai.2022.104844">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In fuzzy logical relationship (FLR) based forecasting models, FLRs play a vital role. In each FLR of such models, the engaged observations in premise and consequent are consecutive at time. The association (named short association in this paper) implied by the premise and consequent of such an FLR can reflect some of the properties and regularities hidden in a time series, which has been verified by more successful applications. However, there exists other kind of associations that cannot be described by short association. In this paper, the concept of long association to describe these different associations is proposed. And long-association FLRs are then proposed to reflect such long associations. For a long-association FLR, the engaged observations in the premise and consequent are not consecutive at time. This new kind of FLRs exists more and can overcome one deficiency of the existing FLR based forecasting models: no FLR available for forecasting occurred often at some prediction moments. Departure from long-association FLRs, we construct trend long-association FLRs to reflect the trend long associations in time series and design a novel forecasting model. The advantages of the proposed (trend) long-association FLRs and the superiority of the proposed model are verified in experiments with comparisons with other forecasting models.},
  archive      = {J_EAAI},
  author       = {Fang Li and Chen Liu and Xiyang Yang},
  doi          = {10.1016/j.engappai.2022.104844},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104844},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Incorporate long association into high-order fuzzy logical relationship based time series forecasting},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Early warning of tunnel collapse based on adam-optimised
long short-term memory network and TBM operation parameters.
<em>EAAI</em>, <em>112</em>, 104842. (<a
href="https://doi.org/10.1016/j.engappai.2022.104842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collapses are common geohazards during tunnel boring machine (TBM) construction under complex geological conditions. This study proposes a tunnel collapse early warning method based on an adaptive momentum estimation optimised long short-term memory (Adam-LSTM) network and TBM operation parameters. Based on the Songhua River water conveyance project, a sample database containing 7538 TBM excavation cycles, three types of geological information, and 18 tunnel collapse statistics is established. A total of 5440 TBM excavation cycles from stable tunnelling sections are used for model training. The key TBM operation parameters in the first 30 s of the parameter-rising phase are used as inputs to the LSTM cell, and the geology data is considered through fully connected layers outside the LSTM cell. Then, the rock-breaking efficiency index (specific energy, Se ) of the stable phase is predicted. Compared with the stable tunnelling section, the prediction accuracy of Se in the collapse section decreases to some degree. In collapse area I (i.e. collapses 15–17), by setting the threshold of the statistical indexes based on 30 consecutive predicted Se , an early warning index system for tunnel collapse is constructed. Collapse area II (i.e. collapses 5–7) and collapse area III (i.e. collapse 18) are used to verify the effectiveness of the proposed method.},
  archive      = {J_EAAI},
  author       = {Shaokang Hou and Yaoru Liu},
  doi          = {10.1016/j.engappai.2022.104842},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104842},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Early warning of tunnel collapse based on adam-optimised long short-term memory network and TBM operation parameters},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Test case generation using improved differential evolution
algorithms with novel hypercube-based learning strategies.
<em>EAAI</em>, <em>112</em>, 104840. (<a
href="https://doi.org/10.1016/j.engappai.2022.104840">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Search-based algorithms are a recent research hotspot for solving path coverage (PC), which is the most critical and challenging problem in the field of automated test case generation (ATCG). There remains a large research space for achieving ATCG-PC’s goal of finding a set of test cases covering all possible paths with as little computational overhead as possible. In contrast to two existing research approaches of testing different search-based algorithms and developing different fitness functions, this paper proposes two learning strategies based on a hypercube (termed HBL and THBL), which are inspired by a problem-specific knowledge expressed by the mathematical formulas of different fitness functions for ATCG-PC. The hypercubes of HBL and THBL are developed via an opposition-based learning strategy around the current best solution. The two learning strategies can guide search-based algorithms to search for test cases that cover uncovered paths. Two improved differential evolutionary algorithms based on HBL and THBL are then proposed to solve ATCG-PC. Experimental studies on thirty instances generated by eight classical benchmark programs and six fog computing benchmark programs show that the proposed algorithms achieve highest path coverage with fewer test cases and less running time than some compared state-of-the-art algorithms.},
  archive      = {J_EAAI},
  author       = {Qinghua Su and Gaocheng Cai and Zhongbo Hu and Xianshan Yang},
  doi          = {10.1016/j.engappai.2022.104840},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104840},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Test case generation using improved differential evolution algorithms with novel hypercube-based learning strategies},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tri-reference point method for q-rung orthopair fuzzy
multiple attribute decision making by considering the interaction of
attributes with bayesian network. <em>EAAI</em>, <em>112</em>, 104838.
(<a href="https://doi.org/10.1016/j.engappai.2022.104838">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an irrational behavior theory, the tri-reference point (TRP) method proposed by combining multiple reference points and practical scenarios can consider more complex and realistic scenarios. In order to explore the application of TRP under q -rung orthopair fuzzy ( q -ROF) environment, we construct a new TRP model and solve the multi-attribute decision making (MADM) problem with Bayesian network (BN). More specifically, considering that BN can automatically learn the relationship of attributes from both the direction of influence and the degree of interaction, we firstly introduce the BN into q -ROF environment to depict the interaction between attributes in a MADM. BN can deduce posterior probability according to the prior knowledge, so it can calculate the probabilities of attributes for a MADM problem under q -ROF environment. Based on their probabilities, we further propose an improved Borda score method to calculate the attributes weights. Then, inspired by prospect theory, we develop a new TRP model by utilizing the double- S shape of TRP. Meanwhile, a novel comparison method for two q -rung orthopair fuzzy numbers ( q -ROFNs) is presented which combines possibility degree method and score function. Finally, we give an example of land investment project selection of rural cooperative to elaborate and verify our proposed method.},
  archive      = {J_EAAI},
  author       = {Decui Liang and Wen Cao and Zeshui Xu},
  doi          = {10.1016/j.engappai.2022.104838},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104838},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Tri-reference point method for q-rung orthopair fuzzy multiple attribute decision making by considering the interaction of attributes with bayesian network},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sustainable negotiation-based nesting and scheduling in
additive manufacturing systems: A case study and multi-objective
meta-heuristic algorithms. <em>EAAI</em>, <em>112</em>, 104836. (<a
href="https://doi.org/10.1016/j.engappai.2022.104836">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel integrated framework for nesting (i.e., part orientation selection and two-dimensional packing) and scheduling parts assigned to batches (or jobs) on additive manufacturing machines. For the first time, a tri-objective optimization model is designed that interprets profit, energy utilization of machines, and goodwill losses (i.e., tardiness, negotiation, and increasing due date) as three sustainability criteria. Besides, considered negotiation plans may reduce the prices of ordered parts for a possible increase in the initial due date set by customers. The model’s scalability is supported by tailoring three algorithms: robust improved ɛ -constraint method, non-dominated sorting genetic algorithm (NSGA-II), and multi-objective grey wolf optimizer (MOGWO). Several insights are derived by analyzing the model’s sensitivity to its key parameters and validating its applicability by a case study of Amazon’s last-mile delivery process. The results confirm the conflicting objectives, suggested action plans, and proposed algorithms.},
  archive      = {J_EAAI},
  author       = {Keivan Tafakkori and Reza Tavakkoli-Moghaddam and Ali Siadat},
  doi          = {10.1016/j.engappai.2022.104836},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104836},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Sustainable negotiation-based nesting and scheduling in additive manufacturing systems: A case study and multi-objective meta-heuristic algorithms},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Consensus reaching model for counter-intuitive in d–s
evidence theory and application under 2-tuple linguistic representation.
<em>EAAI</em>, <em>112</em>, 104832. (<a
href="https://doi.org/10.1016/j.engappai.2022.104832">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the information fusion field, Dempster–Shafer (D–S) evidence theory is a multi-source technology to solve the uncertain problems. With the aim of improving the decision accuracy, D–S evidence theory can make full use of information from different sources which are redundant and complementary. However, the influence caused by conflicting evidence during information fusion, named the counter-intuitive result, will confuse the selection of decision-makers (DMs). Inspired by the distance-based uncertainty measure, which is a typical technique used to manage uncertain information, the consensus reaching model is applied to overcome the influence caused by conflicting evidence in this paper. Considering the hesitant and uncertain of cognition, 2-tuple linguistic representation method is introduced to model and manage this vague decision information given by DMs. Finally, a consensus reaching model for counter-intuitive result in D–S evidence theory is put forward. To verify the effectiveness of the proposed method, the selection of plant protection machine suppliers is modeled as a multi-criteria decision-making (MCDM) problem. According to the decision-making process, the best option for plant protection machine suppliers is obtained. The decision result indicates a strong correlation between the consistency value and conflicting value of evidence.},
  archive      = {J_EAAI},
  author       = {Chenliang Li and Xiaobing Yu},
  doi          = {10.1016/j.engappai.2022.104832},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104832},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Consensus reaching model for counter-intuitive in D–S evidence theory and application under 2-tuple linguistic representation},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-objective iterated local search based on decomposition
for job scheduling problems with machine deterioration effect.
<em>EAAI</em>, <em>112</em>, 104826. (<a
href="https://doi.org/10.1016/j.engappai.2022.104826">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work addresses an unrelated parallel machine scheduling problem in which the jobs cause deterioration of the machines. This factor decreases the performance of the machines, increasing the processing times of the jobs over time. We propose a mixed-integer nonlinear programming model for the problem that has two objectives: to minimize the maximum completion time of jobs (makespan) and to minimize the total time of delay of the jobs. In this paper, we also develop a different approach to extend Iterated Local Search (ILS) meta-heuristic to multi-objective problems. The Iterated Local Search Based on Decomposition (ILS/D) employs the decomposition strategy similar to the Multi-objective Evolutionary Algorithm Based on Decomposition (MOEA/D), in which the ILS is used as the search engine to improve the search process within the structure of the MOEA/D. We compared the ILS/D, MOEA/D and Non-dominated Sorting Genetic Algorithm II (NSGA-II) algorithms. The results show that the ILS/D outperforms the MOEA/D and NSGA-II algorithms by a significant margin. These findings show that the decomposition strategy is beneficial not only for evolutionary algorithms, but is also an efficient way to extend the ILS to multi-objective problems.},
  archive      = {J_EAAI},
  author       = {Vívian Ludimila Aguiar Santos and Thales Francisco Mota Carvalho and Luciana Pereira de Assis and Miri Weiss-Cohen and Frederico Gadelha Guimarães},
  doi          = {10.1016/j.engappai.2022.104826},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104826},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-objective iterated local search based on decomposition for job scheduling problems with machine deterioration effect},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Control with adaptive q-learning: A comparison for two
classical control problems. <em>EAAI</em>, <em>112</em>, 104797. (<a
href="https://doi.org/10.1016/j.engappai.2022.104797">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper evaluates adaptive Q-learning (AQL) and single-partition adaptive Q-learning (SPAQL), two algorithms for efficient model-free episodic reinforcement learning (RL), in two classical control problems ( Pendulum and CartPole ). AQL adaptively partitions the state–action space of a Markov decision process (MDP), while learning the control policy, i.e. , the mapping from states to actions. The main difference between AQL and SPAQL is that the latter learns time-invariant policies, where the mapping from states to actions does not depend explicitly on the time step. This paper also proposes the SPAQL with terminal state (SPAQL-TS), an improved version of SPAQL tailored for the design of regulators for control problems. The time-invariant policies are shown to result in a better performance than the time-variant ones in both problems studied. These algorithms are particularly fitted to RL problems where the action space is finite, as is the case with the CartPole problem. SPAQL-TS solves the OpenAI Gym CartPole problem, while also displaying a higher sample efficiency than trust region policy optimization (TRPO), a standard RL algorithm for solving control tasks. Moreover, the policies learned by SPAQL are interpretable, while TRPO policies are typically encoded as neural networks, and therefore hard to interpret. Yielding interpretable policies while being sample-efficient are the major advantages of SPAQL. The code for the experiments is available at https://github.com/jaraujo98/SinglePartitionAdaptiveQLearning .},
  archive      = {J_EAAI},
  author       = {João Pedro Araújo and Mário A.T. Figueiredo and Miguel Ayala Botto},
  doi          = {10.1016/j.engappai.2022.104797},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104797},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Control with adaptive Q-learning: A comparison for two classical control problems},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An immune plasma algorithm with a modified treatment schema
for UCAV path planning. <em>EAAI</em>, <em>112</em>, 104789. (<a
href="https://doi.org/10.1016/j.engappai.2022.104789">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The success of a task carried out by an unmanned combat aerial vehicle for short UCAV is directly related with the path in the battlefield or operation area. The path of the UCAV should ensure that the probability of being shot down by the enemy weapon systems and the consumption of fuel are optimized. Immune Plasma algorithm (IP algorithm or IPA) is one of the most recent optimization techniques. In this study, the path planning of UCAV was made based on a modified IP algorithm called as centrifuge IPA (centIPA). The performance of the centIPA was first investigated in detail by assigning different values to the control parameters and using various battlefield scenarios. The results obtained by the centIPA were also compared with the results of other metaheuristics and their improved variants under the same conditions. The comparative studies between centIPA and other metaheuristics showed that newly introduced plasma extraction technique significantly contributes to the solving capabilities of IPA and centIPA outperforms its competitors for the vast majority of the test scenarios.},
  archive      = {J_EAAI},
  author       = {Selcuk Aslan},
  doi          = {10.1016/j.engappai.2022.104789},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104789},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An immune plasma algorithm with a modified treatment schema for UCAV path planning},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Discrete tree seed algorithm for urban land readjustment.
<em>EAAI</em>, <em>112</em>, 104783. (<a
href="https://doi.org/10.1016/j.engappai.2022.104783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Land readjustment and redistribution (LR) is an important approach used to realize development plans by converting rural lands to urban land and also providing urban infrastructure. The LR problem, which is a complex challenging real-world problem, is a discrete optimization problem because its structure is similar to TSP (Traveling Salesman Problem) and scheduling problems which are combinatorial optimization problems. Since classical mathematical methods are insufficient for solving NP (Nondeterministic Polynomial) optimization problems due to time limitations, meta-heuristic optimization algorithms are commonly utilized for solving these kinds of problems. In this paper, meta-heuristic algorithms including genetic, particle swarm, differential evolution, artificial bee, and tree seed algorithms are utilized for solving LR problems. The stated meta-heuristic algorithms are used by applying spatial-based crossover and mutation operators depending upon the LR problem on each algorithm. Moreover, a synthetic dataset is used to ensure that the quality of the solution obtained is acceptable to everyone, to prove an optimal solution easily. By utilizing the suggested spatial-based crossover and mutation operators, finding the ideal solution is aimed using the synthetic dataset. In addition, five different modifications on TSA (Tree-Seed Algorithm) are performed and used to solve LR problems. All the modified versions of TSA are carried out only by changing the mechanism of seed reproduction. The novel TSA approaches are respectively named as tcTSA (tournament current), tbTSA (tournament best), pbTSA (personal-best based), t2TSA (double tournament), and elTSA (elitism based). In the experimental studies, the hybrid approach, which includes the crossover and mutation operators, is successfully applied in all of the algorithms under equal conditions for a fair comparison. According to experimental results performed using the dataset, it can be clearly stated that especially t2TSA outperforms all the algorithms in terms of performance and time.},
  archive      = {J_EAAI},
  author       = {Ismail Koc and Yilmaz Atay and Ismail Babaoglu},
  doi          = {10.1016/j.engappai.2022.104783},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104783},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Discrete tree seed algorithm for urban land readjustment},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Solving a novel multi-divisional project portfolio selection
and scheduling problem. <em>EAAI</em>, <em>112</em>, 104771. (<a
href="https://doi.org/10.1016/j.engappai.2022.104771">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A common problem faced by organizations is how to select and schedule an optimal portfolio of projects subject to various constraints, such as a limited budget. This problem is known as the project portfolio selection and scheduling problem (PPSSP). Despite the widespread nature of this problem, no existing model adequately addresses a sufficient set of characteristics that arise in real-world problems. One contribution of this article is the proposal of a novel, practical class of PPSSP that consists of multiple groups of projects, proposed by different sections of a major organization. The proposed problem can be considered as a generalized PPSSP given that many specific PPSSPs reported in the literature can be generated by relaxing certain constraints. As this is a novel formulation, existing algorithms cannot ensure high-quality solutions to this problem. Thus, a further contribution of this article is the design of three hybrid meta-heuristic algorithms based on a custom-purpose heuristic and local search operator. A case problem, inspired by future force design (FFD) in the Australian Defence Force (ADF), is presented to exemplify the applicability of this model to a real-world problem. Results indicate that the obtained solutions are of acceptable quality for implementation.},
  archive      = {J_EAAI},
  author       = {Kyle Robert Harrison and Saber M. Elsayed and Terence Weir and Ivan L. Garanovich and Sharon G. Boswell and Ruhul A. Sarker},
  doi          = {10.1016/j.engappai.2022.104771},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104771},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Solving a novel multi-divisional project portfolio selection and scheduling problem},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A genetic algorithm tool for conceptual structural design
with cost and embodied carbon optimization. <em>EAAI</em>, <em>112</em>,
104711. (<a
href="https://doi.org/10.1016/j.engappai.2022.104711">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conceptual design decisions have the largest influence on a building project’s safety, value, and environmental impact; hence they are commonly assigned to a “senior engineer” to make use of his/her experience. However, the senior engineers can be biased towards solutions inside their area of expertise, which often prevents them from finding the best solutions among alternatives that must consider complex inter-related, and multi-disciplinary parameters. The engineering community could benefit from a rapid and high-quality decision-making method or tool to increase the speed and quality of its high-impact design choices. There are valuable studies in the literature exploiting Artificial Intelligence (AI) to improve the structural design process; however, most of them focus on the final design stage (e.g., Building Information Modeling), and the rest requires an existing project database (e.g., architectural drawings, already decided material types) to propose a small number of initial design alternatives. In this article, we present the development and validation of a genetic algorithm tool based on Non-dominated Sorted Genetic Algorithm II (NSGA-II) that can be used to analyse a wide range of safe, economical and low-CO 2 options for the conceptual design of buildings. The design space starts from a design brief (with only the information about the site characteristics and project objectives). The solutions are explored with the material, grid size, floor type, lateral resistance, and foundation system variables. In a short computational time (&lt; 2 min per run), users are provided with a Pareto graph of a large set of feasible solutions (in terms of cost, embodied CO 2 emissions and free space) that an engineer would not be typically able to evaluate within a traditional conceptual design process. For future applications, the methodology presented in this paper is flexible to include more engineering materials (e.g., timber, masonry, structural glass), complex architectural forms and merge other disciplines in decision making (e.g., building physics construction management, fire safety).},
  archive      = {J_EAAI},
  author       = {Alper Kanyilmaz and Patricia Raquel Navarro Tichell and Daniele Loiacono},
  doi          = {10.1016/j.engappai.2022.104711},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104711},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A genetic algorithm tool for conceptual structural design with cost and embodied carbon optimization},
  volume       = {112},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An improved multisource data fusion method based on a novel
divergence measure of belief function. <em>EAAI</em>, <em>111</em>,
104834. (<a
href="https://doi.org/10.1016/j.engappai.2022.104834">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to manage conflict in Dempster–Shafer (D-S) evidence theory is still an open problem. To address this problem, a novel divergence measure is proposed to measure the distance between evidence. The proposed divergence measure comprehensively considers the difference between sets of belief function and creatively deal with possible zero in the denominator by pre-averaging with base belief function. It satisfies symmetry, nonnegativeness and nondegeneracy. Furthermore, some numerical examples demonstrate that the proposed divergence measure is more reasonable and effective compared with existing belief divergence measures. In addition, based on this proposed divergence measure, a novel fusion method for multisource data is introduced which considers both the uncertainty of the evidence itself and mutual support from other evidence. The proposed fusion method achieves the highest accuracy compared with other existing fusion methods in the experiment and their time complexity is investigated in detail to distinguish them from each other. Finally, the proposed fusion method is applied to a real classification application and gains the highest accuracy in all three categories. Considering its high fusion accuracy and time cost, it is suitable for cases where accuracy is extremely crucial and immediacy is not strictly required. Therefore, it is an effective multisource fusion method on realistic complex cases.},
  archive      = {J_EAAI},
  author       = {Boxun Liu and Yong Deng and Kang Hao Cheong},
  doi          = {10.1016/j.engappai.2022.104834},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104834},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An improved multisource data fusion method based on a novel divergence measure of belief function},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An online semantic mapping system for extending and
enhancing visual SLAM. <em>EAAI</em>, <em>111</em>, 104830. (<a
href="https://doi.org/10.1016/j.engappai.2022.104830">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a real-time semantic mapping approach for mobile vision systems with a 2D to 3D object detection pipeline and rapid data association for generated landmarks. Besides the semantic map enrichment the associated detections are further introduced as semantic constraints into a simultaneous localization and mapping (SLAM) system for pose correction purposes. This way, we are able generate additional meaningful information that allows to achieve higher-level tasks, while simultaneously leveraging the view-invariance of object detections to improve the accuracy and the robustness of the odometry estimation. We propose tracklets of locally associated object observations to handle ambiguous and false predictions and an uncertainty-based greedy association scheme for an accelerated processing time. Our system reaches real-time capabilities with an average iteration duration of 65 ms and is able to improve the pose estimation of a state-of-the-art SLAM by up to 68% on a public dataset. Additionally, we implemented our approach as a modular ROS package that makes it straightforward for integration in arbitrary graph-based SLAM methods.},
  archive      = {J_EAAI},
  author       = {Thorsten Hempel and Ayoub Al-Hamadi},
  doi          = {10.1016/j.engappai.2022.104830},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104830},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An online semantic mapping system for extending and enhancing visual SLAM},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Population structure-learned classifier for high-dimension
low-sample-size class-imbalanced problem. <em>EAAI</em>, <em>111</em>,
104828. (<a
href="https://doi.org/10.1016/j.engappai.2022.104828">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification on high-dimension low-sample-size data (HDLSS) is a challenging problem and it is common to have class-imbalanced data in most application fields. We term this as Imbalanced HDLSS (IHDLSS). Recent theoretical results reveal that the classification criterion and tolerance similarity are crucial to HDLSS, which emphasizes the maximization of within-class variance on the premise of class separability. Based on this idea, a novel linear binary classifier, termed Population Structure-learned Classifier (PSC), is proposed. The proposed PSC can obtain better generalization performance on IHDLSS by maximizing the sum of inter-class scatter matrix and intra-class scatter matrix on the premise of class separability and assigning different intercept values to majority and minority classes. The salient features of the proposed approach are: (1) It works well on IHDLSS; (2) The inverse of high dimensional matrix can be solved in low dimensional space; (3) It is self-adaptive in determining the intercept term for each class; (4) Its computational complexity is analyzed. A series of evaluations are conducted on one simulated data set and ten real-world benchmark data sets on IHDLSS on gene analysis. Experimental results demonstrate that the PSC is superior to the state-of-art methods in IHDLSS.},
  archive      = {J_EAAI},
  author       = {Liran Shen and Meng Joo Er and Weijiang Liu and Yunsheng Fan and Qingbo Yin},
  doi          = {10.1016/j.engappai.2022.104828},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104828},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Population structure-learned classifier for high-dimension low-sample-size class-imbalanced problem},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-localization based on terrestrial and satellite
semantics. <em>EAAI</em>, <em>111</em>, 104824. (<a
href="https://doi.org/10.1016/j.engappai.2022.104824">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to its vast applicability, the semantic interpretation of regions or entities is increasingly attracting the attention of scholars in the robotics community. Recent research in robot vision has equipped, modern autonomous systems with the ability to semantically recognize and segment entities from scenes with the aim to effectively interpret the environment. Extending this notion, the semantic representation of the surroundings is considered to be a fundamental property for robot self-localization, especially in the absence of any georeferencing signal. In this paper, we present a robust algorithm to locate the position of an autonomous agent within a georeferenced map through particle filtering. Specifically, the proposed approach consists of (i) a motion model of metric data from visual odometry, (ii) an observation model of graph-based descriptors with semantic and metric information and (iii) a re-sampling model, based on the stochastic universal sampling. The above components are evaluated under an extensive set of experiments revealing the robustness and accuracy of our final self-localization system.},
  archive      = {J_EAAI},
  author       = {Vasiliki Balaska and Loukas Bampis and Antonios Gasteratos},
  doi          = {10.1016/j.engappai.2022.104824},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104824},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-localization based on terrestrial and satellite semantics},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Diagnosing alzheimer’s disease from on-line handwriting: A
novel dataset and performance benchmarking. <em>EAAI</em>, <em>111</em>,
104822. (<a
href="https://doi.org/10.1016/j.engappai.2022.104822">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neurodegenerative diseases are caused by the progressive degeneration of nerve cells that affect motor skills and cognitive abilities with increasing severity. Unfortunately, there is no cure for this type of disease and their impact can only be slowed down with specific pharmacological and rehabilitative therapies. Early diagnosis, therefore, remains the primary means to delay brain damage and improve the quality of life of people affected. Neurodegenerative diseases also affect movement fine control. Consequently, the analysis of handwriting dynamics can represent an effective tool to support an early diagnosis of these diseases. While many methods have been proposed in the literature based on the use of a wide range of handwriting tasks, researchers have not yet defined a universally accepted standard experimental protocol to collect data. Furthermore, although some databases containing handwriting data have been produced, only a few of them were designed specifically for research on neurodegenerative diseases, and, in most cases, they involve a small number of participants performing a few tasks. Here, we introduce the DARWIN (Diagnosis AlzheimeR WIth haNdwriting) dataset to overcome these drawbacks, which contains handwriting samples from people affected by Alzheimer’s and a control group. The dataset includes data from 174 participants, acquired during the execution of handwriting tasks, performed according to a protocol specifically designed for the early detection of Alzheimer’s. We report the results of the experiments performed to evaluate the effectiveness of the proposed tasks and features in capturing the distinctive aspects of handwriting that support the diagnosis of Alzheimer’s disease.},
  archive      = {J_EAAI},
  author       = {Nicole D. Cilia and Giuseppe De Gregorio and Claudio De Stefano and Francesco Fontanella and Angelo Marcelli and Antonio Parziale},
  doi          = {10.1016/j.engappai.2022.104822},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104822},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Diagnosing alzheimer’s disease from on-line handwriting: A novel dataset and performance benchmarking},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Novel online discriminant analysis based schemes to deal
with observations from known and new classes: Application to industrial
systems. <em>EAAI</em>, <em>111</em>, 104811. (<a
href="https://doi.org/10.1016/j.engappai.2022.104811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In industrial systems, continuous monitoring of process conditions is crucial. Existing discriminant analysis methods, including quadratic discriminant analysis (QDA), Fisher discriminant analysis (FDA), exponential discriminant analysis (EDA), orthonormal discriminant vector (ODV) and kernel Fisher discriminant (KFD), have been widely used in fault classification literature. Although efficient in controlled environment, they may fail in practice as they discriminate through a closed space. They cannot recognize observations that do not belong to their training set. In this paper, we propose statistical subspaces to allow these methods to efficiently deal with unseen observations of unknown classes. Traditional discriminant functions are summarized, and then new decision schemes are presented. Continuous stirred tank reactor (CSTR) and Tennessee Eastman process (TEP) evaluated the performance of the proposed approach and applied it on five popular methods. The results show that the new space has superior performances in term of discrimination between known and unknown faults.},
  archive      = {J_EAAI},
  author       = {Chuyue Lou and M. Amine Atoui and Xiangshun Li},
  doi          = {10.1016/j.engappai.2022.104811},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104811},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Novel online discriminant analysis based schemes to deal with observations from known and new classes: Application to industrial systems},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An intuitionistic fuzzy multi-distance based evaluation for
aggregated dynamic decision analysis (IF-DEVADA): Its application to
waste disposal location selection. <em>EAAI</em>, <em>111</em>, 104809.
(<a href="https://doi.org/10.1016/j.engappai.2022.104809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-criteria decision-making (MCDM) methods used in solving real-life problems are very useful tools as they allow the evaluation of many qualitative and quantitative factors simultaneously. An increasing number of new methods and approaches are being introduced into the literature to overcome different MCDM problems with many proportional and contradictory features. Since the assessments and judgments made for the addressed MCDM problems may vary depending on the conditions that arise in the future, most of the current static MCDM methods can lead to ineffective and wrong decisions. Therefore, there is a need to develop flexible decision models that will enable to deal with a dynamic decision system using current and future information in the literature. In addition, as the decision process brings with its uncertainties arising from incomplete information, the use of intuitionistic fuzzy sets (IFSs) in the decision process will provide a more accurate representation of data and better handle uncertainties that may arise in decision problems. In this study, the extension of the CRITIC method to IFSs is first developed, which takes into account the objective weights of the criteria in an uncertain environment for weighting the criteria. Then, it is intended to develop the extension of the DEVADA method to IFSs in order to create a dynamic decision system capable of dealing with uncertainties. In addition, a stronger multi-measurement system is proposed by considering Euclidean and cosine distances together. To better demonstrate the feasibility and efficiency of the method, the waste disposal location selection problem, where the evaluations are open to temporal changes, is discussed. A comprehensive sensitivity analysis is then performed to verify the stability and effectiveness of the method. Besides, a comparative analysis is presented with distance-based MCDM methods showing the superiority and advantages of the developed method.},
  archive      = {J_EAAI},
  author       = {Nurşah Alkan and Cengiz Kahraman},
  doi          = {10.1016/j.engappai.2022.104809},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104809},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An intuitionistic fuzzy multi-distance based evaluation for aggregated dynamic decision analysis (IF-DEVADA): Its application to waste disposal location selection},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Influence of statistical feature normalisation methods on
k-nearest neighbours and k-means in the context of industry 4.0.
<em>EAAI</em>, <em>111</em>, 104807. (<a
href="https://doi.org/10.1016/j.engappai.2022.104807">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Normalisation is a preprocessing technique widely employed in Machine Learning (ML)-based solutions for industry to equalise the features’ contribution. However, few researchers have analysed the normalisation effect and its implications on the ML algorithm performance, especially on Euclidean distance-based algorithms, such as the well-known K-Nearest Neighbours and K-means. In this sense, this paper formally analyses the effect of normalisation yielding results significantly far from the state-of-the-art traditional claims. In particular, this paper shows that normalisation does not equalise the contribution of the features, with the consequent impact on the performance of the learning process for a particular problem. More concretely, this demonstration is made on K-Nearest Neighbours and K-means Euclidean distance-based ML algorithms. This paper concludes that normalisation can be viewed as an unsupervised Feature Weighting method. In this context, a new metric ( Normalisation weight ) for measuring the impact of normalisation on the features is presented. Likewise, an analysis of the normalisation effect on the Euclidean distance is conducted and a new metric referred to as Proportional influence that measures the features influence on the Euclidean distance is proposed. Both metrics enable the automatic selection of the most appropriate normalisation method for a particular engineering problem, which can significantly improve both the computational cost and classification performance of K-Nearest Neighbours and K-means algorithms. The analytical conclusions are validated on well-known datasets from the UCI repository and a real-life application from the refinery industry.},
  archive      = {J_EAAI},
  author       = {Iratxe Niño-Adan and Itziar Landa-Torres and Eva Portillo and Diana Manjarres},
  doi          = {10.1016/j.engappai.2022.104807},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104807},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Influence of statistical feature normalisation methods on K-nearest neighbours and K-means in the context of industry 4.0},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A meta-inspired termite queen algorithm for global
optimization and engineering design problems. <em>EAAI</em>,
<em>111</em>, 104805. (<a
href="https://doi.org/10.1016/j.engappai.2022.104805">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel bio-inspired termite queen algorithm (TQA) to solve optimization problems by simulating the division of labor in termite populations under a queen’s rule. TQA is benchmarked on a set of 23 functions to test its performance at solving global optimization problems, and applied to six real-world engineering design problems to verify its reliability and effectiveness. Comparative simulation studies with other algorithms are conducted, from whose results it is observed that TQA satisfactorily solves global optimization problems and engineering design problems.},
  archive      = {J_EAAI},
  author       = {Peng Chen and Shihua Zhou and Qiang Zhang and Nikola Kasabov},
  doi          = {10.1016/j.engappai.2022.104805},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104805},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A meta-inspired termite queen algorithm for global optimization and engineering design problems},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spectral and spatial reduction of hyperspectral image guided
by data reconstruction and superpixels. <em>EAAI</em>, <em>111</em>,
104803. (<a
href="https://doi.org/10.1016/j.engappai.2022.104803">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pixel-wise classification of hyperspectral image (HSI) with hundreds of spectral bands often suffers from the Hughes phenomenon. Furthermore, classifying tens or hundreds of thousands of pixels is also time-consuming. Therefore, it is necessary to develop new methods to reduce HSI from dimensionality and space, aiming at classifying HSI quickly and accurately. To address these issues, this paper proposes an effective spectral and spatial reduction method for HSI guided by data reconstruction and superpixels (SSR). Different from the existing dimension reduction methods, the suggested spectral reduction guided by data reconstruction is an integration of band selection and band extraction. The reconstructed low-dimensional image not only retains the main spectral information of HIS, but also is independent of the generation order. Subsequently, based on the assumption of superpixel homogeneity, a novel superpixel-to-sample mapping is defined. This allows us to classify HSI using superpixels rather than pixels to achieve the goal of spatial reduction. As a result, the proposed SSR method reduces HSI spectrally and spatially. Finally, a superpixel-level SVM classifier is designed to classify the reduced HSI to verify the effect of hybrid reduction. Experimental results on three commonly used real hyperspectral datasets show the effectiveness of the proposed method. Compared with several state-of-the-art methods, the proposed method has a superior classification performance in terms of accuracy and efficiency.},
  archive      = {J_EAAI},
  author       = {Quanshan Gao and Fuding Xie and Dan Huang and Cui Jin},
  doi          = {10.1016/j.engappai.2022.104803},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104803},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Spectral and spatial reduction of hyperspectral image guided by data reconstruction and superpixels},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Romie: A domain-independent tool for computer-aided robust
operations management. <em>EAAI</em>, <em>111</em>, 104801. (<a
href="https://doi.org/10.1016/j.engappai.2022.104801">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Romie is a decision support tool based on AI’s latest advances in the domain of robust scheduling. Unlike all existing systems, the tool allows to (i) visually model the operational problem and context entirely (ii) optimize to find near-optimal schedules while taking uncertainty into account and (iii) deal with a combination of various key performance indicators (KPIs). It comes with a web user interface. Part or all of the modelled activities may be associated to random variables describing their stochastic durations, in order to produce schedules that are robust w.r.t. temporal uncertainty. Hence, depending on the pursued KPIs, the schedules maximize a combination of the following terms: the probability of satisfying the problem constraints, the expected return/efficiency, the expected outcome quality, and even the operators’ wellness by minimizing its expected extra-hours. Initially developed for spatial exploration and demonstration in the context of Mars analogue missions (i.e. missions on Earth that simulate condition and aspects of Mars missions), this versatile tool is here applied to operations management in both biotechnology manufacturing and robots parametrization in a cave exploration context.},
  archive      = {J_EAAI},
  author       = {Michael Saint-Guillain and Jonas Gibaszek and Tiago Vaquero and Steve Chien},
  doi          = {10.1016/j.engappai.2022.104801},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104801},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Romie: A domain-independent tool for computer-aided robust operations management},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data-driven model for accommodation of faulty angle of
attack sensor measurements in fixed winged aircraft. <em>EAAI</em>,
<em>111</em>, 104799. (<a
href="https://doi.org/10.1016/j.engappai.2022.104799">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {On March 10, 2019, Ethiopian Airlines’ Boeing 737-8 MAX nose-dived and crashed shortly after takeoff in the south-east of Addis Ababa, near Ejere Town. The cause of the crash was a faulty angle of attack (AOA) sensor. In the past, many aircraft accidents were associated with faulty AOA sensors. The literature uses triplex and duplex AOA sensor fault detection, isolation, and accommodation (SFDIA). The triplex voting mechanism uses three AOA sensors. A critical problem with the triplex method is that the consolidated value inherently depends on the sensor measurements. This problem makes fault detection and isolation susceptible to simultaneous failure. The duplex fault detection and isolation uses two sensors, reducing cost and providing lower protection. We propose using two AOA sensors and a virtual AOA sensor for faulty AOA SFDIA. The proposed faulty AOA sensor detection and isolation algorithm is based on conventional residual analysis with a fixed threshold for faulty AOA sensor detection and isolation. The virtual sensor is a data-driven model based on a recurrent neural network (RNN) for AOA accommodation. We use a combination of simple RNN (sRNN) and gated recurrent units (GRU). The model aims to effectively use the encoder–decoder behavior of the GRU for better AOA accommodation in the case of faulty AOA measurement, faulty velocity measurement, and faulty pitch rate measurement. Test results show that the proposed method can detect, isolate, and accommodate faulty AOA sensors with a lower number of false alarms than a model that uses only long-term memory (LSTM).},
  archive      = {J_EAAI},
  author       = {Bemnet Wondimagegnehu Mersha and Hongbin Ma},
  doi          = {10.1016/j.engappai.2022.104799},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104799},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Data-driven model for accommodation of faulty angle of attack sensor measurements in fixed winged aircraft},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An algorithm to compute time-balanced clusters for the
delivery logistics problem. <em>EAAI</em>, <em>111</em>, 104795. (<a
href="https://doi.org/10.1016/j.engappai.2022.104795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An effective supply chain organization is fundamental for any manufacturing, distribution, retail or wholesale business. New technologies have made considerable improvements in the whole process of inventory management; Artificial Intelligence (AI) represents one of the best options for the industry and their search for more intelligent and robust logistics solutions. Based on a real-world scenario, we approach the challenge of defining delivery routes within a city such that the time they require to be traveled is approximately the same. Moreover, while the routes must ensure that drivers’ workload is time balanced and contract regulations can be met, they also must correspond to a customers’ partition (sectorization) according to well-defined, non-overlapping delivery areas. We introduce an approach to solve the problem through the algorithm HSAC (Hierarchical Simulated Annealing Clustering). The proposed algorithm first applies a divisive approach to the data, using simulated annealing at each step to create time-balanced partitions, and then solves the TSP problem to create optimal routes within the defined groups. Based on real data concerning two Mexican cities, our experimental results show that HSAC can solve the sectorization problem efficiently.},
  archive      = {J_EAAI},
  author       = {Adriana Menchaca-Méndez and Elizabeth Montero and Marisol Flores-Garrido and Luis Miguel-Antonio},
  doi          = {10.1016/j.engappai.2022.104795},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104795},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An algorithm to compute time-balanced clusters for the delivery logistics problem},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning invariant semantic representation for long-term
robust visual localization. <em>EAAI</em>, <em>111</em>, 104793. (<a
href="https://doi.org/10.1016/j.engappai.2022.104793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-term visual localization is a challenging problem in practice, which depends on the observed images captured by airborne camera to make the mobile robot perform the task of pose estimation during continuously navigating in complex scenes. Semantic information in the image has great invariance in changing environment and can be used to generate robust scene descriptor, but the performance of Convolutional Neural Network (CNN) based semantic segmentation highly depends on semantic labels, the generalization ability of the trained model is weak and labeling process for large-scale scene images is labor-intensive. To solve these problems, this paper proposes a new long-term visual localization method which fuses depth and semantic information in the scene, and its novelty lies in: (1) using a module of fusing depth and semantic information in the scene aims to extract the invariant scene representation when the environment changes, which effectively improves the robustness of long-term visual localization task and (2) using a domain adaptation module with the adversarial loss has adaptation ability from virtual dataset to real dataset, which require labor-free semantic labels annotation and generalize to more realistic application scenarios. Finally, the results show that our method outperforms state-of-the-art baselines under various challenging environments on the Extended CMU Seasons and RobotCar Seasons datasets in specific precision metrics.},
  archive      = {J_EAAI},
  author       = {Junjun Wu and Qingwu Shi and Qinghua Lu and Xilin Liu and Xiaoman Zhu and Zeqin Lin},
  doi          = {10.1016/j.engappai.2022.104793},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104793},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning invariant semantic representation for long-term robust visual localization},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The impact of heterogeneous distance functions on missing
data imputation and classification performance. <em>EAAI</em>,
<em>111</em>, 104791. (<a
href="https://doi.org/10.1016/j.engappai.2022.104791">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work performs an in-depth study of the impact of distance functions on K-Nearest Neighbours imputation of heterogeneous datasets. Missing data is generated at several percentages, on a large benchmark of 150 datasets (50 continuous, 50 categorical and 50 heterogeneous datasets) and data imputation is performed using different distance functions (HEOM, HEOM-R, HVDM, HVDM-R, HVDM-S, MDE and SIMDIST) and k values (1, 3, 5 and 7). The impact of distance functions on kNN imputation is then evaluated in terms of classification performance, through the analysis of a classifier learned from the imputed data, and in terms of imputation quality, where the quality of the reconstruction of the original values is assessed. By analysing the properties of heterogeneous distance functions over continuous and categorical datasets individually, we then study their behaviour over heterogeneous data. We discuss whether datasets with different natures may benefit from different distance functions and to what extent the component of a distance function that deals with missing values influences such choice. Our experiments show that missing data has a significant impact on distance computation and the obtained results provide guidelines on how to choose appropriate distance functions depending on data characteristics (continuous, categorical or heterogeneous datasets) and the objective of the study (classification or imputation tasks).},
  archive      = {J_EAAI},
  author       = {Miriam Seoane Santos and Pedro Henriques Abreu and Alberto Fernández and Julián Luengo and João Santos},
  doi          = {10.1016/j.engappai.2022.104791},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104791},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {The impact of heterogeneous distance functions on missing data imputation and classification performance},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A parallel compact firefly algorithm for the control of
variable pitch wind turbine. <em>EAAI</em>, <em>111</em>, 104787. (<a
href="https://doi.org/10.1016/j.engappai.2022.104787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Firefly algorithm (FA) is a meta-heuristic optimization algorithm inspired by the flickering behavior of fireflies. Due to its excellent performance, it has been widely used in engineering field.​ However, FA is a population-based algorithm, which needs to occupy a lot of running memory. It is adverse for some small wind turbines or scenarios with limited memory Therefore, this paper proposes an improved firefly algorithm, called parallel compact firefly algorithm (PCFA). The compact technique helps FA save operation memory, which is advantageous for some usage scenarios limited memory. And the parallel technique helps compact FA achieve better solutions and faster convergence. The proposed PCFA was tested on 28 benchmark functions and applied to the proportional–integral–derivative (PID) parameter tuning of the variable pitch wind turbine. Results demonstrate that (1) PCFA is superior to common compact optimization algorithms not only on less memory consumption, but also on more competitive solutions and faster convergence. (2) PCFA shows the better applicability in the PID parameter tuning of variable pitch wind turbine. It can availably smooth the power output of wind turbine under less memory consumption.},
  archive      = {J_EAAI},
  author       = {Jie Shan and Shu-Chuan Chu and Shao-Wei Weng and Jeng-Shyang Pan and Shi-Jie Jiang and Shi-Guang Zheng},
  doi          = {10.1016/j.engappai.2022.104787},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104787},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A parallel compact firefly algorithm for the control of variable pitch wind turbine},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Underwater image restoration via backscatter pixel prior and
color compensation. <em>EAAI</em>, <em>111</em>, 104785. (<a
href="https://doi.org/10.1016/j.engappai.2022.104785">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of underwater cameras instead of divers to enter complex underwater areas for real-time monitoring of fish, shrimp, and algae is significant to the aquaculture industry. However, underwater images are severely degraded due to light absorption and scattering, limiting the development of underwater computer vision and robot vision perception. To solve blurriness and color degradation issues, this paper developed a restoration method based on backscatter pixel prior and color cast removal from the physical point of view of underwater image degradation. The proposed method used only a single underwater image as an input to estimate various parameters accurately, such as depth map, backscatter map, and illuminant map. Specifically, a backscatter estimation algorithm based on a depth map was proposed to improve the contrast of underwater images. Then, an algorithm was designed to remove color deviation based on the illuminant map. In particular, a color compensation strategy was created that could completely eliminate red artifacts in underwater images that were generated by the strong attenuation of the red channel. We designed comparative experiments from multiple angles on different real underwater image datasets. Experiments showed that the proposed method improved the contrast and removed the color deviation of light absorption compared to several reported methods. Even on underwater images with severe attenuation, the proposed method showed a significant positive effectiveness and stability on color cast removal.},
  archive      = {J_EAAI},
  author       = {Jingchun Zhou and Tongyu Yang and Weishen Chu and Weishi Zhang},
  doi          = {10.1016/j.engappai.2022.104785},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104785},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Underwater image restoration via backscatter pixel prior and color compensation},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predictive hierarchical harmonic emotional neuro-cognitive
control of nonlinear systems. <em>EAAI</em>, <em>111</em>, 104781. (<a
href="https://doi.org/10.1016/j.engappai.2022.104781">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion enables biological organisms to respond quickly and reasonably to uncertain and unpredictable events. This basic survival instinct is remarkably in line with the theory of model predictive control (MPC) that predicts the future occurrences of events to determine a present appropriate action. Specifically, here we propose to resolve the basic challenge of nonlinear MPC in keeping low computational cost by using a modified computational model of the limbic brain. For this purpose, we modify the thalamus–amygdala expansion link by a harmonic function to reach a differentiable and smooth mathematical model. The proposed harmonic emotion-based neuro-cognitive network (HENN) avoids the typical hidden layers in neural networks, leading to a lower computational cost. We then extend this architecture to a hierarchical HENN (H 2 ENN) to reach higher modeling accuracy. Theoretical analysis proves the training algorithm’s convergence for the general case of brain emotional learning (BEL). Specifically, the learning rules are shown to converge in a finite number of iterations if a solution exists. These theoretical results are general and equally applicable to HENN and hierarchical harmonic emotional neuro-cognitive network (H 2 ENN). Predictive control based on H 2 ENN is then applied to control a 3-Prismatic-Spherical-Prismatic (3-PSP) nonlinear parallel robot manipulator and compared with the same general structure that uses a conventional neural network instead. Results indicate the proposed H 2 ENN-based nonlinear MPC approach offers better accuracy. At the same time, its computational cost is twenty times less than the competing method.},
  archive      = {J_EAAI},
  author       = {Hengameh Mirhajianmoghadam and Mohammad-R. Akbarzadeh-T.},
  doi          = {10.1016/j.engappai.2022.104781},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104781},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Predictive hierarchical harmonic emotional neuro-cognitive control of nonlinear systems},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Partial label learning with competitive learning graph
neural network. <em>EAAI</em>, <em>111</em>, 104779. (<a
href="https://doi.org/10.1016/j.engappai.2022.104779">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial Label Learning (PLL) is a weakly supervised learning framework where each instance may be associated with more than one candidate label, among which only one is true. Traditionally, the PLL problem is solved by removing the false candidate labels based on the instance relationship, while the potentially useful information between instances and labels as well as the potential candidate label relationship is ignored. In this paper, a new PLL framework PL-CGNN is proposed, which treats the instances with false labels as noise, and the PLL is reformulated to remove the noise instances. First of all, the feature of each label class is approximately represented by the center point of all the related instances. The significant operation enables the similarity between instances and labels measurable. Next, all the candidate labels for each instance compete for the biggest similarity. To further improve the robustness of the model, the competition procedure for the most similar label is extended to the neighbors of this instance. The label with the most wins is the final ground-truth one. The relationship between candidate labels guides the situation that the competition process develops into. Through iterative competitive learning, each label class approaches the true value. Experiments carried out on diverse datasets show that the performance of the PL-CGNN model is outstanding.},
  archive      = {J_EAAI},
  author       = {Jinfu Fan and Yang Yu and Zhongjie Wang},
  doi          = {10.1016/j.engappai.2022.104779},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104779},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Partial label learning with competitive learning graph neural network},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid decision making aided framework for multi-criteria
decision making with r-numbers and preference models. <em>EAAI</em>,
<em>111</em>, 104777. (<a
href="https://doi.org/10.1016/j.engappai.2022.104777">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a risk modeling about fuzzy numbers, R-numbers have successfully extended to multi-criteria decision making (MCDM) methods for the real-life decision making problems involving the risk and uncertainties associated with fuzzy numbers. To obtain more reliable and robust multi-criteria ranking alternatives in these uncertain situations, a hybrid decision making aided framework involving stochastic multiobjective acceptability analysis (SMAA), robust ordinal regression (ROR), and multi-attributive border approximation area comparison (MABAC) is proposed for MCDM problems with risk factors and preference models. Firstly, some novel operations of the R-numbers associated with triangular fuzzy numbers are proposed to explore a broader application scope. Secondly, a novel MABAC method combined with the R-numbers is proposed for MCDM problems which focus on uncertainty and error of triangular fuzzy numbers. Thirdly, a hybrid decision making aided framework which applies SMAA and ROR into the novel MABAC method is proposed for obtaining robust multi-criteria ranking alternatives through two binary relations, and two measures complement each other. Moreover, a Monte Carlo simulation of the framework is performed. Lastly, an application of assessment of wind energy potential and comparative analysis is provided to illustrate the efficiency and superiority of the proposed framework.},
  archive      = {J_EAAI},
  author       = {Qian Zhao and Yanbing Ju and Peiwu Dong and Ernesto D.R. Santibanez Gonzalez},
  doi          = {10.1016/j.engappai.2022.104777},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104777},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid decision making aided framework for multi-criteria decision making with R-numbers and preference models},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A surrogate-assisted jaya algorithm based on optimal
directional guidance and historical learning mechanism. <em>EAAI</em>,
<em>111</em>, 104775. (<a
href="https://doi.org/10.1016/j.engappai.2022.104775">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An improved Jaya algorithm named surrogate-assisted Jaya algorithm based on optimal directional guidance and historical learning mechanism (SDH-Jaya) is proposed in this study to address the continuous optimization problems. In the SDH-Jaya, a surrogate-assisted model combined with the polynomial model and radial basis model built by the individual with real fitness is introduced to decrease the expensive computational simulations and accelerate the convergence speed. Two co-evolutionary mechanisms, which are named assisted co-evolutionary mechanism and self-learning co-evolutionary mechanism, are proposed to optimize the surrogate model and evolutionary population. Search directions and steps of the SDH-Jaya are adjusted adaptively by the differential vector resulting from the best solution and worst solution in the candidates at each generation. The historical population stored in an archive is selected randomly to provide new search areas for improving the diversity of the population during the evolution process of the SDH-Jaya. The performance of SDH-Jaya is tested on CEC2017 benchmark problems. The experimental results reveal that the effectiveness of the SDH-Jaya algorithm outperforms the classical Jaya algorithm, its variants, and state-of-the-art algorithms in terms of the quality of solution and execution time.},
  archive      = {J_EAAI},
  author       = {Fuqing Zhao and Hui Zhang and Ling Wang and Ru Ma and Tianpeng Xu and Ningning Zhu and Jonrinaldi},
  doi          = {10.1016/j.engappai.2022.104775},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104775},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A surrogate-assisted jaya algorithm based on optimal directional guidance and historical learning mechanism},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A systematic literature review on software defect prediction
using artificial intelligence: Datasets, data validation methods,
approaches, and tools. <em>EAAI</em>, <em>111</em>, 104773. (<a
href="https://doi.org/10.1016/j.engappai.2022.104773">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Delivering high-quality software products is a challenging task. It needs proper coordination from various teams in planning, execution, and testing. Many software products have high numbers of defects revealed in a production environment. Software failures are costly regarding money, time, and reputation for a business and even life-threatening if utilized in critical applications. Identifying and fixing software defects in the production system is costly, which could be a trivial task if detected before shipping the product. Binary classification is commonly used in existing software defect prediction studies. With the advancements in Artificial Intelligence techniques, there is a great potential to provide meaningful information to software development teams for producing quality software products. An extensive survey for Software Defect Prediction is necessary for exploring datasets, data validation methods, defect detection, and prediction approaches and tools. The survey infers standard datasets utilized in early studies lack adequate features and data validation techniques. According to the finding of the literature survey, the standard datasets has few labels, resulting in insufficient details regarding defects. Systematic Literature Reviews (SLR) on Software Defect Prediction are limited. Hence this SLR presents a comprehensive analysis of defect datasets, dataset validation, detection, prediction approaches, and tools for Software Defect Prediction. The survey exhibits the futuristic recommendations that will allow researchers to develop a tool for Software Defect Prediction. The survey introduces the architecture for developing a software prediction dataset with adequate features and statistical data validation techniques for multi-label classification for software defects.},
  archive      = {J_EAAI},
  author       = {Jalaj Pachouly and Swati Ahirrao and Ketan Kotecha and Ganeshsree Selvachandran and Ajith Abraham},
  doi          = {10.1016/j.engappai.2022.104773},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104773},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A systematic literature review on software defect prediction using artificial intelligence: Datasets, data validation methods, approaches, and tools},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Wind turbine pitch reinforcement learning control improved
by PID regulator and learning observer. <em>EAAI</em>, <em>111</em>,
104769. (<a
href="https://doi.org/10.1016/j.engappai.2022.104769">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wind turbine (WT) pitch control is a challenging issue due to the non-linearities of the wind device and its complex dynamics, the coupling of the variables and the uncertainty of the environment. Reinforcement learning (RL) based control arises as a promising technique to address these problems. However, its applicability is still limited due to the slowness of the learning process. To help alleviate this drawback, in this work we present a hybrid RL-based control that combines a RL-based controller with a proportional–integral–derivative (PID) regulator, and a learning observer. The PID is beneficial during the first training episodes as the RL based control does not have any experience to learn from. The learning observer oversees the learning process by adjusting the exploration rate and the exploration window in order to reduce the oscillations during the training and improve convergence. Simulation experiments on a small real WT show how the learning significantly improves with this control architecture, speeding up the learning convergence up to 37%, and increasing the efficiency of the intelligent control strategy. The best hybrid controller reduces the error of the output power by around 41% regarding a PID regulator. Moreover, the proposed intelligent hybrid control configuration has proved more efficient than a fuzzy controller and a neuro-control strategy.},
  archive      = {J_EAAI},
  author       = {J. Enrique Sierra-Garcia and Matilde Santos and Ravi Pandit},
  doi          = {10.1016/j.engappai.2022.104769},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104769},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Wind turbine pitch reinforcement learning control improved by PID regulator and learning observer},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Aerial combat maneuvering policy learning based on
confrontation demonstrations and dynamic quality replay. <em>EAAI</em>,
<em>111</em>, 104767. (<a
href="https://doi.org/10.1016/j.engappai.2022.104767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Combat Aerial Vehicles (UCAVs) is becoming a crucial platform to perform dangerous missions with the ability of autonomy and intelligence in making decisions. Recently, many researches have focused on UCAV air-to-air combat mission and attempted to solve maneuvering policy using deep reinforcement learning (DRL). Yet, previous studies on the sequential decision problem often have limitations due to the complexity of combat environment, overdependence on expert knowledge, and low learning efficiency from large-scale exploration space. In view of the lacks, the paper aims to automatically formulate counter maneuvers with the application of DRL and proposes a novel dynamic quality replay (DQR) method which is capable of guiding agent learn tactical policy from historical data efficiently, and can get rid of the dependence on traditional expert knowledge. Firstly, in order to accelerate model convergence, confrontation demonstrations generated with traditional algorithms are used for agent basic training before interacting with the environment. Moreover, the formal training is divided into four stages, in which DQR introduces a common framework to filter new interactive data for memory replay, including the process of classification, evaluation and sampling. The episodes are classified into different class based on opponent models and confrontation result. DQR can evaluate sample quality in each class and sample training batch with episode quality dynamically The new method is suitable for continuous action or discrete action space, and can makes pay-offs between specific demonstrations and exploration. Finally, we designed different initial engagement scenarios to train the agent models, whose basic algorithms are DQN, VPG, DDPG and SAC. In the test experiment, the winning rate of models can reach 0.6 or more, and the best model SAC can reach 0.8 for each stage, which means the feasibility and efficiency of the methods.},
  archive      = {J_EAAI},
  author       = {Dongyuan Hu and Rennong Yang and Ying Zhang and Longfei Yue and Mengda Yan and Jialiang Zuo and Xiaoru Zhao},
  doi          = {10.1016/j.engappai.2022.104767},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104767},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Aerial combat maneuvering policy learning based on confrontation demonstrations and dynamic quality replay},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SEM: Safe exploration mask for q-learning. <em>EAAI</em>,
<em>111</em>, 104765. (<a
href="https://doi.org/10.1016/j.engappai.2022.104765">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most reinforcement learning algorithms focus on discovering the optimal policy to maximize reward while neglecting the safety issue during the exploration stage, which is not acceptable in industrial applications. This paper concerns the efficient method to improve the safety of the agent during the exploration stage in q-learning without any prior knowledge. We propose a novel approach named safe exploration mask to reduce the number of safety violations in q-learning by modifying the transition possibility of the environment. To this end, a safety indicator function consisting of distance metric and controllability metric is designed. The safety indicator function can be learned by the agent through bootstrapping without additional optimization solver. We prove that the safety indicator function will converge in tabular q-learning and introduce two tricks to mitigate the divergence in approximation-based q-learning. Based on the safety indicator function, the safe exploration mask is generated to modify the original exploration policy by reducing the transition possibility of unsafe actions. Finally, the simulations in both discrete and continuous environments demonstrate the advantages, feasibility, and safety of our method in both discrete and continuous q-learning algorithms.},
  archive      = {J_EAAI},
  author       = {Chengbin Xuan and Feng Zhang and Hak-Keung Lam},
  doi          = {10.1016/j.engappai.2022.104765},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104765},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {SEM: Safe exploration mask for q-learning},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A powerful meta-heuristic search algorithm for solving
global optimization and real-world solar photovoltaic parameter
estimation problems. <em>EAAI</em>, <em>111</em>, 104763. (<a
href="https://doi.org/10.1016/j.engappai.2022.104763">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The teaching-learning-based artificial bee colony (TLABC) is a new hybrid swarm-based metaheuristic search algorithm. It combines the exploitation of the teaching learning-based optimization (TLBO) with the exploration of the artificial bee colony (ABC). With the hybridization of these two nature-inspired swarm intelligence algorithms, a robust method has been proposed to solve global optimization problems. However, as with swarm-based algorithms, with the TLABC method, it is a great challenge to effectively simulate the selection process. Fitness-distance balance (FDB) is a powerful recently developed method to effectively imitate the selection process in nature. In this study, the three search phases of the TLABC algorithm were redesigned using the FDB method. In this way, the FDB-TLABC algorithm, which imitates nature more effectively and has a robust search performance, was developed. To investigate the exploitation, exploration, and balanced search capabilities of the proposed algorithm, it was tested on standard and complex benchmark suites (Classic, IEEE CEC 2014, IEEE CEC 2017, and IEEE CEC 2020). In order to verify the performance of the proposed FDB-TLABC for global optimization problems and in the photovoltaic parameter estimation problem (a constrained real-world engineering problem) a very comprehensive and qualified experimental study was carried out according to IEEE CEC standards. Statistical analysis results confirmed that the proposed FDB-TLABC provided the best optimum solution and yielded a superior performance compared to other optimization methods.},
  archive      = {J_EAAI},
  author       = {Serhat Duman and Hamdi Tolga Kahraman and Yusuf Sonmez and Ugur Guvenc and Mehmet Kati and Sefa Aras},
  doi          = {10.1016/j.engappai.2022.104763},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104763},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A powerful meta-heuristic search algorithm for solving global optimization and real-world solar photovoltaic parameter estimation problems},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Characterization of the autoencoder radiation anomaly
detection (ARAD) model. <em>EAAI</em>, <em>111</em>, 104761. (<a
href="https://doi.org/10.1016/j.engappai.2022.104761">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we demonstrate an in-depth analysis and characterization of the Autoencoder Radiation Anomaly Detection (ARAD) algorithm. ARAD is a deep convolutional autoencoder designed to detect anomalous radioactive signatures in gamma-ray spectra collected by NaI(Tl) detectors. This model works by learning a dimensionally constrained representation of background gamma-ray spectra called the latent space. The latent space cannot fully describe anomalous components in new spectra, resulting in a decrease in spectral reconstruction accuracy that triggers an alarm. This paper demonstrates the model’s performance on a set of data collected outside of the High Flux Isotope Reactor and Radiochemical Engineering Development Center facilities at Oak Ridge National Laboratory. We also perform an evaluation of the model’s detection performance using a set of publicly available synthetic data representing a radiation detector moving throughout an urban city street. We demonstrate the algorithm’s ability to detect sources in locations with highly dynamic background count rates resulting from variations in naturally occurring radioactive materials and precipitation-induced radon washout, a challenge for many traditional radiation detection algorithms. We compare these results against those from another unsupervised radiation anomaly detection algorithm based on principal component analysis. ARAD achieved excellent performance on both datasets and proves the viability and efficacy of autoencoders for radiation anomaly detection.},
  archive      = {J_EAAI},
  author       = {James M. Ghawaly Jr. and Andrew D. Nicholson and Daniel E. Archer and Michael J. Willis and Irakli Garishvili and Brandon Longmire and Andrew J. Rowe and Ian R. Stewart and Matthew T. Cook},
  doi          = {10.1016/j.engappai.2022.104761},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104761},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Characterization of the autoencoder radiation anomaly detection (ARAD) model},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhancing underwater image via adaptive color and contrast
enhancement, and denoising. <em>EAAI</em>, <em>111</em>, 104759. (<a
href="https://doi.org/10.1016/j.engappai.2022.104759">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images captured under water are often characterized by low contrast, color distortion, and noise, hindering some visual tasks carried out on it. Despite remarkable breakthrough has been made in recent years, effective and robust enhancement of degraded image remains a challenging problem. To improve the quality of underwater images, we propose a novel scheme by constructing an adaptive color and contrast enhancement, and denoising (ACCE-D) framework. In the proposed framework, Difference of Gaussian (DoG) filter and bilateral filter are respectively employed to decompose the high-frequency and low-frequency components. Benefited from this separation, we utilize soft-thresholding operation to suppress the noise in the high-frequency component. Specially, the low-frequency component is enhanced by using an adaptive color and contrast enhancement (ACCE) strategy. Moreover, we derive a numerical solution for ACCE, and adopt a pyramid-based strategy to accelerate the solving procedure. Both qualitative and quantitative experiments demonstrate that our strategy is effective in color correction, contrast enhancement, and detail revealing. In the quantitative evaluations, by performing on the 890 real-world underwater images from UIEBD, the proposed method obtains 0.65 UCIQE, 1.59 UIQM, 0.81 FDUM, 1.34 PCQI, 0.62 CBPD, and 7.75 entropy scores, achieving average increase of 5% comparing with several state-of-the-art methods. Furthermore, we have verified the utility of our proposed ACCE-D for enhancing other types of degraded scenes, including foggy scene, sandstorm scene and low-light scene.},
  archive      = {J_EAAI},
  author       = {Xinjie Li and Guojia Hou and Kunqian Li and Zhenkuan Pan},
  doi          = {10.1016/j.engappai.2022.104759},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104759},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing underwater image via adaptive color and contrast enhancement, and denoising},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LOT: An industrial oriented ontology engineering framework.
<em>EAAI</em>, <em>111</em>, 104755. (<a
href="https://doi.org/10.1016/j.engappai.2022.104755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ontology Engineering has captured much attention during the last decades leading to the proliferation of numerous works regarding methodologies, guidelines, tools, resources, etc. including topics which are still being investigated. Even though, there are still many open questions when addressing a new ontology development project, regarding how to manage the overall project and articulate transitions between activities or which tasks and tools are recommended for each step. In this work we propose the Linked Open Terms (LOT) methodology, an overall and lightweight methodology for building ontologies based on existing methodologies and oriented to semantic web developments and technologies. The LOT methodology focuses on the alignment with industrial development, in addition to academic and research projects, and software development, that is making ontology development part of the software industry. This methodology includes lessons learnt from more than 20 years in ontological engineering and its application on 18 projects is reported.},
  archive      = {J_EAAI},
  author       = {María Poveda-Villalón and Alba Fernández-Izquierdo and Mariano Fernández-López and Raúl García-Castro},
  doi          = {10.1016/j.engappai.2022.104755},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104755},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {LOT: An industrial oriented ontology engineering framework},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid grasshopper optimization algorithm and harris hawks
optimizer for combined heat and power economic dispatch problem.
<em>EAAI</em>, <em>111</em>, 104753. (<a
href="https://doi.org/10.1016/j.engappai.2022.104753">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Combined Heat and Power Economic Dispatch (CHPED) is a real-world optimization problem with several complex constraints that has been a topic of studies around energy systems and optimization processes. This paper attempts to conceptualize a potent algorithm by combining the Modified Grasshopper Optimization Algorithm (MGOA) and the Improved Harris Hawks Optimizer (IHHO) for attaining a better balance between the beginning stages of global search and the latter stages of global convergence. The proposed attempt is abbreviated as MGOA-IHHO. Firstly, the chaotic and Opposition-Based Learning (OBL) methods are invoked to generate the initial population. Second, the mathematical model of the conventional Grasshopper Optimization Algorithm (GOA) is modified using Sine–Cosine Acceleration Coefficients (SCAC) to simulate the global exploration at the initial iterations and graduating to the global convergence at the final stages of optimization. Hence, it is named MGOA. Finally, the adaptive search mechanism integrates the two improved search phases of HHO with a search phase of MGOA to improve the performance of the proposed optimization method. This mechanism investigates the best solution for the aging level of the individual during the optimal evaluation process for choosing an appropriate search phase in MGOA-IHHO. The intended effect of the proposed MGOA-IHHO method is verified with other nature-inspired methods on standard single-objective test functions including 23 benchmark problems, 30 test suits of IEEE Congress on Evolutionary Computation 2017 (CEC2017), and four CHPED problems. The statistical results ascertain that the proposed hybridized MGOA-IHHO is capable of providing promising results when compared with its variants and optimization algorithms introduced in the literature.},
  archive      = {J_EAAI},
  author       = {Murugan Ramachandran and Seyedali Mirjalili and Morteza Nazari-Heris and Deiva Sundari Parvathysankar and Arunachalam Sundaram and Christober Asir Rajan Charles Gnanakkan},
  doi          = {10.1016/j.engappai.2022.104753},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104753},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid grasshopper optimization algorithm and harris hawks optimizer for combined heat and power economic dispatch problem},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive nearest neighbor reconstruction with deep
contractive sparse filtering for fault diagnosis of roller bearings.
<em>EAAI</em>, <em>111</em>, 104749. (<a
href="https://doi.org/10.1016/j.engappai.2022.104749">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Case-based intelligent fault diagnosis has had some notable successes in recent years. However, compared with parameter-based methods, they pay less attention to automatic and powerful feature extraction. Meanwhile, most approaches use k -nearest neighbor (KNN) algorithms or related variants, which fail in adaptive nearest neighbor location. To deal with these shortcomings, an algorithm called adaptive nearest neighbor reconstruction (ANNR) is proposed, which can take advantage of both parameter- and case-based diagnosis methods. Firstly, ANNR offers sparse and robust feature extraction by designed deep contractive sparse filtering (DCSF), which fuses a local contractive term to learn robust feature manifolds. Secondly, to locate the nearest neighbors for diverse testing samples adaptively, a case-based reconstruction algorithm is developed to obtain correlation vectors between training and testing samples. Finally, according to correlation vector of each testing sample, its optimized nearest neighbors are located, enabling precise feature classification. Extensive experiments were conducted on two roller bearing vibration signal datasets and verified its effectiveness.},
  archive      = {J_EAAI},
  author       = {Weiwei Qian and Shunming Li and Jiantao Lu},
  doi          = {10.1016/j.engappai.2022.104749},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104749},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive nearest neighbor reconstruction with deep contractive sparse filtering for fault diagnosis of roller bearings},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning-based airborne sensor task assignment in unknown
dynamic environments. <em>EAAI</em>, <em>111</em>, 104747. (<a
href="https://doi.org/10.1016/j.engappai.2022.104747">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In sensor management, the existing researches rely on traditional system modeling and strive to maximize the information superiority. In fact, on the one hand, complex environmental disturbance, incomplete information or uncooperative behavior in air combat missions often bring out unknown system evolution; on the other hand, to take full advantage of sensor effectiveness is of course essential, but more importantly, the detection security is the primary guarantee. This paper proposes the airborne sensor task assignment problem in unknown dynamic environments. Different from traditional methods that minimize the estimation error covariance or information entropy based on system dynamic model, our scheme needs to maximize agent survival while maintaining the necessary sensor detection without such model support. In assignment implementation, it is not straightforward to apply existing reinforcement learning methods, but design the state space and rewards ingeniously to meet the actual combat requirements. First, instead of selecting the locations of agents and targets as fundamental and infinite state variables, we consider the situation variables, such as target threat ranking together with cumulative radiation and information acquisition indication of sensors, which are all discrete state variables to reduce computational burden. Second, the reward structure is also designed based on the complex constraints of the mission, which is to encourage lower assignment risk and relatively full utilization of sensing, while penalizing too dangerous continuance assignment and inadequate assignment revenue. Simulations show that our proposed scheme achieves the desirable mission completion rate and the acceptable target tracking accuracy.},
  archive      = {J_EAAI},
  author       = {Jing He and Yuedong Wang and Yan Liang and Jinwen Hu and Shi Yan},
  doi          = {10.1016/j.engappai.2022.104747},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104747},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning-based airborne sensor task assignment in unknown dynamic environments},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Comprehensive driver behaviour review: Taxonomy, issues and
challenges, motivations and research direction towards achieving a smart
transportation environment. <em>EAAI</em>, <em>111</em>, 104745. (<a
href="https://doi.org/10.1016/j.engappai.2022.104745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this article is to review and analyse previous academic articles associated with car behaviour analysis for the period of 2010 to June 10, 2021 and understand the benefits of using data collection devices. Articles related to car driver behaviour and sensor utilisation are systematically searched. Three major databases – ScienceDirect, IEEE Xplore and Web of Science – were searched. A set of inclusion and exclusion criteria were developed for the search protocol. All articles were coherently classified via taxonomy. Also. The motives that have led researchers to continue their investigations are explored. The challenges and issues of driver behaviour analysis are illustrated with respect to power consumption, data analysis, detection, cost, security and privacy, sensor usage and individual challenges. The research direction of this review points towards different aspects based on the critical analysis of the different scenarios of driver behaviour studies in real time situations. Here, the critical behaviour analysis of intelligent transportation system development is addressed. The gaps in the reviewed articles include the following: sensors used during experiments, the effect of thresholds on labelling processes or data balancing and classification accuracy, the thresholds in identifying driving styles in the car-following model, insufficient experiment size (large scale or small scale) and limitations in data pre-processing. An implementation map depicting the steps of the case study is provided to give insights into the procedures and the problems they address. This review is expected to offer valid and clear points, contributing to the enhancement of driver behaviour research.},
  archive      = {J_EAAI},
  author       = {R.A. Zaidan and A.H. Alamoodi and B.B. Zaidan and A.A. Zaidan and O.S. Albahri and Mohammed Talal and Salem Garfan and Suliana Sulaiman and Ali Mohammed and Z.H. Kareem and R.Q. Malik and H.A. Ameen},
  doi          = {10.1016/j.engappai.2022.104745},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104745},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Comprehensive driver behaviour review: Taxonomy, issues and challenges, motivations and research direction towards achieving a smart transportation environment},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning transfer feature representations for gas path fault
diagnosis across gas turbine fleet. <em>EAAI</em>, <em>111</em>, 104733.
(<a href="https://doi.org/10.1016/j.engappai.2022.104733">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent data-driven fault diagnosis based on conventional machine learning techniques has been extensively studied in recent years. However, these methods often assumed that the data used for training and testing are drawn from the identical distribution, which is impractical in real application. Such idealized hypothesis may confine these promising data-driven techniques to well-designed experimental environments rather than actually putting them into real-world applications. In practice, the distribution discrepancies between source domain and target domain will degrade the diagnostic performance. To this end, this work introduces a transfer learning based extreme learning machine to align the distribution discrepancies of the data collected from a turbofan engine, which is rarely studied in the fault diagnosis for aero-engine. The proposed method is capable of learning the transferable cross domain features while preserving the properties and structures of source domain as much as possible. Meanwhile, the marginal distribution and conditional distribution discrepancies are matched. Through these transfer data representations, a relatively high diagnostic accuracy is guaranteed. Finally, extensive experiments have been performed on gas path fault diagnosis of turbofan engine, including hybrid transfer cases and complete transfer cases, to verify the effectiveness and feasibility of the proposed method.},
  archive      = {J_EAAI},
  author       = {Bing Li and Yong-Ping Zhao and Yao-Bin Chen},
  doi          = {10.1016/j.engappai.2022.104733},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104733},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning transfer feature representations for gas path fault diagnosis across gas turbine fleet},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-objective improved novel discrete particle swarm
optimization for emergency resource center location problem.
<em>EAAI</em>, <em>111</em>, 104725. (<a
href="https://doi.org/10.1016/j.engappai.2022.104725">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The location of emergency resource centers has always been a great challenge in emergency management, which directly influences the recovery speed of disaster areas and the credibility of the government. Although most studies propose mathematical models based on economic indicators and solve them with various algorithms, few of them consider the panic perceived by the victims, and several algorithms are designed from the characteristics of the problem. To address these issues, we develop an emergency resource center location model (ERCLM) with objectives of the panic perception and the total weighted distance, and then design a multi-objective improved novel discrete particle swarm optimization (MOINDPSO) for it. The main idea of the proposed algorithm is three-fold: 1) The representation of the solution is modified and the search operator is improved by a new mechanism named solution memory. 2) The solutions are evaluated by the idea of fuzzy correlation entropy analysis (FCEA), which is efficient in the selection of better solutions. 3) An external archive is used to store the nondominated solutions, and a mechanism for choosing leaders from the external archive along with a mechanism to enhance the stability for the obtained solutions is put forward. Eventually, numeric experiments of comparison algorithms and ablation experiments of two designed mechanisms are carried out on 26 data sets to show the effectiveness and the universality of the proposed algorithm.},
  archive      = {J_EAAI},
  author       = {Dajiang Peng and Chunming Ye and Mengran Wan},
  doi          = {10.1016/j.engappai.2022.104725},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104725},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-objective improved novel discrete particle swarm optimization for emergency resource center location problem},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel fuzzy clustering based method for image segmentation
in RGB-d images. <em>EAAI</em>, <em>111</em>, 104709. (<a
href="https://doi.org/10.1016/j.engappai.2022.104709">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic image segmentation is a challenging task in computer vision applications, especially in the presence of occluded objects, varying color, and different lighting conditions. The advancement of depth-sensing technologies has introduced RGB-Depth cameras which are capable to generate RGB-Depth images and brought significant changes in computer vision applications. However, the segmentation of RGB-Depth images is a difficult task. Therefore, in this paper, a new segmentation method for RGB-Depth images has been introduced and named as random Henry gas solubility optimization-fuzzy clustering method. Firstly, a random Henry gas solubility optimization algorithm has been developed. Next, the proposed optimization algorithm has been employed to obtain optimal fuzzy clusters which are finally merged through segmentation by aggregating superpixels. The standard NYU depth V2 RGB-Depth indoor image dataset is used for performance evaluation. The proposed segmentation approach has been compared with five different methods namely, kmeans, fuzzy c-means, Henry gas solubility optimization algorithm, chaotic gravitational search algorithm, and J-Segmentation in terms of qualitative and quantitative measures. The result analysis shows that the proposed RGB-D segmentation method outperforms the other considered methods.},
  archive      = {J_EAAI},
  author       = {Nand Kishor Yadav and Mukesh Saraswat},
  doi          = {10.1016/j.engappai.2022.104709},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104709},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel fuzzy clustering based method for image segmentation in RGB-D images},
  volume       = {111},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SimCLRT: A simple framework for contrastive learning of
rumor tracking. <em>EAAI</em>, <em>110</em>, 104757. (<a
href="https://doi.org/10.1016/j.engappai.2022.104757">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the second stage of the rumor defeat task pipeline, rumor tracking aims to filter tweets related to a specific event. However, due to the different levels of attention of different events, events related to fewer tweets may be masked by related to more tweets. In some research, the researchers give up detecting the events containing a small number of tweets for better results. To this end, we propose a Simple Framework for Contrastive Learning of Rumor Tracking (SimCLRT)-a novel rumor tracking framework that uses contrastive learning to alleviate the cover between tweets. SimCLRT contains three variants SimCLRT-CNN, SimCLRT-Linear, and SimCLRT-RNN. We conduct experiments on the two commonly used rumor tracking datasets PHEME and RumorEval. The results show that SimCLRT completely defeated baselines. Like the detection performance on the events that contain many tweets, SimCLRT can also effectively detect events containing a small number of tweets. Furthermore, we compare and analyze the performance of SimCLRT variants. SimCLRT-CNN is the model that performs best in our experiments. Although SimCLRT-Linear has a slight advantage on the RumorEval dataset, its robustness is weaker than SimCLRT-RNN and SimCLRT-CNN. If in a long text environment, we consider SimCLRT-RNN will perform more competitively.},
  archive      = {J_EAAI},
  author       = {Hui Zeng and Xiaohui Cui},
  doi          = {10.1016/j.engappai.2022.104757},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104757},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {SimCLRT: A simple framework for contrastive learning of rumor tracking},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep reinforcement learning with the random neural network.
<em>EAAI</em>, <em>110</em>, 104751. (<a
href="https://doi.org/10.1016/j.engappai.2022.104751">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a Deep Reinforcement Learning (DRL) algorithm that expands the Random Neural Network (RNN) Reinforcement Learning (RL) method to include the previous learnings entirely from previous rewards, rather than only the actual one. The Random Neural Network weighs are updated with the current reward and the previous values, including time and memory. This addition makes DRL slower to make decisions, although it also increases its performance in some experiments. Several configurations to introduce DRL, such as sampling rate and memory duration, are also proposed and analysed in this article. The proposed DRL algorithm is included in a decision process that predicts trends: upward, downward and equal market directions in addition to values. Experimental results based on market prices demonstrate that the addition of Deep Learning to the Reinforcement Learning algorithm increases its performance slightly in some experiments; however, it also increases its computational cost. In random environments such as the stock market, it is preferable to make decisions based on the previous values (short memory) rather than historical records (long memory).},
  archive      = {J_EAAI},
  author       = {Will Serrano},
  doi          = {10.1016/j.engappai.2022.104751},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104751},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep reinforcement learning with the random neural network},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comprehensive survey of clustering algorithms:
State-of-the-art machine learning applications, taxonomy, challenges,
and future research prospects. <em>EAAI</em>, <em>110</em>, 104743. (<a
href="https://doi.org/10.1016/j.engappai.2022.104743">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is an essential tool in data mining research and applications. It is the subject of active research in many fields of study, such as computer science, data science, statistics, pattern recognition, artificial intelligence, and machine learning. Several clustering techniques have been proposed and implemented, and most of them successfully find excellent quality or optimal clustering results in the domains mentioned earlier. However, there has been a gradual shift in the choice of clustering methods among domain experts and practitioners alike, which is precipitated by the fact that most traditional clustering algorithms still depend on the number of clusters provided a priori. These conventional clustering algorithms cannot effectively handle real-world data clustering analysis problems where the number of clusters in data objects cannot be easily identified. Also, they cannot effectively manage problems where the optimal number of clusters for a high-dimensional dataset cannot be easily determined. Therefore, there is a need for improved, flexible, and efficient clustering techniques. Recently, a variety of efficient clustering algorithms have been proposed in the literature, and these algorithms produced good results when evaluated on real-world clustering problems. This study presents an up-to-date systematic and comprehensive review of traditional and state-of-the-art clustering techniques for different domains. This survey considers clustering from a more practical perspective. It shows the outstanding role of clustering in various disciplines, such as education, marketing, medicine, biology, and bioinformatics. It also discusses the application of clustering to different fields attracting intensive efforts among the scientific community, such as big data, artificial intelligence, and robotics. This survey paper will be beneficial for both practitioners and researchers. It will serve as a good reference point for researchers and practitioners to design improved and efficient state-of-the-art clustering algorithms.},
  archive      = {J_EAAI},
  author       = {Absalom E. Ezugwu and Abiodun M. Ikotun and Olaide O. Oyelade and Laith Abualigah and Jeffery O. Agushaka and Christopher I. Eke and Andronicus A. Akinyelu},
  doi          = {10.1016/j.engappai.2022.104743},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104743},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A comprehensive survey of clustering algorithms: State-of-the-art machine learning applications, taxonomy, challenges, and future research prospects},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improved double TQWT sparse representation using the MQGA
algorithm and new norm for aviation bearing compound fault detection.
<em>EAAI</em>, <em>110</em>, 104741. (<a
href="https://doi.org/10.1016/j.engappai.2022.104741">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The double tunable wavelet transform sparse representation realizes signal decomposition by constructing a basis function dictionary that match various characteristic waveforms of compound fault signal. However, the quality factor describing the resonance characteristic of the wavelet basis function can only be determined from practical experience, which is often subjective, and can significantly affect the matching degree between the wavelet basis function and the fault signal. To solve this problem, a new sparse representation method and a new norm are proposed. First, the multi-population quantum genetic algorithm (MQGA) is used to optimize the selected quality factor parameter combinations. The cross-correlated kurtosis of the periodic impact signal is established as the new norm and used to evaluate the optimized parameters. Then, according to the principle of energy entropy dominance, main sub-bands of the low resonance component are reconstructed to reduce noise interference and enhance the impact characteristics of the signal. Finally, Hilbert envelope demodulation analysis is performed on the reconstructed signal to obtain the instantaneous fault characteristic frequency. The proposed method was applied to diagnose compound faults of aviation bearings. The results show that the proposed method can effectively separate and extract the compound fault signal of a bearing in an aero-engine testbed. Furthermore, the compound fault of a damaged bearing in a helicopter transmission system was successfully decoupled, which verified the effectiveness and practicability of the proposed method.},
  archive      = {J_EAAI},
  author       = {Shuo Zhang and Zhiwen Liu and Sihai He and Jinglin Wang and Lufeng Chen},
  doi          = {10.1016/j.engappai.2022.104741},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104741},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improved double TQWT sparse representation using the MQGA algorithm and new norm for aviation bearing compound fault detection},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Instance segmentation of biological images using graph
convolutional network. <em>EAAI</em>, <em>110</em>, 104739. (<a
href="https://doi.org/10.1016/j.engappai.2022.104739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instance segmentation in biological images is an important task in the field of biological images and biomedical analysis. Different from the instance segmentation of natural image scenes, this task is still challenging because there are a large number of overlapping objects with similar appearance as well as great variability in shape, size and texture in the foreground and background. In this paper, we propose a novel method for segmentation of graph-guided instances of biological images, which successfully addresses these peculiarities. Our method predicts the embedding at each pixel and uses clustering to recover instances during testing. Specifically, we design the Graph-guided Feature Fusion Module in response to overlapping instances. Our Graph-guided Feature Fusion Module combines fine deep features and coarse shallow features to learn the affinity matrix, and then uses graph convolutional network to guide the network to learn object-level local features. Next, we devise the Gated Spatial Attention Module to effectively learn key spatial information by introducing a gating mechanism. Furthermore, we give the Cluster Distance Loss that can effectively distinguish foreground objects from similar backgrounds. The effectiveness of our proposed method has been verified on various biological and biomedical datasets. The experimental results show that our method is superior to previous embedding-based instance segmentation methods. The SBD metric for our method reached 90.8% on the plant phenotype dataset (CVPPP), 72.5% on the cell nucleus dataset (DSB2018), and 81.8% on the C.elegans dataset, all achieving state-of-the-art performance.},
  archive      = {J_EAAI},
  author       = {Rongtao Xu and Ye Li and Changwei Wang and Shibiao Xu and Weiliang Meng and Xiaopeng Zhang},
  doi          = {10.1016/j.engappai.2022.104739},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104739},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Instance segmentation of biological images using graph convolutional network},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fire detection in video surveillances using convolutional
neural networks and wavelet transform. <em>EAAI</em>, <em>110</em>,
104737. (<a
href="https://doi.org/10.1016/j.engappai.2022.104737">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fire is one of the most frequent and common emergencies threatening public safety and social development. Recently, intelligent fire detection technologies represented by convolutional neural networks (CNNs) have been widely concerned by academia and industry, substantially improving detection accuracy. However, CNN-based fire detection systems are still subject to the interference of false alarms and the limitation of computing power. In this paper, taking advantage of traditional spectral analysis in fire image detection technology, a novel Wavelet-CNN method is proposed, which applies the 2D Haar transform to extract spectral features of the image and input them into CNNs at different layer stages. Two classic backbone networks, ResNet50 and MobileNet v2 (MV2) are used to test our method, and experimental results on a benchmark fire dataset and a video dataset show that the method improves fire detection accuracy and reduces false alarms, especially for the light-weight MV2. Despite the low computational needs, the Wavelet-MV2 achieves accuracy that is comparable to state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Lida Huang and Gang Liu and Yan Wang and Hongyong Yuan and Tao Chen},
  doi          = {10.1016/j.engappai.2022.104737},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104737},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fire detection in video surveillances using convolutional neural networks and wavelet transform},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Auction-based approach with improved disjunctive graph model
for job shop scheduling problem with parallel batch processing.
<em>EAAI</em>, <em>110</em>, 104735. (<a
href="https://doi.org/10.1016/j.engappai.2022.104735">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The job-shop scheduling problem (JSSP) is encountered in several industries, including the military where heat treatment is applied prior to the machining process in production. This study aims to minimize the overall make-span of a JSSP with parallel batch processing. The problem is formulated as a mixed-integer linear programming model. Feasible solutions are derived from an auction-based approach for forming batches, allocating operation machines, and scheduling. An improved disjunctive graph model is further developed to search for better solutions. We conduct numerical experiments to test a set of benchmark instances. A comparison of the results with those obtained applying other existing algorithms and CPLEX demonstrates the effectiveness and stability of the proposed auction-based approach and improved graph model. Furthermore, a statistical analysis using IBM SPSS shows that the proposed auction-based approach has an absolute advantage in solving medium-scale and large-scale instances of JSSP with batch processing.},
  archive      = {J_EAAI},
  author       = {Chengkuan Zeng and Guiqing Qi and Zixuan Liu and Jiafu Tang and Zhi-Ping Fan and Chongjun Yan},
  doi          = {10.1016/j.engappai.2022.104735},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104735},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Auction-based approach with improved disjunctive graph model for job shop scheduling problem with parallel batch processing},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Safe learning-based gradient-free model predictive control
based on cross-entropy method. <em>EAAI</em>, <em>110</em>, 104731. (<a
href="https://doi.org/10.1016/j.engappai.2022.104731">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a safe and learning-based control framework for model predictive control (MPC) is proposed to optimize nonlinear systems with a non-differentiable objective function under uncertain environmental disturbances. The control framework integrates a learning-based MPC with an auxiliary controller in a way of minimal intervention. The learning-based MPC augments the prior nominal model with incremental Gaussian Processes to learn the uncertain disturbances. The cross-entropy method (CEM) is utilized as the sampling-based optimizer for the MPC with a non-differentiable objective function. A minimal intervention controller is devised with a control Lyapunov function and a control barrier function to guide the sampling process and endow the system with high probabilistic safety. The proposed algorithm shows a safe and adaptive control performance on a simulated quadrotor in the tasks of trajectory tracking and obstacle avoidance under uncertain wind disturbances.},
  archive      = {J_EAAI},
  author       = {Lei Zheng and Rui Yang and Zhixuan Wu and Jiesen Pan and Hui Cheng},
  doi          = {10.1016/j.engappai.2022.104731},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104731},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Safe learning-based gradient-free model predictive control based on cross-entropy method},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi–modal unsupervised fault detection system based on
power signals and thermal imaging via deep AutoEncoder neural network.
<em>EAAI</em>, <em>110</em>, 104729. (<a
href="https://doi.org/10.1016/j.engappai.2022.104729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper a multi-modal unsupervised Deep Learning based algorithm for fault detection is proposed. Such method is applied to real data from a testing procedure implemented on an industrial production line. Both thermal images and current and power measurements coming from industrial refrigerators are collected. The considered dataset is highly unbalanced with the vast majority of samples being healthy. Thermal images are processed via a Deep Convolutional neural network. The features extracted from the thermal images are thus merged to structured data of power, current and temperature. Therefore, a Deep Auto-Encoder is trained on the dataset to signal anomalies corresponding to faults in the refrigerators. Three different methods are trained and compared: (1) an automatic method in which an expert extracts relevant features from thermal images without using the image recognition module; (2) a semi-automatic method where the convolutional neural network is applied to regions of interest within the thermal images selected by an expert operator; (3) a fully automatic method in which the Deep convolutional network processes the whole thermal image without any human intervention. The three methods show comparable results with nevertheless slight differences.},
  archive      = {J_EAAI},
  author       = {Francesco Cordoni and Gianluca Bacchiega and Giulio Bondani and Robert Radu and Riccardo Muradore},
  doi          = {10.1016/j.engappai.2022.104729},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104729},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi–modal unsupervised fault detection system based on power signals and thermal imaging via deep AutoEncoder neural network},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A differential evolution algorithm with the guided movement
for population and its application to interplanetary transfer trajectory
design. <em>EAAI</em>, <em>110</em>, 104727. (<a
href="https://doi.org/10.1016/j.engappai.2022.104727">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The extremely sensitive and highly non-linear search space of interplanetary transfer trajectory design brings about big challenges on global optimization. As a representative, the current known best solution (fuel consumption) of the global trajectory optimization problem designed by the European space agency is very hard to be found. To deal with this difficulty, a powerful differential evolution with the guided movement for population, named G_DE is proposed in this paper. G_DE employs a two-stage evolutionary process, which concentrates on learning global structure in the earlier process, and tends to self-adaptively probe the structures of numerous local spaces at a later stage. During these two stages, four guidance strategies related to the learning from the population distribution are proposed. The experimental test results show that G_DE can find the current known best solutions of Cassini1 and Sagas directly. For the newly proposed GTOP-X problem, G_DE has found state-of-the-art solutions for four encounter sequences, and using five gravity assists, G_DE found encounter sequences with fuel consumption as low as 1.5676 km/s. The experimental test on 10D CEC2017 problems proves G_DE has a comparable performance with recently proposed differential evolution variant.},
  archive      = {J_EAAI},
  author       = {Mingcheng Zuo and Guangming Dai and Lei Peng and Zhe Tang and Dunwei Gong and Qinxia Wang},
  doi          = {10.1016/j.engappai.2022.104727},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104727},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A differential evolution algorithm with the guided movement for population and its application to interplanetary transfer trajectory design},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An improved marine predators algorithm for the optimal
design of hybrid renewable energy systems. <em>EAAI</em>, <em>110</em>,
104722. (<a
href="https://doi.org/10.1016/j.engappai.2022.104722">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microgrid technologies are exciting energy sources that are economically feasible for current and future applications in light of increased energy demand and the depletion of traditional sources. This article focuses on the latest metaheuristic algorithm, the marine predators algorithm (MPA), in the field of energy. To investigate a method for reducing the system’s investment costs in Minia, Egypt, the combination of reinforcement learning (RL) with MPA is used to build a new method, Deep-MPA, where RL principles are applied to adjust and enhance the lack of MPA in global searching. The exploration/exploitation ratio is regulated by varying the step size, which affects the efficiency of the MPA. Instead of updating the value of the parameter for all agents in the same manner, RL principles are used to update it on the basis of the current individual state. Additionally, to resolve the common challenge of using RL to determine the appropriate global search parameters for MPA, Deep-MPA is used to design a hybrid renewable energy microgrid system, which includes photovoltaic panels, a wind turbine system, a diesel generator, and battery storage systems. These are some of the criteria and constraints that this system may require to ensure its stability, robustness, performance, and load satisfaction. The proposed Deep-MPA is verified by contrasting the results with different algorithms in the CEC’2017 test. Moreover, Wilcoxon’s test validates the statistical significance of the Deep-MPA. The energy cost is reduced by 6% of total consumption.},
  archive      = {J_EAAI},
  author       = {Essam H. Houssein and Ibrahim E. Ibrahim and Mohammed Kharrich and Salah Kamel},
  doi          = {10.1016/j.engappai.2022.104722},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104722},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An improved marine predators algorithm for the optimal design of hybrid renewable energy systems},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detection of local and clustered outliers based on the
density–distance decision graph. <em>EAAI</em>, <em>110</em>, 104719.
(<a href="https://doi.org/10.1016/j.engappai.2022.104719">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier detection tasks refer to identifying the objects that have different characteristics from the normal observations. Most existing approaches detect outliers from the global perspective, which can effectively detect global outliers and most clustered outliers but cannot detect local outliers when the normal samples form clusters with different densities. The methods based on local outlier factors can effectively detect local outliers, but when the number of outliers increases, the more occurrences of clustered outliers will lead to the degeneration of the detection performance. We proposed an outlier detection method based on density–distance decision graph to detect local, global and clustered outliers simultaneously. Firstly, kernel density estimation and local reachable distance are combined to calculate the local density. The density ratio of the neighbors of an instance to itself is calculated as the degree of local outliers. Then, we propose a metric named density lifting distance as the degree of global outliers, which is calculated by the distance between k nearest neighbors with higher density of the instance and itself. The density ratio and density lift distance are combined to draw the density–distance decision graph, and the product of two metrics is calculated as the final outlier score. Comprehensive experiments were conducted on 8 synthetic datasets and 16 real-world datasets compared with 12 state-of-the-art methods. The results show that the proposed method works well when the samples form clusters with different densities as well as the percentage of outliers varies, and outperforms the state-of-the-art methods tested in terms of AUC.},
  archive      = {J_EAAI},
  author       = {Kangsheng Li and Xin Gao and Xin Jia and Bing Xue and Shiyuan Fu and Zhiyu Liu and Xu Huang and Zijian Huang},
  doi          = {10.1016/j.engappai.2022.104719},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104719},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Detection of local and clustered outliers based on the density–distance decision graph},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust EMRAN-aided coupled controller for autonomous
vehicles. <em>EAAI</em>, <em>110</em>, 104717. (<a
href="https://doi.org/10.1016/j.engappai.2022.104717">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a coupled, neural network-aided longitudinal cruise and lateral path-tracking controller for an autonomous vehicle with model uncertainties and experiencing unknown external disturbances. Using a feedback error learning mechanism, an inverse vehicle dynamics learning scheme utilizing an adaptive Radial Basis Function (RBF) neural network, referred to as the Extended Minimal Resource Allocating Network (EMRAN) is employed. EMRAN uses an extended Kalman filter for online learning and weight updates, and also incorporates a growing/pruning strategy for maintaining a compact network for easier real-time implementation. The online learning algorithm handles the parametric uncertainties and eliminates the effect of unknown disturbances on the road. Combined with a self-regulating learning scheme for improving generalization performance, the proposed EMRAN-aided control architecture aids a basic PID cruise and Stanley path-tracking controllers in a coupled form. Its performance and robustness to various disturbances and uncertainties are compared with the conventional PID and Stanley controllers, along with a comparison with a fuzzy-based PID controller and an active disturbance rejection control (ADRC) scheme. Simulation results are presented for both slow and high speed scenarios. The root mean square (RMS) and maximum tracking errors clearly indicate the effectiveness of the proposed control scheme in achieving better tracking performance in autonomous vehicles under unknown environments.},
  archive      = {J_EAAI},
  author       = {Sauranil Debarshi and Suresh Sundaram and Narasimhan Sundararajan},
  doi          = {10.1016/j.engappai.2022.104717},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104717},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust EMRAN-aided coupled controller for autonomous vehicles},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A proposal of edge detection in images with multiplicative
noise using the ant colony system algorithm. <em>EAAI</em>,
<em>110</em>, 104715. (<a
href="https://doi.org/10.1016/j.engappai.2022.104715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiplicative noise is one of the most aggressive types of noise present in various types of images: Synthetic Aperture Radar, Ultrasound images, Ultrasonic Imaging, among others. Edges detectors such as Canny or Sobel are not very efficient for processing an image with multiplicative noise, they also require filtering algorithms, a preprocessing, which is why bio-inspired algorithms are an alternative for processing images with the presence of multiplicative noise, due to its efficiency in finding an approximate solution. This article proposes a method for the edges detection in images with multiplicative noise using the Ant Colony System algorithm. For which we must adapt the Ant Colony System algorithm to detect contours, this we define the calculation of a global pheromone matrix between several edge detection equations, gradient, and the coefficient of variation, these equations are compared for their edge detection performance using a visual inspection and a performance function. The results of the experiments show a correct implementation of the algorithm proposed to the images with multiplicative noise even for high noise levels.},
  archive      = {J_EAAI},
  author       = {Sergio Baltierra and Jonathan Valdebenito and Marco Mora},
  doi          = {10.1016/j.engappai.2022.104715},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104715},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A proposal of edge detection in images with multiplicative noise using the ant colony system algorithm},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intelligent fault diagnosis of train axle box bearing based
on parameter optimization VMD and improved DBN. <em>EAAI</em>,
<em>110</em>, 104713. (<a
href="https://doi.org/10.1016/j.engappai.2022.104713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The vibration signal of the axle box bearing of the train is affected by the track excitation and the random noise of the environment. The vibration signal is nonlinear and non-stationary, and the signal characteristics of the early fault are weak and easy to be submerged, which leads to the low accuracy of the weak fault diagnosis of the bearing. To solve this problem, a weak fault diagnosis method for train axle box bearing based on parameter optimization Variational Mode Decomposition (VMD) and improved Deep Belief Network (DBN) is proposed. Firstly, the nonlinear convergence factor, Levy flight theory and greedy algorithm optimization theory are introduced into the Grey Wolf optimization algorithm (GWO), and an improved GWO algorithm based on hybrid strategy is proposed to improve the performance of the algorithm and solve the local optimal problem of the algorithm. Secondly, the improved GWO is applied to optimize the VMD parameters, which is used for signal decomposition. And the fault feature information of modal components with maximum correlation coefficient is extracted by multi-scale scatter entropy. Finally, the improved GWO algorithm is applied to optimize the parameters of the DBN to solve the parameter setting problem, and the optimized DBN is used as a pattern recognition algorithm for weak fault diagnosis of bearings. Through experimental comparison and analysis, the proposed method can effectively solve the problem of weak fault diagnosis of axle box bearings, and has high diagnostic accuracy.},
  archive      = {J_EAAI},
  author       = {Zhenzhen Jin and Deqiang He and Zexian Wei},
  doi          = {10.1016/j.engappai.2022.104713},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104713},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent fault diagnosis of train axle box bearing based on parameter optimization VMD and improved DBN},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-quantile recurrent neural network for feeder-level
probabilistic energy disaggregation considering roof-top solar energy.
<em>EAAI</em>, <em>110</em>, 104707. (<a
href="https://doi.org/10.1016/j.engappai.2022.104707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of feeder-level energy disaggregation is to decouple the net load measured at the feeder-head into various components. This technology is vital for power system utilities since increased visibility of controllable loads enables the realization of demand-side management strategies. However, energy disaggregation at the feeder level is difficult to realize since the high penetration of embedded generation masks the actual demand and different loads are highly aggregated. In this paper, the solar energy at the grid supply point is separated from the net load at first via either an unsupervised upscaling method or the supervised gradient boosting regression tree (GBRT) method. To deal with the uncertainty of the load components, the probabilistic energy disaggregation models based on multi-quantile recurrent neural network model (multi-quantile long short-term memory (MQ-LSTM) model and multi-quantile gated recurrent unit (MQ-GRU) model) are proposed to disaggregate the demand load into thermostatically controlled loads (TCLs), non-thermostatically controlled loads (non-TCLs), and non-controllable loads. A variety of relevant information, including feeder measurements, meteorological measurements, calendar information, is adopted as the input features of the model. Instead of providing point prediction, the probabilistic model estimates the conditional quantiles and provides prediction intervals. A comprehensive case study is implemented to compare the proposed model with other state-of-the-art models (multi-quantile convolutional neural network (MQ-CNN), quantile gradient boosting regression tree (Q-GBRT), Quantile Light gradient boosting machine (Q-LGB)) from training time, reliability, sharpness, and overall performance aspects. The result shows that the MQ-LSTM can estimate reliable and sharp Prediction Intervals for target load components. And it shows the best performance among all algorithms with the shortest training time. Finally, a transfer learning algorithm is proposed to overcome the difficulty to obtain enough training data, and the model is pre-trained via synthetic data generated from a public database and then tested on the local dataset. The result confirms that the proposed energy disaggregation model is transferable and can be applied to other feeders easily.},
  archive      = {J_EAAI},
  author       = {Xiao-Yu Zhang and Chris Watkins and Stefanie Kuenzel},
  doi          = {10.1016/j.engappai.2022.104707},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104707},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-quantile recurrent neural network for feeder-level probabilistic energy disaggregation considering roof-top solar energy},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reveling misleading information for defenders and attackers
in repeated stackelberg security games. <em>EAAI</em>, <em>110</em>,
104703. (<a
href="https://doi.org/10.1016/j.engappai.2022.104703">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Critical infrastructure protection has become a major problem in today’s economy. Furthermore, the ongoing attacks on the population have piqued interest in resource allocation models in the face of societal dangers. Attacker–Defender Stackelberg Security Games (SSGs) have emerged as a critical field of study and development for resolving this issue. A game-theoretic model for SSGs with incomplete information is presented in this study. The objective is to reduce the knowledge and ingenuity of attackers when it comes to selecting a target, location, and time for an assault. For security resource allocation, we present a Bayesian-Stackelberg game-theoretic framework. The defenders’ diverse preferences create a decision-making dilemma, which needs the development of a system to devise strategies that encourages coordination. We construct an incentive-compatible optimum mechanism that maximizes benefits while incentivizing participants to implement the offered strategies. Our findings demonstrate that is possible to compute a mechanism able to obtain effective defensive coordination in security games under certain restrictions. In this approach, attackers and defenders learn their behavior by seeing private information in a Markov process-restricted game. The artificial intelligence technology chosen to perform the learning process is Reinforcement Learning (RL) approach. We provide an algorithm and evaluate the repeating game using myopic players as attackers and defenders. Experiments on SSGs can be managed using a random walk technique. The suggested framework’s efficacy and efficiency are demonstrated using a numerical example.},
  archive      = {J_EAAI},
  author       = {Julio B. Clempner},
  doi          = {10.1016/j.engappai.2022.104703},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104703},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reveling misleading information for defenders and attackers in repeated stackelberg security games},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Solving hard-exploration problems with counting and replay
approach. <em>EAAI</em>, <em>110</em>, 104701. (<a
href="https://doi.org/10.1016/j.engappai.2022.104701">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The reinforcement learning agent has been very successful in many Atari 2600 games. However, while applied to a more complex and challenging environment, it is crucial to avoid falling into the local optimum, especially when the games contain many traps, ample action space, challenging scenarios, and sporadic successful episodes. In this case, using the intrinsic motivation method can easily fall into the local optimum. If the domain knowledge is excessively used, it is not applicable when encountering different game designs. Therefore, to enhance the agent’s ability to explore and avoid catastrophic forgetting due to the fades of intrinsic motivation, a Trajectory Evaluation Module is developed and integrated with ideas from the Count-Based Exploration and Trajectory Replay method. Moreover, our approach is integrated very well with the Self Imitation Learning method and works effectively for hard-exploration video games. Our policy is also evaluated with two video games: Super Mario Bros and Sonic the Hedgehog . The experiment results show that our Trajectory Evaluation Module can help the agent pass through various obstacles and scenarios, and successfully break through all levels of Super Mario Bros .},
  archive      = {J_EAAI},
  author       = {Bo-Ying Huang and Shi-Chun Tsai},
  doi          = {10.1016/j.engappai.2022.104701},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104701},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Solving hard-exploration problems with counting and replay approach},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Coarse-to-fine SVD-GAN based framework for enhanced frame
synthesis. <em>EAAI</em>, <em>110</em>, 104699. (<a
href="https://doi.org/10.1016/j.engappai.2022.104699">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frame interpolation and synthesis are growing topics in the field of computer vision. Hence, these topics gained more attention recently where several deep-learning architectures were proposed to enhance the quality of the synthesized frames. In this paper, an efficient handcrafted deep approach is proposed for better frame synthesis. The proposed approach takes advantage of singular value decomposition (SVD) framework and Generative Adversarial Networks (GAN). The proposed approach does not require any computationally expensive feature extraction steps such optical flow techniques and block-based motion compensation techniques. Nonetheless, the SVD components still carry the relevant motion information needed to deal with the challenges such as large motion and occlusion. Thus, the frames are temporally upscaled via SVD based construction procedure where new middle frames are interpolated for further enhancement using a GAN based approach that eliminates most of the visual artifacts. The proposed frame synthesis approach is comprehensively evaluated in different scenarios where its performance is assessed and compared with the state-of-the-art. Our framework outperforms the majority of the deep learning approaches in terms quantitative results in addition to qualitative results where our framework can generate smoother frames with less visual artifacts.},
  archive      = {J_EAAI},
  author       = {M. Kas and I. Kajo and Y. Ruichek},
  doi          = {10.1016/j.engappai.2022.104699},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104699},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Coarse-to-fine SVD-GAN based framework for enhanced frame synthesis},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhancing the scalability of fuzzy rough set approximate
reduct computation through fuzzy min–max neural network and crisp
discernibility relation formulation. <em>EAAI</em>, <em>110</em>,
104697. (<a
href="https://doi.org/10.1016/j.engappai.2022.104697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy rough sets (FRS) framework is proven to be useful in computing predictive features in the presence of incompleteness and uncertainty in hybrid systems. However, the existing FRS methods for feature subset selection (reduct computation) are not scalable to large datasets due to higher space and time complexities. Towards increasing the scalability of FRS reduct computation, FMNN-FRS approach is proposed earlier, utilizing fuzzy min–max neural network (FMNN) preprocessing to enable reduct computation in fuzzy hyperbox space instead of object space. FMNN-FRS approach considers fuzzy discernibility matrix (DM) for computation of an approximate reduct. However, it is observed that the space utilization of fuzzy DM limits the scalability of FMNN-FRS. To further increase the scalability of FMNN-FRS method by the reduction in the space complexity, in this work, a novel way of crisp DM construction is proposed from the knowledge derived from FMNN preprocessing (CDM-FMFRS). Extended overlapping criteria, with tolerance parameter, are also designed for arriving at the crisp discernibility relation through fuzzy hyperboxes. The proposed CDM-FMFRS approach computes an approximate reduct using SFS strategy on the generated crisp DM. Empirically, the experimental results established that the classifiability of the induced model from the proposed algorithm is similar or better than FMNN-FRS and other state-of-the-art FRS reduct approaches with a significant reduction in computational time. Results also established better scalability achieved by CDM-FMFRS than FMNN-FRS.},
  archive      = {J_EAAI},
  author       = {Anil Kumar and P.S.V.S. Sai Prasad},
  doi          = {10.1016/j.engappai.2022.104697},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104697},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing the scalability of fuzzy rough set approximate reduct computation through fuzzy min–max neural network and crisp discernibility relation formulation},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Graft: A graph based time series data mining framework.
<em>EAAI</em>, <em>110</em>, 104695. (<a
href="https://doi.org/10.1016/j.engappai.2022.104695">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid technology integration causes a high dimensional time series data accumulation in multiple domains and applying the classical data mining tools and techniques becomes a challenging task. Hence, the time series data representation have gained popularity over the years, which ease the task of mining, analysis and visualization. Graph based representation is one such emerging tool in which the time series data is represented as nodes and edges of graph. The current graph based representation is designed either to mine the motif or discords from a single time series or cluster the time series where each node represents a time series sample. Such representation technique causes information loss and also no further analysis could be performed other than clustering. To address these challenges, we propose a unique graph representation for time series dataset that works on multiple domains. Novelty of the graph representation is that it is unique for multiple time series and it acts as a framework for whole time series clustering, temporal pattern extraction from each cluster and temporally dependent rare event discovery. A new research direction for the proposed graph based framework is shown. Comparative analysis reveal the superiority of the proposed framework particularly as a clustering technique. The key contributions of the paper are: (i) transformation strategy of time series database from time domain to graph structure in topological domain (ii) time series clustering using path level analysis (iii) identification of temporally dependent co-occurring patterns (iv) rare event detection using component level analysis},
  archive      = {J_EAAI},
  author       = {Kakuli Mishra and Srinka Basu and Ujjwal Maulik},
  doi          = {10.1016/j.engappai.2022.104695},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104695},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Graft: A graph based time series data mining framework},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-category intuitionistic fuzzy twin support vector
machines with an application to plant leaf recognition. <em>EAAI</em>,
<em>110</em>, 104687. (<a
href="https://doi.org/10.1016/j.engappai.2022.104687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intuitionistic fuzzy twin support vector machine for multi-categorization is developed in this study, which incorporates both structural and empirical risk concepts. In this method, each training pattern is first aggregated with the appropriate membership and non-membership degrees, which describe the position of a pattern in relation to its class centre and surrounding circumstances in input or feature space, and then the separating hyperplane is constructed using the kernel function and convex quadratic programming. Empirical findings on an artificial and thirteen UCI standard datasets show that it outperforms well-known existing methods including improved support vector machines, K-nearest neighbour, logistic regression, decision trees, random forests, and multilayer perceptrons. Furthermore, the suggested classifier with linear, polynomial, and Gaussian kernels has been used to identify the leaves of various plants, where the shape, texture, and margin data are extracted from the leaf in order to categorize the plant species. The method’s generalization capacity is demonstrated by the classification results on two leaf datasets of thirty and one hundred species, respectively. To compare the suggested method’s prediction capacity with others, statistical analysis is performed using two non-parametric tests, Friedman and Wilcoxon, with a 5% threshold of significance. The results show that the proposed method yields better performance for both linear and non-linear kernels.},
  archive      = {J_EAAI},
  author       = {Scindhiya Laxmi and S.K. Gupta},
  doi          = {10.1016/j.engappai.2022.104687},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104687},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-category intuitionistic fuzzy twin support vector machines with an application to plant leaf recognition},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improved surrogate-assisted whale optimization algorithm for
fractional chaotic systems ’ parameters identification. <em>EAAI</em>,
<em>110</em>, 104685. (<a
href="https://doi.org/10.1016/j.engappai.2022.104685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate identification of the unknown parameters in fractional chaotic systems is crucial for their precise control. However, the evaluation of these systems is relatively expensive in the sense that its numerical process demands considerable time. Thus, it is essential to design a less time-demanding algorithm with high accuracy. Motivated by this, this paper aims to propose an algorithm with high accuracy and quick convergence speed, leading to a smaller computational budget. To achieve this goal, an Improved Surrogate-Assisted Whale Optimization Algorithm, denoted as ISAWOA, is proposed. A surrogate-assisted model is employed to approximate the fitness function, then, both the Lévy flight and the quadratic interpolation techniques are used to improve the exploration and exploitation capacity of the Whale Optimization Algorithm. The simulation results on 20 classical benchmark functions demonstrate that ISAWOA is able to locate an optimal solution with high accuracy and much faster than 14 other algorithms found in the literature. Finally, the proposed algorithm is validated on several representative fractional chaotic systems where ISAWOA is again able to outperform other methods, both in precision and CPU time. The overall test results show that ISAWOA is a promising algorithm with high accuracy, quick convergence, and that it requires a moderate amount of CPU time when dealing with parameter estimation problems on fractional chaotic systems.},
  archive      = {J_EAAI},
  author       = {Shuhui Wang and Wei Hu and Ignacio Riego and Yongguang Yu},
  doi          = {10.1016/j.engappai.2022.104685},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104685},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improved surrogate-assisted whale optimization algorithm for fractional chaotic systems ’ parameters identification},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel fractional time-delayed grey bernoulli forecasting
model and its application for the energy production and consumption
prediction. <em>EAAI</em>, <em>110</em>, 104683. (<a
href="https://doi.org/10.1016/j.engappai.2022.104683">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy affects the stable and sustainable development of social economy. Energy prediction plays an important role in the process of China’s energy market transformation. Scientific and reasonable energy predicting method can help government to make decisions effectively, and then adjust energy structure and industrial layout. The energy field is full of fractional order phenomenon and nonlinear disturbance. Aiming at the energy data sets with the characteristics of scarcity, complexity and nonlinear, a mathematical model including time delay term and Bernoulli equation can be used to fit this trend. A new fractional time-delayed grey Bernoulli model is proposed, and the new model has a wider application in the nonlinear field. The model is discretized by integral, and the least square estimation of the linear parameters and the approximate time response equation are obtained. The Grey Wolf Optimizer (GWO) is used to search the optimal parameters of the model. In addition, the energy prediction model is established from the perspective of renewable energy and fossil energy, and the effectiveness of the model is verified by three actual cases of renewable energy, crude oil and fossil fuel. Compared with the other seven grey models, the results show that the new model has higher prediction performance. Finally, the energy development trend in the next few years is predicted by using the proposed model, and relevant conclusions are drawn according to the prediction results.},
  archive      = {J_EAAI},
  author       = {Yong Wang and Xinbo He and Lei Zhang and Xin Ma and Wenqing Wu and Rui Nie and Pei Chi and Yuyang Zhang},
  doi          = {10.1016/j.engappai.2022.104683},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104683},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel fractional time-delayed grey bernoulli forecasting model and its application for the energy production and consumption prediction},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Differentially private frequent episode mining over event
streams. <em>EAAI</em>, <em>110</em>, 104681. (<a
href="https://doi.org/10.1016/j.engappai.2022.104681">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frequent episode mining is a wide range framework of data mining from sequential data with many applications, which is a totally short-ordered collection of event-types and unearths temporal correlations without information loss over event streams. While offering substantial benefits, directly releasing frequent episodes to the public will enormously threaten the individual’s privacy. However, there is little work so far concentrating on privately frequent episode mining. In this paper, we investigate the privacy problem in mining frequent episodes from event streams due to continuous releases in successive windows and propose a real-time differentially private frequent episode mining algorithm over event streams to avoid the privacy leakage with ω -event privacy guarantee. To obtain private frequent episodes, we propose a sample-based perturbation approach, which improves the accuracy of selecting frequent episodes based on sampling databases. To reduce the privately mining time and avoid repeatedly privacy budget allocation to coincident window of adjacent releases as much as possible, we present an incremental perturbation approach according to the judgment in dissimilarity calculation mechanism. Meanwhile, in order to protect data collected from any ω successive timestamps over event streams, we employ an adaptive ω -event privacy mechanism on the basis of the dynamicity of episodes. Finally, experimental results on real-world datasets demonstrate the effectiveness and efficiency of our algorithm.},
  archive      = {J_EAAI},
  author       = {Jiawen Qin and Jinyan Wang and Qiyu Li and Shijian Fang and Xianxian Li and Lei Lei},
  doi          = {10.1016/j.engappai.2022.104681},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104681},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Differentially private frequent episode mining over event streams},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SF-GRA method based on cumulative prospect theory for
multiple attribute group decision making and its application to
emergency supplies supplier selection. <em>EAAI</em>, <em>110</em>,
104679. (<a
href="https://doi.org/10.1016/j.engappai.2022.104679">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emergency supplies supplier selection can be regarded as a classic multiple attribute group decision making (MAGDM) problem. MAGDM is an interesting everyday problem full of uncertainty and ambiguity. As a new extension of fuzzy sets (FSs), spherical fuzzy sets (SFSs) can express vague and complex information in MAGDM more comprehensively. The gray relational analysis (GRA) is a practical method to process MAGDM problems. Furthermore, the cumulative prospect theory (CPT) can well capture the psychological behaviors of decision makers (DMs) in the assessment process. Therefore, in this paper, a spherical fuzzy GRA based on CPT (SF-CPT-GRA) method is proposed for MAGDM issues. In the meantime, the CRiteria Importance Through Intercriteria Correlation (CRITIC) method is used under the spherical fuzzy environment to obtain unknown attribute weights, which enhances the rationality of weight information. Finally, an example of emergency supplies supplier selection is given to illustrate the practicality of the proposed method. Sensitivity analysis and further comparative analysis attest the stability and validity of SF-CPT-GRA method. The proposed method takes full account of the influence of DMs’ risk attitude on decision result, which integrates CPT with GRA (CPT-GRA) and uses SFSs to express DMs’ preference information, making the decision results more scientific. Moreover, the SF-CPT-GRA method provides some references for dealing with other complex uncertain problems and further extension of CPT-GRA method in other decision environments.},
  archive      = {J_EAAI},
  author       = {Huiyuan Zhang and Guiwu Wei and Xudong Chen},
  doi          = {10.1016/j.engappai.2022.104679},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104679},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {SF-GRA method based on cumulative prospect theory for multiple attribute group decision making and its application to emergency supplies supplier selection},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An improved brain storm optimization algorithm with new
solution generation strategies for classification. <em>EAAI</em>,
<em>110</em>, 104677. (<a
href="https://doi.org/10.1016/j.engappai.2022.104677">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, brain storm optimization (BSO) algorithm has received much attention in solving classical optimization problems and is used to implement evolutionary classification models. However, in practical applications, large-scale datasets complicate the structure of the classification model, which can have a great impact on the classification performance. In the optimization process, the traditional single-strategy BSO cannot preserve the information of dominant solution well, and its generation strategy is inefficient in solving various complex practical problems. To solve this problem, we introduce feature selection to improve the optimization model structure. Meanwhile, in order to enhance the search capability of BSO, three new generation strategy are embedded in the BSO algorithm in this paper. With the three generation methods of global optimal, local optimal and nearest neighbor, the information of the dominant solution can be better preserved and the search efficiency can be improved. The performance of the proposed generation strategy in solving classification problems is demonstrated on ten datasets with different sizes and dimensions. The experimental results reveal that the new generation strategy can enhance the performance of BSO algorithm for solving classification problems.},
  archive      = {J_EAAI},
  author       = {Yu Xue and Qi Zhang and Yan Zhao},
  doi          = {10.1016/j.engappai.2022.104677},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104677},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An improved brain storm optimization algorithm with new solution generation strategies for classification},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Temporal segment graph convolutional networks for
skeleton-based action recognition. <em>EAAI</em>, <em>110</em>, 104675.
(<a href="https://doi.org/10.1016/j.engappai.2022.104675">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Different actions usually emphasize on different parts of a skeleton, even for a specific action, different action stages have the corresponding emphases. Previous studies generally construct the human skeletons as predefined, thus lacking the adaptability to different action modes. In addition, these methods simply employ the padding or truncation operation on the skeleton sequence to fix the sequence length, resulting in additional temporal misalignment problem. In this work, we propose a novel temporal segment graph convolutional networks (TS-GCN) for skeleton-based action recognition. Our model divides the whole sequence into several subsequences. Then GCNs are applied on each subsequence to capture the dynamic information stage by stage, which can align the motion features in temporal domain. Besides, in order to explore the intrinsic features contained in each subsequence, our model introduces a graph-adaptive method to construct an individual graph that can be learned and updated from skeleton data for each subsequence, which increases the generality of graph construction to adapt to different sequences. Extensive experiments are conducted on two standard datasets, NTU-RGB+D and Kinetics. The experimental results demonstrate the effectiveness of the proposed method.},
  archive      = {J_EAAI},
  author       = {Chongyang Ding and Shan Wen and Wenwen Ding and Kai Liu and Evgeny Belyaev},
  doi          = {10.1016/j.engappai.2022.104675},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104675},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Temporal segment graph convolutional networks for skeleton-based action recognition},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DeepFakes detection across generations: Analysis of facial
regions, fusion, and performance evaluation. <em>EAAI</em>,
<em>110</em>, 104673. (<a
href="https://doi.org/10.1016/j.engappai.2022.104673">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Media forensics has attracted a tremendous attention in the last years in part due to the increasing concerns around DeepFakes. Since the release of the initial DeepFakes databases of the 1st generation such as UADFV and FaceForensics++ up to the latest databases of the 2nd generation such as Celeb-DF and DFDC, many visual improvements have been carried out, making fake videos almost indistinguishable to the human eye. This study provides an in-depth analysis of both 1st and 2nd DeepFakes generations in terms of fake detection performance. Two different methods are considered in our experimental framework: (i) the traditional one followed in the literature based on selecting the entire face as input to the fake detection system, and (ii) a novel approach based on the selection of specific facial regions as input to the fake detection system. Fusion techniques are applied both to the facial regions and also to three different state-of-the-art fake detection systems (Xception, Capsule Network, and DSP-FWA) in order to further increase the robustness of the detectors considered. Finally, experiments regarding intra- and inter-database scenarios are performed. Among all the findings resulting from our experiments, we highlight: (i) the very good results achieved using facial regions and fusion techniques with fake detection results above 99% Area Under the Curve (AUC) for UADFV, FaceForensics++, and Celeb-DF v2 databases, and (ii) the necessity to put more efforts on the analysis of inter-database scenarios to improve the ability of the fake detectors against attacks unseen during learning.},
  archive      = {J_EAAI},
  author       = {Ruben Tolosana and Sergio Romero-Tapiador and Ruben Vera-Rodriguez and Ester Gonzalez-Sosa and Julian Fierrez},
  doi          = {10.1016/j.engappai.2022.104673},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104673},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {DeepFakes detection across generations: Analysis of facial regions, fusion, and performance evaluation},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fuzzy subspace clustering noisy image segmentation algorithm
with adaptive local variance &amp; non-local information and mean
membership linking. <em>EAAI</em>, <em>110</em>, 104672. (<a
href="https://doi.org/10.1016/j.engappai.2022.104672">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Fuzzy C-means (FCM) clustering algorithm is an effective method for image segmentation. Non-local spatial information considers more redundant information of the image thus is more robust to noise. However, under-segmentation of non-local spatial information may exist with higher noise density. The number of iteration steps is also significant in FCM, and employing membership linking can effectively reduce the number of iteration steps. Nonetheless, when there are outliers in the membership degree, the membership linking can make the algorithm converge prematurely before reaching the optimum, affecting segmentation performance. This paper presents a fuzzy subspace clustering noisy image segmentation algorithm with adaptive local variance &amp; non-local information and mean membership linking (FSC_LNML). Firstly, local variance templates are utilized to eliminate the under-segmentation of non-local information, and local variance &amp; non-local information are integrated into the FCM objective function to improve robustness. Secondly, the mean membership linking is employed as the denominator of the objective function to reduce the number of iterations and solve the problem that the algorithm converges early before reaching the optimum when the membership has an outlier. Thirdly, the absolute intensity difference between the original image and the local variance &amp; non-local information and its inverse are used to adaptively constrain the original image and the local variance &amp; non-local information. Finally, the concept of the subspace is introduced to adaptively assign appropriate weights to each dimension of the image to improve the segmentation performance of color images. The simulation results on noisy grayscale images and noisy color images show that the efficiency of the proposed method FSC_LNML is better than other fuzzy-based clustering algorithms. The convergence proof of the algorithm is also presented.},
  archive      = {J_EAAI},
  author       = {Tongyi Wei and Xiaopeng Wang and Xinna Li and Shengyang Zhu},
  doi          = {10.1016/j.engappai.2022.104672},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104672},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fuzzy subspace clustering noisy image segmentation algorithm with adaptive local variance &amp; non-local information and mean membership linking},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comprehensive survey on 3D face recognition methods.
<em>EAAI</em>, <em>110</em>, 104669. (<a
href="https://doi.org/10.1016/j.engappai.2022.104669">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D face recognition (3DFR) has emerged as an effective means of characterizing facial identity over the past several decades. Depending on the types of techniques used in recognition, these methods are categorized into traditional and modern. The former generally extract distinctive facial features (e.g. global, local, and hybrid features) for matching, whereas the latter rely primarily on deep learning to perform 3DFR in an end-to-end way. Many literature surveys have been carried out reviewing either traditional or modern methods alone, while only a few studies are conducted simultaneously on both of them. This survey presents a state-of-the-art for 3DFR covering both traditional and modern methods, focusing on the techniques used in face processing, feature extraction, and classification. In addition, we review some specific face recognition challenges, including pose, illumination, expression variations, self-occlusion, and spoofing attack. The commonly used 3D face datasets have been summarized as well.},
  archive      = {J_EAAI},
  author       = {Menghan Li and Bin Huang and Guohui Tian},
  doi          = {10.1016/j.engappai.2022.104669},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104669},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A comprehensive survey on 3D face recognition methods},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Motion parameters measurement of user-defined key points
using 3D pose estimation. <em>EAAI</em>, <em>110</em>, 104667. (<a
href="https://doi.org/10.1016/j.engappai.2022.104667">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motion parameters measurement is essential for understanding animal behavior, exploring the laws of object motion, and studying control methods. Nowadays, advanced computer vision based on machine learning technology supports markerless object tracking in 2D videos. However, due to the fact that all objects move in three-dimensional space, this paper introduces a method of measuring motion parameters using 3D pose estimation. First, an enhanced iterative bundle adjustment algorithm is proposed for multi-camera calibration in a multi-camera vision system by adding two control parameters, which dramatically reduces the reprojection error of multi-camera calibration and lays the foundation for high-precision triangulation. Then, a new spatiotemporal loss function is proposed, which considers the relationship between key points that do not constitute limbs, thereby improving triangulation accuracy. The new multi-camera calibration algorithm is evaluated on ChArUco and 3D pose estimation for metronome, planet pendulum, human hand, Koi, and cheetah. The experimental results show that: (1) the two hyper-parameters in the enhanced iterative bundle adjustment algorithm effectively suppress the influence of noise and play a good role in reducing the reprojection error of multi-camera calibration; (2) the spatiotemporal loss function has a strong constraining ability, the time loss can stabilize high frame rate video triangulation to maintain accuracy, while the space loss can improve the accuracy of triangulation for more complex structures; (3) multi-view data fusion is also conducive to improving the accuracy of triangulation. Moreover, the method was successfully applied to some actual measurement scenes: (1) the accurate measurement of the frequency of a metronome; and (2) the success measurement of the movement of a Koi, which conforms to the basic model of fish swimming. Some dynamic measurement results are displayed at https://github.com/wux024/AdamPose .},
  archive      = {J_EAAI},
  author       = {Xin Wu and Yonghui Wang and Lei Chen and Lin Zhang and Lianming Wang},
  doi          = {10.1016/j.engappai.2022.104667},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104667},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Motion parameters measurement of user-defined key points using 3D pose estimation},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cross-domain mutual information adversarial maximization.
<em>EAAI</em>, <em>110</em>, 104665. (<a
href="https://doi.org/10.1016/j.engappai.2022.104665">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation challenges the problem where the source domain and the target domain have distinctive data distributions. Different from previous approaches which align the two domains by minimizing a distribution metric, in this paper, we report a new perspective of handling unsupervised domain adaptation. Specifically, we formulate domain adaptation as maximizing the obtained knowledge of the target domain through observing the source domain. Technically, we maximize the mutual information between the source domain features and the target domain features in a deep adversarial network. Firstly, we use a feature extraction network and a domain discriminator with opposite goals to form adversarial components, and learn the domain-invariant features between the source and target domains through adversarial training. Secondly, we use the optimization goal of maximizing the mutual information between cross-domain features to supervise the adversarial training process to ensure that the maximum target domain information can be obtained by observing the source domain features. Finally, we evaluate our method on four datasets: Office-31, ImageCLEF-DA, Office-Home, and VisDA-2017, and all achieve better performance than previous methods. We show that our method, named Cross-domain Mutual Information Adversarial Maximization (CMIAM), is a promising approach and able to outperform previous state-of-the-arts on various unsupervised domain adaptation tasks.},
  archive      = {J_EAAI},
  author       = {Lichao Meng and Hongzu Su and Chunwei Lou and Jingjing Li},
  doi          = {10.1016/j.engappai.2022.104665},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104665},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cross-domain mutual information adversarial maximization},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A kernel-based control approach for multi-period assets
allocation based on lower partial moments. <em>EAAI</em>, <em>110</em>,
104659. (<a
href="https://doi.org/10.1016/j.engappai.2021.104659">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In quantitative finance, multi-period portfolio optimization can be reformulated as a stochastic optimal control problem, and standard feedback tools can be employed for its analysis. The performance of the trading solutions strongly depend on the quality of the model of the returns. Therefore, data-driven solutions have been recently proposed to optimize simple-linear allocation policies, based only on a set of possible market scenarios. In this work, kernel-based methods are proposed to design more complex and effective control actions, providing better trade-offs in terms of risk and investment performance with respect to linear ones, by preserving convexity. The proposed approach relies on the minimization of the Lower Partial Moments (LPM) risk measure. The effectiveness of the method is shown on a set of real historical financial data.},
  archive      = {J_EAAI},
  author       = {Mirko Mazzoleni and Gabriele Maroni and Simone Formentin and Fabio Previdi},
  doi          = {10.1016/j.engappai.2021.104659},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104659},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A kernel-based control approach for multi-period assets allocation based on lower partial moments},
  volume       = {110},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Recovery of linear components: Reduced complexity
autoencoder designs. <em>EAAI</em>, <em>109</em>, 104663. (<a
href="https://doi.org/10.1016/j.engappai.2022.104663">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reducing dimensionality is a key preprocessing step in many data analysis applications to address the negative effects of the curse of dimensionality and collinearity on model performance and computational complexity, to denoise the data or to reduce storage requirements. Moreover, in many applications it is desirable to reduce the input dimensions by choosing a subset of variables that best represents the entire set without any a priori information available. Unsupervised variable selection techniques provide a solution to this second problem. An autoencoder, if properly regularized, can solve both unsupervised dimensionality reduction and variable selection, but the training of large neural networks can be prohibitive in time sensitive applications. We present an approach called Recovery of Linear Components (RLC), which serves as a middle ground between linear and non-linear dimensionality reduction techniques, reducing autoencoder training times while enhancing performance over purely linear techniques. With the aid of synthetic and real world case studies, we show that the RLC, when compared with an autoencoder of similar complexity, shows higher accuracy, similar robustness to overfitting, and faster training times. Additionally, at the cost of a relatively small increase in computational complexity, RLC is shown to outperform the current state-of-the-art for a semiconductor manufacturing wafer measurement site optimization application.},
  archive      = {J_EAAI},
  author       = {Federico Zocco and Seán McLoone},
  doi          = {10.1016/j.engappai.2022.104663},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104663},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Recovery of linear components: Reduced complexity autoencoder designs},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Problem formulation in inventive design using doc2vec and
cosine similarity as artificial intelligence methods and scientific
papers. <em>EAAI</em>, <em>109</em>, 104661. (<a
href="https://doi.org/10.1016/j.engappai.2022.104661">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decades, companies have continually sought out approaches that help them reduce the innovation cycle time due to its importance in their success. Among these approaches are TRIZ-based systematic inventive design processes, such as Inventive Design Methodology (IDM). Nevertheless, the application of these methods in the initial analysis, which requires an exhaustive gathering of information at the start of the innovation project without considering its impact on the final solution, decreases the agility of these types of processes. Consequently, a lean-based method called Inverse Problem Graph (IPG) has been proposed to formulate problems in the initial analysis phase of the inventive design process. However, the manual gathering of essential information to create a network of problems in the IPG method requires time and effort, which impresses the method’s capability. This paper integrates an automatic information retrieval approach, using Doc2vec and Cosine Similarity as Artificial Intelligence methods and Scientific Papers, into the IPG process. The integration helps to introduce a new method for the initial analysis phase of inventive design, helping to resolve part of its drawback in collecting essential knowledge from Scientific Data. The capability of the proposal is then tested through an application using a Lattice Structure case study.},
  archive      = {J_EAAI},
  author       = {Masih Hanifi and Hicham Chibane and Remy Houssin and Denis Cavallucci},
  doi          = {10.1016/j.engappai.2022.104661},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104661},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Problem formulation in inventive design using doc2vec and cosine similarity as artificial intelligence methods and scientific papers},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). IntroVAC: Introspective variational classifiers for learning
interpretable latent subspaces. <em>EAAI</em>, <em>109</em>, 104658. (<a
href="https://doi.org/10.1016/j.engappai.2021.104658">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning useful representations of complex data has been the subject of extensive research for many years. In particular, with the diffusion of complex Deep Learning-based approaches in engineering applications, the possibility to interpret, to a certain degree, model predictions is of fundamental importance for both the model users and developers. In the context of Deep Neural Networks, Variational Autoencoders have gained lots of attention since they provide an explicit model of the data distribution based on an encoder/decoder architecture which is able to both generate images and encode them in a low-dimensional subspace. However, the latent space is not easily interpretable and the generation capabilities show some limitations since images typically look blurry and lack details. In this paper, we propose the Introspective Variational Classifier (IntroVAC), a model that learns interpretable latent subspaces by exploiting information from an additional label and provides improved image quality thanks to an adversarial training strategy. We show that IntroVAC is able to learn meaningful directions in the latent space enabling fine-grained manipulation of image attributes. We validated our approach on the CelebA dataset. When compared with standard Variational Autoencoder Classifiers, the proposed approach outperform them by achieving a Frechét Inception Distance of 25.5 versus a value of 63.9.},
  archive      = {J_EAAI},
  author       = {Marco Maggipinto and Matteo Terzi and Gian Antonio Susto},
  doi          = {10.1016/j.engappai.2021.104658},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104658},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {IntroVAC: Introspective variational classifiers for learning interpretable latent subspaces},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimal maintenance scheduling under uncertainties using
linear programming-enhanced reinforcement learning. <em>EAAI</em>,
<em>109</em>, 104655. (<a
href="https://doi.org/10.1016/j.engappai.2021.104655">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maintenance is of great importance for the safety and integrity of infrastructures. The expected optimal maintenance policy in this study should be able to minimize system maintenance cost while satisfying the system reliability requirements. Stochastic maintenance scheduling with an infinite horizon has not been investigated thoroughly in the literature. In this work, we formulate the maintenance optimization under uncertainties as a Markov Decision Process (MDP) problem and solve it using a modified Reinforcement Learning method. A Linear Programming-enhanced RollouT (LPRT) is proposed, which considers both constrained deterministic and stochastic maintenance scheduling with an infinite horizon. The novelty of the proposed approach is that it is suitable for online maintenance scheduling, which can include random unexpected maintenance performance and system degradation. The proposed method is demonstrated with numerical examples and compared with several existing methods. Results show that LPRT is able to determine the suitable optimal maintenance policy efficiently compared with existing methods with similar accuracy. Parametric studies are used to investigate the effect of uncertainty, subproblem size, and the number of stochastic stages on the final maintenance cost. Limitations and future work are given based on the proposed study.},
  archive      = {J_EAAI},
  author       = {Jueming Hu and Yuhao Wang and Yutian Pang and Yongming Liu},
  doi          = {10.1016/j.engappai.2021.104655},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104655},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimal maintenance scheduling under uncertainties using linear programming-enhanced reinforcement learning},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Image segmentation of leaf spot diseases on maize using
multi-stage cauchy-enabled grey wolf algorithm. <em>EAAI</em>,
<em>109</em>, 104653. (<a
href="https://doi.org/10.1016/j.engappai.2021.104653">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grey wolf optimizer (GWO) is a widespread metaphor-based algorithm based on the enhanced variants of velocity-free particle swarm optimizer with proven defects and shortcomings in performance. Regardless of the proven defect and lack of novelty in this algorithm, the GWO has a simple algorithm and it may face considerable unbalanced exploration and exploitation trends. However, GWO is easy to be utilized, and it has a low capacity to deal with multi-modal functions, and it quickly falls into the optima trap or fails to find the global optimal solution. To improve the shortcomings of the basic GWO, this paper proposes an improved GWO called multi-stage grey wolf optimizer (MGWO). By dividing the search process into three stages and using different population updating strategies at each stage, the MGWO’s optimization ability is improved while maintaining a certain convergence speed. The MGWO cannot easily fall into premature convergence and has a better ability to get rid of the local optima trap than GWO. Meanwhile, the MGWO achieves a better balance of exploration and exploitation and has a rough balance curve. Hence, the proposed MGWO can obtain a higher-quality solution. Based on verification on the thirty benchmark functions of IEEE CEC2017 as the objective functions, the simulation experiments in which MGWO compared with some swarm-based optimization algorithms and the balance and diversity analysis were conducted. The results verify the effectiveness and superiority of MGWO. Finally, the MGWO was applied to the multi-threshold image segmentation of Leaf Spot Diseases on Maize at four different threshold levels. The segmentation results were analysed by comparing each comparative algorithm’s PSNR, SSIM, and FSIM. The results proved that the MGWO has noticeable competitiveness, and it can be used as an effective optimizer for multi-threshold image segmentation.},
  archive      = {J_EAAI},
  author       = {Helong Yu and Jiuman Song and Chengcheng Chen and Ali Asghar Heidari and Jiawen Liu and Huiling Chen and Atef Zaguia and Majdi Mafarja},
  doi          = {10.1016/j.engappai.2021.104653},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104653},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Image segmentation of leaf spot diseases on maize using multi-stage cauchy-enabled grey wolf algorithm},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Non-intrusive surrogate modeling for parametrized
time-dependent partial differential equations using convolutional
autoencoders. <em>EAAI</em>, <em>109</em>, 104652. (<a
href="https://doi.org/10.1016/j.engappai.2021.104652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel non-intrusive surrogate modeling scheme based on deep learning for predictive modeling of complex systems, described by parametrized time-dependent partial differential equations. Specifically, the proposed method utilizes a convolutional autoencoder in conjunction with a feed forward neural network to establish a mapping from the problem’s parametric space to its solution space. For this purpose, training data are collected by solving the high-fidelity model via finite elements for a reduced set of parameter values. Then, by applying the convolutional autoencoder, a low-dimensional vector representation of the high dimensional solution matrices is provided by the encoder, while the reconstruction map is obtained by the decoder. Using the latent vectors given by the encoder, a feed forward neural network is efficiently trained to map points from the parametric space to the compressed version of the respective solution matrices. This way, the proposed surrogate model is capable of predicting the entire time history response simultaneously with remarkable computational gains and very high accuracy. The elaborated methodology is demonstrated on the stochastic analysis of time-dependent partial differential equations solved with the Monte Carlo method.},
  archive      = {J_EAAI},
  author       = {Stefanos Nikolopoulos and Ioannis Kalogeris and Vissarion Papadopoulos},
  doi          = {10.1016/j.engappai.2021.104652},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104652},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Non-intrusive surrogate modeling for parametrized time-dependent partial differential equations using convolutional autoencoders},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DSU-net: Distraction-sensitive u-net for 3D lung tumor
segmentation. <em>EAAI</em>, <em>109</em>, 104649. (<a
href="https://doi.org/10.1016/j.engappai.2021.104649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic segmentation of lung tumors is a crucial and challenging problem. Many existing methods suffer from ambiguity of tissue regions and tumor regions, which occur with similar appearance. To address this problem, we propose a new cascaded two-stage U-net model, Distraction-Sensitive U-Net (DSU-Net), to explicitly take the ambiguous region information (referred as distraction region) into account. Stage-I generates a global segmentation for the whole input CT volume and predicts latent distraction regions, which contain both false negative areas and false positive areas, against the segmentation ground truth. Stage-II embeds the distraction region information into local segmentation for volume patches to further discriminate the tumor regions. To this end, a Distraction Attention Module (DAM) is proposed and applied in each level of U-Net in Stage-II, to improve the discrimination of features. We evaluate our network on a lung cancer dataset from Gross Target Volume segmentation of MICCAI2019 challenge. Experimental results show that the proposed DSU-Net outperforms existing U-like networks.},
  archive      = {J_EAAI},
  author       = {Junting Zhao and Meng Dang and Zhihao Chen and Liang Wan},
  doi          = {10.1016/j.engappai.2021.104649},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104649},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {DSU-net: Distraction-sensitive U-net for 3D lung tumor segmentation},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Swarm intelligence, exact and matheuristic approaches for
minimum weight directed dominating set problem. <em>EAAI</em>,
<em>109</em>, 104647. (<a
href="https://doi.org/10.1016/j.engappai.2021.104647">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There exist numerous heuristic and exact approaches in the literature for addressing minimum weight dominating set problem (MWDS) on vertex-weighted undirected graphs which is a well known NP -hard problem. However, little attention has been paid to its counterpart in vertex-weighted directed graphs called minimum weight directed dominating set problem (MWDDS) despite its use in modeling real-world applications involving directed interactions. As directed graphs can model undirected graphs, MWDDS can be considered as a generalization of MWDS, and hence, MWDDS is also NP -hard. In this paper, we present two approaches based on swarm intelligence, one approach based on integer linear programming (ILP) and one matheuristic approach to address the MWDDS. These approaches are the first approaches for MWDDS in their respective categories. One of our swarm intelligence approach is based on artificial be colony (ABC) algorithm, whereas the other is based on invasive weed optimization (IWO) algorithm. Both these approaches are hybridized with problem specific heuristics and a local search mechanism. We have evaluated the performance of our approaches on benchmark instances derived from the standard benchmark instances of MWDS. Computational results show the effectiveness of our approaches.},
  archive      = {J_EAAI},
  author       = {Mallikarjun Rao Nakkala and Alok Singh and André Rossi},
  doi          = {10.1016/j.engappai.2021.104647},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104647},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Swarm intelligence, exact and matheuristic approaches for minimum weight directed dominating set problem},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep-learning-based short-term electricity load forecasting:
A real case application. <em>EAAI</em>, <em>109</em>, 104645. (<a
href="https://doi.org/10.1016/j.engappai.2021.104645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rising popularity of deep learning can largely be attributed to the big data phenomenon, the surge in the development of new and novel deep neural network architectures, and the advent of powerful computational innovations. However, the application of deep neural networks is rare for time series problems when compared to other application areas. Short-term load forecasting, a typical and difficult time series problem, is considered as the application domain in this study. One-dimensional Convolutional Neural Networks (CNNs) use is rare in time series forecasting problems when compared to Long Short Term Memory (LSTM) and Gated Recurrent Unit (GRU), and the efficiency of CNN has been rather remarkable for pattern extraction. Hence, a new method that uses one-dimensional CNNs based on Video Pixel Networks (VPNs) in this study, in which the gating mechanism of Multiplicative Units of the VPNs is modified in some sense, for short term load forecasting. Specifically, the proposed one-dimensional CNNs, LSTM and GRU variants are applied to real-world electricity load data for 1-hour-ahead and 24-hour-ahead prediction tasks which they are the main concerns for the electricity provider firms for short term load forecasting. Statistical tests were conducted to spot the significance of the performance differences in analyses for which ten ensemble predictions of each method were experimented. According to the results of the comparative analyses, the proposed one-dimensional CNN model yielded the best result in total with 2.21% mean absolute percentage error for 24-h ahead predicitions. On the other hand, not a noteworthy difference between the methods was spotted even the proposed one-dimensional CNN method yielded the best results with approximately 1% mean absolute percentage error for 1-h ahead predictions.},
  archive      = {J_EAAI},
  author       = {Ibrahim Yazici and Omer Faruk Beyca and Dursun Delen},
  doi          = {10.1016/j.engappai.2021.104645},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104645},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep-learning-based short-term electricity load forecasting: A real case application},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). BroadGAN: Generative adversarial networks of discriminating
separate features based on broad learning. <em>EAAI</em>, <em>109</em>,
104640. (<a
href="https://doi.org/10.1016/j.engappai.2021.104640">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the generative adversarial network (GAN) was proposed in 2014, it has rapidly become a hot topic in the field of deep learning. In recent years, there are many optimizations for GAN, which are divided into three kinds, including the optimization of loss functions, external structure of network and internal structure of network. Few people optimizes GAN from internal structure of network, and because of the process of game, slow training speed is one of the biggest problems of GAN. This paper introduces the ideology of broad learning algorithm (Chen and Liu, 2017) to put forward the multi-judge generative adversarial network method based on different random features to enhance the quality of generative result and increase the training speed of GAN (Goodfellow et al., 2014). This model provides a method which reduce the input information of each discriminator to optimize the training process of GAN. The experiments on cifar10 and anime face dataset find that our model obtains a better performance than the GMAN model and Base model. This paper finds a group of hyper-parameters to enhance the BroadGAN.},
  archive      = {J_EAAI},
  author       = {Qimin Jin and Rongheng Lin and Fangchun Yang},
  doi          = {10.1016/j.engappai.2021.104640},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104640},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {BroadGAN: Generative adversarial networks of discriminating separate features based on broad learning},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A framework for designing power-efficient inference
accelerators in tree-based learning applications. <em>EAAI</em>,
<em>109</em>, 104638. (<a
href="https://doi.org/10.1016/j.engappai.2021.104638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine Learning techniques (ML) are being widely adopted in embedded devices due to their efficiency and flexibility. However, the strict power limitations in such devices, combined with the variable resource requirements of ML models, require further understanding of how model complexity affects power and performance. This paper proposes a framework that facilitates the design space exploration of dedicated decision trees (DT) and random forests (RF) accelerators by enabling a joint assessment of power dissipation and prediction accuracy. The proposed framework translates tree-based structures to hardware description languages (HDL). The HDL modules are submitted to logic and physically-aware hardware synthesis flows, allowing a detailed power-performance analysis of VLSI DTs and RFs. Using four data sets of embedded applications as case studies, we found that quantizing the input features leads to accuracy gains of up to 6.3% compared with the precise versions. We also show that using shallower trees may lead to small prediction loss with significant reductions in power, which is favorable for power-constrained applications. Our translator achieves better results in terms of energy/inference w.r.t. prior related works under comparison, one of which employed standard methods for hardware translation such as High-Level Synthesis. The proposed solution presents a power reduction of 10 times or more for the same inference throughput reported in prior works.},
  archive      = {J_EAAI},
  author       = {Brunno Abreu and Mateus Grellert and Sergio Bampi},
  doi          = {10.1016/j.engappai.2021.104638},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104638},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A framework for designing power-efficient inference accelerators in tree-based learning applications},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On residual-based diagnosis of physical systems.
<em>EAAI</em>, <em>109</em>, 104636. (<a
href="https://doi.org/10.1016/j.engappai.2021.104636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article we describe a novel diagnosis methodology for physical systems such as industrial production systems. The article consists of two parts: Part one analyzes the differences between using sensor values and using residual values for fault diagnosis. Residual values denote the health of a component by comparing sensor values to a predefined model of normal behaviour. We further analyse how faults propagate through components of a physical system and argue for the use of residual values for diagnosing physical systems. In part two we extend the theory of established consistency-based diagnosis algorithms to use residual values. We also illustrate how users of the presented diagnosis methodology are free to substitute the residual generating equations and the diagnosis algorithm to suit their specific needs. For diagnosis, we present the algorithm HySD, based on Satisfiability Modulo Linear Arithmetic. We present an implementation of HySD using threshold values and a symbolic diagnosis approach. However, the approach is also suitable to integrate modern machine learning methods for anomaly detection and combine them with a multitude of diagnosis approaches. Through experiments on the process-industry benchmark Tennessee Eastman Process and another benchmark consisting of multiple tank systems we show the feasibility of our approach. Overall we show how our novel diagnosis approach offers a practical methodology that allows industry to advance from current state of the art anomaly detection to automated fault diagnosis.},
  archive      = {J_EAAI},
  author       = {Alexander Diedrich and Oliver Niggemann},
  doi          = {10.1016/j.engappai.2021.104636},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104636},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {On residual-based diagnosis of physical systems},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Nonspecificity, strife and total uncertainty in supervised
feature selection. <em>EAAI</em>, <em>109</em>, 104628. (<a
href="https://doi.org/10.1016/j.engappai.2021.104628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose three novel feature ranking methods for supervised feature selection in the context of classification which are based on possibility theory. All three methods – nonspecificity, strife and total uncertainty – are tested on eight artificial data sets and ten medical real-world data sets and benchmarked against ReliefF, the Fisher score, the fuzzy entropy and similarity (FES), the Fuzzy similarity and entropy (FSAE) filter, symmetrical uncertainty as well as using no feature selection. The feature ranking methods were applied following two approaches: (1) using a fixed threshold for the number of highest-ranking features selected and (2) using a hybrid feature selection approach with a classifier (k-nearest neighbor classifier, decision tree, similarity classifier, SVM) to select the optimal number of features to select. The results indicate that strife and the Fisher score are the two feature ranking methods that for both approaches are on average ranked the highest in terms of the test set accuracy on the real-world data sets. Besides that, for the hybrid approach, strife uses most of the time a considerably smaller number of features than nonspecificity and total uncertainty. In terms of stability, which was measured with the adjusted stability measure (ASM), the Fisher score and strife were among the most stable feature ranking methods in this study. Additionally, strife’s feature subsets were diverse compared to those of the remaining feature selection methods, making it a good candidate to be included in a feature selection ensemble.},
  archive      = {J_EAAI},
  author       = {Christoph Lohrmann and Pasi Luukka},
  doi          = {10.1016/j.engappai.2021.104628},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104628},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Nonspecificity, strife and total uncertainty in supervised feature selection},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). New mist-edge-fog-cloud system architecture for thermal
error prediction and control enabled by deep-learning. <em>EAAI</em>,
<em>109</em>, 104626. (<a
href="https://doi.org/10.1016/j.engappai.2021.104626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The geometric precision of machined gears is reduced by thermal errors. So the prediction and control of thermal errors are essential. But the prediction and control are a process involving the processing of a large-volume thermal data, and then the processing efficiency is low, which severely hinders the geometric precision improvement. To solve this problem, a new mist-edge-fog-cloud system (MEFCS) architecture is proposed for the error prediction and control. A finite element model is established to prove the applicability of bidirectional long short-term memory (Bi-LSTM) network. A cosine and sine gray wolf optimization (CSGWO) algorithm is proposed to optimize the batch size. Then the CSGWO-Bi-LSTM network error model is proposed. The predictive accuracy is 90.80%, 94.57%, 95.77%, 96.79%, 97.51%, 98.45%, and 98.92% for the multiple linear regression model, recurrent neural network, LSTM network, Bi-LSTM network, CSGWO1-Bi-LSTM network, CSGWO2-Bi-LSTM network, and CSGWO3-Bi-LSTM network, respectively. The volume of the transferred data is reduced by 11/16 with the data-based model, and the volume of the transferred thermal data is reduced to 1/10 with the designed system. A precision threshold is set, and the predictive accuracy is improved by 8.31% by the system with the precision threshold compared with the system without the precision threshold. With the proposed MEFCS, the accuracy level of the tooth profile deviation f H α is increased from ISO level 5 to ISO level 3. The total execution time of the mist-cloud structure, mist-edge-cloud structure, mist-fog-cloud structure, and mist-edge-fog-cloud structure is 206 s, 200 s, 186 s, and 167 s, respectively.},
  archive      = {J_EAAI},
  author       = {Hongquan Gui and Jialan Liu and Chi Ma and Mengyuan Li and Shilong Wang},
  doi          = {10.1016/j.engappai.2021.104626},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104626},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {New mist-edge-fog-cloud system architecture for thermal error prediction and control enabled by deep-learning},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybrid dynamic bayesian network method for performance
analysis of safety barriers considering multi-maintenance strategies.
<em>EAAI</em>, <em>109</em>, 104624. (<a
href="https://doi.org/10.1016/j.engappai.2021.104624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Safety barriers play a critical role in preventing unintentional hydrocarbon flow leaking from reservoir to external environment or another formation during different offshore operation stages, and such a leakage has the potential to trigger cascading events and may lead to catastrophic consequences. The present study aims at the development of a hybrid DBN-based approach for dynamic performance analysis of safety barriers in the prevention of subsea downhole leakage incidents. Events in operation, such as different types of maintenances and process demand are taken into account to enhance the safety barrier performance. These factors could be analyzed by reflecting inspecting and repair activities of safety barriers with multistate-based multiphase Markov process. In order to obtain a dynamic and synthetic risk analysis of subsea downhole leakage, a dynamic Bayesian network-based model is proposed, incorporating the failure analysis of safety barriers and downhole multiple leakage pathways. Such analysis allows determining the dynamic risk characteristic of leakage events, and key safety barriers under different maintenance scenarios. Dynamic performance of such safety barriers is evaluated with respect to four aspects: preventive maintenance and imperfect repair, degradation effects, process demand and maintenance cost. The approach is tested through the application to a case study with an offshore oil and gas well. The results the importance of safety barrier performance in controlling the expected leakage scenarios.},
  archive      = {J_EAAI},
  author       = {Shengnan Wu and Bin Li and Yangfan Zhou and Maoyu Chen and Yiliu Liu and Laibin Zhang},
  doi          = {10.1016/j.engappai.2021.104624},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104624},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybrid dynamic bayesian network method for performance analysis of safety barriers considering multi-maintenance strategies},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multilevel and holonic model for dynamic holarchy
management: Application to large-scale road traffic. <em>EAAI</em>,
<em>109</em>, 104622. (<a
href="https://doi.org/10.1016/j.engappai.2021.104622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, with the emergence of connected objects and cars, road traffic systems become more and more complex and exhibit hierarchical behaviors at several levels of detail. The multilevel modeling approach is generally appropriate to represent traffic from several perspectives. However, few works have been interested in multilevel traffic modeling. Moreover, most of the available multilevel models of traffic proposed in the literature are static because they use a set of predefined levels of detail and these representations cannot change during simulation. To tackle these drawbacks, this paper introduces a holonic multilevel and dynamic traffic model for large-scale traffic systems. To this end, the paper proposes a density-based upward holonification model to group similar entities to structure the holarchy of traffic. Additionally, it proposes a downward holonification model based on the Gaussian distribution to break down non-atomic entities. Moreover, the paper presents a methodology for the management of the holarchy’s dynamics over time allowing the transitions between heterogeneous representations of a traffic system. Furthermore, multilevel indicators based on standard deviation are proposed to assess the consistency of the simulation results. The experiments are conducted with several simple scenarios on a highway to investigate the trade-off between the simulation accuracy and the availability of computational resources.},
  archive      = {J_EAAI},
  author       = {Igor Tchappi and Yazan Mualla and Stéphane Galland and André Bottaro and Vivient Corneille Kamla and Jean Claude Kamgang},
  doi          = {10.1016/j.engappai.2021.104622},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104622},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multilevel and holonic model for dynamic holarchy management: Application to large-scale road traffic},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Type-2 fuzzy instrumental variable algorithm for evolving
neural-fuzzy modeling of nonlinear dynamic systems in noisy environment.
<em>EAAI</em>, <em>109</em>, 104620. (<a
href="https://doi.org/10.1016/j.engappai.2021.104620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In neural-fuzzy modeling, dealing with dynamic systems in a noisy environment is a relevant issue due to uncertainties in the experimental data. In this sense, a type-2 fuzzy instrumental variable based learning algorithm for evolving neural-fuzzy modeling is proposed in this paper. For antecedent adaptation, an Extend Kalman Filter based evolving type-2 fuzzy algorithm is adopted, where the participatory concept is used to mitigate the effects of outliers in the data flow. For consequent estimation, a type-2 fuzzy instrumental variable based subspace identification method is proposed. From the data flow, the instrumental variables are computed via recursive singular spectral analysis and used to estimate the fuzzy Markov parameters. From Markov parameters, the linear state-space matrices are obtained, recursively. Results illustrate the efficiency of the proposed methodology compared to other prominent approaches in the literature for identifying a nonlinear dynamic system with discontinuous function corrupted by colored noise and online identification of a 2DoF helicopter with correlated noise.},
  archive      = {J_EAAI},
  author       = {Anderson Pablo Freitas Evangelista and Ginalber Luiz de Oliveira Serra},
  doi          = {10.1016/j.engappai.2021.104620},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104620},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Type-2 fuzzy instrumental variable algorithm for evolving neural-fuzzy modeling of nonlinear dynamic systems in noisy environment},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An intelligent quality-based fusion method for
complex-valued distributions using POWA operator. <em>EAAI</em>,
<em>109</em>, 104618. (<a
href="https://doi.org/10.1016/j.engappai.2021.104618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information quality (IQ) is a significant index in information processing, e.g. multiple information fusion. An extended method considering the IQ has been investigated using the multi-complex-valued information. However, how to fuse the multiple complex-valued distributions (CvDs) with correlation and preference of decision-maker may be a fantastic issue. In this paper, we propose a new method using the power ordered weighted average (POWA) operator to integrate multi-complex-valued distributions considering the information correlation and preference of decision-maker. The proposed method is an extension of the previous work. Some examples and applications are used to illustrate the effectiveness of the proposed method.},
  archive      = {J_EAAI},
  author       = {Yanan Li and Ruonan Zhu and Xiangjun Mi and Bingyi Kang},
  doi          = {10.1016/j.engappai.2021.104618},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104618},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An intelligent quality-based fusion method for complex-valued distributions using POWA operator},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploring fuzzy set consensus analysis in IoT resource
ranking. <em>EAAI</em>, <em>109</em>, 104617. (<a
href="https://doi.org/10.1016/j.engappai.2021.104617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complexity of the procedures for discovering, classifying, and selecting suitable resources to meet customer demands is related to the growing resource offers connected to the Internet. This proposal takes into account the uncertainties in the specification and processing of customer preferences, via consensual analysis. In this work we study the relationship between restricted equivalence functions, more generally, consensus measures, and the possibility of building the latter using the former. Thus, consensus measures of fuzzy values and consensus measures on fuzzy sets are both defined by aggregations, such as the arithmetic mean and the exponential mean. Based on the interval-valued fuzzy logic we consider inaccuracies related to the measurements beyond the uncertainties, modeling the imprecision of expertise in classifying a set of resources in the IoT based on the IT2FL-EXEHDA-RR Model. Several results arise from these methods. Firstly, the methodology L [ 0 , 1 ] -FCM, which is performed to measure how similar are the corresponding fuzzy values of a fuzzy set on [ 0 , 1 ] . In particular, it is applied to the superior and the inferior limits of each interval-valued membership function, modeling linguistic variables related to the attributes of the IT2FL-EXEHDA-RR Model. And the second one, based on L F χ -FSCM, providing the consensus analysis among a family of fuzzy sets. In the reported case study, this is applied to obtain the consensus measure between corresponding upper and lower bounds of each interval-valued function. This research also investigates the conditions under which we can build convex sum based on L F χ -FSCM, including the analysis of their main properties.},
  archive      = {J_EAAI},
  author       = {Lizandro de Souza Oliveira and Amanda Argou and Renato Dilli and Adenauer Yamin and Renata Reiser and Benjamín Bedregal},
  doi          = {10.1016/j.engappai.2021.104617},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104617},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Exploring fuzzy set consensus analysis in IoT resource ranking},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel vision-based weakly supervised framework for
autonomous yield estimation in agricultural applications. <em>EAAI</em>,
<em>109</em>, 104615. (<a
href="https://doi.org/10.1016/j.engappai.2021.104615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous systems have been established as a ground-breaking technology in agriculture, particularly for resource optimization and labor savings. However, even those solutions that are limited to monitoring activities, such as yield estimation, rely on costly robotic platforms equipped with a series of range devices ( e.g., LIDAR and GPS-RTK). Recently, vision-based strategies have gained considerable attention as a less expensive and more efficient alternative, capable to be on par with or even surpass approaches that benefit from range sensors. Nonetheless, they exploit deep learning methodologies, which require burdensome labeling procedures to perform training. To address these shortcomings, we present a novel approach that performs yield estimation requiring only a monocular camera and needs a limited amount of supervision information. It detects, locates and maps fruits and tree canopies to estimate the total yield of a specific crop. To keep the image labeling effort to a minimum, we propose a weakly-supervision paradigm that only requires a simple binary label encoding the presence or the absence of fruits in the training images. Our approach does not make any assumptions on the underlying platform, i.e., it can be used by collecting images either with a hand-held camera or with an autonomous robot. Therefore, we are able to considerably reduce the deployment time, the energy and the cost of the overall yield estimation system. At the same time, we keep the performance comparable to both vision-based fully supervised baselines (which require costly labeling operations) and classical systems that rely on more expensive and power-demanding sensors.},
  archive      = {J_EAAI},
  author       = {Enrico Bellocchio and Francesco Crocetti and Gabriele Costante and Mario Luca Fravolini and Paolo Valigi},
  doi          = {10.1016/j.engappai.2021.104615},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104615},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel vision-based weakly supervised framework for autonomous yield estimation in agricultural applications},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Weighted matrix-object data clustering guided by
matrix-object distributions. <em>EAAI</em>, <em>109</em>, 104612. (<a
href="https://doi.org/10.1016/j.engappai.2021.104612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In data mining, the input of most algorithms is a data set in which each example is a feature vector. However, in many real applications an example usually contains multiple feature vectors and its observed classification is the responsibility of all feature vectors. We call this example kind matrix-object. Some existing clustering algorithms for matrix-object data fail to consider contributions of attributes to clusters, which may degrade clustering solutions due to less discriminative attributes. Some existing clustering algorithms for the data in which each example is a vector consider the contributions but encounter difficulties in handling matrix-object data. For matrix-object data, ordered and cross matrix-object distributions may exist in a cluster and cause different ways of measuring qualities of clusters. In this paper, we propose a weighted matrix-object data clustering algorithm guided by matrix-object distributions. We define cluster and matrix-object compactness respectively for the two distributions to measure qualities of clusters. The bigger the compactness is, the higher the quality is. So the proposed algorithm utilizes the compactness to assign a weight to each attribute for each cluster and maximizes weighted cluster and matrix-object compactness to find the optimal weight and the final clustering partition. Furthermore, a regular term about weight is added to the objective function to make more higher discriminative attributes participate in the optimization. Experimental results on real data have shown the effectiveness of the proposed algorithm. Compared with previous clustering algorithms, the proposed algorithm improves the clustering performance and enhances the interpretability of clustering results.},
  archive      = {J_EAAI},
  author       = {Liqin Yu and Fuyuan Cao},
  doi          = {10.1016/j.engappai.2021.104612},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104612},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Weighted matrix-object data clustering guided by matrix-object distributions},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An information fusion method based on deep learning and
fuzzy discount-weighting for target intention recognition.
<em>EAAI</em>, <em>109</em>, 104610. (<a
href="https://doi.org/10.1016/j.engappai.2021.104610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the military confrontation environment, recognizing the target intention is helpful to know the target actions in advance, and the global intention recognition of target formations can provide decision-making reference for the command center. In this work, a new information fusion method for multi-target formation intention recognition is developed, which combines the advantages of deep learning and Dempster–Shafer theory. This method firstly construct the deep learning networks and design the corresponding conversion methods to obtain the uncertain information for target intention recognition. Then, a new fuzzy discount-weighting operation is proposed. This operation defines the new fuzzy discount rule and fuzzy weighting rule, which generates discount evidence and weighting coefficients to improve the reliability of evidence, then obtain a more reasonable fusion result. The simulation results show that the method is effective and feasible for global target intention recognition under uncertain and incomplete information.},
  archive      = {J_EAAI},
  author       = {Zhuo Zhang and Hongfei Wang and Jie Geng and Wen Jiang and Xinyang Deng and Wang Miao},
  doi          = {10.1016/j.engappai.2021.104610},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104610},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An information fusion method based on deep learning and fuzzy discount-weighting for target intention recognition},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive harris hawks optimization with persistent
trigonometric differences for photovoltaic model parameter extraction.
<em>EAAI</em>, <em>109</em>, 104608. (<a
href="https://doi.org/10.1016/j.engappai.2021.104608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an adaptive Harris hawk optimization with persistent trigonometric (sine–cosine)-differences (ADHHO) is proposed for parameter identification of Photovoltaic (PV) systems. In the optimized version of HHO, we innovatively propose the persistent-trigonometric-differences mechanism for improving the global search capability of HHO; moreover, we improve the energy factor in the original algorithm so that ADHHO obtains a better balance between exploration and exploitation. Note that the proposed method can obtain lower CPU time in parameter extraction for the three-diode and PV module models with an enhanced parameter extraction performance. To validate the performance of ADHHO, we verified the parameter extraction capability of the single-diode model (SDM), double-diode model (DDM), triple-diode model (TDM), and PV module model (PVM), respectively. Further, we verified the parameter extraction effect of ADHHO in three commercial cells with different light intensity and temperature conditions. Experiments show that the method proposed in this paper can reasonably simulate the output performance of solar PV cells and can be used as a trustworthy method for the extraction of unknown parameters of solar PV systems.},
  archive      = {J_EAAI},
  author       = {Shiming Song and Pengjun Wang and Ali Asghar Heidari and Xuehua Zhao and Huiling Chen},
  doi          = {10.1016/j.engappai.2021.104608},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104608},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive harris hawks optimization with persistent trigonometric differences for photovoltaic model parameter extraction},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid algorithm for time-dependent vehicle routing
problem with soft time windows and stochastic factors. <em>EAAI</em>,
<em>109</em>, 104606. (<a
href="https://doi.org/10.1016/j.engappai.2021.104606">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to meet the logistics and distribution requirements with poor actual traffic conditions, this paper considers adding soft time windows and stochastic factors (road traffic congestion, weather changes, etc.) based on classic vehicle routing problem. Firstly, we construct a time-dependent vehicle routing problem (TDVRP) with soft time windows model with the objective function of minimizing the total cost of distribution. A Hybrid Algorithm (HA) combining Sweep Algorithm (SA) and Improved Particle Swarm Optimization (IPSO) is developed to solve this model. Secondly, we compare IPSO with other algorithms through benchmark test functions and traditional vehicle routing problem cases. Finally, By applying HA to the modified Solomon benchmark test set, this paper compares HA with the existing solutions in the number of vehicles used, total transportation distance and total waiting time. Then experimental results manifest the practicability of HA.},
  archive      = {J_EAAI},
  author       = {Ke-Wei Jie and San-Yang Liu and Xiao-Jun Sun},
  doi          = {10.1016/j.engappai.2021.104606},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104606},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid algorithm for time-dependent vehicle routing problem with soft time windows and stochastic factors},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intelligent weight generation algorithm based on binary
isolation tree. <em>EAAI</em>, <em>109</em>, 104604. (<a
href="https://doi.org/10.1016/j.engappai.2021.104604">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, in order to make the statistical information of the scoring system more reasonable, a new questionnaire weighting algorithm is proposed to intelligently identify the credibility of survey in this paper. Based on the core idea of the Isolation Forest (iForest), the weights of questionnaire are computationally identified by considering depth of nodes and relative mass between nodes. Using Swee Chuan Tan’s approach of constructing Half-Space Trees, the problem of non-unique weights with repeated calculations is solved and the lower randomness of the result is obtained. In addition, the impact of multiplicity of point on weight is considered by introducing a tiny deviation, and a weight updating method is proposed to deal with the dynamic change of data. The final simulation results demonstrate that the proposed method is defective and accurate, and that the reliability of the questionnaire can be more intelligently recognized in the scoring and evaluation system.},
  archive      = {J_EAAI},
  author       = {Di Wang and Haoyue Liu and Yuming Li},
  doi          = {10.1016/j.engappai.2021.104604},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104604},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent weight generation algorithm based on binary isolation tree},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning variable ordering heuristics for solving constraint
satisfaction problems. <em>EAAI</em>, <em>109</em>, 104603. (<a
href="https://doi.org/10.1016/j.engappai.2021.104603">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Backtracking search algorithms are often used to solve the Constraint Satisfaction Problem (CSP), which is widely applied in various domains such as automated planning and scheduling. The efficiency of backtracking search depends greatly on the variable ordering heuristics. Currently, the most commonly used heuristics are hand-crafted based on expert knowledge. In this paper, we propose a deep reinforcement learning based approach to automatically discover new variable ordering heuristics that are better adapted for a given class of CSP instances, without the need of relying on hand-crafted features and heuristics. We show that directly optimizing the search tree size is not convenient for learning, and propose to optimize the expected cost of reaching a leaf node in the search tree. To capture the complex relations among the variables and constraints, we design a representation scheme based on Graph Neural Network that can process CSP instances with different sizes and constraint arities. Experimental results on random CSP instances show that on small and medium sized instances, the learned policies outperform classical hand-crafted heuristics with smaller search tree (up to 10.36% reduction). Moreover, without further training, our policies directly generalize to instances of larger sizes and much harder to solve than those in training, with even larger reduction in the search tree size (up to 18.74%).},
  archive      = {J_EAAI},
  author       = {Wen Song and Zhiguang Cao and Jie Zhang and Chi Xu and Andrew Lim},
  doi          = {10.1016/j.engappai.2021.104603},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104603},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning variable ordering heuristics for solving constraint satisfaction problems},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enabling integration and interaction for decentralized
artificial intelligence in airline disruption management. <em>EAAI</em>,
<em>109</em>, 104600. (<a
href="https://doi.org/10.1016/j.engappai.2021.104600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Airline disruption management traditionally seeks to address three problem dimensions: aircraft scheduling, crew scheduling, and passenger scheduling, in that order. However, current efforts have, at most, only addressed the first two problem dimensions concurrently and do not account for the propagative effects that uncertain scheduling outcomes in one dimension can have on another dimension. In addition, existing approaches for airline disruption management include human specialists who decide on necessary corrective actions for airline schedule disruptions on the day of operation. However, human specialists are limited in their ability to process copious amounts of information imperative for making robust decisions that simultaneously address all problem dimensions during disruption management. Therefore, there is a need to augment the decision-making capabilities of a human specialist with quantitative and qualitative tools that can rationalize complex interactions amongst all dimensions in airline disruption management, and provide objective insights to the specialists in the airline operations control center. To that effect, we provide a discussion and demonstration of an agnostic and systematic paradigm for enabling expeditious simultaneously-integrated recovery of all problem dimensions during airline disruption management, through an intelligent multi-agent system that employs principles from artificial intelligence and distributed ledger technology. Results indicate that our paradigm for simultaneously-integrated recovery executes in polynomial time and is effective when all the flights in the airline route network are disrupted.},
  archive      = {J_EAAI},
  author       = {Kolawole Ogunsina and Daniel DeLaurentis},
  doi          = {10.1016/j.engappai.2021.104600},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104600},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enabling integration and interaction for decentralized artificial intelligence in airline disruption management},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Differential exponential entropy-based multilevel threshold
selection methodology for colour satellite images using
equilibrium-cuckoo search optimizer. <em>EAAI</em>, <em>109</em>,
104599. (<a
href="https://doi.org/10.1016/j.engappai.2021.104599">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the entropic based multilevel threshold selection methods use 2D histogram, which is constructed using the local averages, leading to a loss of edges. Further, the computation of the entropy using the diagonal pixel values only leads to a loss of information. Nevertheless, traditional 2D histogram based multilevel thresholding methods suffer from efficiently retaining the spatial correlation information. In addition, the conventional entropy uses logarithmic function, which has inherent problems, thereby, reducing the accuracy at some situations. To solve these issues, a differential exponential entropy (DEE) -based multilevel threshold selection methodology is proposed. To suppress the high magnitude peaks in the 2D histogram, the normalized local variance is used while the construction. A novel objective function is suggested to compute the DEE. A new Equilibrium-Cuckoo Search Optimizer (ECSO) is suggested to maximize the DEE. For testing, standard benchmark functions are used. The results are compared with the physics-based Equilibrium Optimizer (EO) and the nature-inspired Cuckoo Search Algorithm (CSA). Different benchmark colour satellite images are acquired from the Landsat Image Gallery database for the experiment. The performances are compared with the state-of-the-art methods. Different metrics such as PSNR, SSIM and FSIM are used for the image quality assessment. A statistical analysis is presented in terms of the Box plots. Our proposed DEE-ECSO outperforms the other techniques. The suggested algorithm would be useful for segmentation of the brain MR images for biomedical engineering applications.},
  archive      = {J_EAAI},
  author       = {Monorama Swain and Tanmaya Tapaswini Tripathy and Rutuparna Panda and Sanjay Agrawal and Ajith Abraham},
  doi          = {10.1016/j.engappai.2021.104599},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104599},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Differential exponential entropy-based multilevel threshold selection methodology for colour satellite images using equilibrium-cuckoo search optimizer},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An improved preference-based variable neighborhood search
algorithm with ar-dominance for assembly line balancing considering
preventive maintenance scenarios. <em>EAAI</em>, <em>109</em>, 104593.
(<a href="https://doi.org/10.1016/j.engappai.2021.104593">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For assembly line balancing problem considering preventive maintenance scenarios (ALBP-PM), the production managers’ preferences should be concerned and hence the derived Pareto-optimal solution set ( POS ) should be advanced towards the corresponding region-of-interest. Otherwise, production managers might select a final solution far from their interests, and then obviously reducing the quality and efficiency of decision-making. Thus, a preference-based multi-objective optimization problem is formulated to simultaneously minimize the cycle times under different scenarios and total task adjustments among scenarios. An improved variable neighborhood search algorithm (IVNS) with novel ar -dominance and three modifications is proposed to obtain a preferred POS . Specifically, ar -dominance is integrated into it to guide the advancement direction of the preferred POS . Enhanced neighborhood structures based on critical stations are proposed to generate better-quality neighbor solutions whose cycle times are mathematically proven smaller. On this basis, a local search strategy is designed to randomly select a neighbor solution to guarantee quality and decrease the computational cost. A problem-specific adaptive restart mechanism is developed to escape from the local optimum. Computational results suggest that the IVNS obtains a better preferred POS than other eight state-of-the-art algorithms in terms of convergence, distribution and closeness to the preferences, and furthermore, incorporating preferences into the ALBP-PM helps production managers make final decisions in a more precise and faster way.},
  archive      = {J_EAAI},
  author       = {Lianpeng Zhao and Qiuhua Tang and Zikai Zhang},
  doi          = {10.1016/j.engappai.2021.104593},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104593},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An improved preference-based variable neighborhood search algorithm with ar-dominance for assembly line balancing considering preventive maintenance scenarios},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-external archive-guided henry gas solubility
optimization algorithm for solving multi-objective optimization
problems. <em>EAAI</em>, <em>109</em>, 104588. (<a
href="https://doi.org/10.1016/j.engappai.2021.104588">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new multi-objective evolutionary algorithm by adapting the recent Henry Gas Solubility Optimization (HGSO) with multiple objectives. The proposed MOHGSO uses the Pareto dominance relation as means of comparison and integrates two types of archive, while an elite archive is used to store the Pareto solutions found over the evolutionary process, the other external-archives are used to store the local best solutions corresponding to each cluster. Moreover, efficient archiving and leader selection strategies based on the crowding distance computation are proposed to guide the population towards the true Pareto front. The performance of the MOHGSO algorithm is validated through an extensive comparison with three well-known algorithms on twelve test functions and four engineering design problems. The experiments of two widely used metrics in the field called IGD and Sp metrics show the ability of the proposed algorithm in achieving interesting results. Furthermore, the statistical results related to the Wilcoxon test indicate that the proposed algorithm outperforms significantly the selected methods for the above metrics at a 99% confidence level.},
  archive      = {J_EAAI},
  author       = {Soumaia Kahloul and Djaafar Zouache and Boualem Brahmi and Adel Got},
  doi          = {10.1016/j.engappai.2021.104588},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104588},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-external archive-guided henry gas solubility optimization algorithm for solving multi-objective optimization problems},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interweave features of deep convolutional neural networks
for semantic segmentation. <em>EAAI</em>, <em>109</em>, 104587. (<a
href="https://doi.org/10.1016/j.engappai.2021.104587">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although semantic segmentation based on Deep Convolutional Neural Networks (DCNN) has made great signs of progress, the issue that features generated by deep models are of low-resolution and will negatively affect the final semantic segmentation performances is not fully addressed yet. In this paper, we propose to adaptively combine high-level and low-level features of DCNN to improve the quality of the features used for semantic segmentation. To this end, we design a feature interweaving neural network module to fuse features from different layers of DCNN to effectively take advantage of their complementary properties. And, in order to enhance complementarity and diminish contradiction of the features for better feature fusion, we propose a feature modulation neural network module to modulate the features before interweaving. Furthermore, global information of images is summarized and used to augment the features for providing guidance for feature interweaving. The proposed method is extensively evaluated and compared to state-of-the-art methods based on two benchmark semantic segmentation datasets Cityscapes and PASCAL VOC 2012 in the experiments. Obtained results demonstrate the effectiveness of the proposed method.},
  archive      = {J_EAAI},
  author       = {Shuang Bai and Wenchao Gu and Lingxing Kong},
  doi          = {10.1016/j.engappai.2021.104587},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104587},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Interweave features of deep convolutional neural networks for semantic segmentation},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Information quality for intuitionistic fuzzy values with its
application in decision making. <em>EAAI</em>, <em>109</em>, 104568. (<a
href="https://doi.org/10.1016/j.engappai.2021.104568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information quality has attracted increasing attention in recent years. In this paper, we propose a measure to quantify the information quality of intuitionistic fuzzy information based on a pseudo probability transformation, and derive its induced order to rank intuitionistic fuzzy values. The proposed measure and the induced order are proved to possess some well-defined properties that ensure rationality. Further, in order to rank intuitionistic fuzzy alternatives in decision making, we turn the proposed information quality into a ranking-oriented information quality, and present its induced order to generate the ranking. The decision capacity of our method is founded with the goal of rationalizing, simulating and further facilitating the interpretability and transparency in human decision making. A comparative study has been conducted, demonstrating the effectiveness of the proposed approach to ranking alternatives. The proposed approach is shown to outperform existing ranking methods via case-by-case comparisons. Finally, an application involving decision making of drug selection and an application in multi-criteria decision analysis of supplier selection are provided.},
  archive      = {J_EAAI},
  author       = {Dawei Xie and Fuyuan Xiao and Witold Pedrycz},
  doi          = {10.1016/j.engappai.2021.104568},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104568},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Information quality for intuitionistic fuzzy values with its application in decision making},
  volume       = {109},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Echo state networks for online, multi-step MPC relevant
identification. <em>EAAI</em>, <em>108</em>, 104596. (<a
href="https://doi.org/10.1016/j.engappai.2021.104596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an online nonlinear system identification algorithm for model predictive control relevant identification, based on an echo state network (ESN) trained using the recursive least squares method with a directional forgetting factor. The proposed online ESN architecture is formed by a reservoir, with fixed recurrent connections, and a reservoir readout mechanism, which is updated online to define the network output. The ESN is used to perform a multi-step prediction task, which can be used for model-predictive control purposes. The proposed online identification algorithm is evaluated in simulation using a conical tank level process and compared with the results of other approaches from the literature. The results show that the proposed algorithm is able to identify the nonlinear characteristics of the process without considering any prior information about it. In addition, the results for long-range predictions are better than the ones obtained with a model linear in its parameters and several baseline ESN models from literature, after the adaptation phase of the proposed algorithm.},
  archive      = {J_EAAI},
  author       = {Bernardo B. Schwedersky and Rodolfo C.C. Flesch and Samuel B. Rovea},
  doi          = {10.1016/j.engappai.2021.104596},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {104596},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Echo state networks for online, multi-step MPC relevant identification},
  volume       = {108},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Synchronization for stochastic lévy noise systems on a
time-varying multi-weights network via delay intermittent control.
<em>EAAI</em>, <em>108</em>, 104594. (<a
href="https://doi.org/10.1016/j.engappai.2021.104594">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In previous papers, either the time-varying coupling structure or multi-weights have been considered into networks. However, few scholars have paid attention to networks with both time-varying coupling structure and multi-weights. In this paper, we formulate and probe stochastic Lévy noise delayed systems on a time-varying multi-weights network (SLDSTN) for the first time. In order to solve the synchronization problem of SLDSTN, we design a novel class of delay intermittent control. Different from previous intermittent control based on current state, delay intermittent control is based on past state. Then, by means of Lyapunov method, graph theory and some techniques of inequalities, sufficient conditions for exponential synchronization in mean square of SLDSTN are proposed. Therein, we relax the condition of processing the time-varying coupling term successfully. Furthermore, for presenting the superiorities of delay intermittent control, delay feedback control and aperiodically intermittent control also are applied to solve the synchronization problem of SLDSTN. To demonstrate the effectiveness of the theoretical results, a class of single-link robot arms is considered as a practical application. Finally, some numerical simulations are provided.},
  archive      = {J_EAAI},
  author       = {Hui Zhou and Qiguang Jiang and Wenxue Li},
  doi          = {10.1016/j.engappai.2021.104594},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {104594},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Synchronization for stochastic lévy noise systems on a time-varying multi-weights network via delay intermittent control},
  volume       = {108},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning temporal action models from multiple plans: A
constraint satisfaction approach. <em>EAAI</em>, <em>108</em>, 104590.
(<a href="https://doi.org/10.1016/j.engappai.2021.104590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning, as a discovery task from past observations, is interesting in engineering contexts for identifying structures and improving accuracy. Learning in planning scenarios aims at recognizing past behavior to predict action models to improve decisions. This is appealing because practical scenarios are usually complex, sometimes difficult to be described formally, which require expert knowledge and engineering that becomes impractical in real-world applications. We introduce a Constraint Satisfaction formulation for learning PDDL2.1 temporal action models in planning. Given a collection of observations on multiple plans and a set of empty operators, we automatically create a learning task that identifies which conditions+effects are necessary, together with their temporal annotation, and induces durations and costs. Our formulation encapsulates planning (causal links, threats and effect interferences) and mutex (to avoid contradictions) constraints to be fully satisfied from the observed plans. The formulation is simple, but it proves very effective and easily adaptable to different levels of expressiveness. We evaluate such effectiveness in different IPC domains and compare the quality of the learning vs. other state-of-the-art learning approaches.},
  archive      = {J_EAAI},
  author       = {Antonio Garrido},
  doi          = {10.1016/j.engappai.2021.104590},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {104590},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning temporal action models from multiple plans: A constraint satisfaction approach},
  volume       = {108},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A generalized divergence of information volume and its
applications. <em>EAAI</em>, <em>108</em>, 104584. (<a
href="https://doi.org/10.1016/j.engappai.2021.104584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dempster–Shafer evidence theory provides a powerful method for the expression and fusion of uncertain information. When handling the high conflict information, traditional Dempster combination rule can produce counterintuitive results. Hence, the reasonable conflict measure is essential in information fusion. Inspired by this view, the paper propose the new method to measure conflict between bodies of evidence. Firstly, we define a new information volume of mass function for the perspective of information discord and non-specificity. Second, we propose a generalized divergence based on information volume of mass function, denoted as Jensen–Shannon divergence of information volume ( I J S ) . I J S can effectively measure the conflict between bodies of evidence. I J S reflects the conflict between bodies of evidence in terms of the differences between the support of propositions and the elements. That is, compared to the current approach, I J S not only fully considers the differences between the support degree of propositions, but also the differences of elements in propositions from the perspective of information non-specificity. When the mass function degenerates to a probabilistic distribution, I J S also degenerates to the classical Jensen–Shannon divergence. Meanwhile, I J S also satisfies the axioms of distance measure, such as non-negativity, symmetry and etc. Further, we proved these axioms based on mathematical derivation, and some numerical examples are applied to explain axioms and advantages. Based on the proposed divergence measure, we propose a multi-source information fusion method in the real world, and several data sets can be used to show that the proposed fusion method is superior to current method under the framework of evidence theory.},
  archive      = {J_EAAI},
  author       = {Xiaozhuan Gao and Lipeng Pan and Yong Deng},
  doi          = {10.1016/j.engappai.2021.104584},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {104584},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A generalized divergence of information volume and its applications},
  volume       = {108},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sequential transformer via an outside-in attention for image
captioning. <em>EAAI</em>, <em>108</em>, 104574. (<a
href="https://doi.org/10.1016/j.engappai.2021.104574">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attention-based approaches have been firmly established the state of the art in image captioning tasks. However, both the recurrent attention in recurrent neural network (RNN) and the self attention in transformer have limitations. Recurrent attention only takes the external state to decide where to look, while ignoring to discover the internal relationships between image regions. Self attention is just the opposite. To fill this gap, we firstly introduce an Outside-in Attention that makes the external state participate in the interaction of the image regions. And, it prompts the model to learn the dependency inside the image regions, as well as the dependency between image regions and the external state. Then, we investigate a Sequential Transformer Framework (S-Transformer) based on the original Transformer structure, where the decoder is incorporated with the Outside-in Attention and RNN. This framework can help the model to inherit the advantages of both the transformer and recurrent network in sequence modeling. When tested on COCO dataset, the proposed approaches achieve competitive results in single-model and ensemble configurations on both MSCOCO Karpathy test split and the online test server.},
  archive      = {J_EAAI},
  author       = {Yiwei Wei and Chunlei Wu and Guohe Li and Haitao Shi},
  doi          = {10.1016/j.engappai.2021.104574},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {104574},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Sequential transformer via an outside-in attention for image captioning},
  volume       = {108},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An SEI3R information propagation control algorithm with
structural hole and high influential infected nodes in social networks.
<em>EAAI</em>, <em>108</em>, 104573. (<a
href="https://doi.org/10.1016/j.engappai.2021.104573">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information propagation and control have great significance to manage public opinion in social networks. This paper aims to establish a novel information propagation model and the corresponding control algorithm to display the processes of information evolution, propagation and control. Considering high influential nodes and structural hole nodes highly influence the decision-making choices of public users’ opinions in the information propagation process, the structural hole node discovery and score (SHNDS) algorithm and high influential node discovery and score (HINDS) algorithm are proposed, respectively. According to different node status for a social network, the network nodes are divided into susceptible ( S ), latent ( E ), ordinary influential infected ( I n ), structural hole infected ( I s ), high influential infected ( I h ) and removed nodes ( R ). Then, combining with the SHNDS and HINDS algorithms, a new SEI 3 R information propagation model and the corresponding control algorithm are proposed. Experimental results show that when the high influential nodes are regarded as the initial information propagation nodes, the information propagates to all nodes of their communities which contained the initial information propagation nodes. The information propagation ranges are wider than SEIR and SEI 2 R models. When the structural hole nodes are taken as initial information propagation nodes, the information propagates to the entire networks. When the structural hole nodes and high influential nodes are both seen as the initial information propagation nodes, information propagation speeds and ranges are faster and wider than the former two cases, respectively. By controlling high influential nodes, structural hole nodes, and both of them, the numbers of nodes received the information are reduced in turn. These indicate that information control effects are gradually improved.},
  archive      = {J_EAAI},
  author       = {Qian Zhang and Xianyong Li and Yongquan Fan and Yajun Du},
  doi          = {10.1016/j.engappai.2021.104573},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {104573},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An SEI3R information propagation control algorithm with structural hole and high influential infected nodes in social networks},
  volume       = {108},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Proportional integral derivative booster for neural
networks-based time-series prediction: Case of water demand prediction.
<em>EAAI</em>, <em>108</em>, 104570. (<a
href="https://doi.org/10.1016/j.engappai.2021.104570">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-step time-series prediction is an essential supportive step for decision-makers in several industrial areas. Artificial intelligence techniques, which use a neural network component in various forms, have recently frequently been used to accomplish this step. However, the complexity of the neural network structure still stands up as a critical problem against prediction accuracy. In this paper, a method inspired by the proportional–integral–derivative (PID) control approach is investigated to enhance the performance of neural network models used for multi-step ahead prediction of periodic time-series information while maintaining a negligible impact on the complexity of the system. The PID-based method is applied to the predicted value at each time step to bring that value closer to the real value. The water demand forecasting problem is considered as a case study, where two deep neural network models from the literature are used to prove the effectiveness of the proposed boosting method. Furthermore, to prove the applicability of this PID-based booster to other types of periodic time-series prediction problems, it is applied to enhance the accuracy of a neural network model used for multi-step forecasting of hourly energy consumption. The comparison between the results of the original prediction models and the results after using the proposed technique demonstrates the superiority of the proposed method in terms of prediction accuracy and system complexity.},
  archive      = {J_EAAI},
  author       = {Tony Salloom and Okyay Kaynak and Xinbo Yu and Wei He},
  doi          = {10.1016/j.engappai.2021.104570},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {104570},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Proportional integral derivative booster for neural networks-based time-series prediction: Case of water demand prediction},
  volume       = {108},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On a two-stage progressive clustering algorithm with
graph-augmented density peak clustering. <em>EAAI</em>, <em>108</em>,
104566. (<a
href="https://doi.org/10.1016/j.engappai.2021.104566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the rapidly growing volume and velocity of big data, real-time streaming data analysis has become increasingly important in many applications. To discover knowledge from such data, a wide range of machine learning techniques have been proposed and used in practice. Among them, clustering, which aims at grouping objects into different classes on the basis of their similarity, is the most common form of unsupervised learning. However, most existing clustering algorithms are designed for static data, and hence are not best suited for streaming data. In this paper, we propose PC-DPC, a two-stage progressive clustering algorithm with graph-augmented density peak clustering. PC-DPC first identifies clusters of streaming data using an improved density peak clustering algorithm, and then merges newly arriving data into the existing data pool by measuring inter-cluster structural similarity, which considers the distance between a center and representative points. We illustrate the superiority of PC-DPC over several state-of-the-art clustering algorithms in terms of clustering accuracy and running time on publicly available benchmark datasets.},
  archive      = {J_EAAI},
  author       = {Xinzheng Niu and Yunhong Zheng and Wuji Liu and Chase Q. Wu},
  doi          = {10.1016/j.engappai.2021.104566},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {104566},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {On a two-stage progressive clustering algorithm with graph-augmented density peak clustering},
  volume       = {108},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An optimal washout filter for motion platform using neural
network and fuzzy logic. <em>EAAI</em>, <em>108</em>, 104564. (<a
href="https://doi.org/10.1016/j.engappai.2021.104564">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To experience the motion sensation of a real vehicle through a motion simulator, a motion cueing algorithm (MCA) is required to transform the vehicle motions to the driving motion platform (DMP) while respecting the physical limitations of DMP. In this aspect, the optimal washout filter (WF) extracts the optimal motion signals including linear accelerations and angular velocities for the DMP with consideration of the human vestibular model and DMP motion states using the linear quadratic regulator (LQR) technique. The LQR technique is employed to obtain the optimal and pre-defined higher order transfer functions by solving the Riccati equation. However, the Riccati equation is solved using fixed weights, leading to an inconvenient usage of the DMP workspace. In this research, a new optimal WF model is designed and developed using a neural network (NN) and a fuzzy logic controller (FLC). The NN is introduced to solve the Riccati equation online while the FLC model is designed to extract the weighting matrices of the LQR technique. The proposed technique considers the physical DMP limitations online and reproduces accurate motion signals with a high degree of fidelity. The results demonstrate the efficiency of the developed optimal WF model as compared with those of existing optimal WF models.},
  archive      = {J_EAAI},
  author       = {Mohammad Reza Chalak Qazani and Houshyar Asadi and Shady Mohamed and Chee Peng Lim and Saeid Nahavandi},
  doi          = {10.1016/j.engappai.2021.104564},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {104564},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An optimal washout filter for motion platform using neural network and fuzzy logic},
  volume       = {108},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hierarchical pyramid attentive network with spatial
separable convolution for crowd counting. <em>EAAI</em>, <em>108</em>,
104563. (<a
href="https://doi.org/10.1016/j.engappai.2021.104563">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To tackle the challenging scale variation issue of the crowd counting task so as to improve the counting accuracy, we present a novel method based on Hierarchical Pyramid Attentive Network (HPANet) for crowd counting. Specifically, a Scale-aware Pyramid Attentive (SPA) block, extracting the rich multi-scale context, is designed elaborately as using the two-branch spatial separable convolution as its core component to replace the conventional pure convolution with larger kernel size to reduce the computation, as well as adopting a self-attention operation for the spatial feature aggregation. In order to further learn the scale-aware feature representation well from the input image, we stack the designed SPA block in a hierarchical way and fuse their features flexibly as another crucial module of the proposed HPANet, the Hierarchical Feature Fusion (HFF) module. Combining the designed SPA block and HFF module, the developed HPANet could remedy the scale variation issue and thus improve the counting performance with the mighty scale-aware feature representation. The performance of the HPANet is evaluated on four public available benchmark datasets in this paper, including ShanghaiTech, Mall, Beijing BRT and UCF-QNRF. Extensive experimental results on benchmarks demonstrate that the proposed HPANet could have an effective performance for crowd counting and the ablation experimental results validate the effectiveness of the components of HPANet on the counting task. The designed HPANet could realize a preferable counting performance in view of alleviating the scale variation issue, without the cost of introducing too much additional parameters for the multi-column structure.},
  archive      = {J_EAAI},
  author       = {Shihui Zhang and Xiaoxiao Zhang and He Li and Huan He and Dandan Song and Lei Wang},
  doi          = {10.1016/j.engappai.2021.104563},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {104563},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hierarchical pyramid attentive network with spatial separable convolution for crowd counting},
  volume       = {108},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generating various airfoils with required lift coefficients
by combining NACA and joukowski airfoils using conditional variational
autoencoders. <em>EAAI</em>, <em>108</em>, 104560. (<a
href="https://doi.org/10.1016/j.engappai.2021.104560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of inverse design problem in mechanical design is to obtain shapes that satisfy the required design specifications. It is also desired to obtain varieties of shapes, but finding multiple shapes in a short computation time is difficult using the conventional methods. This paper proposes the use of the conditional variational autoencoders (CVAE) with normal distribution, denoted by N -CVAE, along with the von Mises–Fischer distribution, denoted by S -CVAE, to find multiple solutions for the inverse design problems. Both the CVAE models embed shapes into a latent space. The S -CVAE enables the separation of data in the latent space, whereas the N -CVAE embeds the data in a narrow space. These different features are used for various tasks in this study. In the first task, the dataset consists of only one type of data. Here, S -CVAE outperforms N -CVAE because it can easily separate the data. In the second task, the dataset consists of two different types of airfoils. It is desired to combine two types and to generate new types of data. N -CVAE is useful in this task since it embeds different shapes in the same latent area, due to which, the model outputs intermediate shapes of different types. The shape-generation capability of S -CVAE and N -CVAE are experimentally compared in this study.},
  archive      = {J_EAAI},
  author       = {Kazuo Yonekura and Kazunari Wada and Katsuyuki Suzuki},
  doi          = {10.1016/j.engappai.2021.104560},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {104560},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Generating various airfoils with required lift coefficients by combining NACA and joukowski airfoils using conditional variational autoencoders},
  volume       = {108},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-strategy whale optimization algorithm and its
application. <em>EAAI</em>, <em>108</em>, 104558. (<a
href="https://doi.org/10.1016/j.engappai.2021.104558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Whale Optimization Algorithm (WOA) is a key tool for solving complex engineering optimization problems, aiming at adjusting important parameters to satisfy constraints and optimal objectives. WOA has a simple structure, few parameters, high search capability, and easy implementation. However, it suffers from the same problems as other metaheuristic algorithms of being prone to local optima and slow convergence, for which the Multi-Strategy Whale Optimization Algorithm (MSWOA) is proposed. Four strategies are introduced in MSWOA. Firstly, a highly randomized chaotic logistic map is used to generate a high-quality initial population. Secondly, exploitation and exploration are enhanced by setting adaptive weights and dynamic convergence factors. Further, a Lévy flight mechanism is introduced to maintain the population diversity in each iteration. Finally, the Evolutionary Population Dynamics (EPD) mechanism is introduced to improve the efficiency of search agents in finding the optimum. Another problem lies in the Semi-Supervised Extreme Learning Machine (SSELM) based on manifold regularization is an effective classification and regression model, but the random generation of input weights and hidden layer thresholds and the grid selection of hyperparameters lead to unsatisfactory classification performance. To this end, we developed the MSWOA-SSELM model, optimally selected the parameters of SSLEM using MSWOA, and applied it to logging layer recognition, which effectively improved the accuracy of logging interpretation. By comparing the experiments with 14 swarm intelligence algorithms on 18 benchmark test functions, the CEC2017 benchmark suite, and an engineering application problem, the experimental results show that MSWOA is significantly superior and effective in solving global optimization problems. Finally, the proposed MSWOA-SSELM is applied in three wells and outperforms other classification models in terms of Accuracy (ACC), Root Mean Square Error (RMSE), and Mean Absolute Error (MAE). It obtained the best results with 96.2567% ACC, MAE of 0.0749, and RMSE of 0.3870.},
  archive      = {J_EAAI},
  author       = {Wenbiao Yang and Kewen Xia and Shurui Fan and Li Wang and Tiejun Li and Jiangnan Zhang and Yu Feng},
  doi          = {10.1016/j.engappai.2021.104558},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {104558},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-strategy whale optimization algorithm and its application},
  volume       = {108},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Outranking-based multi-objective PSO for scheduling
unrelated parallel machines with a freight industry-oriented
application. <em>EAAI</em>, <em>108</em>, 104556. (<a
href="https://doi.org/10.1016/j.engappai.2021.104556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents Outranking-based Particle Swarm Optimisation (O-PSO) a novel metaheuristic to address the multi-objective Unrelated Parallel Machine Scheduling Problem. It is a particle swarm optimisation algorithm enriched with the preferences of the Decision Maker (DM), articulated in a fuzzy relational system based on ELECTRE III. Unlike other multi-objective metaheuristics, O-PSO searches for the Region of Interest (RoI) instead of approximating a sample of the complete Pareto frontier. The RoI is the subset consisting of those Pareto-efficient solutions that satisfy the outranking relations, that is, they are the best solutions in terms of the DM’s system of preferences. Therefore, O-PSO not only approximates the Pareto solutions but also supports multicriteria decision analysis of the schedules. The efficiency of O-PSO is validated on a benchmark of synthetic instances from the scientific literature, where the Wilcoxon rank-sum test provides statistical evidence that O-PSO offers high-quality solutions when compared with two state-of-the-art metaheuristics; specifically, O-PSO is capable of generating a greater proportion of solutions (on average, ranging from 7% to 14%) dominating those of the state-of-the-art algorithms, as well as finding more solutions (from 13% to 18%) that satisfy the DM’s preferences. O-PSO is also applied to a real-world case study in the transport industry to provide evidence for its applicability.},
  archive      = {J_EAAI},
  author       = {Gilberto Rivera and Raúl Porras and J. Patricia Sanchez-Solis and Rogelio Florencia and Vicente García},
  doi          = {10.1016/j.engappai.2021.104556},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {104556},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Outranking-based multi-objective PSO for scheduling unrelated parallel machines with a freight industry-oriented application},
  volume       = {108},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-objective teaching–learning evolutionary algorithm for
enhancing sensor network coverage and lifetime. <em>EAAI</em>,
<em>108</em>, 104554. (<a
href="https://doi.org/10.1016/j.engappai.2021.104554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coverage plays a vital role in the performance and proper functioning of wireless sensor networks. However, ensuring a network’s coverage is met numerous challenges due to sensors having limited sensing range, communication range, and energy. Many coverage problems are NP-hard, one of which is the network coverage with lifetime problem (CTLP). As such, a number of meta-heuristic algorithms have been proposed to solve CTLP in practical scenarios. This paper proposes an approach for CTLP based on the teaching–learning based optimization algorithm (TLBO), which is often employed to address continuous optimization problems. Specifically, a discrete version of multi-objective improved teaching–learning based optimization algorithm (MO-ITLBO) called HTLBO is proposed, employing genetic operators inspired by evolutionary computing methods. Experimental results are extensively compared to those obtained from previous approaches, namely MO-ITLBO, fast elitist non-dominated sorting genetic algorithm (NSGA-II), multi-objective differential evolution (MODE), and multi-objective evolutionary algorithm based on decomposition (MOEA/D). The evaluation shows significant improvements in different metrics, including spacing, hypervolume, non-dominated solutions, and coverage.},
  archive      = {J_EAAI},
  author       = {Nguyen Thi Tam and Vu Dinh Hoang and Huynh Thi Thanh Binh and Le Trong Vinh},
  doi          = {10.1016/j.engappai.2021.104554},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {104554},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-objective teaching–learning evolutionary algorithm for enhancing sensor network coverage and lifetime},
  volume       = {108},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial intelligence in prognostics and health management
of engineering systems. <em>EAAI</em>, <em>108</em>, 104552. (<a
href="https://doi.org/10.1016/j.engappai.2021.104552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prognostics and health management (PHM) has become a crucial aspect of the management of engineering systems and structures, where sensor hardware and decision support tools are deployed to detect anomalies, diagnose faults and predict remaining useful lifetime (RUL). Methodologies for PHM are either model-driven, data-driven or a fusion of both approaches. Data-driven approaches make extensive use of large-scale datasets collected from physical assets to identify underlying failure mechanisms and root causes. In recent years, many data-driven PHM models have been developed to evaluate system’s health conditions using artificial intelligence (AI) and machine learning (ML) algorithms applied to condition monitoring data. The field of AI is fast gaining acceptance in various areas of applications such as robotics, autonomous vehicles and smart devices. With advancements in the use of AI technologies in Industry 4.0, where systems consist of multiple interconnected components in a cyber–physical space, there is increasing pressure on industries to move towards more predictive and proactive maintenance practices. In this paper, a thorough state-of-the-art review of the AI techniques adopted for PHM of engineering systems is conducted. Furthermore, given that the future of inspection and maintenance will be predominantly AI-driven, the paper discusses the soft issues relating to manpower, cyber-security, standards and regulations under such a regime. The review concludes that the current systems and methodologies for maintenance will inevitably become incompatible with future designs and systems; as such, continued research into AI-driven prognostics systems is expedient as it offers the best promise of bridging the potential gap.},
  archive      = {J_EAAI},
  author       = {Sunday Ochella and Mahmood Shafiee and Fateme Dinmohammadi},
  doi          = {10.1016/j.engappai.2021.104552},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {104552},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Artificial intelligence in prognostics and health management of engineering systems},
  volume       = {108},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Transfer-based taxonomy induction over concept labels.
<em>EAAI</em>, <em>108</em>, 104548. (<a
href="https://doi.org/10.1016/j.engappai.2021.104548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a domain-specific set of concepts, taxonomy induction is the problem of inducing a taxonomy from the set of concepts. The problem, despite having practical importance, has not received as much research attention, in contrast with related problems such as link prediction, due to its difficulty and lack of domain-specific benchmarks. In this paper, we present a principled approach for taxonomy induction in the e-commerce domain over a set of concept-labels, given background resources such as a pre-trained language representation learning model and examples of other taxonomies, induced over other concept-sets, but no example links for the target concept-set. Our approach, developed as an academic-industrial collaboration, is significantly more competitive than seven different baselines, including the transformer-based RoBERTa model, on three real-world and widely used e-commerce concept-sets.},
  archive      = {J_EAAI},
  author       = {Mayank Kejriwal and Ke Shen and Chien-Chun Ni and Nicolas Torzec},
  doi          = {10.1016/j.engappai.2021.104548},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {104548},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Transfer-based taxonomy induction over concept labels},
  volume       = {108},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Regularized twin minimax probability machine for pattern
classification and regression. <em>EAAI</em>, <em>107</em>, 104550. (<a
href="https://doi.org/10.1016/j.engappai.2021.104550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an excellent discriminant classifier based on generating prior knowledge, the minimax probability machine (MPM) has been widely used and deeply researched in many fields. The core idea of minimax probability machine is to directly estimate probability accuracy bound by minimizing the maximum probability of misclassification. However, minimax probability machine does not include a regularization term for the construction of the separating hyperplane, and it needs to solve a large-scale second-order cone programming problem in the solution process, which greatly limits it development and application. In this paper, to improve the performance of minimax probability machine, we propose a novel binary classification method called regularized twin minimax probability machine classification (TMPMC). The TMPMC constructs two non-parallel hyperplanes for final classification by solving two smaller second-order cone programming problems to improve the performance of the MPM. For each hyperplane, our method is theoretically well grounded on the idea of minimizing the worst case (maximum) probability of misclassification of a class of samples while the distance to the other class is as large as possible. Our approach was first derived as linear methods, and subsequently extended as kernel-based strategies for nonlinear classification. Additionally, we extend TMPMC to the regression problem and propose a new regularized twin minimax probability machine regression (TMPMR). Experimental results on several datasets show that our methods are competitive in terms of generalization performance compared to other algorithms.},
  archive      = {J_EAAI},
  author       = {Jun Ma and Guolin Yu},
  doi          = {10.1016/j.engappai.2021.104550},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104550},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Regularized twin minimax probability machine for pattern classification and regression},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An efficient unsupervised image quality metric with
application for condition recognition in kiln. <em>EAAI</em>,
<em>107</em>, 104547. (<a
href="https://doi.org/10.1016/j.engappai.2021.104547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose an unsupervised textural-intensity-based natural image quality evaluator (TI-NIQE) by modelling the texture, structure and naturalness of an image. In detail, an effective quality-aware feature named as textural intensity (TI) is proposed in this paper to detect image texture. The image structure is captured by the distribution of gradients and basis images. The naturalness is characterized through the distributions of the locally mean subtracted and contrast normalized (MSCN) coefficients and the products of pairs of the adjacent MSCN coefficients. Furthermore, a new application pattern of image quality assessment (IQA) measures is proposed by taking the quality scores as the essential input of the recognition model. Using statistics of video quality scores computed by TI-NIQE as input features, an automatic IQA-based visual recognition model is proposed for the condition recognition in rotary kiln. Extensive experiments on benchmark datasets demonstrate that TI-NIQE shows better performance both in accuracy and computational complexity than other state-of-the-art unsupervised IQA methods, and experimental results on real-world data show that the recognition model has high prediction accuracy for condition recognition in rotary kiln.},
  archive      = {J_EAAI},
  author       = {Leyuan Wu and Xiaogang Zhang and Hua Chen and Yicong Zhou and Lianhong Wang and Dingxiang Wang},
  doi          = {10.1016/j.engappai.2021.104547},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104547},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An efficient unsupervised image quality metric with application for condition recognition in kiln},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fault diagnosis of modular multilevel converter based on
adaptive chirp mode decomposition and temporal convolutional network.
<em>EAAI</em>, <em>107</em>, 104544. (<a
href="https://doi.org/10.1016/j.engappai.2021.104544">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The reliability of the insulated gate bipolar transistors (IGBTs) is essential to the stable operation of the modular multilevel converter (MMC) system. However, there are a large number of IGBTs in the MMC system and the open-circuit faults of IGBTs are usually so hidden that it is difficult to find. Therefore, this article proposes a fault diagnosis framework based on temporal convolutional network (TCN) integrating adaptive chirp mode decomposition (ACMD) and silhouette coefficient (SC). First, ACMD is used to extract and reconstruct signal components from the original signal. Then, in order to avoid artificial selection of signal components, silhouette coefficient is introduced to characterize the importance of each component. Finally, the TCN model automatically extracts the features of the signal components and outputs the classification results. The main contributions are as follows: (1) A complete fault diagnosis framework that can adaptively extract features and perform fault classification is proposed in the paper. (2) For the MMC using the carrier-phase-shifted pulsewidth modulation strategy, the fault can be located to the IGBT by the output current. (3) Under certain noise conditions, the fault diagnosis proposed in the paper method still has good robustness. (4) The signal visualization of different residual blocks and channels explains the working mechanism of the AMCD-SC-TCN framework.},
  archive      = {J_EAAI},
  author       = {Qun Guo and Xinhao Zhang and Jing Li and Gang Li},
  doi          = {10.1016/j.engappai.2021.104544},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104544},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fault diagnosis of modular multilevel converter based on adaptive chirp mode decomposition and temporal convolutional network},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Clustering with label constrained dirichlet process mixture
model. <em>EAAI</em>, <em>107</em>, 104543. (<a
href="https://doi.org/10.1016/j.engappai.2021.104543">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a constrained Dirichlet process mixture model with labels as side information. Specifically, the labeled information is incorporated through the use of a product partition prior to give clusters of instances with similar labels a higher prior preference. The proposed formulation is further extended to handle multiple side information. The empirical results on several benchmark datasets show that our method can consistently improve its clustering performance as more labeled data become available. Even in the presence of noisy labels, the proposed method rarely performs worse than its unsupervised counterpart. The effectiveness of the proposed method is also demonstrated through an application of magnetic resonance imaging for identifying major brain tissues.},
  archive      = {J_EAAI},
  author       = {Nurul Afiqah Burhanuddin and Mohd Bakri Adam and Kamarulzaman Ibrahim},
  doi          = {10.1016/j.engappai.2021.104543},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104543},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Clustering with label constrained dirichlet process mixture model},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Emotion recognition: A smoothed dirichlet multinomial
solution. <em>EAAI</em>, <em>107</em>, 104542. (<a
href="https://doi.org/10.1016/j.engappai.2021.104542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multinomial-based models have been extensively used for count data modeling and challenging applications such as image processing, text recognition, and behavioral sciences. Despite the good performance obtained with those models, they still suffer from challenging issues that require continuous exploring of other alternative approaches. In this work, we address the issue of smoothing language modeling. To the best of our knowledge, distributions defined in a smoothed simplex were not considered before as conjugate priors for the multinomial. We propose a smoothed Dirichlet multinomial (SDM) distribution and a mixture of SDMs with a likelihood-based learning. We evaluate the proposed approach on three challenging applications related to emotion recognition: depression on social media, happiness analysis, and pain estimation. The smoothed Dirichlet multinomial solution presents the best results comparing to the related works and the multinomial-based models such as Dirichlet compound multinomial and the multinomial model.},
  archive      = {J_EAAI},
  author       = {Fatma Najar and Nizar Bouguila},
  doi          = {10.1016/j.engappai.2021.104542},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104542},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Emotion recognition: A smoothed dirichlet multinomial solution},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimizing class priors to improve the detection of social
signals in audio data. <em>EAAI</em>, <em>107</em>, 104541. (<a
href="https://doi.org/10.1016/j.engappai.2021.104541">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To detect social signals such as laughter and filler events in an audio recording, the most straightforward way is to utilize a Hidden Markov Model — or these days a Hidden Markov Model/Deep Neural Network (HMM/DNN) hybrid. HMM/DNNs, however, perform best if the DNN outputs are scaled by dividing them by the a priori class probabilities first, before applying a dynamic or Viterbi beam search. These class a priori probability values (or priors for short) are usually estimated by counting the frame occurrences of each class in the training set and then dividing these totals by the total number of frames. These estimates, however, may in fact be suboptimal for a number of reasons ranging from imprecise labeling to the overconfidence of DNNs. In this study we show empirically that more reliable scaling factors can be obtained by optimization. Using this approach, we managed to achieve a 6 − 9 % relative error reduction both at the frame level and the segment level, using a public database containing spontaneous English mobile phone conversations.},
  archive      = {J_EAAI},
  author       = {Gábor Gosztolya},
  doi          = {10.1016/j.engappai.2021.104541},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104541},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimizing class priors to improve the detection of social signals in audio data},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning latent features with local channel drop network for
vehicle re-identification. <em>EAAI</em>, <em>107</em>, 104540. (<a
href="https://doi.org/10.1016/j.engappai.2021.104540">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle re-identification targets to find the target vehicle images in a large dataset which is composed of vehicle images from multiple non-overlapping cameras. Due to the various illumination, viewpoints and resolutions, it is challenging to find the right vehicle images accurately. Most existing works put emphasis on learning strong features by exploiting the attention parts in vehicle images, which leads to some small important cues being suppressed by these significant parts. Hence, a local channel drop network (LCDNet) is proposed in this paper, which focuses on seeking the latent features by releasing the constraint of most attentive features. Specially, besides the normal local feature learning network, LCDNet consists of an attentive local feature learning branch that drops some regions to promote learning the attentive features of local regions. Besides, the batch ranking loss is introduced to split the samples into two groups in a batch and regularize them by enforcing a margin, which ensures the model to learn meaningful features to distinct vehicles. Moreover, to further calculate the similarity of various images, the paper proposes a multi-distance based ranking method to achieve more accurate results. Experiments on several benchmark datasets validate the effectiveness of the proposed method.},
  archive      = {J_EAAI},
  author       = {Xianping Fu and Jinjia Peng and Guangqi Jiang and Huibing Wang},
  doi          = {10.1016/j.engappai.2021.104540},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104540},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning latent features with local channel drop network for vehicle re-identification},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient probability-oriented feature matching using wide
field-of-view imaging. <em>EAAI</em>, <em>107</em>, 104539. (<a
href="https://doi.org/10.1016/j.engappai.2021.104539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature matching is a key technique for a wide variety of computer vision and image processing applications such as visual localization. It permits finding correspondences of significant points within the environment that eventually determine the localization of a mobile agent. In this context, this work evaluates an Adaptive Probability-Oriented Feature Matching (APOFM) method that dynamically models the visual knowledge of the environment in terms of the probability of existence of features. Several improvements are proposed to achieve a more robust matching in a visual odometry framework: a study on the classification of the matching candidates, enhanced by a nearest neighbour search policy; a dynamic weighted matching that exploits the probability of feature existence in order to tune the matching thresholds; and an automatic false positive detector. Additionally, a comparison of performance is carried out, considering a publicly available dataset composed of two kinds of wide field-of-view images: catadioptric and fisheye. Overall, the results validate the appropriateness of these contributions, which outperform other well-recognized implementations within this framework, such as the standard visual odometry, a visual odometry method based on RANSAC, as well as the basic APOFM. The analysis shows that fisheye images provide more visual information of the scene, with more feature candidates. Contrarily, omnidirectional images produce fewer feature candidates, but with higher ratios of feature acceptance. Finally, it is concluded that improved precision is obtained when the location problem is solved by this method.},
  archive      = {J_EAAI},
  author       = {María Flores and David Valiente and Arturo Gil and Oscar Reinoso and Luis Payá},
  doi          = {10.1016/j.engappai.2021.104539},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104539},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Efficient probability-oriented feature matching using wide field-of-view imaging},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel feature based ensemble learning model for indoor
localization of smartphone users. <em>EAAI</em>, <em>107</em>, 104538.
(<a href="https://doi.org/10.1016/j.engappai.2021.104538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For WiFi-based indoor localization, optimal selection of features leads to the increased perceptibility of the localization procedure. It is essential to capture the important sets of Access Points (APs) that best defines the floor map for the positioning process. To maintain sustainable localization, the selection of APs enables scaling the solution and reducing the maintenance cost. In the present work, our contribution is twofold- the power of Particle Swarm Optimization is utilized for the selection of important APs. Then, a feature-based ensemble model is designed for the selected subsets of APs to retain the generality of localization performance. The base learners capture the different ambiance in the training and testing process. Extensive experimentation was carried out using the collected dataset from multiple smartphone devices. The proposed feature selection and training pipeline has also been tested with two popular benchmark datasets- UJIIndoorLoc and JUIndoorLoc. Results indicate that the proposed feature-based ensemble model could achieve 86%–96% accuracy with around 50%–65% reduction in APs for the datasets. The mean absolute error (MAE) indicates the distance between the predicted and actual location points. It is found to be 2.68 m, that is, neighboring location points, which is quite acceptable for user localization in indoor spaces.},
  archive      = {J_EAAI},
  author       = {Ayan Kumar Panja and Syed Fahim Karim and Sarmistha Neogy and Chandreyee Chowdhury},
  doi          = {10.1016/j.engappai.2021.104538},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104538},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel feature based ensemble learning model for indoor localization of smartphone users},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mathematical models of CBSC over wireless channels and their
analysis by using the LeNN-WOA-NM algorithm. <em>EAAI</em>,
<em>107</em>, 104537. (<a
href="https://doi.org/10.1016/j.engappai.2021.104537">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent studies, several chaos-based secure communication (CBSC) systems are developed and are assumed to be effective and promising tools for balancing communications in wireless applications. The reliability of a wireless communication system is dependent on the synchronization between receiving and transmitting nodes. Therefore, it is crucial to analyze the mathematical models for different enhancements through CBSC and avoid the difficulty in synchronization. We have designed a novel computational paradigm that uses weighted Legendre polynomials to construct series solutions for mathematical models of the Lorenz Chaotic Attractor (LCA) and Double Scroll Attractor (DSA) (with filter and without filter) by using Chua’s circuits. We design fitness functions for each system of differential equations. Two optimization techniques, the Whale Optimization Algorithm (WOA) and the Nelder–Mead (NM) algorithm are adopted to optimize the objective functions and calculate the best set of unknown weights. We name our soft computing paradigm, the LeNN-WOA-NM algorithm. We have compared our results with state-of-the-art, and we establish that the LeNN-WOA-NM algorithm is fast, accurate, and reliable. We present graphical and statistical analysis to further elaborate on the performance of our algorithm.},
  archive      = {J_EAAI},
  author       = {Naveed Ahmad Khan and Muhammad Sulaiman and Abdulah Jeza Aljohani and Maharani A. Bakar and Miftahuddin},
  doi          = {10.1016/j.engappai.2021.104537},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104537},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Mathematical models of CBSC over wireless channels and their analysis by using the LeNN-WOA-NM algorithm},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel ECG diagnostic system for the detection of 13
different diseases. <em>EAAI</em>, <em>107</em>, 104536. (<a
href="https://doi.org/10.1016/j.engappai.2021.104536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manual analysis of electrocardiogram (ECG) signals is a laborious and prone-to-error task, even for a specialist with many hours of experience. For this reason, research on automatic ECG diagnosis is widespread in the literature and continues to grow each year. The present paper describes a novel and fully functional expert system for automatic diagnosis of 13 different diseases using standard 12-lead ECGs. This system makes three significant contributions to the state of the art: (a) the large number of different diseases diagnosed; (b) the use of 5 leads for a more precise identification and measurement of the ECG waves; and (c) a novel noise indicator that measures the quality of the acquired ECG signal. The kernel of the system consists of a set of rules that replicate a specialist’s diagnostic process but with the speed of an automatic system. The rules use a set of parameters generated after a noise-filtering process of the ECG signal and subsequent identification of its different waves (P, QRS complex, T, and Delta). The design of the rules was carried out with the collaboration of a specialist with more than 20 years of experience in ECG diagnosis and using a database of 284,000 ECGs as support. The system was validated by the specialist, obtaining a reliability of 80.8%. Given the complexity of the problem and the number of diagnoses covered, the results are considered satisfactory and make the system a useful support tool for diagnosis.},
  archive      = {J_EAAI},
  author       = {Iñigo Monedero},
  doi          = {10.1016/j.engappai.2021.104536},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104536},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel ECG diagnostic system for the detection of 13 different diseases},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). K-means – laplacian clustering revisited. <em>EAAI</em>,
<em>107</em>, 104535. (<a
href="https://doi.org/10.1016/j.engappai.2021.104535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, clustering the real-life data using attribute information alone is not enough because the data come from various resources and may have data object relations. Thus, it enforces to include the relation information of the data while clustering. Knowing its importance, many researchers have used it along with attribute information. The Integrated K-means Laplacian (IKL) algorithm is one such type that integrates the attribute and pair-wise relations to cluster the data. It is well known for its way of clustering the data. However, it has issues in the creation of the normalized Laplacian matrix. The current study proposes three different ways of creating the normalized Laplacian matrix to rectify those issues. Based on these modifications, three new variants of the IKL algorithm are produced. Besides, the pair-wise similarity matrix (W) is another crucial element in the IKL algorithm. Earlier, the Gaussian function was used to create W in IKL, whereas this study proposes 12 different kernel functions to form W instead. Their influences on the existing and proposed algorithms’ performance are studied. Nine benchmark datasets are used to demonstrate the same. Further, the performances of proposed algorithms are compared with existing algorithms in recent literature by using the seven clustering evaluation metrics and running time of algorithms. The comparison studies reveal that the proposed modifications to the IKL algorithm are significant, and the statistical tests prove the same. Besides, an analysis is carried out by replacing the XX’ matrix with kernel functions, and the improvements in the performances are studied.},
  archive      = {J_EAAI},
  author       = {Sundar Rengasamy and Punniyamoorthy Murugesan},
  doi          = {10.1016/j.engappai.2021.104535},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104535},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {K-means – laplacian clustering revisited},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A blockchain integration to support transactions of assets
in multi-agent systems. <em>EAAI</em>, <em>107</em>, 104534. (<a
href="https://doi.org/10.1016/j.engappai.2021.104534">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Agent systems technology can offer valuable tools to develop applications in domains involving transactions of assets. However, they usually do not have a proper support for reliable and decentralized recording of the transactions that are common in this kind of system. This support can be provided by the Blockchain technology. Furthermore, it is important to have means to represent in the system concepts that are intangible, such as asset and ownership . This paper presents a model of integration between Multi-Agent Systems and Blockchain where an artificial institution connects the intangible concepts related to transactions of assets to the concrete elements composing the system. An application example illustrates an implementation following the proposed integration model, showing its advantages and limitations. In the example, agents contract each other to provide services upon the payment of a dealt value through a system based on cryptocurrencies and blockchain. It highlights the essential contributions of the proposed approach to systems where agents transact assets: regulation of the system, representation of the notion of asset that does not depend on agents, and reliable recording of transactions based on Blockchain.},
  archive      = {J_EAAI},
  author       = {Fernando Gomes Papi and Jomi Fred Hübner and Maiquel de Brito},
  doi          = {10.1016/j.engappai.2021.104534},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104534},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A blockchain integration to support transactions of assets in multi-agent systems},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-camera joint spatial self-organization for intelligent
interconnection surveillance. <em>EAAI</em>, <em>107</em>, 104533. (<a
href="https://doi.org/10.1016/j.engappai.2021.104533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The construction of smart city makes information interconnection play an increasingly important role in intelligent surveillance systems. Especially the interconnection among massive cameras is the key to realizing the evolution from current fragmented monitoring to interconnection surveillance. However, it remains a challenging problem in practical systems due to large sensor quantity, various camera types, and complex spatial layout. Aimed at this problem, this paper proposes a novel multi-camera joint spatial self-organization approach, which realizes interconnection surveillance by unifying cameras into one imaging space. Differing from existing back-end data association strategy, our method takes front-end data calibration as a breakthrough to relate surveillance data. Specifically, this paper first initials camera spatial parameter by sequence complementary feature integration. Through integrating complementarity and redundancy among sequence features, our method has robustness under scene dynamic changes and noise. Then, we propose a multi-camera joint optimization method based on common monitoring coverage correlation analysis to estimate a more accurate relative relationship. By leveraging the two strategies, the spatial relationship and visual data association across monitoring cameras are returned finally. Our system organizes all cameras into a unified imaging space by itself. Extensive experimental evaluations on an actual campus environment demonstrate our method achieves remarkable performance.},
  archive      = {J_EAAI},
  author       = {Congcong Li and Jing Li and Yuguang Xie and Jiayang Nie and Tao Yang and Zhaoyang Lu},
  doi          = {10.1016/j.engappai.2021.104533},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104533},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-camera joint spatial self-organization for intelligent interconnection surveillance},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An interactive consensus reaching model with updated weights
of clusters in large-scale group decision making. <em>EAAI</em>,
<em>107</em>, 104532. (<a
href="https://doi.org/10.1016/j.engappai.2021.104532">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consensus reaching process generates a group decision approved by all experts despite their possible divergent preferences. To circumvent a calculated and nominal consensus without exchanges of views, an interactive consensus reaching strategy is necessary even though it may bring costs, especially for large-scale group decision making problems. To allow experts to make cost-effective preference modifications to reach consensus in large-scale group decision making, this study proposes a dynamic interactive consensus reaching model. Firstly, a minimum-cost-consensus model that focuses on clusters in a large-scale context is introduced, in which the unit preference adjustment cost can be determined objectively. Then, we apply the minimum-cost-consensus solution to develop a feedback mechanism to activate discussions between experts and support preference modifications. The modification degree is defined towards each expert cluster to measure the cost performance of a cluster pertaining to the modifications. On this basis, we update the weights of clusters so as to improve the cost performance. An illustrative example about the grading management of high-alert medication is presented. By comparison, the interactive consensus model only costs 10.1 percent more than an automatic consensus model but gets group consensus with the exchanges of expert views.},
  archive      = {J_EAAI},
  author       = {Huchang Liao and Zheng Wu and Ming Tang and Zhengjun Wan},
  doi          = {10.1016/j.engappai.2021.104532},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104532},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An interactive consensus reaching model with updated weights of clusters in large-scale group decision making},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Three-objective constrained evolutionary instance selection
for classification: Wrapper and filter approaches. <em>EAAI</em>,
<em>107</em>, 104531. (<a
href="https://doi.org/10.1016/j.engappai.2021.104531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The large amount of data that is produced today with new technologies is an impediment for machine learning algorithms to work correctly, both due to the memory requirements and the necessary execution times. That is why the processes of reducing both the quantity and the size of the data are increasingly important. One of these processes is the so-called instance selection . In this paper we propose three-objective constrained optimization models to formulate instance selection wrapper and filter methods (separately) for classification problems, which are solved with multi-objective evolutionary algorithms and multi-objective differential evolution. In the proposed instance selection wrapper method, an objective is added to the usual ones to minimize the generalization error of the classifier. The proposed instance selection filter method simultaneously optimizes the correlation, redundancy and consistency of the datasets. Instance retention constraints are imposed on optimization models to retain a maximum percentage of samples, established by the decision maker, in big data scenarios. The experiments have been designed to compare (1) the NSGA-II and MODE algorithms, (2) two- and three-objective optimization models, (3) two different constraint handling techniques, and (4) the proposed evolutionary approaches and other 12 non-evolutionary approaches used in literature. The proposed wrapper and filter instance selection methods have been used in a real-world business engineering application, and have also been validated using three public datasets to facilitate the replicability of the research results. The results of the experiments show the superiority of the three-objective constrained evolutionary techniques proposed in this paper over the non-evolutionary techniques and over the two-objective evolutionary approaches used in the literature.},
  archive      = {J_EAAI},
  author       = {Fernando Jiménez and Gracia Sánchez and José Palma and Guido Sciavicco},
  doi          = {10.1016/j.engappai.2021.104531},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104531},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Three-objective constrained evolutionary instance selection for classification: Wrapper and filter approaches},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Lane-changing decision modelling in congested traffic with a
game theory-based decomposition algorithm. <em>EAAI</em>, <em>107</em>,
104530. (<a
href="https://doi.org/10.1016/j.engappai.2021.104530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a cellular lane-changing model where the traffic lanes are discretized into cells and formulates the lane-changing process as a multi-player non-zero-sum non-cooperative game in a connected environment where the real-time surrounding traffic data is shared. In a congested traffic scenario where a large quantity of mandatory lane-changing maneuvers are required simultaneously, the size of the game is extended dynamically (i.e., 2–5 players in this case, and it can be extended more if necessary) based on the traffic situation. Discretionary lane-changing maneuvers are also considered in the decision-making process to maximize the use of the capacity of each traffic lane, i.e., distributing the vehicles to each traffic lane as uniform as possible. Moreover, the competing vehicle on the target lane has more flexible actions (i.e., changing to other lanes) except for accelerating and decelerating actions. Thus, its temporary benefit is sometimes sacrificed by taking these actions to pursue the global benefit so that other vehicles could complete mandatory lane-changing maneuvers. It is a known fact that the space complexity expands exponentially as the game size increases, so a novel decomposition algorithm based on game theory is proposed to reduce the complexity and improve computational efficiency. Finally, a rule-based approach, a classic Nash equilibrium approach and the proposed decomposition algorithm are compared by the critical indicators such as the number of lane-changing vehicles, the maximum incoming queues during the process, the mean of computational time per iteration, etc. The performance shows no significant difference in the efficacy of lane-changing maneuvers among these approaches under the uncongested traffic condition. At the same time, the decomposition algorithm is more efficient in computing time than the classic Nash equilibrium approach. As the traffic gets congested, the game theory-based approaches prove more effective in lane-changing behaviours than the rule-based approach. Meanwhile, the decomposition algorithm outperforms the classic Nash equilibrium approach more significantly in terms of computational time.},
  archive      = {J_EAAI},
  author       = {Jian Guo and Istvan Harmati},
  doi          = {10.1016/j.engappai.2021.104530},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104530},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lane-changing decision modelling in congested traffic with a game theory-based decomposition algorithm},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-objective particle swarm optimizer based on
reference point for multimodal multi-objective optimization.
<em>EAAI</em>, <em>107</em>, 104523. (<a
href="https://doi.org/10.1016/j.engappai.2021.104523">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world applications, there are many multimodal multi-objective optimization problems, which have multiple equivalent global Pareto-optimal solutions or with at least one local Pareto-optimal solution in the decision space. While some evolutionary algorithms have been proposed to find the global solutions recently, they are difficult to handle multimodal multi-objective optimization problems with local solutions. Meanwhile, there have been few studies on searching for local Pareto solutions. However, local solutions are additional alternatives for the decision makers if global solutions are impracticable. This paper proposes a particle swarm optimizer based on reference point, termed RPPSO, which combines a reference point mechanism and a local solution preserving technique. The reference point strategy is utilized to establish multiple evenly distributed neighborhoods and guide particles to evolve independently in their respective neighborhoods, so as to detect more Pareto solutions in the decision space. The local solution preserving technique is employed to estimate the dominant radius of each front, and with this radius to classify the individuals as either non-local or local solutions with the aim of retaining the local solutions. In addition, a set of benchmark test functions with local Pareto solutions are designed. The proposed algorithm is comprehensively evaluated on forty-four benchmark functions and is compared with fourteen state-of-the-art algorithms. The experimental results show that the proposed RPPSO achieves competitive performance than its competitors in terms of the reciprocal of Pareto sets proximity ( rPSP ). The RPPSO is also applied to solve on one real-world problem (i.e., map-based problem) to further verify the effectiveness and efficiency.},
  archive      = {J_EAAI},
  author       = {Guosen Li and Ting Zhou},
  doi          = {10.1016/j.engappai.2021.104523},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104523},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-objective particle swarm optimizer based on reference point for multimodal multi-objective optimization},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Application of the novel four-parameter discrete optimized
grey model to forecast the wastewater discharged in chongqing china.
<em>EAAI</em>, <em>107</em>, 104522. (<a
href="https://doi.org/10.1016/j.engappai.2021.104522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The scientific and reasonable prediction of wastewater discharge is of great significance for regional water environment management and water resources protection. To this end, a new high-performance grey prediction model suitable for wastewater discharge prediction named FDGM(1,1, k , r ) is proposed based on the three-parameter discrete grey prediction model (TDGM(1,1) for short) in this paper. Firstly, the mechanism and structure defects of TDGM(1,1) are systematically analysed and made up in FDGM(1,1, k , r ) by adding a nonlinear correction term and new grey generation operator with real number field ( r ∈ R ). Then, the new information priority principle (Metabolic Thought) is introduced into the new model according to the dynamic nature of wastewater discharge prediction. Thirdly, the empirical results of wastewater discharge in Chongqing show that the mean relative percentage error of new model is only 0.216%, which is superior to other mainstream grey forecasting models of wastewater. Lastly, the new model is used to forecast the wastewater discharge in Chongqing China, and the prediction results show that the wastewater discharge in Chongqing will be as high as about 3.1 billion tones in Year 2025, and the government should formulate timely countermeasures to deal with the rapidly increasing wastewater discharge in the future.},
  archive      = {J_EAAI},
  author       = {Xiaoyi Gou and Bo Zeng and Ying Gong},
  doi          = {10.1016/j.engappai.2021.104522},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104522},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Application of the novel four-parameter discrete optimized grey model to forecast the wastewater discharged in chongqing china},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Updating incomplete framework of target recognition database
based on fuzzy gap statistic. <em>EAAI</em>, <em>107</em>, 104521. (<a
href="https://doi.org/10.1016/j.engappai.2021.104521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalized evidence theory (GET) is a generalization of Dempster–Shafer evidence theory. It copes with information in an open world, which makes up for the shortcoming that Dempster–Shafer evidence theory cannot handle information conflict effectively. However, GET also faces an unavoidable problem: how to determine the number of unknown targets in the incomplete frame of discernment (FOD). Fuzzy C-means (FCM) is a clustering algorithm that divides the original data set into different clusters and summarizes similar data into the same cluster. Therefore, determining the number of unknown targets in the open world can be transformed into finding the number of clusters. However, FCM has the disadvantage of subjectively controlling the number of clusters. In order to overcome this shortcoming, we use fuzzy gap statistic algorithm (FGS) to optimize it. FGS can effectively determine the optimal number of clusters in FCM. Therefore, this paper proposes a new method based on FGS to determine the number of unknown targets in the open world. In addition, to verify the method’s accuracy, we conducted seven experiments based on the University of California Irvine ( UCI ) data sets, including Iris, glass, Haberman, Knowledge, Robot, seeds, and WDBC. Finally, the experimental results illustrate that the proposed method to determine the number of unknown targets in the incomplete FOD has high effectiveness.},
  archive      = {J_EAAI},
  author       = {Zichong Chen and Rui Cai},
  doi          = {10.1016/j.engappai.2021.104521},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104521},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Updating incomplete framework of target recognition database based on fuzzy gap statistic},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An online learning algorithm to play discounted repeated
games in wireless networks. <em>EAAI</em>, <em>107</em>, 104520. (<a
href="https://doi.org/10.1016/j.engappai.2021.104520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discounted repeated games are currently being used to model the conflicts that arise between the nodes in a wireless network, such as distributed resource allocation, interference management or defending the network against attacks. In current literature, it is frequent that authors devise a specific strategy that performs well only for their concrete problem, thus, it would be desirable to have a generic algorithm that allows learning strategies for such games. However, current learning algorithms focus on average payoff repeated games, and we show analytically that there are important differences that prevent us from using such algorithms for discounted repeated games. In this work, we aim to fill this gap and we propose LEWIS, a lightweight, online learning algorithm specifically designed for these games, that deals with imperfect and incomplete information and is able to return a good payoff. We test LEWIS on two settings based on current literature problems to show that it has a good performance, hence, being a promising method to learn how to play a discounted repeated game in wireless networks.},
  archive      = {J_EAAI},
  author       = {Juan Parras and Patricia A. Apellániz and Santiago Zazo},
  doi          = {10.1016/j.engappai.2021.104520},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104520},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An online learning algorithm to play discounted repeated games in wireless networks},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Lyapunov-based continuous-time nonlinear control using deep
neural network applied to underactuated systems. <em>EAAI</em>,
<em>107</em>, 104519. (<a
href="https://doi.org/10.1016/j.engappai.2021.104519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several learning-based control with computational intelligence strategies handle challenges related to the difficulty of modeling complex systems or the need for control strategies with provably safe. In recent years, learning-based control using machine learning has been successfully demonstrated in robotics applications and applied to deal with nonlinearities. These control methods may lead to better solutions to nonlinear problems, such as the safety-critical industry, which requires strong guarantees about the controller behavior. Learning-based neural network control can comprehend and learn about plants, disturbances, the environment, and operating conditions. In this paper, we presented a Lyapunov-based nonlinear control determined from a deep neural network, which uses the Lyapunov theory to compute a control law for a nonlinear system. For advance stability analysis, an estimation of the region of attraction is presented. A numerical example and experimental simulations using the rotational inverted pendulum system are performed and compared with a conventional control technique. The proposed method calculated a control law that provided the stabilizability of the system and produced better solutions considering different tracking and process disturbance.},
  archive      = {J_EAAI},
  author       = {Rosana C.B. Rego and Fábio Meneghetti U. de Araújo},
  doi          = {10.1016/j.engappai.2021.104519},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104519},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lyapunov-based continuous-time nonlinear control using deep neural network applied to underactuated systems},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel multi-modal analysis model with baidu search index
for subway passenger flow forecasting. <em>EAAI</em>, <em>107</em>,
104518. (<a
href="https://doi.org/10.1016/j.engappai.2021.104518">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the boom of big data, the Internet contains more and more personal behavior information, but it is difficult to extract effectively. A model involving multivariate processing capability must be constructed to deal with these time series with complex characteristics. In this paper, a novel hybrid model embedding Baidu Search Index is therefore proposed to implement multi-step ahead subway passenger flow forecasting. Firstly, we collect data from informative Baidu Search Index, reduce dimensionality, and screen out the powerful predictors by statistical analysis. Secondly, we extract matching common modes at similar time scales between the subway passenger flow and screened Baidu Search Index via multivariate mode decomposition being optimized by multi-objective algorithm. Furthermore, to eliminate pseudo statistical causality, we select the optimal combination of modal components between subway passenger flow and its corresponding Baidu Search Index at each time scale by an innovative multi–modal analysis strategy. Thirdly, we reconstruct the forecasting values of each selected optimal combination as the final results. The empirical results of Beijing, Shanghai and Guangzhou show that the proposed model can significantly outperform six benchmark models in both the level and directional accuracy. So introducing Baidu Search Index creates a sound opportunity to enhance the subway passenger flow forecasting ability.},
  archive      = {J_EAAI},
  author       = {Kun Jin and Shaolong Sun and Hongtao Li and Fengting Zhang},
  doi          = {10.1016/j.engappai.2021.104518},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104518},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel multi-modal analysis model with baidu search index for subway passenger flow forecasting},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fuzzy risk analysis based on a similarity measure of fuzzy
numbers and its application in crop selection. <em>EAAI</em>,
<em>107</em>, 104517. (<a
href="https://doi.org/10.1016/j.engappai.2021.104517">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crop selection is an important task for optimum output, as it involves various risk factors. Hence, it requires performing risk analysis on crop selection. Generally, these risk factors involved in crop selection can be assessed by probabilistic methods, which require lots of data and are very expensive. As such, an alternative to probabilistic analysis, possibilistic analysis can be performed where the data involved are linguistic variables. These linguistic variables can be observed as fuzzy numbers, in which case fuzzy risk analysis plays an important role. Generally, in the process of fuzzy risk analysis, the final risks are fuzzy numbers, which have to be transformed into linguistic variables, so that the final risks become communicable to the general audience. The similarity measure is such a tool that helps in the process of transformation. Literature reveals lots of similarity measures since its development. This happens as there is not a single universally accepted measure. In this work, an attempt is being made to develop a novel measure of similarity between fuzzy numbers. Generally, the existing measures do not comply with the basic properties of a similarity measure. Nevertheless, the current measure oath to follow some reasonable properties of the similarity measure.},
  archive      = {J_EAAI},
  author       = {Mridul Krishna Gogoi and Rituparna Chutia},
  doi          = {10.1016/j.engappai.2021.104517},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104517},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fuzzy risk analysis based on a similarity measure of fuzzy numbers and its application in crop selection},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On-shelf utility mining from transaction database.
<em>EAAI</em>, <em>107</em>, 104516. (<a
href="https://doi.org/10.1016/j.engappai.2021.104516">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important technique for dealing with transaction database in the field of data mining, utility-driven mining can be used to discover useful patterns (i.e., itemsets, sequences) which have a high utility. However, it has a bias towards the item/object combinations which have more exhibition period since they have more opportunity to generate a high utility. To address this, the on-shelf time period of items need to be considered, thus on-shelf utility mining (OSUM) can be applied in the application which is more closer to the actual situation. Currently several models have been proposed to deal with the OSUM problem, but they still suffer from the requirement that it needs to maintain a massive candidates in memory and to scan database many times. In this paper, we propose two effective one-phase algorithms named OSUMI (On-Shelf Utility Mining from transactIon database) and OSUMI + (the improve version of OSUMI). Both OSUMI and OSUMI + search all itemsets as a set-enumeration tree and discover the on-shelf itemsets with high utility in a more practical way. More precisely, in order to avoid the problems of high memory consumption, two algorithms apply some properties of the concept of on-shelf utility. Besides, two upper-bounds named subtree utility and local utility are applied to early filter out unpromising patterns and then prune the search space. Finally, an extensive experimental study on several real on-shelf datasets shows that our proposed algorithms can be significantly faster than the state-of-the-art algorithm.},
  archive      = {J_EAAI},
  author       = {Jiahui Chen and Xu Guo and Wensheng Gan and Chien-Ming Chen and Weiping Ding and Guoting Chen},
  doi          = {10.1016/j.engappai.2021.104516},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104516},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {On-shelf utility mining from transaction database},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive polyhedral meshing for approximate dynamic
programming in control. <em>EAAI</em>, <em>107</em>, 104515. (<a
href="https://doi.org/10.1016/j.engappai.2021.104515">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes a new criterion for adaptive meshing in polyhedral partitions which interpolate a value function in Approximate Dynamic Programming (ADP) in optimal control problems. The criterion adds new points to a simplicial mesh, based on: a user-defined initial condition probability density function which determines ‘influential’ regions of the state space, uncertainty (variance) propagation, and temporal-difference error. A collection of lemmas justifies the algorithmic proposal. Comparative analysis with other options in literature highlights the advantages of our proposal. The developed methods are applied to simulation examples and an experimental robotic setup.},
  archive      = {J_EAAI},
  author       = {Antonio Sala and Leopoldo Armesto},
  doi          = {10.1016/j.engappai.2021.104515},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104515},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive polyhedral meshing for approximate dynamic programming in control},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Instance-based defense against adversarial attacks in deep
reinforcement learning. <em>EAAI</em>, <em>107</em>, 104514. (<a
href="https://doi.org/10.1016/j.engappai.2021.104514">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Reinforcement Learning systems are now a hot topic in Machine Learning for their effectiveness in many complex tasks, but their application in safety-critical domains (e.g., robot control or self-autonomous driving) remains dangerous without mechanism to detect and prevent risk situations. In Deep RL, such risk is mostly in the form of adversarial attacks, which introduce small perturbations to sensor inputs with the aim of changing the network-based decisions and thus cause catastrophic situations. In the light of these dangers, a promising line of research is that of providing these Deep RL algorithms with suitable defenses, especially when deploying in real environments. This paper suggests that this line of research could be greatly improved by the concepts from the existing research field of Safe Reinforcement Learning, which has been postulated as a family of RL algorithms capable of providing defenses against many forms of risks . However, the connections between Safe RL and the design of defenses against adversarial attacks in Deep RL remain largely unexplored. This paper seeks to explore precisely some of these connections. In particular, this paper proposes to reuse some of the concepts from existing Safe RL algorithms to create a novel and effective instance-based defense for the deployment stage of Deep RL policies. The proposed algorithm uses a risk function based on how far a state is from the state space known by the agent, that allows identifying and preventing adversarial situations. The success of the proposed defense has been evaluated in 4 Atari games.},
  archive      = {J_EAAI},
  author       = {Javier García and Ismael Sagredo},
  doi          = {10.1016/j.engappai.2021.104514},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104514},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Instance-based defense against adversarial attacks in deep reinforcement learning},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Incremental learning for property price estimation using
location-based services and open data. <em>EAAI</em>, <em>107</em>,
104513. (<a
href="https://doi.org/10.1016/j.engappai.2021.104513">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a tree-based incremental-learning model to estimate house pricing using publicly available information on geography, city characteristics, transportation, and real estate for sale. Previous machine-learning models capture the marginal effects of property characteristics and location on prices using big datasets for training. In contrast, our scenario is constrained to small batches of data that become available in a daily basis, therefore our model learns from daily city data, employing incremental-learning to provide accurate price estimations each day. Our results show that property prices are highly influenced by the city characteristics and its connectivity, and that incremental models efficiently adapt to the nature of the house pricing estimation task.},
  archive      = {J_EAAI},
  author       = {Francisco Alvarez and Edgar Roman-Rangel and Luis V. Montiel},
  doi          = {10.1016/j.engappai.2021.104513},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104513},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Incremental learning for property price estimation using location-based services and open data},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel similarity measure in intuitionistic fuzzy sets and
its applications. <em>EAAI</em>, <em>107</em>, 104512. (<a
href="https://doi.org/10.1016/j.engappai.2021.104512">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intuitionistic fuzzy set (IFS) is a classical branch of fuzzy set, which has advantage to deal with uncertain problems. In IFS, similarity measure is an important fundamental concept, it is used to measure consistency between different intuitionistic fuzzy sets (IFSs) and becomes a key parameter in fuzzy decision system. However, the previous methods of similarity measure do not take enough account the effect of hesitancy degree on membership degree and non-membership degree, so that produce counterintuitive results when measuring similarity. Hence, in this paper, a new similarity measure of IFS is presented. The effect of hesitancy degree on similarity measure is fully considered in the proposed method and some properties also haven been discussed to prove the reasonable of proposed method. Meanwhile, some numerical examples are analyzed to illustrate characteristics of proposed similarity measure in detail. Further, the experiments of target classification and clustering problem demonstrate effectiveness and superiority of proposed similarity measure in the environment of expert assessments and data set.},
  archive      = {J_EAAI},
  author       = {Lipeng Pan and Yong Deng},
  doi          = {10.1016/j.engappai.2021.104512},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104512},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel similarity measure in intuitionistic fuzzy sets and its applications},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Uncertainty quantification in neural networks by approximate
bayesian computation: Application to fatigue in composite materials.
<em>EAAI</em>, <em>107</em>, 104511. (<a
href="https://doi.org/10.1016/j.engappai.2021.104511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern machine learning algorithms excel in a great variety of tasks, but at the same time, it is also known that those complex models need to deal with uncertainty from different sources. Consequently, understanding if the model is indeed making accurate predictions or simply guessing at random is not trivial, and measuring the confidence bounds becomes very important. Bayesian machine learning seems to provide the solution, however, many of the state-of-the-art Bayesian algorithms use rigid parametric representations of the uncertainty where the learning process depends on the gradient of a predefined cost function. In this article, a new gradient-free training algorithm based on Approximate Bayesian Computation by Subset Simulation is proposed, where the likelihood function and the weights are defined by non-parametric formulations, resulting in a flexible and fairer representation of the uncertainty. The experiments, specially the engineering case study on composite materials subject to fatigue damage, show the ability of the proposed algorithm to consistently reach accurate predictions while avoiding gradient related instabilities, and most importantly, it provides a realistic and coherent quantification of the uncertainty represented by confidence bounds. All this may lead to a reduction of safety factors in engineering problems, and in general, allows us to make well-informed decisions in situations with a high degree of uncertainty and risk. A comparison with the state-of-the-art Bayesian Neural Networks is also carried out.},
  archive      = {J_EAAI},
  author       = {Juan Fernández and Manuel Chiachío and Juan Chiachío and Rafael Muñoz and Francisco Herrera},
  doi          = {10.1016/j.engappai.2021.104511},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104511},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Uncertainty quantification in neural networks by approximate bayesian computation: Application to fatigue in composite materials},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A dynamical artificial bee colony for vehicle routing
problem with drones. <em>EAAI</em>, <em>107</em>, 104510. (<a
href="https://doi.org/10.1016/j.engappai.2021.104510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Truck-drone hybrid delivery is a hybrid one combining the advantages including large capacity of truck and high travel speed of drone together. Vehicle routing problem with drones (VRP-D) is a common one in the above delivery system. In this paper, VRP-D is addressed and a new dynamical artificial bee colony (DABC) is employed to minimize the overall operational cost. Two bee swarms are produced and an effective evaluation process is used to determine employed bee swarm and onlooker bee swarm dynamically. Variable neighborhood descent is constructed by using 15 neighborhood structures and adopted in employed bee phase and onlooker bee phase in different ways. A number of experiments are conducted on 112 instances and the computational results reveal that DABC provides new best solutions for 37 instances and has promising advantages on VRP-D.},
  archive      = {J_EAAI},
  author       = {Deming Lei and Zhengzhi Cui and Ming Li},
  doi          = {10.1016/j.engappai.2021.104510},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104510},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A dynamical artificial bee colony for vehicle routing problem with drones},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Dynamic feature weighting for data streams with
distribution-based log-likelihood divergence. <em>EAAI</em>,
<em>107</em>, 104509. (<a
href="https://doi.org/10.1016/j.engappai.2021.104509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data streams are expected to undergo changes in data distribution, a phenomenon called concept drift. Another closely related phenomenon is the feature drift of data streams. Feature drifts occur whenever a subset of features becomes, or ceases to be, relevant to the learning task. Identifying the most relevant feature subset from a high-dimensional feature space is challenging in the stream mining scenario. In this study, we propose an online dynamic feature weighting algorithm. Specifically, a feature drift detection scheme is introduced that monitors the changes in the class relevance of the features through a change-detection algorithm based on the log-likelihood divergence score. The score is computed via the kernel density estimator based on the information-theoretic feature merit values. The algorithm is evaluated on both synthetic and real-world datasets, and it is shown that the proposed distribution-based drift detection framework can boost the Nearest Neighbor and Naive Bayes classifier accuracy rates (an average of 2.7% for Nearest Neighbor and 5.5% for Naive Bayes). It also signals feature drifts much faster than traditional methods based on detecting changes in accuracy rates. Finally, the limitations of the proposed method are assessed, and future research directions are discussed.},
  archive      = {J_EAAI},
  author       = {Xiaokang Wang and Huiwen Wang and Dexiang Wu},
  doi          = {10.1016/j.engappai.2021.104509},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104509},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic feature weighting for data streams with distribution-based log-likelihood divergence},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Advanced strategies on update mechanism of sine cosine
optimization algorithm for feature selection in classification problems.
<em>EAAI</em>, <em>107</em>, 104506. (<a
href="https://doi.org/10.1016/j.engappai.2021.104506">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sine Cosine Algorithm (SCA) that is one of the population-based metaheuristic optimization algorithms basically consists of the updating mechanism based on sine and cosine functions. In this algorithm, a few random and adaptive variables are also utilized for more effective motions of the candidate solutions. SCA has some drawbacks like other some metaheuristic algorithms. SCA tends to be stuck into the local regions in the search space and this affects negatively on the computational effort required to find the best solution point in the search space. This paper presents four different improved versions of SCA. The proposed improvements on original SCA are the innovations on the updating mechanism of SCA. To evaluate the performances of Improved Sine Cosine Algorithms (ImpSCAs), well-known numerical optimization problems including CEC 2014 test suite are used. Firstly, different analyses of the proposed ImpSCAs are dealt with such as the convergence analysis, search history analysis, trajectory analysis, average distance analysis, and computational complexity analysis. Secondly, the proposed four versions of ImpSCAs are compared with the original SCA for CEC 2014 benchmark problems with dimension sizes of 10D, 30D and 50D. Finally, original SCA and ImpSCAs are adapted to select optimal feature combination and they are tested for 10 feature selection datasets taken from the UCI machine learning repository. The benchmark results show that the performances of the ImpSCA 1 , ImpSCA 2 , and ImpSCA 4 are better than that of the original SCA. From the feature selection results, it is observed that three versions of ImpSCAs (except ImpSCA 3 ) outperform the original SCA in 80% of the datasets. Source codes of ImpSCAs are publicly available at https://github.com/uguryuzgec/ImpSCAs .},
  archive      = {J_EAAI},
  author       = {Gizem Ataç Kale and Uğur Yüzgeç},
  doi          = {10.1016/j.engappai.2021.104506},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104506},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Advanced strategies on update mechanism of sine cosine optimization algorithm for feature selection in classification problems},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Knowledge-based operation optimization of a distillation
unit integrating feedstock property considerations. <em>EAAI</em>,
<em>107</em>, 104496. (<a
href="https://doi.org/10.1016/j.engappai.2021.104496">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The distillation unit (DU) is an essential product separation unit in refineries. The process operation of DU is directly related to the quality and yield of the final petroleum products. The DU studied in this work is deeply troubled by the varying feedstock properties, which aggravates the difficulty of process operation. To determine the proper operation variables, a knowledge-based operation optimization (KOO) strategy of a DU is proposed in this paper. The KOO strategy is composed of a supervision module and an optimization module. First, the operating conditions are divided into four types based on the feedstock properties. In supervision module, an improved bar-shaped convolutional neural network supervision model (IBS-CNN-based SM) is developed to monitor the operating conditions. The model output which represents the current operating condition information is transmitted to the lower optimization module. In optimization module, the fuzzy-logic-based optimization strategy is designed to adjust two temperature variables — the top temperature of the distillation column (TTDC) and the outlet temperature of the re-boiling furnace (OTRF) to ensure the product quality requirements. Industrial experiments have illustrated the KOO strategy could adapt to the varying feedstock properties. During the experiment, the proposed KOO strategy improved the product qualification rate from 86.67% to 93.34% and saved the consumption of gas and cooling water to a certain extent.},
  archive      = {J_EAAI},
  author       = {Sihong Li and Yi Zheng and Shaoyuan Li and Meng Huang},
  doi          = {10.1016/j.engappai.2021.104496},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104496},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Knowledge-based operation optimization of a distillation unit integrating feedstock property considerations},
  volume       = {107},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
